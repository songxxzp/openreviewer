[
    {
        "id": "U3yk23nowoc",
        "original": null,
        "number": 1,
        "cdate": 1666574714854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666574714854,
        "tmdate": 1666574714854,
        "tddate": null,
        "forum": "PEgBEB74JjB",
        "replyto": "PEgBEB74JjB",
        "invitation": "ICLR.cc/2023/Conference/Paper2592/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is concerned with solving the symmetric generalized eigenvalue problem $Av = \\lambda B v$ , which generalizes various other well known problems like PCS, CCA, ICA etc. A particular approach chosen is to consider a corresponding game between k players and the rewards are set such that the Nash equilibrium is the top-k solution. What we already know about this problem: If we can invert B in the equation above, then SGEP can be solved as an SVD problem. This however loses structure (for example A and B are symmetric in SGEP) and therefore previous game theoretic approaches to solving SVD do not apply here.\n\nLike mentioned above, the approach in this work is to construct a game between k players each selecting a strategy $v_i$. Their first main contribution is in constructing a sound utility function such that the Nash equilibrium of this game is the top-k SGEP solution. Intuitively, the utility for player i conditioned on players j < i (henceforth parents of i) is designed to: (1) incentivize finding directions that have large eigenvalues (called reward) (2) but simultaneously choosing directions which are far from directions chosen by the parents. \n\n To show that these rewards are sound, the work first shows that assuming $B^{-1}A$ has nice spectrum, and the parents converge to correct eigenvectors (called exact parents henceforth), the unique generalized eigenvector $v_i$ maximizes the player i's utility. This follows from noting that for the exact parents, the penalty term linearizes after a re-parameterization (and the reward term is already linear in the said re-parameterization). This shows that the top-k eigenvectors form the strict Nash equilibrium of this game. \n\nAnother particular important aspect of this utility design is that every local maximum is a global maximum here which follows from previous work. Together with above result, this suggests a simple gradient based algorithm. The work next shows under deterministic setting (A and B are known), this simple gradient based algorithm asymptotically converges. This requires proving that the error in eigenvectors for parents lead to bounded error in the solutions for the children. This result borrows ideas from previous work [Gemp et al. 2021].\n\nSome care is needed to extend this to stochastic/streaming setting, we need the terms appearing in the denominator to be nicely conditioned and have to be handled appropriately. This algorithm has a per iteration complexity $dk$ which improves over the previous state-of-the-art per iteration complexity $d^2k$. This is followed by extensive experiments on CCA and ICA showing in practice this method is competitive. ",
            "strength_and_weaknesses": "I think the writing in the paper could use some more work. Especially since most of the claims have short and simple proofs, it would be nice to include some more intuition about them in the main text. I verified most of the proofs in the supplementary materials. Some other concerns I have:\n1. Theorem 1 (which follows from Lemma 1) does not require Proposition 1. And therefore Proposition 1 should not be before Definition 1 and Theorem 1. In fact, its only ever used in showing that Algorithm 2's updates are unbiased. \n\n2. Lemma 1: $w_p$ are not defined. It would be nice to say they are arbitrary real coefficients and give some exposition on your end goal. For example, we now consider $\\hat v_i$ as arbitrary linear combination of $v_i$'s. We will show that maximizing the utility for player is same as solving the following linear program: ...\n\n3. Proposition 1: It would be nice to give a more definite reference for EigenGame (and results implying the utility function is cosine).\n\n\nI think the claims about improving the per-iteration complexity should be followed by explanation about its implication on total time complexity. I think it should be noted that this algorithm does not have convergence rates and in fact, the error from parents on the time-complexity would show up in the number of iterations needed for the algorithm to converge. This is real and looking through proof of Theorem 2, it seems like the number of iterations even in the deterministic case scale exponentially in $k$ (since the $\\epsilon$ error from parents lead to $\\sqrt{\\epsilon}$ error in children's fixed point).\n\nThat said, I would like to emphasize that the above comment does not dilute the contribution of this work.\nI think the paper makes a good technical contribution to an important problem.",
            "clarity,_quality,_novelty_and_reproducibility": "\nOther than the issues raised above, I do not have any other comments. ",
            "summary_of_the_review": "I think this is a good contribution to understanding game theoretic version of various problems like ICA, PCA, CCA etc. Moreover, this work provides a very practical algorithm.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_4TCc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_4TCc"
        ]
    },
    {
        "id": "lz0PV9-ED3",
        "original": null,
        "number": 2,
        "cdate": 1666625586143,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625586143,
        "tmdate": 1666625586143,
        "tddate": null,
        "forum": "PEgBEB74JjB",
        "replyto": "PEgBEB74JjB",
        "invitation": "ICLR.cc/2023/Conference/Paper2592/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an algorithm to compute the $k$ dominant eigenpairs of a streamed matrix. The algorithm is based on an optimization viewpoint where each individual eigenpair is maximizing a separate cost function. Numerical experiments verify the effectiveness of the proposed scheme.",
            "strength_and_weaknesses": "I tried my best to check the proofs and they appear correct.\n\nStrengths:\n-) The paper introduces a nice setting/idea for eigenvalue computations.\n-) Lots of intuition is presented and discussed.\n-) Results demonstrate that the proposed method is effective.\n\n-) The difference between eigengame-PCA and the current work is not properly explained.\n-) The authors should discuss in more depth other optimization-based eigenvalue solvers such as TraceMIN or LOBPCG. \n-) It's likely I missed something here, but why do the authors need to include the \"Nash's equilibrium\" phrase throughout their paper? \nIt seems to me that the algorithm developed is nothing more than an optimization-based eigenvalue solver for streamed datasets; which is absolutely fine for a publication. What am I missing?\n-) The discussion about computational complexity is a bit confusing; why is $O(dk)$ after we parallelize across M=b batches? Is the cost per iteration of for-k loop only $O(d)$? I thought it would $O(dk)$ (which means the paralleized complexity is $O(dk^2)$). I must be missing something here.\n-) My main concern is the following: are there really situations where I can not access the matrices A and B in a sequential batched manner? Because in this case the authors can use standard numerical linear algebra optimization-based approaches (i.e., out-of-core computing). In other words, in what applications $A$ and $B$ are accessed truly randomly?",
            "clarity,_quality,_novelty_and_reproducibility": "All good.",
            "summary_of_the_review": "The proposed method is interesting and the paper is well-written. My main concerns are: a) similarity with the PCA case, and b) realistic application in modern problems.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_dLpL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_dLpL"
        ]
    },
    {
        "id": "zBDWfNCxNbh",
        "original": null,
        "number": 3,
        "cdate": 1666658318736,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666658318736,
        "tmdate": 1668097954418,
        "tddate": null,
        "forum": "PEgBEB74JjB",
        "replyto": "PEgBEB74JjB",
        "invitation": "ICLR.cc/2023/Conference/Paper2592/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work provides an algorithm for identifying the top-$k$ generalized eigenvalues for a pair of symmetric positive definite matrices $A$ and $B$. The algorithm works by reducing this problem to finding a Nash equilibrium to a multi-player game. For this game the authors prove that the gradient ascent algorithm provably converges asymptotically to the top-$k$ generalized eigenvalues. \n\nThe authors also seek to extend their algorithm to the stochastic setting where matrices $A$ and $B$ are accessible through stochastic estimates of their vector products via batching. They propose several modifications to their original objective that addresses several problems that arise with providing unbiased gradient estimates. While their modifications lead to unbiased estimators, they also make a complete and formal analysis harder and thus they leave it for future work. Empirically though, they do observe convergence on problems 1000x larger than the ones studied by prior work.\n\nThe ability to have independent machines processing independent mini-batches of $A$ and $B$, allows for low per-iteration complexity $O(dk)$ as compared to prior state of the art which requires $O(d^2k)$. The key is that matrix vector products cost $O(d)$ instead of $O(d^2)$ when considering minibatches of $O(1)$ samples. ",
            "strength_and_weaknesses": "This work has three major strengths. First, the problem of generalized eigenvalue problem and its importance to the machine learning community is thoroughly motivated. Second, although there have been several works studying game-theoretic solutions to the standard (non-generalized) eigenvalue problem, these approaches are not directly applicable since the generalized eigenvalue problem is not equivalent to a standard eigenvalue problem for a symmetric positive definite $A$. Third, a direct generalization of previous approaches (for example using Equation (4) or (5)) poses unique challenges when applied to the stochastic (mini-batch) setting. Up to the technical issues outlined in Appendix E.2, the proposed approach resolves these challenges.\n\nRegarding weaknesses, there are some points in this work that could benefit from additional elaboration.\n\na) $O(dk)$ iteration complexity property\nThe way I understand it, every algorithm that uses matrix vector products and has as many machines per player as the datapoints in the batch of $A$ and $B$ also avoids the $O(kd^2)$ factor in their per-iteration analysis. Effectively, it seems to me that the key claim is that the proposed algorithm only uses matrix vector products whereas prior art does not. I think clarifying if this is really the case and why prior work cannot adopt the same matrix-vector product interface would help. \n\nSecondarily, as stated the result has some limitations. It is unclear how setting the batch size to be equal to the machine count per player affects the number of iterations required. It is not clear if we are trading off faster iterations and higher iteration counts. \n\nb) Comparison with top-1 generalized eigenvector + deflation\nThis theoretical analysis of this work a lot of times argues that given (approximate) convergence of players $i < j$, player $j$ can approximately find the $j$th generalized eigenvector. To me this seems very similar to how we can use power iteration and variants to find the top eigenvector, apply a deflation step and then find the next eigenvector.\n\nIt is not clear to me if one could apply an algorithm for a top-1 generalized eigenvector like Bhatia et al. (2018) and with an appropriate deflation step find the next one and so forth. Is this actually the case? If so what are the limitations? If not, why?\n\nA key advantage I can see is that here all players work concurrently whereas the other approach would find the eigenvectors sequentially. The theoretical analysis however does not seem to take advantage of that. Maybe an experimental comparison between updating all players concurrently and only updating after the convergence of previous players would help clarify this point to the reader.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Regarding clarity, I refer the authors to points a) and b) above. Beyond the two points above, both the quality and the clarity of the writing looks good to me. \n\nRegarding novelty, although the skeleton of the analysis and the main tools (e.g. penalty terms, error propagation etc.) are the same with the prior work for the standard (non-generalized) eigenvalue problem, the generalized eigenvalue problem poses unique challenges (providing unbiased gradient estimators) that this work addresses, at least partially on the theoretical front. On the empirical side, the proposed approach is shown to outperform the previous state of the art approaches.\n\nRegarding reproducibility, the authors detail the hyper-parameters used in their experiments. They also plan to open source their code, making their experimental claims fully auditable by peers.  \n",
            "summary_of_the_review": "I recommend this paper for acceptance. I am inclined to raise my score higher if the authors improve on the points raised in the \"Strengths and Weaknesses\" section. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_U98f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_U98f"
        ]
    },
    {
        "id": "cItbdZXmcFq",
        "original": null,
        "number": 4,
        "cdate": 1666669786451,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669786451,
        "tmdate": 1666669786451,
        "tddate": null,
        "forum": "PEgBEB74JjB",
        "replyto": "PEgBEB74JjB",
        "invitation": "ICLR.cc/2023/Conference/Paper2592/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers the problem of finding top-k eigenvalues of the symmetric generalized eigenvalue problem (SGEP). It proposes a game-theoretic formulation whose Nash equilibrium is the top-k eigenvalues of SGEP. Using this new result, the authors develop a parallelizable algorithm suitable for tackling SGEP with streaming data sets. It proves the asymptotic convergence of the proposed algorithm and show how to achieve O(dk) runtime complexity. ",
            "strength_and_weaknesses": "Strength:\n1. The paper is clearly motivated and written. It is a pleasure to read.\n2. The game-theoretic formulation is novel, which motivates the development of the novel algorithm.\n3. The proposed algorithm is equipped with strong convergence guarantees.\n4. The proposed algorithm is suitable for parallelization and can achieve O(dk) runtime complexity, which outperforms O(d^2k) in state-of-the-art algorithms.\n\nWeakness:\n1. It seems that the convergence guarantee of the stochastic version of the algorithm is missing.\n2. Can this approach be applied to general non-symmetric GEP? ",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: High\nClarity: Overall good. It would be better to add the keyword \"symmetric\" in the title. \nOriginality: High",
            "summary_of_the_review": "This paper proposes a game-theoretic formulation for SGEP. Based on the novel result that the Nash equilibrium of the formulation is the top-k eigenvalues of SGEP, the authors propose a novel algorithm, which shed new light on many problems that can be equivalently formulated as SGEP. The full-batch version of the proposed algorithm is equipped with theoretical guarantee. It is also applicable to streaming data set with seemingly good numerical performance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_aVkz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2592/Reviewer_aVkz"
        ]
    }
]