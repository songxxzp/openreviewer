[
    {
        "id": "KAXOgLWZGUg",
        "original": null,
        "number": 1,
        "cdate": 1666162582965,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666162582965,
        "tmdate": 1669036030060,
        "tddate": null,
        "forum": "SNzzt94tGzP",
        "replyto": "SNzzt94tGzP",
        "invitation": "ICLR.cc/2023/Conference/Paper313/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles anomaly detection using a memory-based autoencoder approach. The main problem with reconstruction-based AD is that both normal and anomalous examples are well reconstructed making the anomaly score weak. Memory-based AE approaches have not addressed this problem sufficiently. This paper proposed a fairly complex memory mechanism which claims to overcome those issues. It draws inspiration from human cognition (although the precise analogy is not made very clear). The method is compared to a handful of memory-based AE approaches on simple dataset, and claims to obtain better results. ",
            "strength_and_weaknesses": "The task of anomaly detection is obviously important. Reconstruction-based methods have been around for a long time, but getting them to SoTA performance would be very interesting. \n\nI am not positive towards this paper. It makes very strong claims but does not deliver. \n* It claims \"We experimentally demonstrated the human brain\u2019s similarity between RFTM and hippocampus-cortex structures\". This is a really strong claims and I do not think there is sufficient evidence to support it.\n* It claims \"state-of-the-art experimental results\" but in fact the experiments show it's ROCAUC on Cifar10 is around 50% (random performance). The comparison was only made against memory-based AE methods which are far from SoTA. Comparison against CSI (Tack et al.) or PANDA (Reiss et al.) would not support the above claims.\n\nFurthermore, the approach is probably too complex for its level of performance. The design choice is not justified by a sufficient ablation study making it unclear which aspects are in fact helpful.\nFinally, the complexity of the method made it unclear to me. With difficulty I think I managed to understand it, but it still seems arbitrary to me.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The language is clear, but the complexity of the method made it unclear to me although, with difficulty, I think I managed to understand it.\n\nQuality: as mentioned above the key claims are unsupported, ablations and state-of-the-art comparisons are missing. I do not consider the quality as high.\n\nNovelty: While I do not think this mechanism has been proposed before, I did not see new ideas which I could clearly \"take home\" from this paper.\n\nReproducibility: The authors claim this can be implemented using a single line of code, however it would have been helpful to see the code.",
            "summary_of_the_review": "The paper tackles an important problems but the method is not well motivated, unclear. The experimental results are also unsatisfactory.  I recommend rejection.\n\n#######################################################\n\nI have read the the two responses by the authors but would like to keep my rating. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper313/Reviewer_P1F7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper313/Reviewer_P1F7"
        ]
    },
    {
        "id": "w1osoP5FMK-",
        "original": null,
        "number": 2,
        "cdate": 1666577845769,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577845769,
        "tmdate": 1666578601720,
        "tddate": null,
        "forum": "SNzzt94tGzP",
        "replyto": "SNzzt94tGzP",
        "invitation": "ICLR.cc/2023/Conference/Paper313/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper mainly explores the issue of \u201covergeneralization\u201d in unsupervised anomaly detection and proposed a bio-inspired solution, termed \u201cRandom Forgetting Twin Memory (RFTM).\u201d The new model did not change the fundamental structure of existing learning models, e.g., autoencoder, and work in a plug-and-play fashion. It achieves state-of-the-art performance on several public benchmarks.",
            "strength_and_weaknesses": "Strength:\n* The new method is promising compared to other memory mechanism-based anomaly detection methods under the unsupervised semantic anomaly detection (USAD) setting.\n\nWeakness:\n* The major issue is about the experiment design that only USAD setting is considered. While this setting is challenging, other routine settings would be considered as well. This allows the new methods to be evaluated on a variety of data such as image/video datasets.\n* How about the performance of the new method compared to non-reconstruction methods, e.g., [1], which also provides appealing performance under the USAD setting? \n* While it is fair to use the same encoder/decoder in the experiments, readers may be more interested in other methods, e.g., DAAD mentioned in the \u201cintroduction.\u201d\n\n[1] Jihoon ,et al; CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The provided ablation study, illustration, and insights are helpful, too.\n\nThe focus of this paper is to design an improved memory-based and bio-inspired learning module. There are similar methods in this lineup already, although the new one improves the performance on USDA benchmarks.\n\nThe paper may be reproducible as implementation and experiment details are both provided. \n",
            "summary_of_the_review": "In brief, the new method developed an interesting bio-inspired RFTM model under the USAD setting to solve the issue of \u201covergeneralization.\u201d The model details are well-elaborated. However, the experiments are inadequate as only the USAD setting is considered. Other routine settings and non-reconstruction methods should be considered and compared in a more comprehensive way.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper313/Reviewer_8c7P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper313/Reviewer_8c7P"
        ]
    },
    {
        "id": "Upd0T27ZIg",
        "original": null,
        "number": 3,
        "cdate": 1666625601942,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625601942,
        "tmdate": 1666625601942,
        "tddate": null,
        "forum": "SNzzt94tGzP",
        "replyto": "SNzzt94tGzP",
        "invitation": "ICLR.cc/2023/Conference/Paper313/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The work presents a memory network-based autoencoder method for unsupervised anomaly detection, in which random forgetting gates and top-k prototype selection functions are used to regularize the autoencoder networks to avoid overfitting. ",
            "strength_and_weaknesses": "Strengths.\n- The studied problem - having small reconstruction errors in reconstructing anomalous samples - is a common problem in autoencoder-based AD approaches\n- In the presented method, the key idea of enforcing less prototypes in the memory to alleviate the problem is plausible\n- A set of empirical results on three commonly used datasets is used to justify the effectiveness of the proposed method. \n\nWeaknesses.\n- Although the key idea is plausible, it shares similar insights to the previous memory network-based autoencoder approaches for anomaly detection, such as MNAD. The main objective there is to learn less yet compact prototypes to avoid the overfitting of the data. Although the specific way to achieve this objective is different from each other, the new prototype learning in this work does not make clear major contributions. The proposed method seems to simplify the memory learning, but its effectiveness is not clear (see comments below).\n- The presented results are not convincing. 1) The reported results of the competing methods in the paper are significantly worse than the ones in the their original papers and some recent relevant papers [A,B]. 2) The performance of the presented method is far below that of the current SOTA models (e.g., see the results on the three datasets in [A,B]).\n- There are a number of false/misleading claims, such as what does it mean by unlabeled normal samples in \"Unsupervised anomaly detection (UAD) only needs to fit the unlabeled normal samples to learn the normal patterns\" (why is it unlabeled if the samples are known to be normal), and \"most of the experiments were not conducted based on the USAD setup\" when reviewing memory network-based AD methods.\n- It is unclear why the learned memory can be named as Hippocampus and Cortex memory.\n- It claims that the method can work as a plug-and-play component, but not empirical results are given to support this claim.\n\nReferences.\n- A. \"Anomaly Detection via Reverse Distillation from One-Class Embedding.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9737-9746. 2022.\n\n- B.  \"Deep one-class classification via interpolated gaussian descriptor.\" In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 1, pp. 383-392. 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation quality is below the average of ICLR given the issues identified above. The originality of the paper is also weak.",
            "summary_of_the_review": "The paper has major issues in main claims, empirical justification and clarity, and its technical novelty is marginal.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper313/Reviewer_c8kV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper313/Reviewer_c8kV"
        ]
    },
    {
        "id": "D8DCBzoMR7g",
        "original": null,
        "number": 4,
        "cdate": 1666666506687,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666506687,
        "tmdate": 1666666506687,
        "tddate": null,
        "forum": "SNzzt94tGzP",
        "replyto": "SNzzt94tGzP",
        "invitation": "ICLR.cc/2023/Conference/Paper313/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The model consists of three parts: encoder, decod er, and RFTM, The encoder \nmakes a nonlinear transform to the input data x in the latent space. The latent data goes through a re-representation (in the same dimensionality) by the RFTM. Then the data is reconstructed by the decoder. The anomaly of the test sample is measured by reconstruction error. In particular, the RFTM  uses limited prototypes to record and re-represent the latent representation, which makes suppression of overgeneralization feasible, and can be trained end-to-end without introducing any additional penalty terms on top of the original task loss function. The rest of the paper is used to show the functioning of the RFTM module with some comparative results and a lot of ablation studies.\n",
            "strength_and_weaknesses": "Strenghts: \nUnsupervised anomaly detection is a very interesting topic, more insidious than outlier detection.\n\n\nWeaknesses:\nThe comparative results are obviously insufficient, since only Vanilla AE, MemAE and MNAD were used as comparison models. Instead, Trust-MAE, DAAD, [Ruff et al., 2021] should be considered (and already mentioned by the authors in the state of the art). Other approaches are\n\n-- Deep Unsupervised Image Anomaly Detection: An Information Theoretic Framework 2020\n-- FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows\n-- Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection\n--Robust Subspace Recovery Layer for Unsupervised Anomaly Detection  2019\nThese approaches should also be present and discussed in the state of the art\n\nSecond, the study of figure 7 is not clear at all. The space constructed by the autoencoder and the two types of memory of the RFTM should have cavities (autoencoder) and less cavities (the second type of memory of the RFTM in particular). This is somewhat visible in the figures b and c. What is not clear is why the model needs to have a representation space that is dense enough that the anomalies are always forced to be embedded in the distribution of normal representations. Isn\u2019t this a way to hide anomalies instead of highlighting them?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: not clear why density would be needed in the space to avoid overgeneralization. Not clear the figures of Fig.7, and how they demonstrate the goodness of the proposed approach. \n\nQuality: Results are obtained wrt a limited number of state of the art approaches.\n\nNovelty: the approach seems novel, but I cannot judge how much powerful given the limited comparisons\n\nOriginality: Cortex and hippocampus parallelism with the medicine should be more stressed since they are very attractive as justification of the approach.",
            "summary_of_the_review": "- state of the art is insufficien, and I have provided some of the SOTA approaches for UAD\n- qualitative results in FIg.7 are not clear",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper313/Reviewer_ZPFH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper313/Reviewer_ZPFH"
        ]
    }
]