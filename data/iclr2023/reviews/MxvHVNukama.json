[
    {
        "id": "BOH1e1obD0",
        "original": null,
        "number": 1,
        "cdate": 1666699329989,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699329989,
        "tmdate": 1666701330175,
        "tddate": null,
        "forum": "MxvHVNukama",
        "replyto": "MxvHVNukama",
        "invitation": "ICLR.cc/2023/Conference/Paper340/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper investigates contrastive learning in the context of building sentence representations. It finds that the decoupled form that decomposes the contrastive loss into aligment and uniformity components can have a detrimental effect in this setting, due to different training dynamics compared to the InfoNCE loss. These effects can be overcome by truncating the gradients once the negative examples are sufficiently further away compared to the positive example. Crucially, the amount of thresholding is controllable independently of the batch size.",
            "strength_and_weaknesses": "Strengths:\n- The paper investigates different variants of contrastive learning in the context of concrete tasks with natural language\n- It is able to identify a problem with the decoupled contrastive learning approach in this setting, and propose a fix that both addresses this problem and restores performance on downstream tasks\n- The paper proposed loss formulations close to the Triplet loss that typically achieve performance comparable or better than the InfoNCE loss\n\nWeaknesses:\n- After reading the paper, I didn't come away with a clear understanding regarding why the investigation into different contrastive losses is important. One way of looking at the situation is that for any given task there will always be some hyperparameter choices that perform better or worse than others, and in this situation the InfoNCE loss works well and the decoupled versions aren't as good. In that view, this key takeaway from the paper would simply be the advice to always use the InfoNCE objective for sentence representation learning. Clearly there is more going on, but I worry that my impression here points to potentially limited impact of the paper, or at least that the paper doesn't sufficiently convey the importance to the reader. For example, some of the past work was dealing with very real computational limitations related to large batch sizes, but that doesn't seem to be at issue here.\n- ",
            "clarity,_quality,_novelty_and_reproducibility": "See above",
            "summary_of_the_review": "Overall my assessment is that despite the very thorough experiments in the paper regarding different loss formulations, ultimately the scope of the paper is narrow compared to typical papers at ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper340/Reviewer_Rqm3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper340/Reviewer_Rqm3"
        ]
    },
    {
        "id": "EbzWi4k8rR",
        "original": null,
        "number": 2,
        "cdate": 1667013535084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667013535084,
        "tmdate": 1668912102635,
        "tddate": null,
        "forum": "MxvHVNukama",
        "replyto": "MxvHVNukama",
        "invitation": "ICLR.cc/2023/Conference/Paper340/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper identifies an issue with decomposed contrastive losses: a lack of gradient dissipation, which the paper claims leads to overfitting. Gradient dissipation means once negative examples are sufficiently far, those examples effectively no longer receive gradient. To fix this, a series of margin-based contrastive losses are proposed, with different energy functions: dot product, Euclidean distance, and angular difference. Models are then evaluated on semantic similarity tasks and other classification tasks (detailed in Appendix A.1).",
            "strength_and_weaknesses": "*Weaknesses*\nThe contribution of a margin-based contrastive loss has been previously explored. See the Novelty section below.\nAdditionally, I find it concerning that BERT consistently outperforms RoBERTa in the downstream transfer tasks. Why is this the case?\n\n*Additional questions and comments*\n1. The bolding in Table 1 is not consistent across columns.\n2. Is the reason gradient dissipation helps because it allows the model to focus on more difficult examples, rather than continuing to optimize easy ones which already satisfy the margin constraint?",
            "clarity,_quality,_novelty_and_reproducibility": "*Clarity*\nThe paper was clearly written and I enjoyed reading the paper.\n\n*Novelty*\nSimilar margin-based contrastive losses have been proposed [1,2,3]. I do not see how the contribution of this paper differs from previous papers which have used margin-based contrastive losses. If I am misunderstanding the contribution, I am happy to be corrected.\n\n[1] Choi, Hongjun, Anirudh Som, and Pavan Turaga. \"AMC-loss: Angular margin contrastive loss for improved explainability in image classification.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops. 2020.\n[2] Hadsell, Raia, Sumit Chopra, and Yann LeCun. \"Dimensionality reduction by learning an invariant mapping.\" 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06). Vol. 2. IEEE, 2006.\n[3] Shah, Anshul, et al. \"Max-Margin Contrastive Learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022.",
            "summary_of_the_review": "I am not convinced that the proposed margin-based contrastive losses are novel, and found multiple papers that I found to be very similar [1,2,3].",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper340/Reviewer_DG2P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper340/Reviewer_DG2P"
        ]
    },
    {
        "id": "EHfqxhPvxAY",
        "original": null,
        "number": 3,
        "cdate": 1667024856483,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667024856483,
        "tmdate": 1670790008472,
        "tddate": null,
        "forum": "MxvHVNukama",
        "replyto": "MxvHVNukama",
        "invitation": "ICLR.cc/2023/Conference/Paper340/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper analyzes previously proposed contrastive learning methods for image representation learning in the context of learning sentence representations. They consider the standard InfoNCE loss and two \"decoupled\" contrastive losses \"A&U\" (Wang and Isola 2020) and \"DCL\" (Yeh et al 2021) whose losses contain separate terms for alignment (decreasing the distance between an anchor and positive example) and uniformity (increasing the distance between the anchor and negative examples). They first show that the decoupled versions underperform InfoNCE and then present justification using gradients of the loss function with respect to the anchor representation. Their primary argument suggests that decoupled losses keep decreasing the alignment losses even when the negative examples are all far away whereas InfoNCE stops after a point. To counteract these issues, they propose two new losses akin to hinge losses and triplet losses which improve the performance to match the performance or outperform InfoNCE. \n\n-------------------\nScore updated after rebuttal.",
            "strength_and_weaknesses": "Strengths\n1. The paper shows interesting analysis and experiments showing the alternatives to InfoNCE proposed in the literature may not be as robust as previously presented, at least not outside of image representation learning. \n2. The proposed new losses dcl+ and mpt are simple changes made to previous losses and still show improvements over baselines.\n3. The experimental setup for different losses is thorough with extensive grid search done on different hyperparameters.\n\nWeaknesses:\n1. The gradient norm discussion in section 3.2 is not very convincing. In eq (6), the gradient wrt h_i is shown as a sum of a \"positive\" term \\nabla^{pos} and a \"negative\" term \\nabla^{neg} both of which have terms related to the anchor representation h_i. All the plots and justifications are given with respect the norms of these individual terms. It's not clear why it even makes sense to analyse the two terms separately given that the entire gradient term contains directions both of which update anchor-positive and anchor-negative relationships not just the infoNCE loss which has it in the \"positive\" term (in addition to the negative term\"). I would prefer to see plots similar to figure (2) for the entire loss, not just individual components. \n\n2. It is not clear entirely clear to me what the contribution of this work is. Is it a new loss function? is it showing that prior decoupled losses are not good for sentence representation learning? or something else? Additionally, the new losses presented in the paper still do not seem to outperform the infoNCE baseline for a larger (and much more widely used) model RoBERTa, so why should they be used? \n\n3. Not too much of a concern but the writing is confusing in certain places (especially 3.2) and for example the paragraph right after eq (5) does not seem to serve a purpose. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarify: See strengths and weaknesses\n\nQuality: See weaknesses\n\nReproducibility: All hyperparameter details are provided and the loss functions are easy to implement. It appears that the results can be reproduced with minimal effort. ",
            "summary_of_the_review": "While the paper shows the inadequacy of previously proposed alternatives to InfoNCE and proposes simple changes to address them however the optimization dynamics study is not entirely convincing of the justification of the introduced new losses. Further the new losses don't seem to improve over the baseline InfoNCE for larger more common underlying models such as RoBERTa. Hence I would not recommend acceptance in current form.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper340/Reviewer_gozg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper340/Reviewer_gozg"
        ]
    },
    {
        "id": "IWs6Nmetew",
        "original": null,
        "number": 4,
        "cdate": 1667285641369,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667285641369,
        "tmdate": 1667286067694,
        "tddate": null,
        "forum": "MxvHVNukama",
        "replyto": "MxvHVNukama",
        "invitation": "ICLR.cc/2023/Conference/Paper340/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to investigate the secrets of why contrastive learning for sentence representation learning (SRL) works from the perspective of alignment and uniformity (Wang & Isola, 2020).\n\nWhile alignment & uniformity are usually utilized in the literature as a tool for demonstrating the effectiveness of some SRL approaches, this work attempts to directly optimize sentence embedding models based on the metrics, showing that this way of training results in inferior performance compared to that of typical contrastive learning.\n\nIn addition, the authors claim that one of the reasons why the performance gap exists is that contrastive learning exhibits the \"gradient dissipation\" property (especially when the number of negative examples is relatively small), which is not shown when one trains SRL models directly using alignment & uniformity.\n\nTo back up their claim, the authors propose several revised learning objectives that can simulate the \"gradient dissipation\" property even in the case we do not use the original form of contrastive learning and shows that such loss functions can improve the performance of SRL models.\n\n\n",
            "strength_and_weaknesses": "Strengths\n- This work attempts to directly train SRL models based on alignment & uniformity which are usually used as diagnostic metrics to evaluate the effectiveness of SRL models, and from the trial, the authors reveal some intuitive findings on why contrastive learning works in SRL.\n- The paper presents a series of experiments with the newly proposed learning objectives that persuasively back up the claim that the \"gradient dissipation\" property is a key to the success of contrastive learning for SRL.\n\nWeaknesses\n- Conditioned on Figure 2 (a), it seems that the \"gradient dissipation\" property appears especially in the case where the number of negative examples for contrastive learning is relatively small and that the property vanishes as the number of negative examples increases. Therefore, if the property is truly a key to success for contrastive learning, we would arrive at a weird conclusion that it is better to reduce the number of negative examples, which contradicts the wisdom in the literature that it is almost always better to adopt more negative examples.\n- Although the storyline presented in the work was quite persuasive, it is still unclear whether we can make an assertive conclusion only relying on the information obtained from the gradient norm of models.\n- From Table 1, while the proposed losses ($L_{mpt}, L_{met}$, and $L_{mat}$) are better than the typical contrastive learning ($L_{cl}$) when evaluated on BERT, they do not show any superiority when tested on RoBERTa, which weakens the authors' powers of persuasion.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written and provides several novel perspectives that can help us to better understand the inner workings of contrastive learning for SRL.",
            "summary_of_the_review": "To summarize, although the paper presents an attractive story that reveals a part of the secrets of why contrastive learning is effective in SRL, it is still a little bit unclear whether the claims made by the authors are absolutely technically correct, especially considering some concerns I explained in the above Weaknesses part.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper340/Reviewer_qhtV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper340/Reviewer_qhtV"
        ]
    }
]