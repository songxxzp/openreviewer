[
    {
        "id": "ugRGVaj0taF",
        "original": null,
        "number": 1,
        "cdate": 1666529680511,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666529680511,
        "tmdate": 1671070060567,
        "tddate": null,
        "forum": "kN4IkQvvrBD",
        "replyto": "kN4IkQvvrBD",
        "invitation": "ICLR.cc/2023/Conference/Paper1708/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the single domain generalization problem for 3D point cloud classification, which aims to generalize the model trained on a single source domain to an unknown target domain. The method splits the training domain into two subdomains, and models the alignment between the two sub-domains, expecting the model to learn domain-generalized features. The evaluation is conducted on ModelNet-10, shapeNet10, and ScanNet-10 by considering two networks, PointNet and DGCNN.",
            "strength_and_weaknesses": "=== Strength === \n\n1. The studied problem is interesting and important, since domain generalization in 2D image has been studied extensively while in 3D point cloud still under-explored.\n\n2. The method is introduced clearly and is easy to follow.\n\n=== Weaknesses ===\n\n1. The sub-domain splitting strategy. In Tab.1, we can find that the performance of different splitting strategies is not stable, as the performance varies from different datasets. A reasonable explanation should be given. In addition, the features of the sub-domains with/without alignment should be compared. For example, extract a validation set from the training set, then train two networks (baseline, the proposed), then visualize the features and make a comparison. I am wondering whether the subdomain splitting makes sense or not.\n\n2. Following the above comment, in fact, the performance of the splitting strategy is also related to the network structure, which makes me confused about the effectiveness of the strategy.\n\n3. This paper only evaluates two very old networks, PointNet and DGCNN. As many SOTA networks are developed, more evaluations are expected, such as KPConv, and Point Transformer.\n\n4. In Page 5, the paper claims that the motivation behind weighted classification loss is different from previous methods. I am so confused. In fact, in this paper, this loss still addresses the class imbalance problem, and there is no difference from other methods.\n\n5. other concerns: how to select the best model for evaluation? how about the variances of the results over three runs? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: clear, and well-written\n\nQuality: many evaluations are missing\n\nNovelty: the addressed problem is interesting\n\nReproducibility: not sure, no code is available in the submission.",
            "summary_of_the_review": "The addressed problem is interesting and important but the experiments are not adequate.\n\n\n=================== post-rebuttal =====================\nIn the response, the authors have made efforts to conduct additional experiments to address my questions. However, I still have a main conern: different split strategies have different impacts for performance on different datasets and networks.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_AoJ5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_AoJ5"
        ]
    },
    {
        "id": "YD2PKwjKDy",
        "original": null,
        "number": 2,
        "cdate": 1666603492359,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603492359,
        "tmdate": 1666603492359,
        "tddate": null,
        "forum": "kN4IkQvvrBD",
        "replyto": "kN4IkQvvrBD",
        "invitation": "ICLR.cc/2023/Conference/Paper1708/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a Single-dataset Unified Generalization (SUG) framework for the challenging one-to-many domain generalization task in 3D point clouds. A Multi-grained Sub-domain Alignment (MSA) is proposed for spliting the single dataset into multiple sub-domains and then constraining the learned representations to be domain-agnostic and discriminative. A Sample-level Domain-aware Attention (SDA) is further proposed for adapting the uneven domain to an even inter-domain. Extensive experiments on several benchmarks illustrate the effectiveness of SUG.",
            "strength_and_weaknesses": "Strengths:\n1.\tThis work is technically sound and shows promising results. \n2.\tThe design of the proposed SUG framework fits well in the one-to-many DG task. \n3.\tThe extensive experiments on 3 well-established datasets verify the efficiency of the proposed approach.\n\nWeakness:\n1.\tThe differenences, characteristics and comparisons of different datasets has not been fully discussed.\n2.\tLack of introduction to DGCNN and motivation for choosing to use DGCNN as the backbone network.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. It provides a reasonable method and comprehensive experiments with sufficient analysis. ",
            "summary_of_the_review": "Overall this work is well-motivated and fits well in the one-to-many domain generalization task in 3D point clouds. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_Yd9F"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_Yd9F"
        ]
    },
    {
        "id": "k0p8nlQTwfv",
        "original": null,
        "number": 3,
        "cdate": 1666664501591,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664501591,
        "tmdate": 1666737635848,
        "tddate": null,
        "forum": "kN4IkQvvrBD",
        "replyto": "kN4IkQvvrBD",
        "invitation": "ICLR.cc/2023/Conference/Paper1708/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a method for domain generalization for 3D point clouds-based deep learning (i.e., pre-training a 3D model on a source domain to well generalize on a new and unseen domain without accessing any data points from the new domain). The proposed method includes three main components: domain splitting (to split a source domain into sub-domains), multi-grained sub-domain alignment (to align features at different levels from sub-domains), and sample-level domain-aware attention (to weight samples based on their distances to their domain). The proposed method was experimented with two point cloud-based backbones (PointNet, DGCNN) and evaluated on benchmark datasets (ModelNet, ShapeNet, and ScanNet), and also compared with existing ones on these datasets. ",
            "strength_and_weaknesses": "A. Strength\n- The studied problem is important.\n- The proposed method and its components are well-motivated.\n\nB. Weaknesses\n- Presentation needs improvement (many technical details are missing; notation is not used consistently)\n- Experiments are lacking in some aspects.\n- The proposed method does not outperform state-of-the-art (SLT, CVPR22)\n- The performance is quite low compared with supervised learning approach, limiting the practicality of the proposed method.",
            "clarity,_quality,_novelty_and_reproducibility": "A. Clarity: needs improvement (see my detailed comments in the summary section)\n\nB. Quality: acceptable but not strong enough (see my detailed comments in the summary section)\n\nC. Novelty: the problem setting is new, but the proposed solution has limited practicality (see my detailed comments in the summary section)\n\nD. Reproducibility: since many technical details are missing, it is hard to reproduce the work (see my detailed comments in the summary section).",
            "summary_of_the_review": "My detailed comments for the paper are as follows.\n\nA. Presentation:\n- Many technical details are missing. For instance, it is not clear how the mini-batches can be created to include data points from different sub-domains. It is also not clear what layers should be considered to extract low-level and high-level features. What is the kernel function used in Eq (5) in experiments? Do i and j in Eq (5) need to represent samples of the same class? Also, Eq (5) assumes that there are two sub-domains, but what if there are more than 2 domains? What are X and Y in Eq (7) and Eq (8), are they from the same class or different classes? If X and Y come from different classes, then d in Eq (6) cannot show the domain distance. What is lambda in \"Implementation Details\"? What setting (e.g., splitting method) is used for SUG in Table 2 and Table 4? Why the results of SUG in Table 2 do not look like any results of SUG in Table 1?\n- Notation is not used consistently, leading to confusion. For instance, in Eq (4), n is referred to as the number of samples in a class but it is not so in Eq (5). Also, do n_s and n_t represent the number of samples in sub-domains s and t? The same notation for omega in Eq (4) and Eq (6), but, I believe, these omega parameters are different in these two equations. In 3.1, K is referred to as sub-domains, while denoted as M in 4.3. \n\nB. Methodology\n- For geometric splitting, what if Chamfer distance is used to compare two different point clouds?\n- I was wondering what if a contrastive loss is used for the L_MMD_Geo in Eq (5) as contrastive loss is also known for the capability of constraining learnt features. A comparison between the MMD and contrastive loss would be useful to consolidate the proposed solution.\n\nC. Experiments and results\n- How many sub-domains are used in experiments and how is the method affected by the number of sub-domains?\n- I was wondering how the method performs under different batch sizes, as the method may be affected when the batches do not well reflect the data distributions in sub-domains. \n- It is important to experiment the method with different selections of the layers for the low-level and high-level features\n- As mentioned in comments for methodology, it would be great to see a comparison between MMD and contrastive loss.\n- ScanObjectNN in [a] is a real-world dataset including practical challenges such as occlusions, background intervention, etc., that do not exist in ModelNet, and therefore would be ideal to validate the domain generalization ability of the proposed method. Note that, this dataset also shows that many models, successful on ModelNet, fail on it. \n- The proposed method does not outperform state-of-the-art (e.g., SLT)\n- The role of SDA is not very clear (given experimental results). And, it may also be affected by batch setting. This should be verified.\n- Also in terms of performance, SUG is well below supervised learning approach. On the one hand, I do understand that the studied problem is much more challenging than supervised learning approach. On the other hand, the performance of SUG shows that its current status is not at the applicable level. \n\nD. Others\n- It would be clear to explicitly state that d in Eq (6) can be realized using either Eq (7) or Eq (8).\n- It is not clear how the domain characteristic of each sub-domain is identical with the original domain from the following claim \"We conduct the random sampling and split a single source dataset into different sub-domains with the same sample size, where domain characteristic of each sub-domain is identical with that of the original one\". It may be over claimed.\n\nE. Missing reference\n- [a] Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data, ICCV19.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_i2R8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1708/Reviewer_i2R8"
        ]
    }
]