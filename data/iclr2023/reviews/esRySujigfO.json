[
    {
        "id": "i_jQtLP8Cx",
        "original": null,
        "number": 1,
        "cdate": 1666407973493,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666407973493,
        "tmdate": 1670013768408,
        "tddate": null,
        "forum": "esRySujigfO",
        "replyto": "esRySujigfO",
        "invitation": "ICLR.cc/2023/Conference/Paper345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes CLIP-FLOW, which is a method to improve the performance of optical flow models under the semi-supervised learning setting. The proposed method consists of three orthogonal parts: 1) Semi-supervised Contrastive Flow: an additional contrastive loss for training optical flow models; 2) Coordinate Encoding: an additional 2D-coordinate map of each pixel as two additional channels to the original input frames; 3) Semi-supervised iterative training on unlabeled real data by pseudo-labeling. They show on KITTI 2015 dataset the proposed process can improve RAFT and CRAFT models, and achieve a second place on the benchmark.",
            "strength_and_weaknesses": "Strength:\n- The overall writing is clear and easy to understand.\n- The related work section covers quite a complete set of recent works on optical flow, semi-supervised and representation learning.\n- The proposed method is simple and achieves good results in a semi-supervised setting.\n\nWeaknesses:\n- The iterative algorithm is not quite clear:\n  - For input $\\phi_\\text{our}^0$, should it be \"Ours ( $\\phi_\\text{bs}$+ pseudo labeling + contrastive flow loss), ...\"?\n  - Why the 0-th round pseudo-labels are generated by $\\phi_\\text{bs}$ rather than $\\phi_\\text{our}^0$? Since the assumption is that $\\phi_\\text{our}^0$ is better than $\\phi_\\text{bs}$?\n- \"shows significant improvement for synthetic dataset as well\" - it seems I could not find relevant experiments in the paper to back this up.\n- The ablation is not quite complete: there are three orthogonal parts in the proposed method, and CE and CF can be applied to RAFT and CRAFT without the pseudo-label re-training part. Wondering how the performances are for RAFT-CE-CF and CRAFT-CE-CF on KT15 (without PL)? \n  - And for the ablation experiments in table 3 and figure 4, it would be nice to show the performance after conducting the same 3-round iterative training process.\n  - Is the fine-tuning step on $D_R^{\\text{tr}}$ necessary?\n  - How to choose the $S$ for the total training steps on $D_R^{\\text{u}}$?\n- Limitations are not discussed in the paper.\n- Will the authors release code upon acceptance?\n\nMinor:\n- missing bracket on the line right above 3.3: ($\\mathcal{D}_R$ is marginal \n- in section 4.2, \"we finetune the updated RAFT-CF-CE-PL model from part A\": should this be RAFT-CF-CE?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good. This paper is well-written and easy to understand.\nQuality: Fair. See the weakness section - some of the ablations are missing.\nNovelty: Good. As far as I know, the proposed techniques are not seen in previous optical flow research.\nReproducibility: Unknown.",
            "summary_of_the_review": "Overall I think the proposed method makes sense and the performance on KITTI 2015 is good. But I am mostly concerned about the limited ablation of the proposed model.\n\n----\nAfter rebuttal comments:\nThanks the authors for carrying out the rebuttal. But my concerns on limited ablation are not fully addressed:\n1) I think RAFT-CE-CF and CRAFT-CE-CF evaluation is still necessary for validating the effectiveness of CE-CF alone.\n2) The necessity of fine-tuning step on $D_R^{\\text{tr}}$ should be validated.\nand for \"shows significant improvement for the synthetic dataset as well\", I was wondering if the final model, rather than only RAFT-CF-CE, also has significant improvement for the synthetic dataset?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper345/Reviewer_bSsw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper345/Reviewer_bSsw"
        ]
    },
    {
        "id": "UtDz48XlhC",
        "original": null,
        "number": 2,
        "cdate": 1666550295223,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666550295223,
        "tmdate": 1666550295223,
        "tddate": null,
        "forum": "esRySujigfO",
        "replyto": "esRySujigfO",
        "invitation": "ICLR.cc/2023/Conference/Paper345/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Due to the difficulty of labeling GT optical flow data, this paper aims to explore how to better use of synthetic data and transfer the knowledge from the synthetic domain to the real domain. Thus, the two main contributions of this paper are 1) the iterative pseudo labeling and 2) supervised contrastive flow loss. In addition, this paper also discusses the impact of 2D positional encoding in the optical flow task.",
            "strength_and_weaknesses": "Strength:\n\nThis work is a good attempt to explore the (synthetic and real) data usage given the difficulty of the optical flow labeling, and the experiments show good insight on the performance improvements we can obtain by pseudo labeling and contrastive loss. And I think the 2D positional encoding idea is interesting. \n\nWeaknesses:\n\nThe technique novelty of this paper is not very strong. Pseudo labeling and contrastive loss have been widely used recently, and the design of the semi-supervised iterative labeling training strategy (also algorithm 1) seems to over-complicate the approach. See more details in the below section.\n\nThe writing can be improved as I see some obvious typos in the paper. See some examples in the below section.\n",
            "clarity,_quality,_novelty_and_reproducibility": "About the novelty of the paper:\n1. The semi-supervised iterative labeling training strategy (also algorithm 1) seems to over-complicate the approach. I would suggest to compare with a simple baseline, which just trains on all pseudo-lablled data without k-Fold Cross validation (without iterations but with the same amount of epochs). Due to the iterations and model choosing after each iteration, the k-Fold Cross validation setting actually trains on all data, and I would like to see the performance difference from the simple baseline.\n2. The contrastive loss is more like an auxiliary loss, and it has nothing to do with self-supervision. And thus, in my option, it would be better to design the contrastive loss such that the model can be pre-trained on a large number of unlabeled data. For example, we can use video data of consecutive frames and self-supervised losses (like intensity consistency), and see how contrastive loss can be fit into this setting.\n\nClarification:\n1. Any insight on the 2D positional encoding? Wouldn't it confuse the model if we consider optical flow as a feature matching problem?\n2. In section 3.1, RAFT \"F1-all errors of 4.11 (ours) vs 5.10 (raft) on KITTI-2015\" and CRAFT \"F1-all errors of 4.66 (ours) vs 4.79 (craft) on KITTI-2015\". Why CRAFT+this paper is worse thant RAFT+this paper?\n3. In Table 2 and Table 3, why are some results are missing?\n4. In Figure 4 and Figure 5, should the 3rd iteration and RAFT-CF-CE-PL match with each other?\n\nThe manuscript needs a proof-reading, as I see some obvious typos:\n1. In abstract, line2, \",\" is not needed.\n2. In introduction, paragraph 2, line 10, \", however\" can be deleted.",
            "summary_of_the_review": "This work is a good attempt to explore the data usage given the difficulty of the optical flow, but its technique novelty is not very strong.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper345/Reviewer_8YE1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper345/Reviewer_8YE1"
        ]
    },
    {
        "id": "s69_ufsDAfU",
        "original": null,
        "number": 3,
        "cdate": 1666551717435,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666551717435,
        "tmdate": 1670469269195,
        "tddate": null,
        "forum": "esRySujigfO",
        "replyto": "esRySujigfO",
        "invitation": "ICLR.cc/2023/Conference/Paper345/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a semi-supervised optical flow approach based on an iterative pseudo-labeling scheme.\nGiven a pre-trained model (e.g., trained on synthetic datasets), the method computes a pseudo ground truth on an unlabeled target dataset and trains the model on it. The method then fine-tunes the model using a small amount of available ground truth data. \nAfter that, the model generates the pseudo ground truth on the unlabeled target dataset again and loops the process.\nThe paper also proposes a contrastive loss that further improves the accuracy. \nThe proposed ideas consistently improve the accuracy of baseline models.",
            "strength_and_weaknesses": "__Strength__\n\n- Interesting idea: iterative training + pseudo ground truth generation\n\n  The proposed semi-supervised learning scheme is interesting and is successfully validated through experiments. It was interesting to see that the accuracy on the validation set keeps improving along with the iteration steps, like a positive feedback loop.\n\n- Contrastive learning loss\n\n  The paper demonstrates the effectiveness of the contrastive learning loss for the optical flow task; it helps to learn more discriminative features for the matching task. Its contribution would affect and help other following-up works. \n\n---\n\n__Weakness__\n\n- Limited generalization: Analysis on only one dataset with one model.\n  \n  The paper provides an ablation study only on the KITTI dataset. I wonder if the method can also show the same consistent accuracy improvement on the other dataset, such as Sintel. It would be great if the paper can demonstrate the same ablation study (e.g., Table 2 and 3) on the Sintel dataset. In my humble opinion, KITTI is a quite restricted setup with street scenes, perspective motion, and objects with rigid motion. Thus overfitting on the KITTI domain certainly improves the accuracy. On the other hand, Sintel shows much more diverse scenes with various visual effects. \n\n   Furthermore, the paper shows the analysis with RAFT only. Can this scheme generalize to other models, such as CRAFT? Considering the accuracy improvement on CRAFT, it seems a bit limited. I wonder if the paper can also provide the same ablation study for CRAFT. \n\n- Accuracy after the training with pseudo ground truth (i.e., before finetuning)\n\n  I am wondering how the accuracy is, just right after the training with pseudo ground truth for each iteration step. (I guess that Table 2 shows the accuracy after the finetuning step.) I wonder if the accuracy after the pseudo ground truth training improves along with the number of iteration steps. it would be great to include the numbers in Table 2 as a separate column. \n\n- Overlap between the unlabeled data and the validation set\n\n  The KITTI Optical Flow 2015 dataset (which has ground truth labels) is actually included in the KITTI raw dataset. I am wondering if those images are excluded when during the training with pseudo ground truth.\n\n- Contrastive loss on occluded region\n\n   I wonder if the contrastive loss is also applied on an occluded region (or what are the \"valid pixels\" in the text on the page 6?). The contrastive loss shows its benefits but might hurt the accuracy when the loss is applied on occluded pixels because their corresponding pixels don't exist, so the loss will be applied to mismatching pixels. \n\n- Final loss\n  \n  What is the final loss applied to the model? Is it a weighted sum of $L_q$ and $L_{CT}$? (eq.1 and eq. 3?)\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: needs improvement.\n\n  I think the paper needs improvement in clarity. For example, there are missing explanations on 'valid pixels', the final loss on page 6. Furthermore, it would be good to include the ablation study on the Sintel dataset too. \n\n- Quality / Novelty: A bit limited\n \n  If the paper can show that the idea generalizes to another dataset, e.g, Sintel, the paper would have more novelty. The paper included the accuracy on the Sintel test benchmark, but it's not so clear which factor contributes to the accuracy improvement on the Sintel dataset. \n\n- Reproducibility: reproducible\n\n  The paper provides enough details for reproducing the results. But providing source codes will be always helpful. \n\n- By the way, **the paper title on this openreview page doesn't match** with the title in the pdf. ",
            "summary_of_the_review": "The proposed idea is interesting, and the experiments validate its effectiveness. However, the experiment is limited to only one dataset with one model. It would be really great to see more ablation studies using other models (e.g., CRAFT) on other datasets (e.g, Sintel) in order to see that the method can be generalized to other methods/datasets.\n\nFurthermore, it would be great if some concerns about technical designs and experiment setups, as stated in the weakness section.\n\n\n----\n\n__After the authors' response__\n\nI appreciate the authors' response! The responses resolved most of my main concerns. However, due to the following reasons, I would like to keep my original rating, marginally below the threshold.\n- Is the contrastive loss really helpful? Numbers in the tables show that it doesn't give consistent improvement.\n  - In the last two rows in Table 3 (main paper), adding the contrastive loss (CF) marginally degrades the test accuracy on KITTI 2015 test.\n  - In the ablation study on Sintel (Table 4 in the authors' response), the accuracy dropped quite a bit on EPE-Final (test).\n- Novelty concern: As other reviewers mentioned, I am not so sure the novelty is significant enough. It was a bit difficult to find exciting insights. That said, I don't strongly object to accepting the paper.\n- If the target scenario is a real-world domain, an experiment with other real-world datasets would be also interesting (I am sorry that I didn't think about suggesting it before). It could be HD1k, Slow Flow (their ground truth might not be super accurate), Middlebury (not so many training images though), DAVIS (probably reporting keypoint tracking accuracy?), or any suitable dataset.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper345/Reviewer_9251"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper345/Reviewer_9251"
        ]
    }
]