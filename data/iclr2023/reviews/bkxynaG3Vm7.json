[
    {
        "id": "G3PMN3SQ7F",
        "original": null,
        "number": 1,
        "cdate": 1666628879405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628879405,
        "tmdate": 1666628879405,
        "tddate": null,
        "forum": "bkxynaG3Vm7",
        "replyto": "bkxynaG3Vm7",
        "invitation": "ICLR.cc/2023/Conference/Paper2642/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new method for continual learning from non-stationary data under changing schedules (presentation/observation order of data over time). The general idea is to make the continual learning algorithm robust to different changes of schedules, that is, under exchangeability. For that purpose, the method includes a predictor based on composition. While the first one (or feature extractor) is invariant to permutations (schedules) and trained in an online manner, the second uses Experience Replay (Chaudry 2019).",
            "strength_and_weaknesses": "**Strengths:** The problem considered is relevant for the community, as learning from streaming data might be affected by the permutations of the data, that in the paper are denoted as schedules. This problem is well introduced, and the proposed predictor based on combination is meaninful. I particulary liked the idea of the feature extractor that is invariant to permutations for later training the classifier on a different way. Even simpler, the results were understandable and clear to me, with several related baselines that produce a broad picture of the performance.\n\n**Weaknesses:** From my perspective, there are two main points of weakness that make the paper borderline to me. The first one is around the presentation of the schedule and the treatment of such concepts. In the end, when having some i.i.d data, there are already significant contributions and studies of exchangeability and permutation invariant models. For instance, in Bayesian inference, the log-marginal likelihood is invariant to the permutations of the data, and there are multiple ways of building this loss as a combination of log-predictive conditionals where the order and size of batches might change. In the same direction, there are multiple statistical operators that already consider this problem and is somehow a well-studied problem (independent of the continual learning scenario). Therefore, I see important connections missing in section 3.1 when making references to schedules and permutation invariant feature extractors without any reference to well-known concepts in statistics. For example, Eq. (7) seems just a correction of the expectation equation in Eq. (6).\n\nThe second point is around the novelty. Even if the schedule robust predictor with the new feature extractor would be well connected to statistics and the mentioned perspectives, the use of Experience replay for the classifier does not seem particularly new w.r.t. (Chaudry 2019). In that sense, I would like to know extra details on which are the exact differences between SCROLL and the previous methods based on Experience replay. Otherwise, the technical contribution is perhaps a bit reduced in my opinion.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and I did not find technical errors or other details that might be a problem for comprehension or reproducibility.",
            "summary_of_the_review": "An interesting paper with two important flaws that make it somehow weak for acceptance.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_wm7u"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_wm7u"
        ]
    },
    {
        "id": "j6s8Qht_WGN",
        "original": null,
        "number": 2,
        "cdate": 1666639967124,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666639967124,
        "tmdate": 1666639967124,
        "tddate": null,
        "forum": "bkxynaG3Vm7",
        "replyto": "bkxynaG3Vm7",
        "invitation": "ICLR.cc/2023/Conference/Paper2642/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper concerns itself with continual learning and observes that current methods are making assumptions on the schedule that can be unrealistic. In order to ameliorate this, the notion of \\emph{schedule-robustness} is introduced. Intuitively schedule-robustness for CL means that the performance is \"independent\" of the schedule. Empirical evaluations are also provided.",
            "strength_and_weaknesses": "The contributions of the paper are threefold:\n\n1. The notion of schedule-robustness is introduced (see Equation 5). Although I do intuitively understand the definition some things are unclear. First, what is the exact meaning of the $\\approx$-sign? Second, should Equation (5) hold on every dataset D, or only on some datasets? \n\n2. It is observed that some specific pre-existing classifiers are already schedule-robust. This gives a specific algorithm called SCROLL\n\n3. Scroll is evaluated experimentally. Not surprisingly, SCROLL outperforms other approaches when they are applied to different schedules than \"expected\". However it also outperforms them on the schedules for which they were designed, which I don't fully understand. Do you have some intuition on why that is? ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper was easy to read. Regarding quality, in my opinion schedule-robustness is not formally well-defined (see comment above)  and should become more rigorous mathematically. With respect to novelty I have the impression that the current paper is a small incremental contribution on top of recognising that some pre-existing approaches satisfy some desired property. Finally, I don't see any reason why the empirical results should not be reproducible.",
            "summary_of_the_review": "Given the comments above, I believe that the paper needs improvements in mathematical rigorousness, and some discussion on why SCROLL outperforms other algorithms even on the schedules that they are designed for, as (at least for me) this does not check out and I am looking forward for the author's response in the rebuttal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_5vq1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_5vq1"
        ]
    },
    {
        "id": "3vwvjC1J3c",
        "original": null,
        "number": 3,
        "cdate": 1666660881244,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666660881244,
        "tmdate": 1666660881244,
        "tddate": null,
        "forum": "bkxynaG3Vm7",
        "replyto": "bkxynaG3Vm7",
        "invitation": "ICLR.cc/2023/Conference/Paper2642/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work builds on the prior work of curriculum learning to make the curriculum learning process neutral to the training schedule. They first form initial pre-representation-training of the network with the help of NCC/ridge regression. The network is divided into 2 components: \u03d5 (classifier) and \u03c8 (backbone). The \u03c8 from the pre-training is used for the further training of the network (\u03d5 is discarded). \u03c8 stays fixed after this (This combined with NCC or the ridge regression are the components that help make the entire training process neutral to the training schedule).  \n\nThis is followed by the part where they perform online curriculum learning. They employ memory buffers and episode replay techniques for this purpose. For a given input batch from a data stream, they update the memory buffer and the NCC/Ridge-regression clusters accordingly. Here they also update the \u03d5/classifier parameters. Additionally, if the memory buffer is small, they also have some residual connections from \u03c8 to \u03d5 which also get updated. ",
            "strength_and_weaknesses": "Strengths: \n- Thorough and clearly explained experiments where they improve upon the SOTA. \n- Marginally novel technical contribution. \n- Increasing the memory buffer size increases the curriculum learning accuracy. However, Residual Adapters helped get better performance at lower buffer sizes than the full model training. And the ridge regression initialization did the best job. Another way to think about this work is to aim toward making the memory buffer robust to the schedule.\n\nWeaknesses: \n- Only used on CIFAR10,100 with the help of resnet 18. It would help to see the results on other datasets and networks as well. We need to make sure that the results are data/model agnostic. \n- The transition from F_0 -> F_t -> F_T-> f* is very confusing. \n- They need to do a better job at stating what is being trained and what isn\u2019t and what losses are being used at each stage. Maybe having a better diagram or a few more diagrams or just a table explaining the different stages and loss combinations of training will help. \n- It wasn\u2019t very clear if the memory buffer is big, does the whole \u03c8 get trained or not?? \n- Additionally, they need more experiments like Fig.2 (The paper is about preventing catastrophic forgetting, and I only see one experiment where they are analyzing the model\u2019s performance across time). \n- It also isn\u2019t clear whether Fig2. is using NCC or Ridge regression. \n- They need to clearly state as bullet points or a list all the factors which are contributing towards making their method schedule robust. It felt like these factors were all over the place.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: They could make a fair amount of the paper a lot more concise and to the point. It would be really helpful to clearly point out what is their contribution and what isn\u2019t (ex. reveal beforehand things like the Buffering strategy (3.3) are based on someone else\u2019s work, it just felt like that fact was revealed a bit too late; there are a lot of details in section 3 which could be moved to the sections of the related work.). If they talk about their work more directly from the perspective of making the memory buffer robust to schedules, it might make things more intuitive to understand (there are a lot of other ways one could make CL robust to schedule, and from the paper\u2019s headline I was hoping to see something a lot different).\n\nQuality/Novelty: Their approach seems very procedural. Not much theoretical technical novelty. Otherwise, a good amount of experiments and comparisons against other approaches. \n\nReproducibility: Seems fairly easy to reproduce. However, we don't have the exact details of the splits, so getting the same exact numbers at the output won\u2019t be possible. No code or data was provided.\n",
            "summary_of_the_review": "A good attempt at solving a not-so-well-studied problem of curriculum learning. As stated before, marginal technical novelty. I personally couldn\u2019t find a comparable schedule-invariant curriculum learning approach. However, they could have done a better job at making the paper\u2019s theory simpler, easier, and most importantly, intuitive to read. Their work improves over SOTA or was very comparable and delivered what they promised. Therefore, at the moment I am leaning toward a marginal rejection. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_dgx2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_dgx2"
        ]
    },
    {
        "id": "MdbkS4OLDvI",
        "original": null,
        "number": 4,
        "cdate": 1666865625929,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666865625929,
        "tmdate": 1666865625929,
        "tddate": null,
        "forum": "bkxynaG3Vm7",
        "replyto": "bkxynaG3Vm7",
        "invitation": "ICLR.cc/2023/Conference/Paper2642/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work raises the issue of schedule robustness in continual learning, and proposes an approach that is schedule-robust by construction. The proposed approach assumes access to a pre-trained feature extractor, then trains a one-layer classifier online, and adapts the feature extractor after the end of the stream using only memory data.",
            "strength_and_weaknesses": "STRENGTHS\n- The paper raises the issue of schedule robustness, which is very interesting in my opinion.\n\n\nWEAKNESSES\n- I think the contribution of the paper is very limited. In my opinion, the most difficult aspect of continual learning is representation learning, but the proposed approach assummes a pre-trained feature extractor and only deals with the schedule robustness of the final layer of the model. Moreover, training a classifier online while keeping a pre-trained feature extractor frozen has already been explored in past work [1].\n- The use of residual adapters does not really fit into the paper since they do not contribute to schedule robustness. Moreover, we can see from the results in Table 4 that they are only beneficial when the memory size is very very small. Also, it is not possible to say whether they would work well for other kinds of architectures, or even other kinds of convolutional architectures (only ResNet variants are used in the paper).\n- Regarding the results in Figure 2, I think that the main factor that allows scroll to outperform the other methods is that the feature extractor is kept frozen.\n- A minor comment: there are some formatting issues with the pdf (for example, see top of page 9, Table 3 appearing after Table 4, etc.). \n\n\nQUESTIONS:\n- It is unclear to me how a continual learning setting can be both task-free and class-incremental at the same time. Could you explain further?\n- For the results in Tables 1 and 2, do the data arrive in small mini-batches online, or does the model have access to all the data from the present task at the same time?\n- I quickly skimmed over the proof that ridge regression is schedule robust and it seems to me that the proof assumes that all data are available at the same time. This assumption does not hold in online continual learning though. Could you please explain further? Could you also give an intuitive explanation of how ridge regression can be schedule robust?\n- Why do you think NCC performs worse than ridge regression?\n- Is SCROLL applicable to streams with tasks that are not class-disjoint?\n\n\nREFERENCES\n[1] Hayes, T. L., & Kanan, C. (2020). Lifelong machine learning with deep streaming linear discriminant analysis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops (pp. 220-221).",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of the paper is relatively clear. I am not still convinced of its novelty, however. Also, I think there might be some implementation details missing from the text.",
            "summary_of_the_review": "Despite the fact that the paper raises an important issue in continual learning (i.e., schedule robustness), I am not convinced that its contribution is significant enough for a top conference like ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_kayx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2642/Reviewer_kayx"
        ]
    }
]