[
    {
        "id": "gYxC9W9hIL",
        "original": null,
        "number": 1,
        "cdate": 1666113092514,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666113092514,
        "tmdate": 1666113092514,
        "tddate": null,
        "forum": "xtbog7cfsr",
        "replyto": "xtbog7cfsr",
        "invitation": "ICLR.cc/2023/Conference/Paper4023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper gives a necessary condition on a function $f$ for the existence of a local minimum (of a shallow ReLU network which represents $f$) that is stable with a fixed learning rate $\\eta$. The stability condition on $f$ requires a stability norm of $f$ to be bounded. This norm can be interpreted as a form of weighted L1 norm of the Laplacian of $f$.\n\nThe authors then give a depth separation result: an example function $f$ which has infinite stability norm (and hance cannot be approximated with a fixed learning rate in shallow ReLU networks), but such that there is a deeper network representing $f$ in stable manner. \n\nFinally the authors show (under some conditions) that any function $f$ in a weighted Sobolev space can be approximated by networks of increasing width $k$ in a stable manner. ",
            "strength_and_weaknesses": "I think that the question of minima stability is very interesting and crucial to understand what type of functions are learned by DNNs. The analysis proposed here seems quite complete for shallow ReLU networks, though it requires a number of technical assumptions and it gives only a necessary condition for stability. \n\nThe depth separability example function is both surprisingly simple and interesting. Tt suggests that stability conditions in deeper networks might be very different from those of shallow networks.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is clear and precise.\n\nWhile the results of this paper are new, the proof techniques seem to mostly be a combination of (Mulayoff et al., 2021) and (Ongie et al., 2021). The results in this paper are weaker: in (Ongie et al., 2021) it is shown that the representation equals some form of Random trasform based norm, while in this paper the bound on the stability norm is only a necessary condition (do the authors believe that it is also sufficient? In that case what is missing?).",
            "summary_of_the_review": "The paper gives a rather complete answer to the question of minima stability in shallow ReLU networks, using a combination of techniques from two previous papers.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_iAv3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_iAv3"
        ]
    },
    {
        "id": "TBxPoTdm5",
        "original": null,
        "number": 2,
        "cdate": 1666179504061,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666179504061,
        "tmdate": 1666179504061,
        "tddate": null,
        "forum": "xtbog7cfsr",
        "replyto": "xtbog7cfsr",
        "invitation": "ICLR.cc/2023/Conference/Paper4023/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper studies the properties of solutions that are stable for SGD, i.e., the ones that satisfy $\\lambda_1(H)\\leq 2$/step size. Specifically, the authors define a stability norm and prove that the stability norm of a stable solution must be no greater than $1/\\eta-1/2$. Then, the authors study the property of stability norm in both the primal space and dual space. In primal space, the stability norm can be explained as a certain weighted Laplacian norm, suggesting that training with a larger step size tends to find smoother models. The explanation in dual space is also discussed but no clear implication is made. Lastly, it is shown that this stability class can approximate functions with certain high-order smoothness. \n\nThe authors also come up with a target function, showing that this function cannot be approximated by stable two-layer neural networks but can be exactly represented by stable three-layer neural networks. \n",
            "strength_and_weaknesses": "### Strong point\n\nThe paper is overall well-written and I can follow most results smoothly. \nThe theoretical result suggests that the stability of SGD implicitly regularizes the smoothness of learned model whereby SGD with large learning rate  generalizes well. Preivous similar works all are limited to linear networks and univariate two-layer neural networks. This work considers the standard two-layer neural networks, which is much more interesting. Given recent progresses in understanding the interplay between dynamical stability and implicit bias of SGD, I think this work is of great importance. \n\n### Weak point\n\n1. (Ma et al., 2021) also established the connection between stability and the input smoothness of implemented neural networks, and their analysis is also applicable to deep nets. I think the authors should provide a careful discussion of the similarity and differences. \n\n2. In Figure 4, what is the meaning of $\\min. \\lambda_{\\max}$?\n\n3. I find the paragraph above Lemma 2 (the one used to motivate Lemma 2) quite confusing and the writing there can be improved. \n\n4. In Figure 5, it is shown that the accuracy of MNIST has only around 55% for small LR but nearly 100% for large LR. This dramatical difference between small LR and large LR is very unexpected since this task is extremely simple, for which a simple logistic regression might have near 90% accuracy.  I do not understand why neural networks have only 55% accuracy even if it is trained with small LR. Is it because a large initialization is used? ",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is clear, the claim is supported sufficiently, and the result is novel. ",
            "summary_of_the_review": "This paper provides a new analysis of how the dynamical stability of SGD can implicitly regularize the \"complexity\" of the learned model. The result is well supported both theoretically and empirically. I generally feel this is a good work. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_EjYW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_EjYW"
        ]
    },
    {
        "id": "wtYDZUrepOm",
        "original": null,
        "number": 3,
        "cdate": 1666460964283,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666460964283,
        "tmdate": 1666460964283,
        "tddate": null,
        "forum": "xtbog7cfsr",
        "replyto": "xtbog7cfsr",
        "invitation": "ICLR.cc/2023/Conference/Paper4023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the implicit bias of minima stability for two-layer neural network with multiple inputs. Based on previous works on the same topic for two-layer neural networks with single input, the authors extended the analysis to include multi-dimensional input, and showed that stability controls a weighted norm of the Laplacian of the function represented by the neural network. Discussions are made on this regularization effect in both the primal and Radon spaces. Then, the approximation capability of neural networks under stability is studied. For two-layer neural networks, it is shown that functions in a weighted Sobolev space and be approximated by networks with increasing width at stable minima. A depth separation result is proven showing that three-layer neural networks (two hidden-layer NNs) can represent a function that cannot be approximated by two-layer neural networks under any stability requirement. ",
            "strength_and_weaknesses": "Strength: \n\n1. The paper extends previous results on the implicit bias of minima stability for single-input two-layer neural networks to multi-input networks, making the results slightly more general.\n2. The approximation capability of neural networks is studied under stability requirement. This is a more realistic setting to study the approximation properties of neural networks. \n\nWeaknesses:\n\n1. In the analysis of stability, only the learning rate is considered, while the batch size is ignored. Hence the stability criterion is tight only for GD. For SGD, it is just a necessary condition. The difference between GD and SGD cannot be seen in the analysis.\n2. The approximation results in Section 4 and 5 are training data dependent, while in practice the training data are sampled randomly. Is it possible to develop similar results that hold with high probability over the sampling of training data? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality: The paper is clear and easy to read.\n\nNovelty: The implicit bias of minima stability for multi-dimensional two-layer neural networks is new, but built on a similar work on one-dimensional two-layer NN. The approximation of neural networks at stable minima is novel.\n\nReproducibility: All the experiments in the paper are on simple settings and used to justify the theory. I do not have concern on the reproducibility of the experimental results. ",
            "summary_of_the_review": "This paper studies the implicit bias of minima stability and the approximation of neural networks at stable minima. The theoretical results are limited (as detailed in the \"Strength and Weaknesses\" part), but still interesting because (1) it accurately describes an implicit regularization effect of GD, and (2) it discusses the approximation of neural network under a more realistic setting. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_7NLR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_7NLR"
        ]
    },
    {
        "id": "OxqiNL0aOd",
        "original": null,
        "number": 4,
        "cdate": 1667776714032,
        "mdate": 1667776714032,
        "ddate": null,
        "tcdate": 1667776714032,
        "tmdate": 1667776714032,
        "tddate": null,
        "forum": "xtbog7cfsr",
        "replyto": "xtbog7cfsr",
        "invitation": "ICLR.cc/2023/Conference/Paper4023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper generalizes the results of Mulayoff et al. 21 on the implicit bias of minima stability to functions that have multivariate output dimension. The paper considers training ReLU 2-layer networks with squared loss. The main contributions are:\n\n* [minima stability implies smoothness] Show that linearly-stable minimizers of the loss correspond to smooth functions (where a certain weighted integral of the laplacian is not too large)\n\n* [2-layer vs. 3-layer separation] Show that there are functions which 2-layer networks cannot represent at stable minima; but on the other hand, 3-layer networks can.\n\n* [universal representation of smooth functions] Show that sufficiently smooth functions (in a Sobolev sense) can be approximated by stable minima.\n",
            "strength_and_weaknesses": "### Strengths\n* The proofs are clearly written and easy to follow. (I appreciated the Section C providing background on the Radon transform.)\n* The analysis is novel, and significantly extends the previously known case of functions f : R \\to R to functions f : R^d \\to R\n* The results are of interest to the neural networks community, since they give new guidance on how the step size affects the implicit bias of training.\n\n### Weaknesses\n* In Proposition 2 statement, a distribution on x should be specified?\n\nTypos: \"globaly\", \"can be quiet high\", \"this method yield\", \"in the space even\"",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of the work is high:\n* the writing is clear\n* the results are novel (although arguably they can be viewed as a natural extension of Mulayoff et al. 21, combined with Radon transform analysis from papers on representation cost: Ongie et al'20, Parhi & Nowak '21, Jin & Montufar '20)\n* experiments are shown that support the relevance of the results in practice",
            "summary_of_the_review": "Understanding implicit bias of neural networks is an important topic, and this paper presents significant original results. I recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_KQ4p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4023/Reviewer_KQ4p"
        ]
    }
]