[
    {
        "id": "84yxl5s0Yh4",
        "original": null,
        "number": 1,
        "cdate": 1666171944896,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666171944896,
        "tmdate": 1668173515478,
        "tddate": null,
        "forum": "m1f8XUs-RQP",
        "replyto": "m1f8XUs-RQP",
        "invitation": "ICLR.cc/2023/Conference/Paper5473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper examines the advantages of using minimal value equivalent feature sets for state representation compared to feature spaces including irrelevant features. Value-equivalence is given if a reduced feature set leads to the same equivalent policies. The paper performs some experiments comparing partial models to complete models on basic environments with limited state and action spaces.\n",
            "strength_and_weaknesses": "Strong points:\n* The paper defines all concepts step by step and the results are clear\n\nWeak points:\n* The paper's contribution is limited as it formalizes a relatively well-known effect.\n* The paper argues much with MDPs where function approximation might not even be necessary.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of the paper is clear, and the experiments seem reproducible. \nThe novelty of the paper is limited as the positive effect of removing irrelevant features is well-known and studied in general machine learning. However, the paper does neither provide a new approach to a solution nor provides a very deep theoretical analysis.\n",
            "summary_of_the_review": "All in all, the contribution of the paper is limited as it basically examines the effects of optimal subsets which are obvious if they can be determined. However, the paper does not really help to answer questions on how to find representation spaces which are value-equivalent. In addition, there is a strong link to causal analysis in MDPs. Causality analysis basically yields a framework for analysing whether features yield a dependency in estimating a distribution.\n\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_oVRM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_oVRM"
        ]
    },
    {
        "id": "UEwsiexLwH",
        "original": null,
        "number": 2,
        "cdate": 1666893654406,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666893654406,
        "tmdate": 1669693833601,
        "tddate": null,
        "forum": "m1f8XUs-RQP",
        "replyto": "m1f8XUs-RQP",
        "invitation": "ICLR.cc/2023/Conference/Paper5473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a framework to define partial models, value-equivalence and a simple method to learn partial models which are minimal and value-equivalent to the underlying MDP. The paper presents empirical results on two grid-world environments.",
            "strength_and_weaknesses": "Strengths:\n\nThe paper is trying to address a very important research problem and the presented approach is simple to implement which I appreciate a lot. The authors have also presented theoretical results on differences in value-equivalence when learning approximate VE models.\n\nImprovements/Clarifications:\n\n1. What is \\delta in Theorem 3? How is it related to \\epsilon here?\n2. In fig 3, why is 3a only over a single run? Also there are no error bars/variances in 3b and 3c.\n3. In section 5.1, the text only talks about models m1-m6. But fig 3 also has m7. What is m7? For fig 3, please show results for all the 7 models in 3a, 3b and 3c? Why only sample 4 out of 7?\n4. The results are only for discrete grid-world environments, which makes it unclear if the proposed approach will generalize to more realistic settings.\n5. While answering question 7 (on page 9), what does the search budget refer to? Planner lookahead steps or planner time cutoff or something else?\n6. The word lifelong is very misleading because it seems to indicate a continual learning flavor, which is not the case. Please consider removing the word from the title and the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to understand. The proposed model seems novel to the best of my knowledge. I have not verified the theorem proofs in the supplementary material, but the empirical results seem to be reproducible.",
            "summary_of_the_review": "I can currently only advocate a weak accept given that the experimental evaluation is not strong enough to warrant a better score. I highly recommend removing the word \"lifelong\" from the paper title, abstract etc. since it is very misleading and feels like the paper is about continual learning.\n\nEdits post-discussion phase:\n---------------------------------------\nI thank the authors for their clarifications. After more discussion with other reviewers and the AC, I have decided to lower my score to 3: reject, not good enough. I initially kept my original score of 6 following the authors' responses, since I do see value in the work when it comes to learning good partial models of the world. However, the authors have not addressed my concern that the work is not useful for lifelong learning. It currently only deals with a very specific kind of distribution shift which does not require acquiring any new features over time, and hence the model would not truly scale to a lifelong setting. I believe that more thorough experimentation with complex distribution shifts is required to prove that the model would indeed work in the lifelong setting before the work can be accepted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_SiWS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_SiWS"
        ]
    },
    {
        "id": "6PSlZHDRQZ",
        "original": null,
        "number": 3,
        "cdate": 1667515722264,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667515722264,
        "tmdate": 1669673925213,
        "tddate": null,
        "forum": "m1f8XUs-RQP",
        "replyto": "m1f8XUs-RQP",
        "invitation": "ICLR.cc/2023/Conference/Paper5473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work introduces minimal value-equivalent partial models, which are models of the environment built on top of a minimal subset of features from the observational space and holds the property of value-equivalence property. This property ensures that the value function associated with an optimal policy obtained as a result of planning with the model is equivalent to the optimal value function in the true environment. The work theoretically analyzes the value and planning losses for such models and provides estimations for computational and sample complexity. Finally, it illustrates such insights in controlled experiments and suggests inductive biases to implement these models in the Deep RL context, with proper ablation studies.",
            "strength_and_weaknesses": "Strengths:\n\n- The work analyzes the problem of learning dynamics models with relevant information for planning, showing an important direction to develop principled methods. Hence, it is well-motivated.\n\n- It formalizes the class of minimal value-equivalent partial models and provides its theoretical grounding. The definitions are clear, and the assumptions made are also clearly stated.\n\n- The theoretical understanding provides important insights in terms of value/planning losses, as well as the considerations for the sample and computational complexity. Furthermore, the experimental methodology and empirical results support the proposed theory, raising and answering the appropriate questions with the right choice of baselines and ablations.\n\n- Lastly, the work suggests inductive biases to scale its finding for the Deep RL scenario, and conduct ablation studies to support their recommendations.\n\nConcerns:\n\n- There is a limitation of the minimal VE partial models worth discussing in the paper. By definition, the relevant features are directly related to the reward and the task. Therefore, these models do not seem to be well-suited for scenarios where generalization across tasks is crucial (e.g., multi-task/meta-learning), which are important in the context of lifelong RL.\n\n- The distribution shifts analyzed in question 6 only relate to the irrelevant aspects of the environment. It would be interesting to discuss or provide empirical results for distribution shifts in a relevant feature, or even in scenarios where the set of relevant features changes over time, especially given the motivation of lifelong RL. The hypothesis is that the suggested inductive biases are not robust enough to deal with such shifts when it needs to learn the representation.\n\n- The current related work section does not place the work very well in the literature. For instance, I believe the work should contrast with recent literature on RL in the presence of exogenous distractors [1, 2] (once it approaches a very similar problem) and planning in learned latent spaces [3].\n\n\nFurther Suggestions/Minor Concerns:\n\n- It would be interesting to provide a small high-level description of how the Straight-Forward Decision-Time Planning algorithm works, besides the pseudocode. This should help in the presentation of this baseline.\n\n- In Question 3: \u201cD minimal\u2026\u201d -> \u201cDo minimal\u2026\u201d\n\n- Last line of Section 5: \u201ccompunding\u201d -> \u201ccompounding\u201d\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity/Quality: The work clearly states the problem, its motivation, and the proposed method. The experimental part also clearly illustrates the theoretical findings. The work is well-written and didactic.\n\nNovelty: To the best of my knowledge, this work provides a novel contribution to the theoretical understanding of a common intuition. A \u201ccommon intuition\u201d refers to the fact that some previous empirical works already provide results in the same direction for planning/exploring in learned compact latent spaces [3] or even learning from imagined trajectories [4].\n\nReproducibility: On the theoretical side, all theorems are accompanied by detailed mathematical proofs and all assumptions needed. In the experimental section, all results provide confidence intervals for statistical significance. There is no mention of code being open-sourced to encourage reproducibility, nor any description of the computational costs/hardware associated with the experimental section.\n",
            "summary_of_the_review": "The proposed work provides didactic definitions and theoretical grounding from planning in \u201cpartial\u201d models. The experimental part also provided a good illustration of the insights presented, although more experiments are required to claim that the proposed inductive bias works for more complex scenarios. There are some concerns about questions and limitations to be discussed in the paper.\n\nReferences \n\n[1] Efroni et. al. Sample-Efficient Reinforcement Learning in the Presence of Exogenous Information. COLT, 2022.\n\n[2] Efroni et. al. Provable RL with Exogenous Distractors via Multistep Inverse Dynamics. ICLR, 2022.\n\n[3] Ekar et. al. Planning to Explore via Self-Supervised World Models. ICML, 2020.\n\n[4] Hafner et. al. Learning Latent Dynamics for Planning from Pixels. ICML, 2019.\n\n\n====================POST-REBUTTAL============================\n\nI appreciate the authors\u2019 efforts to clear my concerns. After considering the rebuttal and the discussion with other reviewers, I decided to change my score to {5: marginally below the acceptance threshold} for the following reason: despite having interesting theoretical contributions and experiments that illustrate them in a controlled environment, it is hard to evaluate if the proposed inductive bias (illustrated in Appendix C.5) hold for more complex scenarios. My second concern point remains open, as the paper does not provide evidence to support that this proposed inductive bias is robust to deal with more complex distribution shifts, a critical aspect of lifelong RL. This is essential to clear in the experiments once prior work often suggests that more signals are needed for effective representation learning in complex scenarios [3, 4]. As pointed out by other reviewers, this is somehow conflicting with prior literature, which makes it necessary to address for acceptance.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_xzJK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_xzJK"
        ]
    },
    {
        "id": "go8SeD16acO",
        "original": null,
        "number": 4,
        "cdate": 1667525533412,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667525533412,
        "tmdate": 1667525533412,
        "tddate": null,
        "forum": "m1f8XUs-RQP",
        "replyto": "m1f8XUs-RQP",
        "invitation": "ICLR.cc/2023/Conference/Paper5473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work focuses on model-based RL, particular in the life-long setting. It sets up the notation of minimal value-equivalent models, which are minimal-sized models which can capture all task relevant features of the environment. The authors show theoretical results that under a particular definition of partial minimal value-equivalent models, the agent does not incur a performance cost of planning using the model, but experiences improvement in computational and sample complexity. This is verified in experiments based on the MiniGrid domain. The second part of the experimental section is concerned with learning such models from interaction with deep learning architectures. The authors experimentally find that:\n\n1. Models which use representations trained through the loss of the value function perform and scale better than models trained through dynamics prediction as well. \n2. Models trained on a variety of environments perform better than models trained on a single environment in terms of robust transfer. \n3.. Models based using representations based on value-function training are more robust to model compounding errors.",
            "strength_and_weaknesses": "Strengths:\n\nThe paper carries out thorough theoretical analysis of the performance gap of MVE models and their performance in terms of planning and complexity costs.\n\nWeaknesses:\n\n1. It is unsurprising that models which only encode task-relevant features would perform better than generic models, which might have multiple distractions. The difficulty is learning these models using salable architectures. The results presented here are incomplete and somewhat inconsistent with current model-based RL literature, i.e. value and reward signals are often insufficient to learn meaningful representations in more complex environments. \n2. Related to the previous point, the experiments are limited to GridWorld domains, which are relatively straightforward not realistic. It is unclear whether the experimental results presented here would hold in larger more realistic domains (probably not, based on previous works, i.e. Dreamer/SLAC).\n\nI am willing to increase my score if more involved experiments with realistic environments/control problems and current baselines are added.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written with clear organization. The math is clear and easy to follow. The Appendix contains enough details to reproduce results. ",
            "summary_of_the_review": "The paper provides good theoretical analysis of model-based learning in life-long/multi-task setting, however these seem of limited applicability in more complex and realistic domains. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_5G3f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5473/Reviewer_5G3f"
        ]
    }
]