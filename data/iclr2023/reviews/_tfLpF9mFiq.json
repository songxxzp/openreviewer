[
    {
        "id": "N2_GPli5HQT",
        "original": null,
        "number": 1,
        "cdate": 1666030890539,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666030890539,
        "tmdate": 1669825337761,
        "tddate": null,
        "forum": "_tfLpF9mFiq",
        "replyto": "_tfLpF9mFiq",
        "invitation": "ICLR.cc/2023/Conference/Paper5474/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors introduce a simple modification to a metric-learning triplet loss by adding penalty term which encourages the distance between the anchor sample and negative  sample to be similar to the distance between the positive sample and the negative sample. \n\n",
            "strength_and_weaknesses": "Strengths\n- The authors provide results for interesting applications of the method on healthcare data. \n\nWeaknesses\n\n- The proposed idea is extremely simple. In essence, the submission uses the fact that a triplet contains two negative pairs: (a,n) and (p,n). In addition to the standard triplet loss, the authors add a loss that encourages the distance between the p and n pair (a negative pair) to be similar to the distance between the a and the n pair (another negative pair). Thus, the paper just adds an extra loss to the typical triplet loss that encourages all negative pairs in the dataset to be roughly equidistant. \n\n- Given the extreme simplicity of this idea, in my opinion the paper is lacking: (A) a thorough analysis how it compares to other recent triplet/contrastive losses, and in what cases equidistant negative pairs are desirable, (B) a thorough benchmarking comparing to more related work on triplet and contrastive losses*, and (C) an evaluation on a much larger set of common (metric learning) benchmark datasets used in related contrastive/triplet methods, rather than just MNIST and FashionMNIST. \n\n      *To just name a few methods for which I think comparisons are lacking: Lifted Structured Loss [1], Multi-Class N-pair loss [2], Noise Contrastive Estimation [3], InfoNCE [4], Circle Loss [5]\n\n      [1] Oh Song, H., Xiang, Y., Jegelka, S., & Savarese, S. (2016). Deep metric learning via lifted structured feature embedding. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4004-4012). \n \n      [2] Sohn, K. (2016). Improved deep metric learning with multi-class n-pair loss objective. Advances in neural information processing systems, 29. \n\n      [3] Gutmann, M., & Hyv\u00e4rinen, A. (2010, March). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 297-304). JMLR Workshop and Conference Proceedings. \n\n      [4] Oord, A. V. D., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\n\n      [5] Sun, Yifan, et al. \"Circle loss: A unified perspective of pair similarity optimization.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n     \n\n\n- Finally, the motivation via the definition of uniform in-class embeddings is unclear to me, in part because the notation is not well defined at the moment. I encourage the authors to elaborate more on this point. Notation issue: Rojas-Thomas & Santos (2021)  define the local density (LD) over a point x_i in c_k. The authors in this submission define LD on c_k directly, without specifying if p_j is also in c_k or any data point in the dataset. \n\t\n\t",
            "clarity,_quality,_novelty_and_reproducibility": "- The novelty of the method is very limited. Connections to other contrastive losses that make uses of more negative pairs are not explored by the authors. \n\n- The results on MNIST and FashionMNIST should be easy to reproduce. ",
            "summary_of_the_review": "I vote reject as I do not think that this work is ready for publication, given that the comparison to related triplet/contrastive methods on public benchmark datasets is severely limited. Adding more related methods and experiments should not present a significant hurdle. \n\n\n--------\n## Post Rebuttal Update\nI thank the authors for working to improve their submission. I am keeping my score since metric learning work published at top ML conferences should follow a more thorough benchmarking on diverse datasets and against recent competitive metric learning approaches. In addition, in its current form, the submission is still lacking convincing arguments as to why the proposed approach should work better than alternative metric learning approaches that also make use of additional relationships between positive and/or negative pairs. I encourage the authors to take this feedback into account to mature the submission. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Other reasons (please specify below)"
            ],
            "details_of_ethics_concerns": "(A) Authors use health data and split by gender. What is the effect on other sub-groups that are not split? \n\n(B) Could enforcing equidistant negatives results in fairness concerns related to common fairness metrics? Unfortunately I am unfamiliar with the field. ",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_7q7N"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_7q7N"
        ]
    },
    {
        "id": "24eo_OtPAM",
        "original": null,
        "number": 2,
        "cdate": 1666664114254,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664114254,
        "tmdate": 1666664114254,
        "tddate": null,
        "forum": "_tfLpF9mFiq",
        "replyto": "_tfLpF9mFiq",
        "invitation": "ICLR.cc/2023/Conference/Paper5474/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "A variation of a triplet loss for deep metric learning, dubbed NPLB, is proposed. It is inspired by the condition that distance between positive and negative examples should be bigger than distance between anchor and positive. It is illustrated that optimizing such objective leads to more compact clusters. Empirical results on benchmark datasets (MNIST and fashionMNIST) and Biobank dataset show increased prediction accuracy (weighted F1 score), when using embeddings from NPLB.",
            "strength_and_weaknesses": "Strengths\nMotivation for, and derivation of the new triplet objective is clear.\nEmpirical results for cluster density and separability, as well as embeddings utility in downstream prediction tasks looks compelling\n\nWeaknesses\nAt moments it is not easy to follow the flow of the paper. Last paragraph of the Introduction appears to have redundancy in summarizing the main 3 aspects of the contribution: novel variation of triplet objective, embeddings\u2019 utility for classification tasks, and distance based risk indicators. Claim that this approach does not require additional hyperparameters, as it is based on distances, might be misleading. In equation 3, the added \u201cregularization term\u201d, ie the square of distance, could have a hyperparameter multiplicator to tune the impact on overall loss. Just in this case it is set to 1 (similarly as it is set to 0.1 in MDR case).  \n\nMinor suggestions\nEquation 1 has an extra right bracket.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems to contribute incrementally to the spectrum of triplet loss objectives. The empirical evaluation setting could have been explained a bit more clearly. For example, it is not clear if all the test subjects are covered by classes \u201cNormal\u201d, \u201cLow Risk\u201d and \u201cHigh Risk\u201d in section 5.3? Why is the dataset split based on the gender and presented separately for female (and male in appendix)? Also, why is DeepPatient transformation R^n -> R^n and not R^n -> R^d like others? Given that repository will be shared, the results seem reproducible.",
            "summary_of_the_review": "Given that modeling novelty seem to be adding distance based regularization to known objective, and novel application of using the learned metrics as health risk is not quite clear to me, I am leaning towards the rejection, although open to turn to the positive side if my concerns are addressed. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_wL6B"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_wL6B"
        ]
    },
    {
        "id": "T3JSSqJKx2",
        "original": null,
        "number": 3,
        "cdate": 1666710615758,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666710615758,
        "tmdate": 1666710615758,
        "tddate": null,
        "forum": "_tfLpF9mFiq",
        "replyto": "_tfLpF9mFiq",
        "invitation": "ICLR.cc/2023/Conference/Paper5474/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a novel formulation of the triplet objective function by explicitly regularizing the distance between the positive and negative samples in a triplet. \nThey evaluate their approach on (Fahsion) MNIST and EHR data. \n\n",
            "strength_and_weaknesses": "While the approach is interesting, I have major concerns regarding the empirical analysis. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- How stable is the model? In table 5, it would be more meaningful to also re-train the embeddings. \n- It is unclear whether the very small improvements in a toy-like dataset such as MNIST are meaningful. It would be more insightful to see results on a slightly more complex dataset such as CIFAR-10 or CIFAR-100. \n- How does the proposed approach scale? \n- How does the proposed approach work for EHR data in an unsupervised setting (online generation of triplets via negative sampling)? I don't really see the practical relevance of the supervised setting here and importantly comparisons to unsupervised methods PCA and ICA are not meaningful.  \n- PCA and ICA are very poor baselines as dimensionality reduction methods. It would be more meaningful to see results based on eg MDS, a VAE, kernel PCA/GP-LVM, diffusion maps,...\n- In Fig 3, how was the UMAP for non-transformed data computed? Based on the PCA representation?",
            "summary_of_the_review": "Major flaws in empirical analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_LF9L"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5474/Reviewer_LF9L"
        ]
    }
]