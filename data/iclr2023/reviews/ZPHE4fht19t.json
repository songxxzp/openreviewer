[
    {
        "id": "08AjqE4yYj6",
        "original": null,
        "number": 1,
        "cdate": 1666531874236,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531874236,
        "tmdate": 1668699870676,
        "tddate": null,
        "forum": "ZPHE4fht19t",
        "replyto": "ZPHE4fht19t",
        "invitation": "ICLR.cc/2023/Conference/Paper6017/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a block-slot object-centric representation learning scheme\nto use a set of sub-slot representations, aka., block representations, to explicitly encode different properties that\nare conventionally encoded with only one slot representation.\nThe authors show the proposed disentanglement scheme performs better and enjoys better interpretability.\n\nThis idea also seems related to the Part-and-Sum detection Transformer[1] used to perform visual relationship\ndetection, where the authors also propose to use part queries to explicitly\nencode the different partial information that is originally encoded with one sum query.\nThe authors are highly encouraged to discuss whether the proposed method can be applied to\nbroader vision tasks based on DETR such as object detection and segmentation.\n\n[1] Visual relationship detection using part-and-sum transformers with composite queries, CVPR2021",
            "strength_and_weaknesses": "> Strengths\n\n\u2705 The presented idea is interesting and the illustration is clear.\n\n\u2705 The approach section is well-organized into two subsections including (i) the details of the proposed block-slot attention and (ii) how to\nperform object-centric learning with a block-slot attention scheme.\n\n\n> Weaknesses\n\n\u274e According to Figure 1 and the Approach section, we can see that the proposed approach might bring significant extra computation overhead compared\nto the original baseline approach. The authors should report detailed complexity comparisons such as the number of parameters and GFLOPs.\n\n\u274e The authors only verify the proposed approach on the very toy benchmarks like CLEVR-Easy, CLEVR-Hard, and CLEVR-Tex.\nIt would be great if the authors could extend the approach to some real-world benchmarks following very recent works such as SAVi[1] and SAVi++[2]. Besides,  the authors are encouraged to discuss more details and compare the proposed approach to GENESIS-V2[3] empirically if possible.\n\n[1] SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models\n\n[2] SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos\n\n[3] GENESIS-V2: Inferring Unordered Object Representations without Iterative Refinement\n\n\u274e The emergence of semantically meaningful abstract concepts in blocks shown in Figure 4 is very impressive. The authors are encouraged to conduct detailed\nablation experiments to investigate which component is the key to ensuring the emergence of semantically meaningful abstract concepts and whether this conclusion\nstill holds on some real-world benchmarks such as ImageNet and COCO.",
            "clarity,_quality,_novelty_and_reproducibility": "> Clarity\n\nGood.\n\n> Quality\n\nGood.\n\n> Novelty\n\nNormal. As discussed in the related work section, there already exist some efforts along the path of within-slot disentanglement although the proposed approach seems to generalize well and does not require explicit supervision. Similar ideas also have been investigated in the Part-and-Sum detection Transformer along the path of the DETR community.\n\n> Reproducibility\n\nNo code is available.",
            "summary_of_the_review": "How to perform within-slot disentanglement to real-world images in an unsupervised manner is a grand challenge. This work presents some encouraging results in this direction. However, the experiments are relatively weak and the authors are encouraged to extend the proposed approach to more challenging benchmarks, which might be necessary to attract broader attention from the research community. I would like to increase the ratings if the authors could well address the above concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_HPVD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_HPVD"
        ]
    },
    {
        "id": "bteEDYJKXg",
        "original": null,
        "number": 2,
        "cdate": 1666613350295,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613350295,
        "tmdate": 1668596435721,
        "tddate": null,
        "forum": "ZPHE4fht19t",
        "replyto": "ZPHE4fht19t",
        "invitation": "ICLR.cc/2023/Conference/Paper6017/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper describes a novel structured representation of scenes with several levels of hierarchy. The representation is divided into slots which provide object compositionality, and slots have several blocks of latent dimensions which are aimed to disentangle factors of variations for each object. To obtain this representation, the encoder architecture can be seen as a generalization of the well known Slot Attention component to the Block-Slot setting. The model is trained in a standard autoencoding setting, with a decoder inspired from recent work in compositional generative modeling for scenes (SLATE, STEVE), also generalized to Block-Slots via original additions to the architecture. An experimental evaluation on different variations of the CLEVR dataset clearly demonstrates the advantages of the design choices for representation compositionality, quantified as pixel-level object separation and disentanglement. ",
            "strength_and_weaknesses": "The contribution is well scoped, and obtaining good multi layer disentanglement is a very important challenge. Results in Figure 2 and 3 evidence benefits of the proposed method with a clear gap in reported metrics compared to prior work. I however have some concerns about clarity of the presentation and some experimental choices. I believe that these concerns can be addressed during the rebuttal phase. \n",
            "clarity,_quality,_novelty_and_reproducibility": "\nI mainly have concerns with the high level presentation of the contribution, mostly in the introduction:\n- *\u201cthe question [...] is not a small one but actually at the crux of this challenge.\u201d* I would encourage you to improve the phrasing of this claim\n- *\u201cis often considered to be the deep representation learning approach towards high-level cognition.\u201d* I am not sure I understand the meaning of this sentence\n- *\u201cThe state-of-the-art methods for object-centric representations are currently based on Slot Attention\u201d* I don\u2019t specifically disagree with this claim but I think it would be good to provide more context (on which dataset and for which metrics?) \n- *\u201cIn Slot Attention, each slot finds a local area\u201d* \u2026 *\u201cattended local input\u201d* could you point me to a reference showing that the attention process of Slot Attention is local (which would imply a notion of proximity)?\n- *\u201cintra-slot disentanglement has naturally been achieved in the previous probabilistic approaches\u201d* I agree that Slot Attention is originally trained in a deterministic setting. But if this is really the main concern, why not just add a latent space regularization to the training objective in order to encourage disentanglement? It feels like this is not the main concern here\n- *\u201cmake it as generic as possible by making it a simple deterministic layer like Slot Attention\u201d* again, is this really a concern here? This sentence is followed by *\"We believe that once this is achieved, it should not be too difficult to make a probabilistic extension.\u201d*, which seems to contradict your previous statement that the probabilistic view is overly complex\n- *\"considering that the single-dimension representation of a factor is difficult to use as an input to a Transformer\"* could you please support this claim with references and/or arguments? This is the first time I hear about this issue\n- at the beginning of section 2, I find it confusing to call your slots \"block-slots\". I would advise to simply state that a block-slot representation is composed of slots which are composed of blocks. The term of slot is anterior to Slot Attention (for instance in the Genesis or Iodine paper) and can refer to any kind of high level unit in your latent space, so you don't need to specialise the term\n\nConcerning design choices, the concept memory bottleneck described at the bottom of page 3 looks very similar to an attention layer, except that none of the queries, keys and values are projected. Is this on purpose, and is there a risk of capacity problem here? Is this something common in the literature or is this a design choice that is specific to your contribution?\n\nAbout your structured disentanglement metric in Section 4, there are two points I would like to discuss \n- your claim that the structured disentanglement metric of Dang-Nhu doesn't apply to block level disentanglement inside slot is incorrect. In Section 5.4, Dang-Nhu applies their metric to disentanglement between the mask block and the component block inside each slot of the Genesis architecture. I think it's fine that you developed your own concurrent metric, but I would encourage you to make an accurate description of related work. Dang-Nhu also performs aggregation of feature importance inside the block, but the main difference is that they jointly optimise the slot to object matching and the probes via an EM approach. This is a more general approach that doesn't require any kind of visual information for matching. However it leads to more instability. \n- I am concerned that your experimental study compares disentanglement of representations with different numbers of dimensions. The entropy quantity heavily depends on the number of dimensions via the number of terms in the sum and the log base, and I am not aware of any reference studying the impact of increasing the number of dimensions, therefore I am not sure of how to normalise results for comparison. Given that the qualitative evaluation in Figure 3 is consistent with the quantitative results, I'm fine with keeping your results as is, but I would at least warn the reader about this issue. \n\nFinally, I noticed your experimental finding  *\"We also note that deterministic models like SLATE and Slot Attention have significantly more active dimensions than VAE-based IODINE due to the regularising effect of the VAE prior. This observation also correlates with lower completeness-scores of Slot Attention and SLATE relative to IODINE.\"*, and wanted to point out that this is consistent with the systematic evaluation of Dang-Nhu, showing that the VAE loss increases intra-slot disentanglement on a variety of architectures. \n\nMinor:\n- the letter $K$ is used twice for the size of the concept memory and the number of ground truth factors.\n",
            "summary_of_the_review": "This is a novel and original contribution building on the well known Slot Attention component. The technical description is clear, but I have raised a number of concerns about the high-level presentation and phrasing of claims. I am looking forward to discussion with the authors in order to make a stronger acceptance recommendation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_NtVS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_NtVS"
        ]
    },
    {
        "id": "XOoFufbote",
        "original": null,
        "number": 3,
        "cdate": 1666648098490,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666648098490,
        "tmdate": 1668710251833,
        "tddate": null,
        "forum": "ZPHE4fht19t",
        "replyto": "ZPHE4fht19t",
        "invitation": "ICLR.cc/2023/Conference/Paper6017/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents a modification of Slot Attention to make it learn sub-components which are independent of each other (blocks), built out of prototypes which are attended to be independent RNNs. The model is trained through reconstruction (with a transformer+dVAE decoder like recent works) and performs very well on several extensions of the CLEVR dataset, including one with textures (current techniques struggle with non-trivial textured datasets). The results are strong and the presentation is very clear.",
            "strength_and_weaknesses": "\nOverall, I really liked this paper in this current form so I have very little extra to request:\n\n\n1. The Abstract and Introduction are very strong, easy to follow yet entirely clear, it was really well done. Figure 1 conveys nearly the entirety of the model in one single diagram which is fantastic.\n   1. The only nitpick I would have is to indicate that there are M blocks in total, this is the only missing symbol currently. \n2. The Concept Memory bottleneck is potentially both the biggest novelty or drawback of the technique in its current form.\n   1. It was surprising to me that you would directly attend into it by multiplying s_nm with Cm. Somehow I would have expected something more akin to a query/key setup with additional Linear layers. Did you try something like that?\n   2. The choice of making the prototypes the direct outputs is rather strong. \n      1. I feel like this may be too constraining and brittle, for example in complex situations? \n      2. I had to find how many prototypes K you used in the Appendix. You seem to use K=64 throughout, which is rather small. This seems rather much more constraining than what is done VQ-VAE/GAN or GroupVIT-style models.\n      3. How \u201cdelta-ish\u201d were the softmax attention in general? If the softmax becomes extremely peaky, this means you considerably restrict the \u201cspace\u201d of representation (i.e. in the limit, you would only represent 64 possible values, given your choice of K)\n      4. What happens if the dictionary size is much larger? What about if you share it between groups?\n      5. Did you try outputting the \u201cdistance\u201d to the prototypes instead, to have more flexibility and expressive power?\n   3. Didn\u2019t you have to use more flexible attention mechanisms, ala Gumbel, to train these prototypes well enough? I would expect the gradients to die off rather quickly in unused prototypes.\n3. The Block Binding is a very interesting choice, and it seems rather useful to me so I will probably give it a try in my own work.\n   1. However, I would have expected you to try the simplest choice of \u201cjust\u201d concatenating all the groups together per slot first? I.e. provide $S=\\lbrace s_n \\rbrace$, where $s_n = Concat_m(s_{n, m})$.\n   2. You never compared against that, even in Section 6.2? I would never have expected \u201cthe bag of blocks\u201d to be an appropriate representation, provided as a set to the decoder. You do have the block-slots directly, so why don\u2019t you just keep that structure? How does Figure 6a change with that choice?\n4. The results are strong, and the improvement to the metric is well executed. Figure 2 is clear and very impactful.\n5. Figure 4 and the methodology for obtaining it is not clear enough.\n   1. How did you \u201cmask out\u201d part of the images? Did you use the attention weights?\n   2. The corresponding section on 6.1 at the end of Page 7 needs to be expanded to provide more details, as this is a very interesting assessment which is the only way to assess what the groups and prototypes really learn.\n   3. How many prototypes end up being learnt/used? Can we get some kind of \u201ccoverage\u201d metric for their relative importance / specialization?\n6. Figure 5 is strong and very interesting to see.\n   1. It might be worth flagging that the model gets the reflection right (e.g. last row, second to last column on CLEVR-Hard). Do you know if this is thanks to your model, or \u201csimply\u201d due to the Transformer+dVAE decoder being really good at handling these?\n   2. How exactly did you select the groups? You say it was easy to identify and select them, but you do not precisely say how.\n7. Even though you target more complicated versions of CLEVR, this is still \u201cjust\u201d CLEVR, which is rather easy to get results on.\n   1. Did you try targeting Kubric [1] (MOVi-C onwards, discarding the temporal video aspect) or other more complex yet still manageable datasets?\n\n\n[1] https://arxiv.org/abs/2203.03570 ",
            "clarity,_quality,_novelty_and_reproducibility": "* See above, very high clarity.\n* See above, great quality.\n* Great novelty: the group-RNNs + Concept Memory choice + disentangling metric modification + Block Binding were all novel to me.",
            "summary_of_the_review": "Overall, I found this paper extremely interesting, presenting several key novel ideas which appear simple in hindsight which is always a great sign. Results are strong, the evaluation is good with good ablations and the paper demonstrates what I wanted to see and understand.\n\nAs a practitioner of this field, this is absolutely something I will try to leverage and build upon, hence I would recommend for acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_v6kB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_v6kB"
        ]
    },
    {
        "id": "vTkeRlh2GFE",
        "original": null,
        "number": 4,
        "cdate": 1667049373923,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667049373923,
        "tmdate": 1667049373923,
        "tddate": null,
        "forum": "ZPHE4fht19t",
        "replyto": "ZPHE4fht19t",
        "invitation": "ICLR.cc/2023/Conference/Paper6017/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel object-centric representation called Block-Slot Representation, which, unlike the conventional slot representation, provides concept-level disentanglement within a slot, such as color, texture, and position. In comparison with the previous methods, the approach demonstrated significantly better disentanglement of object properties, including complex textured scenes. Finally, the proposed method improves the results on a number of synthetic datasets (CLEVR).\n",
            "strength_and_weaknesses": "**Strengths:**\n\n(1) Overall, this paper is well written, and the technical details are easy to follow. \n\n(2) The main idea of representing a factor of object variation, such as color, texture, and position, is nice and appealing.\n\n(3) The main contribution of this paper is a new method for binding block factors within a slot.\n\n(4) The experiment results support the proposed approach, including the evaluation of the DCI framework, which is a valuable addition to the paper.\n\n\n**Weaknesses:**\n\n**Experiments.** I am mostly concerned with the fact that this approach is mainly proved to be working on synthetic datasets. Thus, I wonder how it would generalize to a real domain. I think the idea is appealing, but I am honestly not sure it will work on real-life datasets.\n\n\n**Novelty.** First of all, I would like to note that the main idea of this paper maintains the high standards of the conference. However, the authors should also know that I had indeed considered this idea important and implemented it 14 months ago, when the first slot-attention paper was published. The method of disentangling the structure within a slot in order to represent a factor of four object variations, such as color, shape, texture, and position, appears to be working entirely on synthetic datasets (CLEVR-like). Due to the fact that it did not work on real domains, as well as the simple nature of the contribution of the main idea (which is, to me, way too simple in this case, although there is a compelling story behind it), I decided to abandon this research direction. Despite acknowledging the importance of this paper, we should also be aware that its contributions could not be substantial enough, especially if we look at the results on real domains.",
            "clarity,_quality,_novelty_and_reproducibility": "I wrote above my concerns.\n",
            "summary_of_the_review": "I wrote above my concerns. I am open to the authors' feedback and other reviewers' opinions.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_jDiA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6017/Reviewer_jDiA"
        ]
    }
]