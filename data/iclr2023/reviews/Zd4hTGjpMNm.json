[
    {
        "id": "AQEZ8cZXuc",
        "original": null,
        "number": 1,
        "cdate": 1666566975274,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666566975274,
        "tmdate": 1666566975274,
        "tddate": null,
        "forum": "Zd4hTGjpMNm",
        "replyto": "Zd4hTGjpMNm",
        "invitation": "ICLR.cc/2023/Conference/Paper3526/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a deep neural network that jointly learns 1) to\nencode images as a variational autoencoder, and 2) to use the images\nto predict neuronal activities recorded in mouse visual cortex (in\nresponse to the same set of images, presented as visual stimuli). By\nsharing the representations used to perform both tasks, the goal of is\nto improve the neural prediction performance by using the autoencoder\nas a regularizer, and, reciprocally, to improve the autoencoder's\nreconstruction quality by making its internals more similar to\nputative processes of biological vision. ",
            "strength_and_weaknesses": "## Strengths\n1. The idea of using a VAE as a regularizer for a neural activity\n   prediction task is interesting and (to my knowledge) novel, and\n   executed in a clean way. The methods and results of the research\n   are reasonably well described in the paper (with a few minor\n   exception, noted below).\n2. The claim that inclusion of the VAE improves representational\n   similarity is backed up by the data, if it is interpreted in the\n   narrow sense of only being related to the specific architecture at\n   hand. However, this comparison is made in complete isolation from\n   the existing literature on representational similarity (see point 3\n   below).\n\n## Weaknesses\n1. It is not clear what is meant by the \"image reconstruction\n   problem\", and how can the proposed architecture bring progress on\n   that. In the introduction, it is stated that the image\n   reconstruction problem is an important one in computer vision, and\n   a couple of references are given to papers by J Fessler on medical\n   applications. Is there any way in which DAE-NR could contribute to\n   this type of applications?\n2. In the abstract and the introduction, the \"guidance of neural\n   information\" is offered as a general principle that should somehow\n   improve image reconstruction performance. However, in the present\n   work, this is only shown to be true for the neural data from one of\n   the three regions recorded in  Antonlik et al\n   2016 (region 3). Including\n   data from the other recorded regions (regions 1 and 2) did not\n   improve appreciably the performance of the autoencoder (table 2),\n   invalidating the generality of the approach, but no comment or\n   justification is proposed for this fact. What makes neurons in\n   region 3 special? Is there a theoretical or practical reason why\n   inclusion of the data for these neurons, but not the others, should\n   help the autoencoder? Or is it simply that these neurons happen to\n   carry a bit more information than those in regions 1 and 2 about\n   important features of the visual stimulus, and therefore their\n   inclusion helps learning better representations in the autoencoder?\n3. For neural activity prediction, no comparison is made with the\n   state of the art (only comparisons with variants of the proposed\n   architecture are done). This is particularly surprising given that\n   the neural data used in this paper comes from another work where\n   neural prediction was performed. In Figure 5A of Antonlik et al\n   2016, the correlation coefficient between model prediction and\n   neural activity is shown to be about 0.5 for all three regions. In\n   the present work (Table 4), this metric is somewhat lower (a range\n   of about 0.3-0.5, considering 8 different models).\n4. The analysis of \"significant neurons\" in table 3 seem\n   overinterpreted. If I've understood correctly the procedure for\n   this analysis, it is as follows: after training the network,\n   neurons (only those for region 3, in the main text) are divided\n   among those for which the model prediction are better than chance\n   (the \"significant\" ones), and those for which they aren't. Then the\n   network is re-trained, from scratch, using only data from either\n   significant or insignificant neurons. It is observed that the\n   significant neurons contribute to improving the VAE, while the\n   insignificant ones don't. It is claimed that \"These experiments\n   verify our hypothesis, indicating that information from significant\n   neurons can guide CAE-FR to better reconstruct images\". I am not\n   sure what is added by this analysis: the simplest explanation is\n   that the insignificant neurons don't carry any (or carry very\n   little) information about the images, so they are effectively\n   random noise generators for the purpose of image reconstruction,\n   and therefore can't possibly contribute to improving it. In other\n   words, in my opinion this analysis is just showing in a different\n   way that some neurons carry some information about the images, and\n   some don't. In this sense, saying that information from informative\n   neurons can contribute to a better reconstruction is somewhat of a\n   vacuous claim; for instance, one could do even better by including\n   skip connections directly from the image input layer.\n5. Additionally, the numbers in the \"significant\" column in Table 3\n   seem uniformly worse than the numbers in Table 2. In other words,\n   it seems that training with the significant neurons alone is better\n   than training with the insignificant neurons alone, but worse than\n   training with all neurons. This seems relevant and should be\n   discussed. How do the authors square this fact with the statement\n   that \"insignificant neurons jeopardize CAE-FR\"?\n6. Why are the images in Figure 2 so small and featureless? The\n   abstract states that the input images are \"natural images\", and the\n   paper says that the data is taken from Antonlik et al 2016. But the\n   images that paper (see for instance Figure 1 in Antonlik et al)\n   look completely different, and the methods section of that paper\n   states \"The stimulus set was composed of static scenes from David\n   Attenborough\u2019s BBC documentary Life of Mammals, depicting natural\n   scenes such as landscapes, animals or humans. Images were scaled to\n   have 256 equally spaced luminance steps, and were composed of\n   384\u00d7208 pixels, and expanded to fill the screen\". I must be missing\n   something, because the images in Figure 2 look like random blobs to\n   me.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written in a reasonably clear way, and the idea of\nregularizing a predictor of neural encoding with a VAE is\ninteresting. However, the quality of the work is not satisfactory in\nmy view, because - as detailed above - several of the claims made by\nthis work are not supported by the evidence. Regarding\nreproducibility, the methods are described reasonably well, but I\ncould not find a code link.",
            "summary_of_the_review": "In my opinion, this paper fails to back up some of its core claims and\nto justify the (claimed) relevance for the proposed architecture from\na computer vision standpoint. Therefore, my recommendation is not to\naccept this work for publication.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_n7th"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_n7th"
        ]
    },
    {
        "id": "_FIOL299uH",
        "original": null,
        "number": 2,
        "cdate": 1666578548689,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578548689,
        "tmdate": 1666578548689,
        "tddate": null,
        "forum": "Zd4hTGjpMNm",
        "replyto": "Zd4hTGjpMNm",
        "invitation": "ICLR.cc/2023/Conference/Paper3526/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper shows that optimizing a CAE model to fit neural data and reconstruct input images at the same time, actually improves the performance of both tasks.  The finding that integrating neural response into deep autoencoder models can improve its performance is quite interesting and novel. ",
            "strength_and_weaknesses": "Strength: Transfer learning based on latent features of a CAE for neural data fitting is not new.  The finding that introducing a loss to maximize the representational similarity of the latent feature representations in a CAE with the real neural activities can improve the image reconstruction performance of an autoencoder is novel and interesting.\n",
            "clarity,_quality,_novelty_and_reproducibility": "clear, novel and the quality seems good.",
            "summary_of_the_review": "This is a relatively simple paper that shows optimizing a CAE model to fit neural data and reconstruct input images simultaneously can actually improves the performance of both tasks.  The approach of integrating neural fitting with CAE for image reconstruction is novel and that fact that it actually shows improvement in performance is reasonable but still a bit surprising, and hence interesting. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_YdJC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_YdJC"
        ]
    },
    {
        "id": "fyxb02JbH7",
        "original": null,
        "number": 3,
        "cdate": 1666658534327,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666658534327,
        "tmdate": 1666661396586,
        "tddate": null,
        "forum": "Zd4hTGjpMNm",
        "replyto": "Zd4hTGjpMNm",
        "invitation": "ICLR.cc/2023/Conference/Paper3526/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper builds a NN to match (a) image reconstruction and (b) neural similarity of the inner layers of the CNN to neural representations (NR) in a mouse visual cortex. The loss function minimizes image error and NR error.\n \nThe results assert that the NN does much better than a convolutional autoencoder (CAE) on image reconstruction, and also (as expected by construction) on NR.\n\nThe basic notion (if I got it right) is that if you fit the encoding layers of a CAE to neural representations from a mouse visual cortex, the CAE will have better image reconstructions. It's unclear to me is whether this effect (reported in the paper) is due to the extra parameters provided by the attached CNM, or by the sparsity prior on model weights, rather than to the NR matching. If it is due strictly to the NR matching, that would be, I think, a big thing.",
            "strength_and_weaknesses": "(strengths)\n\nIt is an interesting idea to merge a CAE and a Convolutional neural model (CNM).\n\n(weaknesses)\nI am troubled by the basic assumption that the neurons in mouse V1, V2, etc can be mapped to layers in a CNN. \nIt is not clear if the gains in image reconstruction are due to the inner layer - Vi fittings, or to extra parameters or the imposed sparsity.\n\nMiscellaneous:\n\nbottom pg 1: Are the structural and functional relationships between ANNs and BNNs sufficiently deep to build on, or are they superficial?\n\nPage 2 \"however, hot to ... question\": This sets up an expectation. Perhaps remove it, or say that you address this question.\n\nFig 1: I believe that layers in a CNN (CAE) do not map 1-to-1 to visual layers in mice. Rather, previous studies showed that given a DNN with M layers, you can map a subset of those layers to Vi\n\nFig 2: why are the CAE images so fuzzy? Doesn't it give good image reconstruction? This is counter-intuitive, unless it is way too small a network, which would suggest that the improved results from an added CNM + fitting are due to extra parameters.\n\nFig 3: Are you able to add error bars to see if these differences are big? Also, is a higher number of significant neurons better? I believe that in Vi, given a constrained set of images, several neurons might be relatively uninvolved, so higher might be inaccurate. (I don't know).\n\nTypos: there are various repeated words (eg \"however however\") , and also a repeated comma.\n\nPage 4: \"turns to be\" -> \"turns out to be\"\n\nBottom of page 4: add sub-heading after description of CNM to clarify that the topic is now the hybrid DAE-NR.\n\neqn 3: beta = 1- alpha?\n\nAbbreviations could be made clearer, noted at time of first introduction. An example is CNM, which I thought was a typo for most of the paper. Also, what is VQ?\n\nPlease note when figures and tables (eg fig 5) are in the Appendix.\n\n\"Network architectures\": Maybe move the architecture description to the appendix where it can be more complete. The 8C88-9CD77 notation is confusing and leaves out detail.\n\nAlso: what does the \"32 x 256\" dimension for VQ-VAE relate to?\n\npage 5\" by applying a sparse mask\". the explanation of why this is done comes much later. Could you move that explanation so that it follows directly (or precedes)?\n\nTable 2 and 5: How do you restrict the CAE image reconstruction to use only a single layer? This is not described in 3.2.\n\nTable 5: do you have error bars (std devs)? Related: what is the appropriate number of decimal places?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I found the paper a bit difficult to follow (see miscellaneous comments above). \n\nI do not see indication of a public codebase.",
            "summary_of_the_review": "I am perhaps the wrong person to review this work, since I am not confident that the suggested parallels between CNNs and BNNs,  which motivate this work, are more than superficial (eg, the main layers can be made to somewhat correspond). Also, I am not up on this literature. This poor fit is reflected in my Confidence score and other scores.\n\nThe accumulation of non-clarities (see \"miscellaneous\" items above), combined with my skepticism about the extent of the CNN-BNN mapping, make me less favorable to the work. But I emphasize my lack of confidence in this assessment.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_bubd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_bubd"
        ]
    },
    {
        "id": "ZAnrB1986q",
        "original": null,
        "number": 4,
        "cdate": 1666697055951,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697055951,
        "tmdate": 1666697055951,
        "tddate": null,
        "forum": "Zd4hTGjpMNm",
        "replyto": "Zd4hTGjpMNm",
        "invitation": "ICLR.cc/2023/Conference/Paper3526/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, an image autoencoder is trained with two loss functions: 1. Image reconstruction loss and 2. Poisson loss to optimize representation similarity between artificial and biological neurons. \n\nThe authors show that by training in the above way:\n1. Image reconstruction is better than the case without Poisson loss\n2. The model shows high resemblance between artificial/biological neurons as compared to standard end to end models",
            "strength_and_weaknesses": "Strengths:\n1. The idea although simple improves the performance on both the tasks.\n2. Experiments seem sufficient enough for validating the proposed idea\n3. The idea is evaluated using different autoencoders suggesting generalizability of the claims.\n\nWeakness:\n1. Minor: the idea presented here is simple multitask network. I am not sure if this is a \"framework\"\n2. In Table 2: if CAE is trained without any brain data why is there any variation in result of region 1, 2 and 3?\n3. What is the difference between NR and FR.? there are lots of acronyms in the paper making it difficult to follow. I would suggest unifying the acronyms as in Tables only CAE is used but in the text there are multiple mentions of DAE-NR. It was only possible to figure out after multiple reads. \n4. There are lots of publicly available datasets from Brainscore (Schrimpf et al. 2018) and others. Why was this particular dataset chosen? \n5. Generalizability is only shown in V1, using other public datasets maybe it might have made sense to show that approach is generalizable to different brain regions as well.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is readable but can be improved signficantly with a rewrite. I would encourage authors to reduce the number of acronyms used in the paper to help readability\n\nQuality: The quality of experiments is good on the DNN side. The experiment however is done only on one dataset of brain recordings and how it compares to state of the art models in neural activity prediction on Brainscore. \n\nOriginality: The idea to use neural data as an auxillary loss along with an image related task is not new. However, here it is applied to a new problem and shows improvement in both reconstruction and representational similarity with biological neurons. The results therefore are new.\n\n",
            "summary_of_the_review": "The idea although not new is applied in a new way to improve both the performance on image reconstruction task and neural response similarity task. \n\nDue to limited testing on brain dataset even though there are lots of publicly available benchmarks I am inclined towards giving it a borderline reject. \n\nHowever, if authors provide a valid reason to not use those benchmarks or provide new results I will be happy to update my rating.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_vnH9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3526/Reviewer_vnH9"
        ]
    }
]