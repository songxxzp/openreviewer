[
    {
        "id": "PWBU0OW2mG8",
        "original": null,
        "number": 1,
        "cdate": 1666624483038,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666624483038,
        "tmdate": 1666624483038,
        "tddate": null,
        "forum": "Th4_9F0a6l",
        "replyto": "Th4_9F0a6l",
        "invitation": "ICLR.cc/2023/Conference/Paper4036/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a proportional sampling method to estimate the ratios between Shapley values by introducing effective coalitions. Then, it combines this method and the existing Integrated Gradients to propose the Shapley Integrated Gradients that can explain a deep neural network (DNN) prediction by attributing the prediction to its input features.\n",
            "strength_and_weaknesses": "In my view, the biggest weakness of the paper is the clarity which requires a major revision.\n\n1. The contribution of the paper is not clear. In the 3rd paragraph of the introduction, the paper states that its main contribution is to \"propose to find a set of informative baseline values\". However, this paragraph discusses the Shapley value as a measure of the feature contribution without discussing how baseline values will be chosen in this paper (as opposed to existing baselines: e.g., zero baseline values).\n\n2. The Integrated Gradient approach is motivated by 2 axioms including the implementation invariance. Thus, it is not convincing that this work criticizes Integrated Gradients by proposing an approach (Shapley value) that not only does not satisfy the implementation invariance but also requires more computation than the Integrated Gradients.\n\n3. Furthermore, while Section 4.1.2 is about the limits of Integrated Gradients, it only discusses the Shapley value. I do not understand the limits of Integrated gradients after reading this section.\n\n4. The paper criticizes that \"Integrated Gradients takes a shortcut compared with calculation path of Shapley value and it will lead to an unsatisfactory and unstable explanation\". However, it uses the Integrated Gradients in Algorithm 2, instead of computing the marginal contribution of coalitions. Thus, why the \"unsatisfactory and unstable\" of the Integrated Gradients is prevented in this work?\n\n5. After section 4.2, I still do not understand how to estimate the ratio between Shapley values even though it is the main objective of this section. In particular, how does the proposed method \"transform the goal from accurate Shapley value to ratio between Shapley value\"?\n\n6. In Theorem 2, P is not in the range of [0,1] so why is it even a probability?\n\n7. In the first paragraph of Section 4.3, it discourages the computation of the marginal difference of sampled coalitions by Algorithm 1 because it is impossible for a large number of players. However, algorithm 1 requires computing these marginal differences when it classifies S into m_i. Does it mean that algorithm 2 is very computationally intensive since it performs computing these marginal differences when invoking algorithm 1? Moreover, this work should include analyses of the computation complexities of the two algorithms.\n\n8. The paper also mentions the 2 key requirements of baselines in the first paragraph of the introduction, but it never says how the proposed baseline values satisfy (or do not satisfy) these 2 requirements.\n\n9. Why does the factor for d_jk not change even though we have an additional requirement that v(S cup x_i) - v(S) = j? According to (1), the factor only depends on the size |S|.\n\n10. In Theorem 2, the explanation is confusing: is a_j a set of coalitions or just a coalition (\"a_j considered to be effective coalitions in bj\")? What does it mean by min(a_j)?\n\n11. Algorithm 2 is confusing because it says the output is baseline samples for each player (in the 2nd line). However, the last line of the algorithm outputs the average of all values of IG.\n\nThere are other minor issues.\n\n12. In the line below equation (4), where is the point (s1,r2)?\n\n13. Typo in C_{|ej|}^{|aj|} in Theorem 2.\n\n14. \"seep up\" -> \"speed up\"\n\n15. D = (d_1j, ..., d_jk, ...) is confusing due to the notation j.\n\n16. What is \\phi in equation (3)?\n\n17. Figure 1.b, there is not any orange color.\n\n18. In the 2nd line of the paragraph after Figure 1, x=(s1,s2) should be x=(S1,S2).\n",
            "clarity,_quality,_novelty_and_reproducibility": "As explained above, I think that the quality and clarity of the paper require a major revision.\nIt is also the case that the writing of the paper makes it difficult for me to judge the novelty of the approach.\n",
            "summary_of_the_review": "It is challenging to evaluate the soundness of the proposed approach due to the clarity and quality of the paper. Furthermore, the proposed baseline values are not motivated properly. As a result, I believe this paper requires a major revision.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_cr3F"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_cr3F"
        ]
    },
    {
        "id": "C5sBNLLDk9",
        "original": null,
        "number": 2,
        "cdate": 1666787959922,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666787959922,
        "tmdate": 1666787959922,
        "tddate": null,
        "forum": "Th4_9F0a6l",
        "replyto": "Th4_9F0a6l",
        "invitation": "ICLR.cc/2023/Conference/Paper4036/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work focuses on the task of attributing the prediction of DNN to its input features and try to address the baseline issues. The work proposes to find a set of baseline values corresponding to Shapley values.To solve the computation dilemma of Shapley value,  a proportional sampling method (Effective Shapley value, ES) is proposed to well simulate the ratios between the Shapley values\nof features. Besides, the submition proposed Shapley Integrated Gradients (SIG) to combine Integrated Gradients with ES, to achieve a good balance between efficiency and effectiveness. I am not an expert in this filed. However, as a reader, this work is unreadable and requires a lot of prior information. Besides, there are a lot of undefined notations or terms.",
            "strength_and_weaknesses": "This method combines Shapley values with the Integrated Gradients method for better accuracy of locating relevant features while causing a trade-off to the efficiency of the original Integrated Gradients method. The novelty of such a combination is limited. The sampling strategy to reduce computation of SHAPLEY VALUE is also not novel.  Moreover, it's not clear how to set baseline values when calculating v(S) in Algorithm 1. It's also not clear how to directly set Di as baseline values in Algorithm 2. Why the authors use Integrated Gradients is also questionable. Each player's contribution is also calculated in the algorithm1. Why is the Integrated Gradients method necessary to calculate the contribution? The overall writing of the methodology is confusing. \n\nMoreover, there are a lot of notations confusing readers: what is v in Eq (1)? What is the difference between S1 and s1? ",
            "clarity,_quality,_novelty_and_reproducibility": " I am not an expert in this filed. However, as a reader, this work is unreadable and requires a lot of prior information. Besides, there are a lot of undefined notations or terms.",
            "summary_of_the_review": "I cannot recommend accepting this work. Although I am no working in this field, this work is far from a ready work for publish.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_y3yp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_y3yp"
        ]
    },
    {
        "id": "SQndIA2S9k",
        "original": null,
        "number": 3,
        "cdate": 1667410540186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667410540186,
        "tmdate": 1667410540186,
        "tddate": null,
        "forum": "Th4_9F0a6l",
        "replyto": "Th4_9F0a6l",
        "invitation": "ICLR.cc/2023/Conference/Paper4036/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes ideas to combine integrated gradients and shapely values effectively. The problem according to the paper is that shapely values  are too expensive to be computed directly. The paper wants to use the ideas from shapely values to find a proper baseline for integrated gradients. The paper proposes effective shapely value, an approximation of shapely values that can be computed more effectively.\n\nThe paper claims that experimental results show that a combination of shapely values with integrated gradients provides good results.",
            "strength_and_weaknesses": "Weaknesses:\n- Experimental validation\n  -  Validation in Fig 2.  The entire experimental setup is not provided. It is not possible to actually implement this experiment and it is not possible to verify why it would make sense. Additional detail is needed.\n - Figures 3, 4, 5: it is not obvious at all why these visualisations are better than any other interpretability method. Why is this method showing the right result?\n - Positioning the work relative to work looking at the limits and potential issues with interpretability methods. There is not discussion whether this method performs well w.r.t. to any of these papers discussing the effectiveness of interpretability methods and their potential limitations.\n    - e.g. the evaluation by Hooker et al. A benchmark for interpretability methods in deep neural networks\n    - Adebayo et al. Sanity checks for saliency maps\n    - Kindermans et al. The (un) reliability of saliency methods, \n   - Wilming et al. Scrutinizing XAI using linear ground-truth data with suppressor variables\n\n- Clarity\n  - On page 3 the shapely value is defined properly. However It is not clear how the Aumann Shapley value should be interpreted with a neural network. The citation for the Aumann Shapley value is not available in open access nor is it discussed properly on websites such as wikipedia. With the limited discussion here I am not able to properly understand the nuances of this. For example it is not clear how the players in the game map to an image classification problem.\n  - On Page 3 at the bottom: We make the hypothesis that baseline sample x\u2032 is considered as background in game and all points alongside P2 are considered as complete set I in game. It is never defined what background in the game actually means. How this should be interpreted. \n  - Theorem 1: please provide an intuition in the main paper. There is also no sufficiently formal definition of all components in the theorem to actually understand the proof in the supplementary.\n  - Page 5: partial coalition appears twice in the document and is not defined. It is not clear from the context what it actually is.\nStrengths:\n - Algorithm 1 and 2: make sure everything is defined properly. It is not clear for example how you can sample according to equation 1 as mentioned in algorithm 1. What is shown there is a sum, not a distribution.\n  - \"We first set players coalition as a single player, like 80*80 area as a player in image.\" This sentence is incredibly confusing. How do you change between a player contribution or not.\n\nStrengths:\nN/A",
            "clarity,_quality,_novelty_and_reproducibility": "As discussed in the weaknesses section there is a lack of clarity which limits reproducibility. On top of that the paper completely ignores a whole body of work critically evaluating interpretability methods. There is no evidence provided that the proposed approach is actually working reliably.",
            "summary_of_the_review": "The paper does not provide sufficient experimental justification of the proposed approach to be accepted. It ignores a lot of issues with interpretability methods and their evaluation that are discussed in literature. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_QQsg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4036/Reviewer_QQsg"
        ]
    }
]