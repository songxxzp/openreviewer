[
    {
        "id": "ub4W7SvfEQ",
        "original": null,
        "number": 1,
        "cdate": 1666585777245,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585777245,
        "tmdate": 1666585777245,
        "tddate": null,
        "forum": "kwF1ZfHf0W",
        "replyto": "kwF1ZfHf0W",
        "invitation": "ICLR.cc/2023/Conference/Paper1100/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose to apply Continuous LDA to pre-trained language models. The authors outline how to jointly train in a weighted loss function both the CLDA and the LM, making CLDA act as a regularizer for language models. In addition, CLDA can be used to interpret LMs, by using attention weights to group words at a concept and document level. The authors finally show that the CLDA actually improves the performance of LMs on the GLUE benchmark, particularly BERT-based ones.",
            "strength_and_weaknesses": "Strength:\n- Novel method of training CLDA jointly with LMs\n- Interpreting method as a bonus, strong theoretical backing\n- Good results on GLUE benchmark\n\nWeaknesses:\n- No major weaknesses\n\nNotes:\n- Concept 67 references \"West Asia\" and not necessarily \"Islam\" as per the highlighted red words. For example, \"Pasha\" and \"Qaeda\" are not related to Islam.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear and of good quality. The method is novel and there are sufficient details for reproducibility.",
            "summary_of_the_review": "The method introduced in the paper proposes to train an LM jointly with CLDA, shows how to interpret the resulting CLDA that uses the LM's attention weights, and improves performance on the GLUE benchmark. These contributions are solid and benefit the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_UZmn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_UZmn"
        ]
    },
    {
        "id": "ejG3QXgCO0",
        "original": null,
        "number": 2,
        "cdate": 1666613880226,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613880226,
        "tmdate": 1666613880226,
        "tddate": null,
        "forum": "kwF1ZfHf0W",
        "replyto": "kwF1ZfHf0W",
        "invitation": "ICLR.cc/2023/Conference/Paper1100/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes adding topic model upon pretrained language models (PLMs), in order to increase its interpretability and downstream performance. More specifically, the authors design CLDA, a new LDA model compatible with continuous word counts, which are computed via aggregated attention scores of the last layer in PLM. Each topics/concept is modeled as Gaussian distribution in the contextual embedding space. The CLDA can be used for interpretation of the PLM outputs when decoupled with PLM training, or used for regularization when jointly trained with PLMs. Experiments shows that CLDA can distinguish topics from word level to document level, and improve several GLUE tasks with joint learning.",
            "strength_and_weaknesses": "Strength: The proposed CLDA model is interesting and new as far as I know. The inference and learning algorithms are well designed.\n\nWeakness: The motivation of this paper is somehow weak to me. Why is it necessary to build LDA models upon the PLMs? What can we gain from the interpretation results such as those shown in Figure 4? How can we evaluate them? For example, if a PLM made wrong prediction on certain example, will the CLDA model give the interpretation and help to fix the error? The application scenarios of the CLDA (from the interpretation view) are completely missed in the paper.\nFor the quantitative results part, it is less discussed what makes the improvement over the baseline models. If it is the regularization effect, is it possible that the baseline models can be fine-tuned with finer but simpler regularization to achieve the similar results, considering that the bi-level optimization of PLM and CLDA is much more inefficient? \nBesides, why not include all the GLUE tasks rather than selecting part of them? And all the experiments and analysis are only tested in fine-tuning stage, it is unclear whether we can apply it in pretraining and what the results could be. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well written and easy to follow. The CLDA algorithm is mathematically sound. The method should be reproducible if the author can public their training and inference code.",
            "summary_of_the_review": "The paper proposes a LDA topic model based on the PLM, which can serve as interpreter and regularizor of the PLM. The method is technically sound. However, the paper is lack of discussion about how the interpretation results can be used and evaluated. The experimental results are incomplete and not that convincing, which prevent further exploration of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_YUbf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_YUbf"
        ]
    },
    {
        "id": "NLf8zMzRcd4",
        "original": null,
        "number": 3,
        "cdate": 1666632632314,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632632314,
        "tmdate": 1666632632314,
        "tddate": null,
        "forum": "kwF1ZfHf0W",
        "replyto": "kwF1ZfHf0W",
        "invitation": "ICLR.cc/2023/Conference/Paper1100/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper extend conventional topic model methods to contextualized word embeddings from BERT-like pre-trained models. The authors propose several modifications including using attention weights as continuous word counts and modeling and considering a contextualized word embeddings to be drawn from a Gaussian distribution corresponding to its latent topic. The authors propose to use the modified topic model as either interpreter for improved interpretability and as a regulator for improved performance. ",
            "strength_and_weaknesses": "Strengthes:\n1. The framework is technically sound and the adaptation of conventional topic model to pre-trained language models is interesting and can be helpful.\n2. The authors conduct both theoretical and empirical analysis of the proposed method.\n\nWeaknesses:\n1. The paper is not very well written and some parts of it are quite hard to follow/parse. Also, the citation style is strange and not reader-friendly.\n2. While the framework of  topic model with pre-trained language model is technically correct, the main claims of the paper (i.e., it can serve as good interpreter and regulator) are not well supported. First, it is unclear how finding the concepts and topics of different level will help users interpret the model's prediction. From this point of view, the proposed method is not as good as (or better) than existing interpretation methods for pre-trained models using either attention weights or shapley values. Second, for the regularization effect, the results on the GLUE benchmark in Table 1 is very poor compared to that in literature. For example, BERT-base can easily achieve around 57 for CoLA, 88 for MRPC in F1, and 66 in RTE, as well as on all other datasets. This is very different from the baseline results reported in Table 1. The experimental settings are also not very clearly described, making the effectiveness of the proposed method as regulator not convincing.\n3. There already exists several works on extending topic models with pre-trained models [1-2]. The authors do not discuss the contribution with respect to these works, making it hard to judge the actual technical contribution of the proposed framework.\n\n[1] BERTopic: Neural topic modeling with a class-based TF-IDF procedure\n[2] Topic Modeling with Contextualized Word Representation Clusters",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Poor\nQuality: OK\nNovelty: Poor\nReproducibility: Ok",
            "summary_of_the_review": "This paper extends topic models in PLMs and uses it as interpreter and regulator. However the experiments does not well support the main claims and the novelty of the technical contribution with respect to similar literature is unclear.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_iDsq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_iDsq"
        ]
    },
    {
        "id": "HLaRpqo1nS",
        "original": null,
        "number": 4,
        "cdate": 1666670740434,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670740434,
        "tmdate": 1666670740434,
        "tddate": null,
        "forum": "kwF1ZfHf0W",
        "replyto": "kwF1ZfHf0W",
        "invitation": "ICLR.cc/2023/Conference/Paper1100/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose to interpret contextual word embeddings by fitting a Gaussian mixture model with a Dirichlet prior over documents (CLDA) to the embeddings. They apply this framework to analyze the embeddings of fine-tuned language models on a number of tasks, and show that the model can be used as a regulator during fine-tuning.",
            "strength_and_weaknesses": "Strengths:\n* The paper follows the interesting idea of fitting a hierarchical Bayesian model to contextual word embedding.\n* It features a detailed derivation of the probabilistic model and the variational inference algorithm.\n* The probabilistic model can be used as a regulator during fine-tuning.\n\nWeaknesses:\n* The fine-tuned BERT-base and RoBERTa- base baselines in Table 1 have consistently worse performance than the official figures from their respective papers, casting doubt on the experimental setting in this paper. Additionally, it is strange that their RoBERTa-base model performs so much worse for QQP than BERT-base.\n* The focus of the method is unclear: Are we looking for \u201cinterpretability\u201d in the sense of (a) explaining a model\u2019s decision boundary, (b) feature attribution for a particular model predictions, or (c) analyzing downstream corpora (e.g., like a topic model)? The authors seem to promise a mix of (a) and (b), but I can\u2019t see how the inferred concepts help to give faithful or even plausible explanations. I would suggest that the authors feature a case study with user requirements & expectations about \u201cinterpretability\u201d and then compare CLDA\u2019s interpretations to the baselines. For example, claims of \u201cimproving readability and intuitiveness\u201d need to be supported more explicitly by the experiments.\n* The authors should be clear about the target setting. The introduction and method only use the term pre-trained language models (PLMs), while in the experiments the method is applied to LMs fine-tuned on sentence classification datasets.\n* The paper should discuss the literature on attention-based explanations in BERT, see Bibal et al., 2022, \u201cIs Attention Explanation? An Introduction to the Debate\u201d, as well as other works that use contextualized embeddings for topic modeling, e.g., Grootendorst, 2022, \u201cBERTopic: Neural topic modeling with a class-based TF-IDF procedure\u201d and Bianchi et al., 2021, \u201cPre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "It is difficult to understand the paper's goals and motivations, as well as some of its terminology.",
            "summary_of_the_review": "This paper proposes a novel interpretability approach using a Bayesian model fit to word embeddings. There are concerns about the experimental settings and intended use cases.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_c7kD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1100/Reviewer_c7kD"
        ]
    }
]