[
    {
        "id": "O61GhKsikEm",
        "original": null,
        "number": 1,
        "cdate": 1666562300374,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562300374,
        "tmdate": 1666562300374,
        "tddate": null,
        "forum": "P17yA67o3VL",
        "replyto": "P17yA67o3VL",
        "invitation": "ICLR.cc/2023/Conference/Paper746/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to use superpixel-based tokens instead of fixed-shape patch tokens for image segmentation, and proposes a graph pooling between transformer blocks to create an increasing size of segmentation from the oversegmented superpixel map.",
            "strength_and_weaknesses": "Strength:\n1. The motivations to use adaptive segment tokens are natural and straightforward.\n2. The paper turns this segmentation problem into a hierarchical segment grouping problem which is very interesting.\n\nWeakness:\n\n1. The paper claims hierarchical segmentation as the main contribution. However, there is no further support for why this is important or useful due to they are outcomes naturally from hierarchical segment grouping.\n\n2. The technical contribution is rather limited. The main technical contribution is the GraphPool algorithm, but further experimental evaluation specifically designed to verify this module's effectiveness is missing.\n\n3. It's mentioned in Sec. 3.3, we have to set the cluster number. Any experiments or investigations on that? Comparison to mode-seeking algorithms such as meanshift may remove the need to set cluster number?\n\n4. Just curious, how can the model learn to correct the over-segmentation error in the superpixel stage? For example, a superpixel contains two or more three semantic different classes. Will the proposed model be able to separate it? \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is good and intuitive. No code is attached.",
            "summary_of_the_review": "Overall, this paper poses certain merits in terms of unsupervised image segmentation. However, there are some missing details/problems to answer mentioned in the [Strength And Weaknesses] tab to increase the soundness of the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper746/Reviewer_5DAX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper746/Reviewer_5DAX"
        ]
    },
    {
        "id": "F8okWQr_HN5",
        "original": null,
        "number": 2,
        "cdate": 1666627233801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627233801,
        "tmdate": 1666627294996,
        "tddate": null,
        "forum": "P17yA67o3VL",
        "replyto": "P17yA67o3VL",
        "invitation": "ICLR.cc/2023/Conference/Paper746/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to concurrently perform image classification and segmentation using adaptive segment tokens, which is demonstrated effective and superior to current methods. ",
            "strength_and_weaknesses": "Strength\n\n1. The paper is well organized and written so that it is easy to follow and understand.\n2. The basic idea is reasonable and insight analysis is convincing.\n3. The proposed is technically sound and the novel.\n\nWeaknesses\n\n1. Not sure how the \"goodness of grouping and consistency across the hierarchy\" are measured and used in proposed method.\n2. More experiment with state-of-the-art segmentation and classification methods would be better.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is good. The motivation and proposed method is clearly presented.",
            "summary_of_the_review": "The paper provides in-depth analysis of the human vision for image recognition and segmentation, and a novel method to deal with the task with superior performance.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper746/Reviewer_BmNe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper746/Reviewer_BmNe"
        ]
    },
    {
        "id": "fNJ1qFoRhnI",
        "original": null,
        "number": 3,
        "cdate": 1666682756872,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682756872,
        "tmdate": 1666682756872,
        "tddate": null,
        "forum": "P17yA67o3VL",
        "replyto": "P17yA67o3VL",
        "invitation": "ICLR.cc/2023/Conference/Paper746/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to replace the standard rectangular patch based tokens in transformers with superpixel based regions. Features for each superpixel are pooled to a token and these are used in a hierarchical transformer architecture. When reducing the number of tokens (GraphPool), furthest point sampling is used to select a subset of tokens and all the tokens from the previous layers are grouped to the sampled tokens with the highest similarity. The complete network is trained in an unsupervised fashion, meaning that a hierarchical segmentation can be extracted from the network without any labels. Using some additional supervision on top of this results in an approach that can perform semantic segmentation in a hierarchical way. The overall idea to modify a transformer architecture to obtain a hierarchical segmentation without the need for direct segmentation supervision is very interesting.",
            "strength_and_weaknesses": "Strengths:\n- The paper proposes an interesting architecture idea and  shows that it has some merit to it with quite some experiments. Especially, the Graph Pooling module seems to work fairly well in their instantiation compared to other baseline approaches.\n- Especially that this can be trained without labels makes it rather interesting.\n\nWeaknesses:\n- I'm mainly concerned about the training of the proposed model. Specifically the GraphPool block seems to perform a non-differentiable hard one_hot assignment. While I understand that this should be a hard assignment, you cannot propagate gradients to this into the features in such a way that pooling operation learns to pool together meaningful features. As such I also wouldn't really know why the additional losses should be effective and the ablation study also shows that they do not have a major effect on the performance. I would assume this could be fixed with something like a Gumbel softmax. Did you consider doing that? As it is right now, I think the model really only groups together similar superpixels based on similar features that become similar by accident, but not because the features of meaningful supersegments were trained to be more similar. I see this as one of the major weaknesses of this paper. Empirically it performs reasonably well, but it's not really clear if that is because it does what one would expect it to do. I get the same feeling about the superpixel segmentation. As far as I can tell, you apply SEEDS to the RGB image and thus the gradients are passed to the initial feature extraction layers through the regions, but the network can never learn better features to create better superpixel oversegmentations.\n- The paper states that the model can deal with varying numbers of input superpixels (and different numbers of coarser supersegments in the later layer) since the number of sampled tokens can just be changed. Sadly there are no real experiments to confirm that. I think this would actually be a super interesting experiment to truly learn something about the architecture. How does it behave when during inference these numbers are actually changed and how important is it that these numbers are selected in the right way? I think focusing a little more on these aspects would make the paper a lot stronger.\n- As far as I understand the paper, all of the reported numbers are based on own experiments, including all the baseline numbers. As such I really wonder how well these baselines were tuned. Simply applying the same schedule to some other network doesn't make it an inherently fair comparison. What makes it even worse is that in several cases the margin between the proposed model and the baselines is not even very large, thus raising the question if the model truly performs better than the VIT or k-mediod baselines, or it's just a simple matter of slightly different tuning of the model. To be fair though, the paper does not claim that the method achieves state-of-the-art results. A comparison with external baselines would be very good though!\n- The ablations not only show that the additional losses don't make a major difference, but even the fact whether or not superpixels are used instead of patches does not have a major impact on the performance. Did you ever check if the quality of the superpixels matters at all? Could you just use bigger or smaller superpixels?\n- Partially the paper is quite informally written and some sections just do not read very well. For example, I have never seen the abbreviation 'a.k.a.' used in a paper and it is consistently missing the last dot. Especially the sections dealing with training setups are not very nice to read and I think they would be better placed in the appendix, likely in tabular form. In general another pass over the paper, checking some spelling and grammar, would likely be good.\n\nQuestion:\n- A quick google search yielded the following CVPR'22 paper \"Semantic Segmentation by Early Region Proxy\". It shows that there is at least one other transformer-based method using superpixels. Even though I don't think it's extremely related, it could make a good addition to the related work.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is fairly easy to understand, although I don't think the writing is of very high quality. The contained research is quite interesting though, I just don't gain any major insights about the key workings of the approach and I'm a bit worried it doesn't really work because it does what one might think at a first glance. Nevertheless, I think the overall idea is fairly novel. Some details are clearly lacking to really make it reproducible and sadly it is unclear if the authors plan to release the code.",
            "summary_of_the_review": "Overall I like the core concept automatically learning a hierarchical segmentation without the need for labels, however, I have some doubts about how the model really works and how well it works compared to external baselines. I think adding some more experiments regarding these issues and giving the paper another good polishing will likely make it a lot better. As such I'm a little unsure whether to accept this or not. Depending on the other reviews and the rebuttal, I'm willing to change my opinion more towards the positive side though.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper746/Reviewer_Jmwj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper746/Reviewer_Jmwj"
        ]
    },
    {
        "id": "5WT9jinYBS",
        "original": null,
        "number": 4,
        "cdate": 1667016249220,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667016249220,
        "tmdate": 1667016249220,
        "tddate": null,
        "forum": "P17yA67o3VL",
        "replyto": "P17yA67o3VL",
        "invitation": "ICLR.cc/2023/Conference/Paper746/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method for jointly computing region segmentation and image recognition, with any supervision to learn segmentations. The concept is based on hierarchical region segmentation to feed tokens into an image transformer, instead of fixed-size image patches. Experiments show that the method achieves recognition accuracy comparable to the baseline transformer but at half the computational cost, and considerable increases in segmentation accuracy.",
            "strength_and_weaknesses": "Strengths\n\nGeneralizing vision transformers to incorporate tokens of arbitrary shape and size is a significant contribution. As the authors state, partitioning an image into fixed size and shape tokens is an artificial construct that ignores image content. Removing that constraint is a worthy goal and should lead to improved performance.\n\nConstructing the model to handle arbitrary image regions requires generalizing it to handle a variable number of tokens. Fig. 2 is a very clear, effective illustration of the important aspects of transformer-based segmentation algorithms and the advantages of the proposed approach. Explicitly computing and leveraging image regions presents complexities but is much more faithful to the image.\n\nThe method is based on hierarchical segmentation using superpixels, an interesting revisitation of traditional methods combined with transformers. Before deep learning such methods were popular and achieved SOTA performance on segmentation problems, and combining these techniques with deep learning is a worthwhile attempt. The primary benefit, as shown in the results, is an improvement in computational efficiency rather than overall accuracy. The results show modestly improved accuracy over the VIT baseline in most cases, with significant improvements in computational cost.\n\nCombining region segmentation and image recognition through jointly optimizing them is a compelling idea, and has been treated only lightly in recent years.\n\nWeaknesses\n\nOn page 1 the authors state that \u201cModels optimized for image classification have no concepts of parts and wholes; recognition is achieved without understanding how different parts such as eyes and face are organized for the whole animal.\u201d This claim seems hard to justify, as CNNs are designed to learn object parts and their relationships, and many works have shown this to be true. This statement should be qualified appropriately or softened considerably.\n\nThe results do not show a significant gain in segmentation accuracy from the proposed method compared to baseline VIT using standard (square) image tokens, on ImageNet, which is disappointing. However the primary strength of the method is in fine-grained accuracy, and this performs better as shown in tables 2 and 3 for VOC.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite clear, and well organized. The method is a novel combination of traditional segmentation with transformer methods, addressing a limitation of transformers in using fixed tokens. There appears to be sufficient detail to reproduce. ",
            "summary_of_the_review": "The paper is well written, with a novel idea that is validated through thorough experiments. It should be of interest to those working in image segmentation and recognition.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper746/Reviewer_kF9A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper746/Reviewer_kF9A"
        ]
    }
]