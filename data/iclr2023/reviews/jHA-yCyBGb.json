[
    {
        "id": "NfmoMEK2vGD",
        "original": null,
        "number": 1,
        "cdate": 1666273912661,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666273912661,
        "tmdate": 1666678578589,
        "tddate": null,
        "forum": "jHA-yCyBGb",
        "replyto": "jHA-yCyBGb",
        "invitation": "ICLR.cc/2023/Conference/Paper4632/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper builds on top of recent, good papers. Diffusion-based generative models have been recently lifted from Euclidean spaces to compact, connected Riemannian spaces (De Bortoli et al, 2022), where given a family of \"normal\" distributions, forward diffusion processes are proved to admit backward diffusion processes similarly to Euclidean spaces. Normal distributions on those spaces are required to be closed under convolution so that the backward processes can be tractable However, such distributions are typically very cumbersome to deal with as they often exist as infinite serieses. Many approximations have to be introduced. The paper specialises to SO(3), and uses a classical, but less well-known family of \"normal\" distributions on SO(3) called Isotropic Gaussian distributions $\\mathcal{IG}_{SO(3)}$ (Nikolayev & Savyolov, 1970), which is not only closed under convolution but also much easier to work with from the calculus point of view.\n\nThe paper goes on and derives an equivalent of score-based generative models (SGMs) on SO(3), and an equivalent of (the spirit of) denoising diffusion probabilistic models (DDPMs) on SO(3). It is shown theoretically that SGM on SO(3) enjoys a lot of similar properties as the Euclidean SGM, as the cumbersome normalizing factor of $\\mathcal{IG}_{SO(3)}$ distributions can be mostly avoided.\n\nIn contrast, in the DDPM on SO(3) case, because there is no closed form for the distance between two distributions in $\\mathcal{IG}_{SO(3)}$, the ELBO cannot be reduced to an analytical form during training.\n\nExperiments on synthetic data comparing the proposed variants showing results favouring SGM on SO(3). However, there is no results on real-world data.",
            "strength_and_weaknesses": "## Strength\n\nThe paper is very well-written. It has an excellent review of existing works.\n\nThe idea of using Isotropic Gaussian distributions for diffusion generative models on SO(3) has been recently introduced in (Leach et al 2022). However, their approach is restricted to DDPM, while this paper is a more complete treatment of the same topic.\n\n## Weaknesses\n\nWhile SGM on SO(3) enjoys many properties similar to Euclidean SGM, I think the treatment of DDPM on SO(3) can be further improved. In the paper, the authors mentioned that they did not try out any other distribution families like matrix Fisher distributions or Bingham distributions for the reverse diffusion process but instead used Isotropic Gaussians for convenience. This part can be elaborated further. What convenience do you get by staying with Isotropic Gaussians? Why not try other families? In my view, once you have set up a reverse Markov process as machine-learnable, you are free to choose the distributions that work best for your data. As mentioned in the paper, by staying with Isotropic Gaussians you have to accept an inconvenience in that there is no analytical form for the KL divergence between two distributions of such kind, leading to an extra forward Markov process during training. Why not use a distribution family where the KL divergence has an analytical form?\n\nI think it makes sense to report some comparisons in training times and inference times between SGM on SO(3) and its closest rival RSGM, since RSGM is very close to SGM on SO(3) in spirit but SGM on SO(3) enjoys a much more efficient implementation thanks to the Isotropic Gaussians. Speed-related results are somewhat lacking in the paper.\n\nEquation (14) is somewhat puzzled to me. In the current draft, it looks like the network predicts the mean rotation using the axis-angle representation. However, the axis-angle representation does not work very well when the mean rotation angle approaches $\\pi$. Perhaps the authors meant that the function $\\mu$ represents the relative rotation (in axis-angle form) from $\\mathcal{x}_i$ to the predicted mean rotation, thereby actually having $\\mathcal{x}_i$ next to $\\exp(\\cdot)$ in the equation?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is technically very clear. The materials are presented in a smooth order, making it easy to follow. The mathematical derivations are correct to me.\n\nResults are reproducible. The authors have provided code and sufficient resources in the supplementary materials, which is very welcome.",
            "summary_of_the_review": "I thank the authors for having submitted this paper. I have had a good read.\n\nThe paper has the right motivation. Its theoretical side is very good. There are minor points of improvements for DDPM on SO(3). However, experiments are restricted to synthetic data only, and there is no result related to training time or inference time compared to the existing best method RSGM, which is a bit unfortunate because the paper promotes efficient computations on SO(3).\n\nNonetheless, I find the pros outweigh the cons.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_aEa8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_aEa8"
        ]
    },
    {
        "id": "RbcfIVGHJoZ",
        "original": null,
        "number": 2,
        "cdate": 1666670055142,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670055142,
        "tmdate": 1666670055142,
        "tddate": null,
        "forum": "jHA-yCyBGb",
        "replyto": "jHA-yCyBGb",
        "invitation": "ICLR.cc/2023/Conference/Paper4632/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper extends diffusion generative models to SO(3) manifold. It provides implementations for score-based generative models and denoising diffusion probabilistic models. The proposed methods are applied to synthetic densities on SO(3).",
            "strength_and_weaknesses": "Strength:\n- Reformulate diffusion models on SO(3) and the loss functions to train the models.\n- The proposed method is better than others in the experiment of synthetic densities.\n\nWeakness\n- Experiments are weak, with only three synthetic densities. The paper claims the proposed method has efficient training, but it\u2019s not evaluated in the experiments.\n- Applications are also weak. The paper mentioned the proposed method can be used for pose estimation, and claims it\u2019s better than previous work. However, it doesn\u2019t explain how the diffusion generative models can be applied to pose estimation, and there\u2019s no experiment to support the claim.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems to have novelty in extending diffusion models to SO(3). Previous work (Leach et al. 2022) also uses isotropic Gaussian on SO(3) for the same purpose. But this paper also modifies the loss function, and achieves better results.\n\nThe paper is heavy in theory, and therefore, it\u2019s difficult to read for the audience without background. Also because of that, it\u2019s not very clear how to reproduce the implementation. \n",
            "summary_of_the_review": "The paper is heavy in mathematical formulation and theory, but is weak in experiments and applications.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_XDGv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_XDGv"
        ]
    },
    {
        "id": "jGo7xKFtJu",
        "original": null,
        "number": 3,
        "cdate": 1666992455248,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666992455248,
        "tmdate": 1666992455248,
        "tddate": null,
        "forum": "jHA-yCyBGb",
        "replyto": "jHA-yCyBGb",
        "invitation": "ICLR.cc/2023/Conference/Paper4632/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a generative diffusion model for SO(3) densities using the heat kernel on SO(3). The authors design both a score-based forward pipeline and well as a denoising pipeline for SO(3). Experiments are done on synthetic datasets of rotation samples. \n",
            "strength_and_weaknesses": "+: The main strength of the paper is the use of a heat kernel on SO(3).\n\n+: The authors carefully chose a tractable heat kernel and how to parametrize the isotropic Gaussian as well as explaining its advantages over Bingham and Fisher matrix distribution (being closed wrt convolutions).\n\n+: Thanks to the heat kernel there is no need to solve for the stochastic DE. \n\n+: Isotropic Gaussian enables a closed form in the KL-divergence term of the ELBO.\n\nAuthors could respond to the following weaknesses:\n\n-: The mapping from the axis-angle representation to SO(3) is not continuous, and it might affect the stability of the network components of the DE solutions. An example of a continuous mapping is the two first columns of the rotation matrix (a Stieffel manifold) as explained in Zhou et al.'s paper (On the continuity of rotation representations).\n\n-: The experimental evaluation is very limited regarding datasets and evaluation metrics. The significance of density estimators is in capturing multimodal distributions arising in real data. There is abundant real data in 6dof object pose in images and point clouds as well as in all joint orientations in human poses. Many insights can be gained by conditioning the diffusion on such inputs. State-of-the-art approaches like citations Murphy et al. or Mohlin et al. have used such data.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written.\n\nThe heat equation on the sphere has been used before for constructing kernels (Multiscale image processing on the sphere, Bulow among others ). \n\nThe authors might want to check the \"Score-based models detect manifolds\" paper by Pidstrigach.\n",
            "summary_of_the_review": "This paper would be an accept if it included experiments conditioned on input images or point clouds. It is the first diffusion on SO(3) as far as I know. Adopting the heat kernel is a great idea, and the implementation of the score-based model and the denoising model are carefully done. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_aBeQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4632/Reviewer_aBeQ"
        ]
    }
]