[
    {
        "id": "GxNbCAE4LXo",
        "original": null,
        "number": 1,
        "cdate": 1666516526606,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666516526606,
        "tmdate": 1666516526606,
        "tddate": null,
        "forum": "C1ns08q9jZ",
        "replyto": "C1ns08q9jZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3223/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel framework to conduct evaluation-free model selection for graph learning models, i.e., without having to train/evaluate any model on the new graph. The framework learns latent embeddings for observed models and the corresponding performance on observed graphs. Moreover, meta-graph features are computed for each graph based on specific structures so that the graph similarity can be measured. The extensive experiments demonstrate the effectiveness of the proposed framework.",
            "strength_and_weaknesses": "Strengths:\n1. The framework solves the novel problem of evaluation-free model selection in graph learning, which is crucial and challenging in real-world scenarios.\n2. The experimental results are comprehensive and adequate. The authors also provide additional results regarding the effectiveness of each module and the efficiency of the framework.\n3. The paper is well organized and easy to follow.\n\n\n\n\nWeaknesses:\n\n1. The structural information in each graph seems to be only incorporated via the meta-graph features. However, this can also be achieved by a specific GNN with a readout function. That being said, the improvement of the proposed framework is hardly believed to result from the incorporation of structural information.\n2. The input for computing the latent embedding of a graph to function f() is not rational. If \u03c6(m) is solely dependent on m, why the input of f() is a combination of m and \u03c6(m), instead of only m or \u03c6(m)? In this way, the information of m can also be preserved. On the other hand, combining both will seem redundant.\t\n3. The experimental part only includes the link prediction task. Although this task is important in graph mining, the proposed method should be capable of various graph mining tasks (considering that the scenario will generally be applications). However, the lack of evaluation on other graph mining tasks will cause the paper to be less convincing.\n4. The paper lacks sufficient theoretical analysis to support the claim of efficacy and efficiency. The empirical results are plentiful, while further analysis would be beneficial.\n",
            "clarity,_quality,_novelty_and_reproducibility": "For the Clarity:\n1. There are several typos and grammar errors in this paper. For example, \u201csmarter, more efficient\u201d should be \u201csmarter and more efficient\u201d. \u201cis fully automatic it does not require\u201d lacks the word \u201csince\u201d. \u201cnumber of wedges\u201d should be \u201cnumber of edges\u201d.\n\n2. The paragraph starting with \u201cBenchmark Data/Code:\u201d appears twice in the main paper, which is redundant.\n\nFor the Quality and Novelty:\nThe quality seems to be solid and the studied problem is novel. The specific modules in the framework are less novel, while the framework is well designed.\n\nFor the Reproducibility:\nFollowing the above, the authors claim that they release the code and datasets, which are not found in the paper. No links are provided.\n",
            "summary_of_the_review": "The paper solves a novel and crucial problem of evaluation-free model selection for graph learning. The experimental results are comprehensive. However, the major drawback lies in the lack of other graph mining tasks except for link prediction. The design is somewhat novel while also lacking theoretical analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_P6vP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_P6vP"
        ]
    },
    {
        "id": "A1Abkxbbm4",
        "original": null,
        "number": 2,
        "cdate": 1666627157598,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627157598,
        "tmdate": 1666627157598,
        "tddate": null,
        "forum": "C1ns08q9jZ",
        "replyto": "C1ns08q9jZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3223/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper considers the problem of how to select an effective GL model for link prediction task on a new graph without training/evaluating process. To deal with this problem, the authors propose a meta-learning based matrix factorization (MF) approach MetaGL. MetaGL adopt the meta graph features to represent graphs, which can convert the transductive MF to an inductive manner for a new graph.\nThe proposed method is evaluated on 301 graphs via 5-fold cross validation with 412 candidate models.\n",
            "strength_and_weaknesses": "### Strengths:\n1. This paper first considers how to select an effective GL link prediction model for a new graph without searching process. It is a new and meaningful problem. \n\n2. The experiments are solid and can support the contributions: effectiveness of the meta-learning framework and global statistical features.\n\n3. The construction of G-M Network makes sense and further improves the performance. \n\n### Weaknesses:\n1. It seems that the extracting of some meta-features (e.g., triangles and Page Rank score) is time-consuming which limits the application on the large-scale graph.\n\n2. The GRL methods in the model set are limited and the model set may not contain some new GRL methods in recent years.\n\n3. It seems to be missing the training details and metrics of the link prediction subproblem.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and original.",
            "summary_of_the_review": "The paper considers a new problem of selecting effective GL models in an evaluation-free manner and proposes an effective approach to handle this problem with solid experiments. However, there are some issues with the scalability and limited GRL methods in the model set. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_3hVZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_3hVZ"
        ]
    },
    {
        "id": "0SMh3qt01Y",
        "original": null,
        "number": 3,
        "cdate": 1666795188083,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666795188083,
        "tmdate": 1666795445692,
        "tddate": null,
        "forum": "C1ns08q9jZ",
        "replyto": "C1ns08q9jZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3223/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work focuses on graph model selection without training by matching the meta-feature and model representations. Extensive experiments are conducted to demonstrate the effective and efficiency of the proposed method. Basically, the overall idea has close relation to pioneering work MetaOD. By comparison, this work adopts the key idea to explore the graph model selection task with meta-knowledge.",
            "strength_and_weaknesses": "Strength:\n1. The presentation and writing are good enough for clearly presenting the motivation and corresponding solution.\n2. Meta-features for graph data are clearly defined by fully extracting the graph structural knowledge.\n3. Extensive experiments are conducted to demonstrate the superiority of proposed method to state-of-the-art meta model selection method.\n\nWeakness:\n1. The novelty is limited to applying the principles of MetaOD to graph data by matching meta-features of graph data with model representations. It's interesting to compare the way to run \"meta-learning\" in this work with the optimization-based meta-learning methods like MAML [1]. The common thing shared by them is that finally selected model should have impressive prediction performance. The principles emphasized in this work pays attention to select the best one from the stored models which are trained on historical data. While optimization-based meta-learning can capture the unique knowledge existing in the input data just by fine-tuning models. I strongly suggest to have a discussion on the difference between them and make a comparison over their prediction performance.\n\n2. Though the proposed method can fast search one model from the candidates, it's still difficult to believe that only comparing the meta-features extracted from graph structures can select the exact model for the input data. What if the extracted meta-feature can not represent the node features distribution differences existing in the graphs? Is it still the best choice for model selection? or is the learning-free model selection suitable to deal with the knowledge gap between the new graph and those graphs in the data pool?\n\n3. Last but not least, I still have concern on the generalization of the proposed method. It's well known that graph consists of unique node sets. How is possible that the models trained on different graphs can be applied to a graph with totally different nodes? Maybe authors should present some concrete applications that are suitable to be applied the proposed method.  \n\n\nReferences:\n1. Finn, Chelsea, Pieter Abbeel, and Sergey Levine. \"Model-agnostic meta-learning for fast adaptation of deep networks.\" In International conference on machine learning, pp. 1126-1135. PMLR, 2017.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is overall clear enough the catch the main idea. However, I have concerns on the novelty of the proposed method.",
            "summary_of_the_review": "This work attempts to facilitate model selection just by matching the meta-knowledge extracted from graph data and the trained models. It's a very interesting idea. But graph data raises unique challenges over the knowledge transferring across different graphs. Considering this point, it's difficult to believe the generalization of the proposed method.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_uUz4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_uUz4"
        ]
    },
    {
        "id": "kf9giYxBFt",
        "original": null,
        "number": 4,
        "cdate": 1667092965363,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667092965363,
        "tmdate": 1667092965363,
        "tddate": null,
        "forum": "C1ns08q9jZ",
        "replyto": "C1ns08q9jZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3223/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors provide the meta-learning framework for graph learning models that estimates the model performance based on the meta-graph features such as network structures. The proposed method optimizes the numerical performance values based on the top-1 probability based cross-entry loss function. Experimental results show that the proposed method can be robustly optimal for various datasets.",
            "strength_and_weaknesses": "* Strength\n- The proposed meta-learning estimates the performance and leverages the predictive power for more robustly good model learning.\n- The proposed method is a novel way of ensembling graph learning algorithms.\n- The small initial overhead results in more reliable performance.\n\n* Weakness\n- The model performance matrix P is a random matrix since the performance is not deterministic. It would be great to study the sensitivity to the variance of the performance matrix P, not just the observation rate.\n- It would be great if the proposed meta-learning is not only used for the model selection, but also for the insights about the performance characteristics of each graph model algorithm -- such as some algorithm working better for a homophily networks or clustering the similar flavor of algorithms, and so on.\n- It would be interesting to compare the performance from MetaGL with the actual best performance. Since we have a fixed set of algorithms and perform training for each method, we are able to compare with the \"optimal\" selection.",
            "clarity,_quality,_novelty_and_reproducibility": "- The manuscript is well-written so that readers can easily follow.\n- Through analysis has been made so the impact by the proposed meta-learning can be well understood.\n- The idea of using graph structure as the meta-learner features is novel enough. It is worth being studied more in the research community.\n- Without the shared performance matrix, it may not be trivial to reproduce the results. For the full reproducibility, all the hyperparameters chosen for performance matrix need to be shared.",
            "summary_of_the_review": "While GNN becomes popular in the ML area, it often requires a lot of resource to train on large datasets and chooses the best working model. The proposed meta-learning will provide the opportunity to produce more reliable results in a more productive fashion. Also, the thorough study for the given MetaGL provides understanding and confidence of the proposed model.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_GdF8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3223/Reviewer_GdF8"
        ]
    }
]