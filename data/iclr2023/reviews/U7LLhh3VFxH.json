[
    {
        "id": "ZmCZ8zjWeql",
        "original": null,
        "number": 1,
        "cdate": 1666577975902,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577975902,
        "tmdate": 1666579736774,
        "tddate": null,
        "forum": "U7LLhh3VFxH",
        "replyto": "U7LLhh3VFxH",
        "invitation": "ICLR.cc/2023/Conference/Paper2534/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a data-agnostic and model-agnostic data augmentation method ESP to enhance a model\u2019s robustness to unforeseen data corruptions. Concretely, ESP consists of two parts, perturbation adding and exponential label smoothing. The added noise perturbation in ESP is sampled from a truncated Gaussian distribution, while Label smoothing here takes the magnitude of perturbation into consideration. Stronger perturbations are companioned by stronger label smoothing.\nThe author provides theoretical proof that perturbations in input space can encourage a model to find a flat minimum on the parameter space. \nExperiments demonstrate that ESP when combined with existing augmentation methods improves the robustness to different degrees.\n",
            "strength_and_weaknesses": "Strength:\n1. The proposed data augmentation is simple, effective, and also theoretically justified.\n2. Both sample-specific adversarial perturbation and universal adversarial perturbation are considered in this study.\n\nWeakness:\n1. As also pointed out by the author, the proposed method is sensitive to hyperparameters. The reported improvement in Table is often marginal. The two facts make the proposed method less practical.\n2. Given the nature of the proposed data augmentation, the author should report the mean and variance of each experiment since randomness is brought by sampling from a truncated Gaussian distribution. This is necessary since the improvements reported are not significant.\n3. In Figure 4, the authors aim to claim the effectiveness of exponential label smoothing. However, the standard label smoothing should be included as a baseline. The improvement of ESP over perturbation-only baseline can be brought by the effectiveness of standard label smoothing.\n4. In Figure 2, the theoretical properties of ESP are illustrated. Is it possible to draw the illustration with real experimental data?\n5. There are many appendix points in the main text. However, no appendix is found in the submission.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall presentation remains to be improved. The novelty of the proposed method is limited. The theoretical justification might be a solid contribution. Its significance cannot be told since the appendix is missing.",
            "summary_of_the_review": "Given the weakness listed above, I tend to reject this paper before rebuttal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_ST3E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_ST3E"
        ]
    },
    {
        "id": "tou4E3hGmMQ",
        "original": null,
        "number": 2,
        "cdate": 1666649593879,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649593879,
        "tmdate": 1669166510953,
        "tddate": null,
        "forum": "U7LLhh3VFxH",
        "replyto": "U7LLhh3VFxH",
        "invitation": "ICLR.cc/2023/Conference/Paper2534/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a new augmentation strategy ESP, which augment training with random perturbation with smoothed labels. The experiments showed that ESP outperforms vanilla L2 augmentation on common corruption robustness. The authors also gave theoretical analysis on the properties of ESP.",
            "strength_and_weaknesses": "Strength:\n* The theoretical analysis provides some insights on the benefits of label smoothing.\n* The proposed ESP augmentation has the potential to be combined with many existing works on common corruption robustness to further boost the model robustness.\n\nWeaknesses:\n* The theoretical analysis is not clear enough. The imbalance's severity N and the normal distribution use the same letter N, which makes me confused when reading this section. \n* Theorem 1 states that ESP can make the optimal boundary less sensitive to imbalance severity, but why is this a desired property for ESP? What is the benefit for a less-sensitive boundary?\n* Theorem 2 proves that perturbations in the input space can be converted to perturbations in parameter space. This result is available in [1] Lemma A.4.\n* In experiments, the paper only compares the result with vanilla L2. I suggest the authors to compare with more label smoothing methods and also mixup.\n\n[1] Convergence of Adversarial Training in Overparametrized Neural Networks\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is written in good quality but needs some improvement in the theoretical properties part.",
            "summary_of_the_review": "In all, I think this paper proposed a simple yet effective method to boost the model robustness against common corruption. The theoretical analysis also provides some insights. However, as I have mentioned in the Weaknesses, I hope the authors can have more experimental comparison and also compare with some related existing theoretical results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_6X1k"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_6X1k"
        ]
    },
    {
        "id": "zsNwGjfV8A",
        "original": null,
        "number": 3,
        "cdate": 1666706911891,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666706911891,
        "tmdate": 1666706911891,
        "tddate": null,
        "forum": "U7LLhh3VFxH",
        "replyto": "U7LLhh3VFxH",
        "invitation": "ICLR.cc/2023/Conference/Paper2534/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for improving robustness to common corruptions via L2-norm bounded data augmentations of varying sizes. The authors show theoretically that data augmentation of this form results in models with flatter minima in parameter space, which has been shown to result in better generalization. This paper also proposes a method for label smoothing that exponentially smooths the labels based on the size of the perturbation. ",
            "strength_and_weaknesses": "Strengths: \n- The paper is mostly well written, and the contributions/methods are clear. \n- The paper provides some theoretical justifications for their method. \n- The proposed method results in consistent improvements in generalization on common corruptions across different datasets.\n\nWeaknesses:\n- Since the proposed method is augmenting the data with noise, and evaluating on the common corruptions dataset, of which several of the corruptions are noise-based corruptions, I think it's important to state whether robustness to all of the corruption types improves, or just those noise type corruptions. \n- The authors mention the proposed method is sensitive to the choice of hyperparameter determining the max perturbation size. When doing the hyperparameter search, how do you determine the optimal hyperparameters? I.e. are you choosing the hyperparameters based on performance on the common corruptions test set? In practice, you'd need some other validation metric for choosing hyperparameters, as fundamentally you are trying to improve performance on unseen, out of distribution data. \n- The paper does not report performance on clean/unperturbed test images. How does the proposed data augmentation scheme affect standard test accuracy?\n\nOther suggestions:\n- I would maybe state earlier in the paper that the label smoothing technique only results in improvements for datasets with a larger number of classes. \n- Most of the figures are too small to properly read. It's a bit difficult to gather any insights from Figure 3. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall mostly clearly written, and provides an original method for label smoothing based on perturbation size. ",
            "summary_of_the_review": "While this paper does report improvements across all datasets in terms of the common corruptions performance and includes some theoretical justifications, it's unclear to me whether the proposed method results in performance improvements for a variety of different unseen perturbations, or just noise-based perturbations. It is also unclear how the hyperparameters would be chosen in practice for unseen perturbations. Given these uncertainties, I'm leaning towards reject. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_rCik"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_rCik"
        ]
    },
    {
        "id": "DXF56Q9fPx7",
        "original": null,
        "number": 4,
        "cdate": 1667015614089,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667015614089,
        "tmdate": 1667015614089,
        "tddate": null,
        "forum": "U7LLhh3VFxH",
        "replyto": "U7LLhh3VFxH",
        "invitation": "ICLR.cc/2023/Conference/Paper2534/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new data augmentation method, which jointly augments data and label, using an empirical hand-crafted rule: The input image is added a random Gaussian noise, and the corresponding label is smoothed with the strength proportional to the image noise magnitude. I think the goal of such data augmentation is to enforce model to have a certain level of smoothness, as regularized by the strength of the augmentation. And ideally improve model robustness. However, the empirical results shows marginal improvements. For example, on CIFAR0-C and CIFAR100-C, it only brings 0.39% and 0.21% accuracy gain over the second best method. I have some assumptions on why the proposed method not bringing good performance gains. Please see details below. ",
            "strength_and_weaknesses": "1. The isotropic random noise might not be the best choice for image augmentation. Imagine two random noises with the same magnitude, one is focused on the foreground object, while the other is focused on the background pixels. The former on should be accompanied with a larger perturbation on the label (i.e. a more smoothed label in your framework), while the later should be accompanied with a smaller label perturbation. This is because the background noise hardly affects the semantic meaning of the image, and thus the label shouldn't change much. However, in your current design, both noises would have a same level of label perturbation, which might not be the best design in my opinion. \n\n2. Besides the marginal performance gain, the proposed method also suffers from hyper-parameter tuning overhead. Specifically, it introduces four new hyper-parameters to tune. I wonder whether it is worthy to pursue the marginal performance at such cost.\n\n3. Since the performance gain on the small datasets are maringal, I wonder whether it brings benefits on larger datasets such as ImageNet(-C).\n\n4. Has the performance on clean test sets been reported in the main text? Both clean accuracy and robustness are important for a real-world model. Previous works such as AugMix and DeepAug usually report clean accuracy alongside robustness. \n\n5. It seems to me that MixUp/CutMix/etc. also share similar idea to jointly perturb label and input. Maybe the author should discuss why the proposed way is better than those previous methods and provide empirical comparison results?\n\nOverall, I suggest revision and resubmit considering the above limitations. ",
            "clarity,_quality,_novelty_and_reproducibility": "Please see above",
            "summary_of_the_review": "Please see above",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_eTKu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2534/Reviewer_eTKu"
        ]
    }
]