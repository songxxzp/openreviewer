[
    {
        "id": "y0y2reDIyYF",
        "original": null,
        "number": 1,
        "cdate": 1666607378903,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607378903,
        "tmdate": 1666626176935,
        "tddate": null,
        "forum": "Y2ShteTrnX2",
        "replyto": "Y2ShteTrnX2",
        "invitation": "ICLR.cc/2023/Conference/Paper3648/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose to use transformers to meta-learn a general-purpose learning algorithm. They train a transformer on many related tasks such that it is able to make a prediction for x given an entire dataset and x as an input to the transformer. They analyze when under which circumstances the transformer memorizes the data seen during meta-training and when it generalizes and note that many tasks and large models are a requirement for generalization.",
            "strength_and_weaknesses": "**Strengths**\n- Method is well-described\n- Interesting problem\n\n**Weaknesses**\n- No motivation provided (explain why no bias is useful and provide an example where this actually led to something more useful)\n- Experimental setup at times unclear (how do you create the different tasks exactly?)\n- No improvements over state-of-the-art (explain how the proposed method could be interesting nevertheless)\n\nThe authors tackle the ambitious problem of creating a black-box meta-learning algorithm. However, they provide neither theoretical, empirical or anecdotal evidence that this might be of any use. Therefore, it appears that this is a challenging problem but might be of no relevance.\n\nI have problems interpreting the results since it is nowhere described what a random transformation is. Are these rotations, shifts, crops, everything together? Maybe the effects observed are related to the fact that given enough tasks, we just have seen every possible transformation? So maybe we keep seeing memorization where test tasks are simply very close to another train test. There is no discussion on how task similarity between train and test tasks changes with growing number of tasks and whether that might have an impact on the results.\n\nHow does the work relate to TabPFN: https://arxiv.org/pdf/2207.01848.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "The methodology is well-described but the work lacks a clear motivation. The problem setting is novel but not justified. Reproducibility is not guaranteed since key aspects of the experiments are not described, e.g., how the different tasks for each dataset are generated.",
            "summary_of_the_review": "The authors address a challenging research question without providing a motivation for solving it. There are some missing details which prohibit reproducibility and ability for the reader to interpret the results themselves. Finally, the method provides no empirical advantage over other methods as well.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_RW6w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_RW6w"
        ]
    },
    {
        "id": "LCCVXC9El1",
        "original": null,
        "number": 2,
        "cdate": 1666665463180,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665463180,
        "tmdate": 1666665463180,
        "tddate": null,
        "forum": "Y2ShteTrnX2",
        "replyto": "Y2ShteTrnX2",
        "invitation": "ICLR.cc/2023/Conference/Paper3648/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper performs an extensive empirical analysis of transformers used as general-purpose meta-learning algorithms in which transformers take a sequence of training data and a test points to output a prediction. The authors make a number of interesting findings including phase transitions when a transformer is able to generalize to unseen tasks and when a transformer is able to generalize to unseen instances within a task. The authors also demonstrate the importance of a large state to be able to learn a task. Finally, the authors propose a number of interventions to increase the ease of meta-optimization including increasing meta-batch sizes.",
            "strength_and_weaknesses": "**Strengths**\nThe paper's empirical analysis is extensive and comprehensive. The authors make a number of interesting observations that to my knowledge have not been made by prior literature. Moreover, the suggestions on interventions to improve meta-optimization are insightful and may be valuable to the community.\n\n**Weaknesses**\nOne weakness of the paper is that experiments are primarily conducted on simple datasets like MNIST. This work would be more significant if experiments could be conducted on more complex datasets.\n\nSince the paper's main focus is on explaining the properties of transformers as meta-learners, it would be helpful to have an expanded related work section explaining in more detail the previously known properties of transformers.\n\nFinally, the distinction between learning and generalization in the introduction of Section 3 is a little unclear to me. It would be helpful if the authors could provide examples of the 4 algorithms in the table here to make this more concrete.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Quality**\nThe empirical analysis in this paper is thorough. The experiments conducted by the authors are well justified, and all claims made by the authors are sufficiently backed up by experiments. As mentioned above, conducting experiments on more complex datasets would increase the significance of the paper.\n\n**Clarity**\nThe paper is generally well written and figures are well illustrated. As mentioned above, more sharply defining the distinction between learning and generalization early in the paper would be helpful.\n\n**Originality**\nTo my knowledge, the insights found by the authors in the paper are novel. However, it would be helpful if the authors could more explicitly separate their new contributions from prior knowledge in the literature; as mentioned above the authors may wish to expand their related works section.",
            "summary_of_the_review": "Overall, the paper makes a number of interesting observations on transformers used as meta-learning algorithms. To my knowledge, these insights are novel, and thus the paper could have a significant impact in the field in its current form. The paper's significance could be further improved by conducting experiments on more complex datasets.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_momp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_momp"
        ]
    },
    {
        "id": "VCBipWLnL-",
        "original": null,
        "number": 3,
        "cdate": 1666728111133,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666728111133,
        "tmdate": 1666728111133,
        "tddate": null,
        "forum": "Y2ShteTrnX2",
        "replyto": "Y2ShteTrnX2",
        "invitation": "ICLR.cc/2023/Conference/Paper3648/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work performs a detailed investigation into the training process and qualities of a black-box meta-learning algorithm in a 'general-purpose learning' framework.\nThe focus is on a setup where the data is a collection of 'tasks', that consist of a sequence of (input, label) pairs for which the learner needs to predict the current label, given the prefix of labeled pairs. Hence, a transformer was chosen as a model that can process the task sequentially.\nThe tasks are generated as randomly projected and label-permuted MNIST images, and the dynamics of the standard meta-training scheme are studied empirically, mainly by monitoring the accuracy signal over training (seen), testing (unseen) and other-domain (Fashion-MNIST) data. \nThe training is claimed to go through stages of 'memorization' (first of instances, then tasks) and finally 'generalization' or 'learning-to-learn' to unseen or cross-domain tasks.\nThe main emphasis is on the transition between memorization and generalization - when does it occur (if at all) and how it is influenced by the properties of training and structure of the network. Mainly, the data size (number of tasks) and model state-size (rather than parameter count). \nThe phase transition is also studied in terms of the loss function, which reaches a plateau before it occurs (or doesn't), and several improvements in training are suggested in order to promote the transition at an earlier stage.",
            "strength_and_weaknesses": "Strengths:\n* The paper presents a very interesting purely-empirical study of the learning dynamics in 'general purpose black box' meta-learning. \n* The experiments are well designed to demonstrate in a simple and clear way how learning progresses through the different stages, towards being able to learn-to-learn. Details are all super clear, very nicely presented and well explained, with nice insights about memorization and generalization.\n* The two findings that are most interesting, in my opinion: (i) How the existence of the phase shift (ability to generalize) is determined, very sharply, by the transformer model size and by the number of tasks. (ii) That the ability to learn is this setting is highly correlated to the state (rather than model) size.\n* I also find very interesting the in-depth look into what is happening during the (previously observed) training plateau, that is typical before moving to generalization. The 3 suggested 'interventions' in the process are well motivated and demonstrated.\n\nWeaknesses:\n* Although I find the observed phenomena and their explanations very interesting, I am concerned about how general they are, or whether they are very specific to the very limited setup that was chosen. This, in my view, limits the scope and impact of the findings, and I think there should have been more effort to relate to this point.\n* This is especially true, as the setup is different from the most standard one in (non-RL) meta-learning, which is few-shot learning. It is closely related, but focuses on the sequential version, rather than a support/query split.\n* In that regard too, the choice of producing tasks by random projections and orderings of MNIST, rather than the more common subsets of classes of a data-set with large variety of classes like imagenet should be justified. \n* Also, would these results and conclusions generalize to non-black-box settings? to the transductive one? \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned, the paper is very clear written, analysis and presentation are of great level of detail and all the information needed is provided for reproducibility.",
            "summary_of_the_review": "Overall, I am very positive about this paper. I think that it very nicely demonstrates interesting phenomena in meta-learning. The new insights are very interesting and might have an impact on related areas as well.\nMy main concern is about the generality of the findings, given the very specific setting used for the experiments, as I described above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_Ujps"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3648/Reviewer_Ujps"
        ]
    }
]