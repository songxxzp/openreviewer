[
    {
        "id": "g3vI8HxS0A",
        "original": null,
        "number": 1,
        "cdate": 1666477199769,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666477199769,
        "tmdate": 1666477199769,
        "tddate": null,
        "forum": "P44WPn1_aJV",
        "replyto": "P44WPn1_aJV",
        "invitation": "ICLR.cc/2023/Conference/Paper2300/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a language-guided framework for multi-dataset training. To solve the consistency of categories in each dataset, the paper encodes the categories in text embedding without manual reconciliation. Also, the paper adopts a dataset-aware augmentation strategy that assigns each dataset a specific image augmentation pipeline, which can suit the properties of images from different datasets.\nThe extensive experiments demonstrate that the proposed method achieves significant improvements on four semantic and three panoptic segmentation datasets.",
            "strength_and_weaknesses": "Pros:\n\n1, The paper is well-written and easy to understand.\n2, The proposed method is simple but efficient.\n3, The experiments are sufficient.\n\nCons:\n\n1, In the table2 of semantic segmentation, the proposed method seems to improve marginally if has a long training time. However, the table3 of panoptic segmentation improves largely.  Could the author have more analysis? is it related to the improvement of instance segmentation?\n\n2, I note that the proposed method is benefited from both CLIP image encoder and text encoder. Thus I wonder if the main reason for the improvement of the proposed method is the usage of the CLIP model, especially the CLIP Image encoder.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. And I think it could be reproduced easily.",
            "summary_of_the_review": "The proposed method gives new insight, using a text encoder to solve the inconsistency of the label system in the different datasets, in multi-dataset segmentation training. This is an interesting direction. In my view, the more experiments analysis should be added.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_wkpT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_wkpT"
        ]
    },
    {
        "id": "1mkUA0sp1rX",
        "original": null,
        "number": 2,
        "cdate": 1666565716402,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565716402,
        "tmdate": 1666566504444,
        "tddate": null,
        "forum": "P44WPn1_aJV",
        "replyto": "P44WPn1_aJV",
        "invitation": "ICLR.cc/2023/Conference/Paper2300/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents LMSeg, which aims to train a model for image segmentation on multi-datasets. The authors claim that they resolve two major challenges in this paper:\n- 1 the domain gap or inconsistency between semantic segmentation and panoptic segmentation.\n- 2 the separated label space.\n\nExperiments show that the proposed method can achieve better results than the previous baseline.",
            "strength_and_weaknesses": "### Strength\n\n1. The paper is well written and easy to follow.\n\n2. I recognize the significance of the problem targeted in this paper. It should be feasible to identify instances in images of datasets labelled for semantic segmentation.\n\n### Weaknesses\n\n**1. The novelty is limited.** The main claim of the authors is that they propose *text-query alignment to address the issue of taxonomy inconsistency*. However, introducing language embeddings to build a unified label space for image segmentation has already been proven to be effective [1, 2, 3]. The Category-guided decoding (CGD) here is just another variant of LSeg [1] that exploits the text-pixel affinity to bridge the domain gap across different label spaces. Dataset-aware augmentation (DAA) here is a non-learnable strategy for data augmentation, which seems to be better mentioned in the section of implementation details instead of methodology.\n\n**2. The improvement is not strong enough.** The numbers shown in Table 2 are not impressive from my point of view. For example, the gain for the average mIOU across four datasets can only be shrunk to a negligible 0.2% for 640K. I focus more on the results trained with a longer schedule since MaskFormer is hard to optimize and originally it needs 300 epochs to train on COCO panoptic. The results look to be prettier when trained under a short schedule, however, this might be due to a better initialization as the encoder of the proposed method is first pre-trained by CLIP (as discussed in Table 4).\n\n### Reference\n\n[1] Boyi Li, Kilian Q Weinberger, Serge Belongie, Vladlen Koltun, and Rene Ranftl. Language-driven semantic segmentation. ICLR 2022\n\n[2] Xu, Mengde, et al. \"A simple baseline for zero-shot semantic segmentation with pre-trained vision-language model.\" arXiv preprint arXiv:2112.14757 (2021).\n\n[3] Rao, Yongming, et al. \"Denseclip: Language-guided dense prediction with context-aware prompting.\" CVPR 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The illustration of this paper is clear and easy to understand. However, the originality of this paper is limited and the improvements are also not impressive to me. Although the authors attach their configs in the supplementary material, they do not promise to release the code in the paper so the reproducibility of this work cannot be guaranteed. ",
            "summary_of_the_review": "My concerns primarily lie in the novelty and efficacy of the proposed method. As discussed above, neither the story nor the performance of this paper impress me, I am thereby inclined to reject this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_DHCs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_DHCs"
        ]
    },
    {
        "id": "J56Iozn4Jp5",
        "original": null,
        "number": 3,
        "cdate": 1667237160577,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667237160577,
        "tmdate": 1670822202398,
        "tddate": null,
        "forum": "P44WPn1_aJV",
        "replyto": "P44WPn1_aJV",
        "invitation": "ICLR.cc/2023/Conference/Paper2300/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to solve two problems of multi-dataset segmentation: (1), inconsistent taxonomy. (2), inflexible of one-hot taxonomy. They map the taxonomy into embedding space with pre-trained pre-trained text encoder. Then they proposed a category-guided decoding module is designed to dynamically guide predictions to each dataset\u2019s taxonomy.\nExtensive experiments demonstrate that the proposed method achieves significant improvements on four semantic and three panoptic segmentation datasets\n",
            "strength_and_weaknesses": "Overall, this paper is good. \n\nStrength:\n\n\n1, The paper is well written and easy to follow. \n\n2, The idea of using unified text embedding to enhance the object queries is interesting and novel for DETR-like framework for multiple datasets segmentation tasks. Category-guided decoding (CGD) is simple yet effective. \n\n3, The extensive results show the effectiveness of proposed framework. \n\n\nWeakness:\n\n1, The idea of using text embedding for multi-dataset segmentation is not novel. The idea is proposed in the work \u201cThe devil is in the labels: Semantic segmentation from\u201d(half year ago on arxiv. ) This paper adds learnable embedding (From COOP-IJCV-2022) and extra attention module. The author should not claim this is very huge contribution in introduction part. \n\n2, Missing Experiment results M-Seg dataset. It would be better for benchmarking results on this dataset. \n\n3, Missing ablation studies on CGD design. \n\n4, Missing parameter and GFlops analysis on proposed CGD. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Good",
            "summary_of_the_review": "Overall, this paper is interesting to me. However, using text embedding for multi-dataset segmentation has been explored before.  Reminded by other reviewer opinions (Reviewer DHCs), I find the real technical novelty is very limited (Category-guided decoding (CGD) and Dataset-aware augmentation (DAA). I lower down my ratings.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_G1t4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_G1t4"
        ]
    },
    {
        "id": "5wo-9FIY8x",
        "original": null,
        "number": 4,
        "cdate": 1668166435587,
        "mdate": 1668166435587,
        "ddate": null,
        "tcdate": 1668166435587,
        "tmdate": 1668166435587,
        "tddate": null,
        "forum": "P44WPn1_aJV",
        "replyto": "P44WPn1_aJV",
        "invitation": "ICLR.cc/2023/Conference/Paper2300/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work extends a MaskFormer model to build LMSeg model, that learns to segment categories across multiple datasets using unified training without resorting to manual taxonomy. LMSeg is built on the fact that the text embeddings for semantically similar categories, as retrieved from CLIP text encoder, projects close to each other on euclidean space. Hence by learning to align the segment embeddings to the text embeddings, it is possible to learn to pool similar categories from multiple datasets without manual taxonomy mapping. Further, in order to dynamically guide the segment embeddings towards dataset-specific taxonomy, LMSeg proposes to use category-guided text-query cross-attention within the transformer decoder. This together with the dataset-aware augmentation strategy can train SoA multi-dataset model that outbeats single-dataset trained models (with similar total budget).",
            "strength_and_weaknesses": "Strengths:\n1. Multi-dataset training for segmentation using a unified taxonomy is the first step towards open-set model. LMSeg automates this training without any -- additional parameters in the form of dataset-specific head, manual mapping and drop in per-dataset mIoU. Similar to other open-set vision model, LMSeg leverages language embeddings to build a unified model.\n2. Moreover, the proposed LMSeg is simple, elegant and easy to implement straight out of MaskFormer model. \n\nWeaknesses:\n1. The model is well engineered. However, I feel there is limited novelty. Multiple recent work has resorted to text-query alignment to build an open-set model for different problem settings (object detection, referring expression). Motivated by this development, LMSeg modifies and trains Maskformer like framework with similar losses. To me, the only novel contribution seems category-guided decoder design. \n2. Secondly, Table 2 & 6 suggests that the impact of LMSeg, CGD & DAA framework on semantic segmentation setting is very minimal. Hence the novel components only contributes to improvements in panoptic segmentation. Any thoughts on what causes this discrepancy ? \n\nHow about evaluating LMSeg in an open-world setting ? Or atleast, cross-category evaluation (i.e., train model by leaving out test categories) or datasets relevant to training data (such as ADE-Full) ? These results should strengthen the empirical evaluation. As for now the multi-dataset evaluation has very limited use case.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written and easy to follow. With given experimental settings it should be simple to reproduce the listed evaluation. ",
            "summary_of_the_review": "LMSeg work makes a good read with clean experimental evaluation with few insights drawn during ablation. However, due to limited technical novelty I would place current version at Borderline acceptance. Adding extra evaluation and drawing better insights, would clearly add more value. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_6V2p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2300/Reviewer_6V2p"
        ]
    }
]