[
    {
        "id": "Hl8a6Qbi_Bx",
        "original": null,
        "number": 1,
        "cdate": 1666391354908,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666391354908,
        "tmdate": 1666391354908,
        "tddate": null,
        "forum": "tkwP32nsEq",
        "replyto": "tkwP32nsEq",
        "invitation": "ICLR.cc/2023/Conference/Paper2309/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied sparse linear bandits with noise variance appearing in the regret bound.",
            "strength_and_weaknesses": "It is interesting to study sparse linear bandits from variance-aware prospective. However, I feel the regime that variance-aware algorithm can improve for sparse linear bandits is not sufficiently interesting. For the current regret bound, it will be dimension-free only for the deterministic case (sigma=0) or nearly deterministic case (sigma=1/sqrt{d}). Sparse linear models or bandits are motivated by the use of high-dimensional features so d is typically very large. The requirement for sigma=1/sqrt{d} is very restricted and does not match any practical application. Thus, the novelty beyond variance-aware linear bandits is limited.\n \nSecond, I feel a variance-aware or problem-dependent lower bound is missing. I would like to see how this problem depends on noise-variance fundamentally. Existing minimax lower bound cannot explain this. \n",
            "clarity,_quality,_novelty_and_reproducibility": "good.",
            "summary_of_the_review": "Although a new prospective for sparse linear bandits is proposed, the improved regime is less interesting. A lower bound to fully characterize the problem is missing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_br26"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_br26"
        ]
    },
    {
        "id": "_xovabu8dc",
        "original": null,
        "number": 2,
        "cdate": 1667097843020,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667097843020,
        "tmdate": 1667097843020,
        "tddate": null,
        "forum": "tkwP32nsEq",
        "replyto": "tkwP32nsEq",
        "invitation": "ICLR.cc/2023/Conference/Paper2309/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper provides a black-box conversion from variance-aware linear bandit algorithm to its corresponding variance-aware sparse linear bandit algorithm. The regret framework is applied to two recent algorithms and obtain quite compelling regret bounds.",
            "strength_and_weaknesses": "\n   Pros:\n\n   (A) The generic formulation uses gap-dependent rounds split into commit and explore rounds to delicately balance exploration while minimizing the resulting regret. The resulting regret terms are almost tight except for a square root sparsity (s) factor which is typically small in practice.\n   (B) Quite a few state-of-the-art algorithms such as VOFUL2 and Weighted OFUL are considered in the framework and their regret are rigorously derived for both the\nframework and the corresponding algorithm components.\n\nCons:\n\n   (i) Experiments show-casing the proposed regret bounds on datasets would have made the paper much more compelling.\n   (ii) As noted in the paper, there is still a gap with respect to the lower bounds and the obtained bounds.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written with the key ideas and proof sketches shown in the main body of the paper . It proposes a novel black-box framework for plugging in linear bandit algorithms and obtain sparse ones. Also, it is self-contained with all the relevant results.",
            "summary_of_the_review": "Overall, a good theoretical paper for providing new algorithms for the variance-aware sparse linear bandits and would be of great interest to the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_babC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_babC"
        ]
    },
    {
        "id": "NnBPOAzRNM",
        "original": null,
        "number": 3,
        "cdate": 1667570338473,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667570338473,
        "tmdate": 1667587612263,
        "tddate": null,
        "forum": "tkwP32nsEq",
        "replyto": "tkwP32nsEq",
        "invitation": "ICLR.cc/2023/Conference/Paper2309/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes the first variance aware algorithms for sparse linear bandits, which interpolates between the $\\sqrt{dT}$ bound in worst case when variances are constant, and the bound independent of $d$ in the deterministic case where variances are 0.\nThe authors achieved this by an explore-then-commit framework that can be applied to existing variance-aware linear bandit algorithms, and showed that by plugging in VOFUL, it can match the regret lower bound for the worse case by a factor of $\\sqrt{s}$, and attain regret upper bound $O(s^3)$ in the deterministic case, i.e., removed the dependence on d and T.",
            "strength_and_weaknesses": "Strength\n\nThe idea of extending variance-aware algorithm to sparse linear bandit is well-motivated.\nThe proposed techniques to make explore-then-commit framework to work when the desired regret is unknown (as the regret for variance-aware algorithms depends on the variances, which are unknown) may are intuitive and technically interesting.\n\nWeakness\n\n1. The description in Section 3.1 can be further improved. Its current form is a bit hard to follow, e.g., maybe first define what is arm $i$ in the first paragraph on page 6.\n\n2. I would appreciate it if the authors can provide more explanations about the fundamental reasons for requiring action set to be unit sphere for all time steps, while Abbassi et. al. (2012) does not? It seems footnote 3 only provides an extreme case, where $\\Omega(d)$ is unavoidable, i.e., unit sphere is only a sufficient condition to help avoid this. Is it possible to further relax this action set assumption, and allow for drifting action set?\n\n3. The authors mentioned the data-poor regimes where $d>>T$ is beyond the scope of this paper. Can the authors elaborate on what are the possible difficulties in this case, and the reason why the proposed framework does not apply?\n\n4. The authors mentioned the $O(\\sqrt{s})$ gap to the regret lower bound can be improved if better variance aware linear bandit algorithm exists. Can the author provide more justification for this, e.g. why this is due to the sub-optimality of the adopted variance aware linear bandit algorithm, instead of the proposed explore-then-commit framework. And is it possible to derive a regret for the proposed framework (in variance aware sparse bandit), that depends on the regret of the adopted variance aware linear bandit, so that, it directly shows with an optimal variance aware linear bandit, the proposed framework is able to close the $O(\\sqrt{s})$ gap?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation and technical contribution is clearly stated, and most part of the paper is easy to follow.\nThe theoretical results look intutive and sound, though I didn't carefully check the proof.",
            "summary_of_the_review": "Variance aware algorithm for sparse linear bandit algorithm is well-motivated, and this paper provides the first solution via a explore-then-commit framework that converts existing variance aware algorithm to the sparse setting. However, there is still an $O(\\sqrt{s})$ gap to the regret lower bound in the worst case, and it is not very clear to me whether this gap can be closed under the current framework.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_MSEd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_MSEd"
        ]
    },
    {
        "id": "pTfbvrBHb3u",
        "original": null,
        "number": 4,
        "cdate": 1667609981002,
        "mdate": 1667609981002,
        "ddate": null,
        "tcdate": 1667609981002,
        "tmdate": 1667609981002,
        "tddate": null,
        "forum": "tkwP32nsEq",
        "replyto": "tkwP32nsEq",
        "invitation": "ICLR.cc/2023/Conference/Paper2309/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a variance-aware framework for stochastic sparse linear bandit problems.  The performance (as captured by regret bounds) bridges the general stochastic reward setting and the deterministic reward setting, which can be efficiently solved by a divide-and-conquer method.  The proposed framework employs variance-aware linear bandit methods (i.e. methods that did not assume or exploit sparsity of the coefficient vector), using repeated \u2018explore\u2019 steps and \u2018commit\u2019 steps with a adapting threshold.  The authors prove regret bounds using two example variance-aware linear bandit methods as sub-routines and achieve ambient dimension free bounds for the deterministic case.",
            "strength_and_weaknesses": "Strengths\n- The authors show that variance-aware methods for linear bandits can be adapted variance-aware methods in the sparse linear bandit setting.  \n- While the authors employ standard explore-then-commit style approach in identifying large coefficients for sparse linear bandits, for the variance aware setting the authors use loop over explore-then-commit steps adaptively changing the threshold.\n- The presentation and writing were mostly clear and easy to follow.\n\nWeaknesses\n- (minor) Some experiments (even for a few toy samples) could help clarify whether empirically (a) the variance-aware linear bandit methods perform poorly in sparse settings compared to the proposed framework\u2019s adaptation of those methods, (b) whether the dependence on $s$ in the bound is tight (i.e. would a new algorithm be needed or possibly just an alternative proof), and (c) if the empirical regret incurred by the proposed framework when actually applied to (nearly) deterministic settings is close to what could be achieved by a divide-and-conquer method designed specifically for the deterministic setting.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity - overall the writing was clear\n\nNovelty - while there has been work on variance-aware linear bandits and separately work on sparse linear bandits, this work appears novel in studying variance-aware methods for sparse linear bandits.\n\nReproducibility -- the authors include proof sketches in the main paper and appendices with technical details \n\n",
            "summary_of_the_review": "The problem is novel (though related to studied problems), the approach extends strategies (explore-then-commit for sparse linear bandits; variance-aware linear bandit methods) in a non-trivial manner.  The paper is well-written.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_DQpC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2309/Reviewer_DQpC"
        ]
    }
]