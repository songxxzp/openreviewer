[
    {
        "id": "N8DUp5EmGZy",
        "original": null,
        "number": 1,
        "cdate": 1666502816104,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666502816104,
        "tmdate": 1666502816104,
        "tddate": null,
        "forum": "IloMJ5rqfnt",
        "replyto": "IloMJ5rqfnt",
        "invitation": "ICLR.cc/2023/Conference/Paper1067/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors proposed an attention retractable Transformer (ART) for accurate image restoration, which consists of dense and sparse attention modules. The experiments are extensive and include several general image restoration tasks, where the proposed method achieves SOTA performance.",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is well-written and easy to follow. It is obvious that the authors pay much attention to most details.\n\n2. The idea about attention retractable Transformer (ART) is motivated by some observations from image restoration tasks and is more specifically designed. The authors provide illustrations of differences between the proposed method and others, like in Figure 1 and Table 1.\n\n3. They propose a sparse attention to compensate the defect of dense attention used in most Transformer-based image restoration methods. In the sparse area of an image, the token interactions help enlarge the receptive field of the module.\n\n4. Alternating sparse and dense self-attention blocks helps provide retractable attention. Then, the ART model can capture both local and global information simultaneously.\n\n5. The ablation study experiments well support the claimed contributions. The main results with promising performance show the superior and effectiveness of the proposed method.\n\n6. In the supplementary file, the authors not only provide more results (e.g., real image denoising), but also provide the source code, pretained models, and detailed readme information (e.g., scripts). Those supplements make the paper stronger and more solid.\n\nWeakness:\n\n1. For image denoising, the authors mainly provide color image denoising results in the main paper and real image denoising in supplementary file. It would be better to include real image denoising in the paper too.\n\n2. In the demo code, the authors mainly provide testing scripts. Will it be possible to give all the training details in the future? That would be good to the image restoration community.\n\n3. Some details are not very clear. For image denoising, did the authors use the framework and/or training strategy (e.g., progressive training) as used in Restormer?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is high-quality, clear, and novel. Furthermore, the authors provide source code and pretrained models, which make it be easily reproducible.",
            "summary_of_the_review": "A well-prepared paper with solid and extensive experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_f4x2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_f4x2"
        ]
    },
    {
        "id": "R3bXuRvsd0",
        "original": null,
        "number": 2,
        "cdate": 1666527575775,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666527575775,
        "tmdate": 1666527575775,
        "tddate": null,
        "forum": "IloMJ5rqfnt",
        "replyto": "IloMJ5rqfnt",
        "invitation": "ICLR.cc/2023/Conference/Paper1067/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper investigates an efficient Transformer based method for high-quality image restoration. Specifically, the proposed Attention Retractable Transformer (ART) incorporates sparse and dense attention to sense larger receptive field. The alternative manner of those two attention blocks help capture global and local information. The ablation study and main comparisons support the claimed components well with SOTA performance.",
            "strength_and_weaknesses": "Strengths\n\n1. The paper is well-written and easy to follow. The idea about attention retractable Transformer is simple yet effective. The combination of sparse and dense attention help sense global and local information for high-quality image restoration.\n\n2.The authors provide extensive experiments to show the effects of each proposed component and the whole method. They also discuss the differences between the proposed method and other related works, which highlight the novelty of the paper.\n\n3.Some experimental curves (e.g., Figs. 4, 8, and 9) provide good visualization during the training. Those curve comparisons make the method more convincing.\n\n4.The quantitative results are good. In Tabs. 2, 4, and 5, the proposed ART achieves the best PSNR/SSIM values in most cases. Such improvements over the previous methods are notable, especially for image SR. The authors also provide model size and flops comparisons, trying to keep fair comparisons with similar parameters and flops.\n\n5.The visual comparisons (e.g., Figs. 5 and 7) show impressive results of the proposed method, which obtains obviously better outputs than others. Such comparisons are also provided in the supplementary file.\n\n6.The supplementary file provides many useful experiments, like more ablation study results, analyses and performance comparisons with related work, real image denoising, and other quantitative and visual comparisons. All those supplements further demonstrate the effectiveness of the proposed method.\n\n7.The authors provide demo code on an anonymous website, where the pretrained models and testing scripts are provided to reproduce results in the main paper and supplementary file. The code availability makes the work more solid and convincing.\n\nWeaknesses\n\n1.Some details are not clear enough. For example, in Tab. 7 of the supplementary file, real image denoising part, did the authors use the same pretrained model to test on SIDD and DND data? Or use different pretrained models for each dataset? Also, did the authors still use the architecture shown in Fig. 2(a) for real image denoising? (As I know, Restormer uses a different structure.) There are some training strategies in Restormer, like progressive training. Did the authors also use such a strategy?\n\n2.It would be much better if the authors can provide some discussions or/and experiments of the method applied for other image restoration applications, like deraining and deblurring.\n\n3.It would be much better if the authors could provide more curve and/or visual comparisons. For example, how about the validation curves and visual results between the proposed method and others, like Restormer.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is organized well, stated clearly, and easy to follow. The work about attention retractable Transformer is novel and achieves promising results for several classic image restoration applications. The submitted code further makes it solid and reproducible.",
            "summary_of_the_review": "Overall, the paper is high-quality with a novel method (ART). The experiments are very extensive and support the contributions well. The submitted code and models make the method more solid.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_wRmT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_wRmT"
        ]
    },
    {
        "id": "Tjy2ot4GigR",
        "original": null,
        "number": 3,
        "cdate": 1666570008826,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666570008826,
        "tmdate": 1666570008826,
        "tddate": null,
        "forum": "IloMJ5rqfnt",
        "replyto": "IloMJ5rqfnt",
        "invitation": "ICLR.cc/2023/Conference/Paper1067/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose an Attention Retractable Transformer (ART), which incorporates sparse and dense attention to widen the receptive field size. The ART method achieves pretty good results in several image restoration tasks, like super-resolution, denoising, compression artifact reduction.",
            "strength_and_weaknesses": "The idea about using sparse and dense self-attention in Transformer is simple but effective. It is good to see such an investigation in image restoration and good performance for different tasks.\n\nAlso, the alternating application of sparse and dense attention blocks help capture the local and global information. The corresponding ablation study supports the claim well.\n\nThe main comparisons with recent methods for different tasks are extensive. The ART achieves quantitative gains and also show obviously better visual results in some challenging cases.\n\nThe supplementary file provides more experiments to show the effectiveness of the ART. They also submit the demo code and pretrained models, which make their work reproducible and more solid.\n\nThe paper is prepared pretty well and organized clearly. It is also easy to read and follow with the provided code.\n\nWeaknesses:\n\nThe proposed method is claimed for image restoration. The authors show experiments on several image restoration tasks, like image super-resolution, color, and real image denoising, and JPEG compression artifact reduction. How would be the method performed for other restoration tasks? Like image deblurring, deraining, dehazing, and so on. It would be good if the authors can provide some additional results for one/some of those tasks. Or at least, the authors can briefly discuss them in the conclusion part.\n\nIn image denoising, the main architecture of ART is different from that of Restormer. Also, Restormer uses a progressive training strategy, which is not used in this paper. Do the authors think that ART would further benefit from the U-Net structure and progressive training used in Restormer? If so, why not use a similar structure and progressive training? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly organized, like some illustration figures, difference summary table. The motivation and method details are also clear. The method is novel and reproducible with the submitted code, models, and scripts.",
            "summary_of_the_review": "The authors propose a new Transformer-based image restoration method with several new components, which are demonstrated by the extensive ablation study and main experiments. Furthermore, the paper is well prepared and reproducible based on the submitted code and models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_eLG6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_eLG6"
        ]
    },
    {
        "id": "p0NEbYL25t",
        "original": null,
        "number": 4,
        "cdate": 1666609644607,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666609644607,
        "tmdate": 1666609701461,
        "tddate": null,
        "forum": "IloMJ5rqfnt",
        "replyto": "IloMJ5rqfnt",
        "invitation": "ICLR.cc/2023/Conference/Paper1067/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes Attention Retractable Transformer (ART) for image restoration, which integrates both dense and sparse attention modules in the transformer-based network. The dense attention block and sparse attention blocks emerge alternately to enable interactions among tokens extracted from a sparse area during restoration. The paper claims that the proposed ART enhances representation ability of Transformer while providing retractable attention on the input image. Extensive experiments are conducted on image super-resolution, denoising, and JPEG compression artifact reduction tasks.",
            "strength_and_weaknesses": "Strength:\n+  This paper introduces sparse attention mechanism to low-level vision task and enable tokens from sparse areas of the image to interact with each other to enlarge the receptive field of transformer.\n+ The paper is well organized and clearly presented. In the paper, the differences and relations with other related works are discussed and analyzed.\n\nWeakness:\n- The improvement in performance is limited. In the SR results. The ART-s has similar parameter size and FLOPS as SwinIR.  The gain obtained by ART-s is insignificant in terms of PSNR and SSIM on dataset Set5, Set14, and B100. ART and ART+ outperforms the SwarIR by 0.1dB, but they are equipped with more parameters. For the image denosing task, the gap between the SwinIR and restormer is not remarkable. \n- The proposed scheme introduces the features from dilated position to enable distant feature access, which benefits restoration of the images with repeated pattern, such as buildings in Urban100.  Table 2 and figure 4, the Urban100 are chosen to be compared with peer works.  The paper should provide more comprehensive result comparison to verify the advantage of ART.\n- The description of the method could be further refined. E.g. The symbol \u201cI\u201d represents original input and intervals in the proposed method. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and clearly presented. The non-local attention modules have been proposed and used in several works. This paper leverage sparse attention in the low-level vision task. Therefore, the novelty of paper is not significant. ",
            "summary_of_the_review": "The paper proposed sparse attention module and design interlaced attention blocks to leverage near and distant feature attention. The designed ART could achieve remarkable improvements on the images with repeat patterns, but it cannot prove its advantages on other general datasets.  The non-local attention modules have been proposed by other recognition works.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_dTRi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1067/Reviewer_dTRi"
        ]
    }
]