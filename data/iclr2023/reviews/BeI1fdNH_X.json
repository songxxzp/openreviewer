[
    {
        "id": "oOvD6gsHn-B",
        "original": null,
        "number": 1,
        "cdate": 1666173078746,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666173078746,
        "tmdate": 1666173078746,
        "tddate": null,
        "forum": "BeI1fdNH_X",
        "replyto": "BeI1fdNH_X",
        "invitation": "ICLR.cc/2023/Conference/Paper2276/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "With the increasing use of machine learning models, it becomes important to understand their decisions before using them in high-stakes real-world applications. Despite the effectiveness of feature-attribution methods in explaining model decisions, the non-linearity of ML models hampers the reliability of the explanations. In this work, the authors hypothesize that the reliability of feature attribution scores can be improved by attributing scores to groups instead of individual features. In particular, they present a novel perspective of group attribution, propose an optimization problem, and integrate it with Shapley value attribution to propose G-SHAP. Qualitative and quantitative empirical results on image classification tasks show that model predictions can be better understood with groups than with individual components.",
            "strength_and_weaknesses": "**Strengths**\n\n1. A new perspective to attributing the importance of input features using *reliability loss* that indicates the discrepancy between predicted and actual contributions and *group attribution* that attributes scores to a group of explanations instead of the individuals.\n\n2. The proposed G-SHAP outperforms vanilla SHAP feature attribution methods and other baseline attribution methods across three real-world datasets.\n\n**Weaknesses and Open Questions**\n\n1. The paper argues about the usability of the explanations in Section 1 but does not discuss it further in the empirical analysis. Further, is usability directly related to the empirical performance of an explanation?\n2. The definitions of reliability loss and group attribution are agnostic to the choice of explanation method, but the paper limits its application to just Shapeley values.\n3. What is the intuitive interpretation of a group? What does it represent? Is it just a simple grouping of individual attributions, or does it aim to group components with similar attributions?\n4. The paper does not compare the results with state-of-the-art feature attribution methods like GradCAM, Integrated Gradients, LIME, etc.\n5. One main takeaway of the paper is that a model prediction is better understood with groups than individual components. The authors motivate the problem using the non-linearity of the model. In addition, grouping multiple features should intuitively lead to better performance as they may break the correlation of dependent features. It would be great if the authors could comment on this.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe writing of the paper can be improved. In particular, the introduction section and the formulation of reliability and group attribution are confusing and need more clarity. \n\n**Novelty**\n\nThe paper introduces formulations for reliability loss and group attributions.\n\n**Reproducibility**\n\nThe code for G-SHAP is shared in an anonymous repo for reproducibility.",
            "summary_of_the_review": "The paper presents a new perspective to attribute group features but lacks clarity and empirical evidence using state-of-the-art methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_ssJm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_ssJm"
        ]
    },
    {
        "id": "kHuueiseEM",
        "original": null,
        "number": 2,
        "cdate": 1666194269540,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666194269540,
        "tmdate": 1666194428083,
        "tddate": null,
        "forum": "BeI1fdNH_X",
        "replyto": "BeI1fdNH_X",
        "invitation": "ICLR.cc/2023/Conference/Paper2276/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a generalizable optimization strategy that codifies a way to trade-off between group attribution and component-wise attributions calculated from explanation methods. The end product is a group attribution version of a given explainer (they propose G-SHAP as an example for groupwise SHAP) that balances the reliability loss from a group attribution compared to component attribution. They also provide formalization for reliability loss (both component-wise and group-wise) with the total loss defined as the geometric mean of the two. ",
            "strength_and_weaknesses": "Strengths:\n- The paper provides and motivates an important problem. i.e. group attributions are important to capture \"groupings\"/non-linear interactions of features as they contribute to a prediction, something that component-wise attribution methods lack. On the other hand, just providing group attributions can result in in obfuscating contributions of individual components. Hence the trade-off that forms the basis of this paper.\n\nWeaknesses:\n1. The paper is extremely hard to read. Is littered with typos, unfinished sentences and overloaded notation. On average, there's a typo in every other sentence, too many for me to list here. The experiment section specially has too many typos to even count. I strongly advise the authors to read through there paper multiple times and improve its readability and remove typos. Even if the paper has an extraordinary contribution it becomes really hard to feel excited about it if it looks like it has been put together last minute.\n\nsome examples:\n-- right above eq (2) \"and an given scores\" (remove \"an\")\n-- above eq (7) \"an score estimation\" (\"an\" --> \"a\" is redundant)\n-- above eq (11) \"with their Once we have the\" (sentence doesn't make sense)\n-- section 3 1st line \"to each player involved in.\" (unfinished sentence)\n\n2. There are decisions being made here that are not clearly motivated, there's an overall lack of theoretical justification for decisions, though heuristic justifications can be made. For example:\n- under eq(3) the logic behind the conclusion that $a = \\xi$ is the global minimum of eq(3) doesn't make sense. Was this intended to be $a = \\phi$? . Why were equations (2) and (3) formulated the way they are formulated? It'd help if the line of thinking behind these equations is clearly articulated before the equations are presented.\n- Before equation (10), a seemingly arbitrary decision is made about the upperbound for CR when, as the authors say it doesn't have one. What's the reason behind choosing this particular upperbound?\n- below equation (8), \\psi can be arbitrarily defined, how arbitrary? does a \\psi that simply spits out random numbers work? e.g. it's unclear what the equivalent \\psi is in the G-SHAP formulation.\n\n3. The experiment section, in addition to be seemingly very rushed, also seems undercooked in terms of comparisons. There are no comparisons with other group-wise feature selection approaches (e.g. see \"instance-wise feature grouping\" by Masoomi et al. NeurIPS 2020 and the methods they compare against) and even the results compared to baselines don't show much improvement.",
            "clarity,_quality,_novelty_and_reproducibility": "- Originality: The work definitely seems original to the best of my knowledge.\n- Quality and Clarity are significant areas of improvement for this work.\n- Reproducibility: The authors provide code which seems considerably detailed, with notes and notebooks. I haven't had the chance to run the code myself.",
            "summary_of_the_review": "This is a promising line of work overall. But in my opinion is not quite ready for publication. The authors should consider taking their time and improving the motivation, writing and experiments provided in the paper. The paper in its current form will be a disservice to their own work if it gets published as it is.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_FuXt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_FuXt"
        ]
    },
    {
        "id": "04BJxKR3Cvv",
        "original": null,
        "number": 3,
        "cdate": 1666693015497,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693015497,
        "tmdate": 1666693015497,
        "tddate": null,
        "forum": "BeI1fdNH_X",
        "replyto": "BeI1fdNH_X",
        "invitation": "ICLR.cc/2023/Conference/Paper2276/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a new explanation algorithm called G-SHAP that computes attributions of feature subsets and attributions of individual features within each subset. The motivation to do so is to overcome the problem of interactions between features, thereby grouping features that interact together into the same group. ",
            "strength_and_weaknesses": "+ves: \n\n- A really good idea to automate the computation of group attributions of feature subsets that interact. Also using the G-SHAP heuristic to determine the optimal subset combination is novel. \n\n-ves: \n\n- Empirical results are shown for images alone, it would be good to show these on tabular / text datasets too. \n- The disentangling of group to individual features is less clear from the text and experiments in the sense as to how these differ from actual shapley values of all individual features and how the repeat problem of assigning individual attribution values within each subset does not occur. \n- Its unclear if the shapley axioms hold at group level based on the computed group attributions. \n- It might be good to build experiments where feature interactions/dependence are known a priori and evaluate if the computed subsets match ground truth. ",
            "clarity,_quality,_novelty_and_reproducibility": "Novel. However parts of the submission are less clear due to significant amount of mathematical notation. ",
            "summary_of_the_review": "See above. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_boPc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_boPc"
        ]
    },
    {
        "id": "vdlQein142A",
        "original": null,
        "number": 4,
        "cdate": 1666743180055,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666743180055,
        "tmdate": 1666743180055,
        "tddate": null,
        "forum": "BeI1fdNH_X",
        "replyto": "BeI1fdNH_X",
        "invitation": "ICLR.cc/2023/Conference/Paper2276/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The manuscript proposes to consider a reliability loss term to consider the differences between component-level explanations, group-level explanations and the actual explanations. \n\nBased on this idea, an optimization approach ( G-SHAP) tailored for Shapley values is proposed. \n\nExperiment on the image classification task on 4 datasets show the effectiveness of the proposed method",
            "strength_and_weaknesses": "Strengths\n- The proposed ideas seem novel to me\n- Varied set of datasets\n- Code to be released\n- An ablation study is present.\n\nWeaknesses\n- High computational costs\n- Focus on a single task\n- Evaluation is not complete.",
            "clarity,_quality,_novelty_and_reproducibility": "\nClarity\nThe presentation of the manuscript is relatively clear and its content has a good flow.\n\nQuality\nThe proposed method is sound and well motivated.\nThe evaluation could be improved.\n\n\nNovelty\nThe proposed combination and reliability terms is, to the best of my knowledge, novel.\n\nReproducibility\nThere seem to be plans to release the code used for the experiments reported in the manuscript. This is a good step towards enabling reproducibility. ",
            "summary_of_the_review": "\nThe proposed combination and reliability terms is sound and well motivated. To the best of my knowledge this is novel.\nThe manuscript has a good balance of verbal and formal descriptions. \nThe evaluation covers a good amount of different datasets which could help paint a wider picture of the capabilities of the proposed method.\n\nMy main concerns with the manuscript are the following:\n\nAs admitted in the paper, the proposed method seems to be computationally expensive, reason for which it might not scale to dense inputs, e.g. pixel-level attribution.\n\nIn Sec. 2.3, it is stated \"it is required not to utilize any information of given prediction, or the estimated score would contain unexpected information of the actual component-wise contribution\" \nCould you further elaborate on this statement?\n\nRegarding the grouping policies, is there a principled manner to select the grouping policy? \n\nCurrently the proposed method is only tested on the image classification task. It would strengthen the manuscript if pointers on how the proposed method could be applied to other tasks were provided.\n\nIndependently of its inner-workings, at the end of the day the proposed method is an explanation method. In this regard, it would have strengthen the manuscript if the proposed method was tested under the sanity checks proposed by [Adebayo et al., NeurIPS'18]. This way there could be guarantees on whether the generated heatmaps/attribution maps do constitute valid explanations.\n\nVery related to the previous point, the manuscript effectively show how integrating reliability and group attribution helps getting better attribution maps. However, it is hard to assess at this points where the proposed method is positioned, w.r.t. to the large pool of existing explanation methods.\nHere I wonder if applying the suggested optimization to a state of the art explanation method would further improve its performance, or whether is this just the case for Shapley-based methods..",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_BDjb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2276/Reviewer_BDjb"
        ]
    }
]