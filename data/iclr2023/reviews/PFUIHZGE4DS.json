[
    {
        "id": "ToMjmfarNCZ",
        "original": null,
        "number": 1,
        "cdate": 1666565935402,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565935402,
        "tmdate": 1666565935402,
        "tddate": null,
        "forum": "PFUIHZGE4DS",
        "replyto": "PFUIHZGE4DS",
        "invitation": "ICLR.cc/2023/Conference/Paper1800/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes to use meta-data for message classification. Specifically, the authors extract meta-data from popular benchmarks, and add them to the models used in training. The results show improvement, but the reader is not sure of the metrics used. The method resembles multi-modal models that already exist, and does not compare to existing methods (e.g. other papers).",
            "strength_and_weaknesses": "Strengths:\n- Good problem to tackle and many datasets.\n\nWeaknesses:\n- There is no need to reserve a subsection (3.2) or a paragraph in Related Work (Accessibility of Transformers) to explain the use of pre-trained models, as this is of widespread use. Please reserve the technical details for a \"Training Details\" section under Experiments, and remove them from everywhere else for easier reading.\n- There should be a discussion of the results: are we using macro-F1 score or accuracy? Some of the results are very close together, and there should be an analysis to show why. For example, which meta-data features are important and which ones are not?\n- There is no comparison with prior work, but rather a table of results with small technical changes.\n\nAdditional notes:\n- Please fix the typos, as there are many repeated words and spelling mistakes\n- Please fix the citations -- most of them should be in parentheses (those that are included as part of the discourse should not)",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not clear, and the work does not rely on what has been done before on these popular benchmark datasets. Many details lack for reproducibility (hyperparameters specifically). The work is not novel enough.",
            "summary_of_the_review": "The paper proposes a simple multi-modal method to add meta-data information to message classification. The authors do not compare to existing data, and there is no analysis or discussion of the results. The method is not novel, and the paper overall could use some proofreading.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_rydk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_rydk"
        ]
    },
    {
        "id": "oADF3YYqUwR",
        "original": null,
        "number": 2,
        "cdate": 1666569951685,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666569951685,
        "tmdate": 1666569951685,
        "tddate": null,
        "forum": "PFUIHZGE4DS",
        "replyto": "PFUIHZGE4DS",
        "invitation": "ICLR.cc/2023/Conference/Paper1800/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new approach to message classification. Specifically:\n\n* It is based on SOTA NLP building blocks.\n* It has a novel technique to infuse metadata.\n\nThis paper shows that:\n\n* Adding metadata increase the performance of their model.\n* Their ulti-modality building block outperforms other methods. ",
            "strength_and_weaknesses": "Strengths:\n\n* This paper leverages additional information from the metadata to boost their model performance.\n* Their multi-modality building block outperforms other methods.\n\nWeaknesses:\n\n* Leveraging metadata and ensembling BERTs have been used for both research prototyping and industry best practices. I am not sure where the novelty is.\n* Using additional information from the metadata can introduce biases. I don't see any effort from the authors to debias their model and data.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is relatively clear but lacks novelty. Based on Sec. 3 and Sec. 4, it will be difficult to reproduce their results.",
            "summary_of_the_review": "This paper is clear but lacks novelty. I am leaning towards rejecting it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns",
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_7oAd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_7oAd"
        ]
    },
    {
        "id": "G5_Y4lC5f4",
        "original": null,
        "number": 3,
        "cdate": 1666589049245,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666589049245,
        "tmdate": 1666589049245,
        "tddate": null,
        "forum": "PFUIHZGE4DS",
        "replyto": "PFUIHZGE4DS",
        "invitation": "ICLR.cc/2023/Conference/Paper1800/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper introduces a mechanism to combine text and metadata in messages. The authors propose using a \"block\" (a custom architecture or pipeline) for each metadata field which is supposedly superior to placing metadata as [SEP] separated sentences or a single pipeline for the whole metadata.",
            "strength_and_weaknesses": "In my opinion, this paper is not at level of an ICLR paper. The ideas are fairly straightforward and probably among the first things attempted by ML practitioners at any single task. I do not think there are any significant technical ideas one can take from this paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is fairly straightforward and not novel.",
            "summary_of_the_review": "- Paper presents a very trivial architecture as an \"improvement\" over various BERT based pipelines. The architecture is really not that sophisticated and seems like a straightforward thing any practitioner would try. No real technical insights.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_uH2i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_uH2i"
        ]
    },
    {
        "id": "XBhs2BPTsc",
        "original": null,
        "number": 4,
        "cdate": 1666627226119,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627226119,
        "tmdate": 1666627226119,
        "tddate": null,
        "forum": "PFUIHZGE4DS",
        "replyto": "PFUIHZGE4DS",
        "invitation": "ICLR.cc/2023/Conference/Paper1800/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a framework for message classification, built with standard transformer (or more precisely, BERT, as used in all experiments) along with meta-data as augmented input. Experiments were conducted on standard text datasets with meta-data of sender and timing information.",
            "strength_and_weaknesses": "Strength:\n- The use of metadata makes sense in some scenarios\n\nWeaknesses:\n- The motivation does not seem to be clear on the specific benchmarks: why would the time or sender information useful for classifying product categories or topic or other categorical labels?\n- Readers might not learn much information from this submission since the presented framework is rather standard while one can draw very few conclusions from the current experiments\n- No comparison with task-specific baselines: the specific datasets have all been used in previous studies while there are no comparisons on previous results, making the last sentence of the conclusion section poorly justified.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This submission in its current form might need a bit of technical guidance in terms of content organization and experimental design.\nFor now readers can only see an architecture being presented and empirical results were shown from small variants (e.g., the choice of final head to be a random forest or standard MLP) of the presented framework.\n\nThe presented framework is standard BERT with augmented input, which does not seem to be technically novel.",
            "summary_of_the_review": "Not too much technical novelty to be presented at a top ML/NLP conference",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_FKbD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1800/Reviewer_FKbD"
        ]
    }
]