[
    {
        "id": "Bkw7rN3CYw",
        "original": null,
        "number": 1,
        "cdate": 1666673028288,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673028288,
        "tmdate": 1666673028288,
        "tddate": null,
        "forum": "3oWo92cQyxL",
        "replyto": "3oWo92cQyxL",
        "invitation": "ICLR.cc/2023/Conference/Paper4675/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to combine meta learning with few-shot adaptation of language models, by essentially building upon methods such as Frozen (Tsimpoukelli et al., 2021) which maps image representations into language model token space, but adding a meta-mapper network, acting as a meta-learner, to more efficiently perform this mapping. The proposed approach can rapidly adapt to newly presented samples with only a few gradient updates, and shows strong results on recently proposed multimodal few-shot benchmarks.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well motivated and described. The ideas are clear and experiments are on several large multimodal datasets.\n2. The paper is very clear with clear figures and exposition.\n3. Experiments are comprehensive and results are strong.\n\nWeaknesses:\n1. The novelty of the paper is limited, since it seems to be a combination of Frozen (Tsimpoukelli et al., 2021) and standard meta-learning approaches to learn the mapping from image representations into language model token space.\n2. There should be more comparisons in both performance and complexity - the proposed method does better but certainly uses more computation so the tradeoff should be analyzed.",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is very clear and nicely written - was a joy to read, but the originality is lacking.",
            "summary_of_the_review": "The novelty of the paper is limited, since it seems to be a combination of Frozen (Tsimpoukelli et al., 2021) and standard meta-learning approaches to learn the mapping from image representations into language model token space.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_zhwM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_zhwM"
        ]
    },
    {
        "id": "_5yfpoP27E",
        "original": null,
        "number": 2,
        "cdate": 1666767273716,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666767273716,
        "tmdate": 1666767273716,
        "tddate": null,
        "forum": "3oWo92cQyxL",
        "replyto": "3oWo92cQyxL",
        "invitation": "ICLR.cc/2023/Conference/Paper4675/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper propose a meta mapper network to tackle the task of multi-modal few-shot learning. Particularly, the proposed meta mapper contextualizes the soft visual prompts with the features of a pre-trained/frozen visual encoder and language models, for adapting the language model to output for the target task. During the inference, only the meta-mapper is fine-tuned via gradient based optimization, to adapt the model for the target multi-modal learning tasks. To train this meta-mapper, MAML-style of meta learning routine is employed for training. With this key idea, this paper achieves strong results on Real-Name mini-ImageNet and Open-Ended mini-ImageNet.",
            "strength_and_weaknesses": "Strength:\n\n+ The main idea of combining soft-prompt tuning and MAML is very straightforward, and novel to some extent.\n+ The empirical results are strong, and show that the proposed method outperforms the previous state-of-the-art in multimodal few-shot learning.\n+ The ablation studies are quite comprehensive, and most of my questions about the methods was addressed. \n\nWeakness:\n- I don't see very obvious weakness of the methods. \n\nQuestions:\n\nOne question I have is about the variance of the model's performance, with respect to the few-shot support examples. Figure 3 has shown same hints but it could be interesting to more variance analysis on realistic VQA data. ",
            "clarity,_quality,_novelty_and_reproducibility": "The overall writing quality is pretty clear, methods are well-motivated. \n\nThe overall quality of the paper is good, solid and comprehensive experiments, and the novelty is okay. \n\nI believe the methods are reproducible. ",
            "summary_of_the_review": "Overall I think this paper is making a solid contribution to the multi-model few-shot learning. The proposed method is interesting enough and effective. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_idxn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_idxn"
        ]
    },
    {
        "id": "EL2G6WfQ64s",
        "original": null,
        "number": 3,
        "cdate": 1667157037979,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667157037979,
        "tmdate": 1667157037979,
        "tddate": null,
        "forum": "3oWo92cQyxL",
        "replyto": "3oWo92cQyxL",
        "invitation": "ICLR.cc/2023/Conference/Paper4675/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a new approach to few-shot multimodal learning using a meta-learning approach that relies on generating visual prefixes that leverage prior training with other tasks. The visual prefix is produced by the proposed meta-mapper that meta-learns from previous tasks. The prefix approach enables seamless bridging of the textual and visual modalities. The proposed approach is computationally lightweight since it uses frozen backbone visual and text encoders (i.e. does not require retraining those), and clearly advances over the state of the art in its results. The paper also presents several insightful ablation results that establish the significance of the proposed approach to meta-learning.",
            "strength_and_weaknesses": "Strengths:\n1. Thorough and insightful literature survey that provides a sound motivation for the proposed approach.\n2. Clear explanation of both the proposed approach and the experimental results.\n3. Sound technical approach that is computationally lightweight and applicable to multiple multimodal tasks.\n4. Experimental results show clear advance over the state of the art.\n5. Insightful ablation results show the advantage of the proposed approach.\n\nWeaknesses\n1. No significant weaknesses. A suggestion - have you thought of how you would bridge three modalities? That is not required for this paper but I would be curious to know your thoughts. For example, how would you bridge visual, text and audio modalities? My guess is that your approach will scale up easily to accomodate more modalities but do think about it.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\nThe paper is well written. It builds the approach logically based on a thorough literature survey and presents the proposed approach abd results clearly and concisely.\nQuality and originality\n\nThe authors claim to be the first to apply meta-learning to multimodal few shot learning. That is a justified claim and the authors follow it up with good experimental results in both accuracy and ablation. I would therefore rate the quality and originality of this work highly. ",
            "summary_of_the_review": "Well written paper. Clear advancement of the state of the art with both the approach and experimental results. Insightful results from ablation. Good paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "Yes, Other reasons (please specify below)"
            ],
            "details_of_ethics_concerns": "It is unfortunate that the authors have neglected to address the ethical implications of their work directly. I am inclined to give them the benefit of the doubt given the quality of their work. They need to consider the following points:\n1. It is well known that the large models that they are using as their backbones have various biases built into them. Therefore some caution is called for.\n2. While keeping point 1 above in mind, it is also true that the proposed meta-learning approach bridges two modalities and in some qualitative results goes beyond the ground truth (The example with the electric guitar player comes to mind). My speculation is that the proposed meta-learning approach is ending up exploiting the complementarities of the two backbone models. That would imply that it will also help mitigate biases that are present in only one of the backbone models. \n3. My suggestion to the authors would be to have a paragraph that directly addresses ethical concerns with the points 1 and 2 above in mind and any other points that they have.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_c2Z3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_c2Z3"
        ]
    },
    {
        "id": "AgeVNcUWskN",
        "original": null,
        "number": 4,
        "cdate": 1667163901939,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667163901939,
        "tmdate": 1667163901939,
        "tddate": null,
        "forum": "3oWo92cQyxL",
        "replyto": "3oWo92cQyxL",
        "invitation": "ICLR.cc/2023/Conference/Paper4675/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed to use meta learning for multimodal few-shot learning. Unlike previous methods that may train fully or partially the vision or language models, this paper freezes both vision and language models while only training the learnable parameters for the meta-mapper. Thanks to the frozen backbones, the meta-learning process is fast and able to make use of the pre-trained knowledge. The experimental results show that the proposed method outperformed the existing Frozen multimodal learning baseline. \n",
            "strength_and_weaknesses": "Strength: \n* The idea itself is very simple and easy to understand, for an impactful research direction. Making use of already pre-trained vision/language models could help save computational cost.\n* This paper is very well written and is very easy to understand. The illustrations of the idea are very clear. \n* Good qualitative results and ablation tests.\n\nWeaknesses:\n* It is appreciated to mark both \"episodic\" and \"cross-domain\" in Table 1 and Table 2. It is clear that the proposed \"episodic\" training helps on the quality significantly on target tasks. However, \"cross-domain\" leads to unfair comparisons, where the Frozen baseline only reported results with \"cross-domain\" setup while this paper highlights results with non \"cross-domain\" (\"in-domain\") setups. I am concerned by this point and if we look at \"episodic\" and \"cross-domain\" row in Table 2, this paper falls behind Frozen overall. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is very well written and is very easy to understand. The frozen backbone idea itself has been explored by a few existing methods, e.g. freezing the language backbone (Frozen). Adopting meta-learning to bridge both vision and language backbone is original, and it also works nicely on the benchmarks. This paper has not attached/released the code, which makes it non-trivial to be reproduced.\n",
            "summary_of_the_review": "This paper proposed a simple idea to bridge pre-trained vision and language backbones via meta-learning. The training is parameter efficient and fast thanks to frozen backbones. Concerns regarding the \"cross-domain\" comparisons lead to borderline rating. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_VtRH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4675/Reviewer_VtRH"
        ]
    }
]