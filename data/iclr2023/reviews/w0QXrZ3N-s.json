[
    {
        "id": "_56CcmOUhx",
        "original": null,
        "number": 1,
        "cdate": 1665833268083,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665833268083,
        "tmdate": 1668657438872,
        "tddate": null,
        "forum": "w0QXrZ3N-s",
        "replyto": "w0QXrZ3N-s",
        "invitation": "ICLR.cc/2023/Conference/Paper2113/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper gives some new insight into the multi-modal knowledge distillation community. Specifically, teacher accuracy does not necessarily indicate student performance, while modality-general features are the key in crossmodal KD. With the explanation of the modality Venn diagram, such a claim is straightforward and easy to understand. The authors also do some controlled experiments and try to support their analysis.\n",
            "strength_and_weaknesses": "Pros:\n1. The proposed Modality Focusing Hypothesis is significant and might raise some interest in controllable cross-model distillation. Rich experiments verify this claim.\n2. The organization of the paper is good in general.\n\nCons:\n1. Although I admit and like the Modality Focusing Hypothesis, this hypothesis conflicts with the general multi-view assumption, i.e., each view could bring extra useful downstream information [1]. Different views always have some specific information and we always find that learning a multi-modal model is better than every single modality (CLIP), at least in most datasets. Why this phenomenon is different in knowledge distillation? One might argue that view-specific information contains much redundancy [1]. I'd like to see some explanations about this point.\n2. It is not clear to me that how to control the $\\gamma$, e.g., how to calculate $\\gamma$ in Table 2? What's the rule? Also, how to quantize this parameter during other experiments? \n3. For MM-IMDB data, why there is more modality-specific information?\n4. The modality Venn diagram is not new enough, as there are plenty of works that use this to analyze the effectiveness of multi-modal learning [1-3]. Specifically, [2] also claims that modality-general information is essential. The author is encouraged to change their claim that treats this as a contribution and do a better job by clarifying the differences between these relevant works and the proposed method.\n\n[1] Self-supervised Learning from a Multi-view Perspective, ICLR'21\n\n[2] Dual Contrastive Prediction for Incomplete Multi-View Representation Learning, TPAMI'22\n\n[3] COMPLETER: Incomplete Multi-view Clustering via Contrastive Prediction, CVPR'21",
            "clarity,_quality,_novelty_and_reproducibility": "Good quality and clarity.",
            "summary_of_the_review": "I recommend accepting the paper (rating 6). I liked the hypothesis proposed by the authors. Although this paper has some drawbacks, the contribution is enough. Ratings can be improved further if the authors could solve my questions.\n\n----------- UPDATE I ----------- \n\nI thank the authors for their response to my concerns, especially about the **modality Venn diagram** and more experimental details. After reading the response, I consistently consider the proposed hypothesis is well-motivated. \n\nI hope the authors could highlight the details about the $\\alpha,\\beta,$ and $\\gamma$ in each experiment (e.g., bold, color) for better illustration.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_i93D"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_i93D"
        ]
    },
    {
        "id": "CE5GV_KgCp",
        "original": null,
        "number": 2,
        "cdate": 1666867214025,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666867214025,
        "tmdate": 1670638411914,
        "tddate": null,
        "forum": "w0QXrZ3N-s",
        "replyto": "w0QXrZ3N-s",
        "invitation": "ICLR.cc/2023/Conference/Paper2113/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, authors investigated the key factors that could improve the performance of student model from a teacher model in a cross-modal knowledge distillation set. Based on authors investigation authors proposed a hypothesis that high performance of a teacher model does not always bring high performance student model, and the performance of the student model is determined by the modality-general decisive features. Based on the hypothesis, authors defined index of the modality-general decisive feature, and provided theoretical analysis and experimental evidence to prove their hypothesis.",
            "strength_and_weaknesses": "The main strength: authors proposed the concept of modality-general decisive features for cross modal knowledge distillation, and proposed a hypothesis that the key factor for improving the student model performance is that the teacher model is trained based on the modality-general decisive features. Authors provided theoretical and experimental analysis to support their hypothesis. This hypothesis could provide new insight for the reason of when a student model could perform well in cross-modal knowledge distillation.\n\nMain weakness: the way to decide what kind of features are modality-general decisive features are difficult to control and search. The advantage of deep learning is to automatically learn the \"useful\" features for improving the performance, while authors strategy of determining the modality-general decisive features is heuristic, and usually difficult to decide. In particular, how to decide the modality-general decisive features itself is a difficult problem.",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation of this paper is clear, and the way for setting up the hypothesis, theoretical and experimental analysis are reasonable, and easy to follow. And the final results also seem to support the hypothesis. The main problem is how to determine the modality-general decisive features in real applications is not explained well. The results were not difficult to reproduce.",
            "summary_of_the_review": "Authors investigated the key factors in determining when the student model could benefit from a teacher model in cross-modal knowledge distillation. Based on authors investigation, authors proposed a hypothesis with a new concept as modality-general decisive features which is essential in training a teacher model. However, it seems that how to determine what are the modality-general decisive features is not a easy task in real applications.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_vsTN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_vsTN"
        ]
    },
    {
        "id": "KcJRn3vrz7",
        "original": null,
        "number": 3,
        "cdate": 1666877621415,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666877621415,
        "tmdate": 1666877621415,
        "tddate": null,
        "forum": "w0QXrZ3N-s",
        "replyto": "w0QXrZ3N-s",
        "invitation": "ICLR.cc/2023/Conference/Paper2113/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper explores the topics of crossmodal knowledge distillation (KD), to transfer knowledge across modalities. To facilitate better understanding of crossmodal KD, the paper proposed a hypothesis that modality-general decisive features are the\ncrucial factor that determines the efficacy of crossmodal KD.",
            "strength_and_weaknesses": "Strength:\n(a) The author hypothesized that for crossmodal KD, distillation performance depends on the proportion of modality-general decisive features preserved in the teacher network, this hypothesis is refreshing to me.\n(b) The verification experiments in Figure 2 and 3 are convincing to me.\nWeaknesses:\n(a) In some cases,  modality general decisive features and modality-specific decisive features of audio and video modalities could be imbalanced, e.g. on VGGSound Event dataset, there could be more audio decisive features than visual features feature, How would the proposed method handle this?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-motivated, and the details provided in the paper could reproduce the experiments.\n\n",
            "summary_of_the_review": " The paper is overall well-motivated and the hypothesis is refreshing to me, however, I have some questions listed in the weaknesses part,",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_Syoj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2113/Reviewer_Syoj"
        ]
    }
]