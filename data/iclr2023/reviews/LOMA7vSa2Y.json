[
    {
        "id": "6a3MAsZOfC",
        "original": null,
        "number": 1,
        "cdate": 1666400156411,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666400156411,
        "tmdate": 1666400315682,
        "tddate": null,
        "forum": "LOMA7vSa2Y",
        "replyto": "LOMA7vSa2Y",
        "invitation": "ICLR.cc/2023/Conference/Paper3280/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In summary, this paper:\n1. Proposes to attack the problem of learning gradient-based optimizers by considering the space of gradient updates which can be represented in the Stochastic Mirror Descent (SMD) framework. \n2. In the SMD framework, the 1-step gradient updates are all parameterized by the expression of the Bregman Divergence. In the current paper's setting, quadratic costs $\\theta^{T} M \\theta$ with learnable matrix $M$ are considered.\n3. Quite a few techniques are used to make learning $M$ feasible; they are primarily:\n    * Expressing $M$ as block diagonal matrices to reduce the size, where each block corresponds to a layer in the neural network. Each block is also parameterized by a Kronecker factorization to further reduce computation.\n    * Using an upper bound on convergence rate, as the actual objective to differentiate $M$ across.\n    * Using implicit gradient descent to further reduce the explosive memory/computation blowups from auto-differentiating through a gradient update chain.\n4. Experiments show solid results on toy quadratic functions, meta-training MNIST variants, and meta-testing on CIFAR10 + ResNet-18. Lastly, \"larger\" tasks were also experimented on with their own meta-train / meta-test, by increasing image resolutions over a distribution of datasets (Aircraft, Butterfly,...etc.) to 224x224. \n   ",
            "strength_and_weaknesses": "# Strengths\n* Even though the proposed method has multiple steps, the paper is very well-written and conveys all such steps clearly, and makes itself accessible to even non-experts.\n* The method appears to be quite natural, theoretically motivated, and utilizes well-known techniques from the literature (convex optimization, bilevel optimization, etc).\n* The experimental results appear to be quite strong, with performance gains over numerous baselines within the few percentages, sometime within the tens of percentages on the \"High Resolution Image Application\" benchmark.\n\n# Weaknesses\n* While I am not an expert on the particular topic of Stochastic Mirror Descent, it appears that the method is only applicable to SGD-like optimizers, and momentum-based optimizers such as Adam are not represented here. If so, is there a way to extend the method to the momentum case? Momentum-based optimizers such as Adam are still the de-facto choice for applications such as reinforcement learning.\n* The largest network used in this paper, ResNet-18, even if applied to 224 x 224 image sizes, is still quite small in the field of deep learning at the end of the day. While I am not explicitly requiring the authors to try the method on much higher compute budget experiments (e.g. training large Transformers, ResNet-101 on ImageNet-sized datasets), I do want to know if the method would still hold up, or if certain parts may need to be changed. \n    * Answering this would greatly improve its impact over today's large-scale training, which in all honesty are probably the intended audience for such a work anyways, since the potential benefits over e.g. large language model training are far bigger than simply improving accuracies over MNIST or CIFAR10.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity + Quality:** The paper's writing is of high quality and I could understand all motivations, even though I am not an expert in this subfield. I found no major issues with the paper and consider it a solid contribution.\n\n**Novelty + Originality:** While the method is not extremely novel, it is constructed motivated techniques from the standard literature, and is well-grounded based on both its conceptual and experimental contributions.\n\n",
            "summary_of_the_review": "The paper is a solid application of well-known optimization techniques in the literature, and has demonstrated this with both conceptual and experimental contributions. The main boost to the paper's score and impact, is if my question about applying the method over larger-scale experiments are answered. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_f8bx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_f8bx"
        ]
    },
    {
        "id": "W6pRF4JZVD",
        "original": null,
        "number": 2,
        "cdate": 1666678605262,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666678605262,
        "tmdate": 1666678605262,
        "tddate": null,
        "forum": "LOMA7vSa2Y",
        "replyto": "LOMA7vSa2Y",
        "invitation": "ICLR.cc/2023/Conference/Paper3280/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper provides a method for meta-learning a preconditioner for gradient descent. The authors motivate the method from the mirror descent perspective, and use a convergence rate bound as a training objective. The authors parameterize the preconditioner in the K-FAC format [1]. Empirically, the method achieves good results across a range of problems.",
            "strength_and_weaknesses": "## Strengths\n\n**S1**: The paper is clearly written and easy to follow, especially given the fairly technical subject. I enjoyed reading it.\n\n**S2**: The proposed method is well-motivated theoretically, with connections to mirror descent.\n\n**S3**: The authors derive a new bound on the generalization performance of their learned optimizer in Theorem 4.1 (I did not check the proof of this bound).\n\n**S4**: Empirically, the method performs well on a range of tasks.\n\n## Weaknesses\n\n**W1**: While the authors present the method quite generally, as learning the Bregman  divergence for mirror descent, they restrict the class of these divergences so that the method is learning a preconditioner for SGD, which has been considered before.\n\n**W2**: The motivation for the training objective in Eq. 8 is not immediately obvious to me.\n\nI discuss the weaknesses in more detail below.",
            "clarity,_quality,_novelty_and_reproducibility": "First, I want to note that I am not an expert on learned optimizers.\n\n## Novelty (W1)\n\nMeta-learning the preconditioner has been considered before, e.g. [2], which is cited by the authors. Could the authors please comment on the differences between the proposed method and other approaches for learning the preconditioner? \n\n## Technical (W2)\n\nFrom the paper, it wasn't clear to me why in Eq. (8) you introduced $\\theta_T^(i)$ in place of $\\theta^*$? It seems like you could potentially try to 1 get the best possible estimate of $\\theta^*$ for each of the meta-training tasks that you have, and then simply train $M$ with the sum of objective in Eq. (7) over the meta-training tasks. In this case, can you assume that $\\theta^*$ does not depend on $M$?\n\nMoreover, my understanding from Section 4.4 is that you essentially arrive at this formulation, where you take gradients of $B_{\\phi_M}(\\theta, \\theta^1)$ where $\\theta$ is the solution to the inner-problem that you obtain. Here, do you assume that $\\theta^*$ does not depend on $M$?\n\nFurther, why did you separate the $1 / \\lambda$ term from the $B_{\\phi_M}$ term in Eq. (8)? Where does this exact expression come from?\n\n## Experiments\n\nI have a small question about the synthetic experiment: what is the optimal preconditioner here? My understanding is that for each given $Q$ the optimal preconditioner should be $Q^{-1}$? If so, how do you learn a preconditioner that is better than $I$ for random $Q$ matrices?\n\nSimilarly, could you provide some intuition into what preconditioner is learned more generally by your method? Is there some interpretable structure in the learned kronecker factors?",
            "summary_of_the_review": "Overall, this is a nice paper with good empirical results. I hope the authors can provide clarifications to my questions above.\n\n## References\n\n[1] Optimizing Neural Networks with Kronecker-factored Approximate Curvature\nJames Martens, Roger Grosse\n\n[2] Meta-Learning with Warped Gradient Descent\nSebastian Flennerhag, Andrei A. Rusu, Razvan Pascanu, Francesco Visin, Hujun Yin, Raia Hadsell",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_c6CM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_c6CM"
        ]
    },
    {
        "id": "gjaNnh3kQaD",
        "original": null,
        "number": 3,
        "cdate": 1667349770531,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667349770531,
        "tmdate": 1670823396554,
        "tddate": null,
        "forum": "LOMA7vSa2Y",
        "replyto": "LOMA7vSa2Y",
        "invitation": "ICLR.cc/2023/Conference/Paper3280/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper approaches meta-learning from a mirror descent perspective, considering a setting where the potential of the Bregman divergence is meta-learned. It proposes a method that can be efficiently implemented by restricting the form of the potential and using the IFT to be practical. Experiments show improved performance compared to competing methods.",
            "strength_and_weaknesses": "- The idea is well-motivated and the approach is promising. Adopting the Mirror Descent framework for meta-learning is something that has been discussed in the community but a practical yet expressive approach was still to be found, which I think this paper accomplishes. The form of the potential is not too constrained (although being block diagonal is somewhat restrictive) and the use of the IFT seems to fit well in this setting.\n- The description of the method is mostly clear, but Algorithm 1 could have more details. Line 8 could be expanded to have the actual form of the hypergradient (following Eq 13) and what steps are used to compute it (Neumann series, as mentioned right before Section 5?). H seems to be an accumulator for the (hyper)gradients of M, and this could also be stated somewhere in Algorithm 1.\n- Experimentally, the proposed method comfortably outperforms competing approaches in most tasks, but it would be very valuable to also consider commonly-adopted few-shot learning problems such as miniImageNet and MetaDataset. Some of the tasks used in the comparison seem less standard. Some of the considered methods also perform very poorly on the considered tasks but are known to perform well on miniImageNet (like MetaCurvature): it's unclear whether these methods are incompatible with such tasks for some reason, or if they were trained under less than optimal settings.\n- A comparison against WarpGrad is expected but not given in the paper. This is an important evaluation since WarpGrad is somewhat motivated by MD and is more recent than most, if not all, of the considered competing methods.",
            "clarity,_quality,_novelty_and_reproducibility": "See points above. The paper is well-written and clear, but Algorithm 1 could be more self-contained and detailed.",
            "summary_of_the_review": "The proposed method strengthens the idea that the MD framework can be successfully adopted for meta-learning, and while a compromise is made in terms of expressivity (the form of the potential is still somewhat restrictive) to achieve reasonable computational costs, the experiments show improvements over competing methods nonetheless.\n\nThe main weaknesses, in my opinion, are the lack of results on more standard tasks such as miniImageNet and MetaDataset, and a missing comparison against WarpGrad. These would be extremely valuable and would enable a more rigorous and complete evaluation of MetaMD.\n\n------------\n\nI believe reviewer Ced8 raises key concerns which I had overlooked in my initial review. The authors' response does not fully address these points, especially regarding the suboptimal performance of baseline methods due to the adoption of lightweight HPO instead of using hyperparameter values recommended by the corresponding papers. This could result in an unfair advantage to MetaMD due to a possible increased robustness to hyperparameter settings -- an advantage that might only manifest when a low budget HPO is deployed which is effectively choosing poor hyperparameter values. In light of this, I have decided to decrease my score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_bxcN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_bxcN"
        ]
    },
    {
        "id": "HhF_JjUOerv",
        "original": null,
        "number": 4,
        "cdate": 1667563742189,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667563742189,
        "tmdate": 1667563742189,
        "tddate": null,
        "forum": "LOMA7vSa2Y",
        "replyto": "LOMA7vSa2Y",
        "invitation": "ICLR.cc/2023/Conference/Paper3280/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes a meta-optimised mirror descent scheme for large-scale optimization problems, based on tuning of a parametric Bregman divergence on a set of curriculum meta-training task. The expected benefits of this meta-learning procedure is to produce an optimiser with accelerated convergence that is transferable to similar optimization problems, while retaining theoretically provable convergence guarantees. The authors provide a theoretical discussion regarding Stochastic mirror descent as well as an optimization framework leveraging the Implicit Function Theorem for meta-optimizing the Bregman divergence used in the mirror descent scheme. The authors further describe a particular construction of the Bregman divergence based on block-diagonal Kroenecker factorization of a quadratic form, aiming at finding a trade-off between computational complexity of the inner optimization problem and meta-adaptability, as well a convergence result of this approach in the convex case. The paper provide experiments showing the doability and the potential benefit of the method (in terms of test accuracy) on a set of synthetic problems / MLP and Convolutional NN training on MNIST-like datasets classification/ ResNet-18 on higher resolution images dataset classification.",
            "strength_and_weaknesses": "Strength : From a formal point of view, I feel that this work is clear and well written : understanding is straightforward, the authors motivates well the proposal, which is further discussed in comparison with the relevant meta-optimization literature. The theoretical and experimental results are also clear without ambiguity. \n\nHowever, I have several concerns regarding the applicability of the method and the execution of the experimental section that I list below in order of importance: \n\n - I) In my opinion, an important question is how transferable is the learnt divergence when applied to new optimization problems, as it determines the genuine applicability of the method and the benefit of the expensive meta-training procedure. It seems that this is very partially answered in the experimental sections with mixed results: In the DiverseDigits experiment, the training loss function seems to plateau at a slightly higher level than two off-the-shelf optimizers without meta-adaptation: RMSProp and Adam, which calls into question the transferability of $B_{\\phi}$ for datasets that are most dissimilar to the meta-training curriculum. In order to form an idea of how general is the learnt meta-optimizer, It would be beneficial to the paper to provide a quantification of the method transferability when controlling tasks dissimilarities (by varying datasets or the loss function for instance).\n\n- II) Another point that weakens the paper argument is that there is no empirical results regarding the acceleration proposed by this method, whereas it is one claim of the abstract. Apart from the iteration count in the toy dataset, no quantification of the acceleration induced by metaMD is provided. Worse, the different optimization baselines are not controlled for computational budget (such as total number of flops or time for reaching stopping criterion for instance). The meta-training procedure is compute-intensive and the argument that it constitutes a \"one-off cost that can be amortized across different meta-test problems of interest\" would hold only if transferability (point ii) is valid which is hardly decidable from the current set of experiments.\n\n - III) Some of the performance metrics seems surprisingly low compared to what is usually reported in the literature. For instance the accuracy regime of ResNet-18 for Caltech and Flowers dataset is lower than 30% for all baselines. By inspecting more closely the training curves in Appendix (figure 6) It seems that this low test performance mainly comes from substantial overfitting. To the author point, the benefit of MetaMD is to provide an implicit regularization of the optimization problem (since meta-training is performed on the other datasets). Since classification test accuracy is the only selected metric, the unusual overfitting regime in which the tested optimization scheme are compared seems to artificially favor MetaMD. \n\n - iv) One explicit motivation of the paper for meta-optimizing a stochastic mirror descent scheme (SMD) is to retain the well-established theoretical guarantees offered by SMD method. However, the authors propose a convergence rate in the convex setting, which is fairly restrictive and ill-aligned with the experiments over non-convex problems carried in the paper. There exists a rich literature on convergence of SMD in the non-convex case and I feel that such theoretical results provided are uninformative. \n",
            "clarity,_quality,_novelty_and_reproducibility": "I reiterate that the paper is well written with a good motivation and presentation of the method. Further, the meta-optimization principle seems to work in practice. However, as I explain above, I am more concerned with the execution of the experiments, which are not justifying well that there is a benefit of the meta-optimization in MetaMD: There is no clear quantification of the transferability of the meta-learned divergence (Rotated digits and DiverseDigits seems an artificial task with merely no difference across data distribution). Technically, while the block-diagonal construction of the quadratic cost for the Bregman divergence is interesting, there is limited novelty since MetaMD makes a direct use of the implicit differentiation framework. \n\n\n",
            "summary_of_the_review": "Overall, while I personally find this line of work very interesting and would like proposals such as MetaMD to come through, I feel that the current experimental section has too many weaknesses which makes this submission not ready for publication. I am willing to discuss more specifically with the authors the points (I-IV) raised above and to increase my score should they provide more compelling experimental evidence, in priority regarding transferability and acceleration. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "- ",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_Ced8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3280/Reviewer_Ced8"
        ]
    }
]