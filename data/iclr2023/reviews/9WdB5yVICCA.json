[
    {
        "id": "6W6iUwpBz1-",
        "original": null,
        "number": 1,
        "cdate": 1665864172281,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665864172281,
        "tmdate": 1665864172281,
        "tddate": null,
        "forum": "9WdB5yVICCA",
        "replyto": "9WdB5yVICCA",
        "invitation": "ICLR.cc/2023/Conference/Paper1141/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents a benchmark and a set of studies about the sensitivity of trajectory prediction models to the removal of non-causal agents.\n\nThe authors had human labelers label the agents that influence the ego behavior in the WOMD validation set. They then used those labels to perturb the dataset. They considered four perturbations, removing all non-causal agents, removing some non-causal agents that equaling to the number of causal agents, removing all causal agents, and removing all static agents.\n\nThey evaluated three representative trajectory prediction models (MultiPath++, SceneTransformer, and Wayformer) under those perturbations. The results show that all those models are sensitive to the removal of causal agents. For example, the relative mADE delta is around 25%, and the prediction errors even decrease in more than 40% of the samples.\n\nThe authors hypothesized that a lack of training data and overfitting could be the cause of this sensitivity. They also found data augmentation (by randomly removing some static agents) could improve the robustness of the models.",
            "strength_and_weaknesses": "--- Strengths\n\n- Robustness is essential to the trajectory prediction task. This paper presents many interesting results about how state-of-the-art prediction models perform under perturbations.\n\n- The causal labels that the authors released to the WOMD validation set will be valuable.\n\n\n--- Weaknesses\n\n- This is an interesting paper. However, my main concern about this paper is that the studies presented in this paper are based on a prediction model whose performance might not be representative. This paper mainly used the MultiPath++-All model for its studies. However, in Table 2, the performance of the MultiPath++-All model is clearly an outlier. It has more than double the prediction error compared to the other models in the table, and it's even a lot worse than MultiPath++. If I understand correctly, the only difference between MultiPath++-All and MultiPath++ is that MultiPath++-All was trained on all agents, so I will expect the performance of MultiPath++-All should be close to or better than MultiPath++ since it's trained on more agents. I hope the authors provide a convincible explanation about why the *-All models have worse performance. The authors used the outlier MultiPath++-All model for most (if not all) of the other studies, including data augmentation and dataset size analysis. I am concerned that the conclusions might not apply to the other state-of-the-art models since the performance of MulthPath++-All seems to be an outlier.\n\n- There are many interesting analyses presented in the paper, but there is not much novelty in the proposed mitigation method. The main method presented in the paper to improve the model's robustness is to augment the training data by randomly removing some static agents. It is not surprising at all that removing some agents will make the model more robust to the removal of agents at test time.",
            "clarity,_quality,_novelty_and_reproducibility": "- The presentation is clear.\n\n- The data will be released to the public.",
            "summary_of_the_review": "This is an interesting paper. However, my main concern about this paper is that the studies presented in this paper are based on a prediction model whose performance might not be representative. And there is not much novelty in the proposed method.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_Chzn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_Chzn"
        ]
    },
    {
        "id": "bTM5DaJgi6u",
        "original": null,
        "number": 2,
        "cdate": 1666040154379,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666040154379,
        "tmdate": 1666147581594,
        "tddate": null,
        "forum": "9WdB5yVICCA",
        "replyto": "9WdB5yVICCA",
        "invitation": "ICLR.cc/2023/Conference/Paper1141/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper designs a benchmark based on the Waymo Open Motion Dataset for evaluating the robustness of trajectory prediction algorithms. They construct perturbed examples by removing non-causal agents, removing causal agents, removing a subset of non-causal agents, or removing stationary agents. Their experiment results show several state-of-the-art prediction algorithms have performance drops when evaluated on their dataset. They also propose two methods, i.e., increasing the training dataset size and using targeted data augmentation, to increase the robustness.",
            "strength_and_weaknesses": "### **Strength**\n\n* Evaluating the robustness of trajectory prediction algorithms is an interesting topic. A standard benchmark is also urgently demanded. \n \n* The structure of the paper is good and the writing is easy to follow.\n\n\n### **Weaknesses**\n\n* **Correctness of non-causal label.** The correctness of the non-causal label cannot be verified or guaranteed. In particular, the causality of sequential data is usually more complex than expected. For example, Figure 1 does not look correct to me. I find that some important agents (a pedestrian and two vehicles in the opposite direction) are removed. I think calling them \u201cnon-causal agents\u201d is not reasonable. Actually, I think it is really hard to identify the non-causal agents unless the underlying causality behind the traffic scenario is explicitly shown. Or interventions are allowed to obtain Randomized Controlled Trials.  \n\n* **Missing literature.** Related works about adversarial robustness of trajectory prediction are missing: [1][2][3][4]. Although this paper does not focus on adversarial robustness, I feel that the robustness mentioned in this paper can also be improved by adversarial training. \n\n* **Motivation.** Based on the last point, I question the motivation for evaluating robustness with the non-causal agents. I doubt that the performance drop of prediction algorithms may be caused by the bias and low diversity of the dataset. In contrast, I think adversarial trajectory perturbation may be more fundamental for robustness. \n\n---\n\n[1] Cao, Yulong, Danfei Xu, Xinshuo Weng, Zhuoqing Mao, Anima Anandkumar, Chaowei Xiao, and Marco Pavone. \"Robust Trajectory Prediction against Adversarial Attacks.\" arXiv preprint arXiv:2208.00094 (2022).\n\n[2] Cao, Yulong, Chaowei Xiao, Anima Anandkumar, Danfei Xu, and Marco Pavone. \"AdvDO: Realistic Adversarial Attacks for Trajectory Prediction.\" arXiv preprint arXiv:2209.08744 (2022).\n\n[3] Zhang, Qingzhao, Shengtuo Hu, Jiachen Sun, Qi Alfred Chen, and Z. Morley Mao. \"On adversarial robustness of trajectory prediction for autonomous vehicles.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15159-15168. 2022.\n\n[4] Wang, Jingkang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, and Raquel Urtasun. \"Advsim: Generating safety-critical scenarios for self-driving vehicles.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9909-9918. 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### **Quality**\nThe quality of the experiment is high. I have some concerns about the motivation of evaluating robustness with causality as I mentioned in the weakness part. Some important literature is also missing.\n\n### **Clarity**\nThe presentation of this paper is very clear.\n\n### **Novelty**\nThe benchmark proposed in this paper is novel.\n\n### **Reproducibility**\nThe label of the non-causal agent is provided in the supplementary. I believe the results are reproducible.",
            "summary_of_the_review": "My biggest concern about the proposed benchmark is the correctness of the causal label. If the correctness of the underlying causality cannot be guaranteed, the evaluation results will be meaningless. In addition, compared to using non-causal agents to evaluate robustness, I think adversarial perturbation is more useful and applicable in real-world AV systems. Overall, I suggest rejecting this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_vJxd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_vJxd"
        ]
    },
    {
        "id": "1vwKRriOPO",
        "original": null,
        "number": 3,
        "cdate": 1666520508601,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666520508601,
        "tmdate": 1666520508601,
        "tddate": null,
        "forum": "9WdB5yVICCA",
        "replyto": "9WdB5yVICCA",
        "invitation": "ICLR.cc/2023/Conference/Paper1141/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a new benchmark for evaluating the robustness of models for motion forecasting of autonomous vehicles. The authors collect human-annotated labels of causal agents on the Waymo Open Motion Dataset, and perform various perturbations of the data using these labels. This data is used to evaluate the robustness of state-of-the-art forecasting methods. Towards this end, the authors also propose two metrics to quantify robustness. The takeaway messages are that all models exhibit a large shift in performance under even non-causal perturbations, and that increasing the training dataset size and targeted augmentation can improve model robustness.\n\n",
            "strength_and_weaknesses": "### STRENGTHS:\n\n1. The paper is largely well-written. \n2. The empirical analysis is extensive and the paper discusses relevant aspects of model performance. \n\n### WEAKNESSES:\n\nThe main weaknesses I find are in dealing with the nature of the problem and the annotation methodology, which I consider are unfortunately crucial towards this paper's contributions. \n\n#### 1\\. On Causality and Perturbation:\n\nThe community has had a larger discussion on the relationship between perturbations and causality. In explainable AI, perturbations are used to obtain sensitivity maps that are then perceived to indicate causal relationships, a methodology that has received some criticism [R1]. More directly, there has been some effort in addressing the issues for the forecasting tasks [R2].\n\nI find that many of the similar problems listed in these papers apply here: specifically that the perturbed samples may no longer lie on the actual data manifold of the real-world data. Simply ignoring the state of an agent to be removed tampers with the validity of the rest of the agents behaviors in the scene as well. This is perhaps the most egregious in the `RemoveNoncausalEqual` perturbation where an equal number of randomly selected non-causal agents are removed. What guarantees that the scene is still valid for the model to make a prediction? \n\nStated differently, if the perturbation results in a different scene configuration that a model has seen before, even a perfect model might change its predictions but that would not constitute a lack of robustness. For instance, multiple valid predictions are possible for a given sequence. Why is Fig. 1 considered non-robust when there might be other examples of a left turn that seems plausible?\n\nThis in theory would not be a problem with the way causality has been mathematically defined, but I believe the problem comes from the way the definition of a causal agent is operationalized, as I describe later in point 3. \n\n#### 2\\. Accounting for the possibility of multiple valid futures:\n\nThe larger body of work of pedestrian forecasting deals with the possibility of multiple valid futures for an observations [R3, R2]. (Also see [R3, 8.4.2] for a discussion on robustness and a link to \"Lasota and Shah 2017\" in that paper which might be useful.) Here the notion of causality does not incorporate this possibility. The models have been trained on a large number of examples, where an agent behavior that causes a change in one example may not cause a change in another. I believe it is possible that this is what explains the large variation under non-causal perturbations as well. [R2] seems to do this in the counterfactual sense as well, but in terms of observed factors that change the 'uncertainty' over possible futures. Here the instructions do somewhat account for this by stating that a casual agent is `one whose presence would modify or influence human driver behavior in any way`.\n\nTo be fair to the authors I cannot see a directly easy way to fix this methodologically. So at the very least making this discussion explicit for future researchers would help minimise the misinformation in this space coming in from XAI methods. The linked papers might help in this regard.\n\n#### 3\\. Operationalization of causal agents and change in causality over the video:\n\nThe paper defines non-causal agents as:\n```\nwe define a non-causal agent as an agent whose deletion does not cause the ground truth trajectory of a given target agent to change.\n```\n\nIs a causal agent then the inverse or contrapositive of this statement? i.e. is an agent causal when their presence causes a trajectory to change, or if their presence *may or may not* cause a trajectory to change?\n\nThe annotator instructions indicate it's closer to *may or may not*:\n\n```\nIf the behavior of a human driver would be modified because of a potential action that an agent is likely to take, then that agent should be causal.\n```\n\nDriving as an activity inherently involves forecsating. From this definition, any potential agent that can influence one's own future is causal.\n\nIn Fig. 6. if the agent on the left (marked as not causal) rushes ahead, say under a red light, they would switch to being causal right?\n\nBut that's not how the annotation seems to be setup. The same agent can go from being causal to non-causal in principle. But I don't believe that is the case in the annotations? In the annotation statistics the authors say that \"cyclists are relatively more\nlikely to be causal agents than pedestrians or vehicles\" which seems odd as an overall statement seeing as cars around the driver ought to always be causal. If this is simply computed as `(# of agents marked as causal / # of agents in data) for each type`, this is a misleading message. \n\n#### 4. Annotation Methodology:\n\n#### 4.1. Annotator Agreement ility and `true' causality of agents\n\nSince improving the reliability of models is one goal of this work, it would help to look at an inter-annotator agreement/reliability metric to see how much the annoatators agreed on an agent being causal, to understand the nature of the problem better.\n\nThe paper assumes there is an underlying truth in whether an agent is causal or not, while simultaneously acknowledging the subjectivity in the perception of the causality:\n\n``` We emphasize that false positives (identifying an agent as causal when it is truly non-causal) are acceptable to a certain extent, but we should avoid false negatives (failing to identify a truly causal agent). ```\n\nThis subjectivity is reflected in that 24% of the labels are selected by a single annotator. The method leans towards treating false positives as accceptable, but there is no way of knowing whether these 24% would qualify as false positives or not. Traditionally in such subbjective annotations (e.g. perceived emotions) the agreement indicates wheter there is consensus in what would change a trajectory. Such a metric would provide more insight into the nature of the problem.\n\n#### 4.2. Whose perception is being modeled?\n\nWhen setting up annotation collections of this nature, the perception of annotator is asked. Here the instructions ask the annotator to simulate a hypothetical driver (Appendix A). Were all annotators drivers? Why not just ask for whether they themselves would be influenced by an agent?\n\n\n[R1] Exploratory not explanatory: Counterfactual analysis of saliency maps for deep reinforcement learning - Atrey et al. \n[R2] Why Did This Model Forecast This Future? Closed-Form Temporal Saliency Towards Causal Explanations of Probabilistic Forecasts - Raman et al. \n[R3] Human motion trajectory prediction: A survey - Rudenko et al. ",
            "clarity,_quality,_novelty_and_reproducibility": "1. The writing is clear and the paper was a pleasure to read. \n2. The quality of the empirical evaluation in terms of the things considered, save for the deeper issues in point 1. of the Weaknesses. \n3. The paper deals with a relevant topic and the broader goal of collecting human annotations is a new approach for trajectory prediction. 4. The dataset being shared is useful for reproducibility but it would help to have the pretrained models as well. ",
            "summary_of_the_review": "The paper is largely well-written and the analysis is extensive. The problems I find lie in dealing with the nature of the problem in setting up the human annotations. To be fair to the authors, if I find I cannot suggest any easy way of fixing the problems, I have not penalized my rating, and instead suggested discussing the problems as a means of increasing awareness for future researchers which is still valuable. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_UcfZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_UcfZ"
        ]
    },
    {
        "id": "eOL76XWInhT",
        "original": null,
        "number": 4,
        "cdate": 1666670051498,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670051498,
        "tmdate": 1666670051498,
        "tddate": null,
        "forum": "9WdB5yVICCA",
        "replyto": "9WdB5yVICCA",
        "invitation": "ICLR.cc/2023/Conference/Paper1141/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper constructs a novel benchmark for evaluating the robustness of trajectory prediction models by deleting non-causal agents in scenes. The causal agents in WOMD\u2019s validation data set (around 42k scenes, as indicated in the paper) are labeled with human labelers. This paper further proposes two metrics to evaluate the robustness of models. To improve the model robustness, this paper considers data augmentation methods that show improvements over baselines. \n",
            "strength_and_weaknesses": "Strength:\n - This paper proposes a novel perturbation which is deleting agents in the scene to emphasize the causal relationship between agents. \nThe experiments are conducted in realistic datasets. \n\nWeakness\n - The agents in the scene would affect the autonomous vehicle at different timesteps. In this paper, the causal agents are detected for the whole scene and are masked out during the whole scenario in the perturbed data. Is it more reasonable to label the timestep that each agent takes effects on the AV and mask accordingly? \n - Considering that this is a benchmark paper, it would be interesting to replicate the experiments in section 4.3 on other methods, such as SceneTransformer and WayTransformer. \n\nThere are several points that need further clarification.\n - For a better presentation of the two proposed metrics mentioned in the intro, It would be better to describe the IoU based metric in section 3.4 instead of in the result section. \n - It would be better to describe the definition of minADE instead of referring to the original paper, considering that minADE is quite important in evaluating the methods. \n - In section 4.2, the paper mentions that \u201cbut a long tail of outlier examples experience a large change ( > 1m).\u201d What does \u201c(?1m)\u201d mean? Is the statement related to Figure 4?\n - In section 4.2, the paper mentions that \u201cthe model sees a large portion of examples where minADE improves\u201d. What does the improvement mean? Which metric is used for measuring the improvements?\n - For figure 5, it would be better to put labels on the y-axis to make a clear comparison.  \n - Typo: In page 1, \u201cdata augmentation effect model sensitivity.\u201d -> \u201cdata augmentation affect model sensitivity.\u201d\n - Typo: In page 5, \u201cthere are causal agents in the scene For example,\u201d -> \u201cthere are causal agents in the scene. For example,\u201d\n",
            "clarity,_quality,_novelty_and_reproducibility": " - The paper\u2019s organizational structure can be further improved and there are points that require further clarification. Please see the above for detailed questions. \n -The perturbation is novel in terms of removing agents in the scene. \n",
            "summary_of_the_review": "There are several key clarifications that need to be addressed before I could fully evaluate the paper. I would recommend rejection for now. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_3msf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_3msf"
        ]
    },
    {
        "id": "DXFpollJjY",
        "original": null,
        "number": 5,
        "cdate": 1666704512433,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666704512433,
        "tmdate": 1666704512433,
        "tddate": null,
        "forum": "9WdB5yVICCA",
        "replyto": "9WdB5yVICCA",
        "invitation": "ICLR.cc/2023/Conference/Paper1141/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper focuses on the robustness of motion forecasting models and makes two main contributions: 1. additional labels for the Waymo Open Motion Dataset with causal labels, 2. evaluation of the robustness of several state of the art models using these \"causal\" labels. The causal labels include agents whose presence influences human drivers\u2019 behaviour in any format.  The paper shows that state of the art models exhibit large shifts in performance under even non-causal perturbation: a 25-38% relative change in minADE.",
            "strength_and_weaknesses": "Strengths,\n* The paper addresses an important problem and is well written.\n* The proposed \"causal\" labels for Waymo Open Motion Dataset is an interesting and novel idea.\n* The paper reports interesting findings: e.g. Figure 1, where there are very large changes in performance even when \"non-causal\" agents are perturbed.\n* The paper includes extensive and fine grained evaluation on the robustness of motion forecasting models.\n* The paper discusses the underlying causes of the lack of robustness of motion forecasting models in detail.\n\nWeakness,\n* The labelling process as described is prone to errors: as described each frame is annotated by only 1 annotator, this can introduce significant errors as the definition of \"causal\" in Appendix A subjective. E.g. in Figure 6, is it not clear why the while sedan on the right is causal? Moreover, the policy of \"please err on the side of including\" can introduce a significant number of false positives. This labelling policy would have a direct impact on the experiments in Section 4.1 \"RemoveCausal\".\n\n* Important prior work is not discussed \"Are socially-aware trajectory prediction models really socially-aware?, Saadatnejad et. al.\"  This work shows that small perturbations on the trajectories of agents can cause large changes in the predicted future trajectories. In the light of these finding, the findings of this paper are not very surprising.\n\n* The paper does not propose any method to improve robustness: the utility of the paper would increase manifold if the proposed labels could be used to improve robustness.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written and clear. The novelty is somewhat limited in light of prior works such as \"Are socially-aware trajectory prediction models really socially-aware?, Saadatnejad et. al.\". There are no issues wrt to reproducibility per se.",
            "summary_of_the_review": "The paper is an interesting read. However, the labelling process needs to be discussed in more detail especially the effect of false positive \"causal\" agents and its effects on the conclusions of the paper. Finally, prior works need to be discussed in more detail.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_oUDJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1141/Reviewer_oUDJ"
        ]
    }
]