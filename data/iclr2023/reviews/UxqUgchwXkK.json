[
    {
        "id": "9MX-jqbfNQy",
        "original": null,
        "number": 1,
        "cdate": 1666632692256,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632692256,
        "tmdate": 1666632692256,
        "tddate": null,
        "forum": "UxqUgchwXkK",
        "replyto": "UxqUgchwXkK",
        "invitation": "ICLR.cc/2023/Conference/Paper6201/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a scalable solver for non-linear multivariate quantile regression. While vector quantiles have been defined and studied in previous work, the authors address several limitations: developing a scalable solver, extending the linear regressor model to allow non-linear models and making sure monotonicity is ensured.",
            "strength_and_weaknesses": "Strengths:\n- Clean abstract in terms of the limitations addressed and the included contributions.\n- Good visualization/illustration of vector quantiles in Figure 1.\n- Brief summary of previous work in introduction and discussion of related work throughout the paper.\n- Even though I am not too familiar with this line of work, vector quantiles seem to be relevant in several niche applications and this paper provides a more scalable solver. With the increased interest in distribution-free uncertainty estimation, I can imagine this becoming and interesting tool.\n- The extension to non-linear models seems to be a particularly important contribution given the experiments and I can imagine this to be impactful in this line of work.\n- I appreciate the experiments on conformal prediction that show the benefit of this method.\n- Providing an open-source implementation.\n\nWeaknesses:\n- The paper is generally more difficult to follow, mainly due to two reasons: the content being very technical and dense (requiring a lot of familiarity with the topic or time to go through equations by trial and error) and missing structure. For example, in section 3, there is a high-level outline/overview missing. The primal discussion, as example, seems less relevant and not be used (more like a comment on related work), while the dual formulation and SGD approach is actually used in the proposed method.\n- The discussion of SQR and prior attempts in section 4, while interesting, seems less important in the main paper and distracted me. I\u2019d prefer this space to be spent on more structure and a bit more guidance through the technical content.\n- When less familiar with this line of work, the experimental setup could also use more details \u2013 e.g., describe at least one metric properly and give a high-level idea of the datasets.\n- The details of the contribution over Genevay 2016 in terms of the solver is a bit unclear to me. As of my understanding the SGD optimization setup of that paper is used with the \u201ctrick\u201d of obtaining constant memory footprint. Is that correct? This could be made clearer throughout the paper. In the abstract/intro it sounds like a novel solver is proposed instead.\n- I couldn\u2019t find the exact non-linear model that is used in the main paper and would be interested in a discussion of the constraints here. Are generally any differentiable non-linear models supported?\n- I am also missing a baseline in terms of runtime. In Figure 2, how would previous solvers perform? When would they stop working?\n- While I appreciate the conformal prediction experiments, this part is difficult to follow and judge from the main paper as the results are exclusively found in the appendix.\n- Generally, this paper and the experiments are difficult to read without the appendix and I think this hurts the paper. I would appreciate if the authors could prioritize experiments and discuss a subset where the results are actually in the main paper, instead.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "I believe this is an interesting contribution even though writing and structure could be improved significantly. Also, I am not too familiar with the background on vector quantiles, but appreciated the conformal prediction results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_u5QX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_u5QX"
        ]
    },
    {
        "id": "s_jsmIrNA-",
        "original": null,
        "number": 2,
        "cdate": 1666674484134,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674484134,
        "tmdate": 1666674484134,
        "tddate": null,
        "forum": "UxqUgchwXkK",
        "replyto": "UxqUgchwXkK",
        "invitation": "ICLR.cc/2023/Conference/Paper6201/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces an efficient, nonlinear model for vector quantile regression (VQR). VQR is the problem of learning the quantiles of a multivariate response variable Y, conditioned on set of covariates x. The approach extends prior work by allowing for a nonlinear function of x and implementing vector rearrangement to guarantee monotonicity of simultaneous quantile estimates.\n\nI am not familiar with Optimal Transport, so unfortunately, a fraction of the paper's key ideas were unintelligible to me.",
            "strength_and_weaknesses": "Strengths:\n* If the authors' literature review is taken to be comprehensive, then they have advanced the state of the art for vector quantile regression (VQR) by quite a large amount: they introduce the first (partially) nonlinear model for VQR, they introduce a vector variation of monotonic rearrangement, and they provide an efficient and scalable implementation.\n\nWeaknesses:\n* If I understand Section 4 correctly, the model does not allow for interactions between x and u. This seems to imply that the model can only model situations where each conditional distribution over Y (for a given x value) is exactly the same as the others (for all other x values), up to an affine scale-and-shift transformation. This seems like an overly-restrictive model, but I guess prior work, using a fully linear model in both u and x, is even more restrictive.\n* Vector quantile regression seems like quite a niche topic. In my experience in corporate research, even scalar-valued quantile regression is little-known and little-used.\n* There doesn't seem to be a comparison to, or a mention of, Bayesian methods or generative modeling, which seems like a very natural fit for this problem.",
            "clarity,_quality,_novelty_and_reproducibility": "A large fraction of the paper, including the essential details of the experimental results, is tucked away in appendices. I feel like this might violate the spirit of the page limit. Perhaps a paper of this size is better suited as a journal article?",
            "summary_of_the_review": "I really like this topic and feel that it deserves more attention. Unfortunately, the audience for this paper would be relatively small. However, I believe it extends the state of the art quite a bit for this problem, and as such it probably deserves to be published.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_fWcC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_fWcC"
        ]
    },
    {
        "id": "rbfoDkTTF1",
        "original": null,
        "number": 3,
        "cdate": 1666810103885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666810103885,
        "tmdate": 1666810103885,
        "tddate": null,
        "forum": "UxqUgchwXkK",
        "replyto": "UxqUgchwXkK",
        "invitation": "ICLR.cc/2023/Conference/Paper6201/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this work, motivated by the limitation that there are no fast or scalable solvers for vector quantile regression (VQR), the authors provide a highly-scalable solver for VQR that relies on solving its relaxed dual formulation. In addition, the authors propose vector monotone rearrangement (VMR), which serves as a refinement step and resolves the co-monotonicity violations in estimated conditional vector quantile functions (CVQFs). Moreover, motivated by the limitation of VQR that it assumes a linear model for the quantiles of the target given the features, the authors propose nonlinear vector quantile regression (NL-VQR). Based on extensive experiments on both synthetic and real data, the authors demonstrate the superiority of VMR and NL-VQR in modeling CVQFs accurately. ",
            "strength_and_weaknesses": "Strength:\n\nThe studied problem is of sufficient interest to the community, and the authors' work seems to be a significant contribution to the field of VQR. \n\nWeaknesses:\n\nAlthough the experimental results are sufficiently promising, I hope that similar to some closely relevant works such as Carlier et al. (2016) and Chernozhukov et al. (2017), the authors can provide some theoretical justifications for their proposed methods.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is generally well-written, and it seems to have sufficiently novel and significant contributions that may advance the field. \n\nThe code has been included in the supplementary material (and also in GitHub) for reproducibility.",
            "summary_of_the_review": "Overall, I think that this is a good work with sufficiently novel methods and interesting numerical results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_2xhV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6201/Reviewer_2xhV"
        ]
    }
]