[
    {
        "id": "jsFHgZMwyG",
        "original": null,
        "number": 1,
        "cdate": 1666357011382,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666357011382,
        "tmdate": 1666357045764,
        "tddate": null,
        "forum": "_hb4vM3jspB",
        "replyto": "_hb4vM3jspB",
        "invitation": "ICLR.cc/2023/Conference/Paper1248/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper targets to one-shot federated learning under high statistical heterogeneity. The authors designed two different solutions: FEDCVAE-ENS and FEDCVAE-KD, both of which construct a VAE on the server to generate samples. The generated samples are utilised to train a classifier on the server. The difference between FEDCVAE-ENS and FEDCVAE-KD is that FEDCVAE_KD create a single server VAE decoder while FEDCVAE-ENS stores a set of VAEs that is trained on local clients.",
            "strength_and_weaknesses": "Strength:\n\n-- The proposed solutions seem effective under the one-shot FL setting. The efficacy and efficiency are both demonstrated in the extensive experiments.\n-- The writing is clear and easy to follow. The tables and figures are well-organized.\n\nWeaknesses:\n\n-- Constructing a generative model to generate samples for FL model training is not new. There are a few works utilizing a similar strategy in FL, for example:\nData-Free Knowledge Distillation for Heterogeneous Federated Learning, ICML 2021\nFine-tuning global model via data-free knowledge distillation for non-iid federated learning, CVPR 2022\nPlease make a comparison with those works\n\n-- Some details are not clear enough for me. For example, in Eq 2, what is the formulation for g(.)?  Is this dissimilarity measured in the data-space or feature space?",
            "clarity,_quality,_novelty_and_reproducibility": "This work is written with clarity and good quality. The originality of this work is good.",
            "summary_of_the_review": "This work focuses on one-shot FL with high data heterogeneity. Two solutions are proposed in this work, which has been tested under extensive experiments. The writing is clear and well-organized. There might be some minor issues in this draft. I look forward to the feedback from the authors in the rebuttal.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_feTx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_feTx"
        ]
    },
    {
        "id": "SB6URURlVmz",
        "original": null,
        "number": 2,
        "cdate": 1666604177814,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604177814,
        "tmdate": 1668770401343,
        "tddate": null,
        "forum": "_hb4vM3jspB",
        "replyto": "_hb4vM3jspB",
        "invitation": "ICLR.cc/2023/Conference/Paper1248/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes an alternative way to perform federated learning; instead of training a discriminative model, the authors propose to train a conditional (on the label) VAE model $p(x, z| y) = p(z)p(x|z, y)$, to convergence on each client and then communicate (once), provided that the clients agree on a $p(z)$, the decoder along with the marginal label distribution of the client, back at the server. The server can then use the marginal $p(y)$ on each client along with its decoder to generate training data $(x, y)$ in order to train centrally a discriminative model. Having access to all of the decoders, the server can also train a global decoder to \u201cdistill\u201d all of the client specific ones to reduce storage requirements. The authors further propose the use of a randomly centred prior mean for $p(z)$ in order to improve the security of the system against external entities. Better performance in cross-silo settings and high non-iid settings is demonstrated. \n",
            "strength_and_weaknesses": "Strengths\n- Relatively simple procedure that requires a single round of communication\n- As far as I know, using VAEs in this specific way for FL is novel\n\nWeaknesses\n- Simple datasets for generative models; how about CIFAR10, CIFAR100 or even Shakespeare?\n- Experimental evaluation against baselines is not entirely apples to apples\n- Some statements and explanations are not entirely accurate (see below)",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presents a relatively simple idea and is mostly clearly written. As far as I am aware, this method is novel in the context of FL. The authors also provide a reasonable amount of information, which should make FedCVAE reproducible. The authors seem to mostly tackle the cross-silo setting, where each client has enough data. One thing I noticed is that the authors mention that the conditional VAE (CVAE) objective at eq. 1 bounds the marginal likelihood $\\log p(x)$; this is not correct, as the specific objective at eq. 1 bounds the conditional marginal likelihood $\\log p(x|y)$. \n\nBesides that, there are a couple of things that are, in my opinion, not properly motivated. More specifically, the authors propose to sample from the generative model and train a classifier at the server. Why is this necessary and why you do not simply use the generative classifier  $p(y|x) = \\frac{\\int p(x| z, y)p(z)dz p(y)}{p(x)}$? To me it seems that the target for the auxiliary classifier is nothing else, but to approximate this generative classifier. The loss for the auxiliary classifier (in the limit where you constantly sample from the generative model) can be obtained by minimising the average KL-divergence between the true CVAE generative posterior $p(y|x)$ and the classifier predictive $q(y|x)$. More specifically: $$E_p(x)[KL(p(y|x) || q(y|x))] = - E_p(y,x) [\\log q(y|x)] + const = -E_p(y,z,x)[\\log q(y|x)]  + const = -E_p(y)p(z)p(x|y,z)[\\log q(y|x)] + const$$ In this sense, it seems that 1) it might not be necessary to train an auxiliary classifier and 2) the modelling choices made in the generative model itself are important for the performance of the actual downstream classifier. I believe a discussion about this is warranted to be added in the paper. Apart from that, when the authors want to sample datapoints from the model they actually use a different distribution over the latents than the one the model was actually trained; e.g., using a $z \\sim U[-1, 1]$ instead of $z\\sim N(0, I)$. They mention that it is beneficial to stay at a high density region of the prior, but how does the performance of the algorithm fare when you use the correct prior? Why not use e.g., $z \\sim N(0, \\sigma)$ with $\\sigma < 1$ which is closer to the correct prior? \n\nAnother thing that could be better explained are the security and privacy aspects of this method, especially given the FL scenario. FedCVAE uploads the CVAE decoder along with $p(y)$ to the server, which is inherently less private than FedAvg. While it is true that with DP you can bound memorisation and get privacy, at the moment the authors do not use anything and the gains in performance when doing DP relatively to e.g., DP-FedAvg are not clear. In fact, given a sufficient powerful generative model, this method should be indistinguishable from sending the actual data. Furthermore, the arguments about security by shifting $\\mu$, need to be more formal. Are there some guarantees that you can give, given a sufficient powerful adversary? For example, given $p(y)$, and $p(x|z, y)$, couldn\u2019t the attacker just try to infer a global mean for $z$? For example, by visual inspection of the samples or an optimization procedure? And a small comment; $U[-10, 10]$ is not an exceptionally good guess for $N(0, I)$ (which is what the text mentions at the beginning of page 9) as 99% of the probability of $N(0,I)$ is in $[-3, 3]$, so 70% of the mass of the uniform proposal is on almost zero probability mass under $N(0, I)$. \n\nFurthermore, this method requires building good generative models which is generally a harder task than building a good discriminative model. How does this work on more complex datasets, such as CIFAR10 and CIFAR100, where $p(x|y, z)$ might not be as sharp? Furthermore, while non-iid settings are nice to have, to me it seems that this method might suffer in less non-iid / iid settings (e.g, $\\alpha=1.0$, $\\alpha=\\inf$) ; the generative distribution is more diverse and thus it would be harder to model accurately with a, hardware constrained, VAE model. This can also sort of be seen when comparing FedCVAE-KD to FedCVAE-Ens; the former has worse performance that the latter, given that the entire training distribution needs to be modelled by a single model. How does the performance of the method scale with higher values of $\\alpha$? Besides that, it seems that the evaluation against the baselines is not entirely apples-to-apples; for example, FedOneShot does not need to reveal to the server the labels and the models trained on the local data, so it has fundamentally different security / privacy tradeoffs. \n",
            "summary_of_the_review": "While the concept of FedCVAE is straightforward, it is novel in the federated setting. Having said that, given my aforementioned comments, around the auxiliary classifier, security / privacy and experimental evaluation, I cannot recommend acceptance of this work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_TDXe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_TDXe"
        ]
    },
    {
        "id": "7l3T4OTAii",
        "original": null,
        "number": 3,
        "cdate": 1667500553932,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667500553932,
        "tmdate": 1669999505840,
        "tddate": null,
        "forum": "_hb4vM3jspB",
        "replyto": "_hb4vM3jspB",
        "invitation": "ICLR.cc/2023/Conference/Paper1248/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces two methods, FEDCVAE-ENS and FEDCVAE-KD, for one-shot federated learning with extreme data heterogeneity among clients. Once client models are trained using conditional variational auto-encoder (CVAE) architectures, the decoders, alongside label distributions of all clients, are uploaded to the server. FEDCVAE-ENS creates an ensemble of synthetic data samples created via all client decoders to create a dataset that can be used to train a centralized classifier at the server. FEDCVAE-KD, on the contrary, trains a centralized decoder at the server using knowledge distilled from the client decoders. The trained decoder is then used to create a dataset of synthetic samples, which is used to train the centralized classifier. Simulation results show that i ) the proposed methods considerably outperform baselines when the data samples are very heterogeneous, and ii) using the CVAE architecture enables a security-promoting extension of the proposed methods that prevents an eavesdropper from training a well-performing centralized classifier.",
            "strength_and_weaknesses": "The paper is very well written and easy to follow. The numerical experiments are well executed and show promising performance achieved by the proposed methods.\n\nThat being said, there are some downsides that, in my opinion, slightly outweigh the strengths of the paper. On the problem formulation side, I believe the one-shot federated learning (FL) problem is not very well motivated; the point of FL is to enable training models at different clients by leveraging each others' data through communication without explicitly sharing them. In a one-shot scenario, the problem essentially reduces to having a set of models, which need to be aggregated into a single, universal model, so I am still not convinced how the \"federated\" aspect of the problem is of the essence.\n\nOn the contributions side, the main issue I have with the paper is a lack of a central, key novelty. In its current form, the paper is mostly a collection of different ideas, namely two algorithms that are almost independent of each other, as well as a security aspect, which is again mostly orthogonal to the proposed methods. To me, what would make this paper much stronger is to focus on only one of these algorithms/aspects throughout the paper. For example, since the performance of FEDCVAE-KD is better than baselines, I believe it would be better to focus on this algorithm in the main body of the paper, and add the ensemble version of the algorithm (which, as the authors allude to, requires a higher amount of memory that scales with the number of clients) as an extension, in a separate discussion section toward the end of the paper and/or in the appendix. Moreover, the security and privacy considerations are definitely important, but including them in the main body of the paper stretches it too thin, in my opinion.\n\nFurther comments:\n\n- Aside from the solid empirical performance, are there any intuitive/theoretical explanations as to why the proposed methods are well suited for i) *one-shot* FL, and ii) *high heterogeneity* FL? As presented, I cannot see a clear motivation for why the proposed methods should perform better in the considered problem formulation.\n- Please discuss whether or not sharing local label distributions with the server violates the privacy of clients' data. How do the proposed methods perform if this information is unavailable at the server?\n- Presenting the flowchart figure for only one of the proposed methods (FEDCVAE-KD) in Figure 2 and not including any of the algorithms for the two proposed methods makes the paper slightly incoherent, without switching back and forth between the body of the paper and the appendix. I suggest rearranging the contents to remedy this issue as best as possible by at least having both the figure and algorithm for one of the methods or having the figures for both methods in the main body of the paper.\n- In the first footnote on page 4, why is a uniform distribution used for sampling $\\mathbf{z}$? Why not, for example, use a truncated Gaussian distribution?\n- In my opinion, including FedAVG is slightly unfair in the experiments. Under FedAVG, a set of client model parameters $\\\\{\\mathbf{w}^k\\\\}_{k=1}^m$ are aggregated using a simple average, i.e., $\\mathbf{w}=\\frac{1}{m} \\sum_\\{k=1\\}^m\\mathbf{w}^k$. In a very heterogeneous case, each of these model parameters is the minimizer of a very different objective function over an entirely different optimization landscape, so it is completely expected that a linear averaging of these model parameters should lead to inferior performance, especially if the averaging operation is done only once.\n- Following the above comment, I believe your primary competing baseline is FedONESHOT, so I suggest adding more details on this algorithm's main idea.\n- Do you have any explanation as to why the standard deviation of the performance of the proposed methods is, on average, larger under SVHN in Table 2?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well-written, and the algorithms are described precisely enough for the results to be reproducible. The novelty of the paper and its contributions are marginal, in my opinion.",
            "summary_of_the_review": "I think this is a borderline paper with clear positive aspects, but one that needs some content streamlining and restructuring, as well as stronger motivation so that the contributions are better appreciated.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_mEpo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_mEpo"
        ]
    },
    {
        "id": "3ZtCaGvhH5-",
        "original": null,
        "number": 4,
        "cdate": 1667515794599,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667515794599,
        "tmdate": 1667515794599,
        "tddate": null,
        "forum": "_hb4vM3jspB",
        "replyto": "_hb4vM3jspB",
        "invitation": "ICLR.cc/2023/Conference/Paper1248/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers one-shot federated learning under high statistical heterogeneity. They propose a data-free FL mothods FEDCVAE-ENS and its extension FEDCVAEKD. Conditional variantional autoencoders(CVAE) are trained locally and then the decoders are sent to the server. At the server, either ensemble or knowledge distillation is used to generate an ensemble dataset which is later used to train the final model. The paper conducts experiments on three datasets to demenstrate its effectiveness under high statistical heterogeneity.",
            "strength_and_weaknesses": "### Strength\n\n* The proposed method of one-shot FL is very interesting and novel.\n* The proposed method doesn't require auxiliary public dataset.\n* Both security and privacy extensions are considered in the paper.\n* It can be applied to heterogeneous local models with similar generative capabilities.\n\n### Weaknesses\n* One potential issue of the method is training a CVAE locally. In the paper, the images used in the dataset are very small, and the amount of data each client has is large. However, in the real-world application of FL like medical imagings, with very large images and very limited number of data samples, training a CVAE locally can be difficult even just for one class of data.\n* The training task of local models is different from the original task. This limits the re-use of pre-trained local model from original task. I think one of the reasons that people want to do one-shot FL is to prevent any re-training locally. But the proposed method still requires to train some new model.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall clarity and quality of the paper is good. The method proposed is novel. Details for reproducibility are provided in the paper.",
            "summary_of_the_review": "The idea of the paper is novel and interesting. Although in real applications with larger images and limited data samples, it may not work very well, it provides a novel perspective of doing one-shot FL.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_nh59"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1248/Reviewer_nh59"
        ]
    }
]