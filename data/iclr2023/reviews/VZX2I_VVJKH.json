[
    {
        "id": "8-m235esy5",
        "original": null,
        "number": 1,
        "cdate": 1666522265494,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666522265494,
        "tmdate": 1670801847982,
        "tddate": null,
        "forum": "VZX2I_VVJKH",
        "replyto": "VZX2I_VVJKH",
        "invitation": "ICLR.cc/2023/Conference/Paper5149/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a local conditional probability model for images in multiscale representations.\nIn this model, the probability of the high-frequency (detail) components is conditioned to the low-frequency (low-resolution) component, and these conditional relations are spatially local. The probability of the final low-resolution residual is modeled globally. \n\nBoth the conditional probabilities and the probability of the low-resolution residual are learnt by CNN denoisers using the relation between the denoiser errors and the gradient of the probability of the signal.\n \nThe local (Markov) structure of the conditional probabilities means that the parameters (receptive fields) of the CNNs are restricted to the local neighborhood and hence the conditional part of the model is relatively low dimensional. This assumes that the conditional relations at each scale are essentially stationary (or translation invariant). \n\nHowever, the receptive fields of the CNN to model the probability of the low-pass residual have to be the same size as the residual in order to capture its non-stationary nature. The requirement of dense connection for the low-pass residual is the main limitation of the proposed model in terms of dimensionality.",
            "strength_and_weaknesses": "STRENGTHS:\n\nThe paper should be accepted because it builds an explicit image probability model as opposed to implicit (non-accessible) models of autoencoders, GANs, normalizing flows, or diffusion methods. These results are an interesting connection between the efforts of (1) linking the gradient of the PDFs with optimal denoising [Miyasawa61, Raphan&Simoncelli11, Vincent11], and (2) establishing conditional relations between low-frequency and high-frequency aspects in spatial neighborhoods of natural images [Buccigrossi&Simoncelli99, Marchand et al.22].\n \nWEAKNESSES:\n\n* The model reminds me of other recent conditional models such as the PixelCNN [van den Oord et al.16, Salimans et al.17].\nI guess the key difference is the formulation in a multiscale representation instead of in the input spatial domain.\nThe authors already compare with CNN models in the spatial domain. I think it would be interesting for the reader to see some example with more sophisticated conditional models in the spatial domain such as the PixelCNN. Of course, in this comparison the size of the images should be big enough for a couple of scales but small enough for proper training of pixelCNN.\n\n* The authors acknowledge the main limitation of their proposal in the discussion \"the non-stationary capabilities of the full model arise primarily from the terminal low-pass CNN, which uses global receptivie fields\". I think this should be acknowledged from the very beginning (in the abstract and/or intro) because the interesting conditional relations (the core of the proposal) always need \"a seed to grow\" which is modeled in a conventional way.\n\n* The dimensionality of the model is small because the Markov structure is spatially local (the interesting theorem 1).\nCould we get extra reductions in the parameters using locality in the orientation and in the scale in redundant wavelets?\nNote that nonorthonormal wavelets could also be applied since it would only imply the consideration of the determinant |W| in Eq. 1, right?. This would mean the extension to orientation and scale of the locality concept applied in space.\n\nREFERENCES:\n\n* van den Oord et al. 16a, Salimans et al.17 Conditional Image Generation with PixelCNN Decoders NeurIPS 2016 arxiv 1606.05328\n\n* van den Oord et al. 16b Pixel Recurrent Neural Networks ICML 2016 arxiv 1601.06759\n\n* Salimans et al.17 PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications ICLR arxiv 1701.05517\n\nMINOR COMMENTS:\n\n* You could cite Marchand et al. 22 the first time you mention that the conditional can be modeled with conditional Gibbs energies (Eq. 2)\n\n* The first paragraph of section 5 mentiones the super-resolution problem and it does not mention the synthesis problem, but then, the next paragraphs alternate between one problem and the other. The two problems should be mentioned at the begining to avoid confusion.\n\n* The proof of Eq. 5 (appendix B) already was done in Raphan&Simoncelli 11, right?. Why not just cite that? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the writing/math is clear and interesting\nQuality and novelty: high because it makes explicit models that are regularly hidden\nReproducibility: I missed links to code",
            "summary_of_the_review": "The paper should be accepted because it builds an explicit image probability model as opposed to implicit (non-accessible) models of autoencoders, GANs, normalizing flows, or diffusion methods. These results are an interesting connection between the efforts of (1) linking the gradient of the PDFs with optimal denoising [Miyasawa61, Raphan&Simoncelli11, Vincent11], and (2) establishing conditional relations between low-frequency and high-frequency aspects in spatial neighborhoods of natural images [Buccigrossi&Simoncelli99, Marchand et al.22]. Experimental results successfully show the good performance of the proposed model. \n\nHowever, some elaboration would be appreciated on: (1) advantages over alternative conditional models (such as PixelCNN) in experiments, (2) acknowledgement of the central role of the low-pass component (not a core of the proposal), (3) possible extensions of the locality concept in space to orientation and scale.\n\nMy current score is 7, but I will be happy to raise to 8 or 9 it if the authors address the suggested points.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_KhB3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_KhB3"
        ]
    },
    {
        "id": "PRLc3fqlkBe",
        "original": null,
        "number": 2,
        "cdate": 1666736043095,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666736043095,
        "tmdate": 1670804192183,
        "tddate": null,
        "forum": "VZX2I_VVJKH",
        "replyto": "VZX2I_VVJKH",
        "invitation": "ICLR.cc/2023/Conference/Paper5149/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a multi-scale conditional probability model to reconstruct and denoise images. Specifically, the scales come from wavelet transform, and they generalize Markov conditional models by parametrizing the conditional gradients with a CNN with a local receptive field. They show how their method performs better than Markov methods conditioned and performed in the pixel domain. They study the effect of the receptive field. They use a previously proposed method to generate new images, i.e., to perform gradient ascent on the log probability of the learned CNNs to draw samples from the learned image distributions. They show applications in denoising, synthesis, and super-resolution.\n",
            "strength_and_weaknesses": "The paper shows the application of their method in several image tasks (generation, denoising, super-resolution).\n\nThe paper can improve on clarity. It is not clear what their contribution is from a general perspective on the performed tasks (e.g., denoising and super-resolution, generation). Please explain the advantages of your method compared to other general frameworks used for super-resolution, denoising, etc. It is not shown how their framework performed against multiple baselines. There seems to be only one method that they compared with which is the vanilla version of their Markov method. Here are detailed comments.\n\nLack of sufficient baselines:\n- By using local convolutional filters and learning locally, their method alleviates the curse of dimensionality; However, how is their method compared to other popular methods in the literature in terms of performance, computational complexity, runtime, etc? (Perhaps, a quantitative comparison between their method and the cited methods on the last paragraph of page 8 is suggested)\n- It is nice to see (in Figure 3) that their method outperforms a similar approach of Markov probability in the pixel domain. However, more experiments with non-Markov baselines should be included. How is the performance of this method for example compared to generic deep learning (e.g., DnCNN bias-free) for denoising, super-resolution, etc?\n\nThe literature review needs proper citations. Here are some examples in the introduction. Please provide citations to\n- the second line in the intro talks about dimensionality.\n- the fourth line in the intro refers to traditional methods.\n- the last line of the first paragraph in the intro refers to global models.\n\nIt is hard to see the relationship between the conditional CNN and (3). Can the authors explain?\n\nA thorough experimental analysis would be nice to add to the characterization of their method: how the performance changes as the number of wavelets, and the depth of scale change.\n\nIt is not clear if the models are trained on the same noise level compared to the test noise or a range. Please clarify and add such information.\n\nHow is the performance on natural images?\n\nIt is not clear how the right image in Figure 6 is generated. Please elaborate on \"CNN denoiser with TF smaller than the image\".\n\nMinor comments\n\n- Moving Figure 2 to the second page will help to understand the - model.\n\n- Why the first row of Figure 4 is smaller? Please fix.\n\n- Elaborate on the statement after Figure 4: \"... less than three percent of the coefficients\".",
            "clarity,_quality,_novelty_and_reproducibility": "The paper needs improvement in clarity and organization. For example, it would be nice if in terms of bullet points the authors can indicate the contributions of this paper and how it differs from prior works, and how it benefits the ICLR community. The method is novel in how it combines ideas to scale up wavelets. ",
            "summary_of_the_review": "The paper proposes a method to generalize multiscale wavelets and markov models to learn conditional distributions of wavelets to recover images. The method needs a thorough experimental study to show its performance against other learning frameworks and to clearly explain how its method differs from prior works and its advantages. Hence, the paper in its current form is not recommended for acceptance.\n\n\n-----------\n\n Given the authors' responses, I have raised my score to 8.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_Pfsy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_Pfsy"
        ]
    },
    {
        "id": "dsudOTEU-ue",
        "original": null,
        "number": 3,
        "cdate": 1666880319354,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666880319354,
        "tmdate": 1670810915415,
        "tddate": null,
        "forum": "VZX2I_VVJKH",
        "replyto": "VZX2I_VVJKH",
        "invitation": "ICLR.cc/2023/Conference/Paper5149/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper generalizes a Markov wavelet conditional probability model developed based on the renormalization group theory. The model is parameterized using conditional CNNs with local receptive fields, which enables stationary Markov properties. The method is extended to handle several face image reconstruction tasks, e.g. image denoising and synthesis. The results show that the model can capture image features with a small receptive field,",
            "strength_and_weaknesses": "Strength:\n\n- This work is well-motivated.\n- This paper addresses an important problem in learning prior probability models of images. \n- The paper seems to be solid.\n- Two application scenarios are provided with technical details.\n\nCons:\n- The image reconstruction results can be further improved.\n- There is no comparison with the state-of-the-art methods on the two mentioned tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has its novelty. The quality of the paper presentation is very good. The paper is reproducible.",
            "summary_of_the_review": "This is a well-written paper with solid theoretical content. The experiments are insufficient. Given the theoretical nature of the paper, this can be somehow tolerated.\n\nThe authors' responses have well addressed by concerns. I have raised the empirical novelty and significant score and also raised the final recommendation to 8.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "The source of the face dataset has not been mentioned. It is not clear whether human ethics has been approved or not.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_CgEx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5149/Reviewer_CgEx"
        ]
    }
]