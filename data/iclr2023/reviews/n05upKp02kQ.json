[
    {
        "id": "JWmXeLrf5o",
        "original": null,
        "number": 1,
        "cdate": 1666544027659,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666544027659,
        "tmdate": 1666544063954,
        "tddate": null,
        "forum": "n05upKp02kQ",
        "replyto": "n05upKp02kQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3290/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper addresses theoretical aspects of sample based inference in partially observable RL problems. In particular, the paper adopts PSR formalism, and proposes B-stability, a structural condition that subsumes several common tractable practically observable RL problems. The paper shows  several algorithms for B-stable PSRs and argues that they have sharp sample complexities for this class of problems.",
            "strength_and_weaknesses": "Strengths: the paper is clearly written, gives a detailed account of related work and necessary background, and introduces a new property, B-stability, which is intuitive and possessed by several important classes of partially observable RL problems. This opens up directions for research related to details of proposed algorithms, learning of B-stable PSRs, and computational issues.\n\nWeaknesses: the paper is of theoretical nature, and as such relies on definitions and proofs of theorems related to B-stability and algorithms. The proofs are not a part of the body of the paper but rather of the appendices, and the full length to be read to understand and check correctness is in excess of 40 pages. I tried to dive into the appendices but didn't have enough time and cannot confirm that the proofs are correct.  My humble opinion is that the paper, with all the contributions which it claims, is perhaps to long for a conference, either the reviewing process or presentation later on. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well organized. The contribution is incremental  --- which by no means a negative comment: building on the body of previous work is, in my opinion, an advantage of this research. However, since the paper is theoretical and most of the results can only be evaluated by careful verification of proofs in the appendices, 'reproducibility' is questionable (is reproducibility of a theoretical paper means being able to prove the results from the paper alone?)",
            "summary_of_the_review": "The paper is interesting, inspiring, and well written, however I am wondering whether it is the right paper for a conference. I cannot assess correctness of claims based on the paper only, and did not have enough time to go thoroughly through the proofs in the appendices. I would prefer a conference paper to be self-contained rather than an extended abstract of appendices significantly exceeding the paper in size.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_jF7R"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_jF7R"
        ]
    },
    {
        "id": "Gsd70LNyP2",
        "original": null,
        "number": 2,
        "cdate": 1666597372596,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666597372596,
        "tmdate": 1666597372596,
        "tddate": null,
        "forum": "n05upKp02kQ",
        "replyto": "n05upKp02kQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3290/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies online reinforcement learning in the general setting of Predictive State Representations (PSRs) with a finite horizon. The authors propose a unified condition for PSRs called B-stability, which encompasses the vast majority of known tractable subclasses such as weakly revealing POMDPs, low-rank future-sufficient POMDPs, decodable POMDPs, and regular PSRs. The authors then provide novel online RL algorithms that could learn B-stable PSR with polynomial samples in relevant problem parameters and can outperform existing methods in the aforementioned subclasses.",
            "strength_and_weaknesses": "This paper provides a unified theoretical framework for online learning in PSRs. The proposed framework, called B-stability, subsumes several known tractable subclasses of models in the literature. I have not read through all details of the proof. However, the PAC results in Theorem 9 seem reasonable. Given the importance of latent representation learning and the relevance of partially observable RL, the unified theoretical framework in this paper could have an impact across different fields of machine learning.\n\nAs for the weakness, this paper is certainly notation heavy. While some of them might be inevitable given the technical nature of this paper, some of the notations are not well defined. For instance, it would be appreciated if the authors could further elaborate on Step 6 of OMLE. It is unclear how the exploratory policy is being set.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is mainly theoretical. The main results seem technically sound. Detailed proofs are provided in Appendix. The idea of developing a unified theoretical framework for online learning in PSRs is certainly novel, and could have impact across disciplines in machine learning.",
            "summary_of_the_review": "This paper provides a unified theoretical framework for online learning in PSRs. The proposed framework, called B-stability, subsumes several known tractable subclasses of models in the literature. Given the importance of latent representation learning and the relevance of partially observable RL, the unified treatment presented in this paper could have an impact across different fields of machine learning.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_PmjQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_PmjQ"
        ]
    },
    {
        "id": "zxmdwPz5cut",
        "original": null,
        "number": 3,
        "cdate": 1666672639372,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672639372,
        "tmdate": 1666720718711,
        "tddate": null,
        "forum": "n05upKp02kQ",
        "replyto": "n05upKp02kQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3290/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The submission considers a sample-efficient learning for PSRs, extending some recent works by (Liu et al., 2022) from POMDPs to PSRs. In some sense, this paper marginally extends a recent work (Zhan et al., 2022) which already claims almost the same contribution. The suggested B-stability is a slightly more general condition than the regularity condition suggested in (Zhan et al., 2022). Just like (Zhan et al., 2022), the algorithm of interest is O-MLE (Liu et al., 2022), and results obtained for PSR can imply several previous results. Proof ideas and techniques are also mostly adopted from (Liu et al., 2022), though there are some differences in technical details from (Zhan et al., 2022). \n\nI think the real contribution of this paper could be an improved sample-complexity analysis of O-MLE, which improves some polynomial factors from previous bounds. The paper also makes connection to decision-estimation coefficient (DEC) first proposed by (Foster et al., 2021), and propose another posterior-sampling based algorithm in parallel. This is also interesting on its own, though slightly off from the main flow of the paper in my opinion. ",
            "strength_and_weaknesses": "\n*Strength*\n\n- The paper is very comprehensive -- the framework is quite general and can imply many previous results with improved upper bounds. \n\n- It is interesting to see the connections with DEC. \n\n\n\n\n*Weaknesses*\n\n- In a current form, the paper sounds in nature too similar to (Zhan et al., 2022). It would have been better to position the paper by, for example, focusing more on the technical innovations to get better sample-complexity. \n\n- The term \"sharp\" is used in several places to emphasize that the upper bound analysis is improved from previous work, but I think this term is somewhat conventionally used when the upper bound matches the lower bound which is not discussed in the paper. \n\n- It is somewhat hard to appreciate the proposed B-stability condition (maybe it is too abstract? or only algebraically explained?). This is a personal opinion but impacts my overall impression of the paper. If there is a better and more intuitive explanation for this, it would be great. ",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is in general very clear. But the paper could be hard for broader audience to read. In terms of originality, I feel that the paper could have emphasized more on technical innovations. ",
            "summary_of_the_review": "Overall, I think the paper provides very comprehensive and advanced results which could be of significant interest to RL theory community. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_PDoA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3290/Reviewer_PDoA"
        ]
    }
]