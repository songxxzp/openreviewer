[
    {
        "id": "VKBTmjOojRn",
        "original": null,
        "number": 1,
        "cdate": 1666607387873,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607387873,
        "tmdate": 1666607387873,
        "tddate": null,
        "forum": "mE91GkXYipg",
        "replyto": "mE91GkXYipg",
        "invitation": "ICLR.cc/2023/Conference/Paper4266/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an interesting prompt tuning method for video relation detection. It includes compositional and motion related cues. \n\nThe authors also propose a new task, called Open VIdVRD, which further considers unseen relationship combinations and unseen objects/motions.",
            "strength_and_weaknesses": "Strengths:\n1. The authors propose to add the composition capability and motion cues to the prompt, making it more robust and less biased for video relation detection. The idea is new.\n2. The design of multi-mode (multiple different motion patterns) prompt groups is interesting.\n3. The paper is well-written and easy to follow. \n4. The authors conducted several experiments to verify the effectiveness of their method. It shows comparable results when comparing to VidVRD SOTA. In their ablation study, their open-vocabulary-based results are better than the baselines.\n\nWeaknesses:\n1. The motion pattern design seems to be complex and not easy to handle a variety of motions. While the use of GIoU is nice, the current design considered only toward/away and near/far. It is difficult to extend to generic motions with GIoU. Since the current design of motion group is very limited, the strong performance improvements are less convincing to be attributed to motion cues.\n2. In the comparison with traditional VidVRD, one may wonder the performance of the proposed model if adding novel samples.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed learnable compositional prompt is new and interesting.",
            "summary_of_the_review": "Overall the proposed method is novel and interesting. However, the design of motion cues seems limited in current stage. It still requires hand-craft effort or expert knowledge.\n\nThe introduced task is a good addition to VidVRD dataset. Results on open-vocabulary setting are good compared to baseline variants.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_K5Cm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_K5Cm"
        ]
    },
    {
        "id": "8NQelnShjn",
        "original": null,
        "number": 2,
        "cdate": 1666644206854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666644206854,
        "tmdate": 1666648156443,
        "tddate": null,
        "forum": "mE91GkXYipg",
        "replyto": "mE91GkXYipg",
        "invitation": "ICLR.cc/2023/Conference/Paper4266/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new approach to video visual relation detection that is based on extension of compositional prompt tuning with motion cues. The Relation Prompt (RePro) is designed to address the technical challenges of Open-vocabulary Video Visual Relation Detection: the prompt tokens should respect the two different semantic roles of subject and object while the tuning should account for the diverse spatiotemporal motion patterns of the subject-object compositions. They achieves a new state-of-the-art performance on two VidVRD benchmarks of not only the base training object and predicate categories, but also the unseen ones.",
            "strength_and_weaknesses": "Strength\n- They proposes a novel setting for video visual relation detection task, Open-VidVRD.\n- They clearly describe interesting idea in this paper. The compositional prompt representation learning method that models the prompt contexts for subject and object separately. the motion-cue-based prompt groups shows good generalization ability on the tasks.\n\nWeakness\n- The novelty is limited. The paper claims that the first one to research on the the open vocabulary video visual relation detection, but the open vocabulary VRD has been widely studied in visual domain, which potentially could be compared.\n- The motivations in evaluation section, and ablations of the proposed approach is not easy to follow.\nIt's also hard to follow how the proposed approach improves the performance on the Open-VidVRD benchmark. ",
            "clarity,_quality,_novelty_and_reproducibility": "- The main idea is interesting and the work is well-written and easy to follow. \n- The proposed method is clearly described and the results has potential impact.\n\n- They partially shared their code, and hyper parameter settings. The results are reproducible.\n",
            "summary_of_the_review": "This paper proposes a new method for several technical challenges of Open-vocabulary Video Visual Relation Detection, and also provides useful prompt group that can be generalized. The paper shows the video visual relation detection is generalizable with the proposed framework. The proposed video visual relation detection task is very interesting, but I would appreciate if the author can clarify the evaluation and motivation behind the design. Overall, I lean toward acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_Nj5q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_Nj5q"
        ]
    },
    {
        "id": "bgaH2nMlmF",
        "original": null,
        "number": 3,
        "cdate": 1666682823415,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682823415,
        "tmdate": 1666682823415,
        "tddate": null,
        "forum": "mE91GkXYipg",
        "replyto": "mE91GkXYipg",
        "invitation": "ICLR.cc/2023/Conference/Paper4266/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a new task called Open-vocabulary VidVRD, where the aim is to detect not only unseen relationships but also unseen objects and predicates. They propose a novel pipeline (i.e. RePro) to detect tracklets and classify the relations between tracklets. In particular, the proposed approach is a compositional and motion-based relation prompt learning framework. In the experiments, the authors show rich experiments, including various ablation studies. ",
            "strength_and_weaknesses": "**Strengths:**\n\n* The paper is well written. \n\n* The authors have introduced an interesting problem and proposed a novel solution for the problem. Further, they showed rich experimental results. \n\n**Weaknesses:**\n\n* What is the difference between visual embeddings ($\\mathbf{v}_i^O$) and RoI Aligned features ($\\mathbf{f}_i$) in Sections 3.1 and 3.2?  \n\n* Figure 3 mix-uses texts (e.g. \"dog\", \"child\") for both visual features and categories. \n\n* The experimental settings in Section 4.4 is not clear. Did the authors use the same tracklets for the comparisons in Tables 3 and 4? This reviewer is unsure if the comparisons are valid. \n\n* Typos:\n    * \"we distil the knowledge ...\" in Line 172\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity, Quality, Novelty:** \nThe paper is well-written, and it shows enough novelty. \n\n**Reproducibility:**\nThe authors added a separate section to discuss reproducibility. They also provide the code, but this reviewer hasn't checked the code.\n",
            "summary_of_the_review": "The paper introduces an interesting task and a framework to solve the task.\nSome parts are still unclear, and this reviewer left the questions in the Weaknesses section. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_Fty6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_Fty6"
        ]
    },
    {
        "id": "y33Xtdswomf",
        "original": null,
        "number": 4,
        "cdate": 1666715686668,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666715686668,
        "tmdate": 1666715686668,
        "tddate": null,
        "forum": "mE91GkXYipg",
        "replyto": "mE91GkXYipg",
        "invitation": "ICLR.cc/2023/Conference/Paper4266/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "- The paper considers the problem of video visual relation detection under an open-vocabulary scenario.\n\n- The main contribution is on prompt learning to adapt the strong visual-language model towards downstream tasks.\n\n- To enable the open-vocabulary, the prompt learning has exploited two techniques, namely, the compositional prompt representation, and motion-based prompt groups, which makes sense.\n\n- The idea has been evaluated on various datasets, and show clear performance improvements.",
            "strength_and_weaknesses": "Strength\n\n- The idea is simple, using compositional prompt and exploiting motion information do generate prompt do make sense in the video visual relation detection task.\n\n- The results have clearly validate the claims, demonstrating state-of-the-art performance under various settings.\n\nWeakness:\n\n- The writing is not satisfactory, it can surely be better.\n\n- Missing many references from ECCV: \n[1] https://arxiv.org/abs/2112.04478\n[2] https://arxiv.org/pdf/2208.03550\n[3] https://arxiv.org/abs/2208.02816\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity : OK\n\nQuality: good\n\nNovelty: good\n\nReproducibility: the writing is not ideal, which makes it a bit difficult to reproduce, unless the author will release the code.",
            "summary_of_the_review": "Overall, I think I like this paper, I like the motivation for solving downstream video tasks with prompt learning, the idea of using composition prompt generation for predicate is good, and exploiting motions makes sense in video understanding tasks.\n\nHowever, the paper writing needs a lot improvement, now it's very hard to grasp the key ideas, too many notions, and unnecessary equations.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_QLPW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4266/Reviewer_QLPW"
        ]
    }
]