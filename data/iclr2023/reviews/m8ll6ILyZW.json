[
    {
        "id": "qydV-Fwxpr",
        "original": null,
        "number": 1,
        "cdate": 1666465747966,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666465747966,
        "tmdate": 1666465747966,
        "tddate": null,
        "forum": "m8ll6ILyZW",
        "replyto": "m8ll6ILyZW",
        "invitation": "ICLR.cc/2023/Conference/Paper3135/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes multi-segmental informational coding as a new embedding scheme for self-supervised representation learning which divides an embedding vector into multiple segments to represent different types of attribute, and as a result each segment automatically learns a set of discrete and complementary attributes. The proposed model enables the estimation of the probability distribution over discrete attributes and thus the learning process can be directly guided by information measurements, reducing the feature redundancy beyond the linear correlation.",
            "strength_and_weaknesses": "**Strengths**\n\n(1) The proposed method is based on an interesting idea of segmenting representation and estimating the probability distribution over discrete attributes, which I think is relatively new.\n\n(2) The paper has considered standard benchmarks for experimentations to demonstrate the effectiveness of the proposed method, where the MUSIC model has performed consistently.\n\n(3) The paper is theoretically well grounded and the authors have shown that the optimal MUSIC embedding features have zero covariance between any two features in different segments and negative covariance between the features within the same segment.\n\n**Weaknesses**\n\n(1) The proposed method have achieved minor improvement on very few datasets, whereas on the other datasets, the method couldn't surpass the state-of-the-art methods, which fails to justify the superiority of the proposal.\n\n(2) The method is nicely motivated by the idea of multi-segmental discretisation, but the evidence that the learnt representation follows intuition is largely missing. At the moment, there is only one example in appendix C, but more such visualisation would have been useful and interesting.\n\n(3) It is not clear or evident what information those individual segments are learning. Also the number of segments should be correlated with datasets and also on the size of crops, which have not been ablated in the paper at this stage and decided in an adhoc manner.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear and understandable. It is well written in good English and the reported results are encouraging but not optimal. The authors have provided pseudocodes in the supplementary material which I expect to be useful for the reproducibility of the method. Therefore, I think the proposed method has a lot of scope, but proper evidence and justifications are missing in some cases.",
            "summary_of_the_review": "I have found the paper very interesting. The paper is theoretically justified. Some experimental or evidential issues evidences are there (mentioned in the weaknesses section) should be improved.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_f3VU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_f3VU"
        ]
    },
    {
        "id": "U5uCAjMd4K",
        "original": null,
        "number": 2,
        "cdate": 1666572690386,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666572690386,
        "tmdate": 1666572690386,
        "tddate": null,
        "forum": "m8ll6ILyZW",
        "replyto": "m8ll6ILyZW",
        "invitation": "ICLR.cc/2023/Conference/Paper3135/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presented a new method for self-supervised image representation learning. Specifically, a multi-segmental informational coding (MUSIC) scheme was proposed to achieve a new feature embedding, which divided the projected feature vector into multiple segments to represent different attributes. The loss function was then designed to maximize the entropy between segments and units within them. Experimental analysis on a few public datasets over benchmark vision tasks shows the effectiveness of the proposed method. The main contribution is the proposed MUSIC coding scheme.",
            "strength_and_weaknesses": "## Strengths\n\n\\+ The proposed idea of minimising the mutual information between different attributes is interesting.\n\n\\+ An analysis section (Sec. 2.4) was presented to help better understand the proposed method.\n\n\\+ An empirical analysis (Sec. 4.2) was provided to evaluate the components within the proposed method.\n\n\\+ The paper is in general well written and easy to follow.\n\n\n## Weaknesses\n\n\\- The proposed method seems to be a disentangle approach for the projected feature vector, which was defined to be within several semantic categories (i.e. the segments as illustrated in Fig. 1). But it is unclear how it was guaranteed to have these semantic meanings for a projected vector. The evenly splitting of the vector was also not well justified.\nOn the other hand, although the projected vector was divided into several segments/attributes, the whole vector is in principle representing the same feature as without such partition. It is unclear, as a result, why this would introduce the claimed attributes information into the representation learning. The experimental results also did not suggest any noticeable improvement over previous works in representation learning.\nIt would be better if some examples/qualitative results could have been shown to validate that the claimed segments were actually related to the particular semantics.\n\n\\- The novelty and contributions of the proposed method are a bit limited. Considering that the general idea and framework are quite similar to prior works on self-supervised representation learning (e.g. SimCLR, BYOL, Barlow twins to name a few), the only difference is the final projected feature processing and the following loss to supervise the network training. Whereas apart from the segments part, even the entropy maximization is quite similar to the approach proposed in Barlow twins and VICReg in a high-level idea.\n\n\\- It is a bit unclear how the \"theoretical analysis guarantees\" the proposed model learns non-trivial, diverse and discriminative features, especially the discriminative features.\n\n\\- The performance of the proposed method is only comparable to several prior works and even worse than some of them (e.g. BYOL, Barlow Twins, VICReg). It is hard to tell and be convinced of the effectiveness of the proposed method and its significance.\n\n\\- The authors discussed the idea of hierarchical clustering in the last section, which is nice to see. This also relates the proposed method to the clustering-based approaches. It would be better to discuss and differentiate the proposed segment-based idea and those clustering-based ideas (e.g. DeepCluster, SwAV etc.) for visual representation learning, especially what is the benefit of the proposed method over those approaches.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality of the work are generally good, but with a few unclear statements that need further clarification, as mentioned above in the Weaknesses part. The novelty is a bit limited, considering similar prior works and the high-level idea of optimizing mutual information (or entropy). This work should be easy to be reproduced, as the PyTorch-style pseudo-code has been provided.",
            "summary_of_the_review": "The main idea of this paper is interesting and seems to make sense in self-supervised visual representation learning. But it was not well presented with sufficient evidence to justify the claims (the segments and attributes part). The experimental performance was also insufficient to support the claimed effectiveness of the proposed method. The overall technical novelty and contributions are also a bit limited.\nAs a result, this paper is considered to be not ready for publication. But the authors are encouraged to provide more details and justifications of the proposed method and the claimed contributions and re-submit to a future venue.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_ZcT3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_ZcT3"
        ]
    },
    {
        "id": "TszVK76rzV",
        "original": null,
        "number": 3,
        "cdate": 1666618346221,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618346221,
        "tmdate": 1666618508175,
        "tddate": null,
        "forum": "m8ll6ILyZW",
        "replyto": "m8ll6ILyZW",
        "invitation": "ICLR.cc/2023/Conference/Paper3135/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a self-supervise learning method using an entropy loss across multi-segments embedding vectors (MUSIC). This method automatically learn different types of attributes in each of multi segments.  Unlike the contrastive learning and its variants, it does not require negative samples in a large batch memory and asymmetric network, gradient stopping, or momentum update. Theoretical analysis support that the MUSIC embedding is transform-invariant, non-trivial, diverse, and discriminative. A set of downstream tasks show that the propose representation learning method is comparable to or outperforms previous states-of-the-arts. An empirical analysis investigates the efficiency in training , the effect of projector depth and feature dimension, and the necessity of the proposed loss function. \n\n\n    ",
            "strength_and_weaknesses": "Strengths\n- The information-theoretic entropy loss is well supported by the theoretical analysis  \n- Model training is efficient as it does not require a large match memory to include negative samples\n-The overall performance is comparable to or outperforms previous states-of-the-arts in several downstream tasks \n- The empirical study is comprehensive to understand the capability of the proposed method. \n\nWeakness\n- Some related work is missing. Recently, there have been a decent number of dense contrastive learning which divides the embedding space into small multi-vectors and exploits their correspondence. For, example,\"Dense Contrastive Learning for Self-Supervised Visual Pre-Training\", Xinlong Wang, Rufeng Zhang, Chunhua Shen, Tao Kong, Lei Li, CVPR, 2021,  \"Dense Siamese Network for Dense Unsupervised Learning\", Wenwei Zhang, Jiangmiao Pang, Kai Chen, Chen Change Loy, ECCV, 2022\n- The paper argues that MUSIC divides an embedding vector into multiple segments that represent different types of attributes such as object part, texture, and shape. However, this hypothesis was never proved. There is no insightful analysis that the multiple segments capture the different visual attributes exclusively.  Although the hypothesis and analogy in Figure 1 may help delivering the \"intended idea\", it would be risky to insist that the model actually learn the features in that manner. \n- Some part of writing is not clear (detailed below)\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity \n- The paper is generally easy to follow but there are some uncertain part \n- (section 1) The introduction section has too many references which takes the sentences apart.  In addition, the parenthesis for cited papers are missing for some reason.  \n- (section 2.2) \"To make attributes discrete and complementary, one-hot encoding is applied to each segment\". The one-hot encoding is implemented by the softmax in eq (1) as a \"soft\" one-hot encoding?  The pseudocode in appendix A also does not include any line of code for one-hot encoding. \n- As stated above, it is not clear that the model learn disentangled visual attributes over the evenly divided segments. The visual analogy in Figure 1 can mislead what the model actually does. \n\nQuality / Novelty\n- The performance of the proposed method is comprehensively validated through the downstream tasks and empirical study\n- The entropy loss was not very novel idea, as it has been used as a regularization term in a lot of previous work. However, the use was theoretically explained and the experimental result clearly show the effectiveness\n\nReproducibility\n- The pseudocode helps understanding the algorithm but it would be even better to share the source code \n- The implementation detail section has sufficient information for reproducing the model training   \n\nMinor comments\n- Check the parenthesis for cited papers \n- (page 9) \"with inter-product\" --> \"with inner-product\" ?\n",
            "summary_of_the_review": "This paper seems to be a good contribution as a self-supervised learning method. However, the motivational idea, which the model learns disentangled attributes over segmented embedding space, was not validated. Also, some relevant references are missing. I hope the authors revise the current version to make up the weaknesses.    \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_yN39"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3135/Reviewer_yN39"
        ]
    }
]