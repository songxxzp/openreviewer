[
    {
        "id": "b-83fQhpjD",
        "original": null,
        "number": 1,
        "cdate": 1666279098507,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666279098507,
        "tmdate": 1666279098507,
        "tddate": null,
        "forum": "-t4D61w4zvQ",
        "replyto": "-t4D61w4zvQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2792/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method of test-time adaptation for video action classification. In specific, the paper introduces two regularization losses. One is the temporal coherence regularization on the local pathway to guarantee the smoothness of adjacent frames, while the other is the entropy minimization to enhance the robustness of the shallow layers. The experiments show that the proposed method achieves the best results on two corruption robustness datasets (Mini Kinetics-C, Mini SSV2-C).\n",
            "strength_and_weaknesses": "Strength:\n+ The two regularization is neat and makes sense. Especially, the attention module to compute the temporal affinity smooths the feature and constrains the temporal coherence, which implements the motivation precisely.\n+ The method achieves strong results and conducts a thorough ablation study.\n+ The paper writing is good and easy to understand.\n\nWeakness:\n+ Figure 3 and Figure 4 are surplus. Leaving one figure in the main paper would be enough. \n+ The ablation study of tuning the whole parameters of the model is missing. Otherwise, only tuning shallow layers and BN layers in the deep layers sounds unreasonable to me. It would be better to provide some experimental evidence.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper writing is good and implementation details are specific, which benefits reproducibility.",
            "summary_of_the_review": "Overall, it is a borderline paper with clear motivation and a reasonable method. The downside is the experimental analysis, which could be more informative and highlight the contribution. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_bEhU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_bEhU"
        ]
    },
    {
        "id": "M_1CdIHH1Jk",
        "original": null,
        "number": 2,
        "cdate": 1666638911375,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638911375,
        "tmdate": 1669149060557,
        "tddate": null,
        "forum": "-t4D61w4zvQ",
        "replyto": "-t4D61w4zvQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2792/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose a test-time training (TTT) method called TeCo, which uses not only a standard classification loss, but also a temporal consistency loss, for TTT on video data. On Mini Kinetic-C and Mini SSV2-C, the authors compared TeCo with a number of baseline methods and show that TeCo outperforms prior work on the evaluated settings.",
            "strength_and_weaknesses": "Strength:\n+ Advancing TTT can potentially have a big impact on real-world computer vision applications.\n+ The authors evaluate TeCo on more than one dataset, and demonstrate consistent improvement on both.\n\nWeakness:\n- The datasets are not commonly used ones in video research or applications. Mini Kinetic-C and Mini SSV2-C are small and the corruptions are artificially generated. Regarding the size, the larger the pretraining dataset is, the less important TTT could be. Thus, instead of experimenting on small scales, it might be more realistic to understand the methods on commonly used larger datasets (e.g. full Kinetics or full SSv2). \nRegarding the corruptions, I'm not convinced that dealing with these artificially generated corruptions are a great way to study generalization. A better way can be to use full Kinetics and SSV2 to pre-train the model, and then use some \"real-world datasets on other domains, potentially with corruptions\" to evaluate the TTT. After all, if one cannot easily find video datasets with \"corruptions\", maybe that suggests the setting isn't very practically useful.\n\n- The models used are small, proposed in ~2017-2019, and perform significantly worse than todays' state-of-the-art. Video architectures have made significant improvements over the last 3-5 years, so one might observe different observations with newers models (e.g. Swin, MViT, etc.).\n\n- There are a number of video TTT models such as, Azimi et al. 2022, but they are not compared.\n\n- The authors note that \"For standard (without test-time optimization), BN, Tent, and SHOT methods, we use\nuniform sampling to extract input from corrupted test data. We apply both uniform and dense sampling to create input for TeCo.\". I wonder if using \"dense sampling\" contributes the higher performance (because effectively the model sees more diverse inputs and can be seen as a type of data augmentation. )\n\n- I wonder how the baselines are implemented and how are the hyperparameters picked. Since the original baseline papers didn't perform these experiments, I assume the authors implemented these experiments. I wonder if the hyperparameters picked would affect the results.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is good. I can understand the proposed method easily.\nThe novelty seems on the weaker side to me, because temporal consistency is not new (e.g., Azimi et al. also uses some sort of temporal consistency).\nThe experiments are not entirely convincing (pls see discussions above).",
            "summary_of_the_review": "Overall, my main concern is regarding experiments. I find the experiment settings limited, and I'm not convinced by the experiments that the proposed method is effective. A more realistic setting (including real datasets, stronger models) would have been more convincing.\n\n\n--- post rebuttal ---\nThanks for providing the rebuttal. The additional experiments comparing with TTT* and the experiments using MViT are helpful and clarify many of my concerns. I also find the domain shift experiments on HMDB and UCF101 very nice and convincing. Regarding the dataset scale, my concerns are still not fully addressed. One potential way to understand the effect of pretraining data scale is to evaluate the proposed method under increasingly larger \"pretraining dataset size\", to see if the improvement still holds when pre-training dataset is large. \n\nOverall, with the new results, I find the paper greatly improved, and I adjusted the rating accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_rshF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_rshF"
        ]
    },
    {
        "id": "DiSLIONTdv",
        "original": null,
        "number": 3,
        "cdate": 1667405876074,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667405876074,
        "tmdate": 1668511256663,
        "tddate": null,
        "forum": "-t4D61w4zvQ",
        "replyto": "-t4D61w4zvQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2792/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a method that deal with input domain shifts in videos during test time (I.e., it deals with corruptions not observed in training data, like different weather conditions).  They propose two self-supervised objectives that are applied to the test-data: one minimizes the entropy of predictions across frames, the other penalizes features/representations that change too strongly during different frames of the video. Results on Mini Kinetics C and Mini SSV2-C are provided.",
            "strength_and_weaknesses": "Strenghts:\n* The method seems applicable to any video model\n* The empirical results look good\n\nWeaknesses:\n* The method is not evaluated on Transformer-based models. It would be nice (though not necessary) if this would be added.\n* The authors do not discuss runtime implications: how expensive is it to run this method? How long do you need to tune this? How much data do you require to obtain reasonable results? It would be nice if these points could be adressed.\n* There are no explanations/ablations on some of the hyperparameters that the metod introduced (See \"Clarity\" below)\n* The authors need to work on Clarity/Reproducibility (see further down in the review)",
            "clarity,_quality,_novelty_and_reproducibility": "In general, the exposition was not always clear, some parts of the paper were hard to follow. The authors introduce hyperparameters but never explain them, or even state how they are set during training, which makes it impossible to reproduce the results in the paper.\n\n* The authors use several symbols without introducing them. For example, what are the g and f functions in Section 3.2? They also appear in Figure 1, but are never introduced in the text.\n\n* The hyperparemters alpha and beta are introduced in the beginning Section 3.1, but it\u2019s never discussed how these variables are set during the experiments, or how sensitive the method is to changing this variable.  There is (an apparently different) beta turning up in Eq. 3.4. Again, there is no discussion about how to set this hyperparameter or how sensitive results are to changing this.\n\n*  Eq (1): Why L1 distance? Wouldn\u2019t L2 distance make more sense? (i.e., do not penalize small pertubations?)\n\n\nMinor remarks:\nWe propose to build our method upon the test-time optimization which updates all the parameters in shallow layers and only normalization layers in the deep layers. => What are \"shallow layers\" and what are \"deep layers\"? From Figure 1, I think you mean the initial (lower) layers are shallow and the layers deeper in the network are the \"deep layers\". But this formulation is ambiguous and not clearly defined.\n\n\u201cTeCo increases 8% and 5.4% average accuracy across backbones on Mini Kinetics-C and Mini SSV2-C\u201d => TeCo increases accuracy by 8% on across backbones on Mini Kinetics-C and by 5.4% on Mini SSV2-C.\n\n\u201cRecently there emerge studies\u201d => Recently, studies have emerged\n\n\u201cthey have subtle enhancement on video data\u201d => they only show minor improvements on video data\n\n",
            "summary_of_the_review": "The authors introduce a method to optimize a network for test-time domain shift. Empirical results look promising, but in its current state the authors need to adress some clarity and reproducibility concerns.\n\nUPDATE: After seeing the updated version by the authors, I feel like most of my weak points have been adequately addressed. I'm not familiar enough with the problem it is addressing to judge it's relevance to the community. But both motivation and empirical validation seem sound to me, so I would like to raise my rating to a 7 (i.e., \"good paper, but unclear about practical relevance\").",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_naa6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2792/Reviewer_naa6"
        ]
    }
]