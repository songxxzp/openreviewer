[
    {
        "id": "97iCRrLphc",
        "original": null,
        "number": 1,
        "cdate": 1666633795929,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633795929,
        "tmdate": 1666633795929,
        "tddate": null,
        "forum": "PxohstFQm9q",
        "replyto": "PxohstFQm9q",
        "invitation": "ICLR.cc/2023/Conference/Paper2693/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper explores the simplicity bias (SB) for 1-hidden layer neural networks (NNs). The paper formulates SB as a concept (the NN learns a simpler feature than those available and informative for classification) and then prove that this might happen in 1-hidden layer NNs. Lastly, the paper proposes a heuristic way to train an ensemble of models to avoid SB. ",
            "strength_and_weaknesses": " * [+] Understanding of neural networks and their (learning) properties is an important task. \n\n * [+] The definition of simplicity bias in Definition 1.1 is clear to me.\n\n * [-] The results are currently limited, e.g. only one-hidden layer network. Despite the authors explicitly identifying this, I am still not convinced that one-hidden layer nets are a practical consideration. \n\n * [-] The core theorem 4.1 is only applicable for an infinite width network. \n\n * [-] The paper mentions that we do not have a clear understanding of the dynamics of deeper networks (page 2), however this is not true. The papers of \u201cTraining Integrable Parameterizations of Deep Neural Networks in the Infinite-Width Limit\u201d or \u201cGradient Descent Finds Global Minima of Deep Neural Networks\u201d already study the dynamics of deep networks (or their proof applies for deep nets). I would recommend revising this paragraph to avoid any confusion from the readers. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Previous work (that is already cited in Geirhos et al) used the term shortcut learning, so I am wondering why the term has been changed to simplicity bias here. Won\u2019t this obfuscate the literature if there are two terms describing the same phenomena? \n\nIs there any proof that the ensemble avoids the SB?\n\nAt the moment, I find the empirical validation, especially in the part of the ensemble method, quite weak. For instance, I am wondering why in Table 1 only up to 10 classes are used. Isn\u2019t it possible that by needing to learn more classes, e.g. in Imagenet, the network avoids such shortcut learning? \n\nMinor: The text requires some proofreading since there inconsistencies, e.g. \u201cHu et al observe\u201d, but \u201cLyu et al considers\u201d; I think all references need to be corrected into the former format. \n",
            "summary_of_the_review": "At the moment, there are certain unclear things to me, e.g. whether the simplicity bias is the same as shortcut learning, or why the results cannot be extended to deep networks or the finite width regime. In addition, I find the experiments are rather weak. Having said that, it is possible that this paper has value for the community if the paper is strengthened during the rebuttal period. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_iV59"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_iV59"
        ]
    },
    {
        "id": "Ay5ynMv7vOw",
        "original": null,
        "number": 2,
        "cdate": 1666669905020,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669905020,
        "tmdate": 1669051795693,
        "tddate": null,
        "forum": "PxohstFQm9q",
        "replyto": "PxohstFQm9q",
        "invitation": "ICLR.cc/2023/Conference/Paper2693/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper elaborates on a specific simplicity bias called LD-SB. Theoretical proofs of LD-SB are provided for 1-hidden layer neural networks on the IFM distribution under different situations. Experiments on four real datasets demonstrate that LD-SB is of practical importance. The authors further propose a new robust ensemble method based on the understanding of LD-SB.",
            "strength_and_weaknesses": "Strength:\n\n- The concept of LD-SB is clearly and rigorously defined, along with a good presentation of related background knowledge.\n- Both theoretical proof (for 1-hidden layer net and IFM) and empirical justification (for four real datasets) are provided to demonstrate the LD-SB.\n- The paper further proposed a potentially useful ensemble method, OrthoP, and show this method is more robust under Gaussian noise.\n\n\nWeaknesses:\n\n- In the experiments on real datasets, the current four metrics do not reflect the third point of the definition for LD-SB. Hence, the current experiments do not fully \u201cshow LD-SB on real datasets.\u201d  As the projection operator is ready, why not train an independent model to show that a model using the remaining features in the orthogonal sub-space can achieve high accuracy? \n- Despite the authors' arguments that fine-tuning on 1-hidden layer network is effective in many practical cases, I do think for real datasets, experiments could involve more sophisticated network architectures. It is interesting to see whether the LD-SB exists in more complex and practical settings.\n- In subsection 4.4.3 for Lazy regime, it said that \u201cable to find a low dimensional projection matrix P which satisfies the conclusions in Theorem 4.2. This statement seems improper since Theorem 4.2 applies to a specific dataset rather than those real datasets.\n- Can you discuss why the low dimension character is also present when applying to real datasets rather than IFM? Is there any other mechanism involved?\n- Missing details of experiments referred to in Fig.5. For example, how is the output of the ensemble model computed? Average over both member models?\n- In Fig.4, it is claimed that the decision boundary of the second model is more non-linear. It would be better to provide a quantitative measure of the non-linearity.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the idea is smoothly presented.\n\nThe proposed LD-SB is novel and interesting.",
            "summary_of_the_review": "The proposed LD-SB is interesting and backed by both theoretical and empirical justifications. However, according to my understanding, the experiments on real datasets do not fully establish the LD-SB (see point 1 in weaknesses). Hence, I give a score of 5, e.g., marginally below the threshold.\n\n------------------------20221122-----------------------\n\nas the authors had addressed my concern about establishing LD-SB in real datasets, I decided to raise my rating from 5 to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_EewH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_EewH"
        ]
    },
    {
        "id": "rBO6fMG-ULg",
        "original": null,
        "number": 3,
        "cdate": 1666843920736,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666843920736,
        "tmdate": 1666843920736,
        "tddate": null,
        "forum": "PxohstFQm9q",
        "replyto": "PxohstFQm9q",
        "invitation": "ICLR.cc/2023/Conference/Paper2693/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper rigorously defined as well as thoroughly established simplicity bias for one hidden layer neural networks, as a function of a low dimensional projection of the inputs. The authors theoretically proved that the network primarily depends on only the linearly separable subspace when the data is linearly separable, and emprically showed that the models trained on real datasets depended on a low dimensional projection of the inputs. Moreover, they proposed an ensemble approach to combine the orthogonal direction learning.",
            "strength_and_weaknesses": "Strengths:\n\nS1. The paper is very well-written and I enjoyed reading it.\nS2. Both theory and experiments look great.\n\nWeaknesses:\n\nS1. The low-rank bias is NOT new. Please refer to [R1] and [R2] as well as related works in the two papers.\n\n[R1] The Low-Rank Simplicity Bias in Deep Networks. https://minyoungg.github.io/overparam/resources/overparam-v2.pdf\n[R2] Principal Components Bias in Over-parameterized Linear Models, and its Manifestation in Deep Neural Networks. JMLR 2022\n\nS2. A better overview of previous related work is suggested. E.g., as mentioned in Shah et al. (2020), simplicity bias is related to Out-of-Distribution (OOD) detection. In OOD detection, the low-rank bias and ensemble learning along the orthogonal projection has also been extensively studied.\n\n[R3] Outlier detection through null space analysis of neural networks. arXiv:2007.01263, 2020.\n\n[R4] Out-of-distribution detection with subspace techniques and probabilistic modeling of features. arXiv:2012.04250, 2020.\n\n[R5] Out-of-distribution detection using union of 1-dimensional subspaces. CVPR 2021.\n\n[R6] ViM: Out-Of-Distribution with Virtual-logit Matching, CVPR 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The low-rank idea is NOT new for defining simplicity bias, therefore, the paper needs to be polished to distinguish from previous works.",
            "summary_of_the_review": "This paper rigorously defined as well as thoroughly established simplicity bias for one hidden layer neural networks, as a function of a low dimensional projection of the inputs. The low-rank idea is NOT new for defining simplicity bias, therefore, the paper needs to be polished to distinguish from previous works.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N.A.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_Hiqj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_Hiqj"
        ]
    },
    {
        "id": "gyyLhq9cZ1",
        "original": null,
        "number": 4,
        "cdate": 1667330665900,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667330665900,
        "tmdate": 1670255468462,
        "tddate": null,
        "forum": "PxohstFQm9q",
        "replyto": "PxohstFQm9q",
        "invitation": "ICLR.cc/2023/Conference/Paper2693/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper analyzes the phenomenon of \"simplicity bias\" in neural networks. Simplicity bias is defined here as the tendency of models to learn \"simple\" features (low-rank linear projections of the input space) that enable the model to solve the task even when different non-linear projections could also be used to solve the task with high accuracy. It is argued in the paper that this can result in \"shortcut learning\" where the model can learn simple features that correspond to \"spurious correlations\" and are not stable w.r.t. distribution shift.\n\nThe paper focuses on 1-hidden layer ReLU binary classifiers.\n\nA theoretical analysis is carried out in the infinite width limit, with two different initialization regimes: a \"lazy\" regime that corresponds to the NTK framework, and a \"rich\" regime with enables training of the hidden layer and is therefore more representative of practical training regimes. Under the assumption that the data comes from a distribution where the input features are independent conditional on the output, they show that the model will project the input in a rank-1 linear manifold if it suffices to solve the problem, even when other non-linear solutions exist.\n\nAn empirical analysis is done on classification heads on top of frozen pre-trained image classification models for various image classification tasks, showing results consistent with the hypothesis.\nThe paper also briefly discusses how to use this simplicity bias property to train an ensemble of diverse models by sequentially projecting the data on the orthogonal space of the linear projections that the model tend to learn.",
            "strength_and_weaknesses": "Strengths:\n- The paper is well-written\n- The result is interesting, important, and as far as I know, novel\n \nWeakness:\n- No discussion of why is \"simplicity bias\" supposedly leads to poor OOD generalization. Wouldn't a more complicated decision boundary be even less robust than a quasi-linear one?\n- How are the projection matrices computed in the experimental section? There is very little discussion and no pseudo-code. Is the weight matrix used in the rich regime? How do you learn the projection matrix in the lazy regime? Are there any constraints?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite clear, important and novel. However, the algorithms for computing the projection matrices are not very clear described, and there is no mention of a code release, hence reproducibility seems low.\n\nEDIT: the reproducibility concerns have been addressed.",
            "summary_of_the_review": "Good paper, I would give a higher score if my concerns about reproducibility were addressed.\n\nEDIT: I am increasing my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_3SUe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2693/Reviewer_3SUe"
        ]
    }
]