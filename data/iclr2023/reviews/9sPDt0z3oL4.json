[
    {
        "id": "51DZwaXppcM",
        "original": null,
        "number": 1,
        "cdate": 1666581733234,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581733234,
        "tmdate": 1666618043757,
        "tddate": null,
        "forum": "9sPDt0z3oL4",
        "replyto": "9sPDt0z3oL4",
        "invitation": "ICLR.cc/2023/Conference/Paper2249/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work considers the linear quadratic regulator problem, and studies the natural actor critic algorithm\u2019s convergence under the single-timescale update, where the step-size of actor and critic variables are proportional by a constant. They show that the algorithm attains the global optimum with the sample complexity of $\\tilde {\\mathcal{O}}(\\epsilon^{-2})$.",
            "strength_and_weaknesses": "Strength:\n- The work considers the single-timescale update, which is more practical than the double-loop update analyzed in previous works.\n- The paper proposes a new analysis framework for the algorithm and establishes the sample complexity of $\\tilde {\\mathcal{O}}(\\epsilon^{-2})$, which matches the best existing sample complexity for single-timescale AC algorithm.\n\nWeakness:\n- Previous works [1, 2] which study the LQR problem seems to have weaker assumption: They only require that initial policy is stable, instead of being stable for each iteration, as assumed in this paper.\n- Since the paper only presents the convergence of the natural AC instead of the AC for the LQR, I suggest the author to add more discussions on the convergence of AC in the introduction.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is easy to follow. The quality and originality are fair-to-good. ",
            "summary_of_the_review": "I have the following main comments:\n\n- The title and the abstract are quite misleading, in which the authors claim that they obtain the convergence of single-timescale AC under LQR problem. After going through the paper, the authors only consider natural AC (NAC). AC and NAC are two quite different algorithms. Hence, the authors must revise any related claims accordingly to reduce confusion. \n\n- From my understanding, Assumption 4.2 is mainly used to ensure the existence of stationary distribution. Is it possible to remove the assumption by considering using the sample from a trajectory? (as in [1, 2])\n\n- Can you also provide convergence of AC under the online update? Even without the knowledge of the model? NAC often has more complex oracle than AC. What is the motivation to consider NAC rather than AC?\n\n- There are works [3, 4, 5] that study the single-timescale AC\u2019s sample complexity for finding a stationary point under the general cost function (rather than LQR). Can their results be extended to LQR problem and obtain the same rate for global convergence? In LQR, the gradient domination property (also known as Polyak-\u0141ojasiewicz inequality) implies that the optimal gap converges in the sample rate as the gradient norm square.\n\n- The authors missed the related reference [4], which gives convergence results for single-timescale AC under the general cost function.\n\n\n[1] Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator.\n\n[2] On the Global Convergence of Actor-Critic: A Case for Linear Quadratic Regulator with Ergodic Cost.\n\n[3] Closing the gap: Tighter analysis of alternating stochastic gradient methods for bilevel problems.\n\n[4] Finite-Time Analysis of Fully Decentralized Single-Timescale Actor-Critic.\n\n[5] A small gain analysis of single timescale actor critic.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_KvYy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_KvYy"
        ]
    },
    {
        "id": "LOkr4KU_O6",
        "original": null,
        "number": 2,
        "cdate": 1666597135686,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666597135686,
        "tmdate": 1668898710535,
        "tddate": null,
        "forum": "9sPDt0z3oL4",
        "replyto": "9sPDt0z3oL4",
        "invitation": "ICLR.cc/2023/Conference/Paper2249/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a single-sample single-timescale Actor-Critic method for the linear quadratic regulator (LQR). The main contribution with respect to the available literature is that the authors suggest the epsilon-optimal solution with a sample complexity \\tilde{O}(epsilon^2) and provide some convergence analyses.",
            "strength_and_weaknesses": "For the policy defined in (7), authors can provide better exploration methods such as optimism or Thompson sampling. The suggested exploration methods can over-explore over time. Also, policies with better exploration methods may improve the theoretical results. \n\nFor experiments, it would be interesting to see comparisons between the single-timescale and two-timescale AC as well. \n",
            "clarity,_quality,_novelty_and_reproducibility": "In the third paragraph of Section 1, the explanation about single-timescale AC is similar to that about two-timescale AC. The statement should include the difference between the single-timescale and two-timescale AC. Further, there are multiple typos and grammatical errors.",
            "summary_of_the_review": "Post rebuttal: \n\nI found the paper unready for publication. The importance and novelty of the results is unclear, e.g., the superiority of the suggested method over the existing ones that are faster, more flexible, and can be implemented in an online manner. The technical assumptions, e.g. stability, are strong, while they are studied in the literature. The literature review is also incomplete in other places, e.g. RL in LQR. The main theoretical contribution lacks scalability and it is not clear how the failure probability affects the convergence results. Also on the main theorem, the main convergence rate which is the last one, is not as strong as one expects, and I believe that it can be improved to 1/T. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_Me62"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_Me62"
        ]
    },
    {
        "id": "eIWw5Mme4Bd",
        "original": null,
        "number": 3,
        "cdate": 1666669404028,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669404028,
        "tmdate": 1666851792116,
        "tddate": null,
        "forum": "9sPDt0z3oL4",
        "replyto": "9sPDt0z3oL4",
        "invitation": "ICLR.cc/2023/Conference/Paper2249/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a single time-scale actor-critic (AC) algorithm to solve the LQR problem. The authors establish an $O(1/\\sqrt{T})$ rate of global convergence. Numerical simulations are provided to demonstrate the performance of the proposed algorithm.",
            "strength_and_weaknesses": "Major Comments:\n\n(1) The claim of \"single time-scale\" is not correct. The constant $c_\\alpha$ in the stepsize $\\alpha_t$ is in fact not a constant, but depends on the final iteration number $T$, as shown in Eq. (52). Since $t\\leq T$, we still have $\\alpha_t/\\beta_t\\rightarrow 0$ as $t$ goes to infinity, and the algorithm is in fact two time-scale. In view of this, the contribution of this paper is unclear.\n\n(2) As a follow-up comment to (1), the motivation of using diminishing step sizes is that the agent does not need to choose the stepsize based on the final iteration number $T$, otherwise one can simply use constant stepsize designed based on $T$. Since $c_\\alpha$ depends on $T$, this contradicts to the motivation of using diminishing stepsizes.\n\n(3) The authors tried to justify the i.i.d. sampling assumption by stating that one can wait until the Markov chain is sufficiently mixed and then collect one sample. However, this contradicts to the \"single sample\" claim made in this paper. Also, in terms of analysis, the i.i.d. assumption greatly simplifies the proof, and hence is not mild in this viewpoint. In addition, there are many existing papers successfully handled Markovian sampling. \n\n(4) While the authors justified the use of Assumption 4.1 and Assumption 4.2 by citing existing papers and providing numerical simulations, these two assumptions are not logical. Before we run the algorithm, there is no guarantee on the size of $K_t$ and the stability of the system. Assuming something that may or may not happen in the future does not make sense.\n\n(5) When talking about finite-time bound, one should avoid using the big O notation and explicitly characterize all the constants. Theorems involving big O notation are not finite-time bounds but asymptotic bounds.\n\nMinor Comments:\n\n(1) Please change the title to \"... natural actor-critic ... \" to avoid confusion with vanilla actor-critic (without fisher information preconditioner). \n\n(2) There are many related papers studying natural actor-critic (even beyond LQR) and established $O(1/\\epsilon^2)$ sample complexity, just to list a few:\n\n[1] Xiao, L. (2022). On the convergence rates of policy gradient methods. arXiv preprint arXiv:2201.07443.\n\n[2] Lan, G. (2022). Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes. Mathematical programming, 1-48.\n\n[3] Chen, Z., & Maguluri, S. T. (2022, May). Sample Complexity of Policy-Based Methods under Off-Policy Sampling and Linear Function Approximation. In International Conference on Artificial Intelligence and Statistics (pp. 11195-11214). PMLR.\n\n(3) The authors should make clear about what is established in the literature and what is the contribution of this work. For example, in Section 3, is everything before the algorithm a contribution of this work or already established in literature (e.g., Proposition 3.1)?\n\n(4) Notation such as svec and smat should be properly defined.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the main paper is easy to follow. The proof seems a bit convoluted but I think this is hard to avoid due to the theoretical nature of this work. ",
            "summary_of_the_review": "Since the proposed algorithm is in fact two time-scale, and there are many existing papers analyzing two time-scale actor-critic and its variants, the main contribution (i.e., analysis of single time-scale actor-critic) claimed by the authors is unclear. In addition, some of the assumptions are not realistic. In view of these two point, I cannot recommend accepting this paper to ICLR.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_HWQj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2249/Reviewer_HWQj"
        ]
    }
]