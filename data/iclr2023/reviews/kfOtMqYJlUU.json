[
    {
        "id": "SB7cK8zZpFA",
        "original": null,
        "number": 1,
        "cdate": 1666205082348,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666205082348,
        "tmdate": 1668572915963,
        "tddate": null,
        "forum": "kfOtMqYJlUU",
        "replyto": "kfOtMqYJlUU",
        "invitation": "ICLR.cc/2023/Conference/Paper1426/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a self supervised method for object segmentation in NeRF. The major idea is applying collaborative contrastive training in both appearance (radiance field) and geometry (density field) level in NeRF. It uses DINO (Amir et al., 2021)  as the basic backbone architecture to extract appearance correlation volume and extend it with geometry correspondence across views. The proposed method is evaluated on several NeRF dataset and show that it outperforms other cosegmentation methods, i.e. DINO-CoSeg and DOCS, that were designed for multiple image cosegmentation but not for NeRF setting.",
            "strength_and_weaknesses": "Strength: It is a good attempt to extend previous cosegmentation method for NeRF setting. The proposed method is reasonable and the results are better than the compared methods.\n\nWeaknesses: The proposed method is not the first work that deal with segmentation in NeRF. Some important references are missing. The experimental comparisons are incomplete as it miss the comparisons with some recent methods. Please check the following recent works:\n\nYu et al., Unsupervised Discovery of Object Radiance Fields, in ICLR, 2021 (missing comparisons)\n\nYang et al., Learning object-compositional neural radiance field for editable scene rendering, in ICCV 2021  (missing comparisons)\n\nRen et al., Neural Volumetric Object Selection, in CVPR 2022 (missing reference and comparison)\n\nSmith et al., Unsupervised discovery and composition of object light fields, in ICLR, 2022. (missing reference and comparison)\n\nKundu et al., Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation, in CVPR, 2022. (missing reference)\n\nLiu et al., Unsupervised Multi-View Object Segmentation Using Radiance Field Propagation, in NeurIPS 2022. (This one should be considered as a concurrent work since NeurIPS conference is after ICLR deadline.)",
            "clarity,_quality,_novelty_and_reproducibility": "I think this work is quite incremental as using a single network to regress density field, segmentation, and colors have already been proposed in previous papers. The appearance correlation volume is somewhat similar to part of the process in Neural Volumetric Object Selection which also use self-supervised learning to extract initial segmentation volume. The geometry constraint are also standard in multi-view stereo and has been demonstrated in Point transformer for point cloud segmentation. Overall, I feel this paper is just a combination of existing methods and then apply it to the NeRF segmentation.",
            "summary_of_the_review": "Please check my above comments regarding missing references and comparisons, and the incremental novelty of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_92aZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_92aZ"
        ]
    },
    {
        "id": "SZeABaIXEYM",
        "original": null,
        "number": 2,
        "cdate": 1666659213885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659213885,
        "tmdate": 1669694548036,
        "tddate": null,
        "forum": "kfOtMqYJlUU",
        "replyto": "kfOtMqYJlUU",
        "invitation": "ICLR.cc/2023/Conference/Paper1426/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a self-supervised object segmentation technique that operates on an optimized Neural Radiance Field. It couples NeRF reconstruction with DiNO-ViT feature extraction and models a collaborative contrastive loss function that helps parse the dominant object in the image. The results show that the segmentation accuracy is at par with the semi-supervised Semantic NeRF and outperforms other approaches. ",
            "strength_and_weaknesses": "Since NeRF is trained under an i.i.d. assumption, there is little semantic correlation between the features across different views. Hence, the color or depth MLPs can't be directly used for semantic tasks. In this paper, a new semantic branch is added to the network that is trained by explicitly enforcing matches across views through collaborative contrastive losses. This is a novel idea, and it becomes feasible to extract the dominant object simply by clustering the logits of the semantic branch. This appears to be a really effective approach and is able to match the segmentation quality of semi-supervised methods such as the Semantic-NeRF. \n\nAlthough the method claims to segment complex real-world scenes, the demonstrated examples are typically single object scenarios with no background noise. In most cases the objects are also centered and parallel to the visual plane. The authors mention that a density based correlation is required to distinguish between objects, but neither the qualitative nor the ablation results reflect the need for this additional loss. The results could be much more interesting if these design choices and other parameters such as the number of kmeans clusters were explained. \n\nWhen a high-performance model such as DINO-ViT is used, it becomes difficult to tease apart the value of the core method vis-a-vis the strong model. The results of the proposed method with Resnet seem much less impressive that with DINO backbone. How much does the DINO model alone contribute to accurate segmentation?\n\nThe comparison to Semantic NeRF is also a bit misleading, since this model can segment only a single dominant object that's in the field of view, whereas Semantic NERF allows simultaneous segmentation of many class labels.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is a bit difficult to understand, especially the narrative around the correlation volumes. Improving the Grammar could help a bit (e.g., paragraph 2, last line - However, still remains a gap..., Page 4, last section: DINO has been verified it has the potential...). The technical details are listed without much explanation as to why they are necessary. To make this paper useful and reproducible, the authors should consider rewriting the technical section with more clarity. \nSome details about the comparative methods are missing. Particularly, Semantic NeRF can be trained from sparse labels. What happens if only a single click is used to seed the object.",
            "summary_of_the_review": "The paper proposes a novel idea of object segmentation by coupling the NeRF color and depth features with DINO powered semantic segmentation features. It provides a nice demonstration that the dominant object in the NeRF model can be parsed in a full self-supervised manner. The details of how to go about it are a bit sketchy, and the lack of detailed ablation studies makes it harder to understand the merits and the inner workings of the correlation volumes. Adding more diverse results of complex real-world scenes, and teasing apart the results from the DINO model alone would make the results more interesting. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_vb78"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_vb78"
        ]
    },
    {
        "id": "AIhdoVC-XUd",
        "original": null,
        "number": 3,
        "cdate": 1666679474919,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679474919,
        "tmdate": 1666684326847,
        "tddate": null,
        "forum": "kfOtMqYJlUU",
        "replyto": "kfOtMqYJlUU",
        "invitation": "ICLR.cc/2023/Conference/Paper1426/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a self-supervised approach to segment objects from novel views synthesized from a NeRF.\n\nThe idea is borrowed from Hamilton et al. (2022) who learned semantic co-segmentation of images in an unsupervised fashion, by distilling the knowledge of DINO. The authors adapted the method to NeRF, to segment objects in novel views without any extra supervision. The knowledge is distilled from both visual and geometric features learned by NeRF.\n\nThe novel object segmentation branch in NeRF, learned by self-supervised distillation of the visual and geometric knowledge, show competitive performances with fully supervised methods such a Semantic NeRF, that require extra manual annotation of the masks.\n",
            "strength_and_weaknesses": "Strengths:\n\nThe paper is well written and the method is technically sound. \n\nThe authors accommodated for a segmentation branch in the NeRF architecture, and the learning for that branch does not require any supervised training.\n\nThe results appear on par with fully-supervised approaches like Semantic-NeRF.\n\nWeaknesses:\n\nIn the second phase of the training, it is unclear whether the color and density heads of the NeRF are frozen or not. Even though the \\lambda_0 is set to 0, the other 2 losses can still induce a catastrophic forgetting of the knowledge learned in the 1st phase.If those are not frozen, the 2nd stage of the training might lead the appearance and geometry head of NeRF to collapse instead of distilling their knowledge into the segmentation head.\n\nThe cross-view geometric correspondence is unclear, in particular the motivation and insight on Equation (7), that appears to average the geometric coordinate t_k along the ray, based on the volumetric rendering based on the density learned by NeRF. Is that simply the point on the surface? Why not integrating some higher dimension features learned in NeRF? Also, for correctness, I believe \\Delta_k in (7) should be \\delta_k like in (1). Moreover, Equation (8) introduces spatial features g and g\u2019 of dimension c, why is that the same dimension of f and f\u2019 introduced in (3) and not of 3 dimension? Is the absolute distance an L2 norm?\n\nIn Equation (5) and (10), why \\lambda_neg is not a negative value?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written but does not necessarily flow well.\n\nThe work appears of quality and technically sound.\n\nThe paper adapts the finding of Hamilton et al. (2022) into a NeRF framework, but provides a novel formulation for the geometry-level correspondence volume with a geometry-segmentation correlation formulation necessary for the approach to provide good results.\n\nThe authors provided the code in the supplementary material (although I don\u2019t have compute resource available to test the reproducibility of the code)\n",
            "summary_of_the_review": "The method provides very interesting insights on how to learn object segmentation in an unsupervised approach, leveraging consistency between multiple views in a NeRF representation.\n\nThe work appears technically sound, and paves the way for further work towards less supervised learning segmentation.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_9Jcm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_9Jcm"
        ]
    },
    {
        "id": "cgSN0TL9LTZ",
        "original": null,
        "number": 4,
        "cdate": 1666684073125,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684073125,
        "tmdate": 1668686346303,
        "tddate": null,
        "forum": "kfOtMqYJlUU",
        "replyto": "kfOtMqYJlUU",
        "invitation": "ICLR.cc/2023/Conference/Paper1426/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes an appearance contrastive loss to apply the self-supervised learned 2D visual feature for 3D representations.\nA new geometry contrastive loss is proposed for object segmentation to involve geometric information for segmentation clustering.\nThe segmentation of the proposed method has a more refined result than its supervised counterpart.",
            "strength_and_weaknesses": "Strengths:\n1. This is a well-written paper.\n2. The proposed method is compared with various methods. The experiments are complete and convincing.\n3. Some visualizations are helpful to understand.\nWeaknesses:\n1. Although the visual results of the proposed method are better than the supervised method. The evaluation metrics of the proposed method are worse than Semantic-NeRF in Tab 2 and Tab 3. What causes that problem?\n2. The paper lacks a quantitative analysis of the effects. May you give an analysis of your design?\n3. The ablations are not sufficient enough. Ablation should contain all of your extra design including geometry contrastive loss and appearance contrastive loss.",
            "clarity,_quality,_novelty_and_reproducibility": "Good. The paper is well-written. The authors describe their method in detail, which guides for reproducing the result.\nThe authors provide various results on different datasets and the comparison of different methods, making the results convincible. \nThe proposed method is somewhat innovative and gets more optimal segmentation results.\n",
            "summary_of_the_review": "The paper is well-written, and the result of object segmentation is better than its counterpart obviously.\nI think it is marginally above the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_LCEX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1426/Reviewer_LCEX"
        ]
    }
]