[
    {
        "id": "uEAt4JUQRE",
        "original": null,
        "number": 1,
        "cdate": 1666652352440,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666652352440,
        "tmdate": 1669400553332,
        "tddate": null,
        "forum": "iYC5hOMqUg",
        "replyto": "iYC5hOMqUg",
        "invitation": "ICLR.cc/2023/Conference/Paper3964/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The author's propose a new metric for evaluating / comparing neural encoding models. They call this metric the Information Gain (IG):\n\n$\n\\frac{ \\langle \\log \\hat{p}(y \\mid x) \\rangle  -  \\langle{\\log p_0(y)} }{ \\langle \\log p_*(y \\mid x) \\rangle  - \\langle \\log p_0(y) \\rangle }\n$\n\nI would instead suggest calling this something like *Normalized Information Gain* as previous papers (e.g. Kummerer et al, 2015) call the numerator the information gain (and in that case it has the right units of bits/nats).\nThe IG is a very well-known metric used to compare different models.\nPersonally, I would prefer to use the term log Bayes factor or log-likelihood ratio, but this is just a matter of taste/background.\n\nMuch of the paper is spent trying to find a good \"Gold Standard\" model $p_{\\star}(y \\mid x)$, which is meant to upper bound the performance of any model. The authors use a reasonable Empirical Bayes methodology here. One concern is that they find encoding models that outperform this \"Gold Standard.\" This is not too much of a problem in my view, but the authors may try the following simple trick/suggestion &mdash; I would try taking a having $p_{\\star}(\\cdot)$ be a weighted average of the current gold standard model $p(y_i \\mid \\mathbf{y}\\_{\\backslash i} , x_i )$ and the *global* distribution over all images (not just those with the same image input as trial $i$). The idea is that one has an extremely large number of trials so you could get a very accurate kernel density estimate of $p(y)$ and shrink your under-powered parametric estimator of $p_*(\\cdot)$ slightly towards this (biased, stimulus-independent) of  the neural response distribution. I'm not sure this will work but it may be worth trying.\n\nThe authors conclude by relating IG to existing metrics within the field like correlation and fraction of explainable variance.",
            "strength_and_weaknesses": "The main strength of this paper is that it identifies a rather serious deficiency within the current state of the field. Having pointing out this deficiency, it presents a very well-known and rigorous solution.\n\nThe main weakness of this paper is that it focuses more-or-less entirely on conceptual first principles. To be sure, these first principles are really important for us to get right, but I would have liked to see more empirical demonstrations that compare multiple encoding models and revisit old results (e.g. Yamins & Dicarlo-style regressions between deep nets trained not on encoding task, but on different image tasks). A skeptical reader may come away unconvinced without a deeper empirical demonstration.\n\nAnother weakness of this paper, in my view, is that it spends a long time trying to identify a \"Gold Standard\" upper bound model, which isn't really necessary for us to compare and rank different encoding models. Thus, a lot of the paper ends up being somewhat uninteresting to me. Further, while it would be nice to have an upper bound on model performance, this isn't easily done. The authors find out in Figure 5a that their encoding model actually out-competes their gold standard, and they then amend their gold standard to be a \"true upper bound\" in Figure 5b. However, I challenge the claim that this is a true upper bound -- the gold standard model is a parametric model (albiet a pretty good one!) and there is nothing saying someone else couldn't come along with something else to beat it. This is especially true since the gold standard model as currently formulated doesn't share any information across different image types / categories. Presumably this is why it is possible for the deep net encoding model to outperform the gold standard. Overall, I would suggest that the author's revise the paper to modify their language --- i.e. treat the gold standard as a useful benchmark or point of comparison, but not a end-all-be-all upper bound.\n\nA final weakness of this paper is the clarity of the notation and deep net experiments, described below. I believe however that this weakness is addressable in review.",
            "clarity,_quality,_novelty_and_reproducibility": "The notation and concepts are confusing in a few places. On the bottom of page 2 the authors say $p_0(y \\mid x) = \\hat{p}(y)$. However, this seems wrong as one would want the null model to be independent of the choice of $\\hat{p}(y)$. That is, suppose I wanted to compare a Poisson encoding model (like Lurz et al) versus a zero-inflated log-normal model. This would seem to imply two different null models in the way the paper is currently written, but I would need to use a common null model to compare ZIL to Poisson in terms of information gain.\n\nI also found the notation $p(y)$ in equation 3 to be confusing. I would write this instead as $p(y \\mid x)$ (or is it $\\hat{p}(y \\mid x)$ here?). The authors say below the equation that $\\theta_1$ and $q$ are dependent on $x$. This helps, so ultimately I understand what they are going for here but the notation should be improved so that readers can refer to equations in a more standalone fashion. I think equation 2 and the equation under the point estimate model in section 2.1 similarly are conditioned on $x$ somehow, so a similar revision of notation there would be helpful.\n\nFinally, and most importantly, I would like the authors to include a more detailed description of the Lutz et al model within the main text of this paper and also expand their discussion of this model in the Appendix. In short, I do not feel the paper is currently \"self-contained\" with all of these details (e.g. it is confusing what is meant by \"core network\").",
            "summary_of_the_review": "I have to admit this paper makes me somewhat depressed. To me it is blatantly obvious that information gain is a superior measure of performance relative to existing conventions. It doesn't feel like we should require a whole paper to set the field straight. But sadly I think this may be a necessary story for people to hear. Thus, I do see merit in this paper.\n\nI am so far proposing a borderline reject to this paper because of the missing details and unclear notation in areas outlined above. However, I'm open to raising my score if the authors revise the paper to provide those missing details.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_1J5x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_1J5x"
        ]
    },
    {
        "id": "oF-0yGgDdsH",
        "original": null,
        "number": 2,
        "cdate": 1666670568093,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670568093,
        "tmdate": 1670093412048,
        "tddate": null,
        "forum": "iYC5hOMqUg",
        "replyto": "iYC5hOMqUg",
        "invitation": "ICLR.cc/2023/Conference/Paper3964/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed a method to obtain upper bound for IG. They showed that this method is efficient and robust using simulated data. They derived the estimator on zero-inflated distribution family. Finally they showed that the encoding model achieved high IG performance on a real dataset.",
            "strength_and_weaknesses": "Strength:\nThe paper is clearly written.\nThe authors are discussing about an important question: how to evaluate a neural encoding model. \nThe authors have shown both theoretical derivations and empirical data studies.\n\nWeakness and questions:\nThe authors mainly test on 1 real dataset, just wonder if the main result (e.g. 90% IG) still holds for other datasets?\nThe mixture model achieves 90% IG on the real data example. Is this good enough? Can IG be used to compare encoding models with different distribution family?\nThere are also other common ways to measure the goodness of a neural encoding model, e.g. decoding performance. I wonder if the authors have done comparisons with other measures? Is IG consistent with other measures?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.",
            "summary_of_the_review": "This paper is clearly written and the discussed question is important. But the paper is lack of more real examples and comparisons. The authors only looked at one real dataset and didn't compare with other methods. I have proposed some detailed questions and weakness in the above section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_ALKJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_ALKJ"
        ]
    },
    {
        "id": "irgCEsP3f0",
        "original": null,
        "number": 3,
        "cdate": 1667327585698,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667327585698,
        "tmdate": 1667327585698,
        "tddate": null,
        "forum": "iYC5hOMqUg",
        "replyto": "iYC5hOMqUg",
        "invitation": "ICLR.cc/2023/Conference/Paper3964/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper identifies an issue in the Information Gain (IG) evaluation metric for neuronal population response prediction, whereby the upper bound 'oracle' likelihood estimate using a Point Estimate (PE) approach (i.e. using a point estimate for the parameters of some simple parameterised distribution like a zero-inflated LogNormal) is often lower than the corresponding lower bound 'null' model estimate. This issue is particularly apparent in settings of few samples, sparse responses or low signal-to-noise ratios (SNRs). The paper proposes to improve the PE approach by instead using a full Bayesian treatment to obtain the posterior predictive distribution for the 'oracle' by marginalising out the parameters with respect to their posterior distribution. \n\nThe paper demonstrates how to efficiently estimate the Bayesian 'oracle' with zero-inflated distributions (which are state-of-the-art ways to model neuronal population responses) and then demonstrates that the Bayesian oracle outperforms its PE counterpart, across different SNRs and sample sizes for the leave-one-out calculations (Figure 3). In section 3.2, the paper uses its proposed IG metric (with Bayesian oracle) to evaluate a trained neural encoding model, highlighting the importance of prior choice, and finally the compares IG and other metrics that have been used to evaluate neuronal population response in section 4.\n\n",
            "strength_and_weaknesses": "Strengths:\n1. The problem the paper is tackling is largely well motivated and seems to be of importance in neural encoding models (the reviewer is not an expert in this area)\n2. The proposed Bayesian oracle solution is simple and appears quite effective empirically at reducing the issues faced by the PE oracle.\n\nWeaknesses:\n1. The reviewer thinks some aspects of the approach could be developed more thoroughly: for example, does we need the full Bayesian posterior predictive in order to obtain better upper bounds or would say using a maximum-a-posteriori PE suffice in ameliorating the issues associated to current PEs. Equivalently, are current PE oracles underperforming because they are PEs, or is it because perhaps that they are overfit to the observed repeated responses (and could be improved with regularisation)? The paragraph above section 2.2 highlighting the issues with the PE approach did not read convincingly and the suggested experiment would help if I have understood correctly.\n2. Likewise, it would be interesting to see *which neurons* are the ones who are being helped by the proposed approaches in the paper: for example, one could plot the difference between the PE and Bayesian oracle as a function of the sparsity of the neuron response q, which would be interesting to see.\n3. The Bayesian oracle does still seem to have a (small) proportion of neurons for which the null model outperforms the GS model (in figure 1). Is there a reason for this/can we identify which neurons these are?\n4. The final section 4 seems a bit orthogonal to the rest of the paper, which is focused on improving IG. It would be good to develop why we care about IG relative to other metrics more though, but this should come earlier in the paper. \n5. Could the authors provide some more motivation for what benefits does improving the upper bound for the IG evaluation metric provide in practice, e.g. can we say something about neuron encoding models that we previously couldn't with the PE upper bound?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is largely written clearly and appears technically sound. The work identifies an issue in an existing metric and proposes a new approach to help with this issue.\n\nSome typos/clarifications:\n\n- prove -> proven in paragraph above section 2.\n- Appendix 4 -> Appendix D under equation 1.\n- What is f in your notation? This should be clarified.\n- What is a.u. in figure 3?\n- Brackets around exponentiated equation at the bottom of page 12.",
            "summary_of_the_review": "I am recommending weak accept as I think the paper identifies and answers a clear problem, and that the proposed approach appears to be effective in practice. I'd like to see more development as to the reason why the proposed approach works (in 'weaknesses', along with other suggestions which will hopefully improve the paper).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_rHRG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3964/Reviewer_rHRG"
        ]
    }
]