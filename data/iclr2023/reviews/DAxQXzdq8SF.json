[
    {
        "id": "DP6mAZGRoaz",
        "original": null,
        "number": 1,
        "cdate": 1666465794283,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666465794283,
        "tmdate": 1666576072402,
        "tddate": null,
        "forum": "DAxQXzdq8SF",
        "replyto": "DAxQXzdq8SF",
        "invitation": "ICLR.cc/2023/Conference/Paper397/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The main technical contribution of this paper is in proposing a variant of deep SOM (self organizing map) model that uses contrastive learning. Experimental results show that the proposed method outperforms various baselines on synthetic and real data.",
            "strength_and_weaknesses": "Strengths:\n1. I found the paper fairly straightforward to follow.\n2. The proposed method is easy to understand.\n\nWeaknesses:\n1. The proposed method is rather incremental. How contrastive learning is incorporated here is really straightforward and a bit obvious.\n2. The introduction partially emphasizes interpretability. I would have liked to see much more of a discussion on interpretability in the main paper regarding the real data experiments. Specifically, how does the interpretability of the resulting 2D SOM maps relate to existing domain knowledge for the applications of interest? How does this interpretability compare to those of baseline models that are used (i.e., does the proposed SOM-CPC model somehow yield more interpretable 2D maps than best-performing baselines?)? Moreover, I think that in answering such questions, it would be helpful to be more precise about what you mean by \"interpretability\" (maybe using terminology from, say, Lipton [2018]).\n3. I would argue that more baselines are needed. Right now the baselines are selected to be ones that use 2D embeddings, which seems like an artificially imposed constraint that really isn't required for many real applications (e.g., I'd imagine that with some real high-dimensional datasets, the low-dimensional manifold that the data approximately reside on simply can't be very accurately represented in 2D and could require more dimensions; forcing the use of a 2D embedding in this case seems like a bad idea). There have been a number of temporal clustering methods proposed in recent years, many of which use deep neural networks to help learn representations (such as but not limited to the work by Lee and Van Der Schaar [2020]). Adding some of these methods as baselines would improve the paper as we would have a better sense of how the proposed method compares to other approaches that aren't restricted to 2D embeddings.\n4. There are some parts where the notation and exposition are a little clunky and could use more polish. For instance, in the second paragraph of Section 2.1 when notation is first introduced, it is not made immediately clear what the index $j$ is for or what it ranges over, and then suddenly the index $j$ gets switched to $i$ in the next sentence. Minor: The phrase \"a given point in training\" could also perhaps be more clearly phrased as \"a given iteration of the training procedure\" where $n$ indexing the iteration number (\"a given point\" makes it sound like it might be referring to a data point).\n\nReferences:\n- Changhee Lee, Mihaela van der Schaar. Temporal Phenotyping using Deep Predictive Clustering of Disease Progression. ICML 2020.\n- Zachary C Lipton. The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Queue 2018.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** I found the paper reasonably clear although there are minor issues with notation and exposition (see weakness point #4).\n\n**Quality/novelty.** Overall, I find the paper to be very incremental and the experimental results to be insufficient (see weakness points #1, #2, and #3).\n\n**Reproducibility.** This paper appears to be reproducible although I have not done a careful check of the source code that has been provided and various details in the appendices.",
            "summary_of_the_review": "I think this paper proposes an interesting although fairly straightforward extension to existing deep SOM models that incorporates contrastive learning. More extensive evaluation of \"interpretability\" and considering additional baselines would really help improve the work although, from what I can tell, neither of these improvements would resolve the issue of the technical novelty being limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper397/Reviewer_hhoQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper397/Reviewer_hhoQ"
        ]
    },
    {
        "id": "aMNOl_QkvW-",
        "original": null,
        "number": 2,
        "cdate": 1666626170651,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626170651,
        "tmdate": 1666626170651,
        "tddate": null,
        "forum": "DAxQXzdq8SF",
        "replyto": "DAxQXzdq8SF",
        "invitation": "ICLR.cc/2023/Conference/Paper397/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a method for representation learning of multivariate time-series, which consists in the combination of Contrastive learning (for encoding the data in a compact latent space) and Self Organizing Maps (for better interpretability of the latent space). The use of interpretable unsupervised techniques is of the highest importance for biomedical applications, which makes the proposed technique appealing.",
            "strength_and_weaknesses": "Strengths:\n1.\tThe paper is well written and clearly organized.\n2.\tThe authors have tested the proposed approach on several applications (real and simulated datasets). Although what is lacking is for example the evaluation of classification performance when using the proposed unsupervised technique (for example in the sleep staging application)\n3.\tThe authors test their approach with state-of-the-art techniques, from which the proposed technique is inspired.\n4.\tThe authors provide well structured source code, which will help greatly for reproducibility of research\n\nWeaknesses:\n\n1.\tThe authors introduce the concept of aggregate causal context $c(t)$, but explain that the use of this $c(t)$ is not mandatory. The authors do not clearly explain (or I failed to understand it) whether the results in tehri experiment did use the aggregate causal context or not (and did not integrate in the ablation study)\n2.\tBiomedical time series are by essence non-stationary, therefore the use of contrastive learning may not be optimal for such data. Could the authors expand a bit on this possible drawback?\n3.\tThe explanation of multiple cluster in the audio dataset seem to be a bit overstretched. Explaining that each cluster (for same speaker correspond to a different chapter might be plausible. But did the authors listen carefully to the audio time-series, and did they notice a difference?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The methodology is novel, although the proposed approach is inspired form existing techniques.\nThe authors provide well structured source code for reproducibility purpose.\n",
            "summary_of_the_review": "This paper introduced an interesting technique for interpretable representation learning, which could be highly interesting for biomedical applications. However biomedical data can be highly non-stationary which might prevent the use of temporal contrastive learning. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper397/Reviewer_eMcU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper397/Reviewer_eMcU"
        ]
    },
    {
        "id": "iElpnG6AA9B",
        "original": null,
        "number": 3,
        "cdate": 1666654845627,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666654845627,
        "tmdate": 1666654845627,
        "tddate": null,
        "forum": "DAxQXzdq8SF",
        "replyto": "DAxQXzdq8SF",
        "invitation": "ICLR.cc/2023/Conference/Paper397/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The submission proposes an algorithm to learn representations of high-rate time series.They focus on a family of models called deep Self Organizing Maps (deep-SOM), models that combine the original SOM objective with (1) neural networks and (2) a task reconstruction loss. The authors introduce a novel variant, SOM-CPC, which follows the deep-SOM formulation, but replaces the task reconstruction loss with an info-NCE objective. Empirical evaluation of their model showcases the strenghts of their proposed approach.\n",
            "strength_and_weaknesses": "Strenghts:\n- The paper is clear, highlighting the necesary related work to understand the proposed algorithm. \n- The empirical evaluation demonstrates good performance across a variety of settings.\n- The proposed method is reasonably novel in that it differs from the other instances of SOM-type models.\n- Code is released, making reproducing the results more feasible.\n\nWeaknesses:\n- The proposed approach reads as a semi-direct application of CPC. CPC (and other objectives similar to InfoNCE) are shown to work across a variety of domains. It is therefore not that surprising that incorporating CPC in a representation task (as one of the two objectives works well).\n- I feel a comparative evaluation of different contrastive objectives might be warranted: does adding temperature bring benefits as in [1]? What about MoCo, SimCLR-type objectives (do they work well in this context)?\n\nReferences:\n[1] CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: A good paper, well-written. Sound empirical evaluation.\nClarity: Clear, in my opinion.\nOriginality: Debatable. On one hand, the approach works and no one has tried something similar, as far as I can tell. On the other hand, the main contribution of the paper is applying InfoNCE to a type of problem for which it is intuitively well suited.",
            "summary_of_the_review": "A well-written, clear paper with good empirical contributions. The authors are clearly proposing a working solution to a real problem, hence my rating of at least 6. On the other hand, the proposed approach can be read as marginally derivative, applying an algorithm that intuitively should work for the problem being considered. This in my opinion justifies not giving a higher score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper397/Reviewer_FiNp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper397/Reviewer_FiNp"
        ]
    }
]