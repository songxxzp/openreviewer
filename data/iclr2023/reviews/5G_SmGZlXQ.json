[
    {
        "id": "71TXbl6nBH",
        "original": null,
        "number": 1,
        "cdate": 1666388850157,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666388850157,
        "tmdate": 1666640169488,
        "tddate": null,
        "forum": "5G_SmGZlXQ",
        "replyto": "5G_SmGZlXQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3553/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper describes a method for characterizing the amount of added toxicity in a multilingual machine translation system\u2019s output. The toxicity detection method is a list-based approach that is unchanged from an earlier publication (NLLB Team et al 2022, cited prominently and repeatedly). The main contributions here are:\n\n(1) Moving from FLORES as the test set to translations from English of the recently proposed Holistic Bias corpus. The main insight seems to be that for toxicity analysis, one doesn\u2019t really need references so much as source sentences that cover topics that are likely to elicit the introduction of toxicity.\n\n(2) They provide an analysis of properties of sentences that tend to elicit added toxicity in Section 3.1 Outside of the bottom half of figure 2, this is mostly descriptive. We get the flavor of what matters with little quantification (\u201cmost of the languages\u201d, \u201cmuch more often\u201d).\n\n(3) They use explainability methods plus robustness characterizations to try to explain added toxicity, and to propose a very weak toxicity detector.\n\n(4) They provide a human verification of the toxicity detector\u2019s output, characterizing the False Positive rate by checking each toxic addition, and using insights from (2) to aim annotators toward examples likely to have False Negatives.",
            "strength_and_weaknesses": "Strengths:\n\nThis is an important problem, and it\u2019s nice to have a paper dedicated to it. \n\nThe paper is mostly clear and easy to follow.\n\nThe proposed list-based method with synthetic but targeted source sentences seems to strike a good balance of interpretability and recall of actual problems. The included human check goes a long way toward validating this approach. It is likely to be adopted by others.\n\nThe characterization of sentences that have added toxicity (plus the details in the appendix) are nice sources of insight and inspiration.\n\nWeaknesses:\n\nI think the paper\u2019s primary contribution (the adoption of the Holistic Bias corpus as a set of source sentences) would have been stronger if they had compared the discovered toxicity rates to those of FLORES-200. It feels like you have to read both papers in order to follow the first and most important sentence of their conclusion.\n\nI didn\u2019t get much out of the Phenomena Causing Toxicity section or the Robustness of Translations section. This felt somewhat out of place compared with the rest of the paper. It was hard to follow, with statistics and methods being introduced and tested in rapid fire, and I\u2019m not sure what was accomplished. I don\u2019t think the goal was to build a glass-box toxicity detector. It would be hard to beat the black-box detector that uses the same word-list based methodology as the gold standard. Instead, the goal appears to have been to explain where toxicity came from in the model. To that end, we are left with the intuition that it is some mix of hallucination and mistranslation of the source. I think this section would have hit a lot harder if the authors had acted on one of their three suggestions (clean mistranslated data, avoid hallucination, be weary of instability) as a way of validating this approach to explanation.\n\nIt\u2019s also strange that there is a large section on explanation / detection, and another section on characterizing based on input attributes, but the authors never contrast the two. Which is more predictive of added toxicity? Input characteristics or glass-box features?\n\nI would have liked to have seen more discussion of the False Positive human evaluation. I couldn\u2019t believe it when that section ended! What caused all those False Positives? Could they be fixed by removing one or two problematic list entries, or was it more complicated than that? IE: do these languages inherently resist the list-based approach?\n\nI would have also liked to have seen more discussion (and numbers) regarding the types of sentences leading to added toxicity. As suggested in my summary, it feels like we have the take the authors\u2019 descriptions at face value, with few backing numbers.\n\nThere are some editing mistakes that detract from an otherwise clean paper:\n\nThe last few sentences of the second paragraph of the introduction are repeated.\n\nThe first sentence of the third paragraph of 4.1 talks about \u201ctoxicity rates\u201d when I think it means to discuss \u201cfalse positive rates\u201d.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear except for the problems mentioned above.\n\nI\u2019m not sure what is meant by quality of work, but this seems to be solid science. The persistent use of various statistical tests, and brief mentions of what results one might expect by chance when doing tests over so many languages was a very nice touch.\n\nThe work is original enough - it would be easy enough to characterize this as a simple addition of two ideas (list based analysis + an existing template-based corpus), but as I mentioned above, I think this strikes the right balance of interpretability and recall. This is a domain where one doesn\u2019t necessarily want to be clever or fancy at the cost of being actionable and scalable. I worry that much of 3.3+3.4 is an attempt to add some technical weight to the paper, where I think more analysis of the actual text might have been more useful and interesting.",
            "summary_of_the_review": "This is not a perfect paper, but it\u2019s solid work on an important topic. I suspect that the solution landed on here (word lists + a template-based corpus) will be good enough for most industrial labs; i.e.: this has a shot at being the definitive citation for the problem of detecting and characterizing added toxicity in MT. I would have liked to have seen more input-related numbers and visualizations over broad text-based descriptions, and I wasn\u2019t crazy about the explainability portion, but I don\u2019t think that should hold the paper back from the public.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_HKPu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_HKPu"
        ]
    },
    {
        "id": "5gEbFiG9PK",
        "original": null,
        "number": 2,
        "cdate": 1666649152927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649152927,
        "tmdate": 1670949857824,
        "tddate": null,
        "forum": "5G_SmGZlXQ",
        "replyto": "5G_SmGZlXQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3553/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper discusses added toxicity detection. The authors conducted substantial analysis in a larger scale multilingual data set containing 164 languages in total. In the work, they combined the NLLB toxicity detection strategy, the HOLISTICBIAS dataset, and the ALTI+ methodology. This type of analysis or data set are useful to assess the MT systems outputs from the ethical perspectives, especially the MT systems suffer from generating offensive outputs regardless of source context or inputs and such errors are critical to human users.  ",
            "strength_and_weaknesses": "Strengths\n- Extensive results and analyses are conducted across languages. \n\nWeakness\n- The paper summarizes the toxicity detection methodology, but do you have any thoughts on how to modify the detected sentences and how to give the feedbacks to have the model less toxic",
            "clarity,_quality,_novelty_and_reproducibility": "It is interesting to read the provided experimental results and analyses which cover many languages. \"added toxicity\" is a critical error in the machine translation outputs. To address this issue, the paper conducted substantial analyses and  summarizes the data points that would be beneficial in the future research. \n\nI was wondering that the NLLB model is trained on lots of problematic data since you obtained sentence outputs with the added toxicity. Ideally, once you detect the critical error sentences, what would you expect the model to behave and how to fix the translation outputs, properly? Do you have any ideas or suggestions? In this light, I would like to see how this methodology helps in terms of data filtering and how you could suppress the added toxicity issues by retraining models on filtered-out data. ",
            "summary_of_the_review": "The paper provides extensive results and analysis on the added toxicity found in MT outputs. Such offensive tokens are known to be a critical error in a practical word, and from the ethical viewpoints, the research topic is worthwhile studying. However, the paper is limited to reporting the analyses and numbers, and it might lack of discussion on how to modify the translation outputs after detection, and how to fix the model itself by removing the toxic data. In this context, I would suggest the authors to try out the proposed methodology as a data filtering tool and by training the model on the filtered-out data, \nI would like to learn how much they can successfully suppress the toxicity in the MT outputs at the end.\n\n+++++++\n\nthank you for considering my comments. Since they are not addressed clearly, I will have my score unchanged.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "As the authors claim at the beginning, this paper contains some toxic examples that may be offensive.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_PvYr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_PvYr"
        ]
    },
    {
        "id": "2KXJspyXETg",
        "original": null,
        "number": 3,
        "cdate": 1666798115753,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666798115753,
        "tmdate": 1666799169224,
        "tddate": null,
        "forum": "5G_SmGZlXQ",
        "replyto": "5G_SmGZlXQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3553/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new paradigm to detect toxicity from multilingual machine translation systems. Basically, the proposed paradigm combines a wordlist method, a specific dataset, and an interpretability method. By using this paradigm, it examines the translation outputs from a multilingual machine translation system. Finally, it reveals some valuable findings about the translation errors from the MNMT system which are very helpful to understand the target MNMT system. \n\n",
            "strength_and_weaknesses": "Strengths:\n1. This paper studies an important topic for multilingual machine translation.\n2. This paper reveals some valuable findings according to human evaluation.\n\nWeaknesses:\n1. The paradigm part of this paper is not clear to me. In section 2, almost all of spaces are used to present something like preliminaries such as definition, an existing dataset and existing interpretability method. However, it does not explain the paradigm to detect toxicity, i.e., how to combine all the three for the new paradigm. Therefore, it is not clear for me what is the technical contribution and novelty of the proposed paradigm on toxicity detection.\n\n2. It seems that the proposed toxicity detection paradigm is dependent on the word alignment and interpretability method. However, this paper does not study its effects on different interpretability methods. In addition, the interpretability method used by this method is presented by an arxiv paper commented as work in progress. In fact, there are many word alignment toolkits which may be much better than the alignment model used in this paper. Moreover, the findings are from the particular dataset, which are very short and not general enough. It is unclear these findings hold on other datasets.\n\nMinor issues:\nThe sentence appears twice in the paragraph two section 1: \"Nevertheless, the overall prevalence of potential added toxicity remains low when evaluating translations of formal sentences such as those in FLORES-200, which makes it difficult to draw conclusions as to this specific aspect of a model\u2019s performance. \".\n",
            "clarity,_quality,_novelty_and_reproducibility": "See details from weaknesses and strengths. ",
            "summary_of_the_review": "See details from weaknesses and strengths. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_mzzx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_mzzx"
        ]
    },
    {
        "id": "SzzFeLKvPk",
        "original": null,
        "number": 4,
        "cdate": 1667064423861,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667064423861,
        "tmdate": 1667064423861,
        "tddate": null,
        "forum": "5G_SmGZlXQ",
        "replyto": "5G_SmGZlXQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3553/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents an approach to detect and analyse toxicity on translations of the HolisticBIAS dataset (originally in English) into 164 languages. The authors attempt to detect the cause of added toxicity in translations and to that end analyse the source contribution and source-target alignment in potentially toxic and non-toxic translations. For the analysis they use a combination of ALTI+ method (source and target contribution) and the Gini impurity metric.\n\n ",
            "strength_and_weaknesses": "The paper provides an interesting analysis of added toxicity over a large set of translations. The amount of languages covered is impressive for this type of bias-benchmark dataset, and the authors try to evaluate two core assumptions regarding the addition of toxic tokens by an MT system: the evaluate the attribution to the source tokens (degree of source sentence contribution) for toxic vs non-toxic cases as well as the word alignment for recurrent descriptor words in the dataset. \n\nHowever, the conclusions drawn from the experiments in the paper are somewhat limited and inconclusive: the authors show that the degree of source contribution is not completely uncorrelated to the added toxicity in the majority of the languages under evaluation, but it is hard to draw any further conclusions. Similarly, very high values of Gini impurity seem to provide a useful signal for toxicity, but still the recall and precision are very low. These methods provide the basis for further analysis, however in the main paper there is no attempt to further qualitative or quantitative analysis per language (except for Figure 2 which is however not really analysed in text). The Appendix C does contain some further attempts for fine-grained analysis that could give useful findings, but it is limited (and not in the main paper). \n\nAdditionally, rather than a novel approach to quantify the amount of added toxicity, the work presents an application of existing approaches to a new corpus. The main aim and contribution of the paper is not stated very clearly and the paper would benefit from a thorough revision. I belive it could turn into a useful contribution, but at this stage it is not suitable for presentation to ICLR. I am adding below some more detailed actionable comments to the authors:\n\nIt is not clear what \u201cdirections\u201d correspond to when mentioned in the abstract, I think it should be translation directions? Although since all translation are out-of-English, perhaps this could be rephrased to be made more clear.\n\nThe mention of automated MT evaluation in the introduction is very outdated. Recent reference-based metrics are mostly trainable (BLEURT, COMET, BleuScore) and there are also automated quality estimation systems for MT that do not require references at all.\n\nI would also cite the corresponding Critical error detection task as well from the Findings of Quality Estimation Shared task 2021 apart from the Sharou and Specia paper. Also I would potentially look into and comment about the approaches of the participants in that task.\n\nThe following passage is repeated in the text:\n\u201cThe NLLB Team et al. (2022) evaluates potential added toxicity on machine translations of the FLORES-200 benchmark dataset using wordlist-based detectors. Such detectors are known for their limitations when it comes to over-detecting items that are toxic only in specific contexts. Nevertheless, the overall prevalence of potential added toxicity remains low when evaluating translations of formal sentences such as those in FLORES-200, which makes it difficult to draw conclusions as to this specific aspect of a model\u2019s performance.\u201d\n\nIt is unclear what is the proposed \u201capproach to automatically quantify the amount of overall added toxicity\u201d that is mentioned as the main contribution in the introduction. Overall, while the introduction raises interesting points is does not help understand what is the novelty and contribution of this work. The last paragraph cramps together a few numbers representing obtained results but the way this is presented it is impossible for the reader to understand how to interpret these numbers and how they compare with other work (e.g. is \u201ccatching 22.3% of the toxicity insertions.\u201d a good or a bad result?).\n\nIs there some empirical or theoretical basis for the hallucination threshold on source attribution (\u201cAs a rule of thumb, we consider a source contribution to be low when it is smaller than a threshold of 40%, in which case we consider the target word is much more likely to be the result of model hallucination.\u201d)? Please cite or explain accordingly.\n\nWouldn\u2019t it make sense to analyse results for toxicity and source contributions for each language separately? Especially since as mentioned by the authors, different languages display different levels of toxicity, while the translation quality and characteristics per language is also known to vary.\n\nIn the statistical significance test you mention: \u201cIf source contribution and toxicity were completely uncorrelated, we would expect to find a result at least this significant for only roughly 5% of languages.\u201d \u2014> I don\u2019t understand this statement, since the test is performed for each language separately? I suspect this is a typo and would like to invite the authors to rephrase/correct.",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty of the paper is somewhat limited since the authors rely in a combination of existing methods on a new dataset. Clarity is also limited and the paper would benefit from some restructuring so that the reader does not have to go back and forth to understand the experiments, however the motivation, main methods and results are clear upon reading the full paper.\n\nRegarding reproducibility the results seem to be be fully reproducible. It would be beneficial if the authors release the translations and human evaluation.",
            "summary_of_the_review": "Could prove to be a useful resource with some interesting insights on added toxicity across different languages but it is not suitable for an ICLR publication yet.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_APYv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3553/Reviewer_APYv"
        ]
    }
]