[
    {
        "id": "C2cGs3nRRaS",
        "original": null,
        "number": 1,
        "cdate": 1666538159376,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666538159376,
        "tmdate": 1666613206747,
        "tddate": null,
        "forum": "u9sFrzSBRK8",
        "replyto": "u9sFrzSBRK8",
        "invitation": "ICLR.cc/2023/Conference/Paper2462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a combinatorial node labeling framework, which solves CO problems by labeling the nodes. The model is based on graph attention networks and trained by reinforcement learning. Graph coloring and minimum vertex cover are studied. Experiments prove the performance of the proposed framework.",
            "strength_and_weaknesses": "Strength\n- The perspective of unifying CO problems in the framework of node labeling is novel and makes sense. \n- Writing is good and the paper is easy to follow.\n- Experiments are sufficient. Experimental settings (baselines, datasets, paremeter settings, etc.) are presented clearly, and results are convincing.\nWeakness \n- One of the biggest concerns is whether the framework really works on the task MVC, which is usually not processed as  the node labeling problem in the main stream of literature. And in this sense, baselines are too old. To make the results more convincing, more recent baselines, e.g. [1][2], and traditional solvers should be compared. Only by comparing the sota methods and traditional ones on both running time and the results on the MVC problem, can the paper prove that node labeling works in tasks beyond graph coloring. Whether it `really' works well on MVC is the key point to judge whether the significance of unifying the CO problems into the node labeling framework is over-claimed.\n-The other concern is the technical novelty of the paper, it seems to me an increment extension from binary classification to the multi-class case based on existing S2V-DQN framework.\n\n[1] Local Search with Efficient Automatic Configuration for Minimum Vertex Cover\n[2] Efficient Minimum Weight Vertex Cover Heuristics Using Graph Neural Networks",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is presented in good clarity and quality. The idea is novel and the results are believed to be reproducible.",
            "summary_of_the_review": "This paper unifies a lot of CO problems into the node labeling framework. Experiments on graph coloring and MVC show the significance. The problem is that the significance of dealing CO problems as node labeling might be overclaimed. More experiments on MVC compare with stronger baselines or experiments on other tasks are recommended.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_j1zE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_j1zE"
        ]
    },
    {
        "id": "MmLNosq4s39",
        "original": null,
        "number": 2,
        "cdate": 1666591690641,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591690641,
        "tmdate": 1666609330325,
        "tddate": null,
        "forum": "u9sFrzSBRK8",
        "replyto": "u9sFrzSBRK8",
        "invitation": "ICLR.cc/2023/Conference/Paper2462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper extends S2V-DQN and enables it to cover more node-labeling-related problems. In terms of the neural network model, S2V embedding is replaced by more recent GAT embedding. Experiments are conducted on graph coloring and minimum vertex cover.",
            "strength_and_weaknesses": "**Strength**\n1. This paper extends the classic S2V-DQN approach, with the purpose to fit into more general problems.\n2. Learning node labels is an interesting characteristic of learning CO, which may inspire future papers.\n\n**Weakness**\n1. The overall pipeline of this proposed approach is very similar to S2V-DQN, and such a reinforcement learning pipeline is actually followed by many other papers to tackle different problems since the S2V-DQN paper was published in 2017. For example, the following papers also study graph coloring:\n    * Enhancing column generation by a machine-learning-based pricing heuristic for graph coloring. AAAI 2022. \n    * Approximation ratios of graph neural networks for combinatorial problems. NeurIPS 2019.\n\n   Considering these existing papers, the node-assignment step, which is the main technical contribution of this paper, seems incremental.\n\n2. Adopting attention models for CO is either a new idea, for example, the highly cited paper:\n    * Attention, learn to solve routing problems! ICLR 2018.\n\n   So in this paper, replacing S2V with GAT in the model does not seem novel either.\n2. Since the proposed scheme also covers \"set\" and \"permutation\" problems, it will be interesting to see the performance of the proposed method on well-studied problems such as TSP. It will be easier to position the effectiveness of this approach w.r.t. existing papers with the results on problems like TSP.",
            "clarity,_quality,_novelty_and_reproducibility": "The authors include code in the supplementary so the clarity and reproducibility are good.",
            "summary_of_the_review": "The idea of \"learning node labeling\" for CO is novel and interesting, however, the technical contributions of this paper seem trivial and incremental. I am suggesting a rejection in consideration of the lack of technical novelty.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_aTgv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_aTgv"
        ]
    },
    {
        "id": "q4Jum-NS5n",
        "original": null,
        "number": 3,
        "cdate": 1666609188570,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666609188570,
        "tmdate": 1666609188570,
        "tddate": null,
        "forum": "u9sFrzSBRK8",
        "replyto": "u9sFrzSBRK8",
        "invitation": "ICLR.cc/2023/Conference/Paper2462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a graph attention network trained using policy gradient reinforcement learning that can label nodes in an efficient way to (try to) solve hard combinatorial optimization problems. They test their method on the graph coloring and minimum vertex cover problem on different kinds of graphs , comparing the performances with greedy algorithms and different neural networks approaches proposed in the past.",
            "strength_and_weaknesses": "\nThe idea to create an efficient way for node labeling in combinatorial optimization problems is new and promising. Indeed, in greedy algorithms (GA) one decides the rules to choose the next node to label. In GA these rules are chosen a-priori, and different choices are possible: taking inspiration from GA, the authors try to infer which is the best order using a Graph attention network: the resulting order for node labeling is different from the standard GA ones.\n\nThe main weakness of the paper is that the performances of the method are not extensively investigated and the comparison with existent methods to solve combinatorial optimization problems is not completely fair and exhaustive. Moreover, the weaknesses of the results are only shown in the Appendix and not in the main text.\n\nFor the graph coloring (GC), the authors compare their results with GAs and with the machine learning (ML) approach of Lemos et al (2019) (GNN-GCP). GNN-GCP is not very good for GC. In fact it acts as a classifier, with the only output being the predicted chromatic number and not a possible configuration of nodes labels. For this reason GNN-GCP can find a number of colors smaller than the correct one, that is a highly undesirable feature. I suggest to compare the results of the method proposed by the authors with other better ML approaches to GC, such as the one in Jan Toenshoff, Martin Ritzert, Hinrikus Wolf, and Martin Grohe. Frontiers in artificial intelligence, 3:98, 2021 (the arXiv reference in the draft should be updated with the published one) or the recent Schuetz, Martin JA, et al. \"Graph Coloring with Physics-Inspired Graph Neural Networks.\" arXiv preprint arXiv:2202.01606 (2022).\n\nFor GC on simple family of graphs, like wheels, trees, even/odd cycles, after a training on graphs up to 400 nodes, the proposed method finds the good chromatic number on graphs up to 1000. The author could test the performances on larger instances in this very basic examples to check if performances degrade going to larger sizes.\n\nThe runtime is shown in Fig. 6-7 for GC and Fig. 8 for MVC. In this last case, the scaling seems to be exponential with the size of the problem and not linear. However in both cases a fit should be performed to show if the scaling is linear or not. (In Fig. 6 the scaling of DSATUR seems to be not-linear too; however DSATUR is a simple greedy method that should perform in linear time, thus I have some doubt on the good implementation of it).\n\nWhen tested on sparse Erdos-Renyi graphs of average connectivity c=7.5, the method proposed by the authors finds a chromatic number of almost 5 for instances with 100 nodes, and a chromatic number of almost 6 for instances with 600 nodes. However a standard message passing algorithm, or a stochastic walk-sat algorithm can find a good coloring with 4 colors up to connectivity larger than 8 for much larger graphs in linear time (see for example L Zdeborova and F Krzakala. Phase transitions in the coloring of random graphs. Physical Review E, 76(3):031131, 2007). Thus the performances of the proposed method are really poor in this case and degrade fast with growing sizes.\n\nFor MVC, following table 10 the proposed method cannot reach results obtained by other existing ML methods. Moreover no comparisons with standard algorithms is performed.\n\nIn Table 7 one notices that performances of the proposed method quite strongly depend on the training set: if trained on ER graphs, the performances on BA graphs reduce and vice-versa: the method cannot generalize well.",
            "clarity,_quality,_novelty_and_reproducibility": "The authors add their code in the supplementary material, to ensure reproducibility. However I did not test it.\n\nFor the reasons explained in the previous section, I do not think the quality of the paper is good enough. \n\nI list here some minor points / typos:\n- Section 2.1: a node labelling is a mapping V\u2192{0,\u2026,n} . n, the max label, could be different from the number of nodes. Coloring is an example of that.\n- Lemma 3.2: \u201c...choosing the label 1 until every vertex in G is adjacent to a node\u2026\u201d replace vertex with edge\n- Section 3.2, paragraph Local attention decoder: in the definition of a_v^{(t)} change h_i with h_v\n- Table 9 only shows cost for ER and BA graphs, while in the caption also WS graphs are mentioned",
            "summary_of_the_review": "Summarizing while the idea of finding an efficient way for node labeling in hard combinatorial problems is new and interesting, the results obtained in the draft are not good enough: the proposed method cannot reach the performances of standard algorithms, it does not generalize well and its performances degrade going to larger sizes of the problems.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_isah"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_isah"
        ]
    },
    {
        "id": "VWLHhnaAwFq",
        "original": null,
        "number": 4,
        "cdate": 1666649693480,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649693480,
        "tmdate": 1666649693480,
        "tddate": null,
        "forum": "u9sFrzSBRK8",
        "replyto": "u9sFrzSBRK8",
        "invitation": "ICLR.cc/2023/Conference/Paper2462/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a framework for learning combinatorial problems over graphs in which the solution can be expressed in terms of an ordered labeling of the nodes. Then, the authors propose GAT-CNL, a neural architecture leveraging the framework to learn to solve such class of problems in a greedy fashion. Empirically, the method presents better results when solving graph coloring and minimum vertex cover.",
            "strength_and_weaknesses": "--- Strength ---\na) The node labeling framework is a clear formulation of a wide class of problems and will help guide future contributions.\nb) The graph coloring problem indeed never had, to the best of my knowledge, a more general ML solution.\nc) Their MDP formulation allows for more than two labels and, more importantly, unknown number of labels. This is because a state is not a partial solution, but a partial labeling, which is fundamentally different.\nd) Lemma 2.4 guarantees a solution in the MDP space, which is not a common result in previous literature.\ne) Empirical results, especially for GC, are very promising.\n\n--- Weaknesses ---\na) Throughout the text, the authors argue that node labeling and greedy strategies are intimately related (due to the ordering of labels). I understand that it's a natural relationship when we design heuristics, but we know that relationship does not necessarily exist in optimal solutions. I think it would be good to make this distinction more clear.\nb) I find the proofs not rigorous enough (although the statements seem to be true to me). The authors try to present constructive arguments, which can result incur easily in this (without enough care). From what I see the proofs can be rewritten to use contradiction instead. A good example of this is Lemma 3.2's proof: The authors construct a solution and immediately conclude \" Labeling the nodes in this order produces a minimum vertex cover of G.\". I understand the lemma stands, but it reads sloppy.\nc) I expected to see larger graphs in the dataset. Also, for ML in combinatorial opt, it is vital to test your solution on graphs that are larger at test time (shift in distribution).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written and easy to follow. The entire training procedure, including hyperparams, is described, which results in transparency and good reproducibility. The paper is not very different from what the ML community has been doing in combinatorial optimization, so novelty is a bit limited (although it definitely exists).",
            "summary_of_the_review": "In my opinion the paper needs a little bit more of work, since the weaknesses currently outweigh the contributions. If the authors are able to test the solution on larger graphs and make the proofs more rigorous, I'm willing to raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_wJkv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2462/Reviewer_wJkv"
        ]
    }
]