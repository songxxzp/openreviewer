[
    {
        "id": "jMYh1pBmZN",
        "original": null,
        "number": 2,
        "cdate": 1666016808092,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666016808092,
        "tmdate": 1666016808092,
        "tddate": null,
        "forum": "22h1XSEiN0",
        "replyto": "22h1XSEiN0",
        "invitation": "ICLR.cc/2023/Conference/Paper4522/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an approach to provide a probabilistic forecast on top of any point forecast. Two post-processing approaches in particular are investigated, one fits a Gaussian noise by learning a condition heteroskedastic variance on top of an existing point forecast, the other fits a quantile-regression model. Experiments are conducted by applying this post-processing to an existing method (NHits) on 7 datasets against several baselines with an emphasis on long-term forecasting performance.",
            "strength_and_weaknesses": "The main strength of the paper are that it is clearly written and has clear motivation since providing accurate probabilistic forecast on top of point forecast has many relevant applications.\n\nThe main weaknesses are as follow.\n\nThe approach is very related to conformal prediction, see [Romano 2019] for instance who proposes to fit a quantile regression model that can be guaranteed to be calibrated or [Hasson2021] who already showed the benefit of the approach by demonstrating how the top point forecast of M5 could be made a top competitor to the uncertainty track with a post-processing. Sadly, those approaches are not mentioned nor compared while being directly similar to the method proposed.\n\nIn addition, the method proposed does not distinguish itself clearly from just fitting a Gaussian/Quantile regression on top of an existing architecture. Indeed, the main improvement reported in the experiments seems to come from using an architecture better suited for long term predictions (NHiTS). However, one could also fit the same model with a Gaussian likelihood or a quantile regression as the loss function of NHiTS and likely obtain similar results in term of CRPS and calibration. The main difference of the approach proposed is the two step estimation but it is not compared to the simpler approach consisting on just fitting a distribution on top of an existing model and also have drawbacks that are not mentioned (two training must be done and latency will likely be twice higher).\n\nTo clearly justify their contribution, the authors should probably show that their methods outperforms both non conformal prediction approaches and fitting Gaussian/quantile regression approaches (the first one because it is state-of-the-art and the standard approach, the second one because it is arguably simpler and faster than the proposed method by the authors). \n\n[Hasson 2021] Probabilistic Forecasting: A Level-Set Approach. Hasson et al. Neurips 2021.\n[Romano 2019] Conformalized Quantile Regression. Romano et al. Neurips 2019.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written. The novelty is poor given the similarity to quantile conformal regression which is not mentioned in this work or even just fitting simple likelihood on top of existing models. The reproducibility is good, the author provided code that should allow one to rerun the benchmarks (which I did not check nor try to run).\n",
            "summary_of_the_review": "Given the lack of novelty and lack of comparison with relevant approaches (conformal quantile prediction, likelihood directly fitted on top of previous models, [Hasson2021]), I recommend rejecting the paper in its current state.\n\nAdditional details:\n* p3: Salinas et al. (2020) does not consider only Gaussian noise model but also other likelihood (neg-binomial for instance)\n* p4: \"To train this model, we use maximum likelihood in a two-step manner, first training the mean model ... using MSE loss, and then ... maximizing the likelihood of the Gaussian observation.\" This seems to be the claimed novelty but a clear baseline would to fit both mean/variance or have a quantile regression on top of an existing architecture. This would have twice lower training runtime and latency and should probably be added in the comparisons (in addition to conformal prediction).\n* Figure 7: this figure is hard to read since you are plotting samples for some methods and confidence intervals for others. It would be much better to report calibration to allow to quantify the calibration of the probabilistic predictions as you are doing for wind/nasdaq\n* why reporting calibration only on wind/nasdaq on not on other datasets (electricity/traffic/etc)? I would recommend reporting calibration plots on all datasets, calibration errors would also be important to provide quantitative metrics\n* Figure 9: small comment calibration are typically plotted with equal axis as it is then easier to assess the quality of the fit\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_RuZ4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_RuZ4"
        ]
    },
    {
        "id": "w82Pskub5G1",
        "original": null,
        "number": 3,
        "cdate": 1666599380369,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599380369,
        "tmdate": 1668961688802,
        "tddate": null,
        "forum": "22h1XSEiN0",
        "replyto": "22h1XSEiN0",
        "invitation": "ICLR.cc/2023/Conference/Paper4522/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work considers long-term time series forecasting based on on deep probabilistic techniques. It shows that intrinsic stochasticity in data is often so remarkable that it poses notable challenges for the interpretation of many current deterministic methods. Importantly, the authors argue that uncertainty quantification is less important than neural network architecture design in many practical scenarios. The authors suggest a probabilistic evaluation framework that solves this challenge and improves prediction on common benchmarks and practical problems in climatology and economy.",
            "strength_and_weaknesses": "Strength\n\n+ intuitive representation of uncertainty through probabilistic treatment\n+ scalability of the method\n+ complements the current state of understanding in an innovative way\n+ relevance to a broad variety real application cases\n\nWeaknesses\n- Limitations and weaknesses of the method could be addressed in the manuscript in more detail as these are relevant for applications",
            "clarity,_quality,_novelty_and_reproducibility": "The reporting is clear and good quality, the approach is novel and innovative, and the relevant literature has been properly cited. Reproducibility has been described properly, and links to public repositories are provided. I did not manage to access these (due to anonymization of the submission?) and could not investigate the code itself. Some data sets may pose challenges for reproducibility: it is said that \"the hourly NASDAQ-100 dataset can also be easily reproduced using public logs\"; a code for doing this could improve the reproducibility further. It is not clear whether the code is provided with an open license.\n\n\n\n",
            "summary_of_the_review": "Overall this is an interesting and timely contribution of good technical quality. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_5QvS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_5QvS"
        ]
    },
    {
        "id": "odTR8owWlEB",
        "original": null,
        "number": 4,
        "cdate": 1666637081804,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637081804,
        "tmdate": 1669505370800,
        "tddate": null,
        "forum": "22h1XSEiN0",
        "replyto": "22h1XSEiN0",
        "invitation": "ICLR.cc/2023/Conference/Paper4522/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a new view of the probabilistic forecasting problem. The authors have shown some drawbacks of some current state-of-the-art probabilistic forecasting methods and propose that a simple model coupled with quantile loss or heteroscedastic Gaussian regression can often outperform more complex and expensive alternatives, particularly in the long horizon setting. The authors support their claim on multiple time series datasets from different domains and with distinct properties. They have also studied how the prediction horizon and time series dimension affect the inference time. Finally, they reach the conclusion that the architecture design of forecasting models should be prioritized over uncertainty quantification techniques.",
            "strength_and_weaknesses": "Strength:\nThe authors have conducted extensive empirical evaluations and conducted a comprehensive background review. The most inspiring part is the discussion on the impact of intrinsic stochasticity and the structure of data on forecasting models. Based on this property, the authors have divided the analysis into time series from different domains. This can serve as an interesting reference for the characteristics of time series datasets and provide insights on which model to choose.\n\nWeakness:\nThis paper is driven by pure empirical studies without theoretical insights or methodological innovation. The employed forecasting models and loss functions are all well-studied. The major work done by the authors is to combine them together and make a comparison on different datasets. Moreover, the authors don't provide a clear explanation of why the NHiTS is chosen as the base model and what is the intuition of its better performance than other complex methods. Lastly, I am also confused about how the authors reached the conclusion that architecture design should be prioritized over uncertainty quantification since the whole paper is comparing CRPS results across different methods. The authors apparently need a transition on this.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is ambiguous on how its conclusion is reached. There is also not too much technical novelty. The authors have provided code to reproduce their experiments.",
            "summary_of_the_review": "This paper is an empirical study of probabilistic forecasting models, while it lacks solid technical novelty and theoretical insights. There is not much innovation in experiments either. I think this paper will benefit from another round of revision.\n\n**Update after rebuttal**\n\nThe authors' responses have addressed some of my concerns, but I believe they are still not sufficient to significantly change my view of this paper. I would encourage authors to incorporate answers to the abovementioned questions in the next revision and discuss the underlying theoretical insights on why the methodology is performed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_Cp5J"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4522/Reviewer_Cp5J"
        ]
    }
]