[
    {
        "id": "FOEu99AwDo",
        "original": null,
        "number": 1,
        "cdate": 1666298019126,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666298019126,
        "tmdate": 1666298019126,
        "tddate": null,
        "forum": "d8CBRlWNkqH",
        "replyto": "d8CBRlWNkqH",
        "invitation": "ICLR.cc/2023/Conference/Paper1111/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a neural network based solver which estimates an explicit transport map rather than just using OT losses. Specifically, the authors introduced a weak OT formulation so as to find the potentially stochastic optimal transport map. The resulting objective becomes a minimax optimization which is learning a transport map and a potential simultaneously and both of them can be parameterized as neural networks. The proposed method is evaluated on a couple of datasets and compared against several baselines. The experimental results are quite encouraging as the estimated map can pushforwards image samples among different contexts but keep the style. ",
            "strength_and_weaknesses": "Pros:\n- Overall, the paper is well-written as the authors delivered their proposed approach clearly. \n- The organization of section 4 is encouraging and easy to follow. It is clear that the proposed method is motivated by the Kantorovich dual formulation with an additional C-transformation.\n- The experimental part is quite sufficient. The authors have conducted experiments on multiple datasets, including anime faces, CelebA datasets and so on. This is quite valuable as OT map estimation approaches are usually concerned with scalability.  \n\nCons and questions:\n- Is it possible to better justify the advantages of the optimal transport map formulation, rather than existing deep generative frameworks? An optimal transport map may allow for better interpretability and generalization. Is it possible to have so called out-of-sample transport results, like in figure 1 of[1], figure 4 of [2]? Also, given the ideally nice smoothness properties of OT maps, shall we expect some results like \"king - man + women - queen\" when we are transporting image samples?\n- While the problem formulation doesn't specify the ground metric. It seems that in the experiments, the authors are still using the quadratic cost. It is reasonable for the image datasets, however it could be nice if there are experimental results for other types of ground metrics, such as cosine similarity for language embeddings.\n- What are the values of z_1, z_2, and z_3 in figure 6, 7, 12, 17 and later?  Does that impose some kind of interpretability on the map?\n- From my understanding, it is true that under the given conditions, an optimal transport plan induced the transport map, which further characterizes the corresponding Wasserstein barycenters and the geodesic. However, given that the transport map is parameterized by a feedforward neural network (U-net), how does this U-net characterize the joint distribution of two distributions? In toy-1D experiments, the authors visualize the optimal plan but that is given by the ot.weak package.\nIn addition, the discriminator in a GAN can be viewed as a classifier. Are there any interpretations we can draw from the potential network f?\n\n[1] Perrot, Micha\u00ebl, et al. \"Mapping estimation for discrete optimal transport.\" Advances in Neural Information Processing Systems 29 (2016).\n\n[2] Zhu, Jiacheng, et al. \"Functional optimal transport: map estimation and domain adaptation for functional data.\" arXiv preprint arXiv:2102.03895 (2021). \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, I think this work is of high quality. Parameterizing the optimal transport estimators as neural networks following the Kantorovich duality is not entirely new but incorporating this weak-cost is quite novel. \nRecently, diffusion models have been achieving incredible performances, especially in image-2-image transformation. The authors may want to justify the advantages brought by an optimal map compared with these approaches.",
            "summary_of_the_review": "In this paper, the authors proposed a framework to estimate the optimal transport map parameterized as a neural network. The paper is well-written, and the contributions are clearly presented. The proposed weak OT cost extends the existing Kantorovich dual formulation, and yields a practical objective for training an OT map on large-scale datasets. The experimental result is quite encouraging. \nThus, I tend to recommend the acceptance of this work. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have no concerns. ",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_NG9Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_NG9Z"
        ]
    },
    {
        "id": "umkWRxxWGyj",
        "original": null,
        "number": 2,
        "cdate": 1666556295728,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666556295728,
        "tmdate": 1666556295728,
        "tddate": null,
        "forum": "d8CBRlWNkqH",
        "replyto": "d8CBRlWNkqH",
        "invitation": "ICLR.cc/2023/Conference/Paper1111/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work presents a novel neural-networks-based algorithm to compute optimal transport maps and plans for both strong and weak transport costs. The problem is converted to a minmax optimization one using noise outsourcing idea. The work proves that the proposed neural-networks are universal approximators of transport plans between probability distributions. The algorithm is evaluated on both toy examples and on unpaired image-to-image translation.\n\nThe contributions of the work are\n1. proposes a novel framework to compute optimal transport maps and plans for both strong and weak transport costs based on noise outsourcing method;\n2. give rigorous proofs for the existence of the solution and show the proposed model is a universal approximator\n3. thorough experimental results to demonstrate the effectiveness of the proposed model",
            "strength_and_weaknesses": "The work has the following strengths:\n\n1. The problem to tackle is to efficiently compute optimal transport maps or plans, which play fundamental roles in deep learning and are highly non-linear and notoriously hard to compute.\n2. By using the noise outsourcing idea, the problem is converted to a minmax optimization problem, which can be tackled efficiently\n3. The experimental results demonstrate the effectiveness of the proposed modal\n\nThe weakness is that the proposed algorithm searches for a solution of a saddle point problem and extract the stochastic OT map from it, but not all saddle points correspond to optimal stochastic OT maps, this type of ambiguity requires further theoretical exploration.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is very well written, the key concepts, mathematical formulations, are highly motivated and clearly represented; the deduction process is summarized as a sequence of lemmas, which are easy to follow and very inspiring; the explanation of the key idea of noise out sourcing is very elegant and exciting; the experimental results are thorough and convincing.\n\nThe method is relatively novel. Although there are so many works addressing on the efficient computation of OT maps/plans, the one using noise outsourcing is quite novel.\n\nThe quality of the work is good, the mathematical modeling and formulation, the usage of theoretical tools are rigorous, and numerical experiments are concrete. \n\nThe authors promise to make their code public available, hence the work should be reproducible.",
            "summary_of_the_review": "This work presents a novel neural-networks-based algorithm to compute optimal transport maps and plans for both strong and weak transport costs. The problem is converted to a minmax optimization one using noise outsourcing idea. The work proves that the proposed neural-networks are universal approximators of transport plans between probability distributions. The algorithm is evaluated on both toy examples and on unpaired image-to-image translation.\n\nIt is well known that optimal transport maps/plans play fundamental roles in deep learning, but their computations are intrinsically complicated. An efficient and accurate computational method is highly desirable. This work offers a novel method for tackling this fundamental problem by converting it as a min-max optimization problem using the noise outsourcing idea. The algorithm can compute both deterministic and stochastic mappings with strong and weak transport costs. The various applications show the flexibility and effectiveness of the method. Although there are some theoretic ambiguity for the saddle points, the proposed method is inspiring the convincing.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The work is a fundamental research, it focuses on theoretic exploration.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_D9LF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_D9LF"
        ]
    },
    {
        "id": "Z4ADTqS80pq",
        "original": null,
        "number": 3,
        "cdate": 1666638652841,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638652841,
        "tmdate": 1666638652841,
        "tddate": null,
        "forum": "d8CBRlWNkqH",
        "replyto": "d8CBRlWNkqH",
        "invitation": "ICLR.cc/2023/Conference/Paper1111/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a scalable way to learn OT maps via a deep neural network. It is especially relevant due to the recent approaches demonstrating the use of OT maps for generative purposes, as opposed to the previous methods where OT was used as a loss when training generators.\n",
            "strength_and_weaknesses": "The paper is very well-written and pedagogical. It also mixes a good deal of theoretical and algorithmic approaches along with thorough empirical evaluations. Maybe the only weakness is that it is mostly motivated by the situation where no deterministic map approaches, and while it is clear that it might be theoretically the case, it is less clear when that situation occurs in practice. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is of high clarity, quality and reproducibility.\n\n",
            "summary_of_the_review": "This is a very good paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_KZKB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1111/Reviewer_KZKB"
        ]
    }
]