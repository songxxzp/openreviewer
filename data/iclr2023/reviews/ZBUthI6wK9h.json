[
    {
        "id": "C4I9i7veJDK",
        "original": null,
        "number": 1,
        "cdate": 1666481414710,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666481414710,
        "tmdate": 1671033536657,
        "tddate": null,
        "forum": "ZBUthI6wK9h",
        "replyto": "ZBUthI6wK9h",
        "invitation": "ICLR.cc/2023/Conference/Paper4552/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors apply GFlowNets to the problem of scheduling operations in a computational graph on homogeneous parallel hardware. The evaluate conditional GFlowNets for the first time with the computational graph being the conditioning input and the schedule being the output. They also innovate by conditioning on the reward temperature in order to find a good trade-off between diversity of the generated samples and their average reward. Diversity is important in this application because the generative policy is trained using an imperfect but cheap to compute proxy and only a few of the generated schedules are then evaluated on the ground truth hardware. GFlowNets are interesting in this context because their training objective makes them sample with probability proportional to the reward (rather than maximizing the reward as in other RL approaches). Experiments show improvements against previous methods, including standard RL methods.",
            "strength_and_weaknesses": "GFlowNets are a new RL variant (less than a year old) with only a few applications yet, so this paper introduces a new type of application, in the realm of scheduling, and an approach which may be applicable more broadly. The successfully show empirical success on two GFlowNet novelties: conditioning on a rich input (the computational graph) and on temperature (to control the diversity-reward trade-off).\n\nIn page 5, they claim that previous works on GFlowNets did not consider the conditional case, but this is not true and they themselves mention in section 4 that Bengio et al 2021b introduced the theoretical framework for conditional GFlowNets. What is true is that may be the first (or among the first, with concurrent work) to validate experimentally a conditional GFlowNet and show its usefulness.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, of good quality. Novelty is mostly in the form of experiments and a new application domain for a fairly new method (introduced at NeurIPS 2021). \n",
            "summary_of_the_review": "This paper introduced a new form of application for GFlowNets, mapping a computational graph to a distribution over efficient schedules for it. To achieve this, the demonstrate the feasibility and success of the conditional GFlowNet formalism and also show how to use it to control the trade-off between diversity and average reward by conditioning on the reward temperature (exponent of the reward).\nI consider the paper should be published if they fix their claim about conditional GFlowNets (that it was not considered before, see above).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_9S3Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_9S3Z"
        ]
    },
    {
        "id": "mbBp6eaiwly",
        "original": null,
        "number": 2,
        "cdate": 1666647289360,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647289360,
        "tmdate": 1666647289360,
        "tddate": null,
        "forum": "ZBUthI6wK9h",
        "replyto": "ZBUthI6wK9h",
        "invitation": "ICLR.cc/2023/Conference/Paper4552/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper examines the computation scheduling problem, recently tackled by RL methods, and attempts to tackle it with the GFlowNet framework. The application is fairly straightforward, but the authors introduce additional interesting aspects that improve performance.\n\nThis paper has several contributions:\n- applying GFlowNets to the scheduling problem\n- training temperature-conditional GFNs (with temperatures sampled log-uniformly)\n- training Trajectory Balance-style GFNs without having to estimate $Z(G_C)$ using a variance loss trick\n- training on subgraphs as a data augmentation",
            "strength_and_weaknesses": "**Strengths**:\n- clear writing, clear exposition, clear methods\n- brings novel insights into GFlowNet research\n- good use of the diversity-as-a-strength feature of GFlowNets to improve scheduling\n\n**Weaknesses**:\n- there are some details lacking, for example, I'm not sure what the architecture is to condition on a particular computation graph, or how temperature is fed to the MLP producing $e_\\sigma$.\n- there are some convincing results for the temperature-conditional GFN method proposed, but not for the log-partition variance loss. The authors claim that learning $Z_\\theta(G_C)$ is divergent, but no evidence is provided to help understand the reader why this is the case, nor if the learned flows converge to the correct quantities.\n- similarly, the effect of training on subgraphs vs full graphs is not very deeply discussed nor empirically justified.\n\n> To the best of our knowledge, this is the first time that generalization of GFlowNets is tested empirically.\n\nIf I understand prior work correctly, generalization to unseen _data_ has been tested (see e.g. [1]). Perhaps here the authors are instead referring to generalization to unseen conditionals (in the present case, unseen computation graphs to be scheduled)?\n\n> In practice, we use the training distribution to estimate $\\mathbb{E}_s [\\zeta(s)]$ with a mini-batch of trajectories\n\nHow does this interface with (temperature and graph) conditioning? $Z$ is effectively a function of $G_C$ and $\\sigma$. If I understand correctly this means that for a given $G_C$ (and $\\sigma$) many samples are taken. Does this require a \"combinatorial\" number of samples? i.e. for a \"minibatch\" of size $n$ do we need $n=n_b n_G n_\\sigma$ samples?\n\n[1] Evaluating Generalization in GFlowNets for Molecule Design, Andrei Cristian Nica, Moksh Jain, Emmanuel Bengio, Cheng-Hao Liu, Maksym Korablyov, Michael M. Bronstein, Yoshua Bengio, MLDD 2022",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is fairly clear, although there are many details lacking. I am not sure I could exactly reproduce the results of this paper as-is, although probably a fair approximation of it. The paper feels fairly minimal on the empirical side, it has some minimal experiments which are interesting, but it wouldn't hurt for it to be more thorough.\n\nIn terms of novelty, the proposed changes are reasonable ways to improve GFlowNets, but as far as I can tell are not groundbreaking ideas.",
            "summary_of_the_review": "While I am unfortunately unable to judge the impact of this work on scheduling problems, the proposed improvements to the GFlowNet framework seem interesting. I think the paper could do much more in terms of details, empirical validation of the proposed ideas, and potentially tackle larger scale benchmarks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_uJuK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_uJuK"
        ]
    },
    {
        "id": "f36Q-YwBB6s",
        "original": null,
        "number": 3,
        "cdate": 1666659302905,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659302905,
        "tmdate": 1666659302905,
        "tddate": null,
        "forum": "ZBUthI6wK9h",
        "replyto": "ZBUthI6wK9h",
        "invitation": "ICLR.cc/2023/Conference/Paper4552/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Scheduling operations in a computation graph on parallel hardware is NP-hard. This makes ML approaches such as RL attractive. However, the high cost of evaluation necessitates the use of proxy reward models, which can be overfitted to with reward maximization, resulting in poor performance on actual hardware. This is analogous to drug discovery where a proxy model is used in place of wet-lab experiments.\n\nThe solution is to seek not just the best mode in the reward distribution but all modes proportional to their goodness. This can be done by training an amortized sampler which samples proportional to the Boltzmann distribution defined by the EBM (the proxy model). The GFlowNet framework is used to train such a sampler with temperature conditioning. Empirical results show that GFlowNets achieve a higher degree of diversity, which correlates with better on-hardware performance.\n",
            "strength_and_weaknesses": "This paper applies the right tool, GFlowNets, to an important problem, operation scheduling, and obtains good results. Note that it might be worth mentioning that the proposed state space is a DAG, which necessitates the GFlowNet machinery; otherwise, max-entropy RL suffices.\n\nAlong the way, it also empirically evaluates the idea of conditional GFlowNets and utilizes a log-partition variance loss, which are not done in prior work.\n\nThe presented empirical evidence is comprehensive and includes speedup on target hardware and real-world computation graphs.\n\nApproximating E_s[\\zeta(s)] with the mini-batch average of \\zeta(s) reminds me of variance reduction via baseline subtraction where the baseline is estimated with the batch reward. I encourage the authors to explore how the proposed loss is related to established variance reduction methods in RL and beyond.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written with few typos or ambiguities.\n\nOne of the claimed contributions is the introduction of an alternative to pure reward maximization which is more robust to proxy errors. This might be true for the problem of operation scheduling. It is, however, an established method for other domains, such as drug discovery, where a cheap proxy is used in place of the true reward. In fact, one of the references, Bengio et al., 2021a, uses the exact same rationale in the context of molecule generation. It seems appropriate to point out how this key underlying idea is applied elsewhere.",
            "summary_of_the_review": "Well-motivated paper with adequate theoretical and empirical contributions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_umWR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_umWR"
        ]
    },
    {
        "id": "daaVW3u73MF",
        "original": null,
        "number": 4,
        "cdate": 1667137820139,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667137820139,
        "tmdate": 1667137820139,
        "tddate": null,
        "forum": "ZBUthI6wK9h",
        "replyto": "ZBUthI6wK9h",
        "invitation": "ICLR.cc/2023/Conference/Paper4552/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper works on scheduling of a computational graph which is an NP-hard problem.\nThe paper considers a problem of scheduling a computational graph on a fixed no. of homogeneous devices.\nThe paper claims that the previous approaches take large number of evaluations for convergence and suggests proxies as a faster alternative.\nInstead of trying to minimize the makespan measure w.r.t the proxy, this paper creates a set of candidates and learns a generative model to assign higher probability to the low-makespan schedules.\nOverall, the paper is a case study of GFlowNets on scheduling computational graphs.\nMain difference over GFlowNet baseline is (1) using a variance loss on the log-partition function, (2) learning a single model for multiple different reward functions by conditioning the policy network on a temperature.\n\n ",
            "strength_and_weaknesses": "+ High impact problem, considering that scheduling is a very generic problem in computer systems.\n+ Very solid contribution on how to use GFlowNets in scheduling\n+ Solid experiments with good baselines (BRKGA, List Scheduling, GFlowNet)\n\n- Seems to be only simulation (would be great if we can see some real system experiments)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is very well written, clearly explains the problem and its key ideas.\nIts experimentations are also very well explained.",
            "summary_of_the_review": "The paper works on scheduling of a computational graph which is an NP-hard problem.\nThe paper considers a problem of scheduling a computational graph on a fixed no. of homogeneous devices.\nThe paper combines GFlowNet with Topoformer with appropriate changes to the formulation.\n\nWhile it may look incremental from a cursory look, the paper makes a very solid contribution.\nIn fact, its experiments also support its significant benefits.\n\nHowever, it seems that the results are limited to simulation.\nIt would be great if we can see more real system experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_b75p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4552/Reviewer_b75p"
        ]
    }
]