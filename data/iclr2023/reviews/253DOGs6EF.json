[
    {
        "id": "DB2ACN2Q0gr",
        "original": null,
        "number": 1,
        "cdate": 1666671695053,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671695053,
        "tmdate": 1666671695053,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This manuscript proposes an interesting idea based on the observation that PINNs are normally trained using uniform sampling, which might not be the optimal case. Using the proposed method, the region of interest will be naturally sampled with a higher density. This manuscript applied their method to a set of common PDE problems, including Fokker-Planck equations.",
            "strength_and_weaknesses": "Strength:\n- This manuscript is well-written.\n- The proposed method is easy to follow: it is true that the sampling matters in training PINNs.\n- The attached code showed good reproducibility.\n- The experiments validating this method are extensive.\n\nWeaknesses:\n- There are multiple algorithmic choices not justified in the manuscripts. For example, why use the square as the non-negative translator instead of the absolute? More ablation studies are expected to examine them.",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is nicely written. The code is attached. I can reproduce some of the results.",
            "summary_of_the_review": "This manuscript builds its idea based on an interesting observation. However, there are ablation studies that need to justify their choices and provide more advice to practitioners.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_ukjY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_ukjY"
        ]
    },
    {
        "id": "4gIxjYjfex",
        "original": null,
        "number": 2,
        "cdate": 1667197919950,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667197919950,
        "tmdate": 1667197919950,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes the use of the expected molecular distribution function as the loss function to train a Physics Informed Neural Network. Then, the authors use MCMC to sample the molecular distribution function to compute the expectation using the output of the neural network for the molecular distribution function. The authors show three applications: mass conservation for simulated particles, heat equation and fokker planck equation (stochastic differential equation). ",
            "strength_and_weaknesses": "The strength of the paper is the realization that existing PINNs with uniform sampling of the solution space is not sufficient for several applications and clearly discussed with the advection equation. The use of the expected molecular distribution function is also interesting. \n\nThe weaknesses of the paper are as follows:\n1. Why is the expected value of molecular distribution used? In the third application, the KL divergence is used for performance evaluation. Why not use that for the training itself. Are there any mathematical arguments/proofs on why training for expected distribution is good. For the hyperparamenter tuning, the quartile values are used. The choice seems arbitrary and not well explained or justified. \n\n2. The advection equation issue is well explained. So the reviewer (and any reader) will expect that the advection problem will be shown in the applications, at least in the appendix. The chosen application in section 5.1 seems to be a different version (not a soliton that struggles with PINNs). \n\n3. MCMC (or any variant including HMC) itself is too expensive to sample from. The authors also allude to the memory requirements in their high-end GPUs. Is MCMC the right approach for this problem? Is it not making the problem worse? Now if not expectation and some other information metric is used, the cost will go up more!\n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation of the problem and approach are well explained. However, the use of a different loss function for PINN that is sampled from MCMC is not a novel solution to the main issue identified. The experiments also do not support the resolution of the problem mentioned. The choice of the statistics for the loss function is arbitrary and should have been better justified. The hyperparameter choices especially the comments on choosing c in equation 14 are not well justified and reproducible.\n\nThe paragraphs of the Main contributions 2 is not sufficiently justified. How do the authors avoid the conceptual challenges of classical mesh-free methods? A discussion is missing and experiments do not show this point. The third point is not a contribution and not supported by experiments as well. \n\n",
            "summary_of_the_review": "Overall, the paper lacks a good justification for the loss function choice and improvements to the learning representation this choice brings to the table. The experiments do not justify the use of the new loss function and the advantages are not sufficiently highlighted. Overall the idea of the paper is not a significant improvement in the field.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_J4Gd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_J4Gd"
        ]
    },
    {
        "id": "pSdY8wLxdJ",
        "original": null,
        "number": 3,
        "cdate": 1667253831599,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667253831599,
        "tmdate": 1667253831599,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a network based method, in the realm of physics informed methods, to solve a class of PDEs. The proposed methods mainly extend the general framework of having PDE as constraints in the loss function by introducing a partial density and locality of particle interactions. It also proposes to use MCMC method to sample the collocation points.",
            "strength_and_weaknesses": "The strengths of this paper are:\n\n$\\mathbf{1}.$ The idea of using particle density and emphasizing locality of interactions in loss function is novel. It provides a rigorous view of defining a specific loss function for general PDE constrained loss function (of neural networks). The proposed method also incorporate a MCMC sampling strategy, which supports the idea very well. \n\n$\\mathbf{2}.$ The paper is very well organized and clearly written. The literature review is comprehensive along with arguments and to introduce the motivation of the proposed method. Overall, the paper is easy to read for audience in a broad area of deep learning. \n\nThe weakness of this paper:\n\n$\\mathbf{1}.$ There lacks novel proposal of network architecture, which might limit the novelty of this paper. Here, it is worthwhile noting that the novel definition of loss function does qualify as a good contribution. However, the architecture of neural network is not novel.\n\n$\\mathbf{2}.$ Author discussed the applicability of the propose methods. However, the limitation of applicability seems to be obvious as the authors stated. But, it is rather an unfamiliar area for me. ",
            "clarity,_quality,_novelty_and_reproducibility": "$\\cdot$ Regarding the clearness, this paper is very clearly written with a lot of details in each aspect. \n\n$\\cdot$ The novelty, as stated above, is mostly on the proposal of defining a specific loss function framework than a novel proposal of neural network architecture, later of which could limit the novelty for a paper targeting at the top venue.\n\n$\\cdot$ The reproducibility is feasible, and the authors also attached code in the supplementary materials. \n",
            "summary_of_the_review": "This paper proposes a novel loss function with underlying ideas of local partical density/interactions and mesh-free sampling strategy. It is a good paper with clearly written and organized context. The limitation of this paper could be due to its limited novelty and its general applicability.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There is no ethics concern in this paper.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_ZR9E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_ZR9E"
        ]
    },
    {
        "id": "L27w9ujcqh",
        "original": null,
        "number": 4,
        "cdate": 1667471397341,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667471397341,
        "tmdate": 1667471397341,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors claim to propose to sample directly from the distribution over the particle positions, eliminating  boundaries while adaptively\nfocusing on the most relevant regions. It looks higher sample efficiency and improved performance of PINNs.",
            "strength_and_weaknesses": "Weaknesses: It looks that I do not understand what the authors' motivation and what they do to solve. Does mesh-free fluid dynamics really work?  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper does not present clearly. I have not found any novelty. ",
            "summary_of_the_review": "The author need to compare their work to compare the classical work about numerical solution of PDE. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_cZb3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_cZb3"
        ]
    },
    {
        "id": "2InlfAwEIB6",
        "original": null,
        "number": 5,
        "cdate": 1667488681163,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667488681163,
        "tmdate": 1667488681163,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors consider a modification of the PINN construction for solving certain classes of partial differential equations. Namely, they focus on PDEs formulated as a macroscopic description of an underlying microscopic physical process, such as diffusion and advection. They claim that the soft constraint on the PINN loss which informs the network of the original PDE is usually taken as uniformly discretized, which is a poor approximation when the true underlying solution distribution of collocation points is not uniformly spread. They suggest replacing the uniform sampling with a Monte Carlo sampling method, in which the distribution itself is updated during training. They claim that this method resolves the issues of unbalanced density solutions and the need to define a bounding region for the PDE loss.\nThe authors show improved performance over several other collocation point sampling methods, such as uniform, Residual adaptive refinement and some variants, as well as importance sampling.\n\n",
            "strength_and_weaknesses": "Strengths:\n\n1) The paper is well written, clearly explains the objective and modifications made to existing methods.\n2) The presented method is straightforward to implement, and seems to outperform other methods in similar setups.\n\n\nWeaknesses/Questions:\n\n1) The suggested method seems to apply only to micro to macro phenomena, however PDEs are ubiquitous in other scenarios, making this solution very restrictive (albeit interesting).\n2) \"We argue that due to the locality of particle interactions, the regions with higher density are more relevant for regularizing the network.\" This statement is made as motivation for the class of PDEs under study, but it is not proven.\n3) How dependent is the adaptation process on the initial choice of distribution?\n4) While the authors compare their results against other PINN based solvers, it is unclear how the performance stands against other non-PINN methods.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. It seems that some related work may be missing, for instance - https://www.researchgate.net/publication/359932814_Monte_Carlo_PINNs_deep_learning_approach_for_forward_and_inverse_problems_involving_high_dimensional_fractional_partial_differential_equations\nseems to have the same line of inquiry, while they focus on fractional PDEs. It is possible that other works exist employing MCMC in similar ways. ",
            "summary_of_the_review": "A well written paper with clear exposition and empirical results, albeit in a limited class of problems.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_jfSc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_jfSc"
        ]
    },
    {
        "id": "Q3hKCKDqYd3",
        "original": null,
        "number": 6,
        "cdate": 1667538240162,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667538240162,
        "tmdate": 1667538240162,
        "tddate": null,
        "forum": "253DOGs6EF",
        "replyto": "253DOGs6EF",
        "invitation": "ICLR.cc/2023/Conference/Paper4514/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose an extension to the physics-informed neural network approach, which utilizes a particle-based approach to more efficiently sample in the data space, and capture boundary conditions more accurately with less required samples as compared to traditional collocation points. The core contributions of the paper is the injection of microscopic fluid dynamics views rooted in smoothed particle hydrodynamics, into the mesh-free PINN approach to achieve more optimal adaptive sampling.",
            "strength_and_weaknesses": "Strengths:\n- Strong embedding of the proposed approach into the current state of the literature with illustrative parallels being drawn to previous PINN approaches.\n- Well-motivated approach with a clear physical intuition behind it.\n\nWeaknesses:\n- As the approach is particle-based I would have expected an ablation analysis/comparison to particle-based inference approaches such as Sequential Monte-Carlo. The authors only consider inverse transform sampling, Metropolis Hastings, and Hamiltonian Monte-Carlo.\n- Limited set of experimental evaluations with fairly simple physical systems being considered. Would the proposed approach also work on the more difficult Korteweg-de-Vries equations? Would it work with Burgers equations, and how would it compare to the residual adaptive refinement approach of Lu et al. there? Would it scale to even more complex settings, such as the ones explored in XPINNs?",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the exposition is exemplary, with a very strong relation back to prior work in the field, and placing the proposed extension in the right, nuanced context. With previous approaches to the refinement problem in PINNs already utilizing adaptive refinement, and the previous state-of-the-art residual adaptive refinement utilizing Monte Carlo integration at its core, one is lead to question just how close to the proposed approach a particle-based sampler within residual adaptive refinement would be.\n\nIn some of the arguments there is some imprecision such as the argument that only a number of systems can be viewed as particle-based systems. In theory every physical systems can be viewed as an artificial particle-based system, but that viewpoint may not always be conducive to the search for a solution, or be able to compute desired quantities of interest.\n\nThere furthermore exist too expansive claims, which are not supported by the provided experimental evaluation. To cite \"As we have demonstrated applicability to a wide spectrum of PDEs..\", I believe this claim is not supported as while the experiments are chosen from different fields, they still a fraction of the potential PDE-dynamics, and as already pointed out above there exist a number of PDEs in PINN-literature which are significantly more difficult.",
            "summary_of_the_review": "The authors propose an extension to the PINN training approach rooted in particle-based adaptive refinement, utilizing Monte-Carlo sampling to capture the different regions, and boundaries of the problem more accurately. While well-motivated, and well-derived the approach is only a slight extension beyond the previous residual adaptive refinement approach of Lu et al., which furthermore also already utilized a Monte-Carlo integration step. The experiments, while illustrative, could take more difficult PDE-systems into consideration to showcase the true capability and limitations of the proposed approach.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_N5cW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4514/Reviewer_N5cW"
        ]
    }
]