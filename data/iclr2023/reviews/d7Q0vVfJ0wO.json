[
    {
        "id": "klM1GDYkxNB",
        "original": null,
        "number": 1,
        "cdate": 1666356326214,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666356326214,
        "tmdate": 1666356326214,
        "tddate": null,
        "forum": "d7Q0vVfJ0wO",
        "replyto": "d7Q0vVfJ0wO",
        "invitation": "ICLR.cc/2023/Conference/Paper5643/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies \"implicit regularization\", a phenomena in gradient-based optimization algorithms in which the local minima of unregularized cost functions contain properties that one would expect only by adding a regularization term, e.g., sparsity being the most popular one. More precisely, they proposed a reparametrization in which the solution shows \"group sparsity\" structure, which is often obtained by having a elastic net regularization.",
            "strength_and_weaknesses": "Strength\n======\n\n- Excellent contextualization of the problem being investigated.\n- Thorough analysis of the proposed reparametrization and the reasons behind its implicit regularization structure.\n- Great numerical analysis showcasing the theorectical development.\n- The analysis in Theorem 1 showing that the gradient dynamics in DGLNN cannot be emulated by mirror descent is interesting and appreciated.\n\nWeaknesses\n=========\n\n- No major weaknesses.\n\nMinor Comments\n=============\n\n- If I were the authors I would be more specific in the title of the paper.  Maybe find a way to introduce \"Neural Networks\" in the title as it is the model being studied here?",
            "clarity,_quality,_novelty_and_reproducibility": "Well-written and well-motivated paper.  Novelty is significant as the authors discover a particular neural net reparametrization that leads to group sparsity implicit regularization.  Results are reproducible as the code has been shared in the supplementary material.  I would kindly request the authors to make the code available in a public platform such as GitHub in case the paper gets accepted.",
            "summary_of_the_review": "Well-organized paper with potentially impactful results.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_4y3z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_4y3z"
        ]
    },
    {
        "id": "jt_5t3xiVJ",
        "original": null,
        "number": 2,
        "cdate": 1666816815155,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666816815155,
        "tmdate": 1670863145075,
        "tddate": null,
        "forum": "d7Q0vVfJ0wO",
        "replyto": "d7Q0vVfJ0wO",
        "invitation": "ICLR.cc/2023/Conference/Paper5643/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies the implicit bias of gradient descent on diagonal linear networks.\nIt has been lately shown that parametrizing $x$ as $u \\odot v$ in $y \\approx A (u \\odot v)$ induces sparsity in the gradient flow iterates on the least squares loss.\nIn the paper a special architecture is proposed so that gradient descent imposes **group sparsity** on the weights x$.\nThe architecture is a so-called *diagonally-grouped linear neural network* (DGLNN)\nAn analysis is provided under the restrictive assumption of orthogonal design (Theorem 2).\nFor $L$ groups, the proposed parametrization uses two set of variables: scalar ones $u_l$ encoding the magnitude, and vector ones $v_l$ encoding the direction.\n\nGradient flow of the overparametrized objective (Eq 3) is analyzed.\nSection 4 is devoted to a practical version of the gradient flow, gradient descent with weight normalization.\nGuaranties similar to the sparse recovery literature are derived under subGaussianity of the noise (Corollary 1)",
            "strength_and_weaknesses": "Strengths:\n- this is a very active area of research, the contribution is relevant\n- even though the assumptions are strong, there are not so different from classical ones in sparse recovery literature and are a first step to a better understanding of the phenomenon at stake\n\nWeaknesses:\n- the assumption is very strong and unlikely to hold in practice. Testing the behavior of the proposed algorithm on real data to assess the sensitivity to this assumption would be of great interest.\n- comparison with explicit regularization methods is also expected. Implicit bias of mirror descent [2] for group elastic net could also be studied (if the elastic net regularization parameter is sufficiently low, the solution is the same as for group Lasso [2]), as well as iterative regularization methods based on primal dual procedures that can handle non strongly convex bias [4].",
            "clarity,_quality,_novelty_and_reproducibility": "## Experiments:\n- The authors use Rademacher random variables for X. It seems to me that using Gaussian entries is more standard. Random Gaussian matrices are also supposed to satisfy the Assumptions of the paper. For the rebuttal I'd like to see the same experiment with a random Gaussian matrix.\n- \"The entries on the support are all 1\". Can the author provide the Signal to Noise Ratio, $||Xw^\\star||/||\\xi||$? That will be much more informative than saying $\\sigma=0.5$.\n\n## References:\n- The following preprint would be relevant (it appeared on 31 August 2022, so it is of course not a flaw that it was not included in the paper): [1]\n\n## Clarification.\n- The authors state: \"This reparameterization is equivalent to a diagonal linear network, as shown in Figure 1a.\" > For me Figure 1a use the parametrization $w = u \\odot v$, that induces the same bias, but is not equal to the w= $u^N - v^N$ one. Where is $N$ in Figure 1a ? Where is the substraction?\n\n## Maths:\n- In section 3.2, $u^\\star_{min}$ is potentially 0. Then in theorem 3, you need both $\\delta$'s to be equal to 0?\n\n\n[1] *Incremental Learning in Diagonal Linear Networks*, R. Berthier, https://arxiv.org/abs/2208.14673\n[2] *Exact Regularization of Polyhedral Norms*, SIAMOPT 2010, F. Schopfer\n[3] *Characterizing implicit bias in terms of optimization geometry*, ICML 2018, Gunasekar, Lee, Soudry, Srebro.\n[4] *Iterative regularization for convex regularizers*, AISTATS 2021, C Molinari, M Massias, L Rosasco, S Villa",
            "summary_of_the_review": "Interesting idea and result, but valdiation fails to compare to the wealth of existing methods for sparse recovery, including implicit ones.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_aL9r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_aL9r"
        ]
    },
    {
        "id": "EzDobuLV6-d",
        "original": null,
        "number": 3,
        "cdate": 1667035139355,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667035139355,
        "tmdate": 1667035139355,
        "tddate": null,
        "forum": "d7Q0vVfJ0wO",
        "replyto": "d7Q0vVfJ0wO",
        "invitation": "ICLR.cc/2023/Conference/Paper5643/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors study the theoretical properties of diagonally grouped linear neural networks, and they show that gradient descent over the squared regression loss, without any explicit regularization, biases towards solutions with a group sparsity structure. They conduct some experiments to verify their conclusion.  My main concern is the implications of these results on the modern neural networks are unclear. The reason is that the relationship between the diagonally grouped linear neural networks and the widely used deep neural networks in practice are unclear. Thus, the contribution of this paper is limited.",
            "strength_and_weaknesses": "Strength:\n\n1. This paper is well written and easy to read. \n\n2. Some theoretical results in this paper are interesting. \n\n\nWeaknesses:\n\n1. As we know deep learning theory studies aim at understanding the modern neural networks in practice. The authors need to discuss the relationship between their results, such as the group sparsity structure,  and the observations of deep neural networks in practice.\n\n2. In this paper, the authors focus on the diagonally grouped linear neural network, compared with the existing work, the authors need to explain more on the relationships between their structure and the ones in the modern neural networks. The grouped CNNs the authors mentioned are not the widely used neural network in practice. The authors are also recommended to specify the relationship between the structure of their model and grouped CNNs, such as where one can be reduced to another by using some specific settings.\nThe above limitation makes the contribution of this paper limited. \n\n3. Can the authors show some experimental results to demonstrate that their findings also exist in the neural networks in real applications.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Please see my comments above. ",
            "summary_of_the_review": " My main concern is the implications of these results on the modern neural networks are unclear, which weakens the contributions of this paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_oXvD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5643/Reviewer_oXvD"
        ]
    }
]