[
    {
        "id": "f_X0OhkwCQ",
        "original": null,
        "number": 1,
        "cdate": 1666552400762,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552400762,
        "tmdate": 1668744069540,
        "tddate": null,
        "forum": "gU5sJ6ZggcX",
        "replyto": "gU5sJ6ZggcX",
        "invitation": "ICLR.cc/2023/Conference/Paper5707/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "I thank the authors for their responses. I am especially happy about the added section 3.2. that tries to provide some theoretical reasons for the observed phenomenon of variance collapse. I am raising my score to 6.\n\nThe authors in this paper observe that interpolating between neural network weights decreases the variance of activations. By counteracting this phenomenon they show that much of the performance drop in interpolated models can be recovered. They show this across multiple architectures, normalisations and datasets.",
            "strength_and_weaknesses": "Strengths: The paper is very clear and well written. It is easy to follow and presents a concise observation leading to a simple modification to recover the performance in interpolated models. The experiments are straightforward and clear. They also do a good job in relating to existing research on this subject.\n\nWeaknesses: It would be great if some more theoretical analysis were provided in an attempt to understand why variances collapse, how their modifications change the standard interpolation. While it is great to make a simple observation, propose a fix and demonstrate that it increases performance; one is left wondering, after reading the paper, what exactly we have learned from this scientific study.",
            "clarity,_quality,_novelty_and_reproducibility": "Random Notes:\n\nIt would be great if the paper were readable without prior knowledge of Entezari\u2019s 2021 paper.\n\n3 paragraph, introduction: please define \u2018loss barrier\u2019 when you first use the term\n\n2.2. Please give a more detailed explanation of \u2018unit-rescaling\u2019, \u2018positive homogeneity of ReLU\u2019 and why SGD helps here.\n\nFig 2: I don\u2019t find some of the filters from the middle again on the right, are these the right plots? Also, there seem to be some obvious mismatches, which one could change by hand. I know the best matching may not be interpretable, just wondering if there is a bug here?\n\nAlso, Fig2, I am wondering if for a CNN having a filter which is slightly shifted (e.g. phase shifted wavelet) may give a low correlation in filter shapes, but almost the same pattern of activations in the convolutional feature map? I.e., maybe there is some translation-invariant way of matching convolutional filters?\n\nWhich algorithm are you using for linear assignment? Please provide more technical details.\n\nJust above eq. 2 there is a superfluous \u2018the\u2019\n\nEnd of 2.3. How are the weights interpolated and permuted exactly? Please give more detail.\n\nI am little confused about the ordering of tested models and datasets in different sections. Like, for instance, starting section 3, the standard choice would have seemed like LeNet on MNIST and ResNet on CIFAR10. Also, why are models split into different sections at all, like section 5.3??\n\nSection 4, second paragraph: WHY? Can you give any motivation for this? I guess this relates to my general sense when reading the paper: It would be great to learn something about neural networks, rather than just observing that some statistic changed, fixing it with a hack and claiming victory because performance increased.\n\nHere is a proposal for a little more understanding of what is happening: Take a 2D slice of the loss landscape (like in other model averaging papers, e.g., the ones about model soups) and visualise the different interpolation schemes: 1) regular interpolation should be a straight line; 2) adding the constraint that the mean and variance remain the same for the units should a slight deviation \u2013\u00a0possibly through regions with lower loss? This is just a first proposal for an experiment to dig deeper, build more intuition and try to actually understand what is going on.\n\nFig 6: too small, and the different losses seem redundant, maybe just pick one an put others in appendix?\n\nFig 6: what is this? Only permuted or also variance adjusted? Add clarification.\n\nEnd of 5.2: OK, I appreciate that you add Ainsworth et al. as concurrent work. However, now you are comparing against them. If you do this, then please do it properly. Include it in your plots. Show if the variance trick also improves upon the better permutation scheme from their paper etc\u2026\n\nFig 8: What is this? Top1/5 accuracy? Why are those two papers cited, is it their interpolation method?\n\n5.4.: \u2018have\u2019 +a \u2018maximum barrier\u2019\n\nWhat exactly is the statement you are trying to make with Fig. 9? Surely not a causal relationship? Also, I am not sure how much of an explanation that offers at the end of section 5.",
            "summary_of_the_review": "The paper is clear, simple and proposes an effective modification to interpolation variance collapse. There is some concurrent work, to which it would be great to provide a more detailed comparison. Moreover, it would be great if the paper would go beyond noticing that some statistics changed, modifying this and obtaining better performance. Ideally, after reading this paper, we would have a slight advance (even preliminary, anecdotal) about why variance collapses in interpolated models, how the modification changes the interpolation path and why this works.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_SpdK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_SpdK"
        ]
    },
    {
        "id": "aRmEnktTcw",
        "original": null,
        "number": 2,
        "cdate": 1666649941704,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649941704,
        "tmdate": 1669667911948,
        "tddate": null,
        "forum": "gU5sJ6ZggcX",
        "replyto": "gU5sJ6ZggcX",
        "invitation": "ICLR.cc/2023/Conference/Paper5707/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the linear mode connectivity problem empirically and uncovers a new phenomenon called variance collapse (where activation variances of interpolated networks between two parent networks reduces significantly). Test accuracy barrier reduction is shown successfully for the interpolated networks (for CIFAR-10, barrier goes down to about 1.5% gap in test accuracy between parent models and the interpolated network).",
            "strength_and_weaknesses": "The paper has following strengths:\n\n1. It is interesting to see the variance collapse phenomenon on the interpolated networks.\n\n2. Barrier reduction for CIFAR-10 down to 1.5% is significantly better than existing techniques.\n\n3. The paper is well-written and nicely explained. Related work is cited and discussed very well.\n\n\nThe paper has following weaknesses:\n\n1. The correction method presented by the authors is trivial. It is well-known that tuning batchnorm can significantly improve accuracy (sometimes even in completely unsupervised, domain adaptation settings, e.g., see: TENT: https://openreview.net/forum?id=uXl3bZLkr3c). Hence, it is no surprise that fixing batch norm statistics would help in this case. While the proposed method achieves great results on CIFAR-10, we can see that on ImageNet (despite the proposed method being the current best), the gap in interpolation accuracy is very significant (making this method not too useful on large-scale datasets). I was wondering if instead of just initializing affine parameters and re-computing the running mean/variance statistics, the authors were to finetune (or learn) the BN stats similar to TENT above, would we see significant reduction in the ImageNet barrier (compared to their current results)? Having better numbers for large scale datasets like ImageNet would indeed make this work useful.\n\n2. In the final sentence, the authors state \u201ca better understanding of linear interpolation would result in improvements in applications like weight-space ensembling, checkpoint averaging, robust finetuning, etc.\u201d. I think the current paper lacks the use of proposed ideas (e.g., fixing variance collapse, etc.) within a real application framework. It would make the paper significantly stronger if the authors could pick a couple of the above applications and show that fixing this subtle issue significantly improves the current solutions in those domains.\n\n3. There are many figures in the paper that do not contribute much to other results. Example, training loss barrier, test loss barrier, etc. (Fig. 6ab, Fig. 7a), do not provide any new intuitive information over the test accuracy barrier results. I suggest to remove the redundant information and include more results on downstream applications and other experiments suggested above (e.g., TENT on linear interpolations, etc.).\n\n4. Finally, I am a bit unclear on what happens when the model already has BNs (e.g., ResNets). Do you add a new BN layer in your correction method (even if a BN layer is already present)? Page 6, \u201cWe present the following practical\u2026\u201d paragraph seems to suggest that you add a new BN layer. If you do add an extra BN layer: When you do interpolation, wouldn\u2019t you already set the affine parameters (of existing BN) to the respective interpolated means and interpolated variances from parent networks (similar to all other weights in the network)? In that case, I am not sure how the new BN layer adds anything new (other than recomputing the running mean and running variance statistics with training data, which is similar to other methods like TENT that also tune the BN layer (but they also do some more learning on the BN layers)). Also, when you do the permute invariance methods, do you consider the BN layers (for somehow permuting the affine parameters, running mean, running variances)?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is clear, lacks a bit of novelty since BN tuning methods already exist.",
            "summary_of_the_review": "The paper can be significantly stronger if it actually shows improved results on downstream applications and manages to reduce the ImageNet barrier further with more advanced BN tuning methods.\n\n==== UPDATE AFTER REBUTTAL ====\n\nI have read the author response and other reviews. I am raising my score to 6 since the authors have reasonably addressed my main concerns. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_zoWW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_zoWW"
        ]
    },
    {
        "id": "JU-08Vot7z",
        "original": null,
        "number": 3,
        "cdate": 1667055725627,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667055725627,
        "tmdate": 1667055725627,
        "tddate": null,
        "forum": "gU5sJ6ZggcX",
        "replyto": "gU5sJ6ZggcX",
        "invitation": "ICLR.cc/2023/Conference/Paper5707/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes the striking empirical phenomenon that, accounting for permutations, two independently trained networks of the same architecture will have no energy barrier on the linear path between them. Furthermore, the authors demonstrate an issue with naive interpolation for deeper networks where the activations experience a variance collapse on this linear path, creating an 'artificial' barrier on this connected path. To resolve this, the authors propose a simple renormalization procedure that re-establishes mode connectivity (albeit no longer linear). ",
            "strength_and_weaknesses": "Strengths:\n- Renormalization without permutation significantly lowering the barrier is an interesting finding complementary to the concurrent Ainsworth et al. 2022 result.\n- Renormalization technique is an improvement over Ainsworth et al. 2022, which requires the replacement of BatchNorm layers with LayerNorm layers to alleviate the barrier in Residual networks.\n\nWeaknesses:\n- The pattern of increasing test error corresponding to a larger barrier is an interesting finding. But there doesn't seem to be an intuition on why this is true. Without an explanation, it's unclear why this pattern is viewed as expected or \"simple\"\n\nFrom the paper:\n\"the high barrier of ImageNet models stems in part simply from the relatively higher test error of said models\"\n\nComment:\nCould the authors elaborate on the connections between robustness and linear mode connectivity? Is there an expectation that linear mode connectivity will indicate robustness?  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and refreshingly honest about the LMC phenomenon being shown empirically for smaller models while still needing further validation in the ImageNet setting where the energy barrier is still significant. The overall idea is simple and straightforward.\n\nThe authors do provide source code, so reproducibility is likely.",
            "summary_of_the_review": "The empirical validation of the LMC phenomenon is important, and this work does a good job of diagnosing the issues with LMC when applied in practice. The renormalization method appears novel and significantly improves the loss barrier along the bath between the two models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_LkzC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5707/Reviewer_LkzC"
        ]
    }
]