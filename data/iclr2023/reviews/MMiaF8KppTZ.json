[
    {
        "id": "wDQIlMDSuc",
        "original": null,
        "number": 1,
        "cdate": 1665978630930,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665978630930,
        "tmdate": 1665978630930,
        "tddate": null,
        "forum": "MMiaF8KppTZ",
        "replyto": "MMiaF8KppTZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3328/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "I am unable to review this paper.",
            "strength_and_weaknesses": "NA",
            "clarity,_quality,_novelty_and_reproducibility": "NA",
            "summary_of_the_review": "NA",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_ExFJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_ExFJ"
        ]
    },
    {
        "id": "Xfdc0q0jw9T",
        "original": null,
        "number": 2,
        "cdate": 1666530718685,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530718685,
        "tmdate": 1666530718685,
        "tddate": null,
        "forum": "MMiaF8KppTZ",
        "replyto": "MMiaF8KppTZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3328/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In the development of social sciences to investigate human societies, measurement models in the social sciences did not keep in mind the deep societal reach of  algorithms. This calls for new methods to measure feasible information. However, this paper shows that innovative approaches to obtaining such fair and trustworthy information are heuristic at best. \n\nThe ineffectiveness of fairness in a machine learning task is proven by a purely logical view on fairness of a binary classification task. Namely, it is shown that first-order logic language \ud835\udc3f and \ud835\udc3f- theory \ud835\udc47 for binary classification is not expressible in the first-order logic \ud835\udc3f-formula. This means in first-order logic that fairness and trustworthiness is algorithmically undecidable for binary classification. And so we are unable to find an effective algorithm that decides whether a well-defined formula in logic theory is true. To prove this undecidability, the paper looks at a special class of classifiers that, in logic, are similar to binary classifiers. These classifiers are called random binary classifiers, and they are based on a random graph structure. It is shown that random graphs are isomorphic, which results in the theory of random graphs to be almost surely decidable. However, in a considerable proof it is shown that despite random binary classifiers to be almost surely decidable, one cannot use any first-order logic expression to compare two binary classifiers fairly. Hence, we arrive to the conclusion of the paper, that fairness in binary classification remains to be heuristic at best. The paper suggests further research on higher-order logic.",
            "strength_and_weaknesses": "Strengths: \n\nUse of first-order logic in machine learning\nPaper with profound mathematics with mainly known-results\n\nWeaknesses: \n\nFields of mathematics are mentioned, but I doubt that they are immediately obvious to regular machine learning researcher. It seems to be model theory at first, next I\u2019m thinking it\u2019s more real analysis. This may be due to the order of the paper. However, many definitions are introduced in Section 1.1. \n\nThroughout the paper and its proofs, I am missing the connection to a more intuitive definition of fairness in a classification task.",
            "clarity,_quality,_novelty_and_reproducibility": "To me, the paper wasn\u2019t clear instantly. Some may have to do with the structure with the paper, and a lot will have to do with the fact that these parts of mathematics have been a few years for me. But some parts could use some further mathematical explanation. For example, the definition of the random graph in section 1.2 was a bit vague to me. It followed that I couldn\u2019t easily reproduce all the proofs. I had to think on some proofs for a while. I do think there is a novelty in this paper as I\u2019ve never encountered a logical view on fairness. Also, after doing brief research, I couldn\u2019t find any substantial papers on mathematical logic and fairness in machine learning. Furthermore, the paper is based on few references and so it may be that there\u2019s not much to find.",
            "summary_of_the_review": "Overall, I think this is an interesting and possibly, a novel paper. It took me some effort to understand everything, which will probably have to do with me, but maybe also with the way the paper is written.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_ZpSj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_ZpSj"
        ]
    },
    {
        "id": "-y-UiqaBeyE",
        "original": null,
        "number": 3,
        "cdate": 1666824960383,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666824960383,
        "tmdate": 1666824960383,
        "tddate": null,
        "forum": "MMiaF8KppTZ",
        "replyto": "MMiaF8KppTZ",
        "invitation": "ICLR.cc/2023/Conference/Paper3328/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper claims that it proves that fairness and trustworthy are undecidable for binary classification. The authors frame this as a first-order logic problem to guide their proof.",
            "strength_and_weaknesses": "I am not entirely sure what the point of this paper is, unfortunately. The introduction makes claims about fairness and trustworthiness not being decidable, but the preliminaries (which claim to be self-contained) do not provide a formal mathematical definition of either concept that would be necessary to make claims about decidability. This is not made clearer in section 2.1, where the first result concerning inexpressiveness of fairness is claimed. Some translation here between any common fairness metric and the claim here would be helpful. Moreover, I do not understand how the claim in section 3 around undecidability is novel (even if it is valid), which also seems acknowledged in footnote 2. I also do not understand how these claims relate to trust, as the concept does not come up again in the paper. Overall, I am not sure what the contribution of the paper is, or what I should take from it.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is unclear about what its contribution is and why that contribution matters. From what I do understand, it doesn't seem novel. There are no experiments.",
            "summary_of_the_review": "See above. Paper's contributions are not clear, both in a big picture sense and in terms of how it relates to the field on algorithmic fairness. It is also not clear what is novel here, even if it were relevant (e.g., see footnote 2 in the paper).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_isj2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3328/Reviewer_isj2"
        ]
    }
]