[
    {
        "id": "-t1r-Y7mkw",
        "original": null,
        "number": 1,
        "cdate": 1666531415907,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531415907,
        "tmdate": 1666531415907,
        "tddate": null,
        "forum": "rJcLocAJpA6",
        "replyto": "rJcLocAJpA6",
        "invitation": "ICLR.cc/2023/Conference/Paper3682/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper propose a method to calculate the compositional uncertainty of sequence to sequence model for semantic parsing tasks, that is in tasks where the input is an utterance and the output is a graph.\nFor doing so the authors propose to marginalize the probability of output sequences so to calculate the expected probability of a node, give its parent node in a generated graph. Since marginalizing over all possible subsequences between two symbols is intractable in general, the authors propose to approximate this process using beam decoding.\nThe authors use the compositional uncertainty to calculate the expected calibration error, that is how well the uncertainty matches the performances of the model. The authors compare standard ECE and compositional ECE, showing that the second one is a better choice.\n\nFinally the model is used in a collaborative semantic parsing where parts of the predictions (for example where the models is more uncertain on) can be send to human validation. Results show that the proposed measure of uncertainty finds more errors than random, and it is close to an oracle selection.",
            "strength_and_weaknesses": "The paper is well written and seems to be a missing piece in the semantic parsing literature. Calibration error is a standard metric to understand how trustworthy the predictions of a model are, and apparently this is the first attempt at calculating it in the setting of compositional sequence to sequence models.\n\nThe paper is pretty clear and goes step by step explaining the various concepts used in the paper. it is equation-heavy but easy to understand.\n\nThe premises for section 3.2 are a bit vague, to me modelling compositional uncertainty would be very helpful in an active learning framework, where subgraph on which the model is uncertain are asked to be reannotated. The collaborative semantic parsing scenario is not very realistic to me.\nIt is not clear to me also how the oracle is defined.",
            "clarity,_quality,_novelty_and_reproducibility": "First sentence of the intro, typo, graph paring -> graph parsing\nTable 1 and fig 3 are extremely small\n\nI find the paper technically sound and clear.",
            "summary_of_the_review": "This work introduce a technique that allows practitioner to calculate compositional uncertainty in seq 2 seq model for graph parsing.\nI am not an expert in graph parsing but it seems that this paper fills a void in that space.\nI am not able to judge if more experiments on different datasets are required to prove if the approach is general enough to be used in any kind of text 2 graph task.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_oThz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_oThz"
        ]
    },
    {
        "id": "sRvg_rSV9X",
        "original": null,
        "number": 2,
        "cdate": 1666630360595,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666630360595,
        "tmdate": 1669307326615,
        "tddate": null,
        "forum": "rJcLocAJpA6",
        "replyto": "rJcLocAJpA6",
        "invitation": "ICLR.cc/2023/Conference/Paper3682/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors do seq2seq parsing with various semantic parsing datasets, and employ a specialized method called GAP that is meant to incorporate \"compositional uncertainty\" (UC). My interpretation is that UC incorporates probabilities over graph construction (i.e. edge and node creation) rather than token predictions when training seq2seq models with max-likelihood objectives (although there is a fine line between these two, and perhaps the former is achieved simply by using the right action space). Also, their training involves approximate normalization over subgraphs via importance sampling. Because of uncertainty measures that GAP implements, it is suitable for human-in-the-loop graph editing (sec 3.2). This last idea is quite interesting --- maybe your initial graph is fine and a human can slightly fix it up to drastically improve performance. That being said, the eval is somewhat limited and the main text is lacking details.",
            "strength_and_weaknesses": "# Strengths\n\n1. The paper is focused on seq2seq parsing with T5. This is a challenging task and active research area. They evaluate on many semantic parsing tasks.\n\n2. The authors explicitly model the graph rather than solely treat it as a string-to-string task.\n\n3. The authors evaluate in a creative scenario where humans can edit noisy graphs to drastically improve performance, although this section is limited.\n\n# Weaknesses\n\n1. There are many missing related work, and it is not right to say they are first to explore local probabilities for seq2seq parsing.\n\n2. The evaluation is very hard to interpret. In the main table 1, there are no baselines and only T5 w/ GAP is evaluated as far as I can tell. In figure 3 there are many methods but I am not sure how it ties into the main storyline regarding T5 w/ GAP. In addition the evaluation is not very standard, which alone is not a major problem, but warrants further explanation in the text.\n\n3. To me the most exciting part of the work is that noisy graphs can potentially be edited to improve performance. This section leads to some concerns... I am surprised RANDOM can be so effective. There are not really any details on how human edits are done. There is not much analysis on the subgraph editing, and it seems like most of editing can be done by editing one or two labels.",
            "clarity,_quality,_novelty_and_reproducibility": "1. Probably should mention Vinyals et al, 2014 \"Grammar as a Foreign Language\", one of the earliest successful attempts to do seq2seq parsing.\n\n2. Also, for parsing specifically there are probabilistic models that represent uncertainty well, i.e. chart parsers.\n\n3. Since you are using PENMAN, you may be interested in the SPRING model from Bevilacqua et al. 2021 and the stack-based transformer work from Ramon Astudillo and others (starting in 2020 with multiple followups). From those works, the paper from Drozdov et al. 2022 is particularly relevant as it explicitly models uncertainty with respect to alignments between graph nodes and input text tokens using importance sampling. The earlier RNNG work from Dyer et al 2016 also uses importance sampling in seq2seq setting.\n\n4. The compositional uncertainty is measured locally. Although convenient, it's well know this can be lead to propagating errors (i.e. label bias problem), which was motivation to introduce CRFs to combat this problem in MEMMs. This is not a major issue per say, since contextual encoders blur lines between local and global decisions, but should be aware of this when using graphical models. Some related discussion in Andor et al 2016 \"Globally Normalized Transition-based Neural Nets\" and also Buy and Blunsom 2018 \"Neural Syntactic Generative Models with Exact Marginalization\".\n\n5. About this claim \"We are the first work to study compositional uncertainty for seq2seq graph parsing.\", certainly others have addressed this issue of P(v | pa(v), x) before even if they have used different terminology, so this is not the first.\n\n6. Does \"long-range\" in \"long-range parent-child conditional probability\" refer to distance in graph or distance in sequence? This usage was a bit confusing to me. My understanding is that neighboring words can be arbitrarily far away in the graph and vice versa. Later in the text suggests this means long-range in both spaces.\n\n7. In sec 2.1.1 I think \"global likelihood\" is really \"cumulative likelihood\". One other thing I am confused about here is what is being integrated over... is it graphs of a certain size? Is there an ordering over graph creation actions that is important to know?\n\n8. Regarding \"sequence accuracy (ACCseq) does not necessarily correlate to the SMATCH score,\": is sequence accuracy the same as \"exact match\"? Doesn't SMATCH assign partial credit? So clearly SMATCH would be different.\n\n9. In general, I think it is neat to use PENMAN here, but I am also a little confused why it would be useful. Is it because of top-down representation? Does the data employ non-tree graphs? If so, then wouldn't variables be necessary (it says you use the non-variable PENMAN).\n\n10. The idea about editing subgraphs based on uncertainty is neat, but I have some questions that I was confused about. Can any arbitrary subgraph be edited, or only certain types (e.g. must include all nodes between root and leaf)? Do authors believe subgraph editing is sufficient --- when subgraph is wrong, perhaps the entire graph has mistakes? Does low model probability really equate to uncertainty --- wouldn't ambiguity (near random) more align with concept of uncertainty? It seems intuitive that locally low probability could be an unreliable indicator in out-of-domain --- predicting a node for a rare or unusual token for example could give low local probability, so maybe there is other low hanging fruit for identifying subgraphs to edit.\n\n11. Assuming the GAP formulation is desirable, I'm still confused on the details of the parameterization. Can it really be derived solely from beam-search probabilities? If so, is this achieved simply by choosing the correct action space? I would think this is not enough, since the same graph can be potentially created from different actions and I am not sure it would have the same probability.\n\n12. The authors may be interesting in existing work on retrieve-and-edit (Hashimoto et al.) or parse editing in general, which is loosely relevant.\n\ntypo: \"Here to The model\"\n\nUPDATE: Numbered for convenience.\n",
            "summary_of_the_review": "The core idea of the paper, that uncertainty can be used to inform graph editing, seems very interesting but I am not sure it is well executed. Parts of the presentation are confusing, and there could be more analysis on the graph editing portion. By fixing up writing, adding appropriate baselines, and providing more emphasis on graph editing part, then I think this could be a stronger paper. Right now I do not think it meets standards of the conference.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_jzBV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_jzBV"
        ]
    },
    {
        "id": "rqb1VozEDV",
        "original": null,
        "number": 3,
        "cdate": 1666902458994,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666902458994,
        "tmdate": 1666902458994,
        "tddate": null,
        "forum": "rJcLocAJpA6",
        "replyto": "rJcLocAJpA6",
        "invitation": "ICLR.cc/2023/Conference/Paper3682/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper is a novel and profound contribution to sequence-to-sequence graph parsing of natural language, quantifying and evaluating compositional uncertainty in seq2seq graph parsing through a newly-proposed probabilistically interpretable framework and a new metric which measures a model's calibration in predicting graph structures. A large battery of tests together with human evaluations shows strong empirical support for the framework.",
            "strength_and_weaknesses": "Strengths:\n- A novel and creative contribution to modelling and evaluation for uncertainty in seq2seq parsing.\n- Thorough experiments, high-quality writeup, convincing results.\n\nWeaknesses:\n- The selection of datasets is not thoroughly elaborated from the viewpoint of availability vs. linguistic breadth. English is dominant in graph parsing, but care should be taken to qualify how the approach would scale up (with the number of languages covered) and down (with diminished resource availability in low-resource languages). A Limitations section addressing this linguistic breadth angle, and an honest account of this contribution being by and large for English only, would suffice.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is of exceptional quality and clarity, and it is both original and important to the (sub-)field.",
            "summary_of_the_review": "Contained above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_3RNa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3682/Reviewer_3RNa"
        ]
    }
]