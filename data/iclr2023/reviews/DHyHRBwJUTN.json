[
    {
        "id": "WKQi6rX6N2X",
        "original": null,
        "number": 1,
        "cdate": 1666453922671,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666453922671,
        "tmdate": 1666920602687,
        "tddate": null,
        "forum": "DHyHRBwJUTN",
        "replyto": "DHyHRBwJUTN",
        "invitation": "ICLR.cc/2023/Conference/Paper828/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposed a novel dataset, TABMWP, for math word problems with tabular context, which contains over 30,000 open-domain problems that require multiple steps of reasoning. On top of the dataset, it further proposed a new approach to learning to select in-context examples and construct the performing prompt for the test example. It then conducted extensive experiments evaluating the performance of the proposed approach, GPT-3, state-of-the-art QA, and TableQA methods on the new dataset TABMWP. The experiment results demonstrate the better performance of PromptPG in many cases.",
            "strength_and_weaknesses": "Strength:\n-\n\n[+] The proposed dataset is novel and of high quality.\n\n[+] The proposed approach, built on top of [1] and [2], applies reinforcement learning to select in-context examples for the few-shot GPT-3 model and has better performance over state-of-the-art QA, and TableQA methods in most settings.\n\n[+] The proposed approach also has better performance than some other selection strategies of in-context examples.\n\nWeakness:\n-\n\n[-] The authors should investigate the performance gain of PromptPG over prompting baselines w/ GPT-3 in relation to the usage of many times more training examples.\n\n[-] The presentation of this work misses some important details of the proposed approach PromptPG (see below).\n\nA few detailed questions related to the proposed approach PromptPG:\n\n1. What is the structure of the prompt creator in Figure 2? Does it contain learnable parameters?\n\n2. How does PromptPG handle the structured tabular data exactly? Are there steps for generating queries to the tabular data? If so, where are the steps in Figure 2?\n\n3. How do you select the candidate examples? Are they randomly drawn from the training data? How would different candidate pools affect the performance of selecting in-context examples?\n\n---\n\n[1] Jiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan, Lawrence Carin, and Weizhu Chen.\nWhat makes good in-context examples for GPT-3? In Proceedings of Deep Learning Inside Out\n(DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning\nArchitectures, pp. 100\u2013114, 2022a.\n\n[2] Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, and Jian-Guang Lou.\nTapex: Table pre-training via learning a neural SQL executor. In International Conference on\nLearning Representations (ICLR), 2022b.",
            "clarity,_quality,_novelty_and_reproducibility": "This work proposed a novel and high-quality dataset TABMWP for math word problems with tabular context, which could be used as a benchmark dataset of tabular reasoning domains. The presentation of the proposed approach is not very clear, which makes it hard to evaluate its originality and the key parts that improve over other baselines. ",
            "summary_of_the_review": "This work proposed a novel and high-quality dataset TABMWP for math word problems with tabular context, which could be used as a benchmark dataset of tabular reasoning domains. It then proposed a new approach PromptPG which applies reinforcement learning to select in-context examples for the few-shot GPT-3. The work also conducts extensive experiments to evaluate the proposed approach over many other baselines. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper828/Reviewer_MEHB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper828/Reviewer_MEHB"
        ]
    },
    {
        "id": "hqO0ezVeNxb",
        "original": null,
        "number": 2,
        "cdate": 1666619795717,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619795717,
        "tmdate": 1666619795717,
        "tddate": null,
        "forum": "DHyHRBwJUTN",
        "replyto": "DHyHRBwJUTN",
        "invitation": "ICLR.cc/2023/Conference/Paper828/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents TABMWP, a dataset of grade-school-level math problems with tabular context and human annotated solutions in text form. Then the author proposes a method called PROMPTPG to mitigate the unstable issue occurred when solving problems above in few-shot setting. The problems and solutions in dataset were originally collected from a math learning website. Then the author manually filtered them to ensure there\u2019s no problem can be solved without the tabular context and numerical reasoning process and checked the solutions\u2019 correctness. The idea of the method proposed is trying to find the most appropriate in-context examples for a given problem in test time. The policy to choose in-context example is learnt by a reinforcement learning policy gradient strategy.",
            "strength_and_weaknesses": "Strength:\na)\tThe idea of using reinforcement learning policy gradient strategy to train an agent to find helpful prompting examples is interesting. It enables \u201cautomatic prompt-tuning\u201d to some extent, since directly tuning GPT-3 is hard.\nb)\tThe author provided a math problem dataset annotated with quality text solutions. It is helpful for researches which use general-purposed LM to perform mathematical reasoning tasks (e.g. \u201cchain-of-thought\u201d).\nc)\tThe author conducted a rich set of experiments to test the method and incorporated human performance.\n\nWeakness:\na)\tThe idea of constructing a tabular math problem dataset is not very inspiring.\nb)\tSome statements are contradictory. In the introduction, the author claimed that retrieving semantically similar examples might not work well. But in the ablation study part, the result indicates that selecting similar examples as prompt does make an improvement.\nc)\tPROMPTPG needs to be compared with manually chosen and fixed in-context example. If one randomly chooses example for every test-time problem, obviously it can increase the variance of accuracy.\nd)\tDynamically selecting prompt examples still might not be enough. It relies on quality human annotated solutions (when \u201cchain-of-thought\u201d is needed). Sometimes the effort to obtain such annotations is non-trivial.\ne)\tThough ablation study and case study were performed, there is no in-depth analysis of them.",
            "clarity,_quality,_novelty_and_reproducibility": "The TABMWP dataset is helpful for researches which use general-purposed LM to perform mathematical reasoning tasks.\nThe idea of using reinforcement learning policy gradient strategy to train an agent to find helpful prompting examples is interesting.",
            "summary_of_the_review": "The main problem of this paper is that the experiments do not validate the motivation of the paper. \n(1) Is the selection of examples important for the TABMWP dataset dataset? PROMPTPG needs to be compared with manually chosen and fixed in-context example.\n(2) The policy gradient method designed in this paper is independent of the tabular data. Therefore, why this method is proposed for tabular data is not explained. Although the authors mentioned in Section 3.2 that \"may be more severe on TABMWP\", this has not been verified.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper828/Reviewer_5Mut"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper828/Reviewer_5Mut"
        ]
    },
    {
        "id": "ZKQLeAF0-V",
        "original": null,
        "number": 3,
        "cdate": 1666683099601,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666683099601,
        "tmdate": 1666683099601,
        "tddate": null,
        "forum": "DHyHRBwJUTN",
        "replyto": "DHyHRBwJUTN",
        "invitation": "ICLR.cc/2023/Conference/Paper828/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces TabMWP - a dataset containing open-domain grade-level problems that require mathematical reasoning on both textual and tabular data. It evaluates a number of models and methods on this dataset and finds that chain-of-thought prompting on GPT-3 is the strongest baseline. Inspired by the sensitivity of the chain-of-thought performance to the choice of prompt examples, the paper further introduces a method to learn to predict a dynamic set of prompt examples per test-question, where the model is trained through REINFORCE to output prompt examples that would maximize the expected accuracy on the test question.",
            "strength_and_weaknesses": "### Strength:\n\n- This paper introduces a well-designed math word dataset that contains tabular information, upon which the answers depend. The dataset contains diversity in terms of difficulty level (from different grades), answer format (free-text or multiple choice) and table format (structured, semi-structured, and image), along with the associated answer rationales. This is extremely valuable to the community for evaluating the performance of models when working with tabular datasets.\n\n- The dynamic prompting method via policy gradient appears novel and interesting, and has been shown to improve performance over a number of baseline strategies.\n\n- The experiments are well-designed and covers a broad range of ablations and a large set of baselines, including human performance. This provides a very valuable starting point for the community to benchmark on this dataset.\n\n### Weakness:\n\nI have several questions that I hope the authors can answer:\n\n- Is promptPG using rationale augmented few shot examples? What happens if it uses simple few-shot without rationales?\n\n- What happens if we increase the number of shots in-context? Would using more than 2 shots reduce the variance that come from choosing different prompt examples?\n\n- Clarify what it means to have or not have C (choice options) in Table 4.\n\n- Can you train for a fixed set of in-context examples? What would be the performance gap? It would be interesting to see how much does the improvement come from dynamic prompt examples rather than an optimized set of static examples.",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is beautifully written and easy to follow, with effective figures, summaries, and comparisons to existing work.\n\n- The dataset appears to be highly original (first of its kind), and the proposed promptPG method appears to be novel to the best of my knowledge.\n",
            "summary_of_the_review": "This paper introduces a tabular math word dataset and benchmarks a number of methods on this task. The paper further introduces an RL-based method for dynamically choosing the prompt examples to be used for in-context learning. Both are novel and significant contributions to the best of my knowledge.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper828/Reviewer_G2Gx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper828/Reviewer_G2Gx"
        ]
    },
    {
        "id": "M-STnt66zo",
        "original": null,
        "number": 4,
        "cdate": 1666846038715,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666846038715,
        "tmdate": 1666846038715,
        "tddate": null,
        "forum": "DHyHRBwJUTN",
        "replyto": "DHyHRBwJUTN",
        "invitation": "ICLR.cc/2023/Conference/Paper828/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "1. This paper proposes TabMWP, a dataset of 30k examples containing grade-level problems that require mathematical reasoning on both textual and tabular data.\n2. The paper establishes a number of baselines for the dataset\n3. The paper proposed a policy gradient method to select few-shot in-context examples",
            "strength_and_weaknesses": "Strength\n1. The paper is very well-written and easy to follow\n2. the baseline evaluation of the proposed dataset is comprehensive\n\nWeakness\n1. The paper would benefit from a related work subsection that discusses if policy gradient has been applied in similar setup, or is this totally new?\n2. There are a lot of math NLP datasets out there.  I understand this may be the first dataset that tests reasoning on both textual and tabular data, but it is unclear how this dataset would push forward NLP research.  Unlike text + image, there's already a quite natural way of combining table and text, so I'm not sure how this dataset may open up new research directions.  So this is a concern of the potential impact of this dataset.",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty is debatable, but Clarity, Quality, And Reproducibility are good!",
            "summary_of_the_review": "this is a pretty complete piece of work that has a new dataset and comprehensive experimental evaluation on the dataset.  whether this dataset can inspire important future research is unclear.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper828/Reviewer_MYrE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper828/Reviewer_MYrE"
        ]
    },
    {
        "id": "wZ7NW70tpUJ",
        "original": null,
        "number": 5,
        "cdate": 1666850063158,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666850063158,
        "tmdate": 1666922864981,
        "tddate": null,
        "forum": "DHyHRBwJUTN",
        "replyto": "DHyHRBwJUTN",
        "invitation": "ICLR.cc/2023/Conference/Paper828/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a dataset of Tabular Math Word Problems (TabMWP), consisting of Math word problems with associated tabular data.  Additionally, the authors introduce a policy gradient approach (PromptPG) for selecting in-context examples as prompts for a GPT-3 few-shot language model in generating answers to the TabMWP problems.  The dataset is open-source, and contains multiple types of answers (numeric, multiple-choice, text), and the policy gradient method is shown to outperform other approaches.",
            "strength_and_weaknesses": "Strengths:\n\n- The new dataset is a valuable resource for an interesting problem, and goes beyond similar previous datasets in terms of scale and types of problems as shown in Table 2.\n- The PromptPG method demonstrates impressive performance, and the experimentation is very thorough in testing against SOTA approaches, the influence of hyperparameters, human performance, simpler selection strategies (random / nearest neighbor).\n\nWeaknesses:\n\n- The method is mainly a combination of previous approaches, and there is not substantial theoretical/conceptual novelty\n- It is not clear why the method is framed specifically as a reinforcement leaning method - since the problem instances are all independent, it would seem more accurate to describe it as online learning, and describe the approach as optimizing a supervised model with latent variables.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, quality and reproducibility are high.  As mentioned above, the novelty is less clear.",
            "summary_of_the_review": "The paper represents a potentially valuable contribution to an interesting problem in natural language processing, showing how a 'high-level' algorithm can be developed by using existing components to achieve SOTA results in a surprisingly straightforward manner.  The paper will be of interest to those working in natural language processing and deep learning.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper828/Reviewer_fX43"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper828/Reviewer_fX43"
        ]
    }
]