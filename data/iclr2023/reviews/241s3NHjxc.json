[
    {
        "id": "65m7EWzDEpC",
        "original": null,
        "number": 1,
        "cdate": 1666335853213,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666335853213,
        "tmdate": 1666335853213,
        "tddate": null,
        "forum": "241s3NHjxc",
        "replyto": "241s3NHjxc",
        "invitation": "ICLR.cc/2023/Conference/Paper3972/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new graph transformer architecture based on quantum computation. The main idea is to replace the typical attention matrix by a \u201cquantum computable\u201d attention matrix. The main motivation for such a proposal is easily getting access to graph features (such as maximum probability assignment from an antiferromagnetic Ising model) using quantum computation. The proposed algorithm is simulated under small scale experiments (graphs with up to 20 nodes) and shows comparable performance when compared to popular non-quantum coputation-based graph neural networks. ",
            "strength_and_weaknesses": "Strength 1: Designing neural network architectures for quantum processing is an active & significant area of research.\n\nStrength 2: To my knowledge, this paper is the first to propose quantum computer-version of graph transformers.\n\nWeakness 1: While the paper mainly focuses on introducing new global graph features, the benefit of introducing additional feature, e.g., better expressive power or empirical performance, is not clear. \n\nWeakness 2: The motivating example is not very convincing since I think the example (samples from antiferromagnetic Ising model) can be obtained using existing graph neural network. Samples (or labels) from antiferromagnetic Ising model can be framed as samples from a probabilistic graphical model (PGM). Obtaining such a sample has been well-studied in the context of structured prediction, e.g., graph Markov neural network.\n\nWeakness 3: The paper does not empirically compare with the existing quantum graph neural network, hence the contribution of this paper as a \u201cnew quantum neural network for graphs\u201d is not clear.\n\nWeakness 4: This paper only computes the attention matrix using quantum processing units and requires CPU or GPU for other operations. It is not clear how the whole architecture can be efficiently implemented in practice.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper provides good preliminaries for readers unfamiliar with quantum computing, which was helpful. However, this paper is not clear in what contribution it brings to the machine learning community and how the contribution is empirically validated.\n\nNovelty: This paper newly develops a self-attention-like architecture for graphs, which is novel. However, the novelty is not very clear in the text since the related works are only briefly mentioned.",
            "summary_of_the_review": "This paper proposes a new quantum computing-based architecture for graphs. Although I am a non-expert in quantum computing, I do not think this paper brings clear contribution to the machine learning community in current form. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_FV73"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_FV73"
        ]
    },
    {
        "id": "W46jQ3KwEo",
        "original": null,
        "number": 2,
        "cdate": 1666523474081,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666523474081,
        "tmdate": 1666523474081,
        "tddate": null,
        "forum": "241s3NHjxc",
        "replyto": "241s3NHjxc",
        "invitation": "ICLR.cc/2023/Conference/Paper3972/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, a new quantum enhanced GNN is proposed from the perspective of quantum mechanics. The paper regards the graph as a quantum system, transforms the graph topology into the interaction of a group of qubits, and uses the long-range correlation of the quantum system to calculate the relationship between different vertex to form the aggregation weight of GNN. The author illustrates the advantages of graph quantum states compared with traditional methods to obtain graph structures from three aspects. By rewriting the update mechanism of traditional GNN, the proposed model can distinguish some graph structures that are difficult to distinguish by traditional GNN. The experimental results show that this new model performs similarly to standard GNN architectures on different benchmarks.",
            "strength_and_weaknesses": "**Strengths\uff1a**\n- This paper extends graph transformers with quantum computed aggregation and introduce a GNN architecture where the aggregation weights are computed using the long-range correlations of a quantum system. The method this paper uses is novelty.\n- The goal of this paper is to explore new types of global structural features emerging from quantum physics that can be added to a GNN. And the author explains the reasons for adopting graph quantum state from three aspects. This makes the motivation clear.\n- The whole paper is clear in structure and content.\n\n**Weaknesses\uff1a**\n\nThe author mentioned that this method can easily detect some complex structures compared with traditional methods, and gave some special cases in Chapter 3, which is the motivation of the author to introduce the graph quantum states, but these special cases can not show that the graph structure detection ability of quantum graph GNN is greater than that of traditional methods. From the aspect of structure detection, this paper lacks the relevant experimental comparison with traditional methods in general situations, rather than the carefully constructed data in Section 6.1. If you want to show that the graph quantum state has better structure detection capability than traditional methods on some graphs, both two models in Section 6.1 have reached 100% accuracy, and the loss index based on this may not be convincing. At the same time, according to the results of comparative experiments on various tasks in Section 6.2, it is difficult to explain the advantages of this method compared with traditional methods, which is not enough to support the author's motivation. In addition, this paper does not prove other advantages of GTQC.",
            "clarity,_quality,_novelty_and_reproducibility": "The content and the structure of this article is clear. In this paper, quantum computation is combined with traditional GNN method to form quantum enhanced GNN, which not only retains the framework of traditional GNN, but also introduces graph quantum computation. The method is novel. But the experimental results are not convincing. In general, the quality of this paper is average.",
            "summary_of_the_review": "The experiments in this paper fail to prove the possible advantages of quantum graph GNN mentioned in Section 3. At the same time, the author does not give other capabilities of the model, which leads to the ambiguity of the meaning of the designed model. From this point of view, this paper should be rejected.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "For the part of Experiment 6.1, can you compare the performance of traditional GNN or transformer with the model proposed in this paper in terms of structure detection under general rather than specific design data sets. Or design new experiments or experimental indicators to prove the advantages mentioned in Section 3.1.  In addition, can you further propose and explain other advantages of the model proposed in this paper from a theoretical or experimental perspective.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_fcGg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_fcGg"
        ]
    },
    {
        "id": "zDjX86UvoX",
        "original": null,
        "number": 3,
        "cdate": 1666526324126,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666526324126,
        "tmdate": 1666526324126,
        "tddate": null,
        "forum": "241s3NHjxc",
        "replyto": "241s3NHjxc",
        "invitation": "ICLR.cc/2023/Conference/Paper3972/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a quantum computing-based Graph Transformer architecture. The authors illustrate that their model outperforms the 1-WL test by finding the ground state energy of the Ising Hamiltonian. They also implement their algorithm on the classical computer and conduct experiments on some classical graph tasks. Experimental results show that their model is comparable to other GNN architectures.",
            "strength_and_weaknesses": "Pros: \n1.\tIt\u2019s interesting to combine quantum computing with Graph Neural Networks.\n2.\tThe authors show another way to construct an attention map, which may bring some inspiration.\n\nCons:\n\n[Whether the requirements.are realizable] \n\nThe proposed algorithm requires a large reliable quantum computer. The authors claimed that their algorithm outperforms the 1-WL test, which is illustrated by finding the ground state for some particular physical system. However, finding the ground state of some strongly correlated systems is proven intractable for classical computers (i.e., NP-hard [1]). Thus, it is hard to say that their algorithm also works well on a classic computer in practical applications. \n\n[No theoretical guarantee on classic computer]. \n\nIt\u2019s great to design an algorithm that only works well on a quantum computer and enjoys better expressiveness. However, in the current stage, using a reliable quantum system is not realistic. Given this, the authors need to justify that their model outperforms GNN state-of-the-art variants (e.g., ESAN[2]). Therefore, the significance of the algorithm is questionable.\n\n[1] F. Barahona, J. Phys. A 15, 3241 (1982)\n[2] Beatrice Bevilacqua et al. Equivariant subgraph aggregation networks. In International Conference on Learning Representations, 2022.\n\n[Experimental results]\n\nThe author compared their model with several out-of-date baseline methods but showed superior performance. The method needs improvement, and the authors should include strong baselines for comparisons, such as TorchMD-Net and ESAN.",
            "clarity,_quality,_novelty_and_reproducibility": "The quantum part is not easy to follow for a basic-knowledge person. I have asked some domain experts for help understanding the technical part. The experimental part is not very solid and needs improvements.",
            "summary_of_the_review": "The way of improving graph transformers is interesing but the current quality of the work, especially the empirical results, are not ready to publish in the venue, and I recommend rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_w3FW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3972/Reviewer_w3FW"
        ]
    }
]