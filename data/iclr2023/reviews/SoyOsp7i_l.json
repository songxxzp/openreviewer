[
    {
        "id": "GhZugcudRRg",
        "original": null,
        "number": 1,
        "cdate": 1665896060208,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665896060208,
        "tmdate": 1665896396154,
        "tddate": null,
        "forum": "SoyOsp7i_l",
        "replyto": "SoyOsp7i_l",
        "invitation": "ICLR.cc/2023/Conference/Paper4815/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper focuses on query answering over knowledge graphs. The idea is to use standard link prediction knowledge graph embeddings to model each triplet or atomic formula, create a message and spread it out to do a message passing over the query graph. Experiments on standard benchmark shows the proposed method achieves better or comparable results than prior state-of-the-art methods.",
            "strength_and_weaknesses": "The paper proposes a simple and effective method for query answering over knowledge graphs. It seems a combination of the ideas of CQD and MPQE. The authors perform extensive experiments and ablation studies to evaluate the proposed method. However, they did not seem to include the results of other recent baselines. Please find some more questions below.\n- It misses some words in the first paragraph on page 4. \u201cis able to produce a continuous truth value\u2026\u201d\n- What does \u201csuo\u201d mean at the end of Sec 4.1?\n- In Eq.5, what is the search domain for the embedding? \n- How is the logical message passing neural network different from a regular message passing NN? The update function is almost exactly the same.\n- The paper does not say how to handle the union operator. But I assume the way is to do a form of aggregation at the end. I suggest the authors add one paragraph about this.\n- The paper mentioned one form of query that cannot be handled by the other methods? Does the proposed method handle such queries? How would you handle an atomic formula $\\neg(a_1=a_2)$?\n- How does the model perform on larger benchmarks in [1]?\n- The baselines are not fully considered, there are GNNQE, kgTransformer and some other recently proposed query reasoning methods that are not compared in the main result.\n\n[1] SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The method is clearly written and easy to follow. But, I do find the authors did not include a discussion on how they handle the union operation using their message passing architecture. Also there are some weird indents at the start of many paragraphs, which look like uncleaned comments.\n\nQuality & Novelty: I think the paper produces a nice combination of CQD and MPQE. The experiment seems lacking, the authors did not compare the proposed method with all recent baselines.\n\nReproducibility: the results seem reproducible with all the details in section 7.1.\n",
            "summary_of_the_review": "Please find the details above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_5THt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_5THt"
        ]
    },
    {
        "id": "HgoTL7vTEkf",
        "original": null,
        "number": 2,
        "cdate": 1666343757870,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666343757870,
        "tmdate": 1666343757870,
        "tddate": null,
        "forum": "SoyOsp7i_l",
        "replyto": "SoyOsp7i_l",
        "invitation": "ICLR.cc/2023/Conference/Paper4815/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose to represent first-order logical queries as query graphs and then design a novel message passing-based framework LMPNN on the graphs to answer given queries. This is a successful attempt to combine the power of pretrained knowledge graph embeddings and message passing to perform logical reasoning. The proposed LMPNN is quite simple (a virtue) but experiments demonstrate its superior performance.",
            "strength_and_weaknesses": "## Strength \n1. This paper manages to answer complex EFO-1 queries by exploiting the potential of pretrained knowledge graph embeddings, showing that pretrained embeddings also contain abundant semantic information for logical negation.    \n2. The proposed LMPNN is simple but effective, attaining new SOTA results on benchmark datasets.    \n3. The authors conduct extensive ablation studies to evaluate the influence of different hyper-parameters.    \n4. This paper is clearly written and easy to follow.\n\n## Weakness\n1. The proposed framework is dependent on the underlying knowledge graph embeddings. The authors may want to provide more results using other KGE models (e.g., DistMult, TransE, RotatE, etc).   \n2. To perform efficient logical message passing, it seems that a closed-form message encoding function is necessary. If the underlying KGE is TransE or ConvE, then how to implement PMPNN?    \n3. The authors define a class of more expressive logical queries in Definition 1 and show that it can represent more queries compared with operator trees. However, there is no such kind of query in the current benchmark datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nThis paper is clearly written and well organized\n\n## Quality\nThis paper is technically sound. The main claims are well supported by theoretical analyses or experiments, and the experimental results are convincing.\n\n\n## Novelty\nThe overall framework seems novel and interesting to me. The idea of exploiting the power KGE to perform logical reasoning is inspired by CQD (ICLR21), while the authors further incorporate message passing to the framework and succeed to model logical negation. \n\n## Reproducibility\nThe authors provide detailed experimental settings and the range of grid search, so the reproducibility looks nice.",
            "summary_of_the_review": "This paper proposes a novel and interesting model for logical reasoning. The proposed model is simple and shows strong performance on standard benchmarks. The submission will be more solid if analyses and experiments for more KGE models can be provided.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_zhhh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_zhhh"
        ]
    },
    {
        "id": "cC4uLRzBG-p",
        "original": null,
        "number": 3,
        "cdate": 1666649628800,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649628800,
        "tmdate": 1666653458769,
        "tddate": null,
        "forum": "SoyOsp7i_l",
        "replyto": "SoyOsp7i_l",
        "invitation": "ICLR.cc/2023/Conference/Paper4815/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a Logical Message Passing Neural Network (LMPNN), which relies on pre-trained knowledge graph embeddings and MLP-based local one-hop inference to perform the Complex Query Answering (i.e., EFO-1) task. Compared to the prior work CQD [1], which formalizes the KG reasoning as an optimization problem, this paper proposes to use the closed-form solution of ComplEX to approximate the single-hop inference and use an MLP-based multi-layer GNN to perform the multi-hop reasoning.\n\n[1]: Arakelyan, Erik, Daniel Daza, Pasquale Minervini, and Michael Cochez. \"Complex Query Answering with Neural Link Predictors.\" In International Conference on Learning Representations. 2020.",
            "strength_and_weaknesses": "Strength:\n\n1. LMPNN is quite parameter-efficient, where only MLP and the embeddings of existential variable and free variable are learned.\n\n2. Due to the novel design of closed-form approximation of single-hop ComplEx, LMPNN is inference-efficient (in a GNN manner) compared to optimization-based methods like CQD [1].\n\n3. LMPNN achieves competitive or better performance on FB15k, FB15k-237, and NELL datasets.\n\n4. Compared to previous work CQD, LMPNN can additionally model the negation operation.\n\n\nWeaknesses:\n\n1. My main concern is on the comparison with the optimization-based method (i.e., CQD). The author claims that \"Moreover, it is unclear whether CQD can be applied to complex queries with negation operators\". Could I interpret it as the CQD is evaluated without the negation operations for INP, PIN, PNI, etc settings? Would it be possible to just use Eq. 7&8 in the paper to get an optimization-based baseline? Since one of the contributions in the paper is a GNN-like inference, I believe a fair comparison with optimization-based methods is necessary.\n\n2. The method is motivated by how to better perform one-hop queries, however, the experimental results show that LMPNN is usually outperformed by CQD in the 1P setting. Since in 1P, the one-hop ComplEx closed-form approximation should lead to the same solution as CQD, could the author explain the reasons?\n\n3. I feel the claim of bridging the gap between EFO-1 query answering and \"the long-standing achievements of KGR\" is a little over-claimed, given that previous work like CQD already uses the exactly same pre-trained KGE model (ComplEx).\n\nTypos:\n\nPage 5, \" In Figure 1, the central node x receives messages from all neighbor nodes, suo.\" what does \"suo\" mean?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly and technically sound. The proposed method (w.r.t one-hot inference-based GNN) is novel.",
            "summary_of_the_review": "The proposed LMPNN is 1) parameter-efficient, 2) inference-efficient (compared to optimization-based methods like CQD), and 3) achieves competitive or better performance on three EFO-1 datasets. My main concern is about the fair comparison with optimization-based methods with negations. Therefore, I can only recommend a weak accept for the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_NhRN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4815/Reviewer_NhRN"
        ]
    }
]