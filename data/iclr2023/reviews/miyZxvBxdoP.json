[
    {
        "id": "UN9teXyxFXe",
        "original": null,
        "number": 1,
        "cdate": 1666469858198,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666469858198,
        "tmdate": 1666576658086,
        "tddate": null,
        "forum": "miyZxvBxdoP",
        "replyto": "miyZxvBxdoP",
        "invitation": "ICLR.cc/2023/Conference/Paper861/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper extends label smoothing [Szegedy et al., 2016] to temporal data, and relates the proposed temporal label smoothing approach to multi-horizon prediction. Experiments on real data show that the proposed temporal label smoothing approach outperforms several baselines.",
            "strength_and_weaknesses": "Strengths:\n1. The problem being addressed is well-motivated.\n2. The proposed TLS method is straightforward to understand.\n\nWeaknesses:\n1. The proposed TLS method appears to be a rather incremental advance, extending label smoothing to the temporal setting in a straightforward manner, and then the choice of how the temporal component is parameterized comes off as ad hoc.\n2. It took me a bit of time to figure out how to interpret Figure 2. If at all possible, I would suggest providing some additional explanation to make parsing this figure easier.\n3. In terms of discussing related work, I think it would be helpful to compare the proposed method with deep imbalanced regression [Yang et al., 2021], which also involves imbalanced data and label smoothing (I realize that the proposed approaches are different and the latter isn't tailored for early adverse event prediction; I think these authors also did look at time series data as one of their examples).\n4. In Table 2, I would suggest providing some more significant figures or at least stating something about the p-values that are \"0.00\" as I would guess they aren't actually exactly equal to 0.\n5. Statistical significance aside, I think it would be helpful to provide more commentary on how much of a *practical* difference there is between the proposed temporal label smoothing method and the different baselines. Basically even if there's a statistically significant difference in an evaluation metric, the difference might not be practically significant (some of the numbers from TLS look quite close to those of the multi-horizon baseline, for instance). If it's at all possible to try to quantify the difference in terms of how much earlier TLS can predict an outcome compared to different baselines, that would be helpful (in this case, just as an example, it could be that TLS can in some sense predict as accurately as the multi-horizon baseline 5 seconds faster, and that this 5-second difference is statistically significant but one could argue that 5 seconds is not going to make a difference practically in many clinical applications).\n6. I find the number of baselines to be rather small, and it is unclear to me why this is the case. There are *many* machine learning and data mining methods proposed for early prediction/detection/classification of various critical events. I would suggest doing a more thorough literature search to find additional baselines to try. As just a few examples of existing work (this listing is very much non-exhaustive), see the work by Xing et al. [2009], He et al. [2013], Chen et al. [2013], and Lauritsen et al. [2020], or the recent software package by Tavenard et al [2020]; note that some of these would require some sort of conversion of irregularly sampled data into regularly sampled numerical time series but there are straightforward ways to do this (e.g., discretizing time and using some imputation strategy like forward filling to fill in missing values). Moreover, for the specific applications considered, I think it's also worthwhile comparing to any sort of early detection method that is actually currently in clinical use, if any (if not, then it would be helpful indicating that this is the case).\n7. There are small typos here and there. Please proofread carefully. As a few examples (not exhaustive), equation (2) ends in \"[\" which looks like a typo, the third line of the first full paragraph of Section 4.2 has the misspelled word \"reweigthing\", and the last sentence of the first full paragraph of Section 4.3 has a missing space after a period: \".Thus\".\n\nReferences:\n- George H. Chen, Stanislav Nikolov, Devavrat Shah. A Latent Source Model for Nonparametric Time Series Classification. NeurIPS 2013.\n- Guoliang He, Yong Duan, Tieyun Qian, Xu Chen. Early prediction on imbalanced multivariate time series. CIKM 2013.\n- Simon Meyer Lauritsen, Mads Ellersgaard Kal\u00f8r, Emil Lund Kongsgaard, Katrine Meyer Lauritsen, Marianne Johansson J\u00f8rgensen, Jeppe Lange, Bo Thiesson. Early detection of sepsis utilizing deep learning on electronic health record event sequences. AIIM 2020.\n- Romain Tavenard, Johann Faouzi, Gilles Vandewiele, Felix Divo, Guillaume Androz, Chester Holtz, Marie Payne, Roman Yurchak, Marc Ru\u00dfwurm, Kushal Kolar, Eli Woods. Tslearn, A Machine Learning Toolkit for Time Series Data. JMLR 2020.\n- Zhengzheng Xing, Jian Pei, Philip S. Yu. Early Prediction on Time Series: A Nearest Neighbor Approach. IJCAI 2009.\n- Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, Dina Katabi. Delving into Deep Imbalanced Regression. ICML 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** The paper is mostly clear and easy to follow. Note that I found Figure 2 somewhat difficult to follow (see weakness point #2), and there are some typos that should be fixed (see weakness point #7).\n\n**Quality/novelty.** The paper isn't particularly novel (see weakness point #1), which detracts from the significance of the work. Meanwhile, I have concerns about how much benefit there is, practically speaking, of the proposed method (see weakness point #5). Moreover, I think there aren't enough baselines considered (see weakness point #6).\n\n**Reproducibility.** The authors have provided code. I have not carefully looked at it though.",
            "summary_of_the_review": "Overall, I find this paper to be incremental and it's unclear to me how practically significant the improvements are of the proposed method vs the baselines evaluated. Furthermore, I think that there simply aren't enough baselines considered.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper861/Reviewer_JLK5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper861/Reviewer_JLK5"
        ]
    },
    {
        "id": "SHEXiXd513",
        "original": null,
        "number": 2,
        "cdate": 1666666205163,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666205163,
        "tmdate": 1666666205163,
        "tddate": null,
        "forum": "miyZxvBxdoP",
        "replyto": "miyZxvBxdoP",
        "invitation": "ICLR.cc/2023/Conference/Paper861/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors studied the problem of improving model predictions of adverse clinical events by using a novel regularization scheme on the target labels. The main novelty lies in adapting the classical Label Smoothing technique to be temporally aware and empirical results have been presented to justify the claim of effectiveness of the method. \n",
            "strength_and_weaknesses": "Some of the key strengths of the paper are as follows;\n\n- The authors study a clinically important problem. The proposed mechanism is simple and a natural extension to classical techniques. Furthermore, being a model agnostic regularization scheme, the proposed solution can have a significant impact on medical AI problems.\n- The results at a high level is promising across 2 tasks. The authors have also provided some deliberation on when the method may not be satiable\n- Figure 5 and the associated analysis is particularly interesting. The insights about the negative weighting of re-weighting samples has the potential to impact future research\n\nThe paper may need to address the following aspects\n\n- First, the presentation of the paper makes it less comprehensible and hard to follow. Figures have been presented without properly marking the x axis (e.g Figure 4 - what does each of the ticks around x-axis represent?). The method also lacks clarity. The authors may want to improve the method presentation and use a glossary to help the readers follow the proposed notations. \n- A somewhat related criticism around the presentation can be identified in understanding the effect of the label smoothing technique (for instance Figure 2 is missing x-tick annotations as well). It seems from the illustrations that the regularization technique rewards the model to learn the near horizon data points better. If this understanding is correct, the clinical significance of the model can be debatable. For instance, predictions for certain tasks such as decompensation a few time points from actual event is clinical irrelevant as the actionability of such predictions is low. \n- This connects to the third criticism around clinical impact of the work - while the authors have claimed that clinically relevant metrics (e.g in Figure 7) is in scope, there is no sub-group level analysis to make sure the model is not unduly decreasing performance across certain sub-groups. The cutoff criteria for AU-PRC evaluation also seems arbitrary - if this was selected under the guidance of clinicians/practicioners, it should be reported.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper solves an important problem and proposes a novel extension of classical method to solve it. However, the presentation and clarity of the method needs to be improved. The impact of the solution is also debatable (which arguably could also have been impaired by the presentation). \n",
            "summary_of_the_review": "Overall, the authors have proposed an interesting and simple solution to handle multi-horizon forecasts, especially for EHR data. While the presented results are interesting, the clinical meaningfulness of the experiments is not well justified. Some other aspects that may need to be addressed are as below\n\n- Section 4.3, the reported method of providing uncertainty around model predictions is arguably measuring the training stability. There are other and arguably important forms of uncertainty that typically plagues EHR data (such as data uncertainty due to selection bias and model uncertainty due to over-specification). It may be useful for the authors to justify what form of uncertainty are they reporting and how to interpret the results for model usage\n- Section 5.1, below Table 2, the authors claim that their method is 'statistically superior' - this is a vague term. They may consider reporting on the 'statistical significance' of the results\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No sub-group level analysis has been presented. The proposed schema, if used in practice, can have unintended effects of amplifying algorithmic bias by preferential selection of samples\n",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper861/Reviewer_kP8w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper861/Reviewer_kP8w"
        ]
    },
    {
        "id": "2UtYXu3Jl-w",
        "original": null,
        "number": 3,
        "cdate": 1666682098771,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682098771,
        "tmdate": 1666683898748,
        "tddate": null,
        "forum": "miyZxvBxdoP",
        "replyto": "miyZxvBxdoP",
        "invitation": "ICLR.cc/2023/Conference/Paper861/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Motivated to reduce model confidence with stronger smoothing at the class boundary, this paper proposed to Temporal Label Smoothing, for early prediciton of adverse event. Simple form comparison with existing methods and experiments using three ICU datasets are presented. It is also proved that stepwise temporal label smoothing is equivalent to Multi-horizon prediciton. ",
            "strength_and_weaknesses": "This paper focuses on the existing practical issue of adverse event (AE) prediciton to propose temporal label smoothing. Detailed backgroud review and ample exploration of performance under multiple existing prediction methods and smoothing methods. \n\nIt's nice that the author compared not only AUPRC but also Recall. \n\nThis reviewer is wondering how the repeated AEs were presetned in the HiRID dataset and did the author pre-process the data or train the data to add a specific feature indicating first/repeated/worsen/relieved/... AE, and if such effort can help improve the performace, especially for the with frequent repeated AEs scenario, under which the proposed method isn't significant compared to existing methods.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "This is a nicely written paper. The notaions used in this paper is clear and the reference to the appendix etc present. Occational, the notaion shows up before first defination like \\alpha^{exp} show in Figure 3a before defining in equaiton (5), Table 1 refers to A3 which is clear while still may not make too much sense to reader who're not so familar with this topic first time. \n\nThe idea of smoothing at the boundary is old in general yet new for this specific topic. The implementation of this smoothing did help improve the performance in two of the three adopted datasets, which are with less repeated AEs. \n\nThe smoothing agothrim provided and the adopted GRU/transformer combination looks replicable but I haven't tried to reproduce. ",
            "summary_of_the_review": "This paper proposes a smoothed version of regulaization called temporal label smoothing to improve boundary performace. The idea is nice for clinic practise and shown to be with better performace with certain clinic datasets with AEs repeatation rate not so high. \n\nThe presentation and idea is nice, though the final performance can be improved. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Other reasons (please specify below)"
            ],
            "details_of_ethics_concerns": "Found this under review paper with author names listed under \nhttps://arxiv.org/abs/2208.13764\nhttps://deepai.org/publication/temporal-label-smoothing-for-early-prediction-of-adverse-events",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper861/Reviewer_zja8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper861/Reviewer_zja8"
        ]
    }
]