[
    {
        "id": "IqTX-bBJCO",
        "original": null,
        "number": 1,
        "cdate": 1666577139292,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577139292,
        "tmdate": 1666660289150,
        "tddate": null,
        "forum": "ufCQZeAMZzf",
        "replyto": "ufCQZeAMZzf",
        "invitation": "ICLR.cc/2023/Conference/Paper1618/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a post-processing to the LINKX with the low-rank constraint on the adjacency matrix. Then, it employs softimpute alternating least square to reduce the complexity. Finally, it bridges the connection between the proposed methods and subspace clustering based on low-rank recovery. Experimental evaluations verify its superiority.\n",
            "strength_and_weaknesses": "Strength\n- The motivation of low-rank on adjacency matrix makes sense.\n- The experimental evaluations are sufficient.\n- The connection between subspace learning based on LRR and the proposed method is interesting.\n\nWeaknesses\n- The novelty of this paper is limited.  The low-rank constraint on adjacency matrix is not novel, such as [1]. This paper just employs the softimpute alternating least square to speedup the computation. The construction of \\tilde{A} at the beginning of page 5 is not novel yet. This strategy has been proposed in dealing networks with heterophily, such as [2].\n- The organization is redundant.\n\n[1] Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, Jiliang Tang: Graph Structure Learning for Robust Graph Neural Networks. KDD 2020: 66-74\n\n[2] Jiong Zhu, Ryan A. Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K. Ahmed, Danai Koutra: Graph Neural Networks with Heterophily. AAAI 2021: 11168-11176",
            "clarity,_quality,_novelty_and_reproducibility": "- The clarity and reproducibility are good.\n- The novelty and the originality are weak.",
            "summary_of_the_review": "My main concern is the limited novelty as shown in weakness.\f",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_TShN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_TShN"
        ]
    },
    {
        "id": "ZQ-GpT89sy",
        "original": null,
        "number": 2,
        "cdate": 1666593716028,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593716028,
        "tmdate": 1666593716028,
        "tddate": null,
        "forum": "ufCQZeAMZzf",
        "replyto": "ufCQZeAMZzf",
        "invitation": "ICLR.cc/2023/Conference/Paper1618/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a low-rank matrix to approximate the coefficient matrix which describes the aggregations of neighborhood information globally. The paper designed a new coefficient matrix with the form of a low rank matrix $UV^t$ which is the solution of the minimization problem inspired by the subspace clustering problem. Furthermore, author proposes a semi-supervised pseudo label generation process as well as matrix initialization step using classic neural approaches on graphs. To solve this matrix, author proposes a novel alternating update algorithms based on softimpute and proves its correctness. The proposed solution achieves results on real-world datasets comparable to other state of the art models and consistently outperforms other methods on synthetic datasets.",
            "strength_and_weaknesses": "Strength:\n1) The paper connects the representation learning on the graph with heterophily and the signed networks. This connection has not been explored by previous literatures and might provide more insights of the learned representations.\n2) The motivations and designs of the algorithms are articulated clearly with both theoretical derivations and numerical simulations.\n3) The authors conduct extensive experiments to verify the effectiveness of the algorithm and provides ablation study and diagnostic plots to verify their modeling assumptions.\n\nWeaknesses:\n1) Although novel, the connection between signed networks and the modeling target is not clear. And thus, the motivation of assuming low-rank approximation needs further elaborations. \n2) The graphs used in the experiments are not large. Does this proposed solution scale to graphs with hundreds of thousands of nodes?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper describes the proposed algorithm with great clarity and the algorithm itself is novel as it is based on a novel interpretation of the coefficient matrix.\n\nBut still, there are few issues that prevent me from understanding this paper:\n1) The paper claims \"signed graph are naturally generalized c-weakly ... task with c classes.\" After reading the paper, I still find it confusing. Are the edges here defined as whether two nodes belong to the same classes? If so, then it is trivial. How does this justify the low rank assumption of the coefficient matrix?\n2) The derivation of the formula (19) is based on the approximation of the (18). I think the approximation step should be provided and an analysis of the approximation error is also quite helpful. Dropping the nuclear norm term could have non-trivial impacts to the final solutions.\n3) The objective for the GloGNN is different from the paper which uses k-hop $A_{gcn}$.\n",
            "summary_of_the_review": "This paper proposed a novel solution using low-rank matrix to the problem of GNN learning on graph with heterophily. This paper is in general well written and provide a new perspective. However, the experimentation results are not very strong and the scalability of the solution is not verified. Besides, although the author mentions the connection between signed networks and the heterophilous graphs, it is not clear to me whether there is non-trivial connection. Considering this is the core concept and motivation, I am currently giving a reject but I am willing to raise my score if the authors could provide additional explanations.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_Yww3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_Yww3"
        ]
    },
    {
        "id": "5jvvaXbILeZ",
        "original": null,
        "number": 3,
        "cdate": 1666676495657,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666676495657,
        "tmdate": 1667438902772,
        "tddate": null,
        "forum": "ufCQZeAMZzf",
        "replyto": "ufCQZeAMZzf",
        "invitation": "ICLR.cc/2023/Conference/Paper1618/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes Low-Rank Graph Neural Network (LWGNN), which enhances GNNs by utilizing low-rank approximation to recover the underlying fully-connected matrix Z. In the matrix Z, a positive Z[i,j] means that node j and node i belong to the same class, and a larger value of Z[i,j] means that node j has more influence on node i and vice versa. By using Z as the propagation matrix, LWGNN achieves good performance on node classification tasks of heterophilic graphs. \n\nThe motivation for the low-rank representation comes from the weak balance theory in Signed Social Networks, which leads to a low-rank property of the underlying fully connected signed graph obtained from the classes of each node. Thus, the authors represent Z as the product of two low-rank matrices U and V. For each layer, the authors obtain U, V by (1). reasonable optimization objectives (Equation 7) with closed-form solutions (Equation 9-12), i.e. softImpute-ALS algorithm; (2). carefully designed initialization (Equation 14); and (3). pseudo-labeling (Equation 8) to fulfill the objective function.\n\nThis paper is an extension to GloGNN [1] in that they both require solving the propagation matrix Z in each layer, and using it for propagation. The main differences between LWGNN and GloGNN are: 1) LWGNN makes explicit use of low-rank matrix and low-rank approximation, while GloGNN only implicitly uses low-rank matrices for computing acceleration; 2) LWGNN draws the Z close to the signed adjacency matrix A, while GloGNN does not utilize the signs. \n",
            "strength_and_weaknesses": "Strengths:\n\nS1: The paper has a clear motivation for explicitly exploiting the low-rank property of the signed social graph. \n\nS2: This paper achieves good performance on node classification tasks of heterophilic graphs.\n\nS3: Figure 3 shows that, as the operating rank of U and V increases, the recovery error for signed matrix first decreases, and then increases, which is consistent with the weak balance theory.\n\nS4: LWGNN inherits the satisfactory time complexity from GloGNN. The authors prove that the time complexity of the forward propagation process is linear to the edge number, which is commendable considering that the process of finding the closed-form solution involves the computation of dense matrix multiplication and inversion. \n\nWeaknesses:\n\nW1: The model largely inherits GloGNN in each component, which limits the contribution of this work. \n\nW2: Many practices in this paper are borrowed elsewhere without a clear claim, e.g.,\n- Equation (5), MLP(A) in H^{(0)} is similar to the approach in LINKX;\n- Equation (6), the initial residual connection is similar to APPNP;\n- The first term (propagation term) in Equation (7) is from GloGNN.\nThese are all powerful submodules. The paper should indicate the source of the design ideas. Also, ablation experiments for these modules are encouraged.\n\nW3: Due to the integration of several modules, it is not clear if the utility of signs is crucial for performance gain. The \\tilde{A} in Equation 7 (i.e., the set of edge signs with pseudo labels) should be replaced by the vanilla adjacency matrix A to verify that the supervision of edge sign plays a role. Note that the ablation model is not the same as GloGNN.\n\nW4: Still, due to the integration of several modules, the model has more hyperparameters. For example, \\mu from the use of MLP(A), \\delta from the use of pseudo-labeling, which may lead to a decrease in the usefulness of the model. \n\nW5: The proof in Appendix 1 seems to be incomplete.\n\nW6: Despite S4, the paper is only experimental on smaller (N<20,000). Thus, experiments on the arxiv-ogbn dataset or some LINKX datasets to highlight S3 might be beneficial. \n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is overall friendly to readers. \n- Quality and Novelty: The work's motivation is clear, but it is largely incremental compared to previous work.\n- Reproducibility: The code is released.\n",
            "summary_of_the_review": "The work is novel in motivation and good in performance. However, it is largely built on existing work, and it\u2019s not very clear which components its power gains from. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_4e9z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_4e9z"
        ]
    },
    {
        "id": "vMSZMlV-hTI",
        "original": null,
        "number": 4,
        "cdate": 1666776866564,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666776866564,
        "tmdate": 1666830626207,
        "tddate": null,
        "forum": "ufCQZeAMZzf",
        "replyto": "ufCQZeAMZzf",
        "invitation": "ICLR.cc/2023/Conference/Paper1618/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new GNN architecture inspired by a model of homophily and heterophily in social networks. Nodes with similar features are modeled with a positive edge, while nodes with different features are modeled with a negative edge. The paper notices that the weak balance theory for networks naturally applies in the setting of GNNs, since the nodes can be grouped according to which class they belong to. Using existing theory of weakly balanced networks being of low rank, the paper uses a GNN model which explicitly tries to compute a low-rank signed coefficient matrix for node aggregation. This architecture is evaluated for several node classification tasks and compared to existing GNNs.",
            "strength_and_weaknesses": "Strengths\n-\n\n- The paper draws from well-established theory on low-rank matrix factorizations and signed networks. It is able to adapt an existing ALS algorithm to a new case using a surrogate loss term, which it justifies using a bound. There is a nice discussion of computational complexity and methods to speed up the optimization.\n- LRGNNs significantly outperform other types of GNNs empirically on the heterophilic datasets, especially Squirrel.\n- The experiments are comprehensive and provide good intuition as to why LRGNNs are able to perform well. Adding node-wise independent noise to each of the feature vectors hurts most GNNs, but LRGNNs are robust to this.\n\nWeaknesses\n-\n\n- All of the datasets used seem to rely only on short-range interactions; this is evidenced by each GNN only using one layer for each of the datasets. This brings up the question of how much the graph structure is actually being used. How would LRGNNs compare in the cases where deeper GNNs are necessary?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. It presents a novel GNN type which takes a different approach from existing convolutional architectures.",
            "summary_of_the_review": "I believe that the contributions of the paper are significant and are able to handle heterophily well, which other GNNs have struggled with.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_aB3d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1618/Reviewer_aB3d"
        ]
    }
]