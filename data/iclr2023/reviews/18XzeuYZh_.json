[
    {
        "id": "ZzxlSDt4p4",
        "original": null,
        "number": 1,
        "cdate": 1666532600235,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666532600235,
        "tmdate": 1669936093711,
        "tddate": null,
        "forum": "18XzeuYZh_",
        "replyto": "18XzeuYZh_",
        "invitation": "ICLR.cc/2023/Conference/Paper6379/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for correcting bias of continual learning method using experience replay. The proposed method uses a memory from past examples to train the last layer of a neural network trained by an experience-replay-based method. This prevents the model from being biased to recently observed samples. By fixing layers other than the last, it also prevents overfitting to the chosen samples from the memory. The authors show that the proposed method indeed reduces the bias and improves the overall performance.",
            "strength_and_weaknesses": "# Strengths\n- The paper points out an important weakness of experience replay that seems relevant to the research of continual learning.\n- The proposed method is simple and widely applicable without big implementation or computational overhead.\n- The experiments consistently show its effectiveness.\n\n# Weaknesses\n- The problem setup on the mathematical level is not clear to me. The paper says that it does not assume strong assumptions, but without any assumptions on how the distribution can change, I don't think we can say much about the learnability. One possible direction may be considering some form of cumulative regret as in online learning, but the paper does not seem to be considering such a setup either.\n- The setups of the experiments are also not clear to me. How the samples are drawn in the stream from the dataset (e.g., gradually including new classes) seems important, but I could not find any part mentioning that.\n- I could not understand how the proposed method makes the right amount of bias correction. If the effect is too strong, it can be biased in the opposite way, to the past experience side.\n- The measure of the \"bias\" is misleading because it does not quantify the bias in the sense of the standard statistics. (The expectation is not taken over all possible draws of the training samples.) It is also a quite weak measure because it averages over the samples.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to read, but the technical part can be improved. At least, I would like to see the problem formally defined especially around how the data are generated and how the learned model is evaluated. As I mentioned, the setups of the experiments are not clear to me, and it may be difficult to reproduce them.",
            "summary_of_the_review": "Although the work is well-motivated, the paper is easy to read, and the experiments show the effectiveness of the proposed method, some important details are not clear, and the theoretical part might have a weakness. Also, there is no evidence that the proposed method really corrects the bias theoretically or even empirically because the measure of the bias does not seem to capture the bias that the authors are trying to mitigate. I vote for weak reject.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_cbbB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_cbbB"
        ]
    },
    {
        "id": "QSNuckm80R",
        "original": null,
        "number": 2,
        "cdate": 1666649648711,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649648711,
        "tmdate": 1669795431711,
        "tddate": null,
        "forum": "18XzeuYZh_",
        "replyto": "18XzeuYZh_",
        "invitation": "ICLR.cc/2023/Conference/Paper6379/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses the problem of recency bias in the task-free continual learning setup. It proposes a new metric to quantify prediction bias and a method to mitigate it through adjusting parameters of the final model layer post training. The authors then propose a online procedure for training and unbiasing the model over the data stream via an experience replay mechanism. They test the performance of the algorithm over multiple datasets comparing favourable to several baselines.",
            "strength_and_weaknesses": "Strength:\nThe paper looks into the very important problem of continual learning. It is very readable and easy to follow.\n\nWeaknesses:\nThe paper lacks on clarity and quality at several major points. These are concretely listed in the next section. It is also of limited novelty - also clarified in the following section.",
            "clarity,_quality,_novelty_and_reproducibility": "There are many points, where the paper is not sufficiently clear.\n- It is not clear, how the task-free setup is instantiated in the theoretical discussion and in the experiments. It argues that in the task-free setup, no strong assumptions are made about the non-stationarity over the stream (neither task nor class incremental). What is the source of the unseen data here? Some future data coming after the last observation in the current stream? Or are these some examples generated in parallel with the whole stream (and therefore tracing the entire history of the distribution shifts)? Are the classes assumed to be stable or can they possibly change as well? Can there be more/less classes, Can these change in nature? Similarly, how is the experimental data organized for the continual setup with distribution shifts? Are these organized into binary or 10-wise tasks (as common in the task and or class incremental setup) without indicating this to the model? Or is the data randomly mixed? Where, how is the distribution shift happening? How is the test set constructed?\n- In section 2.2 you claim that the larger the stream, the larger the memory will be. Why \"will\" it be? Or do you mean to say it \"shall\" be larger? You further claim to investigate algorithms with computation cost O(n) independent of m. Isn't the memory itself a function of n? Why would the cost be ever O(mn)?\n- In the experimental section, accuracy, bias and information retention are reported. Is accuracy and bias calculated over test set? How is the test set constructed with respect to the shifting distribution in the stream? Is the av IR equivalent to accuracy over the train set (= the whole stream)? If not, how is it different?\n\nI believe the ideas are also not particularly novel\n- the hierarchical view of NNs as a feature extractor with a follow up classifier has been introduced previously for example in the works of Naftali Thisby and his group.\n- So was the need to weight unequally the current and replay observations to compensate for the oversampling of current distribution (e.g. Ramapuram et al., Lifelong generative modeling, 2020)\n\nThere are some further clarity or quality issues\n- in section 3.3. the prediction bias quantification is outlined. The prior class probabilities are defined as expectations over the one-hot class encodings. The expectation is taken with respect to what distribution. The notation suggests that the output p is again a class-long vector, is that so? The same goes for q as expectation of the classification outputs. What is the distribution used in this expectation?\n- JS is suggested as symmetric divergence. Why the need for JS? What would be wrong with KL and using the prior for the weighting?\n- section 4.2 you claim \"we can essentially compare the quality of the representations that their feature extractor learns\". How can you compare these?\n- section 4.4. \"the computational graph in the left part of Figure 1 flows from the feature extractor to the classifier, but the classifier is not updated with the resulting gradients\". What do you mean? That in this setup you do not train the classifier? Or did you mean to say the feature extractor? \n\nReproducibility is limited:\n- Authors do not indicate, if the code is anywhere available\n- How are the expectations in 3.3 calculated?\n\nMore general question - you seem to be training the classifier and the surrogate classifier in a completely disconnected manner (no sharing of parameters or parameter passing, etc.). Isn't this eventually going to lead into a complete divergence between the two classifier models with which the feature extractor is unlikely to be able to cope?\n",
            "summary_of_the_review": "The topic of the paper - continual learning - is an important one and novel methods in this area would be of great interest to the community. However, I find the current paper lacking significantly in clarity, quality and novelty to be recommendable for publication at ICLR. I therefore recommend rejection from the conference.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_yCcF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_yCcF"
        ]
    },
    {
        "id": "Y4JHTBvU6P_",
        "original": null,
        "number": 3,
        "cdate": 1666666222583,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666222583,
        "tmdate": 1666666222583,
        "tddate": null,
        "forum": "18XzeuYZh_",
        "replyto": "18XzeuYZh_",
        "invitation": "ICLR.cc/2023/Conference/Paper6379/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper focuses on online bias correction during task-free continual learning. The paper first shows, both theoretically and empirically, why simple experience replay biases on the results of the recent stream observation. Second, the paper introduces the metric to quantify prediction biases. Using the observation from this, the paper proposes a simple approach called Online Bias Correction which appropriately modifies the final layer of the network to correct for the biases online. Finally, the paper concludes with extensive experimentation of the OBC showing significant improvement on a number of task-free continual learning methods on multiple datasets.",
            "strength_and_weaknesses": "Strengths:\n1. Online task-free continual learning has recently drawn more attention because it focuses on solving practical challenges. The direction of this paper is promising as it focuses on correcting the bias incurred during training, addressing a major problem in this area.\n2. The claim of correcting the prediction bias by changing the way the classifier is trained is well supported by extensive experimentation of various methods on a good amount of datasets.\n3. The proposed method, Online Bias Correction, is simple but very effective. Also, it acts as a wrapper around other task-free continual learning methods. The main advantage of this is that it can be applied to existing methods without any major change in existing architecture and training procedure.\n4. The paper also includes the ablation study on surrogate classifier which was introduced by the proposed method. Its effectiveness is well supported by extensive experimentation.\n\nWeaknesses:\n1. Even though the paper has used a variety of datasets, many recent papers in this area also use CORe50 [1]. I believe that it would strengthen the experiments and would make it easier to compare against some other work.\n2. In section 3.2, the explanation on data sampling bias is unclear. First, they state that past and future observations have contributed equally. Then it is changed to not contributing equally, making it confusing. I believe that a clear mathematical definition would likely remove the confusion.\n3. Main concern of the method is that it is a wrapper over the existing methods which makes it dependent on them and also might not guarantee effectiveness on the methods outside the ones used in the experiments.\n4. Table 1 includes a column called \u201cBias\u201d. Is this the result of the Jensen-Shannon divergence? \n\n[1] Lomonaco, Vincenzo, and Davide Maltoni. \"Core50: a new dataset and benchmark for continuous object recognition.\" Conference on Robot Learning. PMLR, 2017.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to read and follow. The ideas in the paper are clear and presented in a coherent manner. The contribution seems to be novel. The authors have pledged to make the source code public upon acceptance for reproducibility.",
            "summary_of_the_review": "The paper focuses on a problem that is underexplored. The ideas presented are novel. The contribution is significant in the area of Bias correction, especially in online settings of task-free continuous learning. Even though the proposed method is a  wrapper around the existing methods, I think it is a significant and valuable contribution in this area as it is also evident from the rich set of results included.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_S1Ps"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_S1Ps"
        ]
    },
    {
        "id": "EZUZXKUDNiT",
        "original": null,
        "number": 4,
        "cdate": 1666711960597,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666711960597,
        "tmdate": 1670432090385,
        "tddate": null,
        "forum": "18XzeuYZh_",
        "replyto": "18XzeuYZh_",
        "invitation": "ICLR.cc/2023/Conference/Paper6379/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Paper proposes a method to correct a recency bias in replay-based task-free continual learning, but separately optimising the final connected layer  of network from the rest of the network. Focuses on continual learning in vision with evaluations in the area.",
            "strength_and_weaknesses": "Strengths\n- A very simple but highly effective method for bias correction in task-free continual learning\n- Ablates the effect of various components (e.g. utility of surrogate classifier).\n- Well written paper with decent set of evaluations in the vision space.\n- Good comparison to baselines and shows particularly good performance with respect to the bias metric proposed, and another metric proposed by Cai et al (2021).\n\nWeaknesses\n- Lack of understanding into why various components work despite ablations. This makes it difficult to find as much value in the paper, given the focus on toy datasets. Concretely, in section 4.5 it details why a surrogate classifier is necessary. However, there is no exposition on why surrogate classifier is necessary. There is a reference to gradient flow and figure 1 but nothing beyond that.\n\nMinor Comments & Questions\n- Provide a name for the bias metric, and then use that name in the tables\n- Highlight performance of OBC in tables.",
            "clarity,_quality,_novelty_and_reproducibility": "Clear and should be easily easy to reproduce given the simplicity.",
            "summary_of_the_review": "A simple method to mitigate the effect of the recency bias in task-free continual learning. Well written paper. Accept.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_zZ8e"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6379/Reviewer_zZ8e"
        ]
    }
]