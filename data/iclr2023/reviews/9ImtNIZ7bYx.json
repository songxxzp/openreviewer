[
    {
        "id": "dQSIe80N6Bj",
        "original": null,
        "number": 1,
        "cdate": 1666425992662,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666425992662,
        "tmdate": 1666425992662,
        "tddate": null,
        "forum": "9ImtNIZ7bYx",
        "replyto": "9ImtNIZ7bYx",
        "invitation": "ICLR.cc/2023/Conference/Paper2561/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors suggest an unsupervised method for semantically meaningful perturbations of the learned latent W in GAN models such as StyleGAN. They propose to find a global basis called Frechet basis. The basis is discover in two steps: 1. The global semantic subspace is discovered by the Frechet mean in the Grassmannian manifold of the local semantic subspaces. 2.  Frechet basis is found by optimizing a basis of the semantic \u00b4subspace via the Frechet mean in the Special Orthogonal Group. Additionally, the authors suggest a refinement scheme for previous methods.",
            "strength_and_weaknesses": "## Strength\nResults are very good visually compared to the GANSpace method which already gives very good results. The quantitative results are also superior to next best GANSpace. The paper is written in a clear and high quality fashion. The paper suggest nice mathematical insight on the GANs latent space decomposition and semantic structure. The mathematical formulations also are being backed up with the qualitative and qualitative results.\n\n## Weaknesses\nThe paper is mathematically heavy where it is hard to follow (for me) on this translates the latent W (for example the 2D several layers and resolutions latent of StyleGAN2). I would have like to see more comparisons to a supervised method to understand the gap between the supervised and unsupervised methods.",
            "clarity,_quality,_novelty_and_reproducibility": "This seems to be a high quality paper. The authors did not clarify if they intend to release code and/or models. The authors improve upon previous work but present nice mathematical analysis backed up by good results.",
            "summary_of_the_review": "I believe this paper is important to the community and advances the understanding of the semantic meaning of the GANs latent space.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "no ethics concerns ",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_G2MK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_G2MK"
        ]
    },
    {
        "id": "lEt5pFkBFc",
        "original": null,
        "number": 2,
        "cdate": 1666623667252,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623667252,
        "tmdate": 1669265053749,
        "tddate": null,
        "forum": "9ImtNIZ7bYx",
        "replyto": "9ImtNIZ7bYx",
        "invitation": "ICLR.cc/2023/Conference/Paper2561/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a method to disentangle the semantic space in a GAN model by using Frechet means. The pipeline has two steps. First, the semantic subspace is constructed by the Frechet mean in the Grassmannian manifold of the intrinsic tangent spaces. Then, the Frechet basis of the semantic subspace is constructed by using Frechet mean in the Special Orthogonal Group. The experimental results show that the proposed method produces better semantic factorization than the previous methods. ",
            "strength_and_weaknesses": "** Strength **\n\n- The paper presents a generalization of the intrinsic local tangents introduced by Choi et al. (2022a) by averaging the semantic subspaces. This is an interesting extension with solid theoretical support. \n\n\n** Weakness ** \n\n1) The comparison against unsupervised global basis methods is not sufficient. Since this method is built upon Choi et al. 2022a, I think additional discussions and result comparisons with Choi et al. are needed despite it is a local method. By taking the mean of the local subspaces to discover global directions, does this lead to improvement or similar results?\n\n2) There are not sufficient qualitative results in both the paper and the appendix. Figure 3 only shows the change of two attributes, and it is unclear how the method works for other attributes. \n\n3) Results on additional datasets should be provided too, e.g., LSUN bedroom, cars, etc.\n\n4) More analysis on the factorization of different attributes should be added. For example, consider common attributes such as pose, age, smile, eye gaze, wearing glass, etc., with the proposed unsupervised factorization, how these attributes are disentangled in the discovered global directions? Computing some correlations between these attributes might help. \n\n4) Regarding robustness (Figure 5), it can be seen that Frechet means is not always better. Did the authors have any insight into when we can use GANspace and when to use Frechet means? ",
            "clarity,_quality,_novelty_and_reproducibility": "- It is a bit unclear to me how global semantic directions as in the proposed method compare to local directions, and which one should be preferred in which situations. Explaining this could strengthen the motivation of the method. \n\n- Figure 4, 5, 6: the X-axis represents discrete values, so I do not see why a line plot is used here. The connection between two consecutive X values is not meaningful. ",
            "summary_of_the_review": "The paper presents an interesting and technically solid method to enable global semantic factorization of the latent space in GAN models, but the experiments are insufficient to justify the usefulness of the method. Given the current scale of the experiments and the quality of the results, the paper might need another cycle for major revision. I therefore lean toward a clear rejection. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_hbhj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_hbhj"
        ]
    },
    {
        "id": "iFxBLTN8iuh",
        "original": null,
        "number": 3,
        "cdate": 1666642525761,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666642525761,
        "tmdate": 1668761838293,
        "tddate": null,
        "forum": "9ImtNIZ7bYx",
        "replyto": "9ImtNIZ7bYx",
        "invitation": "ICLR.cc/2023/Conference/Paper2561/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a way to find global semantic representation in GAN. It is based on looking for an average subspace among the tangent spaces in some layer of the generator. This subspace is then used to generate semantically factorized images in experiments, with both quantitative and qualitative results.",
            "strength_and_weaknesses": "The paper shows that the Frechet basis can achieve better semantic factorization compared to stat-of-the-arts. The paper is well written, and the results are solid. \n- I am just not sure on how the results in Section 4 change when one uses a different set of layers in the considered GAN, in particular how it depends on the size of each layers, and the nature of each layer (e.g. convolutional or fully connected). Could you provide more discussions in Section 4.1 or later?",
            "clarity,_quality,_novelty_and_reproducibility": "What is the n in eq. 1, and section 3.1.1? Is it d_W or the number of samples from Z? Do you consider the case where the number of samples of Z goes to infinity? What does the mu <= in eq. 11 stand for? ",
            "summary_of_the_review": "Rev: I would remain my score 6 as it would have been better to include the details of i.i.d. sampling in the evaluation of FID scores. As the problem has no uniqueness solution, I find that the impact of the results remains limited. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "na",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_McwQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_McwQ"
        ]
    },
    {
        "id": "r2tlgDU0PS",
        "original": null,
        "number": 4,
        "cdate": 1666682916485,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682916485,
        "tmdate": 1670466406022,
        "tddate": null,
        "forum": "9ImtNIZ7bYx",
        "replyto": "9ImtNIZ7bYx",
        "invitation": "ICLR.cc/2023/Conference/Paper2561/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an unsupervised way to find the global semantic perturbations in a latent space in GAN, named Frechet Basis. Specifically, it is found by using Frechet mean to the local semantic perturbations. Experiments show that the proposed basis can provide better semantics and robustness than the previous unsupervised global methods. The paper also introduces a basis refinement scheme that can refine prior works by running the basis refinement on their subspaces.",
            "strength_and_weaknesses": "### Strength\n* The paper is well-written and easy to follow. Moreover, the paper provides a thorough background introduction and related prior works.\n* The motivation is clear, and the intuition behind the proposed method is straightforward. Interpreting the global semantic variation as the mean of the local semantic variations seems simple but effective.\n* The experiment results seem promising. The proposed method appears effective and provides better semantic factorization and robustness.\n\n### Weaknesses\n* I have some concerns about the design choices in the proposed method. I feel more analysis should be conducted. For example, there are plenty of ways to find the mean of subspaces; why would Frechet mean be the best choice? It would be better to provide an ablation study on such a design.\n* The refinement improvement on GANSpace seems limited. While the refinement on SeFa leads to a near Frechet basis performance. Is there any justification or explanation for the such result?",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nIn general, the paper is well-written with sufficient technical details. \n### Novelty\nThe proposed method seems to have incremental novelty.\n### Reproducibility\nCodes are provided in the supplementary materials. However, I'm unsure whether it is sufficient to reproduce all the experiments in the paper based on current information.",
            "summary_of_the_review": "In general, the paper proposes a straightforward solution for an important problem. However, the experiments seem limited. I am willing to raise my recommendation if more theoretical justification or empirical study are provided.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_toHN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2561/Reviewer_toHN"
        ]
    }
]