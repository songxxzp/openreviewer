[
    {
        "id": "4j6KKCvalW",
        "original": null,
        "number": 1,
        "cdate": 1665959860090,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665959860090,
        "tmdate": 1670021170867,
        "tddate": null,
        "forum": "bvgHBkSBdcj",
        "replyto": "bvgHBkSBdcj",
        "invitation": "ICLR.cc/2023/Conference/Paper5094/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to use coordinate-based networks for time-series data representation. This is done by proposing a new architecture which separates a time series into a trend (low-frequency) and seasonal (high-frequency) component by representing each independently with a set of weights and a SIREN, and then summing them. The method proposes to generalize over these coordinate-based representations of time series data using hypernetwork architectures: one which outputs standard SIREN representations of time series, and one which outputs the modified iSIREN architecture proposed with the decomposition of signal frequencies. The paper demonstrates that this new architecture results in improved time series fitting, and that the hypernetwork architecture places similar time series signals at similar places in the latent space.",
            "strength_and_weaknesses": "In my opinion, the strengths of the paper are:\n- The paper tackles an important problem which is improving the quality of neural signal representations of 1D signals, and generalization across instances of these signals.\n- The paper is written very clearly, and the method is explained well. The figures are very detailed and describe the proposed architecture concisely.\n\nI think that the main weakness of the paper is novelty. Specifically:\n- The iSIREN architecture proposed is a SIREN, but with a factored out low-frequency component. This has already been proposed in [1] (where the output of a coordinate-based network is the sum of two different functions), although a slightly different function implementation is used here for the trend component instead of another low-frequency biased SIREN.\n- The generalization aspect, HyperTime, effectively just uses the SIREN + hypernetwork setup, with the same set-encoder used in the SIREN paper, for generalization. This generalization scheme has already been shown to work for coordinate-based representations of images, so it is not surprising it could also work for 1D signals, considering that the original SIREN paper also fits 1D signals in the form of audio.\n- It seems that the results don\u2019t outperform the standard SIREN by much? Figure 3 shows that SIREN and iSIREN seem to converge similarly, and Table 1 shows that they are much more similar to each other than to any of the other methods. It is difficult to evaluate the relative magnitude of the difference in these numbers. \n- Additionally, I don\u2019t find the baseline comparisons to be fair. There exist other methods for coordinate-based networks (ex: hybrid implict-explicit architectures, SAPE, etc\u2026) which can be used for signal representation and generalization. Simply comparing versus other nonlinearities in the network architecture is not a fair comparison as the SIREN paper already has shown that they simply don\u2019t work for high-frequency signal memorization, so they are not valid baselines to compare to an improvement on SIREN.\n- The generalization visualization in Figure 5 shows that the synthetic and real data distributions match, but the real data distribution doesn\u2019t seem to be clustered. Thus I wonder if the prior learned by this hypernetwork would allow the useful aspects of generalization, such as solving inverse problems for example? In the original SIREN paper, this is used to perform inpainting of images - is something similar done here for time series?\n\n\n[1] Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. Yifan, Wang and Rahmann, Lukas and Sorkine-hornung, Olga. ICLR, 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I find the paper to be exceptionally clear, and the quality of experiments to be relatively high. However, I believe that the novelty of the method is very limited - existing tools from a method were applied to a slight variation of a previous signal type, and it was not compared against state-of-the-art coordinate-based network architectures for signal representation, rather against baselines which have shown to completely fail. The method seems reproducible.",
            "summary_of_the_review": "The paper proposes a method for representing time series data with a coordinate-based network architecture based on SIRENs, and generalizing across these representations with hypernetworks. Overall, I find the method to be described and evaluated well. However, the architecture proposed is heavily based on previous work, and is not compared to other state-of-the-art coordinate-based representation architectures which have emerged for other applications. The generalization aspect is interesting, but is not novel as it is just a drop-in of the method used in SIREN, and is not shown to be useful for a useful application in 1D signal processing, such as solving inverse problems.\n\nPOST REBUTTAL UPDATE: After reading the other reviews and responses, I am not inclined to change my score. I now understand that the purpose of iSIREN is not to improve directly on SIREN, but instead to provide an interpretable breakdown. However, the argument of using two separate SIRENs (as in [1]) requiring an additional hyperparameter is not convincing, as iSIREN also needs to choose the parametric form for one of the networks. While I believe the FFT loss is novel in this context (although it has been used before in imaging applications), I find that the paper still combines a lot of known methods into a new type of data. This is interesting and important for this application domain, but doesn't propose anything new or enable significantly more interpretable function fitting. For this reason, I view the paper as borderline for acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_Wscx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_Wscx"
        ]
    },
    {
        "id": "nfFI_p5VfM",
        "original": null,
        "number": 2,
        "cdate": 1666652782855,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666652782855,
        "tmdate": 1666652782855,
        "tddate": null,
        "forum": "bvgHBkSBdcj",
        "replyto": "bvgHBkSBdcj",
        "invitation": "ICLR.cc/2023/Conference/Paper5094/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present the iSIREN pipeline, designed to accurately reconstruct signals. To do it, they use latent representations of the data set. They also work with metrics in the FFT domain to enforce an even better reconstruction.",
            "strength_and_weaknesses": "Strengths:\n1. I think that enforcing accuracy in the Fourier domain adds powerful constraints that should generate better results.\nWeaknesses:\n1. The f(t) = ftr(t) + fs(t) decomposition introduces a very strong assumption: What happens with non seasonal signals?\n2. Even though the results are good and generally better, the experiments are not conclusive in stating the superiority of the proposed pipeline. This is important because the method is not based on fundamental principles but on common sense ad-hoc decisions. Thus, it is the experiments that should state whether the pipeline is better or not.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear and incrementally original.",
            "summary_of_the_review": "As stated above, the work is incrementally novel. Even though very good results are obtained, it is difficult to assess whether they are general (not many experiments) or conclusive (marginal improvements).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_H1Gq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_H1Gq"
        ]
    },
    {
        "id": "bzX8bjFOwG",
        "original": null,
        "number": 3,
        "cdate": 1666750557191,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666750557191,
        "tmdate": 1670838738477,
        "tddate": null,
        "forum": "bvgHBkSBdcj",
        "replyto": "bvgHBkSBdcj",
        "invitation": "ICLR.cc/2023/Conference/Paper5094/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors propose an implicit neural representations method for time-series data, namely iSIREN. The key different from the original SIREN is that iSIREN has modelled the trend and seasonality explicitly. Then authors show that the parameters of iSIREN can be produced by a hypernetwork (HyperTime or iHyperTime), such that the new generative model can be produced on-the-fly without any training by feeding the time-series data into hypernetwork. The proposed method is demonstrated for reconstruction and generation tasks cross many datasets and surpassing some other baselines. ",
            "strength_and_weaknesses": "* Strength\n\n(i) The work is well written and the motivation of using implicit neural network is appreciated because of lack of the similar work on this direction.\n\n(ii) By separating the trend component from the seasonality, the model has better interpretability. Besides, it also offers a way for trend/seasonality decomposition.\n\n(iii) Hypernet is an interesting angle here, as it saves time from training a new model for incoming data.\n\n* Weakness\n\n(i) The work is largely built-on SIREN and the migrating to time-series data is not challenging, given the flexibility of implicit network itself.\n\n(ii) While the decomposition of tend and seasonality is interesting, it is hard to justify they are the components that are claimed to be, esp. for the case of seasonality, i.e., SIREN can model seasonality (more broadly, periodic pattern) well, but you may not claim that what SIREN has modelled is truly seasonality.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality is good, while novelty is fairly ok. Reproducibility is hard because of missing details, though the underlying models, e.g., SIREN and hypernet are easy to implement. ",
            "summary_of_the_review": "Overall it is a nice paper with a good demonstration of implicit network for time-series data. I may upgrade the score if the seasonality modelling part is further elaborated.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_jVNg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_jVNg"
        ]
    },
    {
        "id": "L3COuOxQhr",
        "original": null,
        "number": 4,
        "cdate": 1666960534669,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666960534669,
        "tmdate": 1666960534669,
        "tddate": null,
        "forum": "bvgHBkSBdcj",
        "replyto": "bvgHBkSBdcj",
        "invitation": "ICLR.cc/2023/Conference/Paper5094/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes, based on SIREN, a new interpretable INR architecture for time series called iSIREN. Building up on that, the paper proposes to use the iSIREN set-up in the context of hypernetworks for time series generating. Both methods differ from its plain counter version (SIREN and SIREN-based hypernetwork) in that it splits the model into a classic time\ntime series additive decomposition, i.e. trend and seasonal component. The paper provides a variety of different experiments showing its superior performance compared to baseline models.",
            "strength_and_weaknesses": "Using a series decomposition for SIREN and SIREN-based hypernetworks in novel up to my knowledge. However, using an additive time series decomposition into trend and seasonal component is one of the most standard approaches in time series analysis. The paper provides many and versatile experiments showing a strong performance of the provided models on many different tasks.\n\nHowever, there are open questions and weaknesses that need to be addressed:\n\n* Is the better performance of iSIREN due to the additive decomposition technique or simply because it uses slightly more parameters than standard SIREN?\n* What are the weaknesses of the provided models, e.g. slower training/inference time and so on?\n* Adding an FFT penalty term to the loss function seems to be a great idea. Is it novel or has it been used in this context already before?\n* No standard deviations are provided. It is not clear if the obtained results are robust.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality of writing needs to be significantly improved. Most parts of the provided formulas are not properly introduced and defined, which makes it very hard to read. For instance almost none of the variables in eq. (5) are defined anywhere in the paper. \nThe novelty is very marginal, as both SIREN and hypernetworks are already established methods as well as using a time series additive decomposition into trend and seasonal components are well established in standard time series analysis.\n\nThe results are not reproducible, as no code is provided. Moreover, no standard deviations are provided for different initializations of the models. Hence, the results are not reproducible.",
            "summary_of_the_review": "The paper introduces iSIREN and a hypernetwork based on iSIREN, which consists of SIREN together with a time series additive decomposition. The novelty is very marginal and the results are not outstanding. Moreover, the results are not reproducible. Finally, major parts of the paper need to be rewritten. Hence I recommend to reject the manuscript in its current form.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_wjaa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5094/Reviewer_wjaa"
        ]
    }
]