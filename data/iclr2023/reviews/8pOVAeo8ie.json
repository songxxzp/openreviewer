[
    {
        "id": "X9JumSQd9D",
        "original": null,
        "number": 1,
        "cdate": 1666039706119,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666039706119,
        "tmdate": 1669231361564,
        "tddate": null,
        "forum": "8pOVAeo8ie",
        "replyto": "8pOVAeo8ie",
        "invitation": "ICLR.cc/2023/Conference/Paper599/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces visual prompt tuning (VPT) methods in long-tailed recognition and proposes a modification to VPT to adapt to long-tailed scenarios with so-called long-tailed prompt tuning (LPT). The method is simple and effective. The results of compared benchmarks show improvements from the proposed LPT method. ",
            "strength_and_weaknesses": "The proposed method is simple yet effective and achieves general improvements over compared baselines in the reported experiments. I think it is a good contribution to the community to introduce prompt tuning to long-tailed recognition because it sparks thinking on how to effectively utilize pre-learned knowledge (pre-trained weights in this case). However, prompt tuning has a prerequisite, a \"pre-trained weights\" or a foundation model, which is not always approachable. And the existence of pre-trained weights shifts the goal of long-tailed methods from \"balanced learning from imbalanced data\" to \"effectively transfer pre-trained knowledge to imbalanced data\". This shift makes evaluating the model's pure recognition and generalization ability harder, and generally changes the setting of long-tail recognition. Although this might not be a bad thing, I think this shift is worth some discussion. Moreover, since the basis of the method is to solve challenges like \"fine-tuning whole model impairs the generalization ability of pre-trained models\", the discussion on why we need to preserve the generalization ability of pre-trained models is necessary.",
            "clarity,_quality,_novelty_and_reproducibility": "I think this paper is clear overall. Some proofreading is needed for some grammar errors. Code is not yet available.",
            "summary_of_the_review": "Overall, I think this paper is good.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper599/Reviewer_q9x4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper599/Reviewer_q9x4"
        ]
    },
    {
        "id": "JpxJtWFtCg",
        "original": null,
        "number": 2,
        "cdate": 1666649626827,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649626827,
        "tmdate": 1669011454226,
        "tddate": null,
        "forum": "8pOVAeo8ie",
        "replyto": "8pOVAeo8ie",
        "invitation": "ICLR.cc/2023/Conference/Paper599/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a method, Long-Tailed Prompt Tuning (LPT), for light-weight finetuning of ViT's in the long-tailed image recognition regime. They identify three key issues with current methods for finetuning for long-tailed recognition:\n\n1. Full finetuning is expensive\n2. Full finetuning reduces generalization performance\n3. Model features are not compatible between different finetuned models, (increased deployment cost?)\n\nLPT attempts to fix these issues by adding a stage to the VPT training procedure, which introduces group (class) specific prompts at intermediate layers of the vision transformer. They claim that this approach makes their model have better:\n\n1. Generalization (evaluated wrt ImageNet-Sketch)\n2. Better performance in the long-tailed regime\n3. Light-weight finetuning",
            "strength_and_weaknesses": "##### Strengths\n\n- Very strong results in the long-tailed regime. In particular, the Places-LT were convincing. The problem of representation learning in long-tailed scenarios is relevant quite broadly, as most natural data sources exhibit long-tailed behavior.\n- Method seems intuitive (e.g. better clustering for class labels). Unclear why this leads to better generalization (see weaknesses), but the results speak for themselves.\n- The method is straightforward to understand but shows creativity, in particular the strategy for integrating the group level prompt-embeddings was interesting.\n\n\n##### Weaknesses\n\n- Would appreciate more generalization results. In particular I would like to see results on all 5 ImageNet distribution shifts in Taori et al. (ImageNet-R, ImageNet-A, ImageNet-Sketch, ImageNet-V2, ObjectNet). Also how do these robustness claims fair when you pretrain on ImageNet-LT?\n- In Section 5.2 (robustness), you should compare with methods which focus on robust finetuning (e.g. [1] and [2] which show good results on CLIP-pretrained backbones). It's known that full-finetuning reduces robustness but there's methods to mitigate those effects for certain classes of pretrained models. Also, does VPT exhibit similar robustness capabilities to your method? Since your LDA experiments show the features remain roughly similar, I would think it does.\n- Would like to see ablation results on adding the group embeddings early vs late in layers, instead of shared prompt -> group. Would also like to see what happens if you just used group embeddings.\n- You claim that \"LPT shares a pretrained model for different learning tasks, and only needs to store the small-sized prompts, largely increasing the model compatibility and reducing practical deployment cost,\" however you don't compare to any multi-task methods. This claim is weak.\n- You also make claims about the parameter efficiency of this method, however that doesn't seem to be the main selling point as you don't compare to any lightweight finetuning methods besides VPT.\n- Would like to see more comparisons with CLIP-pretrained methods on iNaturalist and Places-LT. What is the result when you use your method with a CLIP pretrained backbone? I find CIFAR results to be not convincing in general, would appreciate some clarity at larger scales. \n\n[1] Robust fine-tuning of zero-shot models, Wortsman et al. 2020\n[2] Overcoming Catastrophic Forgetting by Incremental Moment Matching, Lee et al. 2017",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity was good overall but could use some work. In particular, I had to look at ablation tables to see what data the models were pretrained on. This is very important information and should be prominent in the main text (although it's possible I missed it somewhere, please correct me if so).\n\nThe writing quality was good and the paper seems novel. It builds on VPT in a significant way.\n\nThe reproducibility is unclear but appears to be good. The authors have not provided code, and while the paper seems detailed enough to replicate, I have not attempted this.",
            "summary_of_the_review": "**Update post-rebuttal:** With the promised changes to the draft, I update my review to an _accept_ (score of 8). Thank you to the authors for their thoughtful reply and overall effort.\n\n\nMy overall rating is _weak reject_. \n\nThe results in the long-tailed setting looks strong and the method is very interesting, however I don't think they are fleshed out enough yet for acceptance by themselves. In particular, I would like to see experiments in other long-tailed settings (e.g. the iWildCams dataset), and also for all the methods in Table 3 to be replicated in the iNaturalist setting. The multi-task claim does not appear to be fleshed out. Need results on VTAB/DomainNet for that claim to be in the paper. The generalization results could also be extended to more distribution shifts, which could provide a better understanding of the methods/improvements. You also seem to be comparing with other methods on # of tuned params. Either this is a central claim for your paper, in which case you need comparison to light-weight finetuning methods (besides VPT), or you should clarify that this is a side-benefit of your method.\n\nMy general suggestion would be to focus on the long-tailed regime and present the other experiments as side-benefits.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper599/Reviewer_mA6r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper599/Reviewer_mA6r"
        ]
    },
    {
        "id": "QyWhXlvMDO",
        "original": null,
        "number": 3,
        "cdate": 1666667133985,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667133985,
        "tmdate": 1666667133985,
        "tddate": null,
        "forum": "8pOVAeo8ie",
        "replyto": "8pOVAeo8ie",
        "invitation": "ICLR.cc/2023/Conference/Paper599/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This submission focuses on the long-tailed classification tasks, and proposes the LPT method to alleviate the negative problems of long-tailed learning. The training of LPT consists of two stages. The first stage trains shared prompts to learn general features of the dataset, and the second stage trains group-specific prompts to learn specific features for samples with similar features. The contribution of this paper is to apply the idea of VPT to the long-tailed classification problem and achieves effective improvement.",
            "strength_and_weaknesses": "Strengths:  \n1.\tCompared with previous work, the LPT method can effectively handle various long-tailed learning scenarios by fine-tuning fewer parameters, and the model has strong generalization ability and compatibility.\n2.\tThe experimental settings are reasonable, and the authors have done relatively complete ablation experiments.\n\nWeaknesses: \n1.\tCompared with the VPT method, the LPT method only adds a small number of fine-tuning parameters, but the manuscript does not mention whether the 2-stage method will increase the training time.\n2.\tThe LPT method is robust to the domain shift problem. This paper proposes a possible explanation, but does not specify that domain-specific knowledge is obtained by what kind of prompt and at which stage.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The article is well-written, the problem statements are clear, the conclusions are supported by experimental results, and there are no grammatical errors in the writing aspect.\nThe core idea and components of this method exist in the previous research, so its innovation is not that outstanding.\n",
            "summary_of_the_review": "The authors are inspired by VPT, like using prompts to fine tune the network, and apply this kind of problem-solving idea to the study of long-tailed data. Although this idea exists in previous research, it is undeniable that this method has achieved some effective improvement in experimental performance, so I think it is a meaningful work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper599/Reviewer_ferv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper599/Reviewer_ferv"
        ]
    },
    {
        "id": "jb5bv29sN6",
        "original": null,
        "number": 4,
        "cdate": 1666709453240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666709453240,
        "tmdate": 1669366556102,
        "tddate": null,
        "forum": "8pOVAeo8ie",
        "replyto": "8pOVAeo8ie",
        "invitation": "ICLR.cc/2023/Conference/Paper599/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces an effective prompt-tuning method for long-tailed recognition. The proposed method consists of two phases. They first learn the shared prompt and then consider group prompts. They conduct experiments on Places-LT, Cifar100-LT and iNaturalist 2018. The results are good and comprehensive, which validates the efficacy of the proposed method. \n",
            "strength_and_weaknesses": "Strength:\n\n1. It's a good try to explore prompt tuning for long-tailed recognition. \n2. The experiments and related analyses are comprehensive and clear.\n3. The paper is well-written and easy to follow. \n\nWeaknesses: \n\n1. The biggest concern is the leverage of pretrained models, which are based on much larger datasets. This will make it unfair to compare with previous baselines. This point should be discussed. \n\n2. Since most of previous methods are based on resnet. The difference between different backbones should also be discussed. The difference should be shown clearly in the table.\n\nThus, in all tables in the experiments, it is suggested to provide the corresponding backbone and valid parameters of the proposed method and baselines for a fair comparison. \n\n3. Why the many-shot accuracy of VPT is substantially below than linear probing under balanced sampling in table 1?\n4. The adoption of pretrained model leads to the case that the method is naturally more advantageous than previous methods.  Thus, a more comprehensive comparison between different prompt learning methods is needed in this setting. These methods can be those discussed in the related works. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is mainly focused on the design of phase 2, but according to the ablation in Table 8, the contribution of phase 2 is minor.\n\n1. In table 3, the column of tuned parameters is misleading, even though it is right. Most of the previous methods are learned from scratch, however, the proposed method is based on a pretrained model on much larger datasets, which is unfair.\n\n2. what is the case of type (a) in the ablation \"Effect of Each Phase\"? How to understand the case with phase I but without prompt?\n\n3. In section 4.3, the introduction and motivation of GCL loss seem missing. ",
            "summary_of_the_review": "This paper proposes a new prompt-tuning based method for tackling with long-tailed datasets. The results and the analysis are good. However, there are some points which need further clarification. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper599/Reviewer_qoSe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper599/Reviewer_qoSe"
        ]
    }
]