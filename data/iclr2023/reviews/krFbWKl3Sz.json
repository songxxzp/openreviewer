[
    {
        "id": "UH7y83oliyd",
        "original": null,
        "number": 1,
        "cdate": 1666702745147,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666702745147,
        "tmdate": 1669860453529,
        "tddate": null,
        "forum": "krFbWKl3Sz",
        "replyto": "krFbWKl3Sz",
        "invitation": "ICLR.cc/2023/Conference/Paper5207/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors present a generalized TD learning for the MARL setting, with local updates occurring for K > 1 iterations for each instance of communication. Sample complexities at the inner loop (local TD updates) and the outer loop (consensus updates) are computed based on mild assumptions. Theoretical formulation predicts a worse complexity for the outer loop for the TD update method to match that of the batch learning method, but experiments produce more optimistic numbers, for reasons not provided/studied in the paper.",
            "strength_and_weaknesses": "The paper addresses a well-defined niche. By allowing for multiple local TD updates, a more general version of the MARL-PE problem is constructed and its complexities calculated.\n\nThe argument made can be even stronger with i) a more comprehensive literature review and a more strategic positioning, ii) some attempts to provide insight as to the conditions under which local TD updates would perform at its computed worst complexity, and iii) discussion on the fairness of the tested algorithms in Figures 1 and 3, perhaps by including Figures 4 and 6 in the main paper.\n\nIt would be interesting to cover an important line of MARL research related to the exchange of state information, and especially the succinct packetization of state information to exchange. Works investigating emergent communication may prove important (and arguably necessary) contenders to the local TD updates in the sense that the message-generating function can also be considered a learnable parametrization. Whereas in this paper, that function would be just the identity function accepting the parameters (after local TD updates), studies such as SchedNet (ICLR 2019) would subject the individual state information to undergo feature extraction via a trainable logic (i.e., neural networks). With the common goal of improving communication efficiency, how does the presented method compare against emergent communication methods?\n\nInvestigation on the following questions would make the paper more insightful: Under what circumstances does the computed (worst-case) communication complexity actually manifest in experiments? Do those circumstances also affect whether batch learning performs at its computed worst?\n\nFigures 1 and 3 can be better explained, with particular emphasis on the fairness of the tested algorithms. Since the x-axis is the communication rounds, Figures 1 and 3 do not correctly reflect the K > 1 \"advantage\" given to the local TD update method. At every x-axis tick, the proposed method runs for K (50 or 100 or etc.) iterations, so the graphical display can be misleading, unless accompanied by graphs such as Figures 4 and 6, which picture a more honest view by taking into account both K and L and plotting the errors against sample numbers. Indeed, it is sometimes the case (Fig. 4(a)) that batch learning does better than local TD updates, depending on the choice of K and L. If that really is the case, a further empirical analysis on the effects of K and L on the competition between batch learning and local TD updates may be an interesting addition.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\nIt is difficult to hold the math or the experiments as the pillaring reference of clarity as the conditions under which the computed complexities hold empirically are not studied. Also, the K-rounds advantage of the local TD updates needs some discussion as to its performance gain over vanilla TD learning.\nAs for the writing, there is but one minor fragment, found on the last of the three bullet points on page 3: \"Although the communication,\" seems cut off.\n\nQuality\nIncluding more varied experiments (perhaps, with a few of them violating some of the four assumptions) can be a strong upgrade to the current version.\n\nNovelty\nTo the best of my knowledge, the presented work is original.",
            "summary_of_the_review": "The paper's main strength lies more in the analyses on the feasibility and comparability of local TD updates in MARL-PE than in designing and implementing a novel algorithm itself. If the paper is indeed best viewed in this light, then it would be pleasant to see some updates on the literature review, complexity analyses in the experiments, and the fairness in comparison.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_stTJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_stTJ"
        ]
    },
    {
        "id": "nMU43EqP360",
        "original": null,
        "number": 2,
        "cdate": 1667106511084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667106511084,
        "tmdate": 1667396751854,
        "tddate": null,
        "forum": "krFbWKl3Sz",
        "replyto": "krFbWKl3Sz",
        "invitation": "ICLR.cc/2023/Conference/Paper5207/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the multi-agent policy evaluation problem for a set of networked agents that can communicate through the network. In the linear function approximation regime, the authors apply the standard temporal difference (TD) learning method with no batch samples but multiple local TD updates per communication, and show near-optimal sample complexity and improved communication complexity compared to naive TD updates. Finally, the authors demonstrate the effectiveness of the proposed method in both synthetic and real multi-agent policy evaluation problems. ",
            "strength_and_weaknesses": "Strengths\n\n- The communication compleixity is a bottleneck for distributed RL algorithms to efficiently work for large-scale networked systems. The studied multi-agent policy evaluation problem is a basic multi-agent RL task, which is real and meaningful. \n\n- The authors particularly focus on a class of temporal learning (TD) methods with local TD updates per communication. Compared with batch-based TD methods, the studied method works simpler and is more useful in practice, since a large amount of batch sampling is expensive in many real-world applications.\n\n- It is useful to establish near-optimal sample complexity of the proposed method as the well-studied batch-based TD methods. The studied communication complexity is also important to understanding pros/cons of the proposed methods. \n\n Weaknesses\n\n- The proposed method is limited to an extension of naive TD methods for multi-agent MDPs. It is unknown about the generality of this method to other TD methods.\n\n- This study is limited to the naive TD method which might not be very useful in some settings, for instance off-policy. Other limitations include the linear function approximation and the synchronous communication network.\n\n- The study assumes a series of technical assumptions on the multi-agent MDPs and the function approximation. It is known that these assumptions provide convenience to analyze TD methods with Markovian data if the underlying MDP has a fast mixing. Hence, the first two claimed challenges are not the main difficulty of analyzing the proposed method. \n\n- For the communication complexity, it is unknown if the proposed method can match batch-based TD methods. It is useful if some lower bound can be established for the proposed methods. \n\n- It is expected to see that the information of network topology should be a big factor in the final error bound. This is missing. Experiments on other network topologies should be included for illustration.  \n\n- The literature review misses many recent works on MARL policy evaluation problems, which is detrimental to the novelty. A more complete comparison is recommended, e.g., the paper:  Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is written well. However, there are some ambiguity in technical challenges and main results. Although several technical challenges are mentioned, some of them have been addressed for naive TD methods in the MARL policy evaluation setting. So, it is not  very clear what new techniques the authors have extended. Although the agent-drift seems to be unique challenge, the authors haven't highlight how this fails naive application of recent TD analysis. For the algorithm analysis, it is important to clarify what is the new development for analyzing the proposed algorithm compared with the mean-path result from Srikant & Ying, 2019. More discussions on generalizations to other settings, e.g., nonlinear function approximation and other TD methods, would increase the impact of the study. \n\nThe paper has studied an extension of naive TD method for the MARL policy evaluation problem. Analyzing this extended method seems to be an adaption of existing TD analysis. Hence, novelty in method and analysis requires further justification. \n\nHere are some other questions for consideration:\n\n- 'agent drift' phenomenon is interesting. Is there a way to quantify it? It is important to characterize conditions when the proposed method works and fails.\n\n- What is the specific condition for the inverse in Eq. (4) to exist? \n\n- How does the mixing time in Eq. (5) relate to Assumption 1?\n\n\n",
            "summary_of_the_review": "The paper studies an extension of naive TD method for the multi-agent policy evaluation problem. This extension is limited to a basic TD learning setting, which leaves a question about usefulness in other settings. The analysis also extends existing mean-path analysis in a more direct way, which leaves a question about novelty of analysis. Further study on conditions when the proposed method works and fails due to 'agent drift' is also needed. Since the authors miss many recent works, the novelty hasn't been fully established without a fair comparison. Generalizations to other settings haven't been established in either theory and experiments.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_N76j"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_N76j"
        ]
    },
    {
        "id": "esHHBRbCsFS",
        "original": null,
        "number": 3,
        "cdate": 1667456738162,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667456738162,
        "tmdate": 1667456738162,
        "tddate": null,
        "forum": "krFbWKl3Sz",
        "replyto": "krFbWKl3Sz",
        "invitation": "ICLR.cc/2023/Conference/Paper5207/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the multi-agent reinforcement learning policy evaluation (MARL-PE) problem, where $N$ agents collaborate to evaluate the value function of the global states for a target policy. It focuses on how to analyze the communication cost among agents when using the local temporal-difference (TD) learning method. \nFirst, this paper theoretically shows that executing multiple local TD steps can lower the communication complexity of MARL-PE compared to vanilla consensus-based decentralized TD learning algorithms.\nSecond, the paper theoretically shows that executing multiple local TD steps has higher communication complexity than the batch approach under same sample complexity condition.\nFinally, executing multiple local TD steps is shown to perform similarly to the batch approach in practice under certain settings. \n",
            "strength_and_weaknesses": "Strength:\n\n1. Result novelty: this paper conducted a theoretical analysis of the approach of multiple local TD steps in terms of communication complexity, and showed that this approach indeed lowers communication complexity, which has not been shown before. This seems novel to me.\n\n2. Technical novelty: the analysis of this paper has its technical novelty. Although the paper borrows technical tools from other works, it faces coupled challenges due to: underlying structure of TD, dynamic setting (i.e. MDP), and reward heterogeneity across agents.\n\n3. Theoretical results are clearly stated without ambiguity.\n\n4. Extensive empirical results are included which supports the theory. \n\n---\nWeakness: \nThere is no major technical weakness of this paper in my opinion. Still, I think the following is worth mentioning. \n\n1. It is not clear to me why Assumption 1 matters. Specifically, what would happen/why analysis fails if the stationary distribution is not unique? \nIs Assumption 1 very practical? \nDoes it simplify the problem? What might be the extra challenges if the assumption does not hold?\n\n---\nMinor comments/Questions:\n\n1. Assumption 4: each agent shares the same value function (i.e. same feature $\\phi$ and parameter $w$)? The current statement is confusing. Why not say the global value function $V$ adopts a linear structure?\n\n2. Typo: above section 3.2: definition of V-function: $\\gamma^t$ instead of $\\gamma$. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is mostly clear in my opinion. The motivation and background are well introduced. The technical challenges are well covered. However, I do hope to learn more about the role of Assumption 1, such as why and how it matters.\n\n\nQuality: The quality is fine. In terms of theory, the assumptions and theorems are stated without ambiguity. Although I did not check all the proof, the proof looks valid to me. The experiments are extensive enough, and details are included.  \n\n\nNovelty: This paper is novel. It gives the analysis of multiple local TD steps\u2019s communication complexity, which has been an open problem. Technically novelty is also discussed to handle the three coupled challenges. \n\n\nReproducibility: The reproducibility seems fine. The experiments details are included. However there is no code uploaded so it is hard to be certain whether the experiments can be reproduced. \n",
            "summary_of_the_review": "My current recommendation is to accept.\n\nMy reasons are the following:\nTechnical novelty: this paper gives a first answer to an open problem under certain settings\nGood quality: the paper is well written: clear presentation, enough motivation. Detailed experiments, etc.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_YnpC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5207/Reviewer_YnpC"
        ]
    }
]