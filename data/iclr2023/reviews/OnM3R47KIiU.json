[
    {
        "id": "eUABI9s5HVm",
        "original": null,
        "number": 1,
        "cdate": 1666662341612,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662341612,
        "tmdate": 1669796863562,
        "tddate": null,
        "forum": "OnM3R47KIiU",
        "replyto": "OnM3R47KIiU",
        "invitation": "ICLR.cc/2023/Conference/Paper1052/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a general class of reward function defined by image patches in observations, which enables effective learning guidance when training an VIL agent, visual interpretability, and better training stability. The method is evaluated on a range of DeepMind Control tasks and achieves favorable performance compared baseline methods. ",
            "strength_and_weaknesses": "Advantages\n* The method is straightforward and intuitively corresponds to the observation that comparing patches in image observations with the expert demonstration can provide useful learning signals. \n* The method is evaluated on standard pixel-based benchmarks and achieves comparable performance compared to its baselines. \n* The paper offers a discussion on the visual interpretation of the proposed reward function. \n\nWeaknesses\n* The proposed method is highly similar to previous AIL methods. This itself is not a problem if it provides large performance gain. However, gain is small compared to Shared-Encoder AIL according to Figure 4, while introducing several extra parameters such as aggregation function class and patch size. \n* The other claimed advantage of the method is visual interpretability. However, according to Figure 5, both Shared-Encoder as will as the proposed method have their attention maps focusing on the agent.\n\nOthers\n* There are two typos in equation (4). It seems to be (s, s') ~ \\pi and (s, s') ~ \\pi_E. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow. However, the proposed method is highly similar to previous AIL methods, with the main difference being that images are replaced with patches. ",
            "summary_of_the_review": "The method offers a simple AIL framework for training pixel-based RL agents. The main concern is that the empirical benefits, both in terms of asymptotic performance and sample efficiency, is not high compared to existing works. The paper claims that the method offers better visual explanations, but this particular point is not well-supported by Figure 5 where the baseline method already provides a similar level of interpretability. \n\n--- Post Rebuttal ---\nAfter the rebuttal responses and reading other reviewers' comments, I increased my score from 3 to 5 with more clarifications from the authors. My main concern is that the asymptotic performance gain over the baselines is specific to particular environments, and the visualization analysis is spuriously correlated with motion and does not distinguish positive and negative contributions to the reward. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A. ",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_AJEj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_AJEj"
        ]
    },
    {
        "id": "X42Y9nWOLr",
        "original": null,
        "number": 2,
        "cdate": 1667195131895,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667195131895,
        "tmdate": 1669428059947,
        "tddate": null,
        "forum": "OnM3R47KIiU",
        "replyto": "OnM3R47KIiU",
        "invitation": "ICLR.cc/2023/Conference/Paper1052/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates the problem of visual adversarial imitation learning. Based on Generative Adversarial Imitation Learning (GAIL), the authors re-formulate the discriminator and make it focus on the local regions of the image. Specifically, the visual demonstrations are divided into patches, the discriminator can predict reward for each patch separately. Empirical results show the performance of PatchAIL can outperform the compared methods in several DMC tasks.",
            "strength_and_weaknesses": "Strengths:\n* This paper investigates a practical setting. Visual adversarial imitation learning is quite difficult and few works can solve this problem.\n* The idea is novel. Though dividing images into patches is nothing new, it is a good try to use it in imitation learning.\n* Good and convincing empirical results.\n\nWeaknesses:\n* In 5.3, the authors claim that using 'mean' is the one-of-the-best choice among aggregation functions while 'max' tends to fail in both domains. But in my opinion, once the authors use 'mean' as the aggregation function, it seems that there is no difference between using the patch discriminator and a vanilla discriminator. Also, in Figure 6(a), the curve clearly shows that using 'mean' as an aggregation function results in the worst performance. This seems contradictory to what the authors describe in the paper.\n* The effect of patch regularization is not clear, as shown in Figure 4.\n* Would you mind providing some intuitive analysis about why a too-large or too-small patch could hurt the performance? And In my opinion, the best patch size for different agents should be various due to their different body sizes in the image. Can the authors elaborate on this point more?\n* Do PatchAIL have to use (s,s') as the input of the discriminator? I think this adds a strong constraint on the used expert demonstrations. I believe there are some works about adversarial imitation learning with observations only use a single state as the discriminator input. What if we use a single (s) or (s,a) as the discriminator input?\n* Experiments can be conducted on other visual imitation learning tasks such as Atari Games.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall well-written. The authors do not include their code, so it's hard to verify the reproducibility of the method. I hope the authors can release their code publicly after acceptance since visual adversarial imitation learning is quite difficult and many researchers want to find a good baseline.",
            "summary_of_the_review": "Overall, the paper is well-written and easy to follow. The idea is novel and reasonable. Empirical results are good and convincing. However, there are still some concerns about the experiment, as listed in the weaknesses part. As a result, I provide my initial score as *borderline accept*.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_nR86"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_nR86"
        ]
    },
    {
        "id": "SYRraayyzw",
        "original": null,
        "number": 3,
        "cdate": 1667426048990,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667426048990,
        "tmdate": 1667426048990,
        "tddate": null,
        "forum": "OnM3R47KIiU",
        "replyto": "OnM3R47KIiU",
        "invitation": "ICLR.cc/2023/Conference/Paper1052/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Visual imitation learning algorithm using patch rewards is proposed. For patch rewards, input images from agent and expert are decomposed into small patches and classified by using multiple patch-wise discriminator. The output values of patch-wise discriminators are postprocessed (by $h$) and aggregated (by $Aggr$, e.g., $\\mathrm{mean}$, $\\mathrm{median}$, $\\mathrm{min}$) to generate a scalar reward that is suitable for the RL inner loop of adversarial imitation learning. Authors also introduce patch regularizers that aim to maintain patch-wise information disappearing through the aforementioned reward aggregation. The proposed algorithm shows its effectiveness in DeepMind Control Suite benchmarks and some amount of visual explanability through learned patched rewards.",
            "strength_and_weaknesses": "### Strength\n- The idea seems to be easily applicable to any visual imitation learning tasks. \n- One can visualize the gap between agent and expert behaviors through images. \n### Weaknesses\n- Motivation and theoretical derivation on patch regularization is unclear. It seems that patch regularization is effective only for some tasks where algorithms w/o patch regularization is unstable. \n- Analysis on how the number of expert demonstrations affects the performance is missing, e.g., sample efficiency w.r.t. the number of expert demonstrations, whether the patch reward can be effectively trained for small or large numbers of expert demonstrations, etc.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nThe contribution and main idea of this work is clearly stated, and maths are easy to follow. \n\n### Quality\nThe paper shows good empirical performance together with visualization of learned discriminator\u2019s outputs. The contribution of this work is purely on the empirical side, not on theoretical derivation. \n\n### Novelty\nThe idea of using patch-wise multi-discriminator seems novel and easy to be implemented. \n\n### Reproducibility\nDetails on hyperparameters and experimental settings are shared, so it seems straightforward to reproduce the results. \n\n",
            "summary_of_the_review": "Overall, I believe this is a good submission and far above the acceptance boundary. I only have a few questions below:\n- The approximation from Eq (6) to Eq (7) is unclear to me, especially how $\\mathrm{min}$ can be converted into $\\mathbb{E}$ in the bracket of Eq (7).\n- Adding empirical analysis w.r.t. the number of expert demonstrations will be interesting. I think that may affect Eq (7) in the sense that the expectation in Eq (7) and its approximation can be affected by the number of expert demonstrations.\n- In Figure 6, (a), it seems that $\\mathrm{mean}$ doesn\u2019t seem to work well, whereas $\\mathrm{max}$ works well. This is different from what authors state in Section 5.3. I guess labels in Figure 6 are simply mistyped. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_52Vk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_52Vk"
        ]
    },
    {
        "id": "uB1ClZW2gN",
        "original": null,
        "number": 4,
        "cdate": 1667484135039,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667484135039,
        "tmdate": 1667539273037,
        "tddate": null,
        "forum": "OnM3R47KIiU",
        "replyto": "OnM3R47KIiU",
        "invitation": "ICLR.cc/2023/Conference/Paper1052/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper describes an adversarial imitation learning algorithm that learns a discriminator with patch pixel rewards rather than directly from images. Recent work in the vision deep learning community have shown that using patches is effective in embedding pixels. The authors argue that patch pixels rewards are more informative than using a shared encoder for the discriminator and critic or directly learning from images.\n\nComments:\n- Is the encoder layer CNN and kernels the same size for the independent-Encoder and Shared-Encoder compared to the patch (obviously ignore the 1x1 kernel at the end)? \n- What is \\boldmath{R}_{pxp} in equaiton 5?\n- Which of the 7 tasks were used for tuning hyperparameters versus for evaluation? Or where all hyperparameters run on all 7 tasks and the best hyperparameter across tasks chosen?",
            "strength_and_weaknesses": "Strength:\n- The idea of training a  discriminator with patches to gather dense rewards straightforward\n- The paper is mostly well-written and easy to understand\n- The authors perform thorough experiments comparing all relevant baselines to showcase the significance of their idea.\n- The authors perform an ablation study in figure 6 (b) on various patches, empirically showing why patch size 39x39 was chosen.\n- Additional ablation studies in the appendix show the breadth of empirical analysis.\n\nWeakness:\n- Though training a discriminator with patches is easy and intuitive, the best way to aggregate patches into a reward is not apparent. The authors proposed three aggregation metrics: mean, max, min, and median. From this set of metrics mean was chosen as the default aggregation metric. But from the ablation study, figure 6 (a), mean seems to perform significantly worse than the other metrics. It is not apparent why mean was chosen.\n- There are 3 variants of PatchAIL: PatchAIL w.o. Reg, PatchAIL-W and PatchAIL-B. It is not apparent which algorithm variant is better and why regularization helps. The authors motivate patch regularization, but the experiment evaluation does not justify the motivation.\n- The approximation of equation (6) with equation (7) is unclear.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. Though the technical novelty is limited given the algorithm, the empirical noverlty is very high. The authors not only introduce a new algorithm. They show why the performance gained from their proposed algorithm can not be achieved from baseline algorithms through several ablations of the baselines. The work is high quality and provides insight to the community.",
            "summary_of_the_review": "I recommend this paper for marginally above the acceptance threshold. Though the technical novelt is limited, the empirical novelty is not. The authors do a thorough job empirically justifying the decision made in the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_psvi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1052/Reviewer_psvi"
        ]
    }
]