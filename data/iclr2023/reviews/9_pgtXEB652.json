[
    {
        "id": "Lc8vlLc6zk",
        "original": null,
        "number": 1,
        "cdate": 1666363988918,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666363988918,
        "tmdate": 1666363988918,
        "tddate": null,
        "forum": "9_pgtXEB652",
        "replyto": "9_pgtXEB652",
        "invitation": "ICLR.cc/2023/Conference/Paper2453/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a new representation of texts named Polynomial Band (PB) for text detection. The shape-constrained loss designed for PB considers both shape and the length. The model uses ResNet50 as the backbone followed by Cross-scale Pixel Attention (CPA) and Lightweight Deformable Transformer. CPA is parameter-free, but it can effectively suppress useless regions and thus improves the final results. The lightweight deformable transformer helps to achieve high FPS values. The experimental results show the effectiveness of the approach.",
            "strength_and_weaknesses": "Strengths:\n\nA new text representation, PB, is a concise and powerful representation for most texts observed in wild. The shape-constrained loss is well designed for the representation.\n\nCPA is parameter-free and computationally inexpensive, but it is shown that it is better than other methods.\n\nThe reported absolute numbers look strong.\n\nWeaknesses:\n\nIn section 3.2, it discusses a potential weakness of the representation that it cannot represent lines that have multiple values for single x. Probably, it is true that it is rare to observe such cases in wild, but it is a fundamental limitation of the approach.\n\nText detection is often followed by text recognition using the detected boxes. Typically, features corresponding to the bounding boxes are extracted and fed to the recognition model. The paper does not discuss how to extract features (or pixels) if a text is represented by PB.\n\nIt was not clear how a text is represented by four lines. I guess there is no guarantee that the beginning and ending points of each line match each other and there should be gaps among the lines. In that case, how is a complete region defined given four lines (and how is IoU computed)?\n\nIt was not clear if the proposed representation was good or the model was good. Ideally, other representations should be implemented with the same model and perform fair comparisons among them.\n\nThe results in Table 3 are interesting. Assuming \"-\" is the baseline without anything, adding something other than CPA did not seem to help much or even made it worse. I was not sure if it was reasonable. If there was a good explanation on this, it would be good to have a discussion on it.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I would suggest to use some equations to explain lightweight deformable transformer, but overall, the paper is easy to follow. The proposed text representation has some novelty and it could have a good impact within the community as the absolute numbers look great.",
            "summary_of_the_review": "The results are good and the representation seems powerful and reasonable. Other proposals are also effective. Therefore, I see a good value in the paper for the scene text recognition community. However, there are several weaknesses found in the paper as mentioned above and I am not fully convinced that this paper should be accepted in the current form.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_FmtQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_FmtQ"
        ]
    },
    {
        "id": "251pAX0Yauj",
        "original": null,
        "number": 2,
        "cdate": 1666542611367,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666542611367,
        "tmdate": 1666542611367,
        "tddate": null,
        "forum": "9_pgtXEB652",
        "replyto": "9_pgtXEB652",
        "invitation": "ICLR.cc/2023/Conference/Paper2453/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new text shape representation for scene text based on the coefficients of a quadratic polynomial fitting the four contours (upper, lower, left, right) of the text instance. Then, a transformer-based detector is trained to predict the coefficients of the polynomials for all text instances in an image. The transformer is designed to be lightwieght in order to improve efficiency. Experiments using standard datasets containing irregular texts show state-of-the-art results in detection accuracy and a very good efficiency in terrms of detection time.",
            "strength_and_weaknesses": "Strengths\n- The paper proposes a new compact parametric representation for text shape based on polynomials. It also defines the metric to match the points generated by the polynomial with the points in the ground-truth.\n- It defines a lightweigth transformer architecture with only 2 layers with a specific coarse-to-fine strategy to generate reference points at each transformer layer.\n-  A cross-pixel-attention module with no learnable parameters is introduced to perform pixel-wise attention at different feature scalses.\n- The method obtains state-of-the-art results in text detection on standard datasets, with a very good efficiency in terms of computation time.\n\nWeaknesses\n- It is not clear the contribution of the new polynomial band representation. In comparison with other similar methods (for instance TESTR), it is not clear whether the improvement in the results come from the new representation or from the slight variations in the feature encoding and transformer architecture. I miss some experiment using the same architecture to different shape representations (for instance, polynomials, poitns and bezier). It is important to clarify this point as this is the main contribution of the paper. Apart from it, the architecture proposed is very similar to the one proposed in TESTR.\n- In the experiments there are some results that should be better analyzed and discussed. Results for TESTR are provided without using the recognition branch in training which leads to lower results to those reported in the original TESTR paper. However, reported FPS for TESTR method in tables 1 and 2 are the values reported in the original paper using the dual branch for detection and recognition. I guess that, if only detection branch is used, FPS should be higher. For a fair comparison, FPS using only the detection branch should be reported in this case. \nFurthermore, even if the method proposed here is a detection-only method, I think that a fair comparison should include results of TESTR obtained training the whole pipeline (detection and recognition). Even if the goal is only detection, It could be valid to train TESTR using the two branches and use only the detection branch to obtain the results. \n- In the main paper, it is not clear in section 3.3 how the polynomial representation is matched to a ground-truth polygonal representation consisting of several points not necessarily equally distributed. In the appendix, there are some more detailes, but I think this should be made more clear in the main paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "In general, the paper is clear and well written. As commented before, the whole architecture is similar to the architecture proposed in the TESTR method, with some slight variations. The main contribution is the novel text representation, although experiment do not clearly show that this representation has clear advantages over other common representations used in the past. Except for a few details (also commented before), the method could be reproduced.",
            "summary_of_the_review": "The paper proposes a novel representation for text representation and a transformer-based architecture to predict text shapes. Although results show SoA performance, it is not clear wether the good results come from the new representation. In addition, there are some details in the comparison with the SoA that should be better presented and discussed. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_Lb4V"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_Lb4V"
        ]
    },
    {
        "id": "9tywLYD69VK",
        "original": null,
        "number": 3,
        "cdate": 1666618440971,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618440971,
        "tmdate": 1666618440971,
        "tddate": null,
        "forum": "9_pgtXEB652",
        "replyto": "9_pgtXEB652",
        "invitation": "ICLR.cc/2023/Conference/Paper2453/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a scene text detector, PBFormer, using the transformer with a \u201cnew\u201d text instance representation called Polynomial Band (PB). The proposed PB is able to represent a text with a complex shape since it utilizes four polynomial curves to fit the text instance\u2019s top, bottom, left, and right sides. The proposed PBFormer is basically a transformer model with the proposed PB text representation. Extensive experiments have been conducted to verify the effectiveness of the proposed PBFormer and its superiority to other existing approaches. ",
            "strength_and_weaknesses": "Strengths:\nThe proposed PB text representation utilizes four polynomial curves with a fixed number of parameters to fit a text instance, while polygon-points-based methods require using different numbers of points to describe different text regions. This facilitates the learning of parameters for the predicted outline of a text region, and thus reducing the computational cost of the adopted transformer model. Extensive experiments have been conducted and the results are convincing. \n\nWeaknesses:\n1) The ABCnet [Liu et al. 2020] also adopted a fixed number of parameters to fit the outline of a text region. Therefore, what is the difference between the text representation based on Bezier curves [Liu et al. 2020] and the proposed PB base on Polynomial curves? No discussion regarding this issue has been provided. To this end, the novelty is relatively limited. The authors need to explain more at this point instead of simply claiming the PB\u2019s advantages against polygon-points-based methods.\n2) Vey few technical contributions have been made in the whole network architecture. The three modules contained in the network all utilize well-known techniques. This leads to my concerns on the insufficient academic contribution of this paper. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and well-organized. I think it is easy for an ordinary researcher to reproduce the proposed scene text detector. \nHowever, as mentioned above, I have some concerns about the limited novelty and insufficient technical contribution of this paper. \n",
            "summary_of_the_review": "As analyzed in my above comments, there exist both clear strengths and weaknesses in this paper. To sum up, I think the quality of this paper is slightly below the bar of ICLR. I will be happy to read the author's responses and discuss with other reviewers to make my final decision.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_cjr7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_cjr7"
        ]
    },
    {
        "id": "fshwxQ5gnUS",
        "original": null,
        "number": 4,
        "cdate": 1666627141504,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627141504,
        "tmdate": 1666627141504,
        "tddate": null,
        "forum": "9_pgtXEB652",
        "replyto": "9_pgtXEB652",
        "invitation": "ICLR.cc/2023/Conference/Paper2453/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a novel text representation named Polynomial Band. Cross-scale attention is used to enhance the feature of text regions. The fitting loss function is optimized to adapt to scene text detection task. The results on two benchmarks show the effectiveness.",
            "strength_and_weaknesses": "Strength\n1. The paper proposes Polynomial Band, which uses four polynomial curves to represent the text instance. \n2. The optimized fitting loss is showed to be effective.\n3. The method can achieve promising performance without per-training.\n\nWeaknesses\n1. The cross-scale attention is similar to Adaptive Scale Fusion in DB++. Compared with general attention operation, why can the parameter-free one highlight text regions? The author should show the differences and give more detailed explanations.\n2. The motivation for CPA is not clear. It works similar to an encoder block in transformers, which may explain the use of fewer encoder blocks.\n3. Compared with Bezier curve, polynomial curve is just another form of the fitting function. It seems to be more complicated in terms of the parameters and loss calculation cost. It is recommended to show the advantages more clearly.\n4. The visualizations only display the increase of precision or recall, which I prefer to contribute to the strong feature extraction network rather than polynomial curves. The author better shows the superiority in \"distinguishing adjacent or overlapping texts\".\n5. The training epoches are much larger than previous methods. The good performance may come from the stacking of computing resources.\n6. To show the robustness, it is recommended to test on more challenging datasets, such as ICDAR MLT 2019, ICDAR 2019 Art and DASTA1500.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is well organized.\nQuality: The paper needs to give more theoretical analysis.\nNovelty: The proposed polynomial band is somewhat novel. Optimized fitting loss brings incremental advances.\nReproducibility: The experimental setup is well described.\n",
            "summary_of_the_review": "The contributions are incremental. The analysis and explanations are not enough. It is not enough to meet the quality of ICLR.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_Tjeh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2453/Reviewer_Tjeh"
        ]
    }
]