[
    {
        "id": "TbTj9iwmkL",
        "original": null,
        "number": 1,
        "cdate": 1666520864844,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666520864844,
        "tmdate": 1669108370537,
        "tddate": null,
        "forum": "TT66Tpbus3b",
        "replyto": "TT66Tpbus3b",
        "invitation": "ICLR.cc/2023/Conference/Paper709/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to tackle the pipeline optimization problem that jointly optimizes various hyperparameters in the whole pipeline of machine learning. It proposes per-algorithm encoders and further aggregates the embeddings from all stages of the pipeline to a vector representation. Bayesian optimization is able to efficiently optimize the pipeline performance using the aggregated representation. The paper empirically shows the proposed method\u2019s better performance against baselines. The authors also show the possibility of meta-training the model on existing pipeline evaluation data, and the method\u2019s ability to quickly adapt to different dataset tasks as well as changes in the pipeline structure (e.g., the addition of new algorithms).",
            "strength_and_weaknesses": "Strengths:\n1. The paper is nicely structured and clearly written.\n2. The experiments carried out cover rather extensive scenarios.\n3. The authors additionally looked into the inductive bias of the introduced embeddings, which results in some insights for the architecture design.\n\nWeaknesses:\n1. The novelty of the method is limited, in the context of recent literature.\n2. Lack of empirical justification for the proposed method in the general deep learning setting, where pipeline optimization can be of great importance.",
            "clarity,_quality,_novelty_and_reproducibility": "1. The novelty of this paper is limited as 1) meta-learning approaches for GP deep kernels have been investigated in previous works (Wistuba & Grabocka, 2021) and 2) kernel learning approaches for pipeline learning have been studied as well (Alaa & van der Schaar, 2018). The only difference could be that this work uses an additional fully-connected layer on top of the component-wise embeddings. However, why is this essential? Can BO already consider and utilize the similarities and interactions between these embeddings?\n\n2. Related to the point above, the highly relevant papers mentioned are not used as the baseline for comparison in the experiment section. The authors should at least compare to (Alaa & van der Schaar, 2018) to investigate the effectiveness of pipeline embedding networks, which is the main part that differentiates from other papers.\n\n3. Does the budget in Experiment 3 include the model training time, or is it just the search cost? Can you accompany it with the number of evaluations done to get a sense of the search time overhead, especially when DeepPipe needs to perform fine-tuning?\n\n4. For the scenario when new algorithms are added in Experiment 4, does the aggregator also needs to be retrained? Also, have you considered cases where new stages are added?\n\n5. T-OBOE\u2019s results missing in Experiment 2. Figure 3 and Figure 9.\n\nMinor:\n\n1. To avoid confusion, plot the same method \u201cRS\u201d with the same color.\n\n2. Missing bracket \u201c)\u201d after \u201c(Equation 5\u201d, last paragraph of Section 6.",
            "summary_of_the_review": "Overall, the paper conducts many empirical experiments to validate the superior performance of DeepPipe. However, several aspects are lacking. The authors did not fully establish the gap between the literature and this paper. The inability of previous methods in capturing the interaction and relations among pipeline stages is hypothesized, rather than proved or shown in the experiments. Some important baselines are left out in the experiments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper709/Reviewer_5R6t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper709/Reviewer_5R6t"
        ]
    },
    {
        "id": "SO9-rUoyQqN",
        "original": null,
        "number": 2,
        "cdate": 1666578541299,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578541299,
        "tmdate": 1666614250037,
        "tddate": null,
        "forum": "TT66Tpbus3b",
        "replyto": "TT66Tpbus3b",
        "invitation": "ICLR.cc/2023/Conference/Paper709/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The selection of the algorithms and their hyperparameters is known as Pipeline Optimization. For most existing Pipeline Optimization, techniques do not explore the deep interaction between pipeline stages/components (e.g. between hyperparameters of the deployed preprocessing algorithm and the hyperparameters of a classifier).  This paper aims to capture the deep interaction between components of a Machine Learning pipeline and introduces DeepPipe, a neural network architecture for embedding pipeline configurations on a latent space. Such deep representations are combined with Gaussian Processes (GP) for tuning pipelines with Bayesian Optimization (BO). In experiments, this article demonstrates that the proposed pipeline representation helps to achieve state-of-the-art results in optimizing pipelines for fine-tuning deep computer vision networks.",
            "strength_and_weaknesses": "Questions: \n\n(1) In Equation (1), $p^*$ and $\\lambda(p^*)$  are the parameter to be optimized, and the author has set $p_{\\lambda} = (p,\\lambda(p))$, in section 4, the representation of neural network is $\\phi\\left(p_\\lambda ; \\theta\\right): \\operatorname{dom}\\left(p_\\lambda\\right) \\rightarrow \\mathbb{R}^Z\n$, but Equation (3) does not reflect that $p$ is encoded into MLP, please explain it.\n\n(2) The optimization of $\\theta=\\left\\{\\theta^{\\text {enc }}, \\theta^{\\text {aggr }}\\right\\}$ is confusing. Minimizing the negative log-likelihood of the GP requires a detailed explanation.\n\n(3) The explanation of Equation (5) in Appendix G is too simple and needs a little description.\n\n(4) In figure 1, the 'selector' step can be explained more clearly.\n\nA lot of work has been done and compared with the previous work. From the experimental results, this neural network-based representation method has achieved great success.\n",
            "clarity,_quality,_novelty_and_reproducibility": "AutoML is a future goal for ML community. An expressive ML pipeline is useful for applications. In this topic, BO optimization is a typical way for parameter selection. The authors follow this framework and present their ideas under feature embedding. From this perspective, it likes a feature transformation study. It still belongs to the feature processing component in AutoML. It is thus the contribution is limited. ",
            "summary_of_the_review": "The authors present some useful feature-processing ideas in AutoML. However, they didn't jump out of the constraint of the given AutoML framework. Moreover, the experimental results are not strong enough. There are only a few baselines, and some of them are too old. As far as I know, they are many BO works that can be compared.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper709/Reviewer_KTJe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper709/Reviewer_KTJe"
        ]
    },
    {
        "id": "js8IJ2n6D4",
        "original": null,
        "number": 3,
        "cdate": 1666613982328,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613982328,
        "tmdate": 1666613982328,
        "tddate": null,
        "forum": "TT66Tpbus3b",
        "replyto": "TT66Tpbus3b",
        "invitation": "ICLR.cc/2023/Conference/Paper709/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel approach to pipeline optimization for machine learning models. The proposed method encodes the hyperparameters of every algorithm into a latent space and then aggregates the hyperparameters of the algorithms from all stages into a single latent representation. Based on this learned latent representation, the algorithm uses Bayesian optimization with deep kernel learning to optimize the pipelines, and also allows meta-learning using existing datasets. Extensive experiments are performed to show the practical efficacy of the propose method.",
            "strength_and_weaknesses": "Strengths:\n- The idea of per-component encoders is particularly interesting since it allows the propose method to be extendable. And this extendability has been empirically verified.\n- The experiments are extensive, and they do clearly show the empirical advantage of the proposed method. The way the experiments section (Section 5) is written makes it particularly easy to understand what questions/hypotheses the experiments are trying to answer.\n- Last paragraph of Section 6, the insight provided in this paragraph is particularly nice.\n- The paper is very well written, the proposed method is well explained.\n\nWeaknesses:\n- Section 5.4, top of page 8: It is worrying that different values of F and numbers of encoder layers are used in different experiments. How are these parameters chosen? Ideally, the algorithm should work well in different experiments without requiring the tuning of these parameters; on the other hand, if these parameters are tuned for every experiment, this will be unrealistic since we usually don't get to do this in practice when faced with a new task. This is my biggest concern, please clarify.\n- The paper claims that the proposed method is able to take into account the interactions among different components, but the paper never made it clear which specific algorithmic design(s) has made this possible. I think this is an important insight and should be explicitly discussed.\n- Last paragraph of Section 6, the insight provided in this paragraph is nice as I said above, but why have you used randomly initialized weights for DeepPipe rather than using the weights after training?\n- Section 5.3, Hypothesis 5: I wonder what's the implication of this hypothesis? In other words, what insights can we draw about your algorithm if this hypothesis is validated (which it is)?\n- Page 8, last paragraph: the presentation of this paragraph can be improved, it's difficult to understand in the current form.\n- [minor] Section 3.2, equation (2): it looks like you are assuming noiseless observations, which is different from what is written in the paragraph above where the observations are noisy. Perhaps the paragraph should be modified to discuss noiseless observations.\n- [minor] Section 4.2, equation (5): should give some intuitions as to how this objective is designed.\n- [minor] Section 5.4: The notations in this section are kind of inconsistent with the previous ones such as those in Section 4.1. Is it true that  $L_i=F(Q_i+M_i)$?\n- [minor] Last line of page 7: I think the left bracket is in the wrong place, I think it should be $F\\sum_i(Q_i+M_i)$",
            "clarity,_quality,_novelty_and_reproducibility": "Clarify: The paper is well written and mostly clear.\n\nQuality: The paper doesn't include theoretical results, but it is high-quality as an empirical paper.\n\nNovelty: The components used in the proposed algorithm are not really novel, but they are put together in a reasonable and novel way and combine to give a practical algorithm.\n\nReproducibility: Details about the algorithm and the experimental settings are included, and the code is uploaded.",
            "summary_of_the_review": "The method proposed in this paper is intuitive and useful, and the experiments are comprehensive and nicely done. My only major concern is the first comment I listed above under \"Weaknesses\" regarding whether some of the algorithmic hyperaprameters have been unfairly fine-tuned for different experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper709/Reviewer_2otF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper709/Reviewer_2otF"
        ]
    }
]