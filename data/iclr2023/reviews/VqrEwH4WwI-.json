[
    {
        "id": "huKSEmhF1Z",
        "original": null,
        "number": 1,
        "cdate": 1666679641084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679641084,
        "tmdate": 1666679641084,
        "tddate": null,
        "forum": "VqrEwH4WwI-",
        "replyto": "VqrEwH4WwI-",
        "invitation": "ICLR.cc/2023/Conference/Paper4428/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a novel method of cross-domain transfer with an unaligned dataset, and the proposed approach aims to acquire domain-invariant feature space and a common policy on it. And the experiments with various domain shifts show that the proposed method achieves better performance than existing methods in cross-dynamics. ",
            "strength_and_weaknesses": "Strength \nThe paper proposes to use approach similar to GAN that aims to acquire domain-invariant feature space and a common policy on it. The author provided extensive ablation study, and compared the model with state of the art models, and showed the new model has better performance.\nWeaknesses\nThe training process seems quite complicated. Combined with the instability of adversarial training, the model can be difficult to tune.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\nThe paper is easy to understand, and the quality looks good.\n\n",
            "summary_of_the_review": "The paper is well written and provided extensive experiments to show the proposed method works better than baseline models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_rLRK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_rLRK"
        ]
    },
    {
        "id": "E564jfVW-d",
        "original": null,
        "number": 2,
        "cdate": 1666701299123,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701299123,
        "tmdate": 1670773197423,
        "tddate": null,
        "forum": "VqrEwH4WwI-",
        "replyto": "VqrEwH4WwI-",
        "invitation": "ICLR.cc/2023/Conference/Paper4428/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel method to perform zero-shot cross-domain transfer by learning a domain-agnostic policy in the source domain that can be directly applied to the target domain. To this end, specific training methods (technical contritions) include: \n1. Align representations of states and actions from different domains to a common latent space through adversarial training. \n2. The common policy is trained to adapt to the target task in the source domain.\n3. Directly apply the common policy to the target domain based on the aligned representations. \n\nThe effectiveness of the proposed approach is verified with four Maze environments in the D4RL benchmark, which is shown to outperform other baselines especially when there are sufficient proxy tasks.",
            "strength_and_weaknesses": "Strength:\n1. It is a simple yet reasonable idea for cross-domain policy transfer by aligning and training a policy in a common latent representation space shared by different domains. \n2. The authors provide both qualitative and quantitative results to show the performance of adversarial alignment. \n3. In general, the paper is well-written and easy to follow. \n\nWeaknesses:\n1. My main concern is the novelty of the proposed approach, which seems very similar to GAMA. Both of them use an adversarial objective for state alignment in different domains so that the policy can be directly transferred to the target domain. The major difference is that in this paper, the states are aligned in a common latent space instead of a direct matching.\n2. If I understand correctly, the action $a_z$ from the common policy may only contain compact information. Therefore, if action $a_d$ in the target domain is more complicated than the action in the latent space, only using $a_z$ and the domain ID might not be able to decode $a_d$. For example, $a_z$ may represent a high-level behavior such as \u201cturn left\u201d. However, for a robot to execute this action, it may take multiple steps based on its current domain-specific states (e.g., the pose of its own torso). In other words, the method might only work when the source and target domains have a strong relationship, because the policy in the target domain is completely determined by the common state, and does not depend on any domain-specific skills.\n3. All experiments are conducted in the Maze environments in the D4RL environments, which is inadequate to support the effectiveness of the model in general control scenarios. Therefore, I would suggest validating the model on other benchmarks with a wide variety of dynamics. For a fair comparison, the authors may use the original environments of other baselines, e.g., those used in the GAMA paper.\n4. Except for GAMA, the compared approaches are somewhat \"out-of-date\". Although I understand that this paper is focused on performing policy transfer between offline datasets, without interacting with various environments, it would be nice if the authors could include stronger baseline methods for model comparison, especially the offline RL approaches that show impressive performance on the D4RL dataset.\n5. A typo: \u201cdeomnstrations\u201d in Appendix C.2.\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity and quality: This paper is clearly written.\n2. Novelty: Fair. The main idea is similar to the related work, GAMA, which also uses an adversarial training strategy to align states from different domains.\n3. Reproducibility: Source code provided.",
            "summary_of_the_review": "Overall, I think the paper presents a simple but effective cross-domain policy transfer method. However, I am inclined to reject this paper given its technical novelty compared with GAMA and the insufficient experimental results. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_X2sb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_X2sb"
        ]
    },
    {
        "id": "WbCrrdLHvw",
        "original": null,
        "number": 3,
        "cdate": 1666812799353,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666812799353,
        "tmdate": 1666812799353,
        "tddate": null,
        "forum": "VqrEwH4WwI-",
        "replyto": "VqrEwH4WwI-",
        "invitation": "ICLR.cc/2023/Conference/Paper4428/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The proposed method is as simple as aligning representations in the latent space to learn a domain-invariant policy. Conceptually that makes sense as it can generalise better in the presence of small perturbations and changes in an environment. This allows to do some domain adaptation with zero-shot learning whereby everything learnt in the source domain (environment \u03a7) can be transferred into the target domain (environment \u03a5). The results presented are fairly comprehensive and the visualisations alike, but the description of the method is not very convincing, i.e. it seems to work surprisingly well. The authors have provided the code and the corresponding datasets though.",
            "strength_and_weaknesses": "Strengths:\n\na) Relatively simple method, which can be extended and further improved relatively easily, especially the adversarial training part, and of course the learning part. \nb) Competitive results show promising avenues for expanding on other settings and in other environments\nc) Visualisations of the latent space provide some further understanding of the underlying processes involved.\n\nWeaknesses:\n\na) Background work is rather blunt. The last paragraph on page 2 is not well written. Methods' names are somewhat akwardly provided alongside the in-text citation.\nb) I am not sure that the background covers all recent methods, but because I am not very well aligned with this area I am not very firm on it.\nc) Further to b) more comparisons could have been added to the main text\nd) Methods are not very well described in the main paper - appendix provides further context though so it somewhat compensates. It buffles me though that the method works relatively well, given what the methods employed",
            "clarity,_quality,_novelty_and_reproducibility": "The paper could benefit form some further improvements in the writing, especially on the first page, i.e. pages 1-3. It is a good paper though, with fair novel and original components, Code has been provided hence it is easily reproducible.",
            "summary_of_the_review": "The paper provides adequate experiments and visualisations to justify the advantages of the proposed method. I am somewhat hesitant due to the method description seeming too straightforward and 'simple' (not in a bad way, in that I do not mean that complex is needed) to learn representations that are transferable and generalisable. Results prove me wrong though so am erring in caution.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_QGQp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_QGQp"
        ]
    },
    {
        "id": "Y5_bhUmoB6Q",
        "original": null,
        "number": 4,
        "cdate": 1668682078428,
        "mdate": null,
        "ddate": null,
        "tcdate": 1668682078428,
        "tmdate": 1668682568121,
        "tddate": null,
        "forum": "VqrEwH4WwI-",
        "replyto": "VqrEwH4WwI-",
        "invitation": "ICLR.cc/2023/Conference/Paper4428/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper study the domain adaptation imitation learning. The paper proposes a method to map the state and the action of both domains into a common space. After learning this common space, the target agent can zero-shot perform the new task that only has source demonstrations. Specifically, the paper use domain adversarial learning to learn such common space of the state and the action.",
            "strength_and_weaknesses": "Strength:\n\nThe topic of cross-domain imitation learning is relatively new and has the potential to explore.\n\nThe framework of the paper (the common state and action space) is clearly stated and can inspire the following works.\n\nThe method introduces domain adaptation learning into behavior cloning, which is relatively new in the community.\n\nWeakness:\n\nDomain adversarial learning is a conventional method for domain adaptation when we need to learn domain-invariant representations. The paper directly uses domain adversarial learning to learn the common space of the state. It is not a very novel idea for me.\n\nGAMA uses domain adversarial learning to learn the mapping of the state and the action between domains. The paper is more like a simple version of GAMA, as the domain discriminator of GAMA takes the triples (s, a, s') as input while the paper takes the state s as input. GAMA learns the mapping from the source state and action to the target while the paper learns a common space. Therefore, the contribution of the paper is incremental to GAMA.\n\nIntuitively speaking, the adaptation phase might disturb the aligned space learned by the alignment phase. Because in the adaptation phase, the method will finetune the common policy for the source domain, it will cause inconsistency between the common policy and the decoder of the target domain.\n\nThe alignment scores in Table1 clearly do not favor the proposed method. If the paper would like to claim this alignment score is not a suitable metric, then it needs to propose some new metrics. \n\nThe experimental environments have no overlap with GAMA. Therefore, it is not convincing enough that the method is better than GAMA.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is well-written and easy to follow.\n\nQuality: it has a self-contained framework and proposed a classic solution to the problem.\n\nNovelty: the novelty is limited, according to the weaknesses mentioned above.\n\nReproducibility: good. The source code is provided.",
            "summary_of_the_review": "Overall the paper clearly states the problem and the framework, which can inspire the readers. The following works can benefit from the view of the paper, which introduces the common state and action space.\n\nHowever, the novelty of the work is limited. The paper follows GAMA and combines more ideas in the domain adversarial learning. Therefore, I will weakly reject this paper and hope the author can improve the idea and the experiments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_737K"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4428/Reviewer_737K"
        ]
    }
]