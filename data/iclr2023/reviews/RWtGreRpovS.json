[
    {
        "id": "NoXzf-92JC",
        "original": null,
        "number": 1,
        "cdate": 1666389538402,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666389538402,
        "tmdate": 1669130270457,
        "tddate": null,
        "forum": "RWtGreRpovS",
        "replyto": "RWtGreRpovS",
        "invitation": "ICLR.cc/2023/Conference/Paper926/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Examines the utility of including a large number of parallel softmax operations, also called simplicial embedding (SEM), within a SSL method.  Includes theory showing improvements in generalization error bounds from using SEM, as well as extensive experimental evaluations showing benefits to classification, transfer learning, robustness to input corruption, as well as demonstrating interpretability of the SEM features (clustering by class).  The experiments also give insight on how to choose the number of simplices and the dimensionality of the simplex, as well as the temperature parameter.",
            "strength_and_weaknesses": "Strengths\n\n+ Simple idea with interesting connections to sparse coding (in neuroscience)\n+ Goes beyond looking at performance and also shows improved interpretability.\n+ Includes a theoretical analysis.\n+ Provides useful guidance on setting hyperparameters.\n+ Evaluations show benefits in several problems: classification (without and without corruption) and transfer learning.\n\n\nWeaknesses\n\n- Why are some of the competing methods doing so poorly?  Is the poor performance of BYOB+Gumbel on CIFAR-100 really due to SEM being a better method, or perhaps the Gumbel approach was not implemented as well as possible? [after rebuttal: addressed]\n- It would be nice to how changing the architecture affects results. [after rebuttal: addressed]\n- A minor weakness, but the use of softmax is so commonplace that it doesn't even seem to warrant a mention in related work.\n- The practical utility of the theoretical result is unclear.\n- As reviewer E9n7 and 4CQ8 noted, the baselines could be improved.  BYOL should be trained until convergence, and increasing the number of nonlinear layers or increasing the size of the network to match BYOL+SEM would be more convincing. [after rebuttal: addressed]\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality\n\nThis paper is really solid with regards to explaining the method and examining all the details of how to use it.  The experiments show benefits in many supervised learning tasks, but may need to use stronger baselines.  The theory is interesting but may not be practical.\n\n\nClarity\n\nThe paper is clearly written.\n\n\nOriginality\n\nSEM is conceptually similar to previous approaches, but somehow performs much better than them.",
            "summary_of_the_review": "This paper puts a lot of thought into presenting and analyzing a potentially high-impact addition to semi-supervised learning techniques.  The author's rebuttal addressed many concerns about the fairness of the comparisons and overclaiming. The impact of the technique (around 1-2 percent accuracy) would be interesting to a general audience but perhaps not at spotlight level.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper926/Reviewer_Jv3d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper926/Reviewer_Jv3d"
        ]
    },
    {
        "id": "Easvwq9qiJM",
        "original": null,
        "number": 2,
        "cdate": 1666484319401,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666484319401,
        "tmdate": 1668738878369,
        "tddate": null,
        "forum": "RWtGreRpovS",
        "replyto": "RWtGreRpovS",
        "invitation": "ICLR.cc/2023/Conference/Paper926/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes to apply a  subcomponent-wise softmax to SSL representations (z -> partition -> softmax -> concatenate -> new z), dubbed SEM. They empirically show that this simple transformation combined with a large increase in the dimensionality of the representation yields significant improvements in standard SSL benchmarks (in and out of distribution). They also try to explain the gains by providing generalization bounds of the downstream predictors.",
            "strength_and_weaknesses": "**Updated during rebuttal** the authors removed some strong claims and results showing that the gains are due to the proposed method rather than only increasing dimensionality of the representation. I thus update my score 5->8 .\n\n-------\n\n**Strengths**\n- **Paper is well written** the paper is generally easy to understand and enjoyable to read.\n- **Simplicity and generality** the main strength of the transformation is that it is simple and widely applicable. \n- **Significant empirical gains** the empirical results show uniformly significant gains across settings. Assuming that the baseline is indeed meaningful (see below), the results clearly indicate that the proposed method would be useful. \n\n**Weaknesses**\n- **Is the theory meaningful?** my main issue with the theory is that it might be meaningless and unrelated to SEM[^1]. Specifically, it seems that using the arguments of your theoretical section one would conclude that any transformation that shrinks the support of Z would be better. For example, let $f_{\\mathrm{new}}(z)=g(z/2)$ be a function that is defined like for SEM but the transformation is halving rather than SEM (other transformations like relu also works). Then if I followed your definitions you would essentially[^2] have $\\psi_{f_{new}} - \\psi_{f_{base}} \\leq 2V - 4V = -2V < 0 $. Using the rest of your arguments you would thus conclude that \"halving representation provably leads to better performance\".  You can further use a parameter $t$ instead of $2$ to say $\\psi_{f_{new}} \\to 0$ as $\\frac{1}{t} \\to 0$. For the theorem to be meaningful for SEM it should give rise to the same conclusion for any transformation just because it shrinks the support. Am I missing something?\n- (addressed in rebuttal) **Are gains only due to increasing dimensionality of the representations?** my main issue with the experimental results is that it is unclear to me whether the gains are only due to the increasing dimensionality of the representation rather than to the use of SEM. In particular, I think that your experiments and previous work show that: SEM+high dim helps, SEM only does not help, and high dim only helps. It is thus currently unclear what is the gain of SEM. More specifically: \n    - **Previous papers show similar gains by only increasing dimensionality** [1] argues theoretically + shows empirically that increasing dimensionality of representations helps downstream performance. There figure 7c shows a monotonic improvement in embedding size similar to BYOL+SEM in your figure 3. The line of work on dimensionality collapse, eg, [2], also suggests that higher effective dimensionality of the representation should improve performance regardless of SEM.\n    - **Inadequate baseline** As just mentioned [1] finds a significant monotonic improvement when increasing dimensionality without SEM while your baseline doesn't. I think that the problem is that the baseline you are using does not actually increase the effective dimensionality of the representation. Indeed, your embedding layer is linear (linear layer + BN) and as a result, it cannot increase the dimensionality of the span of the representations (ie you are only increasing the ambient space but not the real/effective dimensionality). To bypass this issue [1] increases the dimensionality before the avg pooling layer (see Appx F1). Another standard way of increasing the dimensionality of representations of resnets which can lead to significant gains is to change the pooling layer (eg see [this code](https://github.com/facebookresearch/vissl/blob/main/configs/config/benchmark/linear_image_classification/imagenet1k/eval_resnet_8gpu_transfer_in1k_linear.yaml#L65) ). For this reason, the current figure 3 does not adequately support the hypothesis that SEM is what drives the performance up.\n    - **SEM without increasing dimensionality seems to show no gains** BYOL + SEM without increasing dimension in Figure 3 seems to perform similarly to standard BYOL (table 17), thus suggesting that SEM without increasing dimensionality does not help.\n - (addressed in rebuttal) **Some over overclaiming**\n    -  in the abstract, you say \"we formally prove that the SEM representation leads to better generalization than normalized\". This is a strong claim, which I do not think is supported given that you only show one upper bound is smaller than the other (without a discussion about their tightness). To support such a statement you could for example provide a lower bound on the generalization gap of $f_{\\mathrm{base}}$ and show that it is larger than the upper bound of $f_{\\mathrm{ERM}}$\n    - section 4.2 you say \"Figure 5 [...] allowing us to confirm two predictions made in Section 3.2: the expected generalization [...]\". Your experiments do not actually test the generalization gap of the probe (as suggested by your theory) but the general test performance. One potential explanation (which would be my guess) is that the training performance of the linear probe is actually what drives the performance up (due to the increase of dimensionality) rather than the shrinking of the generalization gap. I think that showing the generalization gap is needed if you want to make any claims about the relation between your theory and experiments. Another way of testing your claims would be consider the standard \"semi-supervised\" setting where the downstream probe uses only 1% of ImageNet. My guess is that your representation will perform worst there (due to the high dimensionality) while your theory would suggest that it actually performs better due to the sparsity.\n\n[^1] Note that I haven't read all appendices in detail. If the argument breaks please refer me to the exact line and I will look at it.\n\n[^2] I removed $\\delta$ for conciseness but the argument still holds with those.\n\n[1] [Improving Self-Supervised Learning by Characterizing Idealized Representations](https://arxiv.org/abs/2209.06235)\n\n[2] [On Feature Decorrelation in Self-Supervised Learning](https://arxiv.org/abs/2105.00470)",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**: The paper is generally clear, easy to understand and enjoyable to read. My only concern in this respect is that the theoretical section is not understandable using only the main paper. Indeed one of the components of the theorem ($\\psi$) is not even defined in main paper. I think that all terms in the main results should be defined in the main paper.\n\n**Quality**: as discussed in the weakness the theory does not seem meaningful and the main claim of the paper (usefulness of SEM) is not appropriately supported. \n\n**Novelty** the proposed method is novel\n\n**Repredocuability** hyperparameters and code is provided.",
            "summary_of_the_review": "The paper is enjoyable to read and could be impactful if the author's main claim (usefulness of SEM) holds. My main issue with the current version is that I have doubts about: (1) whether the theory is meaningful; (2) whether the gains are due to SEM rather than increasing the dimension of the representation. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper926/Reviewer_4CQ8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper926/Reviewer_4CQ8"
        ]
    },
    {
        "id": "rnAuSnk8uf",
        "original": null,
        "number": 3,
        "cdate": 1666510533646,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666510533646,
        "tmdate": 1669534412557,
        "tddate": null,
        "forum": "RWtGreRpovS",
        "replyto": "RWtGreRpovS",
        "invitation": "ICLR.cc/2023/Conference/Paper926/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper suggests using simplicial embedding (SEM) -- instead of the standard R^d embedding -- as the feature for self-supervised learning and downstream classification. Specifically, given $L*V$-dim feature, SEM applies softmax operation for each $V$-dim subvector and concatenates the sparsified vectors. The paper claims the superiority of SEM theoretically and empirically. First, the paper provides a new generalization bound where the complexity measure $\\varphi$ is determined by the type of final representation. Here, the paper claims that the complexity measure of SEM is strictly smaller than the one of standard R^d embedding. Second, the paper demonstrates that SEM improves the classification performance of various self-supervised learning methods.",
            "strength_and_weaknesses": "**Strength**\n\nThis paper makes a good attempt to validate their claims, providing a theory and empirical evidence. For example, the paper provides an ablation study on the size of $L$ and $V$, a comparison with hard discretization, and an analysis of semantic coherence. The overall presentation was well-written and supported by proper evidence.\n\n---\n\n**Weakness**\n\nWhile the paper suggests an interesting alternative to designing an embedding, my biggest concern is whether future research would really use this technique. Here are some reasons why its practicality is not convincing yet.\n\n* **Weak baselines.** The paper shows an improvement over underfitted BYOL trained for 200 epoch (IN acc.: 70.6) instead of standard 800 epoch (IN acc.: 74.3). Since many methods converge faster but saturates eventually (or even collapse later), the paper should provide the results at 800 epoch. Also, this repo (https://github.com/HobbitLong/SupContrast) shows that SimCLR trained on CIFAR-100 shows acc. of 70.7, although they use ResNet-50, which is 5% higher than this paper. Thus, the overall baseline results are undervalued, and the gain of this method can be exaggerated. Providing the results in the SOTA setup would make the benefit of SEM more convincing.\n\n* **CIFAR-10 results.**\nThe paper only demonstrates the CIFAR-100 results instead of more standard CIFAR-10. I suspect that SEM is less effective for CIFAR-10. Still, it would be informative if the paper provided CIFAR-10 results in Appendix. How can we explain this if SEM is less effective for few-class classification? Discussion for coarse vs. fine-grained classification would be informative.\n\n* **Heavy computation.**\nAs the paper mentions, SEM needs an additional layer to expand the embedding overcomplete, which requires many parameters, memory, and computation. Although Table 17 in Appendix suggests an efficient version, it still uses 2~3x of parameters. Due to this, the actual baseline should be BYOL with some additional nonlinear layers instead of the vanilla BYOL.\nI appreciate that the paper shows that naively adding the overcomplete layer to BYOL does not work, as shown in Figure 3. However, I think a better way to sell this method is to emphasize the scaling part -- instead of adding an overcomplete layer (which may be arguable for a fair comparison) -- achieving SOTA using very-wide models would be more impactful. For example, current self-supervised learning (SSL) methods achieve SOTA on models like ResNet-50 x4. If the paper claims that prior work does not scale for larger models such as ResNet-50 x16 but SEM can, it could be a game changer.\n\n* **Why self-supervised learning (SSL)?**\nWhile the paper targets SSL, the idea of SEM could also be applied to supervised learning. Why the paper's scope should be SSL? Would SEM be more effective for SSL than supervised learning?\n\n* **Comparison with a mixture of experts (MoE).**\nConceptually, SEM may be thought of as a simple instantiation of MoE [1] or MCL [2] where each $V$-dim subvector is routing the specialized feature for each class. The bipartite in Figure 6 shows the learned features are indeed specialized to some classes. Here, the MoE technique is popularly used to train large-scale models. Since one major benefit of SEM is robust training on larger overcomplete features, it may discuss the relation to MoE and may show superiority over them.\n\n[1] Fedus et al. A Review of Sparse Expert Models in Deep Learning. arXiv 2022.\\\n[2] Guzm\u00e1n-rivera et al. Multiple Choice Learning: Learning to Produce Multiple Structured Outputs. NeurIPS 2012.\n\nTypo:\n- Gubel -> Gumbel in the caption of Table 2.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good.\\\nQuality: Good.\\\nNovelty: Good.\\\nReproducibility: Good. It clearly states the base codebase and provides code in the supplementary.",
            "summary_of_the_review": "Overall, I think the paper has a clear contribution. However, I'm on the borderline since empirical evidence is not convincing enough. I'm willing to raise my score if my concerns are addressed:\n- ImageNet results comparing with BYOL in 800 epoch\n- CIFAR-10 results and explanation of why SEM is more effective for many-class classification\n- Results on wide models such as ResNet-50 x16 instead of adding overcomplete layer\n- Discussion on why SEM should be used for SSL - why not supervised learning?\n- Comparison with MoE methods - would SEM be a better way to scale large models?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper926/Reviewer_E9n7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper926/Reviewer_E9n7"
        ]
    },
    {
        "id": "TS058GPVyQ",
        "original": null,
        "number": 4,
        "cdate": 1666530722597,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530722597,
        "tmdate": 1668728938359,
        "tddate": null,
        "forum": "RWtGreRpovS",
        "replyto": "RWtGreRpovS",
        "invitation": "ICLR.cc/2023/Conference/Paper926/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In self-supervised learning (SSL), a representation is learned and it is usually one multi-dimensional vector. This paper proposes an effective representation using multiple sparsified embeddings (SEM) inspired by over-complete representation. It is obtained by projecting the SSL embedding into multiple smaller dimensional vectors each through a softmax operation. The sparsity of the smaller vectors can be controlled via the temperature parameter in the softmax function. The author gives theoretical analysis on the benefit of using SEM and also conducts extensive empirical experiments. The results show the superiority of the proposed method. ",
            "strength_and_weaknesses": "Strength: \n\nClarity and quality of writing. Extensive experiments.\nThe paper is well written with a pretty clear introduction of background and related work. I also like how the author draws inspirations from the over-complete representation literature to motivate the proposed method. The experimental results show both quality improvement (with reasonable computation increase) and interpretability improvement.\n\nOriginality. The work seems pretty novel to me. \nPractical application: Being aware of the increased memory usage from SEM, the author also studies how to efficiently reduce memory usage at inference time. \n\nThough the findings in the proposed work is largely based on prior work in SSL, the SEM idea is pretty interesting and effective (observation from the empirical results).\n\nWeakness:\nQuestions to the author(s):\n\n1. Regarding Figure 5 (a), or effects of increasing $L$. Have you investigated when the improvement of accuracy starts to diminish if we further increases $L$ (e.g, increase $L$ to 20K, 50K)?  A larger number of basic vectors could be very helpful in defining finer granularities in some applications.\n\n2. Could we increase the embedding dimension in BYOL to achieve the similar quality improvement as achieved by SEM?\n\n3. Is the BYOL metric in Figure 1 a strong baseline? This is not something I am familiar with. Please clarify.\n\n4. After SSL embedding is obtained, one usage of the SSL embedding is to perform clustering to obtain needed level of granularity and interpretability. Let's say we cluster the embeddings into 5K groups. And also on the other hand, we have the SEM embedding (when L= 5K), what would be the pros and cons of the two approaches ?\n\nI will be willing to increase my score once the questions above are well clarified/explained.",
            "clarity,_quality,_novelty_and_reproducibility": "See clarity/quality/novelty above.\nReproducibility:\nThe author includes very extensive descriptions of their experiment setup in the appendix and provides code in the supplemental maternal. I believe it will be sufficient to reproduce their work.\n\nMinor comment:\nAppendix D.1: the last line at page 24, \"the $ of parameters\" should probably be change to \"the # of parameters\".\n\n",
            "summary_of_the_review": "The author proposes a simple yet effective component to build more interpretable and more effective representation. The experiments are solid and extensively demonstrate the effectiveness of the method. There, I think it is a good paper - \"accept\".",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/a",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper926/Reviewer_u5uQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper926/Reviewer_u5uQ"
        ]
    }
]