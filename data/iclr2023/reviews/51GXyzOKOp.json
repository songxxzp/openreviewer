[
    {
        "id": "mQ5FyXL_Qn",
        "original": null,
        "number": 1,
        "cdate": 1666551821243,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666551821243,
        "tmdate": 1666551821243,
        "tddate": null,
        "forum": "51GXyzOKOp",
        "replyto": "51GXyzOKOp",
        "invitation": "ICLR.cc/2023/Conference/Paper2225/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper sets out to analyze the influence of attributed graph elements on the changes of parameters in a Graph Convolutional Network under Simple Graph Convolution, without having to go through retraining. The derived influence functions are capable to estimate changes caused by the removal of nodes or edges from the graph. A theoretical analysis provides bounds on the errors of such estimation.",
            "strength_and_weaknesses": "Strength:\n- Novel theoretical results.\n- Experimental verification over the retraining case.\n\nWeakness:\n- Limited to removals operations.\n- Unclear and biased concept of rectification.",
            "clarity,_quality,_novelty_and_reproducibility": "The work makes a tangible and well-presented contribution in the field of GCN training.",
            "summary_of_the_review": "This paper sets out to analyze the influence of attributed graph elements on the changes of parameters in a Graph Convolutional Network under Simple Graph Convolution, without having to go through retraining. The derived influence functions are capable to estimate changes caused by the removal of nodes or edges from the graph. A theoretical analysis provides bounds on the errors of such estimation.\n\nIt is not clear why the conducted analysis should be limited to removal operations.\nOther operations, such as addition, or rewiring under some invariant, may also be studied to derive a complete framework.\nPotential missing elements or predicted elements of a network are also candidate for such analysis.\nIn particular, it is not clear why the proposed concept of graph recitification should only involve removals.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_Jtg1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_Jtg1"
        ]
    },
    {
        "id": "uQqIWaq4HV1",
        "original": null,
        "number": 2,
        "cdate": 1666560772286,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666560772286,
        "tmdate": 1666560772286,
        "tddate": null,
        "forum": "51GXyzOKOp",
        "replyto": "51GXyzOKOp",
        "invitation": "ICLR.cc/2023/Conference/Paper2225/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes extending influence functions-- a method from statistics that approximates the change of parameters or loss functions, with respect to removing or modifying training instances -- for using them in GNNs. As typical GNNs usually involve non-linear activation functions that make derivations of formulas difficult, a simplified version of them, called SGC, is used. SGC is essentially a GNN stripped of all non-linear functions. Hence, the learnable weight matrices collapse to a single matrix that transforms a smoothed version of the adjacency matrix, A^k. For each edge and node, the authors calculate the influence of them (positive or negative) in the loss function. Based on this they propose two applications, graph rectification and graph poisoning, where their method can be useful.",
            "strength_and_weaknesses": "Strengths:\n* The use of SGC allows the use of influence function in the context of GCNs.\n* Despite its simplicity, it seems that results with respect to graph poisoning, can be transferred\nto other architectures with non-linearities, like GCN from Kipf et al.\n* Theoretical bounds on the error of approximation are also provided.\n\nWeaknesses:\n* The use of SGC essentially transforms the problem to that of deriving the influence function of a convex optimization problem.\nHence, what is important in this context is the graph structure itself and the smoothness parameter $k$. I didn't see them being involved in a clear and intuitive way in the paper. E.g. for which types of edges their influence function is higher/lower, or is it difficult to approximate? What is the effect of the smoothness parameter $k$ in the results?  It is difficult to see how Thm 4.1 provides any intuition to this direction.\n* There is no mention of the running time (both actual and in asymptotic notation) of calculating the influence functions for each edge/node in the graph. \n* There is a line of work, e.g. a paper from [NeurIPS 2021 ->\" Robust Counterfactual Explanations on Graph Neural Networks\"] or [KDD 21->\"Counterfactual graphs from Explainable Classification of Brain Networks\"], that identify a set of edges that removing them will change the prediction. Maybe the authors could compare with those in terms of indentifying influential edges (in the extreme positive/negative range).",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of quality and clarity, the paper is in general well-written with minor typos. There are also sufficient experiments performed and an explanation of the setting used. Of course more should be done here: 1. Provide explanation on why some nodes or edges appear as outlines in Figure 4., or if there is a pattern for which edges/nodes are important (e.g. bridges/articulation points are they important?).\n In terms of originality, the paper is to the best of my knowledge the first to study influence functions, that became popular due to Koh & Liang, in GNNs. The fact that SGC is used as an exemplar GCN allows to re-use older results that do not involve the typical nonlinearities that exist in other GCN architectures. As a side note, results also assume additivity of incluence functions. I wonder the impact of this as there is dependency in graphs. E.g. if two edges connect two communities, based on the assumption: $\\mathcal{I}(-x_i, -x_j) = \\mathcal{I}(-x_i) + \\mathcal{I}(-x_j)$ then potentially the impact of removing just one is minimal compared to removing both.",
            "summary_of_the_review": "I think this paper as it is falls within the threshold line. From one point the application of influence functions to GCNs is interesting with first promising results. On the other hand, though, little explanation is provided to the results (besides the accuracy of the method). Moreover, there is no mention at all on the running time and comparison with other methods that collect set of edges for counterfactual graph explanation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_pmjX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_pmjX"
        ]
    },
    {
        "id": "OFHjrO6omh",
        "original": null,
        "number": 3,
        "cdate": 1666637006355,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637006355,
        "tmdate": 1666637006355,
        "tddate": null,
        "forum": "51GXyzOKOp",
        "replyto": "51GXyzOKOp",
        "invitation": "ICLR.cc/2023/Conference/Paper2225/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a method to quantify and estimate how various components of graph neural network models will be affected by node/edge removals in the training set. In particular, the authors derive influence functions for the Simple Graph Convolution (SGC) architecture. The authors provide rigorous theoretical results, including error bounds on the estimated change vs. the actual effect of node/edge removals. A case study on adversarial attacks on graph neural networks showcase a very relevant application of the proposed method.",
            "strength_and_weaknesses": "Strengths:\n- Novelty. Interpretability of graph neural network models is an open area of research, and, to the best of my knowledge, influence functions have not been explored before for this task.\n- Rigorous theoretical bounds on estimation error, and reasonable empirical results that show that theoretical bounds are relevant in practice.\n- Practical significance. The authors illustrate that their proposed method can be used against / for adversarial attacks.\n- Paper is very well-organized, and the authors stay focused on the task at hand.\n\n\nWeaknesses:\n- Gap between theory and practice. The paper focuses on SGC, presumably because it is easier to derive theoretical results for this model. SGC is not as popular as other graph architectures, such as GCN and its many variants. It is also not clear how the proposed method would work in the presence of skip connections, different normalizations, such as LayerNorm, or the myriad of enhancements that are commonly used in modern graph neural network models. As such, there is a gap between the methods proposed in the paper and application. However, this is to be expected of a first exploration of influence functions for GNNs.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: I think this is a high-quality paper. The authors address an important, challenging open question in the GNN literature. And they do so by adapting a well-founded method.\nClarity: This is one of the clearest and focused papers I have reviewed this year (out of 16 papers or so). It is clear what problem the authors are trying to solve and how they plan to solve it. Many papers I have read recently try to do too much and go in too many differen directions, and the main idea gets lost.\nOriginality: The application of influence functions for this task is novel to the best of my knowledge.",
            "summary_of_the_review": "Please see the two sections above. Based on those sections, I believe this paper should be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_9bmE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_9bmE"
        ]
    },
    {
        "id": "yjNooQZPkW",
        "original": null,
        "number": 4,
        "cdate": 1666720862302,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666720862302,
        "tmdate": 1666720862302,
        "tddate": null,
        "forum": "51GXyzOKOp",
        "replyto": "51GXyzOKOp",
        "invitation": "ICLR.cc/2023/Conference/Paper2225/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a methodology to leverage influence functions toward estimating how GNN model parameters change under graph perturbation schemes. This is an important problem to efficiently understand the effect of graph elements on model parameters, without the need to retrain the model. Specifically, the paper considers edge and node removals as perturbation strategies, deriving theoretical bounds to characterize the changes on model parameters. Besides, it is empirically shown how to utilize such graph influence functions to (i) improve the prediction performance, and (ii) as tools to guide adversarial attacks to the GNN.",
            "strength_and_weaknesses": "*Strengths:*\n* Leveraging influence functions to analyze the performance of a GNN constitutes an interesting theoretical framework. \n\n* The paper provides a good experimental pipeline in which the influence scores of nodes and edges are utilized in different ways (e.g., to define attacks).\n\n*Weaknesses:*\n* The formulation of the methodology is done on the Simplified Graph Convolution (SGC) model. Although the paper states that their analysis could be extended to other GNN models, this does not seem to be straightforward. \n\n* Missing possible connections to related work and theory. One of the practical applications of influence functions considered in the paper, examines how edge removals could improve classification performance. To do so, edges with negative influence are removed from the graph before training the SGC model. \n\n  First, what is the fraction of edges that are being removed, and how is the performance affected if we increase/decrease the number of deleted edges? \n\n  Second, how is this methodology related to other approaches that remove edges towards building more robust models? For instance, it has been shown that a simple random edge removal could improve performance by reducing over-smoothing (the DropEdge model). Is this something contradictory to the theoretical results presented in the paper? This point needs further clarification to understand the impact of edge influence scores.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is well-written, and the different concepts are clearly presented. At the same time, the paper keeps a good balance between theoretical contributions and empirical evaluation.  Despite building on existing ideas, the paper studies a novel application of influence functions in GNNs.\n\nTypos:\n* Page 4: Proposition 3.2 offer*s\n* Section 5.4: Table 3 is not mentioned in the paragraphs of the subsection. \n",
            "summary_of_the_review": "Overall, the paper introduces an exciting approach to further understanding the impact of graph components on the performance of the model. Nevertheless, I still have some concerns about the practical application of the framework (restricted or not to SGC) and its relationship to previous developments (e.g., DropEdge).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_Lyjj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2225/Reviewer_Lyjj"
        ]
    }
]