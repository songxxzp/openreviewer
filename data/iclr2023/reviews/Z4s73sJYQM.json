[
    {
        "id": "NqSoyYm-TE",
        "original": null,
        "number": 1,
        "cdate": 1666275425983,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666275425983,
        "tmdate": 1666275425983,
        "tddate": null,
        "forum": "Z4s73sJYQM",
        "replyto": "Z4s73sJYQM",
        "invitation": "ICLR.cc/2023/Conference/Paper5418/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes latent PDE learning with novel autoencoder-type losses.\n",
            "strength_and_weaknesses": "\ns: this paper has excellent and effortless writing that demonstrates both clarity and expertise. I enjoyed reading this manuscript a lot! I also like how the paper makes does a transparent discussion of the training difficulties/annoyances\n\ns: the idea is sensible, and turning the latent state into parameters of the decoder is elegant, which conceptually marries latent dynamics with operator learning. The construction of eqs 6-9 is very clever.\n\ns: the results are good, and sufficiently elucidated\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nClarity excellent. Quality excellent. Novelty high. Reproducibility ok.\n",
            "summary_of_the_review": "\nThis is an excellent paper with refreshing, new ideas on this domain, good enough results and excellent writing.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_mB8q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_mB8q"
        ]
    },
    {
        "id": "eAoLoc3YqD5",
        "original": null,
        "number": 2,
        "cdate": 1666336215670,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666336215670,
        "tmdate": 1666336215670,
        "tddate": null,
        "forum": "Z4s73sJYQM",
        "replyto": "Z4s73sJYQM",
        "invitation": "ICLR.cc/2023/Conference/Paper5418/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method to model dynamical systems in a latent space in a smooth way. To go back and forth from the latent space, a decoder (called \"ansatz\") and an encoder network are used, that are task dependent. One first trick proposed in the paper is to propose some cyclic consistency for this encoder decoder, so that both latent->state->latent and state->latent->state should be identity functions. This is advocated to help for the smoothness of the latent variables.\nThen, the core contribution of the paper in my view lies in the fact that the latent variables are not seen as an input to the decoder, but rather as encoding the *weights* of a network (in an hypernet way),  that inputs the coordinates (time, space) and outputs the value (nerf-style). This is advocated as yielding a much more powerful representation.\nThe rest of the paper is busy with describing important learning tricks and describing experiments.",
            "strength_and_weaknesses": "As a set of strength, I can say the paper is first useful for the not so knowledgeable reader to get references in the field. Then, the proposed method looks original to me, with its two nice contributions (cyclic losses, hypernet decoder). The method seems to be applicable even when the number of trajectories is quite limited (1000 here apparently). It was a nice read and I recommend it for publication.\n\nAs weaknesses, I could mention:\n* The experiments look quite weak to me. I understand that great care was taken on this, but I basically wonder about real world usecases, which I cannot see here.\n* I wonder about how critical is the choice of the decoder. The fact is that the chosen Fourier-based decoder looks pretty appropriate for the datasets at hand (figure 4), but it may be that the system would collapse for other kinds of dynamic data. Would there be some guidelines regarding what kind of decoder are appropriate or some ablation studies on that ?\n* Likewise, even assuming a Fourier-based decoder, the choice of the frequencies look mysterious and I wonder whether their choice needs a lot of care. Why are they not trained ?\n* Table 1 is not satisfying at all. I would have preferred some objective assessment of the encoder/decoder experiments, instead of this \"working/not working\" thing. What does \"working\" mean exactly anyways ?\n* I don't understand the \"spatial energy spectra\" as a metric. Could you please explain it differently ? ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is very clear. I am not an expert in the field but it looks original enough even if the body of literature in latent space modeling is huge. It looks a bit difficult to reproduce the whole set of experiments, unless some care is taken regarding an accompanying github repo, which I could not check.\n\nNo typo I could spot. In the caption of table 2, replace \"number of NFE\" by just \"NFE\"",
            "summary_of_the_review": "I liked the paper and the approach looks promising to me, puting together some cyclic consistency idea for latent space modeling as well as nonparametric hypernet decoders.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_haAi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_haAi"
        ]
    },
    {
        "id": "tplcV9qnqj",
        "original": null,
        "number": 3,
        "cdate": 1666557909426,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557909426,
        "tmdate": 1666557909426,
        "tddate": null,
        "forum": "Z4s73sJYQM",
        "replyto": "Z4s73sJYQM",
        "invitation": "ICLR.cc/2023/Conference/Paper5418/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a latent representation of dynamic systems by proposing an autoencoder framework specialised to PDEs. The authors motivate and introduce several components for the loss functions such as reconstruction, consistency as well a single step pre-training. Good performance is demonstrated on several examples. ",
            "strength_and_weaknesses": "__Strengths__:\n- Interesting idea on how to make use of latent variables for dynamic data.  \n- The idea is well thought out in several aspects, e.g. different loss functions, simpler pretraining, the smooth dynamics etc.\n- The performance seems good across tasks\n- Comprehensive list of relevant work\n\n__Weaknesses__:\n\n- On a high level, the idea of producing latent trajectories to encode temporal data has been present for some time and was also discussed in the original neural ODE paper, which doesn't seem to be mentioned here. But it is also only a very high level connection. ",
            "clarity,_quality,_novelty_and_reproducibility": "__Clarity and Quality__:\n\nThe paper is generally well written and easy to follow. There are some minor issues as listed below:\n\nIn the introduction the authors say \n\n> Those systems have slow-decaying Kolmogorov n-width that hinders standard methods,\n\nHowever, I could not find any further details in the text?\n\n- The word \"Ansatz\" is sometimes capitalized, sometimes not. \n\n__Novelty__:\n\n- I am not familiar enough with the literature to comment on novely.\n\n\n",
            "summary_of_the_review": "The paper has several positive aspects and seems to be thought out well. Empirical results are promising, so I am tending towards acceptance.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_WMEw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5418/Reviewer_WMEw"
        ]
    }
]