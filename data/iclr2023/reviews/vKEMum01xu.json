[
    {
        "id": "kIwiveUYfTn",
        "original": null,
        "number": 1,
        "cdate": 1666588766774,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666588766774,
        "tmdate": 1669875525158,
        "tddate": null,
        "forum": "vKEMum01xu",
        "replyto": "vKEMum01xu",
        "invitation": "ICLR.cc/2023/Conference/Paper3363/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to use key points as internal representations of scenes and model forward dynamics with graph interaction networks. The authors used a multi-object manipulation testbed for evaluating the proposed Keypoint Interaction Network (KINet). They show that KINet can achieve similar results for forward prediction compared with a baseline graph model with ground truth object positions. The authors also show that KINet converges to the goal configuration faster than baselines and generalizes to unseen circumstances where the number of objects, geometries, and background textures are unseen during training.",
            "strength_and_weaknesses": "[+] The paper proposes to extract object key points as representations for modeling forward dynamics. Such an unsupervised learning setting could be treated as a starting step toward many more research areas.\n\n[+] The experiment section is well-organized with not only an evaluation of the future prediction but also a manipulation task.\n\n[-] One major concern lies in the novelty of this paper. The current method shares the same insight as in previous works like OP3[1] and V-CDN [2] since they both adopt an unsupervised key point/mask detection and then a graph message-passing paradigm for solving the dynamics learning problem. Compared with methods, this paper's novelty seems incremental as they can also handle the generalization to an unseen number of objects. The authors should consider adding proper comparison with these two methods as baselines to make a point on the significance of the current model design.\n\n[-] Meanwhile, the currently selected datasets seem simplistic and fail to illustrate the potential of the model on more complex scenes. Under this setting (2D overhead or top view), the results fail to show the effectiveness of model design (e.g. deterministic vs. probabilistic). The authors should consider settings that better justify the significance of their design, especially when other methods showed more complex scenarios like morphing clothes.\n\n[-] A minor question lies in the design for keypoint detection. Why is the current detector taking as input the pair ($I_0$,$I_t$) but not the more common one ($I_{t-1}$, $I_t$)? I don't see a clear advantage in this design since the model will be required to start prediction from a random initial configuration and always comparing with the initial state will cause trouble in long-horizon planning or prediction (i.e., forgetting in long future predictions).\n\n[1] Veerapaneni et al., \"Entity Abstraction in Visual Model-based Reinforcement Learning\", CoRL 2019.\n[2] Li et al., \"Causal Discovery in Physical Systems from Videos\", NeurIPS 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written and easy to follow. However, the novelty of this paper is incremental as supported by the points in the strengths&weakness section. The paper seems to provide sufficient details for reproducing the experiments.",
            "summary_of_the_review": "This paper focuses on learning keypoint-based representations for modeling the forward dynamics of a system. However, the proposed method shares similarity with previous works and the design choices seem to have limited significance as shown in a synthetic dataset setting. Therefore, I don't recommend this paper for acceptance for now. I suggest the authors polish the experiment section and design better experimental settings to show the significance of their method compared with the baselines mentioned in strengths&weakness.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_gVjw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_gVjw"
        ]
    },
    {
        "id": "mMcmpTtGRHR",
        "original": null,
        "number": 2,
        "cdate": 1666621985304,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621985304,
        "tmdate": 1666621985304,
        "tddate": null,
        "forum": "vKEMum01xu",
        "replyto": "vKEMum01xu",
        "invitation": "ICLR.cc/2023/Conference/Paper3363/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an unsupervised framework to learn object-centric representation via keypoint representations. The model abstract the object by keypoints and form a graph representation, where the edges model the relationship between the nodes. An action-conditioned forward model is also learned using contrastive estimation. Experiments are conducted on the rearranging task in MuJoCo as well as a real robot dataset.\n",
            "strength_and_weaknesses": "Strength:\n- The idea of combining keypoint abstraction with unsupervised representation learning is novel and the learned forward makes downstream applications like task planning possible.\n- The experiments show that the proposed model can achieve high accuracy in forward prediction and the real robot execution task.\n\nWeakness:\n- Model design. While combining keypoints and object-centric learning is new, It\u2019s not clear what would be the benefits of choosing a coarser representation as opposed to a denser latent representation. The keypoints abstraction is a bottleneck of the proposed framework, especially in more complex settings or environments. It\u2019s also not obvious how the number of the keypoints $K$ will affect the model's performance as it\u2019s essentially an environment/dataset-dependent hyperparameter. The reconstruction model $f_{rec}$ also depends on $K$. It remains to be seen how the model will perform with more cluttered backgrounds.\n- Discussion about more related work. [1] is also a probabilistic object-centric and action-conditioned video prediction model, and interactions between entities are also modeled. [2] Introduces \u201cvelocity\u201d and physical interaction and may also be used in modeling action-aware object-centric representations. What are the key differences between the proposed model in terms of the advantages and disadvantages in both representation discovery and forward prediction? \n[1] Veerapaneni R, Co-Reyes J D, Chang M, et al. Entity abstraction in visual model-based reinforcement learning[C].\n[2] Kossen J, Stelzner K, Hussing M, et al. Structured object-aware physics prediction for video modeling and planning[J].\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality: I find the paper writing and logic flow clear and easy to follow. \n\nNovelty: The novelty of the proposed model primarily lies in the keypoint abstraction and the interaction network. More justification are expected for why it\u2019s a promising direction.\n\nReproducibility: Implementation details are not provided in the paper. Code is not included.\n",
            "summary_of_the_review": "My ratings are given based on my evaluation of the strengths and weaknesses above. More justifications are expected in the keypoint-based abstraction and distinction with prior work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_85iU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_85iU"
        ]
    },
    {
        "id": "qmWGGKxapHD",
        "original": null,
        "number": 3,
        "cdate": 1667528289535,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667528289535,
        "tmdate": 1667531398038,
        "tddate": null,
        "forum": "vKEMum01xu",
        "replyto": "vKEMum01xu",
        "invitation": "ICLR.cc/2023/Conference/Paper3363/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a method that learns dynamics models from object-centric representations in manipulation settings. This method is unsupervised and can generalize to different numbers of objects, unseen object shapes and unseen backgrounds. They demonstrate the effectiveness of this forward models by applying it to downstream robotics control tasks with a graph MPC algorithm.",
            "strength_and_weaknesses": "Strengths:\n1. This paper presents a method to learn unsupervised forward models that can be generalized to different number of objects.\n2. The method is straightforward and easy to understand.\n\nWeaknesses:\n1. In the related work section, authors mention that Kipf et al.(2019) is very relevant to your method. Kipf(2019) is also unsupervised and doesn't require ground-truth object locations. Could you include this method as part of the baseline as well?\n2. Another natural baseline would be Minderer et al.(2019), which also learns a dynamics model base on unsupervised keypoint representations.\n3. One of the main contribution is the probabilistic graph representation enabled by the learned adjacency matrix. The insight behind this design is that keypoints that are closer in the space could provide redundant information. However in the visualization of the adjacency matrix(supplement A.2.1), I can't reach to a conclusion as in what's being learned in these graphs. Can you provide more explanation and experiments to prove that this design is essential to the method(other than KINet-deterministic)?\n4. I am curious how would the method perform with more keypoints. If there are similar number of keypoints and objects in the scene, each object is only represented by one or two keypoints. Since each object is only represented by their keypoints, is one or two keypoints enough to capture the pose and orientation information?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n1. Overall the method and experiments are clear.\n\nNovelty:\n1. This method looks very similar to Ye(2020). The main difference in the object representation learning part is that in Ye(2020), they require the ground-truth object locations. The main difference in the forward model part is the probabilistic graph representation. I am not entirely convinced that the novelty is crucial. Presenting more comprehensive baselines and experiments may help. ",
            "summary_of_the_review": "This paper presents a new method on unsupervised learning of forward models based on probabilistic graph representations. I am not convinced that the novelties presented in this method are crucial. Presenting more comprehensive comparison to existing methods and other suggested baselines may help.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_2bb6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_2bb6"
        ]
    },
    {
        "id": "Tv9ezUoF_S",
        "original": null,
        "number": 4,
        "cdate": 1667604667062,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667604667062,
        "tmdate": 1670290646001,
        "tddate": null,
        "forum": "vKEMum01xu",
        "replyto": "vKEMum01xu",
        "invitation": "ICLR.cc/2023/Conference/Paper3363/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present Keypoint Interaction Network (KINet) - an unsupervised learning method to associate keypoints with objects and uses a forward motion model to estimate future keypoint states. As an unsupervised method, the authors make no assumptions about access to ground truth semantic keypoint locations, but rather just use image observations and actions.",
            "strength_and_weaknesses": "Strengths:\n\n- Not needing ground truth keypoints is an obvious win. It should make this method usable in multiple setups.\n- The keypoint extraction and graph association are object agnostic, meaning that the method should generalize to unseen objects and scenes. That is, the keypoints have no specific semantic encoding that would cause generalization to fail to other classes of unseen objects.\n\nWeaknesses:\n\n- The fixed \u201cK\u201d in the keypoint detector seems particularly problematic. If K is overcomplete (i.e. just some huge value) for describing the intrinsic degrees of freedom of an object, you could argue that perhaps a fixed K is OK, but generally, for articulated or deformable objects, you might not know a priori the \u201cK\u201d value that is needed to fully recover the pose of an object. Another argument to make is that the k-dimensional feature map is just yet another hidden layer of a larger network (that happens to include the graph representations) - in which case it\u2019s probably a stretch claiming these are semantic keypoints at all.\n- Related to above, the authors claim that the K representation is a bottleneck, however how much of a bottleneck seems to be very much dependent on the value of \u201cK\u201d.\n- Addition of the contrastive loss seems like a tacked-on solution and the authors need to do a better job describing what problem it solves (or what additional regularization it adds). The ablation where it is removed seems fine, but this alone is not enough to justify its use.\n- The class of objects the proposed method is evaluated on seems particularly limiting. The real-world results are all roughly rectangular shapes on a consistent background with minimal occlusion (there\u2019s some slightly more complicated shapes in the sim experiments, but even these are simple from an appearance perspective). I would like to see how this method performs on more complex scenes with background clutter and even on articulated or soft-bodied objects. Why is this not unreasonable or out of scope for this paper?: because the promise of this unsupervised method is that it works on any objects without needing semantic labels, however these experimental results fall short of showing that IMO. By contrast, for THIS particular application, you could very likely do simple heuristics to get a set of keypoints that would probably work just as well (e.g. color centroids, etc).\n- Nit: The Fig 2 real-robot data does not feel like \u201crobot data\u201d to me (I work primarily in robotics). There\u2019s no robotic embodiment visible in the frame, no active perception, etc. For instance a human could have moved the objects between frames. This is a perfectly fine computer vision dataset, but I think it\u2019s a stretch to claim it\u2019s somehow robot data. 5.2 presumably uses a robot (with MPC on your forward model) to actually move the objects, so why isn\u2019t this visible in the frames?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and easy to follow. Reproducibility seems high (although would be even higher if the source code and simulation data is released - but I didn\u2019t see that mentioned anywhere in the paper).\n\nExperimental results - while limiting (see above) - seem well carried out and of high quality (e.g. multiple seeds with sigma values given).\n\nOriginality of the work: There is some novelty in the graph formulation as far as I know. Unsupervised keypoint detection for use in dynamics modeling has certainly been done a few times at this point (e.g. the cited paper Manuelli et al., Keypoints into the future). However I think there\u2019s enough novelty here to justify the submission.",
            "summary_of_the_review": "Overall the paper seems novel and is well written. It is likely to be of interest to the community, however I do find the experimental results to be somewhat underwhelming (hence the final score). I\u2019d like to see more real-world examples with more complex object and scene appearances.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_E8Ms"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3363/Reviewer_E8Ms"
        ]
    }
]