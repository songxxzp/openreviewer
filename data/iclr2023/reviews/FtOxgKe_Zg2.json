[
    {
        "id": "KFm3nzXn0m",
        "original": null,
        "number": 1,
        "cdate": 1666662608178,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662608178,
        "tmdate": 1666662608178,
        "tddate": null,
        "forum": "FtOxgKe_Zg2",
        "replyto": "FtOxgKe_Zg2",
        "invitation": "ICLR.cc/2023/Conference/Paper4213/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed an approach to improve zero-shot prediction results by making a language model predict the instruction (or measure likelihood) given the label and the input, rather than having the model predict the label instead. The paper demonstrates the effectiveness on multiple datasets within the BIG-Bench benchmark. ",
            "strength_and_weaknesses": "Pros:\n\nThe simplicity of this approach is a plus. The avoidance of label overfitting due to FLIP is also a nice advantage with additional benefits on unseen labels.\n\n\nQuestions:\n- Any additional thoughts on why unlikelihood training is crucial for the success of FLIPPED?\n\nCons:\n\n- It is not surprising that the meta training done will make 3B model outperform larger models. The statement that the model performs better compared to 175 or 540B models do not mean much and such statement should be avoided or with caveats mentioned explicitly. To compare with the larger models, it would be good to see the few-shot results without meta training. Or is it the case that FLIPPED does not work at all without meta training? \n- In approach makes sense, however, I still question the universality of this approach. The free-form generation of label being one. \n- Another strong baseline for tasks with unseen labels is to add label explanation in the instructions. \n- Performance gain is observed for some datasets but not overwhelmingly consistent.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is quite well written\n\nQuality: A good amount of experiments are done to demonstrate the applicability\n\nNovelty: Low to moderate. (low novelty is fine if the method is simple and really work well)\n\nReproducibility: Due to the simplicity, if should be quite easy to reproduce.",
            "summary_of_the_review": "Overall, this paper proposes a simple approach consisting of the flipped inference along with the unlikelihood meta training that seems to work well. The experiments are quite extensive. The performance gain is not too consistent so while this method might work in some domain, it might be challenging to be adopted as a universal method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_dMHf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_dMHf"
        ]
    },
    {
        "id": "l6hYVQHjAw9",
        "original": null,
        "number": 2,
        "cdate": 1666663583088,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663583088,
        "tmdate": 1666663583088,
        "tddate": null,
        "forum": "FtOxgKe_Zg2",
        "replyto": "FtOxgKe_Zg2",
        "invitation": "ICLR.cc/2023/Conference/Paper4213/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new meta-training approach for language models. For an instance of task instruction, input and label, their method, called Flipped Learning, increases the likelihood of the task instruction given the input and correct label, while decreasing the likelihood of the task instruction given the input and an incorrect label. Training a T5-3B model with this method on 20 datasets leads to performance gains on various datasets compared to larger (size and compute) models.",
            "strength_and_weaknesses": "### Strength\nComputing the conditional probability of instruction given the concatenation of the input and label has led to strong zero-shot generalization performance. It is mentioned that this is due to the model\u2019s better generalization to labels that it has not seen before (labels that have different surface form, but similar meaning). \n\n### Weaknesses\nAs the authors mention these as well, their proposed training method is limited to tasks which have label options (vs. free-form generation). This would limit the approach in both training and inference/evaluation. It is also not always the case that one could have a task instruction that is easily separable from the input instance. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well-written and easy to follow. Just a few comments:\n* The reason as to why Flipped Training improves label generalization is not very clear. Why would conditioning on a label avoid overfitting on it?\n* What percentage of the labels in the tasks from Big-Bench and the other 14 English NLP tasks are not seen?\n* The unlikelihood loss in section 3.2 could benefit from an example for more clarity. \n* It would also be interesting to see how the model after Flipped Training performs on non-classification tasks? Is it going to be worse or better? Any thoughts on this?\n",
            "summary_of_the_review": "Overall, the approach of conditioning on the label space instead of generating it is interesting, but limited. The motivation for this method could have been discussed more. Some parts about the intuition of why the method increases label generalization are not clear.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_CFao"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_CFao"
        ]
    },
    {
        "id": "zeXfj7NQLH",
        "original": null,
        "number": 3,
        "cdate": 1666803163046,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666803163046,
        "tmdate": 1666803354874,
        "tddate": null,
        "forum": "FtOxgKe_Zg2",
        "replyto": "FtOxgKe_Zg2",
        "invitation": "ICLR.cc/2023/Conference/Paper4213/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper focuses on the zero-shot task generalization setting and proposes to learn to generate the instruction conditioned on the input and label. During inference, labels can be predicted by checking which label is the most likely to generate the given instruction. The authors also incorporate unlikelihood training loss to overcome the degeneration issue where the label becomes uncorrelated with the instruction generation. Such a reversed way of generation achieves very good results on multiple unseen tasks, outperforming the T0 baseline. Notably, a 3B T5 model trained with the proposed method even outperforms T0-11B on 14 BIG-bench tasks and much larger GPT3 and PaLM in zero-shot settings. Analysis shows that the proposed method is mainly beneficial for tasks where the label options are unseen during training.",
            "strength_and_weaknesses": "### Strengths\n\n1. The proposed method is novel and neat\n2. The empirical results are strong demonstrated by a comprehensive set of experiments. As a new way of instruction tuning, FLIPPED could be potentially very impactful given that it outperforms much larger models with much smaller training costs.\n3. The analysis is interesting and insightful, revealing that T0-like methods have difficulties generalizing to unseen label options while FLIPPED does a pretty good job. \n4. The paper is well-written.\n\n### Weaknesses\n\nAs mentioned in the Limitation section, FLIPPED is only naturally applicable to classification tasks where the label space is limited, while DIRECT methods appear to be more flexible from this aspect. \n\n\n### Suggestions\nWhen presenting the main results, I think the authors should clarify FLIPPED outperforms DIRECT on X out of X datasets. The gains are actually not very consistent in the Tables and the mean accuracy does not tell the full story.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written, the proposed method is novel, the experiments are well-documented and should be reproducible.\n",
            "summary_of_the_review": "I recommend acceptance of this paper since the proposed method is novel and simple and achieves very strong results on impactful benchmarks. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_55Bv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4213/Reviewer_55Bv"
        ]
    }
]