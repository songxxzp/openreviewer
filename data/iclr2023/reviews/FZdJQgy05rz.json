[
    {
        "id": "M_k33N5ydwq",
        "original": null,
        "number": 1,
        "cdate": 1666253245027,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666253245027,
        "tmdate": 1669307726943,
        "tddate": null,
        "forum": "FZdJQgy05rz",
        "replyto": "FZdJQgy05rz",
        "invitation": "ICLR.cc/2023/Conference/Paper5741/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a method of estimating the Bayes' error of a class of models for binary classification. They compare the estimation with datasets with multiple human annotated labels to compare the estimated Bayes error with an empirical estimate of the Bayes error. ",
            "strength_and_weaknesses": "## Strengths\n\n- The authors provide many rigorous proofs to support their claims. \n- The empirical results provide further support, showing bias where expected, etc. \n\n\n## Weaknesses\n\n- Theorem 2.2 is introduced from previous work without much context around why it is useful or important for this work. It would be helpful to the reader to provide some context of where and why it will come into play later in the text. \n\n- Until section 3, there is no mention of where the soft labels come from. It seems that the soft labels would have to be soft labels that are given from the true distribution of the data, which it seems would be impossible to attain in most realistic circumstances. Although, this is explained later, I think it would reduce reader confusion by at least alluding to this fact and that it will be dealt with later.\n\n- Section 3, paragraph 3: Why can uncertainty labels not recover $p(y = +1 | \\mathbf{x})$ from $\\min_{y \\in \\pm 1}p(y | \\mathbf{x})$? If one has access to one, doesn't it guarantee we know the other? If $\\min_{y \\in \\pm 1}p(y | \\mathbf{x}) = 0.1$, then isn't $p(y = +1 | \\mathbf{x}) = 0.9$ If this is a subtle misunderstanding about the meaning of soft labels and uncertainty labels introduced in Section 1, then I think there needs to be more time devoted to explaining those concepts in detail.\n\n- Theorem 3.3 seems to show that if one has a noisy corruption of the true class of an instance, then $\\hat{\\beta}$ is an unbiased estimate of the Bayes error. Later on in page 4, the authors state \"In practice, one idea is to ask many labellers for each instance and then use the histogram of the hard labels as a noisy soft label.\" Therefore wouldn't this just produce an unbiased estimate of the Bayes error of the aggregated labellers, which is not in fact an unbiased estimate of the true Bayes error? For example, the estimated Bayes error of a ResNet on CIFAR-10H is higher than that of the human annotated $\\hat{\\beta}$ in figure 4. This might be an obvious point, but I still think it should be stated clearly somewhere in the text.    \n\n- It would be interesting to see the other baseline performances on something other than the toy dataset. For example, ensembles tend to not show much diversity in decision boundaries when considering toy datasets, and therefore often do not outperform simple MLP baselines by much. This changes when the dimensionality of the data increases. It would therefore be interesting to see what happens with the Bayes error of an ensemble of at least one of the network baselines in figure 4.\n\n\n## Minor\n\n- Page 4: reference error, \"which we use later on in Sec. ??\"\n- Page 8: reference error, \"(App. ??)\"",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n\nOther than minor points raised above, the text is clear. \n\n## Quality\n\nThe overall quality is good.\n\n## Novelty\n\nTo my knowledge, the findings presented are sufficiently novel. ",
            "summary_of_the_review": "Overall, I feel positive about the results presented in the text. I raised a number of points above, and I look forward to hearing the responses from the authors regarding the points raised. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_bzQr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_bzQr"
        ]
    },
    {
        "id": "FXB3gHX-m9S",
        "original": null,
        "number": 2,
        "cdate": 1666590163605,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590163605,
        "tmdate": 1666590163605,
        "tddate": null,
        "forum": "FZdJQgy05rz",
        "replyto": "FZdJQgy05rz",
        "invitation": "ICLR.cc/2023/Conference/Paper5741/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a simple estimator for Bayes error in binary classification. The authors are able to show several properties of the proposed estimator including unbiasedness and some convergence guarantee. Experiments on synthetic datasets, CIFAR-10, and Fashion-MNIST show the effectiveness of the proposed estimator. \n",
            "strength_and_weaknesses": "Strength: The proposed estimator is simple to implement. Also it is nice that the authors show some guarantee of the proposed estimator.\n\n\nWeakness: I feel the proposed estimator does not really resolve the core of the Bayes error estimation. For the theory part of the paper, e.g., Theorem 4.1 and Proposition 4.2 and 4.3, the assumption is r_i= p(y=+1|x_i) is known. But to me this is actually the core and hard part of Bayes error estimation, since given r_i one can easily get the Bayes estimator. \n\n\nIn the empirical section of the paper, p(y=+1|x_i) is estimated using deep models, but as we all know from the uncertainty estimation literatures, deep models are not doing a good job calibrating their output scores to p(y=+1|x_i), and their outputs are usually highly screwed. As a result I am not quite sure how I should trust the estimated Bayes error.\n\n\nExperiments are also kind of lacking. I only see two real-world datasets used. To fully show empirically the proposed estimator work I would like to see more numbers on other datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of the draft is clear to me. The proposed estimator is simple and straightforward. I am not sure if it has been proposed before or not. \n",
            "summary_of_the_review": "Overall I feel the work is an interesting try and it does show some promising preliminary results. But as I stated in the weakness section I do have some serious concerns. The assumption that p(y=+1|x_i) is known is so strong that the problem is not interesting any more in theory. In application, the work does not propose convincing ways of estimating p(y=+1|x_i) either. And the experiments are not extensive either. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_5ZHz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_5ZHz"
        ]
    },
    {
        "id": "Cf8M_xLTYrd",
        "original": null,
        "number": 3,
        "cdate": 1666665263381,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665263381,
        "tmdate": 1666665278820,
        "tddate": null,
        "forum": "FZdJQgy05rz",
        "replyto": "FZdJQgy05rz",
        "invitation": "ICLR.cc/2023/Conference/Paper5741/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an instance-free and model-free Bayes error estimation method for weakly supervised data. It leverages the fact that the expectation of the (perfect) predicted probability is the unbiased estimator of the Bayes error. Further, in a more practical and general case where the noises exist, the estimator is asymptotically unbiased. The authors also studied one case where only positive data and their confidence are available, and they show the error is also bounded. ",
            "strength_and_weaknesses": "Strengths: \n- The concept is conceptually simple and well-motivated. \n- The presentation is clear overall. \n- The experiments involve ``real-world'' scenes which may bring practical interest\n- The proposed estimators works (except on ViT and some datasets) better than other trained models in estimating the Bayes error. \n\nQuestions:\n- Some reference are missing. For example, page 4 has a ''Sec. ??'' and page 8 has a ''App. ??''. \n- One paper [1] might be worthy to discuss (and maybe compare) but seems to be missing. It is also a model-agnostic algorithm for estimating the Bayes error, although they require the access to instances. \n- I might be wrong but since human labeler are also imperfect, why is it not possible that ViT can outperform human in providing reliable confidence? \n\n[1] A Model-Agnostic Algorithm for Bayes Error Determination in Binary Classification",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is clear overall - some references need to be fix (see the above paragraphs). The novelty and quality are good. ",
            "summary_of_the_review": "The paper provides an interesting method for estimating the Bayes error that is conceptually simple but theroetically grounded. I believe it would be beneficial to the community and inspire future research.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_YXWn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_YXWn"
        ]
    },
    {
        "id": "frCQf6766eq",
        "original": null,
        "number": 4,
        "cdate": 1666708357403,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666708357403,
        "tmdate": 1669297298819,
        "tddate": null,
        "forum": "FZdJQgy05rz",
        "replyto": "FZdJQgy05rz",
        "invitation": "ICLR.cc/2023/Conference/Paper5741/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "To examine the intrinsic soundness of the classifier (maybe formulated as a deep neural network), this paper proposes a new method to estimate the limit Bayes error, where we just take the mean of the labels that show the uncertainty of the classes. The proposed method is claimed to be model-free and instance-free, and experimental results show its effectiveness. ",
            "strength_and_weaknesses": "Strengths: \n\n* This paper is well-written, and there are many mathematical formulations to formally illustrate the logic and soundness of the proposed method. \n* The experimental results seem promising. \n\nWeaknesses:\n\n* The proposed method seems simple. However, it is not clear in practice how a practitioner implements the whole method.\n\n* The method is supposed to be instance free. However, I still see that real instances would be desired in experiments.  ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well presented. But it would be favored if a flowchart of the whole method can be provided. ",
            "summary_of_the_review": "Please see the above analysis. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_Y3qe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5741/Reviewer_Y3qe"
        ]
    }
]