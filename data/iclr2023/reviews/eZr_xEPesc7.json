[
    {
        "id": "gIxsZaiKGe",
        "original": null,
        "number": 1,
        "cdate": 1666587549017,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666587549017,
        "tmdate": 1669617360429,
        "tddate": null,
        "forum": "eZr_xEPesc7",
        "replyto": "eZr_xEPesc7",
        "invitation": "ICLR.cc/2023/Conference/Paper5914/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes a new method to produce robust models by data augmentations that corrupt semantic information. Semantic corruptions power nuisance-avoiding methods to build robust models against spurious correlations without requiring extra annotations or strong assumptions. This paper analyzes semantic corruptions in powering different robust-modeling methods for multiple out-of-distribution tasks.",
            "strength_and_weaknesses": "Strengths:\n\nS1: This paper focuses on adjusting for spurious correlations, which is an important problem in reliable machine learning.\n\nS2: The main idea of adopting data augmentations corrupt semantic information to produce models that identify and adjust for spurious correlations is reasonable.\n\nS3: The experimental results and analysis look good.\n\nWeaknesses:\n\nW1: A few details are not very clear. How to control the data augmentation directions? How to identify and disentangle the corrupt semantic features.\n\nW2: I wonder what the semantic augmented data look like and it may be better to visualize them.\n\nW3: It might be interesting if the authors can provide experimental results on large-scale datasets like ImageNet with spurious cues.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of this paper is clear and easy to follow.",
            "summary_of_the_review": "This work is focusing on an important problem in reliable machine learning. The motivation of this paper is reasonable and the experimental results look good but there are a few detailed issues that need to be clarified.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_yHka"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_yHka"
        ]
    },
    {
        "id": "sCMW7dGth6j",
        "original": null,
        "number": 2,
        "cdate": 1666616931375,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666616931375,
        "tmdate": 1668947085656,
        "tddate": null,
        "forum": "eZr_xEPesc7",
        "replyto": "eZr_xEPesc7",
        "invitation": "ICLR.cc/2023/Conference/Paper5914/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a data augmentation framework that attempts to avoid spurious correlations (nuisance) in order to enjoy increased generalization. \nTo that end, the authors propose to corrupt the semantic signal in the input. If a model maintains a good level of prediction under these circumstances, it means the model relies on nuisance signals and is thus not robust. Achieving this through data augmentation is possible if nuisance and semantic signals in the inputs are well separable. The authors argue that one way to exploit signal separation is when: \n- local modifications of inputs does not change nuisance but harms semantics.  \n- semantic signal is position dependent (like organ positions in medical image inputs).\nThe authors leverage two random patch permutations (as data augmentation mechanisms) to exploit one of the above separation in practice.\n",
            "strength_and_weaknesses": "Pros : \n- The method is clear and addresses an important issue in deep learning\n- The approach is tested on various tasks\n- The method can be readily plugged into recent approaches from the literature\n\nCons : \n- The method applies only to data where positional information has an impact on semantics but not on nuisance\n- The methodological contribution needs to be validated by comparing to other data augmentation mechanisms that randomize inputs",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite well written and clear. It is also technically sound.\nThe contributions is fairly novel but limited to methological aspects. \nI might have missed it, but I haven't seen a link to the authors code.",
            "summary_of_the_review": "Major remarks: \n\nThe paper explains how to train a biased model using a method from the literature plus one of the introduced mechanisms. But the paper is too quick on how to exploit this biased model to avoid spurious correlations. Please add more information in this regard. Appendix A does not say more than the main text.\n\nThe proposed mechanisms belong to the family of random transformation type of data augmentation. Yet in the experimental section, no comparison with such alternative data augmentation mechanisms can be found. The authors should demonstrate that the positional information on which their augmentations rely is really a key aspect or if random cropping, random erasing or others might compete. \n\nIn Table 2, RM + NURD outperforms known nuisance + NURD for RM size 168. Is this normal ?\n\n\nMinor :\n\nStd deviations wrt the reported accuracies can only be found in the appendices. If paper length permits, I think it would be preferable to display them immediately. \n\nPage 2 : the authors start using mathematical notations that were not introduced before. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_fx5t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_fx5t"
        ]
    },
    {
        "id": "cjwQY57bMd",
        "original": null,
        "number": 3,
        "cdate": 1666712121359,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666712121359,
        "tmdate": 1669559920948,
        "tddate": null,
        "forum": "eZr_xEPesc7",
        "replyto": "eZr_xEPesc7",
        "invitation": "ICLR.cc/2023/Conference/Paper5914/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This article mitigates OOD issues in ERM with semantic corruption.",
            "strength_and_weaknesses": "Strengths:\n1. The proposed method is well analyzed with rich ablation studies.\n2. This paper validates the effectiveness of the method on multiple tasks.\n\n\nWeakness:\n1.  The writing of this paper needs polishing. I have a hard time understanding the expression of this paper.\n2.  to produces -> to produce. In addition, there are many such errors.\n3.  It is recommended to validate the effectiveness of the method on larger datasets.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is poor. The novelty is not that attractive. ",
            "summary_of_the_review": "Due to the poor writing of this article, it is difficult for me to follow what the author wants to convey.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_NEkh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_NEkh"
        ]
    },
    {
        "id": "SApTn_79s3",
        "original": null,
        "number": 4,
        "cdate": 1666811590664,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666811590664,
        "tmdate": 1669063280418,
        "tddate": null,
        "forum": "eZr_xEPesc7",
        "replyto": "eZr_xEPesc7",
        "invitation": "ICLR.cc/2023/Conference/Paper5914/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper shows a simple way to improve the performances of existing methods to avoid spurious correlations, which can be applied to all methods that rely on a bias model that predicts the labels using the nuisances in the data. \n\n \n\nThe authors propose to build the biased model by using transformations to the input data that are such that nuisances are preserved, but the semantic information (which is the one that should drive the classifier) is destroyed. Two types of transformation are considered: 1) permutation-based, which can be applied when only nuisances (and not semantic information) are still present when the input data is randomized; 2) mask-based, which can be applied if only nuisances are present in a subsed of the input data. \n\n \n\nExperiment show that the method successfully avoids spurious correlations when the biased model is constructed as explained above. ",
            "strength_and_weaknesses": "**STRENGTHS** \n\n1. The paper discusses a simple yet effective to generalize and improve existing methods. \n\n2. The performances reached in the experiments are close to then ones achieved when having labelled data for the nuisances. \n\n3. The method seems to be robust to the choice for the \"size\" hyperparameter, which makes it easier to be used in practice. \n\n \n\n \n\n**WEAKNESSES** \n\n1. I am not very convinced on the level of novelty of the paper. While I do acknowledge that the authors present a more unified view of existing methods by formally introducing semantics/separations, in practice many of the presented ideas have been already applied to the same or similar task (for example ROI-MASK in Puli et al, 2022). \n\n2. The two separations introduced in the paper work well with the benchmark datasets for this task. However I do not think they are generic enough in many real tasks, where there is no clear separation between semantics and nuisances, or no obvious data transformation to apply. \nROI masking is for example hard to apply in practice when relevant objects might be in very different parts of an image. \n\n ",
            "clarity,_quality,_novelty_and_reproducibility": "See section above.\n\n**CLARITY** \n\nThe paper is overall quite clear, however:\n \n1. Introduction and section 3.1: When describing global semantics vs local nuisances, your definition of \"global\" vs \"local\" is not very clear to me, I only understood what you meant through the examples you provided.  \n\n2. Section 2: none of the symbols used in the NURD paragraph is defined ($p_{tr}$, $p_{te}$, independence symbol, ..) \n",
            "summary_of_the_review": "This is overall an interesting work. However I have some concerns on the novelty of the presented ideas, as well as the applicability of the method in many real world applications.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_QvJV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5914/Reviewer_QvJV"
        ]
    }
]