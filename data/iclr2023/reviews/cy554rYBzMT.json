[
    {
        "id": "NrAprHft4H7",
        "original": null,
        "number": 1,
        "cdate": 1666393033405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666393033405,
        "tmdate": 1669247749262,
        "tddate": null,
        "forum": "cy554rYBzMT",
        "replyto": "cy554rYBzMT",
        "invitation": "ICLR.cc/2023/Conference/Paper2899/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the question of why trained deep convolutional networks are insensitive to image perturbations such as small translation and rotation. Through a set of studies on CIFAR-10, the paper argues that this is mostly due to spatial pooling and channel pooling, and the two components can be further decoupled at different layers. The paper then propose a simple synthetic task on which neural networks demonstrate similar behavior, and use this synthetic task to theoretically study the arguments made earlier. ",
            "strength_and_weaknesses": "**Strength**\n1. This paper identifies a clean question to study\n2. This paper includes code to reproduce the experiments\n\n**Weakness**\n1. The empirical studies are weak\n    1. The neural networks tested in this paper are very simple. Including some more modern networks would make the study more useful. At the minimum a deep resnet should be included, because skip connections are omnipresent in modern neural networks and it would be interesting to see how the arguments about the decoupling between filter and channel pooling behave with skip connections.\n    2. What happen to other networks if you do the same kind of analysis as in Figure 4? I could not find such results in the Appendix either.\n    3. It would be useful to add error bars to the plots (e.g. Fig. 3).\n    4. Please include more than one dataset so that we get an idea of how generalizable the observations are.\n    5. For many convnet architectures, the number of channels tend to increase at higher layers. In the experiments showing that lower layers are less sensitive to channel permutation, how does the number of channel impact the results? \n\n2. The synthetic tasks are specifically designed to encourage network insensitivity to translations, and in task 2 the neural network architecture (strides equals to filter size) is also tailored to match the task bias. I'm having a hard time to see how this analysis here could help understand what happens in the real world scenarios.",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper includes code for reproducing the results.\n- The paper is relatively easy to follow, though I do have some questions regarding the synthetic tasks and theoretical analysis:\n    1. The proof for Section 4.1 seems to rely on that the number of layers k and the image size L both being sufficiently large. Is there a characterization how large this needs to be have this statement reasonably accurate? In particular, does it match the same regime of the empirical studies on CIFAR-10 (k < 20, L=32)?\n    2. It is mentioned a few times in the arguments that the learned filters are non-negative, why is it the case?\n    3. Does the theoretical analysis apply equally well to a trained neural network and an untrained (randomly initialized) network?",
            "summary_of_the_review": "This paper studies the question of why deep convolutional networks are insensitive to image perturbations such as translation. I find the empirical studies weak and the theoretical studies need some explanations (see above) to both clarify the results and to make connection to the empirical studies. \n\n-------\nAfter rebuttal: thanks to the authors for additional experiments on ImageNet. This addition to the paper require another round of careful review. And my other concerns (e.g. regarding the parameter regime of the proof and the justification for the non-negativity) are not well addressed by the response. Therefore I'm keeping my original rating.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_x5ja"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_x5ja"
        ]
    },
    {
        "id": "WdrxxYwPtP",
        "original": null,
        "number": 2,
        "cdate": 1666447734743,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666447734743,
        "tmdate": 1666447734743,
        "tddate": null,
        "forum": "cy554rYBzMT",
        "replyto": "cy554rYBzMT",
        "invitation": "ICLR.cc/2023/Conference/Paper2899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The manuscript analyzes how convolutional neural networks (CNNs) process spatial information present in the images. The analysis builds on the observation in Petrini 2021 that performance of CNNs is correlated with their invariance towards diffeomorphisms, namely \u201csmooth\u201d transformations of the images,  and anti-correlated with their sensitivity to noise added to the images. The specific goal of this paper is disentangling the role of spatial pooling and channel pooling, operations which are at the basis of the working principle of CNNs. The analysis is performed using real data (CIFAR10) in Sec 2 and synthetic tasks in Sec 3-4. ",
            "strength_and_weaknesses": "Strengths:\n1.\tInvestigating the working principle of deep CNNs remains a topic of interest, and the manuscript sheds some light on the different roles of special and channel pooling\n2.\tThe results on the artificial task, section 3 and 4, are neat. In particular, the analytical derivation in section 4 is enlightening with respect to the manner in which noise is processed in a CNN\nWeaknesses:\n1.\tThe empirical results presented in support to the first \u201ccontribution\u201d, disentangling spacial and channel pooling, are not fully convincing. Fig 3 shows the changes in the sensitivity to shuffling the channel connections. The scale is linear in the left panel (AlexNet and LeNet) and log in the right panel (VGG) creating some confusion.  The change is claimed to be small in the first layers, but this change looks approximately 30 % also for very deep layers in VGG. Only in LeNet the change is clearly small (~ 5 %). Is 30 % small or large? Maybe a baseline should be defined. Moreover, the qualitative differences between the different architectures are not explained. Do they derive from the depth?\n2.\tFig. 4 illustrates the frequency content of the filters of the layers of a CNN at different depth. I do not understand why the curves do not all start from 1. Moreover, I do not understand what we learn from the time dependence of these coefficient.  The main message conveyed by this figure should be that deep layers (1-5) \u201cbecome low-frequency\u201d (while, I assume, late layers become high frequency). A better observable would possibly be the average frequency of the filter\\ sum_{kl} gamma_kl omega. I also have a problem with the interpretation of the frequency content as defined by eq. 3. The receptive field becomes larger and large with depth. Therefore, the same frequency in different layers corresponds to different physical lengths in the input image. Shouldn\u2019t the frequency be mapped in common units across the layers? I also do not fully understand why the observation that early kernels are \"low-frequency\" supports the claim that channel pooling happens late in the network. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is clear and well written. Maybe  devoting the first figure to the illustration of the results of another paper (Petrini 2021) is not fully appropriate and might be partially misleading. In my opinion the most relevant results are those of section 4, which is very squeezed (for example fig 9 is almost not discussed). ",
            "summary_of_the_review": "The manuscript provides some interesting and novel insight on the manner in which CNNs process the information. The analysis of a very simple synthetic dataset presented in section 3 and 4 is clear, while the analysis of CIFAR10 (section 2) is in my opinion not fully convincing. I think the contribution is valuable, but some points need clarification. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_eGsy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_eGsy"
        ]
    },
    {
        "id": "SmUBHfk926n",
        "original": null,
        "number": 3,
        "cdate": 1666634146257,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634146257,
        "tmdate": 1666634146257,
        "tddate": null,
        "forum": "cy554rYBzMT",
        "replyto": "cy554rYBzMT",
        "invitation": "ICLR.cc/2023/Conference/Paper2899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates the mechanism of spatial information loss in image classification networks. This loss in sensitivity to small perturbations in the input is important in learning robust invariant representations of features relevant to the task (image classification in this work). Authors propose that deep convolutional networks learn to first spatially and then channel-wise pool information as we go deeper in the network layer-by-layer. They support their claims with numerical experiments on the CIFAR-10 dataset on multiple architectures. Then, they construct some simple vision tasks, where the simplest solution according to human intuition is pooling, and they demonstrate that the above phenomena from image classification still hold. Finally, they quantify in this simple toy case how sensitivity to input diffeomorphism and additive white noise scales with network depth.",
            "strength_and_weaknesses": "Strengths:\n\n- The paper is organized and easy to follow. The structure is logical and the paper is mostly well-written.\n  \n- The problem the paper investigates is very interesting and is important in better understanding the success of modern deep learning. Overall, the motivation of the paper is clear.\n  \n\nWeaknesses:\n\n- In my opinion, the main claims of the paper are not well supported by the experiments. Based on a single small dataset (CIFAR-10) authors conclude that \"spatial and channel pooling are carried out along the whole network\", however it is not clear to me how authors arrive at this conclusion. The decrease in sensitivity to diffeomorphisms and increase to white Gaussian noise may be caused by some other factors not investigated in this paper. The proposed underlying reasons (different types of pooling at different depths) are a possible and logical explanation, but I don't see how this simple experiment proves this. I am also not convinced by the experiments disentangling the effect of the two types of pooling.\n  \n  - First, in Figure 3 right, in case of VGG11bn the gap between original and channel-shuffled models is already significant in early layers, and in case of VGG11 the gap is almost constant in the first 80% of the network. Overall, the presented evidence is not sufficient to conclude (especially based on a single small dataset) that channel pooling is not happening early in the network.\n    \n  - Second, the plots showing the frequency distribution of learned filters with respect to spatial pooling are difficult to make out. Authors claim that \"layers 2 to 5 become low-frequency with training\", however the lines are so close to each other that it is impossible to verify this. Probably presenting the distribution at t=0 and at end of training would be much easier to interpret, the exact values during training seem to be irrelevant to the paper. Moreover, even if the claim is true, why do we not see pooling at layer 1?\n    \n- It is not clear to me what is the goal of defining the scale-detection tasks. Authors concluded based on standard image classification that the phenomenon holds (early spatial pooling, late channel pooling). Then, they design a problem where our intuition suggests that pooling is the simplest solution, and we observe the phenomena again. I don't see what the scale-detection tasks add that we did not see in the image classification experiments.\n  \n- With respect to task 1, authors claim that \"Spatial pooling is the most direct mean to achieve such insensitivity\" with respect to sensitivity to diffeomorphism. This might be true based on our human intuition, but the learning dynamics of neural networks is not very well understood and this claim sounds too strong.\n  \n- The results on task 1 are not very convincing in Figure 7. In particular, it looks like VGG11's sensitivity to Gaussian noise is more or less constant over layers. The phenomenon seems to hold for networks with batch normalization only.\n  \n- The theoretical analysis is a bit confusing to me. What diffeomorphisms have been used? Why is the translation only 1 pixel? Why are filters necessarily non-negative?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is mostly well-written, however some parts need more clarification (see especially my last comment on Weaknesses).\nQuality: In my opinion, the experiments are insufficient in supporting the claims of the paper convincingly. Authors use very strong wording in many cases that is not completely justified by the experiments.\nNovelty: the direction of the empirical investigation is somewhat novel to the best of my knowledge, however the main phenomenon related to invariance to diffeomorphisms and sensitivity to noise has been investigated in prior work.\nReproducibility: code to reproduce the results has been provided.\nMinor comments:\n\n- typo in Introduction \"Here the inputs images\"\n  \n- typo in Section 1.2 \"in the context adversarial robustness\"",
            "summary_of_the_review": "Overall, I would lean towards rejecting the paper in its current state. I think the empirical evidence provided is not strong and convincing enough due to the reasons I have detailed above under 'Weaknesses'. Furthermore, the motivation for introducing the scale-detection tasks and the theoretical analysis is not clear to me.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_Zxqq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2899/Reviewer_Zxqq"
        ]
    }
]