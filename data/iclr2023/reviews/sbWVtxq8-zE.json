[
    {
        "id": "Dzxnj0myiZ",
        "original": null,
        "number": 1,
        "cdate": 1666130357167,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666130357167,
        "tmdate": 1666130357167,
        "tddate": null,
        "forum": "sbWVtxq8-zE",
        "replyto": "sbWVtxq8-zE",
        "invitation": "ICLR.cc/2023/Conference/Paper671/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method  for automated prompt generation using a combination of Language Models. It shows that certain source LM combinations are more succesful than others in outperforming autoprompts trained on single ML.  The paper also includes a thorough analysis of potential reasons.\n\nAdditionally,  the paper provides an overview of the currentpormting approaches and povides their comparison, describing the recommended areas of use and limitations.\n\nContributions:\n* a novel method for automated prompt generation from a mix of LMs\n* comparison of promtpting approaches\n* analysis of effects and limitations of the newly proposed method\n\nI think that in addition to the proposed method, the paper may serve as great practical reference on prompting methods so it has  a potential for citation and community impact in various aspects. ",
            "strength_and_weaknesses": "Strength:\n* introduced a novel method and clearly showed its benefits and limitations\n* thorough analysis of the potential underlying linguistic reasons (rather than treating as a black-box)\n* clear narration\n* comprehensive overview of related works\n* solid grounding for experimentation\n\nWeaknesses:\n* while the paper doesn't present break-through findings, it is a solid and sufficiently impactful research",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is excellent.\n\nMinor Observation:\nTable 2:  - please, indicate the used metrics in Table caption or title\n\n\nQuality\n* very rigorously performed study: from initial analysis of various approaches to prompting, to comparison of single LM-sourced eotoprompts to the introduction, comparison, and analysis of multi-LM-source autoprompts\n\n\nNovelty\n* the paper is original and novel\n* the novelty is moderate with solid experimental grounding\n\n\nReproducibility\n* to the best I could verify, it is reproducible",
            "summary_of_the_review": "It's an interesting solid paper with moderate novelty. Lean to accept",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper671/Reviewer_9ydY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper671/Reviewer_9ydY"
        ]
    },
    {
        "id": "zywvlr2roX",
        "original": null,
        "number": 2,
        "cdate": 1666365564474,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666365564474,
        "tmdate": 1666365564474,
        "tddate": null,
        "forum": "sbWVtxq8-zE",
        "replyto": "sbWVtxq8-zE",
        "invitation": "ICLR.cc/2023/Conference/Paper671/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies whether prompts that effectively extract information from a language model can also be used to probe other language models for the same information. The authors show that this is indeed not the case. They propose an approach to induce prompts by mixing language models at training time and show that in this\u00a0way they can generalize well across models. They evaluate on the slot-filling task which is good to investigate the knowledge contained in language models. They provide extensive analysis and insight into the generalization of these large language models and how to effectively\u00a0probe information from them.\n",
            "strength_and_weaknesses": "- The motivation of this paper is clear and a worthwhile topic to investigate. The experiment setup and settings are good and the evaluation is sound. The authors provide ample analysis on their findings.\n\n- The way this paper trains and evaluates, it would need to learn a different prompt for each relation in the slot-filling task. The authors use the original (manual) prompts provided by LAMA in their experiments. Isn't that limiting the findings? Have the authors looked into other prompt templates?\n\n- The authors look at three types of language models and various prompt induction methods. The model they choose however is on the [relatively] smaller side. Do the authors think model size and the number of parameters is also a contributor to how these models learn and output knowledge?  Have the authors looked into other bigger models and if not what is their hypothesis about these model's behaviour and how their findings generalize to larger models?\n\n- Table 3 shows that by simply mixing the models we would not achieve good generalization. Do the authors have a hypothesis why that's the case or have they looked further into it?",
            "clarity,_quality,_novelty_and_reproducibility": "This work is clearly written and the message is evident to the reader without any struggle. The experiments are sound and the quality of the work is well done. The novelty of this paper does not lie in developing new models, but rather investigating and understanding the behaviour of existing models. This is a valid and useful idea and it contributes to the field of research. ",
            "summary_of_the_review": "This work is well-motivated, clearly explained, and sufficiently supported by analysis. There are some questions for the authors (see section Strength And Weaknesses), however overall it's a valuable contribution to the field. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper671/Reviewer_FEH5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper671/Reviewer_FEH5"
        ]
    },
    {
        "id": "C6kVTahHseK",
        "original": null,
        "number": 3,
        "cdate": 1666667112471,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667112471,
        "tmdate": 1666667112471,
        "tddate": null,
        "forum": "sbWVtxq8-zE",
        "replyto": "sbWVtxq8-zE",
        "invitation": "ICLR.cc/2023/Conference/Paper671/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and semi-manual prompts on the slot-filling task, the authors demonstrate a drop in performance for AutoPrompt prompts learned on one model and tested on another. The authors introduce a way to induce prompts by mixing language models at training time the results in prompts that generalize well across models. The authors conduct an extensive analysis of the induced prompts, finding that the more general prompts include a larger proportion of existing English words and have a less order-dependent and more uniform distribution of information across their component tokens.",
            "strength_and_weaknesses": "Pros: The authors present a systematic study of the extent to which language models (LM) query protocols, that, following current\nusage, the authors call prompting methods, generalize across LMs.  The authors conduct the extensive analysis of automatically induced discrete prompts, tentatively identifying a set of properties characterizing the more general prompts, such as a higher incidence of existing English words and robustness to token shuffling and deletion. The paper is well-written and easy to understand. There are comprehensive experimental results presented by the authors.\n\nCons: The contribution of this paper to the new methodology for natural language processing is limited. As a result, the analysis in the paper is also limited by mainly utilizing the existing methods.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality of the paper is good. The novelty is moderate and the paper is easy to reproduce with the extensive provided resources and detailed descriptions.",
            "summary_of_the_review": "Please refer to the points in the above sections to improve the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper671/Reviewer_wUgX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper671/Reviewer_wUgX"
        ]
    },
    {
        "id": "6gIrhea3p5T",
        "original": null,
        "number": 4,
        "cdate": 1666876648450,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666876648450,
        "tmdate": 1666876862767,
        "tddate": null,
        "forum": "sbWVtxq8-zE",
        "replyto": "sbWVtxq8-zE",
        "invitation": "ICLR.cc/2023/Conference/Paper671/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper verifies whether automatically induced prompts can use the same information to apply to other models. It turns out that automatically induced prompts by AutoPrompt [Shin et al. 2020] outperforms manual and semi manual methods in slot-filling tasks, and verifies that automatically induced prompts can learn from one model and test in another, and the effect is not good. In addition, also found that more general prompts often contain some attributes.",
            "strength_and_weaknesses": "Strength: The paper is easy to follow.\nWeaknesses: the work lacks novelty, and one can barely find origin idea proposed in the paper. Although the detailed analysis seems to make some sense, the content seems not enough for a regular research paper, even for application track.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and the content is clearly delivered. However, the paper does not has its own model or theoretical idea. It's more like an technical report instead of a research paper.",
            "summary_of_the_review": "The paper verifies whether automatically induced prompts can use the same information to apply to other models. It turns out that automatically induced prompts by AutoPrompt [Shin et al. 2020] outperforms manual and semi manual methods in slot-filling tasks, and verifies that automatically induced prompts can learn from one model and test in another, and the effect is not good. In addition, also found that more general prompts often contain some attributes. The content of the paper is clearly stated, however, generally, the work lacks novelty. Although the detailed analysis seems to make some sense, the content is not enough for a ICRL research paper, even for application track. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper671/Reviewer_DprU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper671/Reviewer_DprU"
        ]
    }
]