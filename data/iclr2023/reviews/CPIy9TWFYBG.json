[
    {
        "id": "HJk5tJmTxe7",
        "original": null,
        "number": 1,
        "cdate": 1666414364472,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666414364472,
        "tmdate": 1668966956340,
        "tddate": null,
        "forum": "CPIy9TWFYBG",
        "replyto": "CPIy9TWFYBG",
        "invitation": "ICLR.cc/2023/Conference/Paper1361/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a proactive multi-camera collaboration method for 3D multi-person human pose estimation with unmanned aerial vehicles (UAVs). The method is based on multi-agent reinforcement learning that treats cameras as agents and utilizes a world dynamics model to improve the performance of the model. Specifically, by additionally predicting the dynamics of camera agents and humans, the paper is able to extract more useful features for the control of the camera agents. Inspired by prior work, the paper also proposes a collaborative triangulation contribution reward (CTCR) that uses the shapley value to improve the credit assignment of reconstruction quality to agents. The paper builds its own RL environment based on Unreal Engine 4 (UE4) where human crowds are simulated with collision avoidance in various scenes. Experiments in this environment demonstrate the superiority of the proposed approach over the baselines. Extensive ablation studies are also carried out to validate the design of the method.",
            "strength_and_weaknesses": "**Strength:**\n\n- The problem the paper aims to solve is interesting and challenging, i.e. reconstructing dynamic human motion in the wild where occlusions often happen and static camera formations are not sufficient to address them.\n- Extensive experiments and ablation studies are done in the simulated environment, which shows the method outperforms the baselines and also validates the usefulness of the proposed techniques.\n- The paper also plans to open-source the UE4-based RL environment used in the method, which would be beneficial to future research on proactive multi-camera human pose estimation.\n\n**Weakness:**\n\n- The method is not evaluated with safety metrics such as collision or interference with humans, which is rather important given the trajectory produced by the method could potentially harm the subjects.\n- The simulation does not consider the dynamics of real-world UAVs and many of the jittery trajectories produced by the method might not be realizable by UAVs.\n- A major concern of mine is that all the experiments are performed in simulation without real-world validation of the proposed approach. Given the method is potentially unsafe and the trajectories might be unrealizable, it is important to demonstrate its real-world applicability as prior work (e.g., AirCapRL) does.",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is generally well-written and easy to read.\n- The paper has good conceptual and technical novelty since it addresses a challenging new task with some new techniques such as CTCR and world dynamics learning.\n- The paper would be hard to reproduce without a full-release of the training code and pre-trained model given the difficulty in reproducing multi-agent RL experiments",
            "summary_of_the_review": "Overall, the paper presents an interesting approach to a challenging and useful problem. However, its evaluation is lacking, especially the real-world evaluation, which is very important given the safety implication and concerns in practicality.\n\n== After rebuttal\n\nThe authors' response addressed most of my concerns, so I updated my rating.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "The proposed algorithm might not produce safe UAV trajectories, and collisions could happen between humans and UAVs.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_W1S5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_W1S5"
        ]
    },
    {
        "id": "QUXFsymBcHD",
        "original": null,
        "number": 2,
        "cdate": 1666624452745,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666624452745,
        "tmdate": 1666624452745,
        "tddate": null,
        "forum": "CPIy9TWFYBG",
        "replyto": "CPIy9TWFYBG",
        "invitation": "ICLR.cc/2023/Conference/Paper1361/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper develops an active vision scheme where multiple non-stationary cameras reconfigure themselves to achieve high-quality 3D human pose estimation.  The camera control problem is cast within the multi-agent reinforcement learning framework.  The paper also presents a new reward formulation that incentivizes the cameras according to their weighted marginal contribution to the 3D human pose reconstruction quality.  This reward seems to address the multi-agent credit assignment issue.  The proposed model is trained within a 3D environment populated with lifelike pedestrians.  The model is jointly trained with world-dynamics-learning task; therefore, it exhibits anticipatory occlusion avoidance, improving the reconstruction accuracy.    ",
            "strength_and_weaknesses": "This is a well-written paper that studies an interesting problem.  The paper claim four \"key\" contributions; however, not all of these contributions have the same scientific or technological impact.  I suggest to divide this list into primary and secondary lists.  The key conributions, I feel, are: 1) problem setup and 2) the new reward formulation.  The engineering effort in setting up the 3D world that others can use for their own work seems to me a secondary contribution.\n\nWhen speaking of active camera collaboration schemes for scene analysis and pedestrian tracking and the use of 3D worlds to study such multicamera systems, the following work comes to mind \n\nSmart Camera Networks in Virtual Reality. Qureshi, F.Z.; and Terzopoulos, D. Proceedings of the IEEE (Special Issue on \"Smart Cameras\"), 96(10): 1640\u20131656. October 2008.\n\nThis is highly relevant to the work presented in this paper, and it should be cited in Multicamera Collaboration Section.  This work studies multi-camera control and uses a 3D world with autonomous pedestrians to develop and evaluate the camera coordination on the task of pedestrian tracking.\n\nIt may be useful to provide a more detailed caption for Figure 2.  Specifically, please define the variables not defined anywhere else.    \n\nIt will be beneficial to provide the number of dimensions for each variable used in equations 1 to 4.  I feel that this will increase the clarity of the proposed approach.\n\nIn Section 3.4 what is the difference between the future position of target person and the future position of pedestrians?\n\nI tried but failed to wrap my head around Eq. 6.  Perhaps it is possible to revise this discussion.  One possibility is to construct Eq. 6 term by term.  This equation deals with the reward for each camera, which, alongwith problem setup, I feel is one of the primary scientific contribution of this work. \n\nI was pleased to see that the paper includes a discussion about the limitations of the proposed method.  Perhaps this discussion should be expanded.  For example, it seems that this work assumes near-perfect camera calibration, wich is not always possible to achieve in practice.  It is especially hard to maintain the calibration of a group of cameras that move around.\n\nI was also pleased see the paragraph about the ethical consideration of using such systems.  I ask that this dicussion should be moved to the main body of the apaper.   It is too important to be relegated to the appendix.\n\nPlease use a different \"bibstyle.\"  As it stands it is tedious to connect a citation to its reference.\n\nThe paper asserts that the group of cameras learn occlusion-avoiding anticipatory behavior.  Actually this was one of the reasons why the model was also trained on world-dynamics-learning-tasks.  Perhaps there is a way to provide some results that support this claim. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written.  The work is novel in the sense that it proposes a new formulation for the control and coordination of a group of non-stationary cameras for the task of 3D human pose estimation.  The work suggests a large engineering effort---from setting up a 3D environment to training a large, non-trivial reinforcement learning model.  I like the fact that the paper promises to open-source the virtual environment and the visualization software. ",
            "summary_of_the_review": "This is an application paper.  It makes a number of technological contributions---the 3D environment, model, etc.  The paper also makes some scientific contributions---model setup and credit assignment strategy.  The paper will be of interest to the machine learning community.  It is particularly useful for those who are interested in multi-agent systems coordination problems where the individual agents rely upon vision as their primary perception modality.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_XxGE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_XxGE"
        ]
    },
    {
        "id": "TsOkynvB476",
        "original": null,
        "number": 3,
        "cdate": 1666624945525,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666624945525,
        "tmdate": 1666624945525,
        "tddate": null,
        "forum": "CPIy9TWFYBG",
        "replyto": "CPIy9TWFYBG",
        "invitation": "ICLR.cc/2023/Conference/Paper1361/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a multi-agent reinforcement learning approach with a Collaborative Triangulation contribution the credit assignment by using their weighted average marginal contribution for 3D human pose estimation in dynamic human crowds. The model is trained with multiple world dynamics learning tasks. The method is evaluated in four photo-realistic UE4 environments. The results show the proposed method outperforms the fixed and active baselines in different scenarios with various numbers of cameras and humans. ",
            "strength_and_weaknesses": "# Strength:\n- The proposed method novel in using multiple (>3) active cameras to perform 3D HPE in human crowd. \n- The proposed method introduces a decentralized framework via multi-agent reinforcement learning for multi-camera collaboration at different scales and scenarios (in simulated enviromnment). \n# Weakness:\n- The proposed approach relies on human recognition module to distinguish people in a scene. For some out-of-distribution human appearances, the current ReID module may not work, which will then hinder HPE task. \n- The practicality of the algorithm seems limited. To perform 3D human pose estimation, dynamic cameras seem quite difficult to deploy in real-time. \n",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity: \n- The paper is well written.\n# Quality: \n- The paper is technically sound, and the effectiveness of the method is empirically demonstrated on various scenarios. \n\n# Novelty:\n- The proposed method is the first one to use multiple dynamic cameras for HPE via multi-agent reinforcement learning framework. \n\n# Reproducibility: \n- The source code of the environments used in the experiments are provided. ",
            "summary_of_the_review": "The paper introduces a novel dynamic multi-camera collaboration framework via multi-agent reinforcement learning to solve the 3D Human pose estimation problem. The paper is clearly written and well-structured with strong empirical evaluation in various simulated scenarios and conditions. One potential drawback of the proposed method is the practicality of the dynamic multi-camera deployment in real-world environments. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_eqPb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_eqPb"
        ]
    },
    {
        "id": "0Mdf4a4QC_w",
        "original": null,
        "number": 4,
        "cdate": 1666649146136,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649146136,
        "tmdate": 1666649173924,
        "tddate": null,
        "forum": "CPIy9TWFYBG",
        "replyto": "CPIy9TWFYBG",
        "invitation": "ICLR.cc/2023/Conference/Paper1361/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper describes a method for active (cameras can move proactively) multi-camera motion capture. The problem is formulated under multi-agent reinforcement learning framework, where the authors propose a new reward (Collaborative Triangulation Contribution Reward) to  incentivize agents according to their weighted average marginal contribution to the 3D reconstruction. The proposed method is evaluated on UE4 environments, where the method has demonstrated notable improvements over baseline, and competing methods.\n",
            "strength_and_weaknesses": "\n\n# Strength\n- The methodology is clearly motivated, and I found it quite novel to use multi-agent reinforcement learning for multi-camera motion capture.\n- The method is extensively evaluated with plenty of experiments and analysis.\n- The proposed virtual environment also seems a very useful tool, and can facilitate future research in the direction if this can be open-sourced.\n\n# Weakness\nThough it's a very interesting work, I am mainly concerned with two aspects: generalizability, and the understanding of the learned policy seems limited.\n- **Generalizability**: as the model training seems only possible with virtual environments, and the real world can exhibit significant gaps with such environments, e.g. different body motion, different type of occlusion etc, it's not clear whether the learned policy can be generalizable to real environments. The experiments in Fig7 are helpful, I think it would be better to also add an upperbound model (\"ours\" trained/finetuned in the same environment) to get a sense of how the model is impacted by the domain gap. Nevertheless, I think the experiment only provides a partial view, still more evidence (e.g. experiments on real datasets) may be needed to validate the generalizability.\n- **Understanding of the learned policy is limited**: I appreciate the amount of experiments provided. But still it is not fully clear what is actually learned by the policy and why it is better than the baseline. It would be helpful if authors can provide more statistics/analysis on the behavior mode of the agents and visualizations. Besides, it would also be useful to provide experiments with more cameras until the performance gap between fixed cam/learned policy is closed. (I would expect with more cameras, it will spread out to cover most views, thus the improvement from a learner polocy can become marginal)\n\n# Other questions\nI have also several minor questions, would be good if the authors can discuss them:\n- wrt 3.1 Action Space, why rotation is limited to 2D and there is no roll?\n- wrt fig6, there is a sudden increase in error for MAPPO at 5-6 human, it would be interesting to understand why this happens, and to provide some illustration to demonstrate the error mode. Also, would be useful to provide the same visualization for MAPPO + RLPred to understand why RLPred is so helpful in such cases.\n- wrt 3.2 Perception Module, it can be helpful to provide an ablation study on used 2D pose models, and see how the errors in 2D pose would impact the learned policy. Currently it's not very clear whether the policy learned to encourage collaboration among cameras, or it's more encouraging camera to be at a view more optimal for 2D pose model. Would be interesting to provide some results with GT 2D pose (from virtual environment), and some cross results to test the generalization ability (e.g. learned from GT 2D pose, test with yolo v3 etc.)\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\n\n### Clarity\nThe paper is clearly presented, I also appreciate that plenty of details are given. \n \n### Novelty\nAs also mentioned above, I found it quite novel to use multi-agent reinforcement learning for multi-camera motion capture.\n \n### Reproducibility\nThough I am not confident that the work can be reproduced 100% without available implementation as a reference, overall I am satisfied with the amount of details given.\n",
            "summary_of_the_review": "\n\nOverall it's an interesting work. The methodology is clearly motivated, and I found it quite novel to use multi-agent reinforcement learning for multi-camera motion capture. Also, the method is extensively evaluated with plenty of experiments and analysis. \n\nI have some concerns regarding generalizability of the method, and that the understanding of the learned policy seems limited. But none of my concerns are deal-breakers and I hope to discuss those in the rebuttal. \n\nOverall I believe it's a decent contribution, and I would recommend it for acceptance.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None to the best of my knowledge.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_FtmL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1361/Reviewer_FtmL"
        ]
    }
]