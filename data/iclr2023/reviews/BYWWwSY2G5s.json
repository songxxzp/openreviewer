[
    {
        "id": "letWdofeIW",
        "original": null,
        "number": 1,
        "cdate": 1666301041983,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666301041983,
        "tmdate": 1670365939933,
        "tddate": null,
        "forum": "BYWWwSY2G5s",
        "replyto": "BYWWwSY2G5s",
        "invitation": "ICLR.cc/2023/Conference/Paper5122/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work examines the problem of continuous-time discrete diffusion models, and the paper mainly focuses on 1) extending the existing discrete-time discrete diffusion models to the continuous-time via stochastic jump processes, 2) extending the score function to generic categorical variables and deriving a score-matching based learning for the model, 3) different sampling methods for the reverse process. Experimental validations on synthetic data, image and music generation have shown promising results comparing to existing discrete-time and continuous-time discrete diffusion models.",
            "strength_and_weaknesses": "*Strengths*\n\nI think this work studies an interesting problem and it is nice to see the authors take the effort to extend the score functions to the categorical data and manage to leverage it to derive a score-matching based objective for estimating the continuous-time diffusion models. The main idea of using score-based objectives instead of ELBO surrogates is well-motivated, and the related works are properly referenced.\n\nThe authors have tried many different parametrizations and a new design for the conditional marginals, and it is also nice to see the proposed score-based learning naturally introduces a new analytic sampling algorithm. Experiments with toy 2-D datasets, CIFAR-10, and monophonic music dataset show the soundness of the proposed method, and the results are competitive with previous state-of-the-art methods. \n\n\n*Weaknesses*\n\nThe presentation is on the weaker side, and I think the paper can be significantly improved by having better clarity.\n- The authors extend the ratio test proposed in Hyvarinen (2007) to the categorical variables but point to equation (14) as the \"score-matching\" objective. However, it does not resemble those used in Hyvarinen (2007) or Song et al. (2020). It would be better if the authors could discuss the relationship of the proposed objective to the classic ones.\n- It would be nicer if the authors could discuss more regarding the similarities and differences from Campbell et al. (2022). For example, is there any subtle difference between the derivation of the continuous time modeling in Section 3.1 and those in Section 3.1 in Campbell et al. (2022)? Also, comparisons between the learning objectives would also make it easier to understand the benefits of the proposed method.\n\nThe parametrization of the conditional marginal distributions. Even though the authors have tried to design an efficient structure through different architecture choices including the hollow transformers, the current design is more computationally demanding comparing to existing methods and prevents it from directly modeling the CIFAR10 data with resolution as small as 32x32, not to mention other datasets with higher resolution. So that it is not easy to perform an apple-to-apple comparison with existing work.\n\nThe experimental validations are not very convincing. Two benefits of the proposed method are discussed in the introduction, including 1) the continuous-time discrete diffusion formulation is more flexible comparing to the discrete-time counterparts and may admit more effective estimation and generation; 2) the score-based learning yields superior estimation quality comparing to the ELBO surrogate used in Campbell et al. (2022) for the continuous-time discrete diffusion models. However, neither of them is convincingly validated in the experiment section. First, there is no formal comparison of the computations used during training and generation between the proposed model and the discrete-time ones. Second, the noise schedule adopted here is different from what used in Campbell at al. (2022). It has been shown that noise schedule can have noticeable impact on the final performance. Thus, this difference may question the validity of the conclusion that the better performance of the proposed model can be solely attributed to the score-based learning process. Third, it would be desirable to perform some ablation studies to validate the designs. For example, comparisons among all three parametrizations in the synthetic experiments and comparisons between the sampling methods discussed in Section 4.2 and 4.3.",
            "clarity,_quality,_novelty_and_reproducibility": "The extension of the ratio test for binary variables proposed in Hyvarinen (2007) to the categorical counterpart is straightforward but make it working with the proposed model is a non-trivial task and requires a lot of architectural designs. Unfortunately, the presentation of this paper makes it difficult to understand. Besides issues mentioned above, a few more:\n- In Section 6.3, it states that \"we use the simulation time $\\tau=1e^{-3}$ for all methods\". Is this $\\tau$ the same as the $\\epsilon$ used in Section 4,2 and 4.3? Or is this something not referenced previously? Which simulation time is used for the CIFAR10 data?\n- In Appendix B.2, how does equation (34) equal to equation (35)? is this a typo?\n- Do we have the similar SDE formulations as in equation (5,6) for the discrete data since we already have the score function? Is it just a simple replacement of the proposed score function?\n\nFor the reproducibility, there are certain experimental details presented in the main text and appendix, but I think it is still not quite easy to reproduce the results presented in Section 6. Hopefully the authors would release their code.",
            "summary_of_the_review": "I think the score-based continuous-time extension of the discrete diffusion models is interesting and the paper makes a novel contribution to it. However, I am leaning towards the negative side due to the weak presentation and not-so-convincing experiments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_tzeK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_tzeK"
        ]
    },
    {
        "id": "l1_FTSCI2l",
        "original": null,
        "number": 2,
        "cdate": 1666633102661,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633102661,
        "tmdate": 1666633102661,
        "tddate": null,
        "forum": "BYWWwSY2G5s",
        "replyto": "BYWWwSY2G5s",
        "invitation": "ICLR.cc/2023/Conference/Paper5122/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The submission considers score-based generative models with SDEs, but for discrete variables. The main challenge here is that the existing score-based methods do not apply to discrete variables since the log likelihood is not well defined. To deal with this issue, the authors use continuous-time discrete-state Markov process to model the forward process, with the according backward process also being a continuous-time discrete-state Markov process. Under this setting, a score-based estimation method is proposed for the diffusion model, with a sampling scheme for the reverse process. \n\nThe performance of the proposed method is thoroughly studied empirically, demonstrating an improved performance. ",
            "strength_and_weaknesses": "Strength\n\n1. The submission is well written. The notations are well defined. The used concepts are background details are clearly provided in the submission, making the paper self-contained. \n\n2. The empirical analysis is thorough and clear. The protocol, competing methods, expected results and the achieved results are clearly provided.  \n\n3. The methodology is novel. While the whole framework follows the existing framework of score-based generative models with SDEs, the proposed score function for discrete state variables is an extension to existing works. \n\nWeakness\n\n1. I am confused by the stochastic jump process. To the best of my knowledge, this terminology is more often used for jump processes like Poisson jump process. Specifically, it emphasizes more the discreteness of the path, instead of the discreteness of the variables: many stochastic jump processes have continuous-time variables. The model used in this submission is more a continuous-time discrete-state Markov process. Would it be possible for authors to clarify the rigorous definition of this terminology? \n\n2. I am wondering whether we can \"naively\" use a score-based generative models with SDEs for discrete variables, by simply doing some discretization when conducting sampling? This might be a bad idea when the variable has only two categories, but what if it has more than 200 categories like the image example in the experiments? What is the problem of this simple solution? Answering this question can further motivate the submission. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n\nThe submission is clearly written and easy to follow. \n\nNovelty\n\nThe submission is novel by extending an existing framework. \n\nReproducibility\n\nImplementation details are provided in the submission. ",
            "summary_of_the_review": "The submission is well written with lots of technical details. A new method is proposed with empirical results supporting the performance improvement. To the best of my knowledge, the submission extends the existing score-based method to discrete variables, which is a contribution to this area. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_grv3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_grv3"
        ]
    },
    {
        "id": "VbcPcRDnQy",
        "original": null,
        "number": 3,
        "cdate": 1666692498818,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692498818,
        "tmdate": 1666692498818,
        "tddate": null,
        "forum": "BYWWwSY2G5s",
        "replyto": "BYWWwSY2G5s",
        "invitation": "ICLR.cc/2023/Conference/Paper5122/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a diffusion-type generative model for categorical data. For this, the authors derive a variational learning scheme to approximate the discrete state space analog of the score of the marginal likelihood. The authors present a forward noise and backward denoising model based on a continuous-time Markov chain model. For learning the authors present three different neural-network-based parametrizations for the variational approximation. The algorithm is extensively evaluated for synthetic and real-world data and shows very good results.",
            "strength_and_weaknesses": "Overall, I do not have much to say about this paper, besides that, I really really enjoyed reading it. It is written in an easy-to-follow way, even though continuous-time stochastic process modeling usually requires immense technical machinery. The approximate inference algorithm is derived in a principled way and the empirical results of the paper are very promising.\n\nSome sugestions I have are:\n- Including the result of equation (47) in the main text, would have made it easier for me to understand how the learning of the conditionals is related to the ratio in equation (10)\n- In Sec 4.1. the transition matrix is given as an aside as $q_{t \\mid s}(\\cdot \\mid \\cdot)=\\int_s^t \\exp(Q_{\\tau})\\, \\mathrm d \\tau$. This is not correct as it is the solution to the linear ODE given in equation (7), for which the solution is given by the state-transition function, for which there is generally no decomposition as a matrix exponential, see, e.g., \"Peano\u2013Baker series\", or, \"ordered exponential\".\n- The results for reversing a CTMC are not new and well known in the context of continuous-time filtering and smoothing. The authors should consider citing the relevant work, see, e.g., [1-3], and the references therein.\n\n[1] Anderson, Brian DO, and Ian B. Rhodes. \"Smoothing algorithms for nonlinear finite-dimensional systems.\" Stochastics: An International Journal of Probability and Stochastic Processes 9.1-2 (1983): 139-165.\n[2] Elliott, R. \"Reverse-time Markov processes (Corresp.).\" IEEE transactions on information theory 32.2 (1986): 290-292.\n[3] Van Handel, Ramon. Filtering, stability, and robustness. Diss. California Institute of Technology, 2007.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I had no trouble understanding the paper and I think it is very nicely written. The approach is novel to me and it should be easy to reproduce the results.",
            "summary_of_the_review": "The paper presents a new algorithm for generative modeling with categorical data. It is very nicely written and it shows very competitive results.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_eZKv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_eZKv"
        ]
    },
    {
        "id": "IuFND8G6Ts-",
        "original": null,
        "number": 4,
        "cdate": 1667117571456,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667117571456,
        "tmdate": 1671180784488,
        "tddate": null,
        "forum": "BYWWwSY2G5s",
        "replyto": "BYWWwSY2G5s",
        "invitation": "ICLR.cc/2023/Conference/Paper5122/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "There is a recent emergence of interests in adapting diffusion models to handle discrete data and this work adds to that literature. To understand the main difference from prior work, it is important to note that there are two (almost) equivalent frameworks for learning diffusion models: the variational lower bound framework and the denoising score matching framework. Prior work on discrete diffusion models have mostly focused on the variational lower bound framework because score functions are not defined in discrete domains. This paper replaces the continuous score with a discrete analogy which were studied in previous work on ratio matching/generalized score matching. The authors then design a transformer-based architecture to model this \"discrete score\" (which is essentially all complete conditionals at time t). Experiments show that the proposed discrete score matching objective is effective in fitting discrete energy-based models and diffusion models, with comparable or worse results on image data but better results on music data. ",
            "strength_and_weaknesses": "## Strengths\n\n* This paper is well-motivated. A well-known fact in the diffusion model community is that score-based objectives often lead to better likelihoods than the ELBO. It is natural to ask if this holds for discrete data. However, the score-based interpretation was overlooked in the prior literation of discrete diffusion models. They mostly mentioned that scores are undefined in this case but ignored the fact that Hyv\u00e4rinen had written about discrete generalization of score matching (called ratio matching) in his own work. \n\n* The proposed learning objectives are technically sound. As far as I checked, the derivations are correct. Modeling the complete conditionals also seems a very natural choice to me. \n\n## Weaknesses\n\n* The paper claims they extend score matching to general categorical data in several places. However, this is not true given the prior work on ratio matching and generalized score matching. The discrete analogy of score has also appeared in these works. From this perspective, the technical novelty seems to be quite limited. \n\n* Although the motivation suggests that using score-based loss function should work better than ELBOs, the results on image data indicates the opposite. On simple datasets like CIFAR10, the proposed method was outperformed by prior discrete diffusion models, including D3PM, Campbell et al. \n\n* One reason the paper uses for explaining the superiority of continuous diffusion models over discrete ones is that score matching for discrete variables does not benefit from prior knowledge about ordinal discrete data. However, I believe this is not the case for the \"discrete score\" definition in (11), which leverages the \"sparse neighborhood\" knowledge by only looking at states that differ by +-1. \n\n* Section 4 is confusing. I do not get the reasoning \"Such a jump rate depends on both the time t and ... Hence, it is inefficient to simulate the reverse time process X_t exactly\". ",
            "clarity,_quality,_novelty_and_reproducibility": "This could be solid paper if the weaknesses are sufficiently addressed. Clarity is generally good except Section 4 (see above comments). The work is original in applying discrete variants of score matching to diffusion models, although techniques mostly follow from prior work on ratio matching and the discrete diffusion model formulation by Campbell et al. \n\nMinor:\n\n* eq. (11), the first \\approx should be identity, and the second identity should be \\approx",
            "summary_of_the_review": "The work investigates an under-explored direction for developing discrete diffusion models. However, the paper is not ready yet due to lack of necessary theoretical developments to address the major problems and insufficient empirical evidence for supporting their claims. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_4YQP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5122/Reviewer_4YQP"
        ]
    }
]