[
    {
        "id": "_wSvplVww4",
        "original": null,
        "number": 1,
        "cdate": 1666591945665,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591945665,
        "tmdate": 1669515182574,
        "tddate": null,
        "forum": "N_g8TT9Cy7f",
        "replyto": "N_g8TT9Cy7f",
        "invitation": "ICLR.cc/2023/Conference/Paper6549/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a framework for generating a dataset of diverse candidate pairs for individual fairness specifications by a set of methods (e.g., an extended word replacement list, unsupervised style transfer, and zero-shot modification using GPT-3). To align with human fairness intuitions for a considered downstream task, the authors propose active learning approaches to improve the quality of the datasets. Empirical studies are conducted to show the proposed dataset is of high quality.",
            "strength_and_weaknesses": "Strengths:\n1. The paper considers a novel approach to bridge the gap between human intuition about input perturbations for individual fairness and the formal similarity specifications capturing them.\n2. The methods to diversify expressive candidate pairs and active learning for quality control of the dataset are technically sound.\n\nWeaknesses (see more details in the section below):\n1. The paper needs further improvement in clarity.\n2. Beyond individual fairness, a discussion of how the proposed dataset with individual fairness would affect group fairness notions is needed.\n3. The broader impact of how relevant stakeholders would use the generated workflow is unclear. \n",
            "clarity,_quality,_novelty_and_reproducibility": "In this section, I will provide more details of my comments.\nFirst of all, I think the paper is technically sound overall. The tasks and paper considered in the paper are a novel combination of well-known techniques. In particular, the paper bridge the gap between human intuition about input perturbations for individual fairness and the formal similarity specifications capturing them.\n\nHowever, I think the paper could be further improved in terms of clarity and discussion of multiple related notions (e.g., group fairness) and the potential broader impacts.\n\nWhile the paper is fairly readable, there is substantial room for improvement in clarity. The techniques involved in this paper span multiple domains, requiring the reader to have a good knowledge of algorithmic fairness, NLP, user study, etc. I have seen the authors put good effort into giving details in the main text and appendix. However, it is hard to understand the experiment sections without referring to the appendix in detail. For example, in Table 2, the authors do not provide any description of the \"Metric/Method\" column in the main text. Similar problems happen in Table 3. I also have a question about evaluating the diversity of generated pairs: the paper uses the fairness metric as the evaluation criterion for models trained on different constraint sets. The word choice of \"diversity\" sounds strange, given the evaluation criterion. A better word choice might be something like \"coverage\". \n\nSince the paper studies fairness. I am also interested in how the generated intuitive fairness specification affects group fairness notions such as demographic parity and equalized odds. Besides, since the fairness specification is intuitively generated by humans, how do you provide more documentary specifications on this to the relevant stakeholders, such as ML/NLP practitioners and model users, to trust the overall workflow?\n\nLastly, I have some questions regarding reproducibility: I only see the codes in supplementary materials. Will the dataset be released? If yes, how do you plan to release them in order to provide a better potential impact in the long run? \n",
            "summary_of_the_review": "The paper is novel and technically sound but needs improvements on clarity, and discussion of broader impact, given that the paper studies fairness.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_cacL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_cacL"
        ]
    },
    {
        "id": "3R3D5-miUtO",
        "original": null,
        "number": 2,
        "cdate": 1666634063134,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634063134,
        "tmdate": 1670031308324,
        "tddate": null,
        "forum": "N_g8TT9Cy7f",
        "replyto": "N_g8TT9Cy7f",
        "invitation": "ICLR.cc/2023/Conference/Paper6549/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new framework to satisfy individual fairness notion by utilizing style transfer along with zero-shot techniques. They also perform crowdsourcing experiments to verify how much aligned results those techniques generate results compared to human intuition. They also use these human signals as means to improve they system for filtering pairs as well as training downstream models. ",
            "strength_and_weaknesses": "**Strengths:**\n\n1. The paper studies interesting and timely problem.\n2. The paper is written clearly and is well-organized.\n3. The approach is simple and easy to follow.\n\n**Weaknesses:**\n\n1. It seems like the approach would be really task dependent. I think it is good for authors to acknowledge this somehow and mention how the task can affect the outcomes.\n2. Related to my above comment, authors only study toxicity problem. It would be good to study other tasks and compare the differences and provide more in depth discussion on what the differences are in terms of the filtering approach per task as well as human alignment results.\n3. While the approach is effective in achieving more \"fair\" outcomes, the approach imposes loss on accuracy.\n4. Given that the task of toxicity detection is a subjective task and in many cases culturally dependent, what mechanisms authors take into account in their human studies other than recruiting more than one worker to label a hit and taking the maximum. Please provide some discussion on this.\n\n**Additional Minor Comment:**\n\nI would suggest authors refer to fairness through awareness instead of individual fairness as really what authors do is to study groups in their tasks (e.g., Muslim vs Christian) but using the notion of fairness through awareness, so to avoid this minor confusion, I would suggest changing the naming.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**:\n\nThe paper is written clearly, is well organized, and the approach is simple and straightforward.\n\n**Quality**:\n\nThe paper is of good quality, but it would be better if additional experiments are added to investigate more various tasks.\n\n**Novelty**:\n\nAlthough the problem of word replacement has been previously investigated, the addition of style transfer and zero-shot capabilities is an interesting touch. \n\n**Reproducibility**:\n\nThe Appendix has some info for reproducibility. ",
            "summary_of_the_review": "The paper studies an important problem and is written clearly; however, some additional experiments can benefit the paper. Including some discussions around my concerns raised in the weaknesses section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_6aFV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_6aFV"
        ]
    },
    {
        "id": "dtwmru4m3Os",
        "original": null,
        "number": 3,
        "cdate": 1666655523736,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655523736,
        "tmdate": 1666655523736,
        "tddate": null,
        "forum": "N_g8TT9Cy7f",
        "replyto": "N_g8TT9Cy7f",
        "invitation": "ICLR.cc/2023/Conference/Paper6549/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The problem this paper makes progress in solving is that of generating data to drive individual fairness constraints on text classification models, with a case study of toxicity classification. The authors make use of a data generation pipeline, such that, starting with an initial dataset of text with mentions of demographic information. First, they create an initial set of counterfactual examples using word replacement, GPT-3 (with three variants of sub-pipelines), and an unsupervised style transfer model. For the last two, they also train a BERT model to detect group presence in a text, which is used as an initial filter for GPT-3 generations and used to train the style transfer model. They then train a \"similarity\" model to detect, given an original text and its generated counterfactual, if both should be treated the same. This similarity model is trained using active learning. They then use this similarity model to iteratively filter out the initial set of pairs to a final set, which is used to train the downstream classifier. \nUsing toxicity classification, they show that classifiers trained on this method was able to improve on fairness, and showed that the generated pairs generally aligned with human annotations' intuition of fairness. They also did ablation studies on downstream model performance given each initial method of data creation, and the effect of active learning on the similarity model. ",
            "strength_and_weaknesses": "The paper addresses several important issues in evaluation text classification models. The issue with evaluation datasets is that there is no evaluation data for certain demographics, let alone parallel data for individual fairness evaluation. Secondly, word replacement methods (which is often used in prior literature) does not check if the parallel data is indeed valid. Especially for nuanced topics like hate speech or t toxicity classification, swapping words is not enough, since a stereotype about one group may not exist for another group (e.g. older people are nurses is not as much of a stereotype as women being nurses in the US). The paper is generally strong in terms of rigor of methodology, novelty of method, and in contribution. \n\nFor weaknesses, the authors could be clearer on what fairness metric is being used for tables such as Table D.3. Additionally, an ablation study could be added in terms of how changing the similarity classification threshold affects performance of the similarity model (and the downstream performance of downstream classifiers)? Finally, I would have liked to see in the appendix table E1-4, the generations from the three methods on the same examples. \n\nThere are also a few nits, for example, make sure to reference all variables in graphs (for example, D in Figure 1). \n\nAs a note, the authors should reference this paper as well for automatic generation of evaluation data: https://arxiv.org/pdf/2202.03286.pdf. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is fairly original, clear,, and is of high quality. ",
            "summary_of_the_review": "I think this is an important problem, and this work will help equip future researchers with another method to generate high-quality data, which can be used for both evaluation of text classification models or to train them.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_Cvse"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_Cvse"
        ]
    },
    {
        "id": "vNBEt-A9iK5",
        "original": null,
        "number": 4,
        "cdate": 1666662065202,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662065202,
        "tmdate": 1666662065202,
        "tddate": null,
        "forum": "N_g8TT9Cy7f",
        "replyto": "N_g8TT9Cy7f",
        "invitation": "ICLR.cc/2023/Conference/Paper6549/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a workflow/methodology to generate pairs of\nsimilar sentences that differ only wrt target/protected populations\nsuch as gender or race. The methodology inclues increasingly\nsophisticated steps, such as word replacement, unsupervised style\ntransfer and generation using GPT3. Crowdsourcing and active learning\nis used to filter the generated pairs. The methodology is demonstrated\nin the context of toxic text prediction. Using the pair-wise sentences\nthat vary only along the protected groups, a RoBERTa model is trained\nby enforcing the logits for the two pieces of text to be similar\n(since the toxic text prediction should not depend on the protected\nsubgroup used in the sentence).",
            "strength_and_weaknesses": "Strengths:\n- The methodlogy could be used in different contexts for generating pairs of similar senteces that differ only in the protected group\n- Lots of experiments to support the methodology\n\nWeakness:\n- Some ad-hoc decisions (e.g., shortening the max sequence size) that are not well explained\n- Lots of experimental results that are not well explained",
            "clarity,_quality,_novelty_and_reproducibility": "In general, I enjoyed reading the paper\tand learning about the\nproposed methodlogy. I had a hard time processing the multitude of\nexperimental results. In particular, it's not clear what the numbers\nrepresent in each table. I would clearly describe in the caption of\neach figure what the rows/columns represent and what metric is\nused. In particular, the paper uses \"fairness\" without clearly\nexplaining how fairness is measured.\n\nSome of\tthe design decisions are not well explained. In\tparticular, I\nam curious about the maximum sequence size of 64 (which is quite\nlimiting). Is that to ensure that the style transfer and the GPT3\ngeneration produce quality results?\n\nNot clear what WR50 means.\n\nIn Table 1, all columns except for BA represent some measure of\nfairness? If that's the case and if I understand the results WR (which\nI'm guessing stands for word replacement) seems quite performant. How\ndo you justify the complexity of adding the style transfer and GPT3 on\ntop. What is the real advantage of the full C dataset?\n\nThe fairness metric used seemed a bit ad hoc. One of the more\nstandard metrics could be use (see Fairness Definitions Explained and\nthe following paper for an example of using equalized odds: Your\nFairness May Vary: Pretrained Language Model Fairness in Toxic Text\nClassification - analysis of many LMs wrt fairness and model\nsize/training size/random seed (in the context of toxic text\nprediction)).\n\nLast but not least, I think \"fairness specifications\" is misleading\nand quite an overblown term for what the paper is about; it made me\nthink of some theoretical formalism/specification. Similar pairs of\ntext across protected groups is a much more honest description of what\nthe paper generates.",
            "summary_of_the_review": "This paper introduces a methodology to generate pairs of similar\nsentences that differ only wrt protected group. The pairs generated\ncan be used to train fairer classifiers by imposing similar logits for\nsimilar sentences.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_Y9Ec"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6549/Reviewer_Y9Ec"
        ]
    }
]