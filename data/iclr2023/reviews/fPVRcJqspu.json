[
    {
        "id": "K_KlHzNFOY",
        "original": null,
        "number": 1,
        "cdate": 1666353376619,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666353376619,
        "tmdate": 1669736792615,
        "tddate": null,
        "forum": "fPVRcJqspu",
        "replyto": "fPVRcJqspu",
        "invitation": "ICLR.cc/2023/Conference/Paper5336/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new generative model for tabular data, as a VAE whose decoder structure is built around GraphNN layers.\n\nThe rationale for this structure is given in terms of inductive biases: on structured data like images or text, the successful models are built around architectures that take advantage of good inductive biases derived from the structure of the data. Tabular data lacks this general structure, and instead generally has a problem-dependent structure. Models like MLP don't have any of those inductive biases, explaining why they don't perform so well on tabular data.\n\nThe paper thus introduces GOGGLE, a VAE-like generative model whose decoder half is built using GraphNN layers that act akin a message-passing scheme on top of a graph defined over the features of the data. Similar to a probabilistic graphical model (while *not* being one), this structure reflects the dependencies between the variables as learned by the model. The paper proposed several regularization schemes over the learned adjacency matrix of this graph to reflect different inductive biases that can be injected in the model such as encouraging sparsity or injecting a partially known dependency structure. While the constructed graph is *not* a proper PGM, it structures the way in which the generative model processes the data.\n\nThe paper  provides experimental validation on several datasets and against multiple other models from the literature tailored to tabular data. Experiments show that GOGGLE reaches better performance across the board and following multiple metrics, including the quality of generated samples to train a downstream classifier on synthetic data. GOGGLE is notably competitive with Bayesian Networks, which remained the state of the art on many tabular problems, suggesting that the injected graphical structure is indeed core to performance on these problems.\n\nThis is further confirmed by an ablation study, which shows that the quality of the graph underlying the GraphNN decoder has a significant effect on the performance of GOGGLE, and that learning it jointly with the rest of the model using the proposed regularization is notably better than trying to infer it beforehand using another method.",
            "strength_and_weaknesses": "**Strengths:**\n- The proposed architecture is well justified and well detailed. The goals and non-goals of the model are clearly stated (notably appendix D is a very welcome comparison).\n- Experiments are detailed and extensive, and the ablation study clearly illustrates the impact of the core contribution (the GraphNN structure of the decoder).\n- The introduced model seems to have a good potential for meaningful impact on the problem of synthetic tabular data, as expressed by the performance impact, in particular in terms of *utility* (using the generated synthetic data for downstream tasks).\n\n**Weaknesses:**\n- The probabilistic part of the decoder is hardly discussed, while potentially having a big impact on the performance of the model. Appendix explains that a MSE loss is used for continuous variables, which corresponds to an isotropic Gaussian noise with fixed variance. See [*Simple and Effective VAE Training with Calibrated Decoders*, Rybkin et al, 2021](https://proceedings.mlr.press/v139/rybkin21a.html) for a discussion of why this is an important factor over the model performance. That paper focuses on image data, but the core argument translates to tabular data. I believe learning a per-feature noise scale for the Gaussian observation model may further improve the performance of the proposed model.\n- The is no discussion of the impact of $L$, the number of GraphNN layers stacked in the decoder. I suspect this parameter might depend a lot on the dataset at hand, and in particular of how sparse or strong the correlations between the variables are?\n- The discussion suggests extending the approach to learning graphs in the latent representation rather than between the observed variable. There is actually already some work in this vein existing (see for example [*Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering*, Li et al, 2019](https://arxiv.org/abs/1803.05206)) which would be worth discussing in the related works section of the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "This is a very clear paper, the contribution seems novel and important.\n\nExtensive description of the model and experimental setting is given in the paper and appendix. One notable exception is the value used for the $L$ hyperparameter in the various experiments that I could not find. The author plan to release the full source code if the paper is accepted.",
            "summary_of_the_review": "This is a good paper that provides a meaningful contribution to the question of generative modelling on tabular data.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_Hvkk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_Hvkk"
        ]
    },
    {
        "id": "m5EnEXarNn",
        "original": null,
        "number": 2,
        "cdate": 1666636244221,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636244221,
        "tmdate": 1666636244221,
        "tddate": null,
        "forum": "fPVRcJqspu",
        "replyto": "fPVRcJqspu",
        "invitation": "ICLR.cc/2023/Conference/Paper5336/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose to use relational inference for the generative model in a tabular setting. The proposed method jointly learns the relation between features in tabular data and parameters of generative models.\n\nThe paper is fairly well structured, apart from missing some of the related works and weak experiments.\n\nMy main concern with this paper is the lack of novelty. One of the main known issues in relational learning (even out of tabular setting) is computational complexity and dealing with high dimensional data, however, the proposed method could not address this issue and only the experiments are conducted on tiny feature sizes which is not an issue. This is not consistent with real-world high-dimensional tabular data.\n\nApart from that, it is not clear to me why they have added the prior knowledge through regularization and not embedded it as a graph similar to MoReL. Incorporating as a regularizer could be done in simpler models as well and there is no comparison in the experiments. ",
            "strength_and_weaknesses": "**Pros:**\n\n- Generative modeling for tabular data is a hard and interesting problem.\n\n**Cons:**\n\n- The novelty is limited.\n\n- The authors missed some related papers, especially in the methodological\u00a0parts, including NRI [ICML 2018], MoReL [ICLR 2022], BayReL [ NeurIPS 2020], and many other related relational inference papers in other domains.\n\n- Some of the self-supervised learning models for tabular data can be used as generative models, including VIME [NeurIPS 2020], SubTab [NeurIPS 2021], and many other available methods which\u00a0are based on self-supervised methods.\n\n- The learned structure is not well explored in experiments. How it will look like and how is different from the ground truth?\n\n- The datasets are not high dimensional.\u00a0\n\n- The authors did not report the performance of the raw data model without generated dataset.\n\n- The authors missed some of the basic regression methods and is not clear how the reported ones are tuned.\u00a0\n\n- The authors reported an average of three different methods. I would like to see the performance of each separately, and also LR and simple methods should be included.\u00a0\n\n- The AUROC metrics is not sufficient. I would like to see the ROC plot as well as other metrics such as recall, FDR, F1, etc.",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty is limited. And the reproducibility of the baselines is not obvious. ",
            "summary_of_the_review": "I believe the paper is not novel and could not address the main issue of this domain. The experiments also cannot support the claims. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_bxj6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_bxj6"
        ]
    },
    {
        "id": "lmFhFIVDSk_",
        "original": null,
        "number": 3,
        "cdate": 1666743046761,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666743046761,
        "tmdate": 1668721597087,
        "tddate": null,
        "forum": "fPVRcJqspu",
        "replyto": "fPVRcJqspu",
        "invitation": "ICLR.cc/2023/Conference/Paper5336/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work introduces a new generative model for tabular data. It proposes to learn both a relational structure between variables and also a data generating process conditioned on that structure. This formulation has not been presented before for neural methods and is a significant contribution. The benefits of this method are that it can incorporate prior information via an adjacency matrix, leverage the benefits of neural networks for generation in the large data regime, and is more amenable to certain types of regularization. These benefits are quantified empirically on a few tabular datasets where the proposed method seems to be the most consistent performer and usually outperforms other baselines.",
            "strength_and_weaknesses": "Strengths:\n- Empirically, the proposed method is usually the best performer across 10 benchmarks.\n- The model-based approach to learning dependencies and graph-based approach to generative modeling is unique and a valuable contribution for the community. I could foresee future work building on this and finding better ways to incorporate prior information.\n- Strong empirical evaluations, ablations, and benchmarking efforts to compare to baselines overall.\n\nWeaknesses:\n- The story on leveraging prior information is not convincingly demonstrated through experiments. Looking at Figure 3, Goggle never seems to outperform BN, and in some cases is handily beat by either BN or CTGAN. Given that leveraging priors is a major strength of the proposed method, the empirical results here are not consistent with that story. Also, the language in that section \"it is encouraging to see that our method achieves comparable performance to BN methods\" is misleading and should be altered.\n- Placement of results tables. Though the method is evaluated on 10 datasets, only results on 4 datasets are presented in the main text. From an outside perspective, it would appear as if these datasets may have been cherrypicked, especially since relative performance numbers on the other 6 datasets in the appendix are not as high.\n- Baselines comparison. Was equal hyperparameter tuning and equal computational budget given to each of the baselines? It does not seem specified in the appendix.\n- Comparison to a MM (mixture models) baseline is missing.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall clearly written and is easy to understand.\nThe quality of the proposed method seems reasonable; although it is not always the best, it most often is the best.\nThe proposed method for a model-based way to learn a generative model for tabular data is novel.\nThe work is NOT reproducible as code is not supplied (though there are some details in the appendix, I do not consider this reproducible unless code is provided).\n\nA couple minor points to improve for paper clarify:\n- I did not understand the point about synchronous vs asynchronous generation. There needs to be more explanation here, or it should go in the appendix (given that it seems the point was not revisited in the main text).\n- How many samples are generated from Goggle for downstream evaluation for assessing Utility? Is it the same number of samples as there were original real samples? If so, it seems surprising to me that training on Goggle synthetic data is better than training on real data - this would be worth highlighting more!",
            "summary_of_the_review": "Overall, the proposed method in this paper seems very promising - a model-based tabular generation scheme that can leverage prior knowledge, that is more amenable to regularization in the small data regime, and that has solid performance empirically across a number of datasets. However, the paper does not meet two of these major marks:\n1) In terms of leveraging prior information, it seems Goggle was always outperformed by either BN or CTGAN in this setting.\n2) Details of hyperparameter tuning are not provided. Specifically, it seems like an equal computational budget may not have been given to each method. Thus, it is hard as a reviewer to deduce whether performance gains come from the superiority of the method or from more extensive parameter tuning.\nNonetheless, the effort put forth in the paper is solid and the main ideas presented would make a valuable contribution. I am marking my score a little lower due to the two major drawbacks above, but I am happy to increase the score during & after discussion with the authors, depending on their response.\n\n********* UPDATE AFTER REBUTTAL ****************\n\nThe authors have resolved my main concerns regarding hyperparameter tuning and have adjusted the language in the prior information section to scope down the claims (as well as adding some new experiments). Additionally, the authors have added a clarification that their method has only been validated on relatively low-dimensional datasets, which their experiments support. For this reason, i am increasing my score as I believe this is a solid contribution to the community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_k5vp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5336/Reviewer_k5vp"
        ]
    }
]