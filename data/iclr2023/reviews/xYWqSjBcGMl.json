[
    {
        "id": "ywS8h3eXDk",
        "original": null,
        "number": 1,
        "cdate": 1666674095942,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674095942,
        "tmdate": 1670733224289,
        "tddate": null,
        "forum": "xYWqSjBcGMl",
        "replyto": "xYWqSjBcGMl",
        "invitation": "ICLR.cc/2023/Conference/Paper3146/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper combines techniques from Neural ODEs together with with prior work on polynomial projections for signal reconstruction (HiPPO). It defines a new method PolyODE that can address various problems with time series analysis such as reconstruction and forecasting, particularly for settings such as irregularly-sampled data.\n\n\n",
            "strength_and_weaknesses": "This paper is not well described or positioned. It appears to be the exactly same as the HiPPO (High Order Polynomial Projections) method from the literature, with two minor variations:\n1. It considers $d$-dimensional input instead of $1$-dimensional, by simply applying $d$ independent HiPPO models.\n2. It claims to be \"continuous time\" and uses a different numerical integration step in between observations, although here the technical details are missing so it is not clear what precisely is being proposed.\n\nSeveral technical details are missing from the paper.\n- It is not clear what $A_\\mu$ means in the paper. It is mentioned that HiPPO derives several families of matrices based on a measure $\\mu$; which one is used in this paper? Is it initialized to a specific matrix and then learned, or frozen to a HiPPO matrix?\n- Details around the \"Numerical Integration\" are very confusing and not clearly presented anywhere in the paper. Section 4.2 claims to use a numerical solver in the style of Neural ODEs, but later claims to use a solver such as Backward Euler. If it is the latter, then Backward Euler is a special case of the integration rules considered in the original HiPPO paper. If it is the former, a more detailed comparison of the tradeoffs of the different integration rules should be discussed and ablated (in particular, a black-box ODE solver trained with the adjoint method should be much slower than the linear recurrences used in HiPPO).\n- How are reconstructions for NODE being done in Figure 1? The PolyODE appears to be just the HiPPO reconstruction framework, but such closed form reconstruction formulas don't exist for general NODEs. Also, what is \\alpha in equation (9)?\n\nEven if the method was described more clearly, this application of HiPPO to higher-dimensional data raises more points that should be discussed. The paper acknowledges that a major limitation of this method is the computational expense of using $d$ independent features (requiring a state size blown up to $dN$), which is why the original HiPPO only used dimension $1$.\n- Computational tradeoffs of this method and baselines should be discussed and quantitatively compared, particularly as a function of $d$ and $N$. Additionally, the numerical integration method should be more clear and its computational speed ablated, as it seems to be an interchangeable component compared to HiPPO's discretization method.\n- This issue of blowing up the dimension by a factor of $N$ is in fact one of the main problems addressed by later extensions of HiPPO to full state-space models such as S4. These baselines should be included where appropriate, as they can be used as drop-in models for most of the considered applications (note that they can also be applied to many \"irregularly-sampled\" time series problems where the sampling is provided as a mask).",
            "clarity,_quality,_novelty_and_reproducibility": "Post rebuttal update:\n---------------------\n\nQuality/Novelty: While largely building off prior work, this paper does propose a new method that combines two established techniques from the literature (HiPPO and neural ODEs). I think the method itself is an interesting proposition.\n\nClarity: I am an expert on the HiPPO line of work and have a general familiarity with neural ODEs, yet I found the technical details of the paper and proposed method incredibly hard to understand, which were only somewhat clarified by a detailed back-and-forth with the authors. I think that the description and comparison to prior work is also somewhat mischaracterized, e.g. claiming that prior work involves memorizing a latent state instead of the input signal, which is a conflation of two different things (HiPPO vs HiPPO-RNN). Part of this confusing description arises from a lack of transparency about the tradeoffs of the method, in particular computation speed. Overall, I think that clarity of both the method and its relation to prior work is the major weakness of this paper.\n\nReproducibility: Despite the lengthy exchange in this thread, I am not confident enough in several details to be able to implement the method from scratch. However, supplementary code was provided and I believe that the authors intend to release reproducible experiments.\n\n--------------\n\nFinal post-rebuttal update:\n\nThe authors have engaged in a lengthy discussion that have cleared up details of the paper, and taken significant efforts to improve the presentation of the paper and the comparisons to related work. I have increased my recommendation to acceptance.\n",
            "summary_of_the_review": "This paper contributes technical ideas that improve on baselines on addressing the problems it is concerned about (e.g. irregular sampled time series). However, the method description is incredibly confusing, which also partly stems from inaccurate portrayals of prior work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_uK5k"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_uK5k"
        ]
    },
    {
        "id": "xE2Grp5ybH",
        "original": null,
        "number": 2,
        "cdate": 1666943633506,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666943633506,
        "tmdate": 1666943818405,
        "tddate": null,
        "forum": "xYWqSjBcGMl",
        "replyto": "xYWqSjBcGMl",
        "invitation": "ICLR.cc/2023/Conference/Paper3146/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents neural ordinary differential equations (Neural ODEs) to learn representations of time-series in a latent space. The dynamic of such a latent space uses continuous-time neural ODEs, extending from existing discrete-time versions [Gu et al, 2020] based on orthogonal polynomials. The paper shows that the learned representations can capture long-range memory with theoretical results and empirical results via reconstructing the past of time series.",
            "strength_and_weaknesses": "Strength:\n- The idea of using orthogonal polynomials to solve long-range properties of time series with continuous-time models is interesting. \n- The paper shows some theoretical results as well as competitive performance of the proposed model.\n\nWeakness:\n- As one of the main contributions, the paper includes the way to use adaptive solvers. However, the paper just briefly mentions Backward Euler and Adams-Moultons [Sauer, 2011]. Firstly, it is not self-contained. Many readers from machine learning background don\u2019t know about such numerical methods. Therefore, the current explanation does not provide . Secondly, although the observation about the stiffness of ODEs is interesting, using such solvers is not a significant contribution. \n- Missing comparisons with neural controlled differential equations with log-signature [Morril et al., 2021]. I think this is the main baseline in terms of capturing long-range dynamics. The paper mentions this reference but does not give empirical comparisons and a detailed discussion. \n- The stiffness of ODE is elucidated clearly. However, there are no illustrations of the spectral information of the matrix $A$.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Quality: Good\n- Clarity: Good\n- Originality: Fair",
            "summary_of_the_review": "This is a solid paper even though it extends from Gu et al. 2020 into neural ODE. I lean toward accepting the paper. At the moment, I give a score of 6.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_mcs4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_mcs4"
        ]
    },
    {
        "id": "AHBTLahqDU0",
        "original": null,
        "number": 3,
        "cdate": 1667246553760,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667246553760,
        "tmdate": 1667246553760,
        "tddate": null,
        "forum": "xYWqSjBcGMl",
        "replyto": "xYWqSjBcGMl",
        "invitation": "ICLR.cc/2023/Conference/Paper3146/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a neural ODE based method to predict time series data. This method mainly projects the long-term trajectory onto basis of polynomials. ",
            "strength_and_weaknesses": "The strengths of this paper are:\n\n$\\mathbf{1}.$ The proposed method is novel and with solid contribution. At the same time, there is a complete presentation of theoretical base, where authors propose the novel dynamic function for PolyODE with comprehensive analysis. It could be a great addition to Neural ODE method in the field.\n\n$\\mathbf{2}.$ The empirical experiment is comprehensive with very detailed explanation in experiment setup and scenarios. The choice of data, baseline and design of the experiments are both very appropriate and/adequate",
            "clarity,_quality,_novelty_and_reproducibility": "$\\cdot$ This paper is very well organized and clearly written.\n\n$\\cdot$ The proposed method is novel and this has been addressed in the above comments.\n\n$\\cdot$ The reproducibility is feasible.",
            "summary_of_the_review": "This paper proposes a novel Neural ODE method which leverages a novel dynamic functions. The proposed method is well supported by the theoretical analysis and empirical experiment. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There is no ethics concern in this paper.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_1xor"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3146/Reviewer_1xor"
        ]
    }
]