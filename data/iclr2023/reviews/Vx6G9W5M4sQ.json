[
    {
        "id": "6KBYeOsGcO",
        "original": null,
        "number": 1,
        "cdate": 1666496317461,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666496317461,
        "tmdate": 1666496317461,
        "tddate": null,
        "forum": "Vx6G9W5M4sQ",
        "replyto": "Vx6G9W5M4sQ",
        "invitation": "ICLR.cc/2023/Conference/Paper6592/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes pFedKT to address the Non-IID data issue in federated learning. pFedKT is based on personalized FL with knowledge transfer. During local training, it utilizes a hypernetwork to generate a local model. The local model is updated with a contrastive loss as regularization, which limits the distance between the local model and global model to incorporate the knowledge of global model into local model. The hypernetwork is then updated with the updates in local model such that the hypernetwork can absorb the knowledge of the existing local models to generate the local model for the next round. Experiments show that pFedKT achieves better accuracy than the other baselines.",
            "strength_and_weaknesses": "Strength: The paper works on an important problem of FL. The idea is clear and the baselines in the experiments are comprehensive.\n\nWeaknesses:\n1. The improvement of pFedKT is low compared with other personalized FL approaches such as pFedHN. From Table 5, the accuracy of pFedKT is even lower than pFedHN in many cases. \n\n2. Each client has a fixed number of classes in the experiments, which is not practical in most applications. More real-world federated datasets can be used in experiments.\n\n3. The local iterations per round is fixed to 100 in the experiments. Experiments with different numbers of local iterations are necessary since the baselines may not work well with a large number of local iterations. \n\n4. The paper assumes that the contrastive loss is Lipschitz smooth and refers to [1] to support the assumption. I cannot see a clear relation between the assumption and the reference. The paper needs to provide more explanation about it.\n\n[1]  Softtriple loss: Deep metric learning without triplet sampling. \n\n5. The paper compares many baselines in the experiments. However, some of them are not personalized FL approaches (e.g., FedProx, SCAFFOLD). The authors may consider removing them to save space.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper has a good presentation.\n\nQuality: The experiments need further improvement. Please see Strength And Weaknesses.\n\nNovelty: Fair. The usage of hypernetwork is not new [2, 3]. Applying contrastive loss in local training has also been exploited [4]. \n\n[2] Personalized Federated Learning using Hypernetworks. ICML 2021.\n\n[3] ON BRIDGING GENERIC AND PERSONALIZED FEDERATED LEARNING FOR IMAGE CLASSIFICATION. ICLR 2022.\n\n[4] Model-Contrastive Federated Learning. CVPR 2021.\n\nReproducibility: Code is not provided.\n\n",
            "summary_of_the_review": "The paper proposes a new PFL algorithm. While the presentation is good, I think the experiments need further improvement and the theoretical analysis needs more justification.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_5c7g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_5c7g"
        ]
    },
    {
        "id": "MIeC7vLhT3R",
        "original": null,
        "number": 2,
        "cdate": 1666561064744,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666561064744,
        "tmdate": 1666561064744,
        "tddate": null,
        "forum": "Vx6G9W5M4sQ",
        "replyto": "Vx6G9W5M4sQ",
        "invitation": "ICLR.cc/2023/Conference/Paper6592/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors tackle the problem of non-iid data in FL. They propose the use of hypernetworks and the target network to cope with this. Clients use a contrastive loss to mitigate non-iid. \nThe key idea is for clients to utilize prior local weights and new global weights obtained from the server. They also provide a theoretical convergence analysis. \nThe computational experiments show that the proposed algorithm outperforms the benchmarks. ",
            "strength_and_weaknesses": "Strengths: \nThe use of prior local models is novel. \n\nWeaknesses: \nThe theoretical analysis is unclear and the connections with non-iid is unclear. \nThe computational experiments do not show extensive improvements and are flaky. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has some unclear statements. For example, it is unclear how test data is set up. It seems that they are local at clients. \nFunction $f$ is never defined. It appears to be the loss function. The papers states 'where f is loss function' but then why not using the notation from Section 3.3.\n\nIt appears that they deal with the horizontal setting but I don't think this is clearly stated. ",
            "summary_of_the_review": "The use of prior local models is definitely a nice idea however I think the authors don't do much with it. The application of the contrastive loss is not new and thus not a contribution. \n\nA have issues with theoretical results. \nTheorem 4.1 require a large number of samples which pretty much goes against non-iid. Clearly a large number of samples does not imply idd but it does exclude many non-iid situations. Theorem 4.1 is loosely stated but it seems to show convergence to global optimal in absence of convexity. This clearly cannot hold. \nThe same remark holds for Theorem 4.2. \n\nThe experiments are limited. The data is non-iid only in terms of class distribution but not in terms of features. This is clearly quite limited. \n\nTable 1: Improvements over local training are 'too good to be true.' I guess it questions if local training has been optimized. For CIFAR-10 the improvement definitely doesn't impress (90.34 vs 90.03). \n\nThere is one definitely relevant reference that is missing: Y. Xue, D. Klabjan, and Y. Luo. Aggregation Delayed Federated Learning.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_fgAG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_fgAG"
        ]
    },
    {
        "id": "HlJM1vOoF76",
        "original": null,
        "number": 3,
        "cdate": 1667247035740,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667247035740,
        "tmdate": 1667248468483,
        "tddate": null,
        "forum": "Vx6G9W5M4sQ",
        "replyto": "Vx6G9W5M4sQ",
        "invitation": "ICLR.cc/2023/Conference/Paper6592/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to improve the performance of personalized federated learning, and, for which, the authors propose two knowledge transfer schemes. In particular, the historical knowledge learned in the local clients is transferred from the hypernetwork, which stores the knowledge of previous local models, to the current local model. Also, the global knowledge, obtained by the aggregation of local models, is transferred to the local clients based on the contrastive learning loss, where the similarity between the updated local model and the aggregated global model is maximized while the similarity between the updated local model and the previous local model is minimized. The authors validate the performance of their model, named as pFedKT, on two image (i.e., CIFAR-10/100) and one language (i.e., Stack Overflow) datasets, on which the pFedKT outperforms relevant personalized federated learning baselines.",
            "strength_and_weaknesses": "### Strengths\n* The proposed historical knowledge transfer scheme with the hypernetwork brings the performance improvement for the personalized federated learning tasks.\n* The authors make effort to theoretically analyze the generalization and convergence bounds of the proposed pFedKT, while they are mostly inspired by the previous work [1] though.\n* The authors perform extensive analyses on the proposed pFedKT, by varying the hyperparameters, and by ablating the knowledge transfer mechanisms. \n\n### Weaknesses\n* The proposed global knowledge transfer scheme is not convincing enough in terms of both the motivation- and experiment-sides. \n* * At first, the authors argue that, by maximizing the similarity between the locally updated model and the globally aggregated model while minimizing the similarity between the locally updated model and the previously updated local model, the proposed pFedKT improves the generalization performance. However, this design choice is not convincing, since the authors already transfer the historical knowledge in the previously updated local model with the hypernetworks, meanwhile, the historical knowledge is negatively considered (i.e., historical information is avoided) in the contrastive learning loss. Therefore, two objectives are conflicts in the federated learning.\n* * In the experiment-side, the proposed global knowledge transfer scheme also does not bring the meaningful performance improvement, i.e., not much helpful for the personalized federated learning. For example, in Figure 7, the proposed global knowledge transfer scheme based on the contrastive loss does not bring the performance improvement. Similarly, in Table 11, the results w/ and w/o contrastive losses are very similar. \n* * Furthermore, in the experimental-side, it is unclear whether the proposed global knowledge transfer scheme can provide better generalization ability empirically. While the authors provide the theoretical result for the generalization bound, I suggest authors to include additional empirical results, if possible, which makes it more convincing.\n* In Section 3.4, the authors only compare the computational and storage efficiencies of the proposed pFedKT against the complex pFedHN model. It is meaningful to discuss the efficiencies of the most basic FedAvg model, as well as the other contrastive- and hypernetwork-based federated learning models, such as MOON and Fed-ROD. \n* Also, in Section 3.4, the authors argue that the proposed pFedKT has obvious strengths against the pFedHN model, since the pFedHN baseline has the larger hypernetwork in the server-side, while the proposed pFedKT has smaller hypernetworks in the client-side. However, this is not convincing, since if we have 1,000 clients, we have 1,000 individual hypernetworks distributed to 1,000 clients, and, in the global view, the size of 1,000 individual hypernetworks would be larger than the size of one hypernetwork in the server.\n* The analysis results in Section 5.3 may be problematic. The authors argue the proposed pFedKT can converge during 100 rounds, therefore, conduct analyses with 100 rounds; however, pFedKT does not converge until 100 rounds, as shown in Figure 4.\n* Since knowledge distillation-based federated learning methods share similar sprits to the proposed knowledge transfer-based federated learning model: the knowledge distillation allows the local/global models to transfer their knowledge effectively, I suggest authors to compare such knowledge distillation-based federated learning baselines: FedPHP, FML and KT-pFL, discussed in the related work section.\n\n---\n\n[1] Personalized federated learning using hypernetworks, ICML 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n* The main idea of the proposed global knowledge transfer scheme with the contrastive loss is not clear enough (See Weaknesses above for details).\n* In regards to the efficiency, the advantage of the proposed models compared to others is not sufficiently clear (See Weaknesses above for details).\n* In Figure 1 (b), it is unclear how to measure the global and local model accuracies. Specifically, in main experiments, the authors report the test accuracy based on the local private data with the local model; then, how to measure the global model accuracy, and how to compare this global model accuracy to the local model accuracies?\n\n### Quality\n* The experimental quality of the analyses in Section 5.3 might be low, since the authors conduct the analyses with the unconverged model. \n* In Section 2.1, \"clients train the received GM on local datasets from scratch\" should be tone-downed, since the client trains the local model from the globally aggregated model, which indeed contains the information for the local model; not training from the scratch.\n\n### Novelty\n* The novelty is mild, since, for the knowledge transfer, the concepts of hypetnetworks and contrastive learning are already proposed in the previous work, such as pFedHN, Fed-ROD, and MOON; however, the differences are faithfully and sufficiently discussed in the related work section as well as other sections. \n\n### Reproducibility\n* The authors do not provide the source code that lowers the reproducibility of this paper; however, the authors plan to release the source code after the acceptance. Therefore, the reproducibility will be probably high.",
            "summary_of_the_review": "The main idea of the proposed global knowledge transfer scheme based on the contrastive loss is not convincing (See Weaknesses above), and there are some improvement points, such as efficiency analyses in Section 3.4 which are not sufficient, and model analyses which are perhaps conducted without the model convergence. Therefore, I cannot recommend the acceptance.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_Luyb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6592/Reviewer_Luyb"
        ]
    }
]