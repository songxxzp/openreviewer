[
    {
        "id": "dmz4sRIN1p",
        "original": null,
        "number": 1,
        "cdate": 1666681549836,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681549836,
        "tmdate": 1668752064311,
        "tddate": null,
        "forum": "UVAmFAtC5ye",
        "replyto": "UVAmFAtC5ye",
        "invitation": "ICLR.cc/2023/Conference/Paper2746/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "### Overview\n\nThe paper aims to generate much deterministic representation for end-to-end speech translation by characterizing style normalization and information enhancement. Overall, I like the paper on incorporating those ideas for S2ST tasks. \n\nIn general, the author's design of both style normalization and acoustic information enhancement methods could be considered as one attribute-based enhancement sharing with some similar findings on latent space prompting or speech input reprogramming via perturbation to drive the model under different models and conditions. Both works are related to characterizing the perturbation for fine-tuning tasks. \n\nThe authors could add some discussion on those fine-tuning pre-training AM works via perturbations to improve the overall impact of this work. \n\nI strongly recommend accepting this work. \n- Original 6; to 8 after rebuttal. \n\n\n***\n\n**References**\n\nA. Voice2series: Reprogramming acoustic models for time series classification, ICML 21\n\nB. WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models, Interspeech 2022\n\n\n\n",
            "strength_and_weaknesses": "### Pros.\n\n1. Startforward but effective approach via the perturbation with fine-tuning CTC \n\n### Cons.\n\n1. Some related perturbation-based references are missing. \n\n2. Since Rhythm, Pitch, and Energy have all been used as information enhancement. The impact of each terms are not very clear. \n\n\n### Questions. \n\n1. It is not clear to me that the \"ASR model with CTC decoding\" has been used as one major setup in this work. Is that any difficulty in using the seq2seq prediction model under the proposed scheme?\n\n2. I heard some high-pitch background noise for Fr-En (https://transpeech.github.io/) examples. Could the authors provide some SNR or speech quality assessment since additional information has been introduced in the proposed method?\n\n***\n\n### Post-Rebuttal\n\nI read the authors' updated version and reply. \n\n- In general, my Q1 (seq2seq modeling) and Q2 (SNR) have been addressed. The authors have also stated a code release in their future version. \n\n- After re-reading, I think the major contribution (normalization and enhancement via perturbations) in section 3 is still a little blur in terms of writing since the speech module and notations are defined in their section 4. The authors could consider refine the proposed method in section with mathematical notation (e.g., $X$ and $p$) to improve their future clarification for general readers. \n\n- I updated my score to accept. This is a ~8 score paper to me. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper with good clarity. Some motivation for the perturbation based fine-tuning could be included. \n\nIn general, there are yet theoretical discussions on the fine-tuning process. But some connections to the previous perturbation-based theoretical study [A] could be included. \n\nThe authors do not mention their code and license. I give a question mark on the reproducibility. [updated: authors state code is to be released. The issue seems to be resolved.]",
            "summary_of_the_review": "In general, it is one good work on tackling characterized perturbation and S2ST. Some references are missing but in general, the area of fine-tuning SSL with a customized approach is still new and worthy of more studies. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No. ",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_2n3x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_2n3x"
        ]
    },
    {
        "id": "-Q4KI3m_w7",
        "original": null,
        "number": 2,
        "cdate": 1666720126282,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666720126282,
        "tmdate": 1666720126282,
        "tddate": null,
        "forum": "UVAmFAtC5ye",
        "replyto": "UVAmFAtC5ye",
        "invitation": "ICLR.cc/2023/Conference/Paper2746/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper address the issues in the recent proposed S2ST framework and propose to solve the problems with two different aspect.\nFirst of all, the paper proposes to alleviate the acoustic multimodal problem by using bilateral perturbation.\nObvious improvement is achieved with this method.\nNext, the paper proposes to solve the high latency problem by introducing a non-autoregressive approach.\nThis leads to a significant speed up compared with the baseline.",
            "strength_and_weaknesses": "Strength:\nThis paper propose two methods to improve the translation accuracy and the inference speed of S2ST systems. Significant improvement is achieved.\nIt is the first implementation of non-autoregressive S2ST\n\nWeaknesses:\nHere are my questions to the paper: \n\nThe author should check the definition of the word \"multimodality\" and the common usage of this word in the community.\n\n\"The proposed bilateral perturbation eases acoustic multimodality and makes it possible for non-autoregressive (NAR) generation\" is stated in the introduction. Why the method of bilateral perturbation and the NAR issue is related? \n\n\"the indeterministic training target for speech-to-unit translation fails to yield good results\" is stated in section 3.1. What is the reason behind this judgement? The units, which generated from the speech with an unsupervised way, contain noise and it was known since HuBERT. The vocoder behind the S2UT should be able to cover this and generated the target waveform. In other way round, this might be a good thing as the acoustic variation is preserved.\n\nHow much BLEU is sacrificed from moving an auto-regressive system to a NAR system?\n\nThe major aim of unit-based S2ST is to deal with unwritten languages. \nWithout this motivation and without the use of discrete units, I would consider the unit-based S2ST approach as a cascade of speech2text translation and TTS. \nWhile this paper is claiming their work on the foundation of unit-based S2ST, they are not evaluating  their models with unwritten language translation task.\nI doubt that the comparison in Table 2 is not fair as the strength of the baselines should be on unwritten language tasks.\n\n\n\n \n\n\n \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The writing is ambiguous and hard to read. E.g. the first sentence in the abstract.\n\nQuality: Standard.\n\nNovelty: Significant.\n\nReproducibility: The codes are not provided in the paper.\n\n",
            "summary_of_the_review": "I would recommend the paper to be accepted if my questions are settled.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_PYA8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_PYA8"
        ]
    },
    {
        "id": "wWBDY5ykTL",
        "original": null,
        "number": 3,
        "cdate": 1666747137783,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666747137783,
        "tmdate": 1666747137783,
        "tddate": null,
        "forum": "UVAmFAtC5ye",
        "replyto": "UVAmFAtC5ye",
        "invitation": "ICLR.cc/2023/Conference/Paper2746/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes two approach for an end-to-end speech-to-speech (S2S) translation: bilateral perturbation to focus the learning step on the linguistics information from the speech (i.e., disregarding acoustic properties such as rhythm and pitch that potential affects the consistency of the translation), and a non-auto-regressive unit decoding mechanism (mask-predict). Experimental results show the two approach to improve translation quality and unit decoding latency.   ",
            "strength_and_weaknesses": "Strengthes\n- The proposed style normalization step (that removes acoustic style information), and the enhancement step (that creates variable speech samples without affecting the linguistic information), are the main strength of the proposed S2S model. In addition to generate deterministic representation of the speech signal, the approach can be applied in several use cases as it will allow to better exploit speech representation learned from a self-supervised pre-training step incorporating both linguistic and acoustic signals. \n- Experimental evidences show the proposed approach (I and II), improves translation quality and a significant decoding latency. These improvements can enable the proposed approach to have multiple application use cases (including simultaneous S2S translation).  \n\n\nWeaknesses\n- Although, the proposed approaches demonstrate improvements for the respective metrics (quality and latency), its is hard to connect the two approaches (or at least it is not well motivated in the paper). I understand, the perturbation approach delivers by making NAR decoding of units in S2S translation is relatively easier, given the simplification on the acoustic features. However, its still unclear which is the main theme of the paper (I will assume the NAR approach is a by-product). \n- Experiments from a single benchmark - given the focus on the acoustic attributes, dataset from variable benchmarks (potentially with high variability in the acoustics information) could provide more strength for the experimental section.        ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n- The paper is well written, and understandable with enough background. The scope covering basic definitions of linguistics and acoustic information, illustrating and discussing the proposed approach (Figure 2), through the experiment and discussion part keeps the flow. \n\nQuality\n- There are instance, that require a proof reading, to tune some of the parts of the work (for instance \"The\nparallel decoding algorithm requires as few as 2 iterations to generate outperformed samples,\" --> ... to generate samples that outperform ... ?). \n\nNovelty \n- The proposed approach follows previous work (see Figure 1a), and different from related work, the proposed approach explores more variants of acoustic features (rhythm, pitch, and energy) of the speech representation.\n- NAR decoding\n\nReproducibility\n- Model parameters are provided\n- ",
            "summary_of_the_review": "This work shows interesting results for a S2S translation task, for quality and decoding latency. The proposed approach addresses the modeling of more acoustic attributes that are not explored in previous work. This work allows for a better use of pre-trained self-supervised models, by generating a deterministic representation. Despite the improvements, the experiment setup is narrow and the motivation to combine quality improvement with latency is poorly stated.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_yedS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_yedS"
        ]
    },
    {
        "id": "oFPLjicN_GS",
        "original": null,
        "number": 4,
        "cdate": 1669153276835,
        "mdate": null,
        "ddate": null,
        "tcdate": 1669153276835,
        "tmdate": 1669153321183,
        "tddate": null,
        "forum": "UVAmFAtC5ye",
        "replyto": "UVAmFAtC5ye",
        "invitation": "ICLR.cc/2023/Conference/Paper2746/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper aimed at alleviating the acoustic multimodality problem for speech-to-unit approaches for direct speech-to-speech translation (S2ST) system. To address this problem, the authors developed bilateral perturbations (BiP) and leveraged the CTC fine-tuning technology. The bilateral perturbations include information enhancement on CTC input and style normalization on CTC target. Information enhancement applies information bottleneck on acoustic features to create speech sample variants in different acoustic conditions (considering rhythm, pitch, energy) while preserving linguistic content. In contrast, style normalization aims to eliminate acoustic-style information and creates acoustic-agnostic \u201cpseudo text\u201d.  After the bilateral perturbation, ASR system with CTC decoding would do better to generate deterministic representations, hence alleviating the acoustic multimodality problem.  The whole idea of bilateral perturbation and leveraging CTC fine-tuning is simple and intuitive. Analysis of unit error rates showed effectiveness of proposed Bilateral Perturbation in reducing acoustic multimodality. With bilateral perturbation, the authors developed NAR S2ST (TranSpeech), while applying the standard KD technology in NAR to reduce linguistic multimodality and prior work of mask-predict NAR unit decoder. Experiments showed effectiveness of BiP over AR baseline system (basic conformer) by 1.2-4.4 BLEU points and NAR baseline system (Transpeech-Distill) by 0.6-1.8 BLEU points. ",
            "strength_and_weaknesses": "Strengths:\n\n(1) The proposed bilateral perturbation approach for CTC fine-tuning to address the  acoustic multimodality problem is simple, intuitive and novel.\n\n(2) With the reduced acoustic multimodality, the paper explored NAR for direct S2ST. As shown in the results, NAR TranSpeech with KD achieved significant speedup over AR direct S2ST without a big degradation in translation accuracy.\n\n(3) The authors investigated a bag of tricks proposed in prior works, including conformer, KD for NAR, mask-predict NAR unit decoder, and other decoding choices including target length beam and NPD. Experiments evaluated efficacy of these tricks and analyzed performance-speed tradeoff, which are useful for future NAR efforts on direct S2ST. \n\n(4) Experiments and analyses are comprehensive. Experimental results on three language pairs of CVSS-C showed good gains in BLEU from the proposed BiP approach for both AR and NAR direct S2ST.  Analysis of unit error rates showed effectiveness of proposed Bilateral Perturbation in reducing acoustic multimodality.  The authors also compared to cascaded systems, which shows that there is still a lot of room for improvement for direct S2ST systems.\n\nWeaknesses:\n\n(1) The paper is overall clearly written. However, some technical details and discussions are missing and need to be included. Please check out the questions under Clarity.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality: \n\nThe paper is generally clearly written, but some technical details and discussions are missing and need to be included:\n\n(1)\tThe style normalization stage did not consider normalizations in rhythm. This needs to be explained.\n\n(2)\tThe HuBERT representations are pre-trained on natural speech. It would be useful to explain the quality of encoded representations by applying pre-trained HuBERT encoder on the style-normalized speech (whether encoding may suffer from reduced naturalness in the style-normalized speech).\n\n(3)\tFor pitch information in Information Enhancement, please elaborate the motivation for the choice of the chain function in this order, instead of other orders or other designs. Appendix C only provides details on each function, still misses answers to this question.\n\n(4)\tFor energy information in Information Enhancement,  please clarify how the average from a log-mel spectrogram is used.\n\n(5)\tIn the ablation analysis, it would help to add ID=4 results in Table 2. Based these results, it seems that adding SN on top of Basic Conformer + IE only brought quite a small gain on BLEU, as 0.41, 0.05, 0.03 respectively. This discussion needs to be added and more insights on how to improve effect of SN are expected.\n\n(6)\tNote that there are some typos, for example, Section 5.1, \u201cBELU\u201d should be \u201cBLEU\u201d.\n\nNovelty: \n\nThe proposed BiP approach is novel, simple, and intuitive. Experiments showed effectiveness of BiP in reducing acoustic multimodality and improving translation accuracy. The NAR direct S2ST achieved significant speedup over AR direct S2ST without a big gap in translation accuracy.\n\nReproducibility:  \n\nAlthough no source code is released, Section 5.1 and Appendix B and Appendix C provide sufficient details for reproducibility.\n\n\nPresentation: \n\nThere are some grammatical errors. For example,\n(1)Introduction, \u201cAmong the conventional method\u201d, method -> methods\n(2)\tIntroduction, \u201crecently proposed direct S2ST literature demonstrate\u2026\u201d,  demonstrate -> demonstrates \n(3)\tThere are quite a few subject-verb agreement errors.\n(4)\tSection 2, \u201cdemonstrates its outperformed translation results\u2026\u201d, outperformed -> outperforming\n",
            "summary_of_the_review": "This paper proposed a simple and intuitive bilateral perturbation (BiP) approach leveraging CTC fine-tuning for tackling acoustic multimodality in unit-based direct S2ST. The proposed BiP approach is shown to reduce acoustic multimodality. With this approach, the paper built non-autoregressive direct S2ST, TranSpeech, and achieved significant speedup over AR direct S2ST without a big degradation in translation accuracy. The authors also investigated other prior approaches such as conformer, KD, mask-predict unit decoder and other decoding choices for TranSpeech. The experiments are comprehensive. The proposed BiP approach achieved good BLEU gains over both AR and NAR baselines. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_H8Cj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2746/Reviewer_H8Cj"
        ]
    }
]