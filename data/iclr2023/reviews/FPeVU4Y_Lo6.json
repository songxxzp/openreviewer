[
    {
        "id": "G1MgwaYj7BQ",
        "original": null,
        "number": 1,
        "cdate": 1666465357647,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666465357647,
        "tmdate": 1666465357647,
        "tddate": null,
        "forum": "FPeVU4Y_Lo6",
        "replyto": "FPeVU4Y_Lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper1772/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose Newton losses, which breaks the loss optimization into two stages. The latent variable $z$ behaves as a target for the model output and is formed using a Newton step on the loss wrt the activations. The parameters are then optimized to match the target by minimizing a squared loss. The authors provide examples of different losses and validate the results experimentally.\n",
            "strength_and_weaknesses": "### Strengths:  \n* The motivation for the approach is clear.\n\n### Weaknesses:  \n* The authors have missed important previous work that introduces such techniques. Namely, lifted networks [1] propose a two-stage optimization scheme by introducing latent variables and matching the output of each later with the latent variables. More importantly, LocoProp [2] introduced the idea of setting layerwise targets and iteratively minimizing layerwise losses to match the targets. The method proposed in this paper is a special case of LocoProp where 1) only a single target is formed for the last layer via a Newton step (this was already discussed in LocoProp in terms of a natural gradient descent (NGD) targets, and the authors show that the final update wrt to the parameters corresponds to NGD), 2) the loss is set to be the squared loss whereas LocoProp uses more advanced Bregman divergences, 3) the model parameters are updated using a single step whereas, in LocoProp, the authors try multiple steps on the fixed point problem and show that the final update on the parameters corresponds to a preconditioned update.\n\n[1] Miguel Carreira-Perpinan, and Weiran Wang. \"Distributed optimization of deeply nested systems.\" In Artificial Intelligence and Statistics, pp. 10-19. PMLR, 2014.  \n[2] Ehsan Amid, Rohan Anil, and Manfred Warmuth. \"Locoprop: Enhancing Backprop via local loss optimization.\" In International Conference on Artificial Intelligence and Statistics, pp. 9626-9642. PMLR, 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "There are a few unclear definitions and notations:\n1) In Eq. (4), $\\Omega$ is used to denote the regularizer both for the model parameters and outputs. This is confusing since these two are of different natures.\n2) Page 4: what does element-wise Hessian mean? Does that mean diagonal approximation?\n3) I could not find the definition of $\\hat{y}$. Also, when defining expectations, please be more clear about what the expectation is wrt. For instance, Remark 1: the empirical Fisher should be an expectation wrt the training labels.",
            "summary_of_the_review": "The authors need to distinguish their work from lifted networks and LocoProp. Currently, their proposed method is a special case of LocoProp on the final layer with a single local iteration. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_T2yc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_T2yc"
        ]
    },
    {
        "id": "Ptl5ae-oQH",
        "original": null,
        "number": 2,
        "cdate": 1666590095581,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590095581,
        "tmdate": 1666590252839,
        "tddate": null,
        "forum": "FPeVU4Y_Lo6",
        "replyto": "FPeVU4Y_Lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper1772/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces an approach to efficiently computing updates that incorporate second-order information. The idea is to decompose the update into two parts: a second-order update of the loss function, and a first-order update of the model. Notably, this avoids having to compute the hessian wrt the model parameters, which would be expensive for complex models like neural networks. It's shown that the two-step scheme can be equivalent to gradient descent and to the newton step algorithm for certain choices of the updates. The approach is tested empirically on algorithmic supervision tasks.",
            "strength_and_weaknesses": "**Strengths** Breaking the update into an update wrt the loss function and an update wrt the model seems like an interesting and practical way to incorporate second-order information without computing the hessian wrt the model.\n\n**Weaknesses** The main weakness is that the math felt very imprecise to me throughout. For instance, throughout the paper argmin's are computed by arguing that the gradient is 0 at the argmin, but this isn't necessarily true since that point might have been outside of the domain. Similarly, there's often an implicit assumption that the model's range covers the entire domain, since this is how we get equivalence of $f(x;\\theta)=z^*\\in\\text{argmin}_z\\ell(z)+\\Omega(z,f(x;\\theta))$, which is used in the proof of Lemma 1 showing that the iterative and two-step method converge to the same points. This is not necessarily true without additional assumptions on the model class.\n\nSection 4 cataloguing various algorithmic supervision losses seemed mostly unnecessary and would potentially work better as an appendix",
            "clarity,_quality,_novelty_and_reproducibility": "I generally found the clarity low throughout, though this could be in-part due to my unfamiliarity with some of the problem settings. For instance, I've read the introduction to the experiments section several times and still have no idea what an \"algorithmic supervision\" task is. \n\nThe main source of confusion was the math though; much of the math very hand-wavy and imprecise to me, as mentioned above. \n\nThe approach seems somewhat novel, and the experimental results suggest that the newton loss can sometimes lead to strong performance improvements over using the regular loss function. \n\nThe empirical results serve mostly as a sanity check and don't seem to reveal any new insights in their own right. As far as reproducibility is concerned, I'm not confident I could reproduce these results unless a code release is planned.",
            "summary_of_the_review": "The approach seems interesting and reasonably motivated, but I am not confident that the math actually checks out and would be hesitant to recommend acceptance.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_qAQi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_qAQi"
        ]
    },
    {
        "id": "1NYdohHkbq",
        "original": null,
        "number": 3,
        "cdate": 1666628238209,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628238209,
        "tmdate": 1666628238209,
        "tddate": null,
        "forum": "FPeVU4Y_Lo6",
        "replyto": "FPeVU4Y_Lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper1772/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to formulate some algorithmic losses (e.g. sorting) as bi-level optimization problems and solve the inner problem with second-order optimization. It reports performance gains over regular optimization",
            "strength_and_weaknesses": "Strengths:\n* The performance improvements are consistent across the experiments.\n\nWeaknesses:\n* I find it extremely hard to understand what the contribution of the paper is supposed to be. Is it simply to use second order optimization on the the inner loss in bi-level optimization? Is it formulating some algorithmic losses as bi-level optimization problems? I also don't understand why the introduction opens up with a discussion of second-order optimization for neural networks, this does not seem relevant at all to what (I think) the paper is doing.\n* Related, I found it difficult to read the paper. The paper seems relatively practical to me, so I don't quite understand the choice to opt for a formal/mathematical style (Definition, Lemma, Theorem, Remark). Section 2 in particular seemed extremely verbose to me, while section 4 is lacking a lot of detail (without giving the reader a strong sense for what is going on in terms of the big picture).\n* The positioning is similarly opaque to me. While the related work cites a bunch of papers, I did not find a clear statement as to what gap in the literature the paper is trying to close and where it is improving over prior works.\n\nMinor comments:\n* Based on the title, I would have expected the paper to propose a method that includes second order information in the objective of general objective functions (similar to e.g. sharpness-aware minimization). I would suggest altering the title to make it more descriptive of the contents.\n* Inlining Tabs 2 & 3 makes reading the corresponding sections unnecessarily difficult.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity** I found it extremely difficult to follow the paper and it is not clear to me where the line between background and newly introduced material is.\n\n**Quality** Difficult to judge due to the lack of clarity.\n\n**Novelty** See quality.",
            "summary_of_the_review": "The contribution of the paper is not clear to me, so I'm arguing for rejection.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_fJV7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_fJV7"
        ]
    },
    {
        "id": "evqJHhSdxp",
        "original": null,
        "number": 4,
        "cdate": 1666649158689,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649158689,
        "tmdate": 1666649158689,
        "tddate": null,
        "forum": "FPeVU4Y_Lo6",
        "replyto": "FPeVU4Y_Lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper1772/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose to use second order method only on the loss function -- not throughout the whole network in the training process.\nThey are also putting a L2 term in the formulation.",
            "strength_and_weaknesses": "I don't see a strength in the formulation. Personally I have tried this method without introducing the L2 term and my finding is not quite satisfactory. Generally speaking when the Newton's method is only applied on the loss function it is a pretty weak method. Another way to think about it is if the loss function is a pure L2 loss, say for regression, then first order and second order methods are the same.\n\nAlso, if the authors are formulating the problem in a usable way, the L2 term should not be necessary. The second order information of the loss should be the only necessary thing to improve the training.\n\nLacking larger scale comparison is also a main problem with the paper. It is hard to say a piece of work is useful without scaling to imagenet-like datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is fair. Novelty is below the ICLR standard.",
            "summary_of_the_review": "Based on the limited novelty I vote for rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_GdUr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1772/Reviewer_GdUr"
        ]
    }
]