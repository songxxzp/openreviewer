[
    {
        "id": "i6F9W1onYIj",
        "original": null,
        "number": 1,
        "cdate": 1666759737914,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666759737914,
        "tmdate": 1666759737914,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a method for generating news articles conditioned on entities to appear in an article. The authors claim that existing methods for generating news articles only model text and ignore visual content and secondly that these methods do not explicitly account for named entities to be mentioned in generated articles. The authors argue that this makes the machine generated articles less natural and prone to failing to mention entities that should be mentioned and which would make the article more realistic.\nThe authors propose a method, called Engin, for generating news articles conditioned on entity information. Engin takes as input metadata and a list of entities to appear in the article and is trained to generate news articles.\nEngin also desires to take \"image information\" into account in generating the article. However, Engin is *not* conditioned on visual features from the image. Instead, the model uses the *ground truth\" captions as the representation of the image. \nFor providing named entities to the model, the authors consider two techniques. One is providing the ground truth entities to appear (oracle) and another is using a CLIP retrieval technique to discover these entities automatically.\n\nAuthors experimentally evaluate their method at generating news articles conditioned on entities and \"image information\". They compare their method against a number of recent techniques (GPT2, Grover, etc.) and show improved perplexity on their generated articles on two datasets (VisualNews and GoodNews). \nThe authors also provide a number of supplemental experiments. They performed a user study to assess how well humans could detect the generated articles and found that their articles were harder to detect than the baseline articles (hence higher quality). They also performed other ablations, testing the impact of different metadata fields on generation, the ability for machine discriminators to detect their articles, and for zero-shot article generation.\nThe authors also provide qualitative examples of the articles generated by their method. ",
            "strength_and_weaknesses": "[Strengths]\nThe idea of incorporating entity information into the generator is an important one. Existing methods for generating news articles, like GROVER, usually take in a title and generate the article based on that (and maybe the source it is supposed to be from). The article, however, fails to mention critical entities that would be mentioned in an article about that subject, making the generated article less realistic. By incorporating entity information into the generator, the model is able to generate more realistic articles.\n\nSimilarly, the authors attempt to integrate \"image information\". The authors argue that news image captions are different from typical image captioning in that the captions are much less visually grounded. The authors argue that directly integrating visual features is not idea and instead also condition their article generator on the captions. In this way, the generated article is much more likely to be related to the visual content paired with it.\n\nExperimentally, the authors demonstrate that their method is better able to fool humans and the machine discriminator, suggesting that the articles it generates are more naturally. The authors also demonstrate impressive gains in perplexity in their experiments and the qualitative results bear out the quality of the generation.\n\n[Weaknesses]\nThere are a number of weaknesses of the proposed approach.\n\nThe model is in some sense an extension to methods like GROVER. GROVER is quite similar to the proposed method in that GROVER trains a news article generator conditioned on metadata. In this paper, the authors essentially just re-train GROVER, but now add two additional metadata fields to the conditioning - one is the list of entities to be mentioned and the other is the *ground truth* image caption. From a technical perspectivie, there is little novelty to this approach. All the authors are doing is retraining GROVER using additional conditioning. Their is no novelty in the learning scheme, despite their being room for it.\n\nFor example, in the learning process used by ENGIN, no loss constraints enforce that ENGIN actually mentions all the named entities in the generated article. People have typically tackled this problem by using pointer-networks or similar strategies to perform a copying of named entities from the input into the output. The authors do not do this and it is unclear why not. Moreover, there is a lack of explicit loss to enforce named entities to appear and to penalize the model for their not appearing, save the standard text generation loss. Why don't authors enforce the model to actually use these entities and not ignore them?\n\nMost importantly from my perspective is that critical related work is not cited. The authors are not the first to condition news article generation on entities or visual information. InfoSurgeon (Fung et al, ACL 2021, oral) presents a method for detecting machine generated news articles. As part of the paper, the authors train a news article generation method. The generator takes in a knowledge graph consisting of entities, relations between entities, events, as well as purely visual entities detected using image features as well as image events detected using imSitu. In sum, the input to the model and its reliance on visual features is much richer than ENGIN. \n\nAs it stands, ENGIN relies on ground truth image captions to generate the article and incorporate visual information. However, as it stands, the model is never able to mention facts that are purely observable visually - for example, maybe an image shows three people cheering but the caption and entity list don't mention this. ENGIN is unable to make any such claim in the article text because it doesn't ingest any visual features. I also am somewhat concerned at the way the paper claims to take in \"Image Information\" but doesn't actually make use of any purely visual features (objects, image events, etc.) and instead relies on captions. \n\nThe CLIP-based NER mechanism is very simple. The authors just use CLIP to take an image's embedding and retrieve a set of candidate entities. Given that entities are a key component of your model, I would have expected a more rigorous or trained model to improve the entity selection mechanism.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear and easy to follow. The authors explain their method and appropriately cite the work it builds upon with sufficient detail to reproduce their results.\nThe paper is well put together and of high quality. However, the experiments and design of the method and model is a straightforward extension of existing techniques. Many obvious avenues for improving the model, such as improving the CLIP-based NER selection mechanism were not explored, so the method itself is of lower quality.\nOverall, the method is of incremental novelty over comparable methods like GROVER. The model does not take in any visual features and the paper is not the first to condition news article generation on entities, as the InfoSurgeon paper did this (and actually conditioned on more complex relation types while integrating image-only visual information). ",
            "summary_of_the_review": "The authors present a method for generating news articles that mention entities. As explained, the paper is well put together and the appropriate experiments are performed. However, the method is a straightforward extension of existing work and offers little technical novelty - it is highly similar to GROVER just adding an additional conditioning metadata field essentially.\nObvious avenues for improvement, such as improving CLIP-based NER were not performed.\nSimilarly, relevant work (e.g. InfoSurgeon) was not compared against or cited. \nVisual features are not used by the model.\n\nAt this time, I would argue the paper does not offer a sufficient contribution for publication as a conference paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Potentially harmful insights, methodologies and applications"
            ],
            "details_of_ethics_concerns": "The proposed approach is a text generation approach comparable to GROVER.\nGROVER has been used for generating misinformation online.\nThe experiments show that the articles generated by the authors' method are HARDER FOR  HUMANS TO DETECT as machine-generated.\nThe technoology could be used to spread disinformation that is harder to detect than existing methods.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_ewLW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_ewLW"
        ]
    },
    {
        "id": "iVzUysws1J",
        "original": null,
        "number": 2,
        "cdate": 1666857547242,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666857547242,
        "tmdate": 1666857547242,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work is in the domain of text generation for long-form articles. The key contribution of this work is to provide additional metadata in the form of named entities to the generative model. Such entities are either provided in advance (oracle) or can also be derived using entity retrieval based on image associated with the article. The empirical results show the benefits of the approach.",
            "strength_and_weaknesses": "**Strengths**\n\n-- The proposed method is quite elegant and simple and is easy to extend by following works.\n\n-- The entity retrieval method (using entity retrieval from a pretrained image-text model) makes the approach more generalizable and not dependent on a provided list of entities.\n\n-- The empirical results show effectiveness of the model as it outperforms all the baselines.\n\n-- The paper is clearly written and easy to follow\n\n**Weaknesses**\n\n-- While the application of named entities as additional metadata is novel to this domain, the same has been studied extensively in NLP literature. It is a good observation that existing methods do not explicitly model named entities, but the technical novelty of the proposed solution is limited.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow. The novelty is limited to the application of a well known concept/technique to a relatively new domain.",
            "summary_of_the_review": "Overall, while the method is quite simple and elegant and will propel more future work, this work has limited novelty in its current form.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_5iPM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_5iPM"
        ]
    },
    {
        "id": "2mEM4iunhrp",
        "original": null,
        "number": 3,
        "cdate": 1666883037413,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666883037413,
        "tmdate": 1666883156723,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed an entity-award article generation framework that incoperates image information. By using external tools such SpaCy and CLIP, this framework can extract named entity candidates to supervise text generation.",
            "strength_and_weaknesses": "This paper is well-written and easy to follow. The idea is simple but intuitive. Incorporating image information is very useful in article generation. The authors conducted extensive experiments and ablation tests to demonstrate the effectiveness of the proposed framework. \n\nWeaknesses: the proposed model only extracted the entity information from the image, while images contain various information out of entities. I would suggest to add a discussion section to outlook how to fully use the image information in this task. In addition, the way of entity-aware article generation is simple (this is not a weakness), but other structures to restrict/prioritize identified entities during the generation should also be tried.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clear and well-organized, I believe it is not difficult to reproduce the results. ",
            "summary_of_the_review": "Novel and interesting work, with good paper organization. But the structure of the framework is not fully explored. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_HgLz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_HgLz"
        ]
    },
    {
        "id": "ElOfiiRKuX",
        "original": null,
        "number": 4,
        "cdate": 1667060020229,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667060020229,
        "tmdate": 1669820228337,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper designs an entity-aware and image-information-integrated article generation method. The entities in the article are recognized with the help of image information and labeled with entity types. The paper claims that by annotating these entities on a target sequence, it enables the model to perceive entity information. The proposed model is evaluated on two news datasets and zere-shot Wikitxt and achieves excellent performance compared to the baselines.",
            "strength_and_weaknesses": "+ Strength\n  - The motivation of this paper is clear enough and it is interesting to introduce image and entity information in the article generation task. Image information augmented NLU and NLG has been explored in many works [1,2,3].\n  -  The model proposed in this paper is simple and effective and achieves good results compared to the baselines.\n+ Weaknesses\n  - Although the authors claim that image information is introduced, the model actually makes use of ground-truth captions and entities extracted from the article. The image information is only used for CLIP to retrieve the relevant entities. Thus, in my opinion, the utilization of images in this paper is too shallow and the ENGIN is more like a named entity-conditioned article generation work. Also, how would it work if use textual information (metadata) instead of image information to retrieve related entities from the candidate entities?\n  - There are some details of the method that I don't understand well enough. For example, \n     1. In inference, the generated text may contain annotations of entity types, right? then what do you do with these entity type annotations? \n     2. Is the utilization of named entities reflected in two aspects? The first is the generation conditioned on named entities. The second is the annotation of named entities and their categories in the target sequence during training. \n     3. When using image information for named entity retrieval, do you use entity names directly or construct specific prompts? Can you further analyze and evaluate the performance of named entity retrieval based on oracle NEs.\n  - I think the statements are inaccurate in many places, e.g.\n    1. 'our key contribution is a novel Entity-aware mechanism to help our model recognize and predict the entity names in articles'. The purpose of this paper is not to recognize entities. This statement would be confusing.\n    2. 'captions and named entities extracted from images'. I can't agree with the statement that the entities are extracted from the images, because the image information is only used to filter the entities recognized by Spacy.\n    3. 'existing methods model named entities uniformly with the other text, making the leverage of named entities less effective.' Can you explain the reasons for this? Or provide some experimental results to support it.\n\n\n[1] Visualize Before You Write: Imagination-Guided Open-Ended Text Generation\n\n[2] Imagination-Augmented Natural Language Understanding\n\n[3] Visually-Augmented Language Modeling",
            "clarity,_quality,_novelty_and_reproducibility": "The method proposed in this paper is simple and therefore not difficult for the reader to understand. However, the details of the method and some statements still need further clarification. Although the application of image information in NLG is interesting, I think this paper is overclaimed for the utilization of image information. In essence, this paper is still a named entity conditioned generation and thus the novelty is limited.",
            "summary_of_the_review": "Overall, I don't think the contribution of this paper is sufficient to be accepted as a conference paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_2PvE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_2PvE"
        ]
    },
    {
        "id": "eKI94S7rovg",
        "original": null,
        "number": 5,
        "cdate": 1667103717698,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667103717698,
        "tmdate": 1667103717698,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Summary:\n\nThis paper proposed to care about article generation with image information where the image info is used in an entity-aware way instead of directly using the visual features. That is, the embedded image in the associated article is firstly transformed into the textual space in the form of textual captions and textual named entities. After the image transformation, the textual contents extracted from the image act like normal body texts of an article, and are then integrated into standard controllable text generation models. To differentiate the entity texts from other texts, the entity categories are appended to the entity texts so the model can learn to predict the labels of named entities as well. Extensive experiments on three datasets are conducted with different model sizes.\n",
            "strength_and_weaknesses": "Strong & Weak:\n\nS1: It is novel to exploit image info in the form of textual entities extracted from it. In this way, the info contained in image and article body is now in the same/homogeneous feature space to be input to the generation model. The side effect is to explicitly alleviate the heterogeneity across the original text space and visual space in the input layer instead of the hidden layers. This may make the learning of modality fusion easier. Hope the authors can discuss furthermore from this perspective.\n\nW1: One possible weakness in my own opinion: While the proposed ENGIE is a new method for article generation with image recommender, each of the individual piece of ENGIE (entities extraction by SpaCy Python library, ranking candidate entities by CLIP, standard controllable text generation model) is not new in itself and has been widely adopted in existing works as pointed out in the paper. This may be not a big issue in practice, since ENGIE demonstrated a strong empirical result on three datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "writing is good; technical originality is somewhat weak; code is not given",
            "summary_of_the_review": "Comments:\n\nC1: The ENGIE model keeps the top $k=10$ candidate entities according to the similarity scores computed by the CLIP, any parameter cures varying with this $k$ to show its impact? \n\nC2: Furthermore, it seems (not clearly said in the paper) that the similarity score is independently computed between each individual entity and the image, and does not consider the relationships among different entities. (This is motivated by the CRF decoding strategy in named entity recognition where the labels/categories of the entities are related in a sequence.) For example, the top $k$ entities, say E1,E2,\u2026, have the maximum similarity scores independently, but can we find a semantic-dense (defined in a proper way) subgraph G\u2019, say it contains E1\u2019,E2\u2019,\u2026, which has larger sum similarity score SUM(G\u2019{E1\u2019,E2\u2019,\u2026}) than that of SUM(G{E1,E2,\u2026}). Hope some discussions are given in this direction.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_LeSY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_LeSY"
        ]
    },
    {
        "id": "OXaI4MDZBTg",
        "original": null,
        "number": 6,
        "cdate": 1667491900405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667491900405,
        "tmdate": 1667491900405,
        "tddate": null,
        "forum": "AtWKqgziLF",
        "replyto": "AtWKqgziLF",
        "invitation": "ICLR.cc/2023/Conference/Paper3185/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for article generation given visual information. Visual features from the embedded images are used to extract name-entity based on the CLIP model. Language model conditioned on the extracted entities along with other meta information is utilized to generate the body of the text. Experiments on three datasets including two news datasets show the efficacy of the model compared to GPT baselines.\n",
            "strength_and_weaknesses": "Strength\n1. The writing is clear and the proposed method seems straightforward and easy to implement.\n\nWeaknesses\n1. I\u2019m strongly skeptical about the prospect of using this technology to generate news articles, as the authors seem to aim at. Any words (especially nouns and verbs) hallucinated from the model instantly make the intended news article \u201cfake news\u201d. See the example in Figure 5. How much of the generated news article is true? Did Lizaso actually say that? This is also frightening as it sounds plausible (in a news article tone).\n\n2. The method lacks novelty. The image information essentially is only used to extract name entities (the caption is provided).\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written. I think the method lack novelty. The method seems straightforward and can be reproduced.\n",
            "summary_of_the_review": "I think the paper overclaims that it uses image information and the method is not novel enough for publication.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Potentially harmful insights, methodologies and applications"
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_g2Tq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3185/Reviewer_g2Tq"
        ]
    }
]