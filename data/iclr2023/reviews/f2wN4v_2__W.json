[
    {
        "id": "aF46WVPUhTB",
        "original": null,
        "number": 1,
        "cdate": 1666655664722,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655664722,
        "tmdate": 1666655664722,
        "tddate": null,
        "forum": "f2wN4v_2__W",
        "replyto": "f2wN4v_2__W",
        "invitation": "ICLR.cc/2023/Conference/Paper1071/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents an approach that generalizes symbolic regression\nto graph-structured physical mechanisms. As opposed to classical\nSymbolic Regression, this work assumes that X and Y in y=F(x) can be\nboth represented as graphs. The method is based on a two-level\noptimization procedure where first the formula skeleton is modeled\nwith a message-passing flow and parameters are learned. In a second\nstep, symbolization is used to each Deep Learning component.\n",
            "strength_and_weaknesses": "+ the idea of formulating the problem as a two step optimization problem, although not new, seems good in the context of this work\n- writing is a bit difficult to follow with some typos and sentences difficult to understand.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: average. Text could be more polished. \nClarity: could be improved.\nOriginality: the work seems to be original, specially mixing SR with GNN.",
            "summary_of_the_review": "This paper presents an approach that generalizes symbolic regression\nto graph-structured physical mechanisms. As opposed to classical\nSymbolic Regression, this work assumes that X and Y in y=F(x) can be\nboth represented as graphs. The method is based on a two-level\noptimization procedure where first the formula skeleton is modeled\nwith a message-passing flow and parameters are learned. In a second\nstep, symbolization is used to each Deep Learning component.\n\nQuestions, comments\n-------------------\n\ns2.3, p4: for each layer: what do you mean by layer (in a general\ngraph)? Why do you need layers?\n\nFor the simple case in mechanics scenario The detailed --> ??\n\nStep 1: predicted acceleration: shouldn't the model be generic?\n\nObtaining the final formula: you haven't mentioned genetic algorithms\nin the methodology. What are the parameters? (population size,\npopulation format, fitness function etc)\n\nIs it fair to compare your model with SymDL, since their purposes and\nknowledge representation are different?\n\nThere are some logic-based systems that can also learn formulas and\nfunctions. Why aren't they included in the related work and why aren't\nthey compared against your work? (e.g. https://arxiv.org/abs/2208.11561).\n\n\nOther comments, typos etc\n-------------------------\n\nfollowing bi-level the optimization --> following the bi-level optimization\nin this layers --> in this layer (in these layers?) (2x)\n\ncannot by handled --> cannot be handled\n\ncan describe a the projection --> ??\n \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_H8ss"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_H8ss"
        ]
    },
    {
        "id": "KyKwjyQpTV",
        "original": null,
        "number": 2,
        "cdate": 1666677720981,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666677720981,
        "tmdate": 1670653143211,
        "tddate": null,
        "forum": "f2wN4v_2__W",
        "replyto": "f2wN4v_2__W",
        "invitation": "ICLR.cc/2023/Conference/Paper1071/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "\nThe paper studies the problem of symbolic regression given the graph structure. It generalizes a previous approach (Cranmer et al. 2020) by additionally learning the formula skeleton. The method is seperated into two steps: searching the Pareto-optimal message passing flows and component-wise symbolic regression. Compared to (Cranmer et al. 2020), the second stage is not new, and the main novelty is to learn and prune the formula skeleton rather than manually designing one. Experiments on different scenarios demonstrate that the proposed method can learn better formulations and it has better prediction performance.",
            "strength_and_weaknesses": "Strengths:\n1. It provides a good problem setting. Symbolic regression on graph-structured data is an interesting topic. \n2. The proposed method is generally intuitive and reasonable. It is easy to understand that not all flows are useful and pruning the flows to get a compact one is a good way to obtain a concise formula.\n3. Nice visulaization and good experimental results.\n\nWeaknesses:\n1. The methodology of this paper is basically following (Cranmer et al. 2020). Its generalization seems essentially a combination of NAS and Symbolic Regression. It is useful, but slightly overstated. For most of the physical systems, we know the mechanism and the design of the \"flow\" seems definite and there is no need to search it. The authors showed one case in Appendix A.4, but it is still not so attractive, because the search space of the flows is not large. The choices of reasonable flows are actually limited. \n2. The definition of complexity and its weight may largely impact the results. The model is unstable. We may need to run multiple times to get the best formula.\n3. Presentation can be improved. For example, A.4 is important to demonstrate the advantage of the method (as described in the conclusion), I believe it should be put in main body of the paper instead of Appendix. The Figure 3 is described in a wierd place. In fact, in Sec 2.3 it only described the Fig 3(a), but not the whole framework. There are also some other unclear points as below.",
            "clarity,_quality,_novelty_and_reproducibility": "Questions/comments about clarity:\n\n1. I do not understand why there are multiple numbers of blocks and how they lead to final formula. From my understanding, if \\phi_e occurs in different blocks, the final formula will also contain two \\phi_e operations, but it seems the learned formulas in Figure4 are quite concise and do not have such overlaps. \n\n2. Definition 2: what is V', E'? Do you mean y is from a different graph? From my understanding y should be from the same graph but does not have overlap with X_i, i.e. y_i \\in {V, E, u}/X_i.\n\n3. typo: \u201cthe following bi-level the optimization\u201d -->\"the following bi-level optimization\"",
            "summary_of_the_review": "The paper is solving an interesting problem and it provides a decent solution. However, the significance and practicality are not convincing. The clarity also needs some improvement.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_dEBy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_dEBy"
        ]
    },
    {
        "id": "s3a07vTSkN",
        "original": null,
        "number": 3,
        "cdate": 1666690743761,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666690743761,
        "tmdate": 1666690743761,
        "tddate": null,
        "forum": "f2wN4v_2__W",
        "replyto": "f2wN4v_2__W",
        "invitation": "ICLR.cc/2023/Conference/Paper1071/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper improves SymDL by searching the Pareto-optimal message-passing flows to learn an additional formula skeleton. Such improvement empowers the method with more generality (requiring no prior knowledge), compactness, while maintaining correctness. Additionally, this paper also extends the applicability to Electricity and Thermology. Overall, the task formation is very interesting and the idea is simple but effective.",
            "strength_and_weaknesses": "Strengths:\n1. The studied problem is important and interesting. AI for science is a highly promising application field that has not been well explored. This paper has made an essential footstep toward finding scientific formulas in a more general and automatic way.\n2. Compared with existing works, this paper has tackled a more practical and challenging problem of learning the formula skeleton rather than manually designing, which is crucial for learning formulas in new physical domains with less prior knowledge.\n3. The proposed method is novel, especially the idea of transforming the discovery of the formula skeleton to the search for the Pareto-optimal message-passing flow with accuracy and compactness.\n4. The two main designs are technically sound. First, the transformation from learning skeleton to searching message-passing flow is correct as the latter corresponds to explicit meanings in the symbolic calculation for graph-structured mechanisms. Second, the design philosophy behind the proposed pruning-based search procedure is reasonable, based on an insightful observation that when the searched graph structure is a subset of ground truth instead of a superset, the optimized score/loss will increase significantly.\n5. The authors conduct extensive experiments. The proposed method can find correct formulas in five mechanisms with different difficulties, while compared methods only succeed in a simple case, i.e., mechanics as in Cranmer et al. 2020. Moreover, it can discover a new analytic formula that can predict real-world pedestrian dynamics more precisely.\n6. Overall, The paper is well-written and easy to follow.\n\nWeaknesses:\n1. For easy-to-use concerns, the paper should have a specific subsection that provides a practical guide on using the proposed method when discovering formulas in new physical domains. Currently, the related information is scattered in Sec. 3.1, Appendix A.3 and A.4, not concentrated enough.\n2. To better demonstrate the superiority of the designed pruning-based search procedure, authors can consider adding further studies in the appendix. For example, how about comparing with a random search method that does not decompose searching steps and does not leverage a pruning strategy? Also, Figure 6 can be improved by plotting four steps together, with the x-axis being absolute training time. This can make the explanation text much easier to follow.\n3. The clarity of this paper can be further improved as follows,\n    - Use a specific figure to demonstrate the design philosophy of the pruning-based search procedure.\n    - Give more details on the normalization process, as in \u201cWe normalize the input-output pairs to make the outputs have variance 1\u201d (Appendix A.3).\n    - Make related work part shorter and save space for results analysis, especially the real-world example in A.4.\n4. A few typos. e.g., on page 8, \u201cthe time cost of each independent part is shown in Table 6\u201d should be Table 3.\n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned in the above review, the paper is generally well-written but still has room for improving clarity. As for its novelty, I like the core idea of transforming the discovery of the formula skeleton into the search for the Pareto-optimal message-passing flow with accuracy and compactness, although the proposed method is built upon the SR method in Cranmer et al. 2020. Still, it is also reasonable and highly insightful. The authors have provided source code for reproducibility check.",
            "summary_of_the_review": "As mentioned in my reviews regarding strengths and weaknesses, I think this paper has tackled a more practical and challenging problem than existing methods. The proposed method is also with novelty and soundness. Moreover, besides finding correct formulas in several known mechanisms, the authors further use it to discover new formulas for predicting real-world pedestrian dynamics. It seems that the obtained formulas are not only more precise (compared with a manually designed one) but also with good interpretability. Hence, I am leaning on the positive side.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_oCCc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1071/Reviewer_oCCc"
        ]
    }
]