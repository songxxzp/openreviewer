[
    {
        "id": "YECiayOxg-",
        "original": null,
        "number": 1,
        "cdate": 1666581675627,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581675627,
        "tmdate": 1666581675627,
        "tddate": null,
        "forum": "3RhuF8foyPW",
        "replyto": "3RhuF8foyPW",
        "invitation": "ICLR.cc/2023/Conference/Paper935/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on hyper-parameter optimization for the federated learning (FL- HPO) problem which is important because the choice of the HPs can have a dramatic impact on the performance. However, there are still some challenges in this area, including the unavailability of the whole dataset, high communication costs, and no FL-HPO approach dealing with a non-neural network. In this case, the author put forward a general algorithm called FLoRA which can train both neural networks and non-neural networks in a single-shot way so that the number of communication rounds is highly saved. The single-shot method is to use different HPs in each client and calculates the loss, forming (HP, loss) pairs. Then, the center collects all (HP, loss) pairs from all clients and generates a loss surface using these data so that the best model can be selected. Moreover, how to generate loss surfaces is also discussed in detail, including SGM, SGM+U, APLM, and MPLM whose performances are also compared in the experiment.",
            "strength_and_weaknesses": "Pros: \n1. The studies problem is very important because hyperparameter tuning for federated learning under some privacy considerations and distributed nature turns out to be not trivial. The theory is a good plus with milder assumptions and higher generality. \n\n2. It is a general method that can be used in any ML model and the tabular data can also be trained, which is a great expansion in FL-HPO. The number of communication rounds is small since it utilizes a single-shot way that all the (HP, loss) pairs are transferred at a time. \u2028\n\n3. The article is logical and most parts are clearly explained. The proposed algorithm (combined with some popular solvers like Bayesian Optimization) is reasonable and seems to work well given the results in the experiments. \u2028\n\nCons: \n\n1. Some parts can be more clearer. For example, on page 6, what is the uncertainty function $u(\\theta)$, and how to choose the regularization parameter $\\alpha$ ?\n\n2. One key step in my opinion is the regression step to find the mapping f from HP to loss, i.e., line 6. This provides a possibility to reduce the communication rounds because the form of the regressor f is explicitly obtained. However, how does this regression step performs? Is it a linear regression or more complicated processes? How about the computational overhead of this process? I may miss something here, but I wish a clarification here. \n\n3. Figure 4 is a good visualization of the idea, which can be put in a more conspicuous way so that readers can understand it more rapidly.\n\n4. The authors mention that the considered setting has an asynchronous HPOS, but it seems to me that Federated Learning often follows a synchronized nature. Can the authors elaborate this a little bit? ",
            "clarity,_quality,_novelty_and_reproducibility": "The quality, clarity and originality of the work need to be improved. ",
            "summary_of_the_review": "Overall, this paper provides a neat method with good explanations and some theoretical justifications. The experiments seem to support the proposed method. I tend to weakly accept this paper given some concerns above and my low confidence score. However, I am happy to adjust my scores based on other reviewers\u2019 comments and the authors\u2019 response. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper935/Reviewer_mUdQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper935/Reviewer_mUdQ"
        ]
    },
    {
        "id": "SaLwBy6zyAp",
        "original": null,
        "number": 2,
        "cdate": 1666617077838,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666617077838,
        "tmdate": 1669030966720,
        "tddate": null,
        "forum": "3RhuF8foyPW",
        "replyto": "3RhuF8foyPW",
        "invitation": "ICLR.cc/2023/Conference/Paper935/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method for tuning the hyperparameters of ML models in the federated setting which only requires a single round of communication. The proposed method is general-purpose since it can be applied to tune the hyperparameters of any ML model, not only neural networks as in some of the previous works. The proposed method firstly lets every agent run local hyperparameter optimization, and then collect all hyperparameters from all agents to fit a loss function, which is then minimized to select the final hyperparameters.",
            "strength_and_weaknesses": "Strengths:\n- The studied problem, i.e., hyperparameter tuning in the federated setting, is highly relevant.\n- The single-shot nature of the proposed method is particularly desirable, since previous methods usually require a lot of additional communication rounds.\n- Some of the theoretical insights in Section 2.3 are very interesting, such as those which show the dependence of the optimality gap on the data heterogeneity and the quality of the local HP optimizations.\n\nWeaknesses:\n- The proposed method does not allow tuning per-party local HPs (paragraph above equation 2.5), I think this may be a limitation of the proposed method, since due to the heterogeneity of the agents, the best HPs for different agents are highly likely to be different.\n- The proposed algorithm (Algorithm 1) requires every agent to pass the raw HP observations to the central server, but wouldn't this lead to concerns regarding privacy? An important principle in FL is that the raw data of an agent can never be passed, and previous papers (see paper [1] below) have pointed out that the hyperparameters of an ML model can indeed contain sensitive information.      \n[1] Differentially private Bayesian optimization, ICML 2015.\n- In the experiments, the proposed method is only compared with a very weak baseline which simply uses the default HP from the package (it is not even optimized by any algorithm). I understand that most of the previous works on FL-HPO may not be comparable, but I think the proposed algorithm should have been compared with more competitive baselines. For example, a natural baseline I can think of is that after collecting all HP observations from all agents, you can simply return the HP that gives the lowest loss (among all HP observations from all agents). I think this makes sense because the loss surface aggregation is the most important technical contribution of the paper, hence this baseline which simply removes this component can be used to evaluate whether the proposed loss surface aggregation is actually useful. Furthermore, when comparing the \"communication savings over multi-shot\" (top paragraph of page 9), can you compare with some of the previous works on FL-HPO (i.e., those mentioned in Section 1.1) which are multi-shot methods?\n- Another important weakness of the empirical evaluation is that the FL algorithm is in fact emulated using centralized training (mentioned at the bottom of page 7). I think this makes the empirical evaluations unrealistic, and may not be able to reflect some unique features/challenges of the FL setting such as heterogeneity.\n- Table 4: some of the results are in fact worse than the baseline (which is in fact not so competitive as I discussed above) especially when the number of agents is large, which is worrying for the practical deployment of the proposed method especially in problems with a large number of agents.\n- Top paragraph of page 6: how exactly is the uncertainty quantification function u designed? I guess it's supposed to be larger if an HP has been explored by a smaller number of agents?\n- Top paragraph of page 7: it is claimed that the theoretical results imply that \"the optimality gap depends only on the HP trials $\\theta^{(i)}_t$ that are closest to the optimal HP setting\". However, I think this may not be accurate. This is because there is a max over all $\\theta\\in\\mathcal{\\Theta}$ on the right hand side of equation 2.9, therefore, to make the term $\\min\\_{t\\in[T]}d(\\theta,\\theta^{(i)\\_t})$ small for all $\\theta$, we need to make sure that the HPs $\\theta^{(i)}\\_t$'s are uniformly distributed in the entire domain. Please correct me if my understanding is incorrect here.\n- How exactly does the \"Multi-shot baseline\" in Figure 1 and Figure 2 work? This was never explained.\n- This may not be a weakness but rather a suggestion. The local HP optimization step for every agent (line 3 of Algorithm 1) may have room for improvement. Since now we have the opportunity to let every agent independently run HP optimization, we can in fact coordinate the local HP optimizations such that they can combine to lead to more accurate global loss surface estimation. For example, you can consider the method of \"distributed exploration\" from the work of Dai et al. (2021), and let every agent explore only a small local region of the entire search space.\n- [minor] I think it will be very helpful if you could explain in the introduction and abstract that being \"single-shot\" means only requiring a single-round of communication. It may be misleading to those not from the field.\n- [minor] Section 1.1, second paragraph: in \"Federated Network Architecture Search\", I think Network should be Neural.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarify: the paper is in general clearly written. The proposed single-shot solution is well motivated.\n\nQuality: Since the paper is more empirical than theoretical, the quality of the empirical evaluations has room for improvement, for which I've listed some points under \"Weakness\" above.\n\nNovelty: The proposed method is intuitive and is in fact not so novel. But the method is well motivated and reasonable.\n\nReproducibility: The code is uploaded for reproducibility.",
            "summary_of_the_review": "The method of this paper is well motivated, but I have many major concerns regarding the method and the empirical evaluations. I've listed my concerns under \"Weaknesses\" above, the first 5 points under \"Weaknesses\" are my most important concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper935/Reviewer_4yTc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper935/Reviewer_4yTc"
        ]
    },
    {
        "id": "_gfu87sDqIY",
        "original": null,
        "number": 3,
        "cdate": 1666687227646,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666687227646,
        "tmdate": 1666687227646,
        "tddate": null,
        "forum": "3RhuF8foyPW",
        "replyto": "3RhuF8foyPW",
        "invitation": "ICLR.cc/2023/Conference/Paper935/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Authors address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). Authors propose FLoRA, which (1) enables one-shot FL-HPO: identifying a single set of good hyper-parameters in a single FL training, (2) can be applied to tabular data and any machine learning models. FLoRA is mainly composed of (1) locally hyper-parameter optimization on each client (2) aggregate local hyperparameter into a global loss surface. Authors theoretically characterize the optimality gap of FLoRA for any convex and non-convex loss functions, which explicitly accounts for the heterogeneous nature of the parties\u2019 local data distributions. Authors use  default HP configuration of scikit-learn as the single-shot baseline. Compared with such a baseline, FLoRA shows significant improvement in final accuracy in several datasets and models. Authors further shows their method achieve significant communication savings compared with multi-shot HPO.\n",
            "strength_and_weaknesses": "Strength:\n\n1: The paper is well motivated. As stated by authors, FL-HPO is very important due to unavailability of global data and limitations on communication and computation budget.\n\n2: The proposed method focuses on general one-shot FL-HPO, which is very challenging and useful. Authors utilize fully independent local HPO and aggregate them into a global loss surface, which is a very novel idea. Further, authors propose several regressor methods to constrict such a loss surface.\n\n3: Authors provide a thorough theoretical analysis on the proposed method. \n\n4: Authors perform extensive experiments on different proposed methods on different models and tasks. In all experiments, the proposed method seems to be better than the baseline.\n\nWeakness:\n\n1: The major concern is that the main baseline, which is simply the default HP configuration in certain package, might not be a strong enough baseline. First of all, such baseline will not adjust HP based on current tasks and datasets (it is more like a zero-shot HPO baseline). I would suggest find other one-shot HPO methods or communication-restricted multi-shot HPO as main baseline, if it is possible. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality:\n\nOverall very good.\n\nNovelty:\n\nOverall seems to be very novel.\n\nReproducibility:\n\nOverall very good and code is provided. Maybe it will be better with an appendix on more details of experiments.",
            "summary_of_the_review": "I recommend weak accept of this paper. I must say I am not very familiar with FL-HPO and its related literature. I think the overall paper is well written and the proposed method is novel and effective. The only major concern is about the main baseline choice, which might be replaced with other one shot FL-HPO.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper935/Reviewer_rh1d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper935/Reviewer_rh1d"
        ]
    },
    {
        "id": "JjuYjfs7fL",
        "original": null,
        "number": 4,
        "cdate": 1666854432140,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666854432140,
        "tmdate": 1666856729447,
        "tddate": null,
        "forum": "3RhuF8foyPW",
        "replyto": "3RhuF8foyPW",
        "invitation": "ICLR.cc/2023/Conference/Paper935/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies how to perform hyper-parameter optimization in the context of federated learning, with minimal additional communication overhead. The authors propose a framework ---Federated Loss SuRface Aggregation(FLoRA)--- that requires only single-shot HPO for hyper-parameter optimization for FL. Theoretically, this paper provides an upper bound on the optimality gap, which captures the influence of parties\u2019 data heterogeneity (Non-IID-ness) and the quality of the local HPO approximation. Empirically, the proposed new approach could largely reduce the number of communications while maintains similar model performance. ",
            "strength_and_weaknesses": "Strength:\n\n1. The problem studied in this work is well-motivated and important in practice.\n2. This work provides a neat solution for solving the problem of hyper-parameter optimization (HPO) for federated learning, with only single shot HPO.\n3. The theoretical results covers the non-iid setting in FL.\n4. Empirically, the proposed approach largely improves upon previous methods in terms of communication overhead.\n\nWeaknesses:\n1. (minor) The experiments mainly focus on the non-deep learning approaches and MLP architectures, it might be interesting to include some modern deep network architectures, e.g., ResNet/ViT etc. \n\nQuestions:\n1. Regarding the loss surface $\\hat{\\ell}$, under certain assumptions on $f(\\theta)$, e.g. $f$ is (strongly) convex, can the upper bound in Eq.(2.9) be further improved? ",
            "clarity,_quality,_novelty_and_reproducibility": "(Clarity) This work is well presented.\n\n(Quality) High quality work.\n\n(Novelty) A novel approach for handling HPO in FL, as far as I know.\n\n(Reproducibility) Good.\n",
            "summary_of_the_review": "Given the importance of the problem and new approach for handling such problem, together with strong empirical results and interesting theoretical results, I recommend acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper935/Reviewer_wq54"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper935/Reviewer_wq54"
        ]
    }
]