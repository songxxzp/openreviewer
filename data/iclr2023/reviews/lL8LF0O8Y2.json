[
    {
        "id": "79b0CJMfl3",
        "original": null,
        "number": 1,
        "cdate": 1666474980016,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666474980016,
        "tmdate": 1666474980016,
        "tddate": null,
        "forum": "lL8LF0O8Y2",
        "replyto": "lL8LF0O8Y2",
        "invitation": "ICLR.cc/2023/Conference/Paper550/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of solving the subgraph counting problem using approaches based on neural networks. The proposed method leverages canonical partition to decompose the considered problem into subproblems, and the entire counting is further calibrated by gossip correction balancing homophily and antisymmetry. Experimental studies are provided to support the proposed designs.\n",
            "strength_and_weaknesses": "Strength:\n\nThe proposed ideas are reasonable. The identified example for showing the expressiveness of SHMP is particularly interesting. Most of the sections are well-written and easy to follow. Source codes are provided through external links. \n\n\nWeaknesses:\n\n- W1: The proposed method is reasonable but does not address the fundamental challenge in subgraph counting: the problem is still computationally hard after fixing a pair of nodes or a certain order of the nodes. That is, the acquired subproblems are in general as hard as the original problem. In this regard, the methods of canonical partition and gossip correction seem simplistic. \n\n- W2: The theoretical contribution is not strong enough, as there is no formal analysis other than one example. It would be better to justify the model expressiveness in a formal way. In addition, the results in Sec 4.2 are pretty straightforward. \n\n- W3: The experiments could be improved in the following aspects:\n  - Given the nature of the proposed method, the performance seems to depend on the node indexing schemes. Such an issue should be investigated at least in experiments.\n  - To justify the statistical significance of the learning performance, one should provide the robustness over the testing set (e.g., std) as well as the robustness over multiple individual trainings (e.g., cross-validation), which are required to rule to out the cases where a) the average error is low but the standard deviation is overly high and b) the trained model is accidentally good. \n  - To make it possible to have an in-depth understanding of the results, it is better to show the exact counting results rather than MSE. \n  - The hyperparameter P seems important, and therefore, it would be better to carefully study its impacts in experiments.\n  - One of the common practices is to select fixed query graphs, and then examine the performance; this paper lists a collection of query graphs, but it is not completely clear to me how they form the training-testing sets. Since this paper involves existing methods in experiments, it could be better to follow the exact settings in those papers, which will make the comparison clearer.\n  -The paper mentions pretraining but not training, which is a little bit confusing.\n\n- W4: Some minor comments:\n  - What does it mean by \u201ccombinatorially long runtime\u201d?\n  - The paper claims that their approach can easily support graphs with node features, which, however, seems non-trivial. A small experiment can be included to support such a claim.\n  - Some notations in Sec 4.1 are not well-defined.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is good, but the quality and novelty are less satisfactory.\n\nThe reproducibility could be better supported by showing the robustness of performance.\n",
            "summary_of_the_review": "This paper has some interesting ideas, but the overall contribution is not significant. The experiments need to be more convincing. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper550/Reviewer_Gava"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper550/Reviewer_Gava"
        ]
    },
    {
        "id": "SQZOGu5OtTn",
        "original": null,
        "number": 2,
        "cdate": 1666650853442,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650853442,
        "tmdate": 1666650853442,
        "tddate": null,
        "forum": "lL8LF0O8Y2",
        "replyto": "lL8LF0O8Y2",
        "invitation": "ICLR.cc/2023/Conference/Paper550/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a deep learning model for the task of subgraph counting. This is a challenging algorithmic problem and a well-known #P problem with applications in biology and social science. Deep learning approaches for subgraph counting have been proposed before, but the model presented by the authors improves both in the accuracy and, most notably, in scalability over existing approaches.",
            "strength_and_weaknesses": "Strengths:\n- Improved performance for a well-studied, relevant problem in the graph theory / network analysis literature\n- There is some novelty on the proposed SHMP module\n- Paper is well-organized and the visuals are very useful for understanding the proposed method\n\nWeaknesses:\n- It is not clear how the improved performance in MSE translates to better results in practice. Why should a practitioner care that the proposed method is more accurate? Is there, for instance, a case study where the proposed approach leads to new biological insights?\n- It is not clear why the authors decided to present squared error as a distribution in Figure 5. I think it would be more informative to see raw squared error numbers, as they present in the rest of the paper.\n- No comparison in terms of runtime to DIAMNet\n- Many typos across the paper ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is clear overall. The problem, competing methods, proposed approach, and experiments are clear to me.\nQuality: The manuscript would benefit from proof-reading to fix the numerous typos, which start at the first sentence in the abstract and end at the next-to-last sentence in the conclusions. The technical quality is below average.\nOriginality: In general terms, the idea of breaking down the subgraph counting problem into subproblems has been explored before (see, for instance, all the work in color-coding algorithms). However, I believe that there is novelty in the particular way in which the authors partition the graph.\n",
            "summary_of_the_review": "See my comments above. Overall, I believe this paper would make a fine addition to the conference and to the subgraph counting literature.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper550/Reviewer_eb8f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper550/Reviewer_eb8f"
        ]
    },
    {
        "id": "k_ae9pXoO4",
        "original": null,
        "number": 3,
        "cdate": 1666848844042,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666848844042,
        "tmdate": 1666848844042,
        "tddate": null,
        "forum": "lL8LF0O8Y2",
        "replyto": "lL8LF0O8Y2",
        "invitation": "ICLR.cc/2023/Conference/Paper550/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors designed a GNN-based framework for subgraph counting. Previous exact/heuristic methods are often slow, given  an NP hard problem. There are several key ideas: 1. canonical partition, 2. heterogeneous message passing, and 3. gossip correction. Extensive experiments are conducted to evaluate the effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strength:\n\n1. Experimental analysis (including those in appendix) is extensive. Additional scalability study / q-error analysis present new insights.\n\n2. The idea of canonical partitioning is novel to me.\n\nWeakness:\n\n1. Apart from exact methods, there are also many recent sampling based estimation methods. Sampling-based methods are not exact, but are significantly faster and often have theoretical guarantees. Some discussion or even comparison to this line of work is needed.\n\n[1] Bressan, Marco, Stefano Leucci, and Alessandro Panconesi. \"Faster motif counting via succinct color codingand adaptive sampling.\" ACM Transactions on Knowledge Discovery from Data (TKDD) 15.6 (2021): 1-27.\n[2] Wang, Pinghui, et al. \"Efficiently estimating motif statistics of large networks.\" ACM Transactions onKnowledge Discovery from Data (TKDD) 9.2 (2014): 1-27.\n\n2. Traditional methods like VF2 runs on CPU, which is not exactly a fair comparison to GNN methods which runs on GPUs. There are also some GPU-based exact methods [3]\n\n[3] Lin, Wenqing, et al. \"Network motif discovery: A GPU approach.\" IEEE transactions on knowledge and dataengineering 29.3 (2016): 513-528.\n\n3. There are also some newer GNN-based baseline [4].\n\n[4] Liu, Xin, and Yangqiu Song. \"Graph convolutional networks with dualmessage passing for subgraph isomorphism counting and matching.\" Proceedings of the AAAI Conference onArtificial Intelligence. 2022.\n\n4. It would be more beneficial if the authors can demonstrate some case work--- how reduced error translate to accuracy in downstream tasks that makes use of such counts? While it is certainly good that MSE is reduced, e.g. from 1 to 0.6, it is not intuitive how significant is such reduction.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. There is some novelty in the proposed idea.",
            "summary_of_the_review": "In short, i think the strengths slightly outweigh the weaknesses. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper550/Reviewer_Eqk2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper550/Reviewer_Eqk2"
        ]
    }
]