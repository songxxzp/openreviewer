[
    {
        "id": "R67kHwbHQpU",
        "original": null,
        "number": 1,
        "cdate": 1666530535643,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530535643,
        "tmdate": 1666530535643,
        "tddate": null,
        "forum": "K96AogLDT2K",
        "replyto": "K96AogLDT2K",
        "invitation": "ICLR.cc/2023/Conference/Paper3849/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The article analyzes the convergence of quantum neural networks (QNNs) where the employed ansatz shares the same symmetry of the problem Hamiltonian, and gives an analytical convergence rate under the framework of the quantum neural tangent kernel. More precisely, they use the information of the problem Hamiltonian to shrink the solution space to an invariant space with dimension $d_{eff}$ (dubbed effective dimension). Furthermore, they exploit the effective dimension to propose the effective quantum neural tangent kernel (EQNTK) to capture the training dynamics symmetric ansatz. They show that a symmetric ansatz with a small effective dimension has a large EQNTK, leading to better trainability. Guided by EQNTK, they further devise a paradigm of ansatz design where a symmetric ansatz is extracted from an over-parameterized one by pruning redundant symmetry-breaking gates.",
            "strength_and_weaknesses": "Strength:\n1. The article is well-written and obtains some positive results for the training of QNNs, which is of prominent importance for researchers studying variational quantum algorithms.\n2. The achieved analytical results of convergence based on the EQNTK have practical guidance on trainability without any training procedure. \n3. The proposed symmetric algorithm provides a novel vision for devising a symmetric ansatz to reduce the quantum resource required for reaching the over-parameterization regime. \n\nWeakness:\nThe paper did not discuss the connection with existing studies about geometric quantum machine learning or equivariant quantum circuits. I\u2019d like to see the authors\u2019 response to this issue.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is well organized and clearly stated in general.\n\nQuality: this is a high-quality paper.\n\nNovelty: the originality is high.\n\nReproducibility: all important parts are provided for reproducing.",
            "summary_of_the_review": "This paper provides elegant and rigorous theoretical results towards understanding the trainability of QNNs with symmetric ansatzes. The proposed algorithm is effective but still has room for further improvement.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_WF6w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_WF6w"
        ]
    },
    {
        "id": "b3dGvHCa4T",
        "original": null,
        "number": 2,
        "cdate": 1666576126081,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666576126081,
        "tmdate": 1666576126081,
        "tddate": null,
        "forum": "K96AogLDT2K",
        "replyto": "K96AogLDT2K",
        "invitation": "ICLR.cc/2023/Conference/Paper3849/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the trainability of quantum neural networks (QNNs) with symmetric ansatzes and how to exploit the symmetry to improve the trainability of QNNs. More precisely, it provides a theoretical understanding of the better trainability of symmetric ansatz over asymmetric ansatz by proposing the effective quantum neural tangent kernel (EQNTK) and connecting it to the over-parameterization theory. With the support of the theory, it proposes a symmetric pruning algorithm to extract a symmetric ansatz from an over-parameterized but asymmetric ansatz to improve the trainability of QNNs.",
            "strength_and_weaknesses": "Given many recent negative results on the trainability of QNNs, such as the barren plateau and convergence, with the importance of trainability for variational quantum algorithms, results given here are useful for the researchers in this field to devise symmetric ansatz with better training performance to achieve the potential quantum advantage. The results themselves focus on the problem of ground state preparation but they are applicable to general quantum machine learning problems. Their main results of the analytical convergence rate depend on the effective quantum neural tangent kernel, which can be easily calculated by calculating the norm of parameter gradients. This facilitates the evaluation of the convergence of QNNs without any training procedure. Another contribution of this paper is proposing a novel paradigm of exploiting pruning techniques to devise symmetric ansatz. As the symmetry pattern of the problem Hamiltonian is sophisticated, they employ the automorphism algorithm from graph theory to recognize the spatial symmetry of the problem Hamiltonian and apply it to prune the ansatz.\n\nA small collection of numerical simulations is given which show the effectiveness of symmetric pruning and justify the important role of EQNTK in guiding the trainability of QNNs. However, the paper did not numerically show that the EQNTK can capture the training dynamics of QNNs. I would like to see a figure display like Figure 2 in [1] in the author\u2019s response.\n\nTypos:\n- In the sentence \u201cThe above results indicate that when the number of trainable parameters scales with $LK \u223c O(d_{eff}^2/(\\eta Tr(H^2 )))$\u201d, the $H$ should be $H^*$.\n- \u201cRecall the considered the problem Hamiltonian is expressed \u2026\u201d.\n\n[1] Junyu Liu, Khadijeh Najafi, Kunal Sharma, Francesco Tacchino, Liang Jiang, and Antonio Mezzacapo. An analytic theory for the dynamics of wide quantum neural networks. arXiv preprint arXiv:2203.16711, 2022b\n",
            "clarity,_quality,_novelty_and_reproducibility": "It is a nice original paper with clear statements.",
            "summary_of_the_review": "This paper obtains important theoretical results showing that constructing symmetric ansatzes improve the trainability of QNNs and provides a practical algorithm to devise symmetric ansatzes.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_1zgw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_1zgw"
        ]
    },
    {
        "id": "xh303xzQ03",
        "original": null,
        "number": 3,
        "cdate": 1667451406691,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667451406691,
        "tmdate": 1668720375223,
        "tddate": null,
        "forum": "K96AogLDT2K",
        "replyto": "K96AogLDT2K",
        "invitation": "ICLR.cc/2023/Conference/Paper3849/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a quantum NTK framework to improve the training convergence of QNNs for the GSP problem via a symmetric ansatz design with a small effective dimension. It also proposes a novel symmetric pruning algorithm to extract the symmetric ansatz from the overparameterized and assymetric ansatz. Empirical results confirm the effectiveness of this symmetric pruning algorithm and the quantum NTK framework.",
            "strength_and_weaknesses": "Strengths\n+ The paper seems well-motivated and the problem statement is clearly explained.\n+ The convegence bound of QNNs with various symmetric ansatz is significantly improved.\n\nWeaknesses\n- I don't think the authors did a good job at positioning their paper with prior art. For example, I would have liked a thorough comparison with related works in Section 5. Instead of having blanket statements like \"Our results differ from the above literature in both theoretical and practical aspects\", it would be better if the authors can clarify how this work is better in terms of both the QNN training and symmetric ansatz.\n- Can the authors quantify the hardware efficiency improvement of their symmetric ansatz?",
            "clarity,_quality,_novelty_and_reproducibility": "To the best of my knowledge, this work is original. I did a quick search and it seems the authors have referenced related works adequately in the paper. The writing is good, but can be improved for non-experts in this area. In particular, I would have appreciated some primers on GSPs and Hamiltonians.",
            "summary_of_the_review": "This paper appears sound and novel. Please see the weaknesses listed above. I am not an expert in this area, and I am giving a rating of 6 for now. Based on the authors' rebuttal and discussions with other reviewers, I can reconsider my score.\n\n----------\nReview Update\n\nI have changed my score to 8 based on the authors' response.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_feix"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3849/Reviewer_feix"
        ]
    }
]