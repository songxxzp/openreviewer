[
    {
        "id": "uzJc622Sub",
        "original": null,
        "number": 1,
        "cdate": 1666513922934,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666513922934,
        "tmdate": 1666513922934,
        "tddate": null,
        "forum": "m1oqEOAozQU",
        "replyto": "m1oqEOAozQU",
        "invitation": "ICLR.cc/2023/Conference/Paper2406/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies GNN-based link prediction models. The authors experimentally analyze the components of existing subgraph GNN (SGNN) methods for link prediction, which exhibit some limitations and redundancy. Then propose a novel method that passes subgraph sketches as messages, which mitigates these issues effectively. ",
            "strength_and_weaknesses": "Strength:\n1. The analysis on the components of existing SGNN methods for link prediction is well-conducted and the results are informative, which may inspire new thoughts on SGNN-based link prediction.\n2. The idea that passes subgraph sketches as messages is novel.\n3. The empirical results render the efficiency and effectiveness of the proposed method.\n4. A more scalable variant is implemented, which prepropagates the node features in the preprocessing stage. This further mitigate the scalability issue of SGNN-based link prediction such as SEAL.\n\nWeaknesses:\nI found the expressiveness analysis is less exciting. Here, more powerful means the capability of distinguishing automorphic nodes. But this can be realized by simple techniques such as adding random features. So, I don't think this is a good theoretical justification of better performance. Can you provide some comments on this?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and well-written. The proposed method is motivated by careful experimental studies and clearly described. The idea that passes subgraph sketches as messages seems novel to me.",
            "summary_of_the_review": "The paper investigates the components of existing SGNN link prediction methods and identifies several key limitations and opportunities of improvements. Then proposes a novel method to use subgraph sketches as messages. Empirical results clearly show the advantages of the proposed method. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_ucmP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_ucmP"
        ]
    },
    {
        "id": "feoMVOcM-ZU",
        "original": null,
        "number": 2,
        "cdate": 1666588969853,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666588969853,
        "tmdate": 1666588969853,
        "tddate": null,
        "forum": "m1oqEOAozQU",
        "replyto": "m1oqEOAozQU",
        "invitation": "ICLR.cc/2023/Conference/Paper2406/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel Graph Neural Networks, ELPH and BUDDY, that estimates key structural information in subgraph GNN without explicit subgraph construction. Specifically, the proposed method estimates intersection and cardinalities using subgraph sketching and incorporates them into Message Passing type GNNs. The paper provably shows more expressive power than Message Passing GNNs and experiments conducted on six link prediction benchmarks show both effectiveness and efficiency compared to state-of-the-art baselines.\n",
            "strength_and_weaknesses": "Strengths\n\n- The essential factors for the performance of existing subgraph-level GNNs are well analyzed through the experimental observation of the SGNNs.\n\n- The proposed idea of effectively estimating intersections and cardinalities without subgraph construction is interesting and novel.\nBy leveraging structural features, the proposed method addresses the inefficiency of existing subgraph-based methods and the automorphic node problem in MPNN.\n\n- Experiments conducted on six link prediction benchmarks show both the effectiveness and efficiency of ELPH and BUDDY compared to recent GNN-based baselines.\n\nWeakness\n\n- Performance between baselines in ogbl-collab does not seem to be compared fairly. The performance of SEAL in ogbl-collab seems to be the performance using the validation set for training whereas other GNN-based methods (GCN, SAGE, Neo-GNN) don\u2019t seem to use the validation set for training.\n\n- It would be good if there were comparisons with GNNs with existing proposed structural features (e.g., DE [1] and node2vec [2]).\n\n[1] Li, Pan, et al. \"Distance encoding: Design provably more powerful neural networks for graph representation learning.\" Advances in Neural Information Processing Systems (2020)\n\n[2] Grover, Aditya, and Jure Leskovec. \"node2vec: Scalable feature learning for networks.\" Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 2016.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of the paper is clear and easy to follow. Also, the proposed idea is very interesting and novel. See the above section on strengths and weaknesses.\n",
            "summary_of_the_review": "This paper presents a novel Graph Neural Networks, ELPH and BUDDY, that estimates key structural information in subgraph GNN without explicit subgraph construction. The presentation of the paper is clear and the proposed idea is very interesting and novel.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_jqUA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_jqUA"
        ]
    },
    {
        "id": "W89_GqY2Mu",
        "original": null,
        "number": 3,
        "cdate": 1666669151322,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669151322,
        "tmdate": 1666669744321,
        "tddate": null,
        "forum": "m1oqEOAozQU",
        "replyto": "m1oqEOAozQU",
        "invitation": "ICLR.cc/2023/Conference/Paper2406/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focused on the research problem of link prediction with GNNs. The authors comprehensively analyzed why the subgraph-based GNNs performs good on link prediction, as well as their efficiency problems. The authors then proposed to estimate the key structural information with subgraph sketching. Doing so combined the advantages of effectiveness on SGNNs as well as the efficiency on full-graph GNNs. \n",
            "strength_and_weaknesses": "S1. This paper is overall clearly written and easy to follow.\n\nS2. The proposed method is very well motivated with comprehensive analysis on why subgraph GNNs works well.\n\nS3. The proposed method is able to successfully combine the advantages of SGNN as well as normal GNNs for link prediction. \n\nW1. Part of the notations in Sec. 2 are a bit confusing. For example. is $Z_{uv}$ a matrix / set of node embeddings or a vector of subgraph embedding? And why is the $u$ in $\\mathbf{y}_{\\mathbf{u}}$ (Eq. (1)) bolded, but not bolded elsewhere (e.g., in the following paragraph)?\nI suggest the authors to follow the common way of denoting vectors and matrices. E.g., using bold lowercase for vectors and bold uppercase for matrices. Currently most but no all of the paper follows that.\n\nW2. I assume the complexity in Sec. 5 and Table 1 are time complexity. If yes, it would be nice if the authors can also provide the space complexity analysis.\n\nW3. As one of the goal of the proposed method is to obtain the effectiveness of subgraph GNNs while still being efficient and scalable, I think it would make the evaluation more comprehensive if the authors can also include the runtime of normal GNNs in Table 3 for comparison.  \n\nMinor ones:\n\nW4. Missing some recent relevant link prediction citations. E.g., [1][2]\n\nW5. In the first paragraph of Introduction, why are points i and ii bolded by not iii?\n\n[1] Learning from Counterfactual Links for Link Prediction, ICML 2022 \\\n[2] Neural Link Prediction with Walk Pooling, ICLR 2022",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is overall clearly written and easy to follow.\n\nQuality: the proposed method seems sound to me.\n\nNovelty: the proposed method is novel by combining the advantages of two approaches. \n\nReproducibility: while the description of the proposed method is detailed, the implementation was not provided.",
            "summary_of_the_review": "Based on the above comments, I recommend acceptance. But I still encourage the authors to address the weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_9q6R"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_9q6R"
        ]
    },
    {
        "id": "PGJYjH0qrLW",
        "original": null,
        "number": 4,
        "cdate": 1667251111573,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667251111573,
        "tmdate": 1667251111573,
        "tddate": null,
        "forum": "m1oqEOAozQU",
        "replyto": "m1oqEOAozQU",
        "invitation": "ICLR.cc/2023/Conference/Paper2406/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a faster and more powerful GNN dedicated for the link prediction task. It captures the essence of success from previous state-of-the-art link prediction methods: subgraph-based structure encoding, which is essentially counts of various \"common neighbors\". To accelerate subgraph-based structure encoding, the authors sharply draw from its connection with the message passing form of computing graph sketches, and integrate this process into MPNN's framework. Experiments show that the proposed method achieves better performance compared to previous SOTAs in terms of both accuracy and scalability.\n\n",
            "strength_and_weaknesses": "I am the author of one of the main baselines compared in the paper. I believe that this is an excellent paper with the following significant contributions:\n1. It unifies the several existing state-of-the-art methods for link prediction prediction and does systematic analysis to show their actual strengths of design. \n2. It is fascinating to see how the computational redundancy in subgraph-based neighbor counting can be eliminated by the message passing form of graph sketch using hyperloglog and minhashing. This is one of the most innovative and smartest GNN designs I have seen in a while.\n3. The experiments including those in Appendix D show that the proposed method perform very well by both accuracy and speed. The main claims in the theoretical parts are well substantiated by the experiments.\n\nWeaknesses:\nI don't see it as a strong negative but I have a question about Fig. 2: it is a bit surprising to see that DRNL (SEAL) can outperforms DE by such a huge margin on Pubmed, considering that SEAL's node labeling function is not more expressive that DE's one-hot distance encodings. Can any explanation be provided on that?\nAlso just a minor typo: the citation after \"Distance Encoding (DE)\" on Page 4 seems incorrect.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall writing quality is very good. However, no code is provided. ",
            "summary_of_the_review": "I strongly recommend the acceptance of the paper for reasons outlined above. However, it would be great to see the code be made available considering that this is very likely to be an impactful piece of research.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_ntmc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2406/Reviewer_ntmc"
        ]
    }
]