[
    {
        "id": "THJD98H5oYn",
        "original": null,
        "number": 1,
        "cdate": 1666000936440,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666000936440,
        "tmdate": 1670878920745,
        "tddate": null,
        "forum": "Jzliv-bxZla",
        "replyto": "Jzliv-bxZla",
        "invitation": "ICLR.cc/2023/Conference/Paper5285/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a novel sampling strategy for collocation points to improve the training performance of PINNs. The strategy is based on the propagation hypothesis, which suggests that information from the boundary of the computational domain has to \"propagate\" to its interior, and that this propagation sometimes fails during PINN training. The authors show that the approach indeed leads to more stable training.",
            "strength_and_weaknesses": "The paper is excellently written, and the arguments for the Evo strategy are clear. The approach is simple, intuitive, and yet effective. The experimental evidence is good, although I would appreciate results with more benchmarks.\n\nThe two weaknesses I see are that 1) the benefit of Causal Evo is not shown or discussed in the experiments, and 2) that comparisons with some parts of the literature are missing entirely or difficult to evaluate.\n\n## Ad 1)\nI understand Evo as a method that mitigated training failures, rather than one that improves performance for a successfully trained PINN. Thus, from that perspective, Evo and Causal Evo perform equivalently in the shown experiments. It would be interesting to see an example where Evo fails because causality is not respected, but where Causal Evo successfully trains the PINN.\n\n## Ad 2)\nI am missing other approaches that have been proposed to mitigate training failures. These approaches include domain decomposition, loss weighting schemes, the architecture from arXiv:2109.09338, or the regularization term proposed in arXiv:2112.05620. It would further be interesting to see if and how the sampling scheme can be combined with the former methods. Further, the comparison is difficult to evaluate because the chosen benchmarks show little overlap with what has been proposed in the literature. For example, CPINN was evaluated in the original paper on a set of benchmarks that does not intersect with the benchmarks chosen in this paper. I would be interested to see how Evo performs on these benchmarks.\n\n## Minor\n- In the paragraph \"Propagation Failure\", the authors argue that trivial solutions can become attractive for PINNs. This has been made precise theoretically in arXiv:2109.09338 and experimentally in arXiv:2203.13648.\n- References to the appendix are broken.\n- The computational overhead of the comparison methods is not clear (\"Challenges with Potential Remedies\"). Similarly, for Evo it is not clear how $\\mathcal{P}_i^s$ changes throughout training (i.e., is it of fixed size, or is rather $\\mathcal{P}_i$ of fixed size?).\n- The four salient properties seem somewhat artificial and post-hoc. For example, the gradual accumulation property is not well justified. As an alternative property, it seems equally intuitive that initially the collocation points should concentrate around the initial and boundary conditions (ensuring successful learning locally, from which propagation can continue), while at later stages the collocation points should be uniform (ensuring uniform accuracy across the computational domain). Thus, a priori, the CPINN sampling strategy seems equally powerful to mitigate propagation failures as Evo. It is even more interesting to see that the CPINN fail for the systems for which Evo succeeds, and I would appreciate an evaluation of Evo on the benchmarks that were chosen by the original authors of CPINN.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and of high quality. The novelty is somewhat limited by the fact that several sampling schemes have been proposed so far, and that the experimental evaluation is limited to only two systems (one with two different parameterizations). Code and datasets are available, which makes the paper reproducible.",
            "summary_of_the_review": "A clear paper with an intuitively appealing, simple, and yet effective method to mitigate training failures in PINNs. To judge if Evo is a major contribution towards PINN training requires more evidence.\n\n*EDIT:* Raised my score according to the discussion with the authors.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_rJ3m"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_rJ3m"
        ]
    },
    {
        "id": "lC_nJJ0FP7",
        "original": null,
        "number": 2,
        "cdate": 1666102315777,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666102315777,
        "tmdate": 1666194990141,
        "tddate": null,
        "forum": "Jzliv-bxZla",
        "replyto": "Jzliv-bxZla",
        "invitation": "ICLR.cc/2023/Conference/Paper5285/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes \"the propagation hypothesis\" as an explanation of why some (collocation) sampling schemes might cause PINNs to fail.\nTo mitigate the issue, the authors propose an _evolutionary_ sampling strategy, that keeps points with high error in a pool and resamples others. They also incorporate a time-weighting scheme to propagate the importance of samples from $t=0$ onwards. The authors show that their method outperforms prior art in 3 datasets when the number of samples used is small.",
            "strength_and_weaknesses": "## Strengths\n* Authors formulate an intuitive concept to identify failure modes of PINNS;\n* Authors propose a simple strategy that improves significantly the sample efficiency of PINNS;\n* Ideas are clearly presented and the work is easy to follow.\n\n## Weaknesses\n* The idea of focusing on regions of high error is not exactly novel in PINNs;\n* While the \"propagation hypothesis\" is intuitive, there is no formal characterization for it in the work;\n* The experimental campaign is shorter than I would expect from a paper with a  very simple idea and no theoretical guarantees;\n* The theory is inconsistent (and perhaps wrong) --- see details below.\n* The experiments lack a more thorough discussion. For instance, do you have an intuition on why Evo is capable of solving the Eikonal equations in some cases (Figure 8) and other methods not? \n\n###More about the theory\n\nFor **theorem 3.1**, there are two issues: \n\n1. The step from lines 5 to 6 on page 11 of the appendix multiplies by $V^{-1/2}$ but should multiply by $V^{1/2}$ since $p(\\mathbf{x}_r)^{-1} = V$;\n\n 2. The paragraph before theorem 3.1 is misleading. It says that sampling proportional to a power of $\\mathcal{R}$ is equivalent to changing the $L^p$ loss in the norm. However, minimizing $\\mathcal{L}^2_r(\\mathcal{Q}^k)$ is not the same as minimizing $\\mathcal{L}^2_r(\\mathcal{Q}^k)$  (or a power thereof) os not the same since $Z= \\int_{\\mathbf{x}_r \\in \\Omega} |\\mathcal{R}(\\mathbf{x}_r) |^k d\\, \\mathbf{x}_r$ depends on network parameters (and therefore is not a constant). \n\nFor **theorem 4.1**, states that, as the number of iterations of Algorithm one approach $\\infty$, their loss reverts to an $L^\\infty$ loss. However, on page 5, the authors state that training PINNS with $L^\\infty$ is undesirable and can lead to $oscillatory behavior between different peaks of the PDE residual landscape\". Does this mean we should always use a small number of iterations in Algorithm 1? This aspect deserves further discussion.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Overall, the paper is well written. \n\nQuality: I have some concerns regarding the theory (listed above).\n\nNovelty: Somehow,  proposals are mostly reappraisals of previous techniques for PINNs (i.e., weighting based on error and enforcing \"physical causality\").\n\nReproducibility: The authors also provide code and experiments seem reproducible. ",
            "summary_of_the_review": "Given that the novelty is somehow limited and my concerns with the implications of the theory & the short experimental campaign, I recommend rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_9MDS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_9MDS"
        ]
    },
    {
        "id": "wwB6e-9Ufg",
        "original": null,
        "number": 3,
        "cdate": 1666670344634,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670344634,
        "tmdate": 1670696141721,
        "tddate": null,
        "forum": "Jzliv-bxZla",
        "replyto": "Jzliv-bxZla",
        "invitation": "ICLR.cc/2023/Conference/Paper5285/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to use evolutionary sampling to mitigate failures in training PINNs. The main idea is based on the premise that solution of a PINN propagates from boundaries towards the interior regions. In contrast to existing work, Evolutionary sampling is able to adapt to the changing PDE residual error landscape while being computationally efficient. Experiments are conducted on multiple challenging PDEs, and the results demonstrate the effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strengths:\n1. Well written, proposed method is sound for the most part.\n2. Experimental validation is conducted on multiple problems that are challenging for standard PINN methods and the proposed method is effective in practice.\n\nWeaknesses:\n1. I am concerned about the practical viability of the idea of adaptive sampling. In real-world scenarios how realistic is to expect the PDE solution to be available at arbitrary space-time coordinates on demand? I imagine these are obtained through sensor measurements, which may be too constrained to obtain at arbitrary points or too expensive to obtain.\n2. While the proposed method is based on a population of samples, there are no mutation or crossover (interaction) operators as you would expect in a typical evolutionary algorithm.\n\nOther Comments:\n- Not a weakness per se, but all the references to the appendix in the main paper were missing. This should be an easy fix.",
            "clarity,_quality,_novelty_and_reproducibility": "- The exposition in the paper is very clear. I enjoyed reading the paper.\n- The quality of the paper in terms of ideas, explanations, analysis, experiments and writing are very good.\n- Code is available for the paper. Although I did not test it, the code along with the experimental details in the paper should be sufficient to reproduce the main results of the paper.",
            "summary_of_the_review": "I am positive about the paper, except for the probable impracticality of real-world adoption. The paper is very well written, and the experiments and analysis are thorough. Most importantly, the method seems to be effective across a range of PDEs.\n\nPost Rebuttal Update:\nI read the other reviews and the author's responses. I will maintain the initial rating for the paper. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_3fsB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5285/Reviewer_3fsB"
        ]
    }
]