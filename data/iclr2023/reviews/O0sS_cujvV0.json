[
    {
        "id": "yWUpddtAbW",
        "original": null,
        "number": 1,
        "cdate": 1666385177798,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666385177798,
        "tmdate": 1666385177798,
        "tddate": null,
        "forum": "O0sS_cujvV0",
        "replyto": "O0sS_cujvV0",
        "invitation": "ICLR.cc/2023/Conference/Paper2256/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the generalization problem in adversarial training. Specifically, it presents a minimax lower bound of the generalization gap, proposes Smoothed-SGDMax that achieves the bound. Connection to stochastic weight averaging (SWA) is also presented. ",
            "strength_and_weaknesses": "**Strength**\n\n* Despite robust overfitting has been observed for quite some time and efforts have been spent to understand its root cause, the problem remain mostly open. This paper is a new effort towards solving this important problem, namely, understanding the generalization behaviour of the SGDMax algorithm in adversarial training.\n\n* The paper provides novel perspectives (a lower bound) in characterizing the generalization gap with respect to the optimization gap. The proposed Smoothed-SGD algorithm is intuitively sensible, theoretically justified and empirically validated. \n\n* The theoretical analysis appears solid. \n\n** Weakness **\n\n* Requiring the functions in class ${\\cal H}$ to be convex significantly limits the applicability of the developed results. \n* Comparing with SGDMax, Smoothed-SGDMax does show improved generalization. However even with Smoothed-SGDMax, there still appears a significant gap between training and test robust accuracies (e.g., green and red curves in Figure 1). Such a gap appears much larger than its counter-part in (regular) training.  Then it seems that non-smoothness can not fully explain robust overfitting.   \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is well and clearly written.  The results are also novel and original. \n\nThere may still be some room for improving the presentation and bringing out more insight. For example, how the non-smoothness of the adversarial loss impacts the algorithmic stability of SGDMax is not discussed. As this appears a key motivation justifying the proposal of Smoothed-SGDMax, its deserves some careful discussion in my opinion.\n\n\n\n",
            "summary_of_the_review": "Overall the paper is mostly well written with novel results towards better understanding of an important problem (robust overfitting) in deep learning, although the results are built on strong assumptions, rather distant from practice.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_Kcyd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_Kcyd"
        ]
    },
    {
        "id": "Yxy-A46_Qse",
        "original": null,
        "number": 2,
        "cdate": 1666606999775,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666606999775,
        "tmdate": 1666606999775,
        "tddate": null,
        "forum": "O0sS_cujvV0",
        "replyto": "O0sS_cujvV0",
        "invitation": "ICLR.cc/2023/Conference/Paper2256/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors investigate the generalization error in optimizing the expected adversarial loss. They utilize the generalization-optimization decomposition and techniques from stability analyses to reveal the minimax optimal optimization algorithm for the adversarial loss. For the lower bound, they show that any algorithm with the convergence rate $s(T)$ suffers from the generalization gap at least $s(T)/n$, where n is the sample size. For the upper bound, they develop an optimization algorithm employing the Moreau envelope to smoothen the adversarial loss function so that the SGD is stabilized. They show that it achieves the optimal generalization gap with $s(T)=T$. Also, they analyzed the optimization algorithm with the approximated Moreau envelope, which gives the same optimal rate. The empirical evaluations demonstrate that their algorithm can avoid robust overfitting.\n",
            "strength_and_weaknesses": "Strength:\n- The minimax optimality in the adversarial loss minimization is crucial for understanding adversarial robustness.\n- The inexact version of the proposed algorithm is novel.\nWeakness:\n- The minimax lower bound result has issues in its originality and correctness.\n- The exact version of their algorithm has an originality issue.",
            "clarity,_quality,_novelty_and_reproducibility": "I'll give comments on each topic. \n\n(Minimax lower bound)\nFirst, the statement of Theorem 4.1 looks weird. The authors take maximization over h inner the minimization over the algorithms. It implicitly assumes that the learner does not know the adversarial loss h, which conflicts with the setting in which the learner knows h. In Chen et al.'s analyses, they take the inner maximization over the distribution D,  which is unknown to the learner. Even if the statement is fixed so that the maximization is over D, I cannot find any difference from Chen et al., 2018. It seems that the originality of Theorem 4.1 is significantly low.\n\nSecond, and more importantly, the lower bound in Theorem 4.1 might be incorrect due to the possibly invalid assumption of Eq. 4.1. The results of Xing et al. and Xiao et al. guarantee an adversarial loss for convex and Lipschitz losses is an element of H in Eq. 4.1. It is not proved that there is a set of g such that the induced adversarial losses are equivalent to H in 4.1. We might need to think of a smaller set of losses as the adversarial losses, by which the minimax error might be smaller. Theorem 4.1 may be correct under the assumption of Eq. 4.1, while it might not be the minimax lower bound on the adversarial loss minimization.\n\n(Exact algorithm)\nI cannot find any difference from Lemma 2.5 in the following paper:\n- D. Davis and D. Drusvyatskiy. Proximal methods avoid active strict saddles of weakly convex functions. Foundations of Computational Mathematics, 2022.\nIt is better to clarify the difference between Lemma 5.1 and the result of Davis and Drusvyatskiy. \n\nGiven Lemma 5.1, Theorem 5.1 is just an application of Hardt et al.'s result. I cannot find any novelty in this analysis.\n\n(Inexact algorithm)\nThe inexact version of the algorithm and its analyses may be novel. It is nice that the inexact one achieves the same rate as the exact one.\n\n(Experimental results)\nThe experimental results of Figure 2 adequately demonstrate the benefit of the proposed algorithm. One thing unclear is why the robust training accuracy of AT, whereas the present algorithm achieves high accuracy. Could the authors clarify this point?\n\nI have one thing unclear in Figure 3. What does 10:0 mean? Does it mean no training data?\n\nMinor comments:\n- The authors claim that SGDmax does not achieve the minimax lower bound with the evidence of Theorem 4.2. However, Theorem 4.2 just demonstrates the upper bound, which might have a tightness issue. Fortunately, the original work reveals the matching algorithm-specific lower bound, which is better to support the claim.",
            "summary_of_the_review": "The minimax optimality of the adversarial loss minimization is a well-motivated and interesting direction. However, I found some issues or low originality in most results. Also, while their main idea is to employ the Moreau envelope, it is not original, as Hardt et al. discuss it as a way to control stability. I thus recommend the rejection.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_rzkp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_rzkp"
        ]
    },
    {
        "id": "-ZQZtdKsGx9",
        "original": null,
        "number": 3,
        "cdate": 1666651411541,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651411541,
        "tmdate": 1666651411541,
        "tddate": null,
        "forum": "O0sS_cujvV0",
        "replyto": "O0sS_cujvV0",
        "invitation": "ICLR.cc/2023/Conference/Paper2256/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work studies the effect of using adversarially robust on generalization\nerror.  In particular they show that the generalization error achieved by\nSGDmax contains a constant term that does not tend to 0 as the sample size\nincreases.  They show that they can remove this constant term in the error by\nusing a smooth variant of SGDmax.\n\n",
            "strength_and_weaknesses": "Strengths\n\n1. The paper studies the important and well-motivated problem of adversarial\ntraining and proposes a new method that improves generalization.\n\nWeaknesses\n\n1. The paper is hard to parse and follow and there are numerous typos and\ninconsistencies in the notation.  One of the main results of this work (Theorem\n4.1) seems to be a direct corollary of prior work but still the proof provided\nin Appendix A.1 is hard to follow.\n\n2. I did not find the Smoothed-SGDMax method proposed by the authors\nparticularly novel since approximating non-smooth terms with their\ncorresponding Moreau envelopes is pretty standard.\n\n\nTypos and other Issues\n\nTheorem 4.2 does not show that SGDmax does not achieve the minimax lower bound.\nIt only gives an upper bound for the generalization error of SGD that does\nnot match the lower bound of Theorem 4.1.\n\nPage 2, next to Figure 1. \"By contrast, Our approach\"\n\nPage 3, First paragraph of Related Work. \"This has led to a series of work aimed at training...\"\n\nPage 13, Proof of Theorem 4.1. \"Where $C_4$ is a universal constant\". There is no constant $C_4$ in the expression (A.2).\n\nPage 13, Proof of Lemma 5.1. The sentence in Element 1 of the proof does not parse.\n\nPage 13, \"Then, take the derivative of $M(u)$ with respect to $u$, we have\"\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly not well-written.  I recommend that the authors carefully\nproof-read the manuscript and fix the various typos and issues in notation.",
            "summary_of_the_review": "Overall, I found the paper not well-written and I believe that it would benefit\na lot by careful proofreading. I do not think that in its current state this\nwork is ready for publication.   Perhaps after a revision, the contributions of\nthis would also become clearer.  Given the fact that the paper is not\nwell-written and the contributions do not seem very exciting, I am currently\ninclined towards rejection but I am willing to reconsider if the authors and/or\nother reviewers can prove otherwise.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_9aTN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_9aTN"
        ]
    },
    {
        "id": "e0PFhuRjf_N",
        "original": null,
        "number": 4,
        "cdate": 1666697905412,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697905412,
        "tmdate": 1666698449933,
        "tddate": null,
        "forum": "O0sS_cujvV0",
        "replyto": "O0sS_cujvV0",
        "invitation": "ICLR.cc/2023/Conference/Paper2256/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studied the generalization performance of adversarial training from the stability perspective. They first derived the minimax lower bound of generalization gap for convex Lipschitz functions, which identifies the gap compared to existing generalization results of SGDmax; then authors proposed Smoothed-SGDmax which shares the same convergence guarantee while achieves the aforementioned (vanishing) minimax lower bound, i.e., fix the gap.",
            "strength_and_weaknesses": "Strength:\n1. The paper is well-written and the flow is clear\n2. The proposed algorithm successfully overcomes the nonvanishing generalization errors in existing SGDmax results, while still share the same convergence guarantee\n\nWeakness:\n1. The tools in algorithm building are not that novel.\n2. The problem setting is the convex regime, which is a bit restricted (to be a bit picky)",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paper is well-written and easy to follow. The results concern both lower and upper bounds, which reveals both novelty and significance.",
            "summary_of_the_review": "Generally I don't have immediate questions to ask.\n\nSome typos:\n1. Theorem 4.2, $\\alpha_t$ and $\\alpha$, do you suggest that you are always using constant stepsize $\\alpha_t\\equiv\\alpha$?",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_xxrH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2256/Reviewer_xxrH"
        ]
    }
]