[
    {
        "id": "iPjBqvqWObw",
        "original": null,
        "number": 1,
        "cdate": 1666403919521,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666403919521,
        "tmdate": 1666404163362,
        "tddate": null,
        "forum": "9JjGZsDvHb",
        "replyto": "9JjGZsDvHb",
        "invitation": "ICLR.cc/2023/Conference/Paper29/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a new benchmark and transformer model for retrosynthesis prediction. The model particularly makes use of the context of the retrosynthesis routes and is hence rather different from existing ones. It does so by using a memory module and an extension of transformer, using matrices in place of the values (i.e., the value matrix is a tensor here).\n",
            "strength_and_weaknesses": "(+) It is true that existing route data is lacking, so the initiative to propose new data is good. Similarly the idea of including context information makes totally sense to me.\n\n(+) The results look promising.\n\n(-) From an ML perspective, the paper/model contains few novelty. \n \n(-) The paper proposes a new dataset as benchmark and one of the main contributions, but it does neither give much detail about the data nor does it provide a detailed comparison to existing works, apart from two sentences. There are recent datasets and benchmarks, e.g. [1], which should be mentioned and compared to. The related work section does not even contain a paragraph about datasets.\n\n[1] Samuel Genheden and Esben Bjerrum, PaRoutes: towards a framework for benchmarking retrosynthesis route predictions, https://pubs.rsc.org/en/content/articlehtml/2022/dd/d2dd00015f\n\n(-) The evaluation is lacking in that the comparison is with single-step models only. If additional (context) information is included, it is likely that the results will be better. It is interesting to see the magnitude of the improvement, however, to learn about the practical effectiveness I think other experiments are needed. Single-step models are usually applied within a planning algorithm. Since the authors focus on the routes, instead of single steps, I would suggest to evaluate the model also in a more realistic setting. For example, it would be interesting to see how close the proposed model (i.e., simple chaining of the transformer predictions) gets to Retro* with the MLP as single-step model, or how it performs when replacing the MLP by the transformer.\n\n================================================================================\n\nMinor Comments\n\n- sounds wrong to me:\n\"For two trees ..., we think these are different trees.\" \n\"Moreover, what needs to be declared is that molecule synthesis...\"\n- There are some typos in Algorithm 1\n- Why do G2Gs and Graphretro perform that bad?\n- What does this mean?: \n\"2) the dataset is based on reaction route instead of reaction tree.\"\n\"Note that in this paper, the default order of the reaction route is the retrosynthesis order.\"\n- The case study in the evaluation, to me it is unclear what it shows specifically, apart from the fact that the proposed model improves upon transformer.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. I think in terms of quality and novelty it is lacking (see details above). Code is not provided, yet the model description is clear and straightforward and one could reimplement it.",
            "summary_of_the_review": "The paper proposes a new benchmark and model for retrosynthesis prediction, yet it's missing an evaluation which would justify those. \nAltogether, I do not think that the paper can be accepted at the current stage and that it would need quite some revision.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper29/Reviewer_tdV3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper29/Reviewer_tdV3"
        ]
    },
    {
        "id": "0SZY5OA9wTK",
        "original": null,
        "number": 3,
        "cdate": 1666609923832,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666609923832,
        "tmdate": 1666609923832,
        "tddate": null,
        "forum": "9JjGZsDvHb",
        "replyto": "9JjGZsDvHb",
        "invitation": "ICLR.cc/2023/Conference/Paper29/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is concerned about retrosynthetic planning, where the task is, given a target molecule, to find a reaction tree to synthesize the target molecule from a set of starting compounds. The proposed method called Metro is based on single-step retrosynthesis transformer, but is equipped with a memory module so that it can make use of the retrosynthetic route as context information for the purpose of predicting the reactants. Another contribution is yet another preprocessing of the USPTO dataset, resulting in a new benchmark. The resultant dataset consists of reaction trees extracted from the dataset, and its test dataset is much larger than that in previous benchmark tasks.\n\nThe authors conducted empirical studies using the proposed benchmark. In terms of top-$k$ accuracy scores, the proposed method achieves more than 10 points improvements over the transformer model (= Metro - memory module). The authors also confirm that the accuracy degrades as the depth of the reaction tree increases.",
            "strength_and_weaknesses": "## Strength\n- The experimental results indicate that the proposed method achieves better accuracy scores than baseline methods, including a transformer-based method. The result suggests that the proposed memory module contributes to the performance improvement, validating their approach.\n- The authors propose a novel benchmark task considering the limitations of the existing one. In addition, since the details are well described in the paper, it will be not difficult to reproduce the task.\n\n## Weakness\n- __Why context information:__ Although the authors discuss why the context information helps in Section 5.3, I am not very convinced of it. The authors claim that the context information can prune the reaction search space, but as far as I understand, many of the existing methods utilize search algorithms for pruning. In fact, all of the methods compared in the experiments use the same DFS algorithm, which is not very fair for the existing methods.\n- __Baseline methods do not cover the existing methods introduced in the introduction:__ Since many of the existing methods combine ML and planning algorithms, it is necessary to compare the proposed method with other methods utilizing a wide variety of search algorithms.\n- __Presentation needs improvement:__ I had a bit difficulty in understanding the proposed algorithm, because the paper does not provide the whole algorithm (Algorithm 1 was helpful to understand it). In particular, although Figure 2 provides the overview of the proposed method, at first, it is difficult to understand why it has three inputs, A, B, and D. I would appreciate it if the authors could provide the whole algorithm first, and dive into the details after that. Similarly, although the authors pointed out three limitations in the third paragraph of the introduction, they came out suddenly, and I was not very motivated from them.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nAs elaborated in the weakness section, there is a room for improvement in terms of clarity.\n\n## Quality\nAs elaborated in the weakness section, the use of context information is not well motivated to me. At least, it is necessary to compare Metro with existing methods using a variety of search algorithms.\n\n## Novelty\nAs far as I am aware of, the preprocessing of the USPTO dataset is novel and therefore the proposed setting is novel.\n\n## Reproducibility\nAlthough the hyperparameters are provided in the appendix, the overall learning algorithm is not explicitly described, and it is difficult to identify the exact algorithm. I would suggest the authors to explicitly describe the learning algorithm and/or release the source code to further improve the reproducibility.",
            "summary_of_the_review": "I am not positive about accepting this paper, mainly because I am still not motivated to utilize context information. I understand that while it can bias the retrosynthetic process and can prune the search space, its advantage over the existing methods has not been clarified because of the selection of baseline methods. If there is any misunderstanding, I would appreciate it if the authors could point them out.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper29/Reviewer_f3iV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper29/Reviewer_f3iV"
        ]
    },
    {
        "id": "yFK9nBlIFW",
        "original": null,
        "number": 4,
        "cdate": 1666610991946,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610991946,
        "tmdate": 1666610991946,
        "tddate": null,
        "forum": "9JjGZsDvHb",
        "replyto": "9JjGZsDvHb",
        "invitation": "ICLR.cc/2023/Conference/Paper29/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a transformer with memory of reaction-trees for a new multi-step-retrosynthesis benchmark.",
            "strength_and_weaknesses": "## Strengths:\n - Propose a new Benchmark for Multi-Step-Retrosynthesis\n - Propose Metro: Memory-Enhanced Transformer for RetrOsynthetic planning by extending Transformer with an additional memory module\n    - reaction route as context information\n    - can control the synthesis path\n\n## Weaknesses:\n - Missing Important Related Work: \n   - Section for Memory Enhanced Architectures, completely missing [1]\n   - Missing Template-Based Methods in Related Works section [2] [3]\n - More clarification on why extracted Reaction-Trees are seen as optimal\n - No code for reproducibility is provided\n - Architecture needs further explanations, e.g. Decoder, Tokenizer, \"Concatenated Embedding\" + residual connection, ...\n - The proposed dataset is a subset of USPTO-Full, please provide a comparison e.g. a scatter plot, of performance differences between e.g. USPTO-Full results and the results obtained on your benchmark set\n\n## Minor Comments\n - Was SMILES augmentation [4] performed or any other type of augmentation?\n - 5.1.1 paragraph about SMILES representation 2 might fit more in the subsequent paragraph 5.1.2, but is nothing inherent about the architecture\n - Please provide variance for point estimate in Table 1 as well as the significance\n - Is any standardization performed on molecules?\n - Please further describe the meaning behind A B C D E F in Figure 2\n - Appendix B.2.: Also describe the hyperparameter search space, as well as how they were obtained\n - Further discussion on why extracted Reaction-Trees are seen as optimal/better; e.g. there might exist faster/more optimal reaction routes\n\n### References\n - [1] Ramsauer, H., Sch\u00e4fl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., ... & Hochreiter, S. (2020). Hopfield networks is all you need. \n - [2] Chen, S., & Jung, Y. (2021). Deep retrosynthetic reaction prediction using local reactivity and global attention. JACS Au, 1(10), 1612-1620.\n - [3] Seidl, P., Renz, P., Dyubankova, N., Neves, P., Verhoeven, J., Wegner, J. K., ... & Klambauer, G. (2021). Modern Hopfield Networks for Few-and Zero-Shot Reaction Prediction.\n - [4] Tetko, I. V., Karpov, P., Van Deursen, R., & Godin, G. (2020). State-of-the-art augmented NLP transformer models for direct and single-step retrosynthesis. Nature communications, 11(1), 1-11.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nThe paper is written quite well, but needs further details in aforementioned topices\n\n## Quality\nOK\n\n## Novelty\nThe dataset is novel, as well as the application of a Memory Module of reaction-trees\n\n## Reproducibility\nNo code provided",
            "summary_of_the_review": "The paper introduces a new interesting benchmark for multi-step retrosynthesis that might be influential in the community of retrosynthesis, however no code or dataset is provided.\nThe architecture seems interesting, but lacks connection to related work, as well as further clarifications.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper29/Reviewer_1qQ1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper29/Reviewer_1qQ1"
        ]
    },
    {
        "id": "VjV3i-Hfz3",
        "original": null,
        "number": 5,
        "cdate": 1667685623703,
        "mdate": 1667685623703,
        "ddate": null,
        "tcdate": 1667685623703,
        "tmdate": 1667685623703,
        "tddate": null,
        "forum": "9JjGZsDvHb",
        "replyto": "9JjGZsDvHb",
        "invitation": "ICLR.cc/2023/Conference/Paper29/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "- a benchmark for retrosynthesis is proposed\n- a model for retrosynthesis is presented\n- the authors claim state of the art\n\nthere are only limited novel contributions in this paper",
            "strength_and_weaknesses": "### strengths\n- clear description\n- interesting memory model\n\n### weaknesses:\n- the paper has several incorrect definitions\n- the paper yet proposes another benchmark for retrosynthesis even though there are already several existing ones\n- the presented model is not properly compared\n- the baselines in the paper are inconsistent with previous work\n- somewhat limited ML model novelty\n- some proposed reactions in the case study are chemically incorrect",
            "clarity,_quality,_novelty_and_reproducibility": "### quality\n- the paper has several incorrect definitions. \n  - in chemistry, a synthetic route and synthetic tree are the same \n  - the depth of a tree is not particularly important, what is more important is the total number of steps in the tree. with this definition, the authors are solving a different task previous work, and comparison to previous work is therefore not very meaningful, as a different metric was used\n  - it is unclear why a transformer model is needed. RETROGRAPH https://arxiv.org/abs/2206.11477 shows a transformer is not needed for adding in contextual information in retrosynthesis search\n- the molecular case study contains incorrect reactions, which casts doubt on the usefulness of the method in practice\n- the results in table 1 are inconsistent with previous works (e.g. GLN should be stronger than neuralsym, single step transformer stronger than neuralsym and GLN). it is unclear whether the baselines have been tuned properly.\n### clarity\ngood\n\n### originality\n1) The benchmark proposed in this paper is very close to the PAroutes  benchmark, which was already published in Feb 2022 https://chemrxiv.org/engage/chemrxiv/article-details/621c86f3c3e9da4f737b0047 - why do we need yet another benchmark?\n2) The use of graph and contextual information has already been proposed in RETROGRAPH https://arxiv.org/abs/2206.11477 earlier in 2022 ",
            "summary_of_the_review": "The proposed benchmark and approach are a small variation of previously existing work. Therefore this reviewer cannot justify to recommend  this work for publication in a top ML conference.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper29/Reviewer_r9kB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper29/Reviewer_r9kB"
        ]
    }
]