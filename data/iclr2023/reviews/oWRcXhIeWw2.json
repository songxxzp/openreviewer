[
    {
        "id": "2V09nfRgSfy",
        "original": null,
        "number": 1,
        "cdate": 1666665604070,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665604070,
        "tmdate": 1666665604070,
        "tddate": null,
        "forum": "oWRcXhIeWw2",
        "replyto": "oWRcXhIeWw2",
        "invitation": "ICLR.cc/2023/Conference/Paper1072/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work focuses on multivariate time series forecasting problems. To capture the  ever-changing correlations over time series data, this work defines a Fourier graph shift operator and constructs the efficient edge-varying Fourier graph networks to formulate spatial temporal dependencies for the varying data. Extensive experimental results demonstrate the effectiveness of the proposed method. \n\n",
            "strength_and_weaknesses": "Strengthes:\n1. This paper addresses the ever-changing correlations over time-series data, which is practical and complement previous works.\n2. This paper presents extensive and strong baselines in time series forecasting scenarios. Experimental results demonstrate the effectiveness of the proposed method. \n\n\nWeaknesses:\n1. The author claims this is the first work that designs a complex-valued feed-forward network in the Fourier space for efficiently computing multi-layer graph convolutions. Actually, there are some pioneer works that discuss the relation of spectral space and GNN [1,2], e.g., I wonder if the author only applies their conclusion to the multivariate time series forecasting scenarios or represents more analysis?\n2. This paper is  not easy to understand. In section 3.2, the author introduces the notation of the graph shift operator. 1) Generally, there are three types of graph shift, graph size, node feature and graph structure.  This work considers the whole three graph shift of some of it? 2) How does edge-varying connect to multivariate time series forecasting problems?   3) How does the spectral GCN address the corresponding shifted problem? Are there some motivational examples or intuitions here?\n\n\n[1] Zhu, H. and Koniusz, P., 2020, September. Simple spectral graph convolution. In the International Conference on Learning Representations.\n[2] Zhang, S., Tong, H., Xu, J. and Maciejewski, R., 2019. Graph convolutional networks: a comprehensive review. Computational Social Networks, 6(1), pp.1-23.",
            "clarity,_quality,_novelty_and_reproducibility": "\nI have provided detailed comments related to clarity, quality, novelty, and reproducibility in the weaknesses section.\n",
            "summary_of_the_review": "This paper studies an interesting research topic and connects multivariate time series forecasting with spectral GCN.. But it has the following limitations: \n1. The presentation of this paper is not clear. It is not easy to extract the main idea and intuition.  \n2.  The contribution of this paper is not clear. It is hard to tell if the author only borrows some existing conclusion in spectral GCN to time series forecasting problems or present some new finding.  \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_cY1E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_cY1E"
        ]
    },
    {
        "id": "ohDrXGH1Z2",
        "original": null,
        "number": 2,
        "cdate": 1667164642919,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667164642919,
        "tmdate": 1669922431507,
        "tddate": null,
        "forum": "oWRcXhIeWw2",
        "replyto": "oWRcXhIeWw2",
        "invitation": "ICLR.cc/2023/Conference/Paper1072/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes using Fourier Neural Network (FNO) to combine Graph Shift Operator (GSO), to enable multivariate forecasting.\nThe architecture first obtains a Fourier transform of embedding of input and then applies it to the proposed operator FGSO, which mainly is consisted of FNO. The authors compare the proposed approach with other Graph based and transformer based forecasting approaches (including ablated versions of the proposed approach) on 7 datasets. They demonstrate competitive performance of the proposed approach. ",
            "strength_and_weaknesses": "## Strength\n\n1. The paper is well-written. I liked how the authors posed the idea of FNO as a simple add-on of GSO to MTS. \n2. A decent collection of datasets and experiments were performed, and an extensive set of graph neural net based and transformer based forecasting methods were compared.\n3. Additional useful ablation study, hyperparameter sensitivity study, and visualization result analyses were also provided. This provides more interesting information and an understanding of the proposed approaches.\n\n## Weakness:\n\n1. Novelty is somewhat limited. As pointed out there are several works learning graph structure as part of forecasting, this work is a straightforward extension of the original GSO by replacing the original operations with FNO. From the novelty point of view, FNO is a recently proposed method for solving PDEs, and Fedformer (ICML 2022, authors already cited and compared) extends FNO to long-term forecasting. I do not recall any work that combines FNO and graph structure to perform multivariate time series forecasting, but the combination of GSO and FNO in this work is simple. \n\n2. Overall, I found the article tricky to follow. I don\u2019t find the plots in Figure 1 very insightful and it is quite hard to see any informative insights regarding EV-FGN in my opinion. The caption is just \"The network architecture of our proposed model\". The detailed FGSO is missing in Figure 1, which makes the reader confused about how FNO is integrated with GSO. Based on the codes provided by the authors, I don't see any difference between FGSO and FNO except for the real and imaginary concatenation parts. It seems to me the concatenation operation is different from the proposed EV-FGN layer in equation 12. Please clarify this point. I feel that more need to be said about architecture and how it numerically affects the type of relations that it is capable of representing, i.e., GSO with and without FNO. Also, \n\n3. The high efficiency of FGSO is not obvious. First, I agree the space-invariant property of FGSO, but the claim of scale-free parameters in the Sec 3 remark is unfair. The complexity of FNO is largely determined by the grid size because it is originally proposed to solve PDEs. Instead, the graph size of MTS considered in this paper is fixed. Directly comparing a method solving PDEs and another solving MTS is unfair. Also, it seems to me the complexity of FNO is not $nd^2$. Numerically, based on table 3, GraphWaveNet trained on traffic dataset has a parameter size of 280860 and takes 105.38 seconds per epoch. On the other hand, EV-FGN has a much smaller parameter size but takes a relatively similar amount of time per epoch (99.25 sec). Could you explain why this happen\uff1f I believe the main computation overhead comes from the Fourier transform and its inverse. \n\n## Questions\n1. Please use notation consistently throughout the paper. For example, in Sec 3.1, it says 'Given input data $X \\in R^{N \\times T}$', '2D discrete Fourier transform (DFT) is applied on the embedding of $X \\in R^{N \\times T \\times d}$', but in definition 2, the input size of  $X$ becomes to ${n \\times d}$. Why is lowercase $n$ in definition 2 and why is not  ${n \\times t \\times d}$? \n2.  The claim that  Fourier Graph Shift Operator captures high-resolution spatial-temporal dependencies is inaccurate or unclear. The Fourier layer in the Fourier Neural operator on its own only uses low-frequency representations, and thus loses higher-frequency modes. The biased term $W$ might help to recover the higher Fourier modes to some extent, but it can not capture high freq features. This is saying adopting FNO is not to capture high-resolution features. If authors regard 'any two variables at any two timestamps' as high-resolution, I would suggest clarifying high-res in the introduction. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The details of the proposed FGSOs need more description. The originality of the work is novel, although limited. ",
            "summary_of_the_review": "Overall I think the idea is interesting and in particular, the direction of making multivariate forecasting using FNO is interesting even if it's a simple extension. However, it could be useful to point out why FNO is useful and compatible with GSO and contrast it to related alternate approaches for multivariate forecasting, such as Fedformer. There are several concerns about the method and questions that I feel need to be addressed, i.e., specifics of the method so it could be understood by the readers. Without additional clarifications, I am leaning on the side of rejection. I will wait for the author to clarify before making my final decision.\n\n\n===============================\n\nAfter rebuttal:\nThe authors made additional clarifications and addressed some concerns. I raised my score from 5 to 6",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_zvHq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_zvHq"
        ]
    },
    {
        "id": "1aWO9_qvOBJ",
        "original": null,
        "number": 3,
        "cdate": 1667265872227,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667265872227,
        "tmdate": 1667281907166,
        "tddate": null,
        "forum": "oWRcXhIeWw2",
        "replyto": "oWRcXhIeWw2",
        "invitation": "ICLR.cc/2023/Conference/Paper1072/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is about the combination of relations of the variables in multivariate time series (MTS) and graph neural networks for the analysis and prediction of MTS. The proposed method is to build a fully-connected supra-graph that connects variable at any two timestamps to learn high-resolution variable dependencies in an efficient way using graph neural networks. One of the contributions is the shift operator that is being proposed to reduce the computation complexity that is introduced by the supra-graph. Specifically, the authors propose to construct the Edge-Varying Fourier Graph Networks (EV-FGN) with Fourier Graph Shift Operator (FGSO) to perform graph convolutions in the frequency domain on a lower-complexity. The experimental setup includes seven datasets from different application scenarios and thirteen comparison models. The overall evaluation shows that in most cases the proposed model EV-FGN outperforms the other state of the art models. The authors include an analysis on the number of parameters and the training time, to show how the FGSO achieves an improvement in the complexity of the model. The authors also include a visualization analysis to show the patio-temporal representation that is learnt by the EV-FGN.",
            "strength_and_weaknesses": "Strengths:\n- The paper is about an interesting topic and the authors do a good job to describe the problem and their methodology, as well as their contributions.\n- There is novelty in this work. The authors build the proposed model in existing concepts, however this is the first attempt to design a complex-valued feed-forward network in the Fourier space with a focus on reducing the complexity that the use of a supra-graph is introducing.\n- The structure of the paper is well-defined. The paper has a nice flow. The appendix also has interesting information and more details, that are useful when reading the paper.\n- The authors have done an extended evaluation of the proposed model and 13 comparison state of the art models in 7 datasets from different applications.\n- The analysis in 4.3 is nicely done and highlights the improvements and the need of the FGSO to reduce the complexity and the runtime of the proposed methodology.\n\nWeaknesses:\n- This work might have a limited interest to researchers of ICLR as the main focus is to efficiently calculate graph operations in the Fourier space.\n- The paper can be difficult to follow. The concepts presented in this work are hard to understand, especially if the reader does not have previous familiarity with them. The authors can do a better job in introducing these concepts with a few examples of how they are used in the literature. Specifically, more motivation in the introduction section is needed and specific examples of the challenges that the papers/methods that are cited in the related work section face, and how the proposed methodology will avoid such challenges. Also, a few examples in the introduction of each concept in the methodology section will help the reader understand and remember the notation and the need of each part/concept.\n- It would be interesting to see an evaluation for the multivariate time series forecasting using state of the art methods in time series representation learning as well.\n- It would also be interesting to compare the proposed methodology when not using the FGSO, how does the performance change and how does the complexity/runtime/number of parameters change?\n\n- Minor typos:\n\u2014 The word weight when used as a verb is noted as \u201cweigh\u201d at least two times.\n\u2014 The dataset METR-LA is noted as META-LA in Table 1. ",
            "clarity,_quality,_novelty_and_reproducibility": "As described above, the proposed method has novelty, however the presentation, the motivation and the clarity in some concepts can be improved. The paper and the appendix of the paper have a lot of extra results and analyses, as well as, implementation details and links to the publicly available code repositories of the comparison models and the datasets, that will help with the reproducibility. They have also submitted their code in the supplementary material.",
            "summary_of_the_review": "Overall, this paper introduces a methodology that for the multivariate timeseries analysis and forecasting, using the supra graph and Fourier Graph Shift Operator to reduce the complexity of such a graph. The proposed method outperforms 13 other state of the art models when comparing to 7 datasets of various domains. The introduced methodology and concepts are hard to follow, but the authors try to introduce them, describe them and justify their decisions in a satisfactory way. However, improvements can be made to help the readers that are not familiar with these concepts (see the weaknesses section above for suggestions.).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_iyiB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_iyiB"
        ]
    },
    {
        "id": "CpJ-DbGmVO",
        "original": null,
        "number": 4,
        "cdate": 1667346156971,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667346156971,
        "tmdate": 1667361860135,
        "tddate": null,
        "forum": "oWRcXhIeWw2",
        "replyto": "oWRcXhIeWw2",
        "invitation": "ICLR.cc/2023/Conference/Paper1072/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method for discovering the underlying correlations between variables in a temporal system which drive its evolution. Recent works have applied GNNs to model these relationships, but several of these approaches have employed a static graph over time failing to capture the potential evolution of this dependency structure. To address this, the proposed approach utilizes an all encompassing supra-graph that jointly represents relationships between all variables at all timesteps. Towards this, the notion of Fourier Graph Shift Operator is introduced which performs graph convolution in the frequency domain. This representation is exploited in devising a frequency-invariant convolution operation that can avoid the $n^2$ node complexity associated with a dense graph and effectively reduces\n it to $n \\cdot \\log n$. Edge-varying diffusion networks are introduced for modelling higher-order diffusion over multiple neighbourhood sizes and a corresponding Fourier representation is introduced. ",
            "strength_and_weaknesses": "### The paper has several strengths:\n- Efficient GNN parametrization in the Fourier domain resulting in reduced computational complexity compared to naive graph-based approaches for MTS modelling.\n- Consequently, the proposed algorithm allows for joint modelling of spatial and temporal variables, that would be prohibitive otherwise due to computational restrictions.\n- Experiments show SOTA performance on a variety of datasets with better computation time and reduced parameter count.\n- Ablation studies demonstrate the effectiveness of each proposed model component.\n\n### It also has some weaknesses in my opinion:\n- The clarity of the formulation is often obfuscated by confusing terminology.\n\nFor example, at the end of page 4: \"Accordingly, we can parametrize FGSO with a complex-valued matrix which is space-invariant...\"\nThis sentence seems misleading. The same term is used previously to refer to a regular GSO, in which case it meant that the kernel function $\\kappa$ is shared across nodes $[n]$. However, the invariance in this case is with respect to the frequency input in the Fourier domain. Therefore, it is not space but frequency-invariant. It seems to me that this is actually the point that allows the convolution operator to be non-static in time since frequency-invariance in the Fourier domain still allows the convolution to be temporally varying in the input domain. This point could be emphasized more.\n\nSimilarly, I was confused by the extension of the argument by considering a 2D domain (i.e. from $[n]$ to $[N] \\times [T]$). The authors say that \"we can extend Definition 2 to a 2D discrete space\". How would that look like? In that case, would the proposed parametrization invariant be invariant to both frequency components?\n\nIn Proposition 1, the dimensions associated with the $S_k$ and $\\mathcal{S}_k$ operators seem to be confusing. $S_k$ is defined to be $n \\times n$, while $\\mathcal{S}_k$ is defined as $n \\times d \\times d$. What is the relation between the two? \n\nOn a related note, the left-hand side of equation (9) should probably read as $H_{EV} X W$ since (I assume) that it is the edge-varying counter part of equation (7).\n\n\n- No interpretation is provided for the frequency-invariant parametrization\n\n Related, I was somehow lacking an interpretation of what this shared parametrization across frequencies means with respect to the convolution operation in the input domain. Although it allows for a non-static temporal representation, it clearly places a big restriction on the possible spatio-temporal interactions that it can represent. I guess my worry is that it might reduce to something straightforward in the input domain, which is only obfuscated by the dual formalism. What do we get when we invert this? What's the range of operations that it can represent? These are questions not at all addressed at the moment.\n\n- Experimental improvements are often marginal\n\nIn the experiments, the improvement is often marginal over the baselines. Further, in Appendix E.4 the authors report that they carefully fine-tune the hyperparameters of their own model. However, for the baselines in Appendix E.2, they report the use recommended default settings only. Hence, significantly more effort is spent on tuning their model compared to zero tuning on the baselines, which makes the experimental results inconclusive. I would be more convinced if rather than using default settings, they also fine-tuned the baseline settings at least with respect to the hyperparameters deemed significant by the respective authors of these baselines.",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed idea is clearly novel and well-motivated. The writing is mostly clear, however, there are still some questions regarding the clarity (and non-triviality) of the proposed formalism - see above. I have not tried running the experiments, however, out of the reported 6 datasets, dataloaders for only 3 of them are provided in the supplementary material. This excludes complete reproducibility of the results.",
            "summary_of_the_review": "The paper proposes a novel approach for performing graph convolution in the Fourier space at a reduced computational cost. This speed-up allows for joint modelling of spatio-temporal interactions. The flexibility of the introduced parametrization, however, is not investigated, and consequently there is a lack of theoretical understanding of what the approach can actually learn. Experiments show minor improvements over the considered baselines, but I think overall these are not conclusive under the given experimental setting. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_jKjm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_jKjm"
        ]
    },
    {
        "id": "FRIcYOKi2W",
        "original": null,
        "number": 5,
        "cdate": 1667470801321,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667470801321,
        "tmdate": 1667470801321,
        "tddate": null,
        "forum": "oWRcXhIeWw2",
        "replyto": "oWRcXhIeWw2",
        "invitation": "ICLR.cc/2023/Conference/Paper1072/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper adaptively learns a supra-graph, representing non-static correlations between any two variables at any two timestamps, to capture high-resolution spatial-temporal dependencies, and define FGSO that has the capacity of scale-free learning parameters in the Fourier space. Accordingly, authors construct a complex-valued feed forward network, dubbed as Edge-Varying Fourier Graph Networks (EV-FGN), stacked with multiple FGSOs to perform high-efficiency multi-layer graph convolutions in the Fourier space. ",
            "strength_and_weaknesses": "The results are adequate in various datasets and look great. The training details are comprehensive. The equations are proved clearly in the paper.\n\nBut The idea seems limited, GSO and MTS with Fourier transform existed before, the paper just extended to other latent space such as Fourier space. The motivation of this is not convincing enough.\n\nQuestions\n1.\tWhy the results on MAPE are higher than other baselines on several datasets?\n2.\tIn Table 3, the authors compare parameter efficiency with old baselines, why not compare with recent baselines from 2021 such as FEDformer?\n3.\tFigure 1 can not visualize the proposed method clearly.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\nQuality: Fair\nNovelty: Limited\nReproducibility: Good\n",
            "summary_of_the_review": "The empirical results are good, while the analytical results are limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_VMXz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1072/Reviewer_VMXz"
        ]
    }
]