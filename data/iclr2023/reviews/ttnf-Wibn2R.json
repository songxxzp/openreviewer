[
    {
        "id": "Ec8yeGvMtn",
        "original": null,
        "number": 1,
        "cdate": 1666432981483,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666432981483,
        "tmdate": 1666432981483,
        "tddate": null,
        "forum": "ttnf-Wibn2R",
        "replyto": "ttnf-Wibn2R",
        "invitation": "ICLR.cc/2023/Conference/Paper5647/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work provides a formal definition for robustness based on learning theoretical terms. Specifically, holomorphicity enables complexity analysis tool to investigate the phenomenon of adversarial examples. In addition, the analysis provides a geometrical interpretation for these phenomena.",
            "strength_and_weaknesses": "Strength:\n\nIt is novel to study the phenomenon of adversarial examples from the aspect of differentiable hypothesis, a new aspect as far as what I know.\n\nWeakness and Questions:\n\n1. The settings are a bit restricted: all theorems are based on binary classification. In addition, many theorems are based on support vector classifier (SVC), which is a linear model and much simpler from the ones used in practice.\n\n2. Numerical results are not very strong: a simple MLP model on a single and simple dataset. The attack to evaluate the adversarial accuracy should be stronger than one-step black-box attack (Figure 3). Probably, more experiments are needed.\n\n3. Presentation needs improvement (See the next section)",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty: As far as what I know, it looks a good perspective to study adversarial examples.\n\nReproducibility: This work does not have too many experiments, the code is provided.\n\nClarify and Quality: I think the presentation of this work needs improvement.\n  * There are some latex compilation errors such as \"Section ??\" in the manuscript.\n  * It is better to provide the pseudo-code of the framework in the beginning of Section 5. This will make the readers better aware of the algorithms proposed.\n  * Some necessary contexts are needed for some theorems. For example, in Theorem 4.1, the authors should clearly state how $f$ is obtained.\n  * Notation is a bit complicated and hard to follow. For example, it is difficult to figure out what is \"L with stroke\" in Theorem 2.5. What do calligraphic letters $\\mathcal{S}$ and $\\mathcal{C}$ represent after definition 3.1. Probably, a notation table is necessary in the appendix.\n",
            "summary_of_the_review": "In general, I think this paper is not ready for publication because of the concerns above.\n\nAs I am not familiar with differentiable hypothesis, I welcome the authors clear my concerns and make me better understand the technical contribution of this paper during the discussion.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_eViJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_eViJ"
        ]
    },
    {
        "id": "DIXEKDSGWgo",
        "original": null,
        "number": 2,
        "cdate": 1666617431899,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666617431899,
        "tmdate": 1669477156049,
        "tddate": null,
        "forum": "ttnf-Wibn2R",
        "replyto": "ttnf-Wibn2R",
        "invitation": "ICLR.cc/2023/Conference/Paper5647/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides an analytical framework to understand adversarial example problems in a more formal way. Several hypothesis classes are discussed, especially $L^2$ (square-integrable functions) and $A^2$ (Bergman space, a subspace of holomorphic square-integrable functions). For their framework, the authors extended the space of classifiers so that it contains complex-valued functions as classifiers. Their main statement (Theorem 4.2) states that a learning rule minimizing Dirichlet energy would induce a robust classifier. A practical discussion on how to implement the main idea and an experimental exploration are provided.\n",
            "strength_and_weaknesses": "[[Strengths]]\n1. The paper provides precious theoretical insights into robust classification.\n2. About implementing the authors\u2019 learning rule (Theorem 4.2), the paper proposes a practical method based on a well-understood PDE problem. This reduction to the PDE problem would open up a new research direction.\n\n[[Weaknesses]]\n1. The paper has a few LaTeX issues. First, there are some missing references, e.g., \u2018section ??\u2019 in Section 5, \u2018lemma ??\u2019 in Appendix C.4, and \u2018definition ??\u2019 in Appendix C.8. Since those missing references appear in the main body (or even in the proof), the authors should fix these missing references. Also, please fix the Appendix sectioning so that the material starts from Appendix A. (Currently, Appendix A is just an empty section with the title \u2018Appendix\u2019)\n2. About the experimental details, the authors mentioned that \u201cThe interested reader can find the details of the experiment in the supplementary materials.\u201d, but the supplementary materials only contain iPython notebooks that the reader should run. This is submitted as an academic paper, and general readers (even those who are interested in experimental details) only read the written materials. Therefore, this raises a reproducibility issue. (the descriptions in the paper are not enough to reproduce the result.) I suggest the authors 1. write an additional section (in the Appendix) about experimental details (e.g., network structure, hyperparameters, etc.) and 2. put your code on a code repository and add the link to the repository in the camera-ready version. (Because this is a blind review, you should not add the repository link during the review process.)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The authors\u2019 contributions look novel, and the writing is straightforward and understandable. There might be a few reproducibility issues.\n",
            "summary_of_the_review": "I consider the paper novel and valuable work. This paper contains novel insights into training robust classifiers. Especially the concept of complex-valued function as a classifier can provide further insights as it simultaneously encodes two geometric objects (the data manifold and the decision boundary). Though I could not check the whole proof, the suggested learning rule looks novel and interesting. The author also demonstrated that the proposed idea is also implementable and can be reduced to solving a PDE problem.\nRegarding some negative factors, the paper contains some LaTeX problems, including missing references, and lacks details about the experimental setup, raising a reproducibility issue. However, I believe these are amendable issues, and I\u2019m willing to raise the score after they are fixed.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_2yAx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_2yAx"
        ]
    },
    {
        "id": "ANRXx69-hg",
        "original": null,
        "number": 3,
        "cdate": 1666636806480,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636806480,
        "tmdate": 1666637698377,
        "tddate": null,
        "forum": "ttnf-Wibn2R",
        "replyto": "ttnf-Wibn2R",
        "invitation": "ICLR.cc/2023/Conference/Paper5647/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors introduced a general framework for training robust models. The idea of using calculus of variations and differential equations to tackle the robust training of neural network models is novel and interesting. Some theoretical analysis is given.",
            "strength_and_weaknesses": "Strength: The idea of using calculus of variations and differential equations to tackle the robust training of neural network models is novel and interesting. The theoretical results seem solid.\n\nWeaknesses: 1. This paper is not well written since there are many typos. For example, see \"Section ??\" on Page 8, \"Lemma ??\" on Page 13, and \"Definition ??\" on Page 15.\n2. Many theoretical results are about SVC. More theoretical results on more complicated models should be included.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is not very well written. \nQuality: This paper is technically sound.\nNovelty: The novelty of this paper is high.",
            "summary_of_the_review": "In summary, this is a solid paper with novel ideas. The idea of using calculus of variations and differential equations to tackle the robust training of neural network models is novel and interesting. However, This paper is not very well written. Also, more theoretical results on more complicated models should be included. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_od7j"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_od7j"
        ]
    },
    {
        "id": "DuYR9iLKxE",
        "original": null,
        "number": 4,
        "cdate": 1666924604206,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666924604206,
        "tmdate": 1666964569767,
        "tddate": null,
        "forum": "ttnf-Wibn2R",
        "replyto": "ttnf-Wibn2R",
        "invitation": "ICLR.cc/2023/Conference/Paper5647/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a geometric and analytic modeling perspective for robust training. They first propose a formalization of robustness in learning theoretic term, then give a geometrical description of the phenomenon for simple classifiers. Experiments are conducted on synthetic and real-world data to verify their idea. ",
            "strength_and_weaknesses": "Strength:\nThe paper tries to provide a general framework for robust learning and the goal is plausible. \n\nWeaknesses: \nThe writing is weak and as a result I can only barely judge the other aspects of the paper.  \nAside from the obvious LaTex compiling error, the paper spends quite a few pages to include new definitions, which are only explained in later sections. When reading the paper following each section, the reader may get confused about why this definition is included -- very oftenly the definition just appear without any motivating sentences. For example, there is no explanation for why SVC is needed before Definition 2.4 and why complex-value classifier is needed before Definition 3.1. \nThe writing also fails to clearly identify Assumptions that should be made for this analytical framework, e.g., \"If we find some sample x that does not perplex h but is not correctly labeled by h, then we assume that H is agnostic to the pattern f x.\" appears in a paragraph, but I think this should be an assumption that needs to get highlighted. \nAlso in terms of clarity, when the paper mentions \"integral representation is more adequate for analysis when there is a continuum of features to choose from, e.g. ANN\" -- the paper does not define what 'feature' is in ANN so one can only guess what the meaning is. \nThere are clarity issues in the main results section (Section 4) as well. Theorem should be self-explanatory as much as possible, whereas in Theorem 4.1, it is unclear what does f mean and there is no short proof provided (if one dives deeper, it points to Appendix C.7 then Proposition C.2 which seems to be from another paper.). \n",
            "clarity,_quality,_novelty_and_reproducibility": "I have expressed my concerns on clarity and quality in the above section. ",
            "summary_of_the_review": "I would vote for reject since the writing does not meet the bar. Even though the paper may contain interesting ideas, it probably should go through another review round after a major revision. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_vhPa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5647/Reviewer_vhPa"
        ]
    }
]