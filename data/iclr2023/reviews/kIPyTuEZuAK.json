[
    {
        "id": "Zia2qAWvI8",
        "original": null,
        "number": 1,
        "cdate": 1665681902932,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665681902932,
        "tmdate": 1665940201614,
        "tddate": null,
        "forum": "kIPyTuEZuAK",
        "replyto": "kIPyTuEZuAK",
        "invitation": "ICLR.cc/2023/Conference/Paper1496/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a visual reasoning task/benchmark that combines 3 levels: perception, syntax, and semantics. The reasoning aspect requires compositional generalization. Concretely, the task is to interpret handwritten arithmetic sequences, directly from images. Models are expected to learn all 3 levels end-to-end, without intermediate supervision. The evaluation is set up with different test set to measure performance of the various levels and with varying difficulty.",
            "strength_and_weaknesses": "### Strengths\n\n- Complementary to existing benchmarks(e.g. SCAN): realistic (non-synthetic) visual input, complex syntax and semantics.\n- Experiments with a broad range of models (classical seq2seq to modern transformers).\n- Various evaluation settings including a few-shot learning scenario.\n\n### Weaknesses / suggestions\n\n- W1: The existing datasets included in the review (Table 2) focus on those with training/test splits specifically designed to evaluate systematic/compositional generalization. It seems to me that other benchmarks for visual reasoning are also relevant to most other aspects of this work, such as the Raven-type matrices, for example [1,2,3]. [1,2] require perception and semantics (I believe), while [3] additionally requires perception of real visual inputs (entire photographs). I think this extension (perception requiring to parse entire photographs) is particularly relevant to this work (w.r.t. the first limitation - discussed by the authors - of the limited visual complexity of digits).\n\n- W2: The chosen task/domain has several limitations, but the authors already discuss these quite clearly at the very end of the paper.\n\n\n[1] [Measuring abstract reasoning in neural networks](https://arxiv.org/abs/1807.04225)\n\n[2] [RAVEN: A Dataset for Relational and Analogical Visual rEasoNing](https://arxiv.org/abs/1903.02741)\n\n[3] [V-PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices](https://arxiv.org/abs/1907.12271)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written.",
            "summary_of_the_review": "I think this task/benchmark is at the right level of complexity for the current state of the art. I cannot see any major flaws in the paper and believe it will be of interest to the research community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_q55G"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_q55G"
        ]
    },
    {
        "id": "mAu9JsI4y4n",
        "original": null,
        "number": 2,
        "cdate": 1666460989205,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666460989205,
        "tmdate": 1666460989205,
        "tddate": null,
        "forum": "kIPyTuEZuAK",
        "replyto": "kIPyTuEZuAK",
        "invitation": "ICLR.cc/2023/Conference/Paper1496/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors created a large dataset that examine seq2seq models' ability to perform perception, syntax and semantics learning. The test sets are carefully constructed to study interpolation and extrapolation in various combinations. A large set of existing models are examined to check their performances.",
            "strength_and_weaknesses": "I want to preface this by saying that I'm not really familiar with this field.\n\nStrength:\n* The dataset is quite interesting to me. I think it can be a well-received dataset to test machine's ability to learn concepts.\n* The presentation is quite clear. The authors show several very informative tables (e.g. comparison with prior datasets, explanation of the various tasks). These tables are quite helpful for someone like me who's unfamiliar with the field.\n* The test set design is systematic and well designed.\n* A good group of existing models are examined. Informative results are provided. \n\nWeakness:\n* I don't know if it's standard practice, but as far as I can tell, the Egyptian characters are not part of the dataset? Not sure if that's an oversell of the paper. \n* the claim that \"Models show a significant gap toward human-level generalization\" is not experimentally evaluated. This sentence is briefly discussed in the caption of Figure 5, but i find the reasoning to be quite weak. The given dataset are based on simple arithmetic, so human are definitely having a very strong prior. By not evaluating the methods properly and isolate the effect of human prior, the claim seems unwarranted. For example, if everything is represented in Egyptian letter (perception level) and/or some new syntax / operations are involved, how can human extrapolate?",
            "clarity,_quality,_novelty_and_reproducibility": "Very nice across these aspects.",
            "summary_of_the_review": "I like this paper and think this is above acceptance threshold. However, I'm waiting to see other reviewers's feedback (who probably are more familiar with the field than I am), before giving it a very strong endorsement.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_LVqC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_LVqC"
        ]
    },
    {
        "id": "Pbpz1EGR_g",
        "original": null,
        "number": 3,
        "cdate": 1666642153127,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666642153127,
        "tmdate": 1666642153127,
        "tddate": null,
        "forum": "kIPyTuEZuAK",
        "replyto": "kIPyTuEZuAK",
        "invitation": "ICLR.cc/2023/Conference/Paper1496/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new language-like dataset, HINT, that requires a learning system to map handwritten arithmetic expressions to numbers. In contrast to prior datasets, HINT require learning systems to learn perception, syntax and semantics. Experiments reveal that current LSTM and Transformer based architectures are unable to generalize well on the problem, and scaling experiments indicate that an infeasible amount of data and parameters are needed to perform well on the task.",
            "strength_and_weaknesses": "**Strengths**\nThe proposed dataset is simple to construct, yet very challenging which is a major plus point. As illustrated in Table 2, the dataset is categorically different from prior work since it tests systematic generalization over perception, syntax and semantics. The dataset has different levels of difficulty corresponding to different levels of generalization. Finally, a major strength of the dataset is the ability to test the acquisition of new concepts.\n\nThe empirical results are also well conducted. Strong baselines are tested on the task, including GPT-3, which provides confidence that the proposed benchmark is actually difficult to solve. The scaling experiments are also quite valuable since they demonstrate that the task can't be solved simply by using more data and computation. In my view, the few-shot learning results in section 4.2 are the most compelling experiments since they illustrate the difficulty of arguably the most challenging aspect of the task (namely, generalizing over semantics).\n\n\n**Weaknesses**\nOverall, the weaknesses of the paper are relatively minor. One concern is regarding the separation between syntax and semantics. In the proposed task, this separation is clear, but in other tasks it seems less clear. For instance, to what extent do solving tasks in CLEVR require understanding the semantics of objects in the scene? The authors appear to argue that semantics are not required, but justifying why this is the case would be helpful.\n\nAlso, the authors effectively test broad generalization over syntax and semantics. However, the way they test generalization over perception seems to be simply using different handwritten examples of the same symbols in the test set compared to the training set. Would it be possible to test a broader level of generalization over perception as well? For example, the authors could replace the symbols with the hieroglyphics from table 1 and test the learning system's ability to quickly learn and generalize to the new symbols.\n\nIt would also be helpful to understand how the models generalize separately on syntax and semantics. For instance, the authors may want to test generalization over syntax while keeping semantics fixed by testing on the same sequences as observed during testing but using different numbers (0, 1,... 9). This would be easier than the SS set proposed by the authors, but would still shed light on how the models operate.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nThe paper is generally well written with well illustrated figures and informative tables. Table 2 is particularly helpful. The bullet points in Section 5 are also quite useful to guide the reader.\n\n**Quality**\nThe decisions behind the construction of HINT are well justified. Experiments are comprehensive, with good choices of baselines and comprehensive additional details in the appendix.\n\n**Originality**\nThe proposed dataset appears quite novel to my knowledge. Although on the surface it may appear similar to some previous datasets, the authors convincingly argue in Section 2 that HINT is designed to be significantly more challenging than prior datasets. As noted above, a particularly compelling aspect of the proposed dataset is its relative simplicity.\n\n",
            "summary_of_the_review": "The proposed dataset appears significantly more challenging than prior datasets, which is backed up by extensive experiments by the authors. The scaling experiments suggest that generalizing on this task will require new algorithmic or architectural innovations rather than merely larger scale. If this dataset encourages the development of new methods that can simultaneously learn perception, syntax and semantics, that could produce a very large impact in the field. Thus, I recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_31D3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_31D3"
        ]
    },
    {
        "id": "30jpGB0-_F",
        "original": null,
        "number": 4,
        "cdate": 1666725164307,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666725164307,
        "tmdate": 1666725164307,
        "tddate": null,
        "forum": "kIPyTuEZuAK",
        "replyto": "kIPyTuEZuAK",
        "invitation": "ICLR.cc/2023/Conference/Paper1496/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new dataset: HINT for studying machine reasoning across the joint domain of perception, syntax and semantics. HINT is a light-weighted dataset based on hand-written style digit arithmetic. Despite its simplicity, this paper introduces various generalization tasks over these three domains and demonstrates that state-of-the-art neural models perform poorly on these tasks. HINT sheds light on future studies of full-spectrum generalizability for machine reasoning.",
            "strength_and_weaknesses": "HINT is a well-designed dataset with simple data yet complex generation tasks. I like the minimalistic design to keep the generalization study clean across 3 different domains, this way we can diagnose a model in more depth. The paper includes evaluations of several state-of-the-art neural models, including variations of recurrent nets (LSTM, GRU), transformers, and GPT-3. Empirical study shows these neural models' capabilities of generalization across perception, syntactics and semantics, revealing a general lack of power on the latter two domains.This paper also provides insightful results on few-shot generalization of new arithmetic concepts.\n\nTo me the weakness of this paper is also obvious. The baselines are too simple and only concentrate on neural networks, while on the other hand semantic parsing has been long-studied by the NLP community ([1] as an example). Even within the domain of neural networks, there are models designed for generalization already been published for a long time (such as [2]). It is very unfortunate that these related works are missing from the discussion.\n\n[1] Guu et al. 2017 \"From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood\"\n[2] Andreas et al. 2017 \"Neural Module Networks\"",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well-written. The results are clearly presented. However, important related works / baselines are missing to further establish its novelty.",
            "summary_of_the_review": "My current assessment to this paper is borderline accept, conditioned on the authors constructive response regarding related fields / baselines. I won't object if this paper is rejected because of weakness on these aspects.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_52ig"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1496/Reviewer_52ig"
        ]
    }
]