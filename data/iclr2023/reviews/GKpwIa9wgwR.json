[
    {
        "id": "t7S7LPqaZQ",
        "original": null,
        "number": 1,
        "cdate": 1666647971462,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647971462,
        "tmdate": 1670015446248,
        "tddate": null,
        "forum": "GKpwIa9wgwR",
        "replyto": "GKpwIa9wgwR",
        "invitation": "ICLR.cc/2023/Conference/Paper5898/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a SUBSELNET to select a subset of training data. SUBSELNET is a non-adaptive method as it is agnostic to model architecture and training stage and. The authors design a neural model approximator to approximate the output of any given architecture. Two variants of subset sampler are proposed.  SUBSELNET is compared against state-of-the-art methods on three datasets to demonstrate the tradeoff advantage between accuracy and speed up.",
            "strength_and_weaknesses": "Strength:\n\n(1)\tWell-motivated problem. Data selection for an unseen architecture is an important problem with real-world impact.\n\nWeakness:\n\n(1)\tThe main problem of this work is the experiment. The authors choose 0.5% and 5% of training data, however, with such a low subsample rate, we notice a dramatic accuracy drop in Figure 1.  It is hard to judge the effectiveness of any methods with such a significant accuracy drop. The experiment should reflect at what speed up, the model can maintain the same accuracy. Essentially, focusing on the left side of Figure 1. The authors may consider a larger range of sampling rates (5%, 10%, 20%,30%, 40%, 50%, 60%, 70%), following the setup of previous work such as GraNd and Gister. \n\nQuestion:\n\n(1)\tWhen calculating inference time, are you assume selection and training are conducted in sequential? Is it possible to perform selection in parallel with training when loading a batch of data?\n\n(2)\tWhat is the training cost of training the model approximator? Have the authors evaluated the approximator error? \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Clarity is fine. Figures are generally easy to read. Most descriptions are clear. \n\nQuality:  Experiments setups can be improved ( See Weakness 1). Writing can be polished with noticeable grammar mistakes.   For example, Section 5.1 Model architectures and baselines: four non-adaptive  -> four adaptive. Figure1 Caption ;and; -> , and\n\nNovelty:  Neural model approximator using GNN seems new for data selection. \n",
            "summary_of_the_review": "I would recommend weak rejection because of the experiment results. It is hard to judge the effectiveness of the proposed method when all methods exhibit significant accuracy drops.  I would increase my score if the authors could demonstrate the efficiency advantage of the proposed method at no or negligible accuracy loss. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_a8HM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_a8HM"
        ]
    },
    {
        "id": "b6R2wmRkGK3",
        "original": null,
        "number": 2,
        "cdate": 1666664761359,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664761359,
        "tmdate": 1666664761359,
        "tddate": null,
        "forum": "GKpwIa9wgwR",
        "replyto": "GKpwIa9wgwR",
        "invitation": "ICLR.cc/2023/Conference/Paper5898/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In  this paper,  a new non-adaptive data subset selection method is proposed. The traditional adaptive method mixed the training and  subset selection. While for the new proposed method, the subset processing is done before the training. Furthermore, the paper also proposed the transductive and inductive variants. The experimental results verified that both variants output perform the baselines on subset selection and also an be used to choose the best architecture.\n",
            "strength_and_weaknesses": "This paper has a clear decomposition on the model into parts including model approximator and subset sampler. And for each part, it has clear annotations to explain the whole process. \nFor the subset sampler, 2 variants are proposed and the experimental results show the tradeoff between them, and furthermore, a combination of these 2 variants are tested too.\nThe comprehensive experimental results proved the effectiveness of the proposed method.\nSome questions:\n1. some writing errors such as \u201cviz.\u201d appeared a couple of times.\n2. both formula (5) and (6) has the E_S, is that correct? \n3. for the E_S optimization objective such as (6), as the parameter \\pi is under the prob distribution and needs sampling, how do you optimize the \\pi? do you use some reparameterization trick which is now shown in the paper.\n4. Can you elaborate more on why you don\u2019t jointly optimize the gnn parameter and transformer parameter?\n5. In the experimental setup, the paper mentions all the baselines are non-adaptive, is it correct?\n6. Do you have any results to show the accuracy gap between the neural model approximator and the fully trained model?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper proposed a new non-adaptive method for the data subset selection problem and has a clear description of the proposed method. Also the experimental results verify the paper\u2019s arguments: mainly on the advantage of the tradeoff between speedup and memory.",
            "summary_of_the_review": "In summary I think this paper makes a good presentation on a new method for the non-adaptive methods and verifies the contributions in the experimental studies. It will be better to fix some annotations and have more ablation studies and show more results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_VJSk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_VJSk"
        ]
    },
    {
        "id": "nzK5ddbTsE0",
        "original": null,
        "number": 3,
        "cdate": 1666918152722,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666918152722,
        "tmdate": 1666918152722,
        "tddate": null,
        "forum": "GKpwIa9wgwR",
        "replyto": "GKpwIa9wgwR",
        "invitation": "ICLR.cc/2023/Conference/Paper5898/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors present SUBSELNET - a non- adaptive subset selection framework for solving a particular aspect of subset selection problem - improving generalizability of the subset selection approach; with existing methods, the algorithm has to be executed from the beginning for each new model.\nThe authors introduce an attention based neural approach that uses the graph structure of the architectures, which is then used to build subset samplers. Their approach has 2 variants: transductive and inductive.\nThey claim that their approach is more efficient than the existing approaches since the subset is chosen at the beginning of the training process, and the entire dataset is not required through the training process. ",
            "strength_and_weaknesses": "The authors have provided the motivation for the problem, and presented the solution to address the problem. They have also evaluated their approach against 6 other approaches, and 3 different datasets, showing the speed up and memory utilization. \nThe approach overall is interesting since, they are able to preselect the dataset for the training process. \n\nHowever, there are a few areas that are not clear from the paper.\n1. It would have been great if the authors spent more time discussing the pros- and cons- of their graph network. In general, graph networks themselves can be large, slow and memory consuming. It seems like the comparison is performed on the output of the graph network rather than the end-to-end approach.\nThe details about the GNN and the graph embedding are important.\n\n2. Much of the details, including the step-by-step algorithm and the details are added to the appendix. For instance, the diagram in appendix B and Pseudocode in C, both would have helped understand the paper better, if it was in the main text.\n\n3. Since the approach relies on pre-selecting, it is not clear how the approach is able to avoid overfitting or underfitting. The authors have split the data into train, validation and test sets. Including a report on the accuracy on these datasets, and the time/ computation resources required for these would have been helpful.\n\n4. The loss function (eq 1) and the objective functions (5 and 6) require more explanation. For intance, the authors state in page 3 after eq1 that: \"One can use submodular functions (Fujishige, 2005; Iyer, 2015) like Facility Location, graph cut, or Log-Determinants to model DIVERSITY(S)\". However, they havent mentioned the approach they have used in the paper. \nLater, they mention the use of entropy on the subset sampler H(Pr\u03c0(\u2022)) to model the diversity in page 4 after eq 5 and  KL after eq 6. The choice of the functions needs to be elaborated to appreciate the approach better. ",
            "clarity,_quality,_novelty_and_reproducibility": "The approach overall is interesting since, they are able to preselect the dataset for the training process. It seems novel in that aspect.\nThe paper's clarity can be improved - important and interesting parts have been moved to the appendix, whereas the math behind the model could have been explained better. \nThe paper as presented, is less easy to reproduce - details about the GNN, the embeddings etc are probably missing. ",
            "summary_of_the_review": "The approach overall is interesting since, they are able to preselect the dataset for the training process. The authors introduce an attention based neural approach that uses the graph structure of the architectures, which is then used to build subset samplers. Their approach has 2 variants: transductive and inductive. They claim that their approach is more efficient than the existing approaches since the subset is chosen at the beginning of the training process, and the entire dataset is not required through the training process.\n\nOverall, there are a few areas that are not clear from the paper, including the implementation and the evaluation of the approach. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_B3Rj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5898/Reviewer_B3Rj"
        ]
    }
]