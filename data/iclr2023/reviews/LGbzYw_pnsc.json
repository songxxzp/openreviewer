[
    {
        "id": "wlh7RJjJVO",
        "original": null,
        "number": 1,
        "cdate": 1666443409579,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666443409579,
        "tmdate": 1666443409579,
        "tddate": null,
        "forum": "LGbzYw_pnsc",
        "replyto": "LGbzYw_pnsc",
        "invitation": "ICLR.cc/2023/Conference/Paper359/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors proposed an overall evaluation system to investigate the gap between humans and machines in dynamic vision tasks. In particular, they chose single object tracking as the representative task, and design an overall evaluation system from three aspects (Experimental environment construction, Experimental executor selection, and Evaluation method design). The results provide insights for fellow researchers in the related fields. ",
            "strength_and_weaknesses": "Strength: \n\nThe paper works on an interesting problem. The presentation of this paper is clear. \n\nThe authors have provided detailed supplementary materials to support the main paper. \n\n\nWeakness:\n\nThe authors used SOT as a single representative task for the evaluation system, but the concept of dynamic vision ability is much broader and includes numerous other tasks. Perhaps the authors can tune down a bit their claims throughout the paper. \n\nCorrespondingly, it is unclear to me how the results could contribute to the real applications, since the evaluation is only on SOT. \n\nAs we all know, human subjects have their biases due to their diverse cognitive background. I wonder if the authors should recruit more diversified human subjects, instead of 15 subjects while all of them are computer vision researchers aged 20-30.  Furthermore, how the machine models are trained also matters a lot. The authors can discuss the above potential issues in order to give a more convincing evaluation. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper\u2019s presentation is clear. It is of moderately good quality and originality. ",
            "summary_of_the_review": "The paper is interesting and has its merits. However, as mentioned above in the weakness part, I feel the title is a bit overclaimed and the actual contribution is not very clear. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper359/Reviewer_RdAz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper359/Reviewer_RdAz"
        ]
    },
    {
        "id": "Upt_7-u0vg",
        "original": null,
        "number": 2,
        "cdate": 1666593867412,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593867412,
        "tmdate": 1666594470909,
        "tddate": null,
        "forum": "LGbzYw_pnsc",
        "replyto": "LGbzYw_pnsc",
        "invitation": "ICLR.cc/2023/Conference/Paper359/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "With the observation that no other work compared humans and machines in dynamic vision ability, the authors designed an overall evaluation system followed by previous work. Specifically, they evaluated humans and machines on the single object tracking task and compared their performance in multiple aspects. The analysis found that humans have stronger DVA, but the gap is not big, especially in the SOTA models. Finally, they show when human-machine cooperate, the performance can be even better than humans.",
            "strength_and_weaknesses": "**Strengths:**\n\n* The paper is well written, and the reviewer enjoyed reading it. \n\n* The authors provide details about the experimental settings so that the readers can understand the experiments well. \n\n* The authors conducted deep analysis for comparing human and machine DVA. \n\n**Weaknesses:**\n\n* The paper lacks contributions. The authors collect additional human subjects' responses for the SOT task and run 20 models to get machine responses, which is followed by deep analysis to compare the human and machine DVA. However, this reviewer is unclear what are the contributions (especially technical contributions) of this paper. \n\n* Section 2.2 does not contain the related work on the computer vision tasks, but the section rather looks like it introduces the term. Indeed, the tasks were already presented in Section 1.\n\n* In Figure 11: \"the blue sequences\" looked like they indicated the letters with a blue background, i.e. all the sequences. It is recommended either change the text background color or make it transparent. Further, it would be better to call the sequences A, B, C, ... instead of B2, D2, G4, ...  for better readability unless B2, D2, G4, ... has meanings. \n\n* Typos: \n\n\"Aritciture\" in Table 1",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:**\n\n* Figure 1(b). What is the table for? Where is the table referred to?\n\n* In human-machine cooperation (Section 4.2), when machines fail to track, did the authors ask humans to provide the current target position? In other words, did the human subjects wait until the machine failed and then pick the position whenever the machine failed? Also, how many subjects participated in the cooperation experiments?\n\n**Novelty:**\n\nAs written in the above section, it is not clear about the contributions of this paper. \n\n**Reproducibility:**\n\nThe authors said in the introduction that they would open-source the toolbox, code, and metrics. \n\n",
            "summary_of_the_review": "The paper is well written with deep analysis to compare humans and machines in dynamic vision ability. However, the paper lacks novel contributions on the topics of learning representation. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper359/Reviewer_zwYU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper359/Reviewer_zwYU"
        ]
    },
    {
        "id": "xDhzxajZZFX",
        "original": null,
        "number": 3,
        "cdate": 1667513956307,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667513956307,
        "tmdate": 1667513956307,
        "tddate": null,
        "forum": "LGbzYw_pnsc",
        "replyto": "LGbzYw_pnsc",
        "invitation": "ICLR.cc/2023/Conference/Paper359/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The presented work focuses on evaluation of the performance of machines and humans in perceptual and cognitive components of dynamic visual ability and understanding the gap between humans and machines capabilities. In addition, an approach for machine and human collaboration is proposed and tested. \nThe experiments were performed on a wide set of models and input data showing that perceptual ability of both humans and machines are closer than the cognitive ability, in which humans outperform machines. It has been also proved that human machine cooperation is possible and can lead to improved performance. ",
            "strength_and_weaknesses": "The claims of the paper are supported with experiments performed for multiple models. The topic is introduced well and compared with relevant studies in the same area. The DVA capabilities are examined from static and dynamic perspective. The work flows logically.\n\nOverall the work is interesting, the only concern is comparison of centers of objects. It is not clear how you ensure humans correctly mark centers of objects. It might be difficult for humans to visually find the object center. Have you encountered any issues there? If yes, then comparison of machine's performance might not be fair. Another minor issue is complexity of figures. It's difficult to quickly understand them, and careful analysis is needed. It would be nice to simplify them if possible. It might be also beneficial to compare the proposed human-machine cooperation mechanism with other existing human in the loop approaches. ",
            "clarity,_quality,_novelty_and_reproducibility": "The work is well structured, clear, and supported by extensive experiments. The code will be made publicly available, so it will be possible to reproduce results. ",
            "summary_of_the_review": "The work is interesting and claims are supported by extensive experiments. The addressed problem and approach seems novel, even though it's using existing models/metrics. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper359/Reviewer_co2u"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper359/Reviewer_co2u"
        ]
    }
]