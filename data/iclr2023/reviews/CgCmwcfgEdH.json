[
    {
        "id": "syAcP5ZzPv7",
        "original": null,
        "number": 1,
        "cdate": 1666674031713,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674031713,
        "tmdate": 1667012581002,
        "tddate": null,
        "forum": "CgCmwcfgEdH",
        "replyto": "CgCmwcfgEdH",
        "invitation": "ICLR.cc/2023/Conference/Paper2993/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper addresses the problem of how to train a single model to handle predictions in multiple domains (domain generalization), more specifically how to learn a model that will generalize well across the different domains.  The authors argue that one deficiency of current approaches is that models often fail to lear nt the distinction between shared common features and domain-specific noise, hindering their generalization.  They define the principal gradient (or PGrad), which is derived as the subspace of the gradients which capture the largest directions of variation (akin to PCA), and argue that updating the model by steps in the direction of the principal gradient will allow for greater generalization capabilities.  They show that different variations on PGrad achieve strong results on DomainBed benchmark datasets, and competitive results on WILDS. They also establish with experimental evidence that variation in the training loss is much smoother.  \n\n",
            "strength_and_weaknesses": "### Strengths\n- The paper is written very directly.  The intuition behind the idea of finding principal gradient directions is well explained, and the connection to the estimation of the Fisher Information Matrix is helpful.  Though I will say that Appendix 5.1 is a bit brisk in its explanation. \n- The clever trick in equation (7) is compactly explained.  \n- Section 2 of the paper establishes links to similar ideas in invariant feature learning and gradient regularization.\n- Building off of DomainBed makes the method immediately more reproducible and straightforwardly comparable to other domain generalization methods.\n\n### Weaknesses\n- In section 2, the authors state that \n> When using ERM in DG setting, each step of model updates uses an average gradient and may introduce and preserve domain-specific noise. For instance, if one training domain includes the trapping signals like cows always in pastures and camels always in deserts (as mentioned earlier).\n\nGulrajani and Lopez-Paz managed to use ERM to achieve great performance on the DomainBed datasets despite being open to this risk.  Given their strong ERM baseline results, which are unable to distinguish domain specific noise from common features, do you think it is a real risk or simply a possible one?\n\n- In section 2.1 just above equation (6), the authors claim \u201cthe revised computational complexity is $n$\u201d.\nIt is unclear what it meant here. The complexity of computing the SVD of the matrix $\\hat{\\mathbb{S}}^{T}\\hat{\\mathbb{S}}$ is cubic in the parameter vector size.  Even after introducing the bijection allowing this SVD to be performed on an n x n matrix, the computational complexity is still cubic in $n$.  Could the authors clarify here?\n- In section 2.1, equation (9) is justified by scaling the eigenvectors $w_z$ by the ratio of $\\frac{\\lambda_z}{\\mathbf{\\lambda}}$.  This is justified under the rubric of normalizing the gradient to reduce training instability, but it is unclear why equation (11) needs to further scale by accounting for the length of $\\Delta_r$.  Could the authors provide a footnote or some more justification for this?  Why not simply adjust the learning rate later in training?\n-  For equation (12), this exposition can be simplified.  It might help to establish a link between the degree to which each individual $\\theta_i$ is optimal (estimated itself via SGD, but not specified IIRC) and the degree to which PGrad can mitigate errors in the directions of any group of $\\theta_i$\n- Section 3 begins with a series of questions that the authors aim to probe in their experiments.  Question 2 is about whether Pgram will work with different architectures or data types.  I feel like Q2 is almost bound to be answered affirmatively.  How could it not? Any parameterized model will yield gradient estimates, and so the principal gradient can always be computed.  As the authors claim in section 2.4, their model is model and data agnostic.  \n\nA question I think would be more impactful, is to see is how well the principal gradient performs in the presence of noisy data that yield high variance gradient estimates?  Could the principal gradient be combined with other variance reduction techniques to yield more stable updates in the presence of such noisy (and variable) gradient estimates?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The central assumption of PGrad is that the principal gradient directions, that are common to each batch in a rollout drawn from the different domains available at training time, are those which should provide the best generalization performance to new domains.  \n\nHaving built on top of DomainBed, the experiments of section 3 should be reproducible (assuming the authors controlled for seeds and other major sources of randomness).  One issue about Table 2 is that it reports the per-domain accuracy average for all domains in all five data sets, possibly masking variation within domains of each task.\n\nAnother hinderance to reproducibility is the statement in the header of Table 2 that\n> We group 20% data from each training domain to construct validation set for model selection\n\nGulrajani and Lopez-Paz emphasize that model selection must be very carefully described and carried out for domain generalization.  Do the authors believe this is a sufficiently balanced and detailed way to specify how model selection was carried out?\n",
            "summary_of_the_review": "The main technical contributions of this paper are to adapt ideas from principal component analysis to the estimation of gradient directions that are common among disparate domains.  While simple on the surface, the authors show clearly that this is a very clever and elegant solution to domain generalization.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_jbQd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_jbQd"
        ]
    },
    {
        "id": "2wHwVbcejX",
        "original": null,
        "number": 2,
        "cdate": 1666688725451,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666688725451,
        "tmdate": 1666707385500,
        "tddate": null,
        "forum": "CgCmwcfgEdH",
        "replyto": "CgCmwcfgEdH",
        "invitation": "ICLR.cc/2023/Conference/Paper2993/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper develops a new optimization algorithm named PGrad for domain generalization. The proposed method attempts to filter out domain-specific noise and provide an update direction that maximally benefits all training domains. The experimental results show improved domain generalization performance on multiple datasets.",
            "strength_and_weaknesses": "Strength\n\nThe technical part of this paper is easy to follow, and the empirical results have shown the potential of the proposed method.\n\nWeaknesses\n1. PGrad is motivated by a few intuitions, which are not supported or verified by any theoretical or experimental analysis. For instance, it's unclear why PGrad \"forces the learned gradient to filter out domain-specific noise\nand follows a direction that maximally benefits all training domains\", where the domain-specific noise is not well-defined to begin with.\n2. PGrad incorporates multiple techniques, including trajectory sampling and its SVD decomposition, directional calibration, L2 normalization, length calibration, and noise suppression. Without a proper ablation study, it's unclear how each technique contributes to the overall improvement. In particular, it is possible that simple techniques such as sequential optimization on each training domain and gradient normalization are responsible for most of the improvement, in which case the motivation would be even less convincing.\n3. The computational overhead of trajectory sampling seems to be significant, but is not discussed in the paper.\n4. While Table 2 include 11 methods for comparison, the experiments on the WILDS dataset (Table 5) only include three methods.",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of this paper is clear. The proposed method is novel and should be easy to reproduce.",
            "summary_of_the_review": "This paper is easy to follow and has shown some promising results. However, it lacks important theoretical or experimental analysis, and ablation studies.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_Fpjy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_Fpjy"
        ]
    },
    {
        "id": "v-QSkeTF071",
        "original": null,
        "number": 3,
        "cdate": 1666987301021,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666987301021,
        "tmdate": 1666987301021,
        "tddate": null,
        "forum": "CgCmwcfgEdH",
        "replyto": "CgCmwcfgEdH",
        "invitation": "ICLR.cc/2023/Conference/Paper2993/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper develops a new optimization method for domain generalization. The idea of the proposed PGrad approach is to use a robust gradient direction for parameter update. The robust direction is estimated in 2 steps. First, the rollout of the weights trajectory is collected by sequentially applying training updates in each of the training domains. Then, the principal components of the collected weight space point cloud are estimated and the final update direction is constructed as a combination of the leading principal directions with the downplayed or truncated contribution of the tail directions. The intuition behind this approach is that the low-variance directions are likely to correspond to domain-specific noise and suppression of this noise presumably leads to robust training updates and better generalization on unobserved test domains.\n\nThe authors conduct an extensive set of experiments demonstrating the effectiveness of the approach on large scale domain generalization benchmarks: DomainBed and WILDS. The method delivers improvement over recent domain generalization methods including closely related approaches (Fish and Fishr) that are based on cross-domain gradient penalties.\n",
            "strength_and_weaknesses": "Strengths:\n* The paper proposes a simple and effective method for domain generalization.\n* The evaluation and ablations of the proposed approach are comprehensive.\n* The authors thoroughly discuss the connection and differences between the proposed approach and the recent related work. I find the argument about the benefit of the sequential gradient computation approach compared to parallel gradients particularly interesting (Appendix A.4).\n\nWeaknesses:\n\nI did not find any critical weaknesses. Below are some questions that came to my mind when reading the paper. These are not meant to be taken as a criticism of the work done by the authors but rather as open questions and potential directions for future work.\n\nAfter reading the paper, it is clear that the method delivers improvements on domain generalization benchmarks. However, the mechanisms behind the success of the method and theoretical justification are not completely clear. The authors provide several insightful yet not very concrete and rather intuition-level explanations (such as noise suppression and connection between trajectory of covariance matrix and Hessian of the loss), but some questions remain unanswered:\n\n* Do the bottom eigenvectors actually correspond to \u201cdomain-specific\u201d noise? Is there any way to validate this claim directly (theoretically or in experiment)?\n\n\n* The authors point out that, compared to approaches based on representation alignment or invariance, PGrad does not place any explicit assumptions on the data distributions across domains and the type of distribution shift. On the one hand it is a nice property as the method can be applied to any domain generalization problem in principle, on the other hand it tells us that we do not really know in what scenarios the method is expected to work well and more importantly when it will fail. Clearly, no single method can be successful in all possible domain generalization settings. Figuring out assumptions on the data generating process and the model under which the method is guaranteed to succeed is an important open question.\n\n* What can be said about the method from the optimization perspective? Does PGrad have convergence guarantees?\n\n* How does the wall-clock time of PGrad training compare to that of SGD training? How significant is the computational overhead of PGrad?\n\n* I find the intuitive explanation of the benefit of the sequential training vs parallel training (Figure 5) very interesting. Is it possible to develop this argument in more precise theoretical statements or design experiments highlighting the effect?\n\nI realize that answering most of these questions requires conducting separate investigations, but I would still encourage authors to include a discussion of these issues mentioned above in the revised version of the paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality:\nOverall the results of the paper are of high quality. Please see my comments under \u201cStrengths And Weaknesses\u201d for detailed comments.\n\n\nNovelty:\n\nTo the best of my knowledge the approach proposed by the authors (i.e. estimation of robust update direction from principal components of trajectory rollouts in the context of domain generalization) is novel. \n\nThe connection between covariance of gradient descent trajectory and the Hessian of the loss (Appendix A.5) has been studied before (see e.g. [1], [2])\n\nI would also like to bring to the authors' attention two prior works which analyze/use PCA of training trajectory for understanding of training dynamics [3] and Bayesian inference in deep networks [4].\n\n\n[1] Mandt, S., Hoffman, M. D., & Blei, D. M. (2017). Stochastic Gradient Descent as Approximate Bayesian Inference. Journal of Machine Learning Research, 18, 1-35.\n\n[2] Chen, X., Lee, J. D., Tong, X. T., & Zhang, Y. (2020). Statistical inference for model parameters in stochastic gradient descent. The Annals of Statistics, 48(1), 251-273.\n\n[3] Antognini, J., & Sohl-Dickstein, J. (2018). PCA of high dimensional random walks with comparison to neural network training. Advances in Neural Information Processing Systems, 31.\n\n[4] Maddox, W. J., Izmailov, P., Garipov, T., Vetrov, D. P., & Wilson, A. G. (2019). A simple baseline for bayesian uncertainty in deep learning. Advances in Neural Information Processing Systems, 32.\n\nClarity:\n\nThe paper is well-structured and clearly-written. The description of the details of the method and experimental results is clear and easy to understand.\n\nI would recommend proof-reading the paper for typos and grammatical errors. I spotted a few minor presentation issues and typos while reading the paper:\n* page 6, typo in 1st paragraph: \u201cmomentum matching\u201d -> \u201cmoment matching\u201d\n\n\n* page 6, 4th paragraph. I have a hard time understanding the sentences \u201cOur method PGrad differs gradient matching by designing a robust gradient flow. Besides, our method learns one Hessian under the DG setup.\u201d \n* page 6, typo in 5th paragraph \u201cthere  exist  other  recent  adopted\u201d -> \u201cthere exist other recently adopted\u201d ?\n\n\n* page 7, Table 2. It would help the reader if the meaning of the subscript numbers in blue, red, and gray was explained in the caption of the table. I understood it from the text of the paper, but it would have been easier if the table was self-explanatory.\n\n\n* Page 9, typo in the 2nd paragraph: \u201cstandard derivations\u201d -> \u201cstandard deviations\u201d\n\n\n* Page 15, 4th paragraph. Perhaps instead of \u201cWe visualize the test domain accuracy and training domains gradient alignment in terms of the training epoch.\u201d it would be clearer to say\n\u201cWe visualize the test domain accuracy and training domains gradient alignment as functions of the training epoch.\u201d \n\n* Page 15, title of section A.5. \u201cTheoretic analysis\u201d -> \u201cTheoretical analysis\u201d?\n\n* Page 16 after equation (16). \u201cWe explain how automatically our method PGrad approximates and aggregates the eigenvalues of the Hessian matrix by following the proposed training procedures.\u201d -> \u201cWe explain how our method PGrad automatically approximates and aggregates the eigenvalues of the Hessian matrix by following the proposed training procedures.\u201d?\n\n\nReproducibility:\nI believe that the paper provides sufficient details for other researchers to be able to reproduce the results. I would encourage the authors to release the code for the reproduction of the experiments.\n",
            "summary_of_the_review": "The authors develop a simple and effective method for domain generalization which improves \nOOD generalization on large-scale benchmarks. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_ap7X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2993/Reviewer_ap7X"
        ]
    }
]