[
    {
        "id": "UXk9RqWD4W",
        "original": null,
        "number": 1,
        "cdate": 1666579042949,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666579042949,
        "tmdate": 1666579042949,
        "tddate": null,
        "forum": "WbyWDWoXD3",
        "replyto": "WbyWDWoXD3",
        "invitation": "ICLR.cc/2023/Conference/Paper146/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The proposed work intends to improve the diversity of multi-agent games by introducing a comprehensive Feint formalization in the combination of \u2018temporal\u2019, \u2018spatial\u2019, and \u2018collective impact\u2019; Despite some minor concerns about the experiments, the proposed method Feint\u2019s effectiveness was proven through the overhead evaluation, which cost a relative low time-consumption to realize the diversity boosting and reward increase. ",
            "strength_and_weaknesses": "Strength:\n\n- The proposed work\u2019s motivation is explicit, the statement clearly proposed the problems to be solved and how to support the influence.\nThe authors pay effort into the multi-agent gaming\u2019s feint\u2019s formalization and tried to solve the problem in a more realistic scenario inspired by the previous two-agent feint work.\n\n - It is proven to be low timing cost while increasing the agent players\u2019 diversity, encouraging it\u2019s the possibility of deployment to other multi-agent tasks.\n\n\nWeakness: \n\n- For the results shown in Figure, are the second sub-figure guaranteed to be converged? It seems that the continuous tendency might result in a worse reward. Maybe the comparison of the results after a longer training iteration would be more convincing.\n\n- The paper didn\u2019t explicitly explain whether the two params \u201c\u03bc1 and \u03bc2\u201d are manually set weights or learned weights in Section 3.2.3. The same confusion also exists in part 4.1: \u200b\u200b\u03bb1 and \u03bb2. If the parameters are empirical values, it\u2019s better to be provided in the paper for better instruction on the method\u2019s implementation.\n\n- It\u2019s stated in the experiments part that the environment Mordatch & Abbeel (2017), alphaStar, etc. were realized and tested to justify the Feint\u2019s effectiveness. If the real scene of gaming can be provided in a case study or presentation video, the performance of diversity would be better verified.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is of good originality, however, some minor issues should be better explained to support the higher quality and clarity of the paper. ",
            "summary_of_the_review": "The work proposed an effective way to encourage the depiction of comprehensive feint, from spatial, temporal, and most innovative part, collective impact sides. According to the author\u2019s explanation, the overall logic is clear and rational, however, as per the weakness, if the author could address the above concerns, the work will be more convincing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper146/Reviewer_r9R4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper146/Reviewer_r9R4"
        ]
    },
    {
        "id": "eytL4tO19K",
        "original": null,
        "number": 2,
        "cdate": 1666582628475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582628475,
        "tmdate": 1666582628475,
        "tddate": null,
        "forum": "WbyWDWoXD3",
        "replyto": "WbyWDWoXD3",
        "invitation": "ICLR.cc/2023/Conference/Paper146/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "If I understand this paper correctly, the authors introduce a way how to optimize for integrating \u201cfeint\u201d actions into the solutions of stochastic-game-like interactions to promote diversity. They do so by gradually building up the criterion function from three aspects they consider the most important, and refer to them as \u201ctemporal\u201d, \u201cspacial\u201d, and \u201ccollective\u201d impacts. The first half of the paper is dedicated to formal mathematical formulation of each of these aspects. The authors then show how to integrate their build up reward function into reinforcement-learning algorithms, or feint recognition models. The last part of the paper presents empirical results achieved with agents using \u201cfeints\u201d, examining gains in utilities, exploitability and diversity, and computational overheads incurred when optimizing for \u201cfeint\u201d inclusion. ",
            "strength_and_weaknesses": "The idea of examining how bluffing in multi-player games may influence the game-play seems indeed compelling to me, yet I have to admit I find this work rather confusing. First, I believe the motivation could be greatly improved. Are the authors attempting to integrate feints, how they say, to \u201cimprove game experiences\u201d? So do they imagine the applications of their work to be in the video-game industry, for example? Or is the inclusion of feints targeted more towards strategic robustness when multiple agents stray too far from the equilibrial paths, as examining reward gains in the experimental section seem to hint? The authors mention some \u201cneed for diversity\u201d yet I do not entirely understand where this need comes from.\n\nSecond, I believe my confusions stems partly also from the language the authors are using. At times, I found myself going through some parts of the text multiple times because I felt like I understood the individual words, yet the sentences did not make much sense as they were worded together. One of the examples is \u201c... [Naik et al.] \u2026 simply shrink smaller weights and deliver more future actions,\u201d which I am not sure how to interpret. Overall, the text seem maybe a bit too ambiguous, and some more concrete or detailed explanation of, e.g., what temporal or spacial impact are could greatly help the readers to familiarize with these concepts and why the authors find them so important.\n\nThis initial exposition seems especially important in the light of the seemingly trivial integration of the authors\u2019 concept into the feint detection or multiagent reinforcement-learning models. \n\nI also lack some intuition why feints would help gaining more utility or achieve lower exploitability agains agents who are not using feints, as the experimental section seems to suggest. If I understanding the feints correctly, as explained in section 3.2.1, the bluffing agents sacrifice longterm full rationality for the possibility of obtaining short-term high rewards. Are the higher gains reported in the empirical evaluation the result of the agents not using feints being at this points still too far from some equilibrium? Or is it because there are multiple feinting agents in the environment, so the deviations are not unilateral?\n\nOverall, I think the idea this paper presents is very interesting, but I feel the presentation needs to be further improved before I can support this paper's acceptance. \n\nNits:\nMethods in 3.1 do not seem to relate to feint at all.\nWhat are \u201cNon-People Characters\u201d? Do you mean \u201cnon-playable characters\u201d?\n\u201cMulti-to-on\u201d, maybe you mean \u201cmany-to-one\u201d?\n\u201cwe synthesis\u201d to \u201cwe syntesize\u201d \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the ideas the paper presents lack better explanation.\nQuality: the empirical section seems well presented.\nNovelty: seems a bit limited; the idea is interesting yet the integration is rather trivial.\nReplicability: the authors claim they hand-crafted the experimental domains, and the code does not seem to be available, which hinders replicability. ",
            "summary_of_the_review": "This paper presents a very interesting idea of including feints into agents\u2019 strategies in multiplayer games, yet I feel the exposition need to be substantially improved for this paper to be considered at a conference like ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper146/Reviewer_ebuk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper146/Reviewer_ebuk"
        ]
    },
    {
        "id": "r1g64gSi4Q",
        "original": null,
        "number": 3,
        "cdate": 1666750215106,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666750215106,
        "tmdate": 1666750215106,
        "tddate": null,
        "forum": "WbyWDWoXD3",
        "replyto": "WbyWDWoXD3",
        "invitation": "ICLR.cc/2023/Conference/Paper146/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method \"Feint\" to enable agents in multi-agent reinforcement learning to exhibit behaviors analagous to feints in human games; i.e. deceptive actions that are intended to look like an attack to draw a response from other agents.",
            "strength_and_weaknesses": "# Strengths\n- The notion of feinting is interesting to consider in a multi-agent reinforcement learning environment.\n\n# Weaknesses\n\n- The notion of feint is never formally defined. So it is unclear exactly what behavior is sought from the agents, and how it differs from standard behavior. For example, if agents are learning optimal policies, wouldn't such policies include feinting if indeed it was beneficial?\n- The proposed method to induce feinting is a simple modification of the reward function to emphasize near-term rewards over longer-term ones. Again, it is unclear how this is meant to encourage feints.\n- The experimental results show that agents with the feinting behavior receive higher rewards. But, that is because their reward functions were directly modified to give different (larger values) to near-term rewards. So this is expected and an artifact of the definition -- it does not show that these agents actually have a competitive advantage, as far as I can tell.",
            "clarity,_quality,_novelty_and_reproducibility": "\nIt is hard to understand what the contribution of this paper is meant to be.  The main concept of \"Feint\" is not well defined, as far as I can tell. The originality of the work is very low, as it is a simple modification to the discounting of rewards at future states.",
            "summary_of_the_review": "\nBased upon the above comments concerning originality and clarity, I will recommend to reject the paper.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper146/Reviewer_b6NC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper146/Reviewer_b6NC"
        ]
    }
]