[
    {
        "id": "CNfIoPkIe6I",
        "original": null,
        "number": 1,
        "cdate": 1665925126384,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665925126384,
        "tmdate": 1670662484953,
        "tddate": null,
        "forum": "tXc-riXhmx",
        "replyto": "tXc-riXhmx",
        "invitation": "ICLR.cc/2023/Conference/Paper4145/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper targets at few-shot classification. Motivated by Label Smooth, it designs LP-FT-FB to impose equivariance on the feature extractor to address the over-fitting problem. It first train a randomly initialized linear classifier on novel samples with FBR. Then the pretrained feature extractor and the classifier are finetuned on the same novel samples regularized with i-FBR. Experimental results show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Pros:\n1. The proposed method is well motivated and clearly stated.\n2. The experimental results look good. \n\n\nCons:\n1. The organization of the paper can be improved. (a) Table1 in the Supplementary Material is interesting. The reviewer suggests moving it to the main paper. Why not merge it with Table 1 in the Main paper? \n2. The reviewer thinks adding experiments to show the results of different i-FBR factor lambda_inv might be interesting, ranging from values smaller than zero to values larger than zero. \n3. Some experimental results are missing. Some experiments (Table.1) are conducted on mini-Imagenet, tiered-Imagenet, and CUB. But some only reported part of the results (e.g. in Table.2, the results of tiered-Imagenet are missing.). This makes the reader wondering whether the results of tiered-Imagenet do not \"look perfect\" and something is hidden behind. If possible, please add these kinds of missing resutls.\n4. Minor issues: (1) The paper uses the format of ICLR 2021, instead of following the recent ICLR'2023 format. (2) The citations in the paper look strange, please fix them.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper reads smooth and the effectiveness of the method is \"almost\" well validated. ",
            "summary_of_the_review": "Although this paper has some minor weakness, considering its clear motivation, simplicity of the method, and good experimental results, the reviewer thinks the paper is above the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_rDwz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_rDwz"
        ]
    },
    {
        "id": "ZGvVTNDFF9",
        "original": null,
        "number": 2,
        "cdate": 1666618553197,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618553197,
        "tmdate": 1666618553197,
        "tddate": null,
        "forum": "tXc-riXhmx",
        "replyto": "tXc-riXhmx",
        "invitation": "ICLR.cc/2023/Conference/Paper4145/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper discussed the distorted/biased features problem between base set and novel set in few-shot learning task, and proposed a Linear-Probing-Finetuning method with Firth-Bias to extract the undistorted features for shot-few learning. It also introduced an inverse Firth Bias Reduction (i-FBR) method for training the model in the few-shot learning setting. The learning procedures in the whole approach are as follows:\n\n1)\tpre-train backbone model B0(\u00b7, \u03b8) on the base set with a regular loss function.\n\n2)\ta randomly initialized linear classifier v(\u00b7, \u03b2) is retrained on the novel samples and regularized with FBR.\n\n3)\tthe pre-trained B0(\u00b7, \u03b8) and v0(\u00b7, \u03b2) are together finetuned on the same novel samples and regularized with i-FBR.\n\nExperiments in this paper are conducted on mini-Imagenet, tiered-Imagenet, and CUB datasets with ResNet-18, ResNet-34, and WideResNet28-10 backbones.\n",
            "strength_and_weaknesses": "Strengths:\n\n    - It\u2019s interesting to explore a better finetuning strategy for the few-shot learning problem.\n\n    - The proposed method is clear to understand and easy to follow.\n\n    - The method seems reasonable to obtain performance gain and the analysis and explanation are sufficient.\n\n    - The improvement over other methods is satisfied.\n\nWeaknesses:\n\n    - Writing of this paper can be improved. Some sentences are colloquial and not scientific, for example: in the abstract, \u201cwe conducted a lot of experiments on the commonly \u2026\u201d. In related work \u201c\u2026 and Knowledge Distillation Hinton et al. (2015) can make the feature extractor\u201d is incomplete.\n\n    - In Table 4, the authors provided the results using DC together with the proposed method, I wonder how about the results without DC. It's better to also provide this to demonstrate the effectiveness of the proposed method.\n\n    - There is no ablation on each stage of the proposed learning procedure, for example:\n\n     (1) train the linear classifier v(\u00b7, \u03b2) on the novel samples without FBR; \n\n     (2) finetune B0(\u00b7, \u03b8) and v0(\u00b7, \u03b2) together on the same novel samples without the proposed i-FBR. (better to put in the main paper instead of appendix)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and novelty are somewhat satisfied. The quality of writing can be improved. The descriptions in the paper are clear for reproducibility.",
            "summary_of_the_review": "Overall, I think this is an interesting paper to explore the finetuning strategy for few-shot learning. However, I feel the writing can be improved with a few minor mistakes in the current shape, also some ablations on each component are encouraged to be put in the main text. I currently give borderline with the positive side. I'm open to increasing the rating according to the authors\u2019 responses to my concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_Yd7H"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_Yd7H"
        ]
    },
    {
        "id": "slMKL5Z1cp",
        "original": null,
        "number": 3,
        "cdate": 1667249876688,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667249876688,
        "tmdate": 1667249876688,
        "tddate": null,
        "forum": "tXc-riXhmx",
        "replyto": "tXc-riXhmx",
        "invitation": "ICLR.cc/2023/Conference/Paper4145/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper points out a potential issue with the linear-probing framework many SoTA methods are based on. Freezing a pre-trained feature encoder could get away with the feature inconsistency problem when one fine-tunes the feature extractor on the limited novel samples. However, the effectiveness of the frozen feature is built upon the assumption that the pre-trained feature extractor is robust enough for the novel samples, which nonetheless is usually not the case for out-of-distribution samples. The authors thus propose a method that effectively fine-tunes the features given limited samples from the novel classes. Specifically, on top of Firth bias reduction, they proposed an inverse FBR that decreases the influence of the novel classes when the extractor is fine-tuned.",
            "strength_and_weaknesses": "Strengths\n1. Provided an intuitive explanation alongside the mathematical proofs as to why the proposed inverse FBR works.\n2. The authors compared the proposed method with many SoTA methods and showed consistent improvements over them.\n3. One experiment demonstrated in Table 4 shows the method is complementary to one of the SoTA papers, Distribution Calibration.\n\nWeaknesses \n1. While the overall explanation seemed well-motivated, I had a question regarding the existence of samples that lie in the subspace orthogonal to the one spanned by the base samples. My concern is the following. If the feature extractor is pre-trained on the base classes, wouldn't the feature extractor tend to \"put\" whatever samples it sees in the subspace spanned by the pre-trained samples? I would appreciate more explanations from the authors pertaining to this argument.\n2. What do the authors mean that in-distribution and out-of-distribution features inconsistently change? It's also not crystal clear to my mind although the authors do provide an explanation with a linear model.\n3. The authors keep using \"equivariance\" in the article. However, for their scenario, e.g., using a feature trained on ImageNet on CUB200, it's not accurate (not sure if \"invariance\" would be a better choice). I would suggest the authors define what they mean by \"equivariant\" more clearly as what I would think of equivariance is when someone performs an operation on the image, the feature would change accordingly.",
            "clarity,_quality,_novelty_and_reproducibility": "Despite the aforementioned unclearness, overall the paper is easy to follow.\n\nPlease correct me if I am wrong about this. While the authors pointing out the issue of using FBR when fine-tuning the entire feature extractor is interesting, essentially, what the authors do was flip the coefficient of FBR from positive to negative, thereby decreasing the overfitting issue. For this, I would consider the paper somewhat novel but not entirely.\n\nIt seems the authors did not provide a link to their code for reproducibility.",
            "summary_of_the_review": "Overall, this paper points out the issue of prevalent SoTA papers on few-shot learning and offers a solution, which the authors showed effective in the experiments compared with other SoTA methods. Despite the effectiveness of the proposed method, the method is slightly limited in terms of novelty as it is built upon the previous FBR paper. Summarizing all these perspectives, I would recommend a weak accept for now.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_C9jy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_C9jy"
        ]
    },
    {
        "id": "557k6algmY",
        "original": null,
        "number": 4,
        "cdate": 1667307436838,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667307436838,
        "tmdate": 1670672096673,
        "tddate": null,
        "forum": "tXc-riXhmx",
        "replyto": "tXc-riXhmx",
        "invitation": "ICLR.cc/2023/Conference/Paper4145/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to use the \"linear probing then fine-tuning\" strategy (LP-FT) introduced in [1], as well as the firth bias reduction (FBR) introduced in [2], to learn the adaptation to novel-classes step in few-shot learning. The proposed method is evaluated on a variety of FSL tasks and demonstrate good results in the fine-tuning for FSL methods.",
            "strength_and_weaknesses": "\nStrength:\n\n1) This is the first time linear probing then fine-tuning is used for few-shot learning\n\n2) The proposed method achieves state-of-the-art results among the fine-tuning methods (as opposed to meta-learning methods) on several few-shot learning benchmarks.\n\n\nWeaknesses:\n\n1) The results are outdated in comparison to the recent state-of-the-art in few-shot learning (For exemple: [3, 4, 5]). Only comparing with fine-tuning methods and not with all meta-learning baselines is unfair. Maybe an idea would be to use more recent pre-trained backbone, for exemple, how would it perform using similar backbones as in [6] ? Is there a reason to only use a pre-trained backbone from [7] ?\n\n2) Other than inverting FBR, which is just using a negative coefficient for FBR, there is no conceptual novelty introduced in the paper. The linear probing then fine-tuning pipeline is introduced in [1] and FBR is introduced in [2].\n\n3) A more in-depth ablation than what is provided in Appendix D is really necessary to understand the contribution of each component of the method. In particular, how does LP-FT performs without FRB in few-shot learning ?\n\n4) The benchmarks used are standard, but very simple, both mini-imagenet and tired-imagenet use 5-way classification novel tasks, which is not challenging. It would be great to consider a much harder benchmark such as ImageNet-1k which has 311-way novel tasks. (See Table of [8], and Table 1.c) of [9]).\n\n\nQuestions and remarks:\n\n1) How hard is it to tune $\\lambda$ both in the linear probing step and in the fine-tuning step ? How do you do it in practice ? More generally, to add on the critic about the lack of ablation, it would be great to provide a full ablation on lambda on all configuration possible, i.e. $\\lambda$ positive, negative and equal to 0, which correspond to FBR, i-FBR on no FBR, for both linear probing and fine-tuning steps (9 configurations in total).\n\n2) Have you tried different probe than the linear probe ? For exemple non-parametric such as k-NN or 2-layer MLP ?\n\n3) Would it be possible to use some kind of regularization on the weights of the linear probe, instead of FBR ? l2/l1-regularization, sparsity, ect.. ?\n\nReferences\n\n[1] A. Kumar et al., Fine-tuning can distort pretrained features and underperform out-of-distribution, ICLR 2022\n\n[2] S. Ghaffari et al., On the importance of firth bias reduction in few-shot classification, ICLR 2022\n\n[3] P. Rodriguez et al., Embedding Propagation: Smoother Manifold for Few-Shot Classification, ECCV 2020\n\n[4] I. M. Ziko et al., Laplacian Regularized Few-Shot Learning, ICML 2020\n\n[5] X. Chen et al., Few-Shot Learning by Integrating Spatial and Frequency Representation, CRV 2021\n\n[6] S. Xu Hu et al., Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference, CVPR 2022\n\n[7] P. Mangla et al., Charting the right manifold: Manifold mixup for few-shot learning, CACV 2020\n\n[8] Y-X. Wang et al., Low-Shot Learning from Imaginary Data, CVPR 2018\n\n[9] L. Gui et al., Learning to Hallucinate Examples from Extrinsic and Intrinsic Supervision, ICCV 2021\n",
            "clarity,_quality,_novelty_and_reproducibility": "1) The latex template is from ICLR 2021, please use the ICLR 2023 template. FYI: the paper is currently 8-pages long, the limit is fixed to 9 pages this year.\n\n2) The writing and presentation are ok but could be improved.\n\n3) The citation template is a bit hard to read, please use a distinctive color, or () or [] around citations.\n\n4) The derivations of Section 2.4 feel unnecessary. Only the formulation of the loss is important, the rest could be derived for the loss. My suggestion would be to put that section into the Appendix in order to make space and move the ablation of Appendix D, which is more interesting, to the main text.\n\n5) After Eq. 8, the symbol $\\lambda_{inv}$ is not defined in Eq. 8.\n\n6) It would be great to include the code with the submission for reproducibility purposes.\n",
            "summary_of_the_review": "Combining LP-FT and FBR for few-shot learning is promising but the current results are far from competitive with recent approaches for few-shot learning. The paper does not introduce a new concept and therefore should at least demonstrate strong results. For these reasons I recommend a reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_nALG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_nALG"
        ]
    },
    {
        "id": "5qF3N6JTh9",
        "original": null,
        "number": 5,
        "cdate": 1667451183242,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667451183242,
        "tmdate": 1670316328007,
        "tddate": null,
        "forum": "tXc-riXhmx",
        "replyto": "tXc-riXhmx",
        "invitation": "ICLR.cc/2023/Conference/Paper4145/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to adapt LP-FT to Few shot learning and designs LP-FT-FB learning framework, in which inverse-FBR is proposed to regularize the feature extractor.  The experiments are extensive, but no theoretical proof is provided for the proposed i-FBR.\n\n",
            "strength_and_weaknesses": "1. The experiments, including those in the supplementary file, are extensive and show the effectiveness of the designed method.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. The paper claims that  the proposed i-FBR can address the biased estimation problem of \ufb01netuning the feature \nextractor in few shot learning. However, there is only experimental validation but no theoretical proof, which is not sufficiently convincing.\n2. In my perspective, the FBR is a principled method to obtain an unbiased estimation by encouraging a sharp distribution. However, the proposed i-FBR seems like an inverse process that attempts to smooth the distribution for unbiased estimation.  In this sense, are other regularization strategies that smooth the distribution also feasible? \n3. The paper writing needs to proved, there are several grammar mistakes. \n\n",
            "summary_of_the_review": "Without theoretical proof for i-FBR, I think the proposed method is not convincing and the novelty is limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_Qxg7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4145/Reviewer_Qxg7"
        ]
    }
]