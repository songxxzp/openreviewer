[
    {
        "id": "1DxISdhCmD",
        "original": null,
        "number": 1,
        "cdate": 1666549375469,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549375469,
        "tmdate": 1666549375469,
        "tddate": null,
        "forum": "99XwOpGYAH",
        "replyto": "99XwOpGYAH",
        "invitation": "ICLR.cc/2023/Conference/Paper3082/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper tackles the problem of representation learning with GANs. To do so, it introduces a novel adversarial objective that is composed of a distribution-matching objective and a clustering objective. In addition, they propose a novel regularization algorithm to ensure the smoothness of the discriminator. Compared to the widespread spectral normalization, the proposed regularization does not control the spectral norm at each layer individually, allowing the discriminator to retain more capacity. The method is evaluated against contrastive state-of-the-art, on CIFAR-10, CIFAR-100, and ImageNet-10.",
            "strength_and_weaknesses": "Strengths:\n- Representation learning is a timely topic. Tackling it with generative models has been a promising approach but their usefulness had yet to be proven compared to their contrastive counterparts. The current submission is a big step in that direction.\n- The approach is original in significant ways. It focuses on the discriminator, which is not usually exploited in GAN literature, and manages to use it as a feature learner.\n- It also proposes a new GAN loss and a new GAN regularization scheme, which both seem useful for training GANs.\n\nWeaknesses:\n- The presentation of the technical parts could be made clearer:\n  - In section 3.2, it seems that $f$ represents alternatively the individual outputs of $D$ as well as their distribution. It could be useful to clarify the notation. It can be especially confusing since the original adversarial objective, i.e. the binary classification objective between fake and real samples, can sometimes be presented as a JSD minimization of the distributions.\n  - It could be useful to remind the reader of how VJP and JVP can be computed in the supplementary. I for one would welcome it.\n  - Table 2 contains important information as it serves as an ablation study regarding the capacity of GAN discriminators to learn features. I don't think this aspect is discussed anywhere in the paper. Also, it isn't mentioned how the representations for the baselines in Table 2 have been extracted.\n  - Have the contrastive baselines been trained on the datasets they are being evaluated on, like the GAN would be? Or have they been trained on ImageNet and evaluated only on those datasets, as is often the case in contrastive benchmarks? This information is important to put the results in context and should be made explicit.\n- The paper should compare to other generative representation learning methods such as those they cite in their related work, or a more recent one [1].\n- The authors might also want to discuss how their objectives relate to and differ from Feature Matching [2]. Here are some more recent examples of where it has been used [3,4].\n- The BigGAN backbone is quite generic and useful, but somewhat outdated, especially for unconditional generation. Have the authors considered StyleGAN-2 [5] or FastGAN [6] backbones? Can the author discuss the potential issues of switching to such backbones?\n\n---\n\n[1] Ali Jahanian, Xavier Puig, Yonglong Tian, Phillip Isola. Generative Models as a Data Source for Multiview Representation Learning. ICLR 2022.\n\n[2] Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen. Improved Techniques for Training GANs. NeurIPS 2016.\n\n[3] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, Bryan Catanzaro. High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs. CVPR 2018.\n\n[4] Liming Jiang, Changxu Zhang, Mingyang Huang, Chunxiao Liu, Jianping Shi, Chen Change Loy. TSIT: A Simple and Versatile Framework for Image-to-Image Translation. ECCV 2020.\n\n[5] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila. Analyzing and Improving the Image Quality of StyleGAN. CVPR 2020.\n\n[6] Bingchen Liu, Yizhe Zhu, Kunpeng Song, Ahmed Elgammal. Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis. ICLR 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is novel in multiple ways, the delivery is quite clear but it leaves out information hurting both understanding and reproducibility.\n",
            "summary_of_the_review": "The work has relevant contributions for both GANs in general as well as their application to representation learning.\nIt tackles the problem in a novel and interesting way.\nHowever, too many details are missing, as well as comparisons, and some related work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_GyrJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_GyrJ"
        ]
    },
    {
        "id": "RZ8nUqPu_5",
        "original": null,
        "number": 2,
        "cdate": 1666640095553,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666640095553,
        "tmdate": 1666640318695,
        "tddate": null,
        "forum": "99XwOpGYAH",
        "replyto": "99XwOpGYAH",
        "invitation": "ICLR.cc/2023/Conference/Paper3082/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes to use the discriminator in a GAN as a feature extractor for self-supervised representation learning. Assuming that both real and fake features from the discriminator follow a gaussian distribution, the authors propose a loss based on the distance between the real and fake gaussian distributions. They also propose performing clustering on the extracted features and use this as an extra loss term for the discriminator optimization. Their proposed method outperforms SOTA self-supervised learning approaches on small-scale datasets and using the K-means metric.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well-written and easy to follow.\n2. The paper is well-motivated, and it is technically and theoretically sound.\n3. The proposed model outperforms BigGAN in terms of image generation quality.\n4. The idea of self-supervised feature representation learning using a discriminator is interesting and novel to the best of my knowledge.\n\nWeaknesses:\n1. There are some grammatical errors in the text, and some sentences are too long to follow. E.g.: Page 1, Yet, to improve...\n2. There is no discussion on different discriminator architectures, such as the patchGAN discriminator or feature extractors as discriminators [1,2]. Also, a more detailed comparison against ICGAN can improve the paper.\n\n[1] Sungatullina, Diana, et al. \"Image manipulation with perceptual discriminators.\" ECCV 2018.\n\n[2] Mao, Xin, et al. \"Is discriminator a good feature extractor?.\" arXiv 2019.\n\n3. The evaluation setting is not common in self-supervised approaches. Usually, linear classification and kNN classifiers are used. In this paper, they use SVM and Kmeans.\n\n4. The computational complexities of the networks in Tab. 1 are not compared.\n\n5. The proposed model only outperforms previous work on one metric.\n\nMinor: \nThe references for related work in Tab. 1 could be added.",
            "clarity,_quality,_novelty_and_reproducibility": "1. The paper is clear, well-written, and easy to understand.\n2. The idea of using a discriminator for self-supervised representation learning is novel to the best of my knowledge.\n3. The architecture and experimental setup are clear and reproducible. The losses may be a bit tricky to re-implement, but they are well explained mathematically.",
            "summary_of_the_review": "The paper has both strengths and weaknesses. I have some concerns regarding the evaluation setting and discussion on existing literature.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_9r54"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_9r54"
        ]
    },
    {
        "id": "_OW2j0ohJIY",
        "original": null,
        "number": 3,
        "cdate": 1666704424381,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666704424381,
        "tmdate": 1666704424381,
        "tddate": null,
        "forum": "99XwOpGYAH",
        "replyto": "99XwOpGYAH",
        "invitation": "ICLR.cc/2023/Conference/Paper3082/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a GAN variant with structural adversarial objectives for self-supervised (SS) representation learning, which aims to achieve a general SS representation learning, especially escaping dependence upon the hand-crafted elements guiding data augmentation or proxy task design. In particular, at a coarse scale, a JSD divergence between the discriminator features of real samples and generated samples is defined as an adversarial objective for GAN.  At a finer scale, an adversarial clustering objective is defined, which groups adjacent real embeddings (features extracted by the discriminator) to form a cluster and adversarially attracts the generated embedding towards the nearby cluster center. Furthermore, an efficient regularization scheme that approximates the spectral norm of the Jacobian is introduced to regularize the discriminator\u2019s smoothness. Experiments demonstrate their proposed GAN achieves results that compete with networks trained by state-of-the-art contrastive approaches.",
            "strength_and_weaknesses": "The proposed structural adversarial objectives are interesting and seem novel. The performance of the proposed GAN especially on K-mean clustering is promising. However, I have the following concerns:\n1. Actually, this is a kind of work that utilizes a generative model together with clustering for SS representation learning. Therefore, deep generative clustering, a.k.a., generative model (GAN/VAE) with clustering, e.g., [1,2,3,4], is closely related to this work, which is missed in the Related Work part of this paper.\n2. I think the proposed work can be better positioned in the literature if the motivation is to target deep generative clustering instead of SS representation learning. I would expect a detailed analysis about the superior performance of the proposed generative clustering to the existing generative clustering works.\n3. [1] also uses discriminator features for clustering. From this aspect, the idea claimed in this work that tasks the discriminator with additional structural modeling is not novel.  \n4. The experimental study is not totally consistent with the original motivation. First, augmentation is adopted though simple. Second, the experiments can be more convincing if conducted on different modalities of data, like text. It can verify the generality of the proposed method and also demonstrate the data augmentation should be specified in terms of data domains.\n5. Gaussian assumption encouraging smoothness and diversified representation is not well justified.\n \n\nSome questions:\n1. Why spectral normalization used in Miyato et al. 2018 will harm model capacity but the spectral normalization used in this work will not?\n2. How to decide which layers of D as clustering features?\n3. What is the size of the maintained memory bank $f_m$?\n4. For coarse-scale optimization with Gaussian, is it using mini-batches to determine the covariance and mean? If so, is it problematic since Eq. (4)/(5) is supposed to be defined on the whole data?\n5. Why \u201cregularizing JD(x) on l2 normalized embedding f will enlarge the norm of f\u02dc throughout training and eventually destabilizes the system; while regularizing JD(x) on f\u02dcoperates oppositely\u201d?\n\n\nErrors\n1. In Section 2.2, \u201cand demonstrates their sensitivity to the parameters of augmentation schemes.\u201d-\u2192demonstrate\n2. In Eq. (2), JSD should equal to $1/2*D_{KL}$\u2026\n3. In $L_{advgroup}$, $f_i^g$ is supposed to be $f_i$?\n4. $\\\\{f_{i,j}\\\\}_{j=1}^{k}$, $k$ is supposed to be $K$.\n5. In Alg 1, $s$ should be $S$.\n6. Fig. 2, (4) should be (d).\n\nReferences\n\n[1] Liu, S., Wang, T., Bau, D., Zhu, J. Y., & Torralba, A. (2020). Diverse image generation via self-conditioned gans. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 14286-14295).\n\n[2] Noroozi, M. (2020). Self-labeled conditional gans. arXiv preprint arXiv:2012.02162.\n\n[3] Guo, X., Gao, L., Liu, X., & Yin, J. (2017, August). Improved deep embedded clustering with local structure preservation. In Ijcai (pp. 1753-1759).\n\n[4] Jiang, Z., Zheng, Y., Tan, H., Tang, B., & Zhou, H. (2017, January). Variational Deep Embedding: An Unsupervised and Generative Approach to Clustering. In IJCAI.\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. The idea that tasks the discriminator with additional structural modeling is not novel.\n2. The proposed structural adversarial objectives are interesting and seem novel.\n3. Some claims are not clarified clearly.\n4. The setting of some hyperparameters is not clear.\n5. There exist formula/grammar errors.",
            "summary_of_the_review": "The proposed structural adversarial objectives are interesting and seem novel. The performance of the proposed GAN especially on K-mean clustering is promising. However, the authors do not well position their work and miss the comparison with closely related works. Thus, the contributions of this work cannot be clearly demonstrated. In addition, the empirical support is not consistent with the original motivation. Last, the clarity of this work needs improvement.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_XWaT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3082/Reviewer_XWaT"
        ]
    }
]