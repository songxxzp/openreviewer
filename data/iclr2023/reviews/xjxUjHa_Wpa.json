[
    {
        "id": "GtIanipV_J5",
        "original": null,
        "number": 1,
        "cdate": 1666313538027,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666313538027,
        "tmdate": 1666313538027,
        "tddate": null,
        "forum": "xjxUjHa_Wpa",
        "replyto": "xjxUjHa_Wpa",
        "invitation": "ICLR.cc/2023/Conference/Paper2470/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes the single image depth estimation method with variational constraints via first-order difference. This paper proposes V-layer which computes the depth difference map and the weight map, which will be utilized to obtain the initial depth map. The initial depth map will be upsampled and refined through the upsampling and refinement module. Finally, the metric scale depth is computed by the metric layer.",
            "strength_and_weaknesses": "1. Strength\n- The proposed method outperforms very recent state-of-the-art methods in various datasets. It also achieves 2nd place in the KITTI depth benchmark.\n- The dense ablation study shows the effectiveness of the V-layer and the refinement step.\n\n2. Weakness\n- It is not clearly described why the variational constraints via first-order difference are helpful for accurate depth estimation. The introduction section is more likely to be a related work section, which should describe why the proposed method (variational constraints) is required to improve the quality of the depth map. \n- Figure 5 shows the evaluation of different backbones. Both Swin-S (w/o) and ConvNeXt-S (w/o) achieve 9.5, but the graph shows the error of ConvNext-S is higher than Swin-S.\n- In table 1,2, it would be good to report the number of parameters or the backbone network (ResNet, Swin-S, Swin-L, etc) because the accuracy of the depth map highly depends on the backbone network. The number of parameters is reported in table 8, but the numbers are slightly different from the numbers in Table 1. \n- This paper argues that the proposed method generalizes well to unseen datasets. And, the evaluations of the NYU-trained model on the SUN3D datasets are provided. The scene properties of NYU and SUN3D datasets are similar, so the evaluations on more challenging variations should be provided such as the KITTI-trained model tested on NYU, etc.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper provides the details of the network structure and the training details, so the reproducibility is high. The technical contribution is somewhat new as the variational constraint is not widely utilized in the single image depth estimation. But the design intuition is not strongly convincing.",
            "summary_of_the_review": "Overall, the proposed method achieves better performance than the conventional method. The dense ablation study demonstrates the effectiveness of the proposed method. However, for me, it is hard to get the design intuition of the proposed method, especially why the variational constraints via first-order difference bring performance improvement. I hope this part is clearly described in the rebuttal.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_PKfN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_PKfN"
        ]
    },
    {
        "id": "5AYz6u1qYK",
        "original": null,
        "number": 2,
        "cdate": 1666646225246,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646225246,
        "tmdate": 1670767675039,
        "tddate": null,
        "forum": "xjxUjHa_Wpa",
        "replyto": "xjxUjHa_Wpa",
        "invitation": "ICLR.cc/2023/Conference/Paper2470/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors propose an algorithm for single-image depth prediction. The key contribution of the algorithm is the V-layer, which utilizes the depth gradient to make a more accurate depth prediction. It takes the gradients in the two-axis directions and their reliability as input and obtains the depth in a linear algebraic way. The resulting low-resolution depth becomes the final depth after several upsamples and refinements. Experimental results show that the proposed method shows SOTA performance and that V-layer contributes to the performance improvement.",
            "strength_and_weaknesses": "This article is well-written and easy to understand. The algorithm's approach is interesting and plausible. Given that only a single image is given, the prediction of depth is a very ambiguous process, so it makes sense to use more solid clues (depth gradients in this paper). The process of restoring depth by building an overdetermined system is novel.\n\nDespite the above advantages, the novelty of this paper should be re-examined. In the last paragraph of page 2 of the paper, the authors claimed that the proposed algorithm is the first attempt to predict the first-order difference of the scene. However, a prior work (1) also predicts the first-order difference and uses them to reconstruct depth, similar to this paper's motivation. Also, (2) exploits more diverse depth derivatives for depth prediction. Related work and contributions should be revised.\n\n(1) Monocular depth estimation using relative depth maps, CVPR 2019\n\n(2) Multi-Loss Rebalancing Algorithm for Monocular Depth Estimation, ECCV 2020\n\n\nMany depth capture devices (e.g., Lidar) can only capture depth of sparse points. On the other hand, gradient is a clue that can be used if we know the depths of all adjacent points. I think this aspect can limit the usefulness of the algorithm. Do the authors have a way around these problems?\n\nThe V-layer seems to work at a much smaller resolution (probably 1/16 or 1/32) instead of the original size resolution. However, this method results in depth prediction using gradients between regions farther away instead of two adjacent pixels. This may be a disadvantage for predicting high-frequency detail. Do the authors have any insight or empirical results regarding the resolution of the v-layer?\n\nA more detailed description of the proposed network structure is needed for reproducibility. It would be nice if detailed layer composition was provided (even in appendix format).\n\n---\nAfter reading the reviews of other PCs and answers from authors,\n\nI raise my primary score to 6.\nThe authors' answers alleviated most of my concerns.\nNotably, Q3 and A3 will interest many researchers in this field. Including it in the paper or appendix would be nice.\nThanks to the authors for their hard work.\n\n---",
            "clarity,_quality,_novelty_and_reproducibility": "This paper has good clarity and quality. Novelty and reproducibility need improvement.",
            "summary_of_the_review": "Overall, I think this paper very interesting. This paper is technically valid and has novel parts, but the parts I mentioned in the shortcomings should be revise. I think this paper is on the borderline.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_K2Ky"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_K2Ky"
        ]
    },
    {
        "id": "P7AF0pLN3m",
        "original": null,
        "number": 3,
        "cdate": 1666927776661,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666927776661,
        "tmdate": 1666927776661,
        "tddate": null,
        "forum": "xjxUjHa_Wpa",
        "replyto": "xjxUjHa_Wpa",
        "invitation": "ICLR.cc/2023/Conference/Paper2470/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes VA-DepthNet to solve single image depth prediction problem by exploiting classical first-order variational constraints. The proposed network disentangles the absolute scale from the metric depth and models unscaled depth map as the optimal solution to the pixel-level depth gradiant. The network focuses on the first order differences of the scene rather than pixel-wise metric depth learning. It improves the performance of depth learning in a large margin.",
            "strength_and_weaknesses": "This work lays a solid contribution towards the field of single image depth prediction by introducing variational first-order constraints, showing state-of-the-art performance on mainstream public datasets. The idea is novel and introducing variational priors can be useful to a number of areas, e.g. depth prediction, scene reconstruction.",
            "clarity,_quality,_novelty_and_reproducibility": "It would be better to have a table to list the detailed framework structure and parameters in the appendix.",
            "summary_of_the_review": "This work lays a solid contribution towards the field of single image depth prediction.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_qKm4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_qKm4"
        ]
    },
    {
        "id": "FFpGtlSduA9",
        "original": null,
        "number": 4,
        "cdate": 1667020878647,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667020878647,
        "tmdate": 1668773351780,
        "tddate": null,
        "forum": "xjxUjHa_Wpa",
        "replyto": "xjxUjHa_Wpa",
        "invitation": "ICLR.cc/2023/Conference/Paper2470/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new network for single view depth estimation. The core technical part is a V-layer that predicts depth gradients and feature weights and solves a refined depth map. Finally, the refined depth is further refined (by black-box operators) to a larger resolution and re-scaled/shifted to the final prediction. Experimental results on NYUd2, KITTI (official and eigen splits) and SUNRGBD set a clear new state-of-the-art. Codes are promised.",
            "strength_and_weaknesses": "Strengths:\n+ Well-written and well-organized.\n+ Clear new state-of-the-art results on an important problem.\n\nWeaknesses:\n- My first major criticism is that the method should be compared with other methods that implements the same idea. In Table.5, we can see that the V-layer out-performs convolution and self-attention. This is not enough. The method should be compared with [A][B][C] and demonstrate why V-layer works and the former formulations do not.\n[A] Predicting sharp and accurate occlusion boundaries in monocular depth estimation using displacement fields, CVPR 2020\n[B] Depth estimation via affinity learned with convolutional spatial propagation network, ECCV 2018\n[C] A Two-Streamed Network for Estimating Fine-Scaled Depth Maps From Single RGB Images, ICCV 2017\n- The motivation and impact of the Conv layer in Equation.8 is not clear. Although I understand that in end-to-end deep models we can always some learnable layers that mysteriously improves performance, this one needs a clearer justification because it belongs to the core technical module.\n- Minor: Claiming MIDAS uses external is unfair as it is evaluated in a zero-shot setting. This can be misleading for future papers.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is good except for equation. I don't have comments on quality, as it's good. Novelty issues are noted in the last box about [A/B/C]. Reproducibility seems good as a code release is promised.",
            "summary_of_the_review": "Generally, I think the paper should be accepted but still has issues (see weaknesses) to be addressed. I am now voting a 6 but I can vote a 8 if convinced.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_3Fva"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2470/Reviewer_3Fva"
        ]
    }
]