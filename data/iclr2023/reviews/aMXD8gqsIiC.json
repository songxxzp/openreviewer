[
    {
        "id": "Ce9W2Zcrx2O",
        "original": null,
        "number": 1,
        "cdate": 1666280020689,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666280020689,
        "tmdate": 1668819930523,
        "tddate": null,
        "forum": "aMXD8gqsIiC",
        "replyto": "aMXD8gqsIiC",
        "invitation": "ICLR.cc/2023/Conference/Paper4467/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper considers approximating the 1-Wasserstein distance between two discrete distributions up to an additive error. Suppose that $\\mu$ and $\\nu$ are two discrete distributions contained within the unit hypercube. Both are supported on n points and both have a $\\operatorname{poly}(n)$ spread. The paper shows a randomised algorithm approximating the 1-Wasserstein distance $W_1(\\mu,\\nu)$ up to an expected additive error of $\\min\\\\{\\epsilon, (d\\log_{\\sqrt{d}/\\epsilon} n)W_1(\\mu,\\nu) \\\\}$ in $O(T(n,\\epsilon/d)\\log_{\\sqrt{d}/\\epsilon} n)$ time, where $T(n,\\epsilon)$ is the time taken by an $\\epsilon$-additive approximation algorithm. Based on this core result, the paper also obtains relative-error algorithms for the Euclidean bipartite matching problem. ",
            "strength_and_weaknesses": "Strengths: Improves the (expected) additive error when the Wasserstein distance is smaller than $\\epsilon/(d\\log_{\\sqrt{d}/\\epsilon} n)$.\n\n~~Weaknesses: The main weakness to me is that the guarantee is in the expected additive error, not a worst-case error guarantee. (The abstract should also state that it\u2019s the \u201cexpected\u201d additive error clearly.)~~\n\n[Update] The authors have clarified that repeating $O(\\log(1/\\delta))$ times gives a worst-error guarantee of the same magnitude with probability at least $1-\\delta$.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written on its own. However, it does not present the existing techniques very clearly. As the paper states that it combines the existing techniques from the additive error algorithms and the relative error algorithms, it is not very clear to people who have not worked directly on the problem what the new innovation is and what the difficulty is to combine the techniques. It is thus difficult to assess the merits of the paper for someone who has not worked directly on the problem.\n\n[Given the short review period, I have not been able to check the proofs carefully or read the proofs in the appendix.]\n\nMinor points:\n- Line 5 of abstract: add a comma after \u201cdominates\u201d\n- Line 8: additive factor -> additive error (it\u2019s additive and thus cannot be a factor)\n- Section 1, paragraph 2, line 4: poly{...} -> poly(...). The same typo appears multiple times throughout the paper.\n- Section 1, paragraph 2, line 5: there is no limiting process here, why \u201cconverge\u201d?\n- Section 1.1, paragraph 1, last line: change the semicolon to a comma\n- Page 4, line -18: it is better to write $d = O(log_{1/\\epsilon} n)$\n- Page 4, line -7: \u201cSince the spread\u2026\u201d This has never appeared before this point, it\u2019s better to say that the algorithm guarantees the spread is \u2026\n- Page 4, line -7: the spread is $O(d/\\epsilon)$, not exactly $d/\\epsilon$, right? The same typo appears multiple times in the paper.\n- Page 7, paragraph starting with \u201cIn the next section\u201d: In the next section -> below (it\u2019s still in the same section)\n- Page 7, paragraph starting with \u201cQuality of Approximation\u201d: please fix \u201cin this section\u201d\n- Page 8, paragraph starting with \u201cHierarchical Partitioning\u201d, line 7: the footnote mark 4 is confusing, as it can be interpreted as the fourth power.\n- Page 9, paragraph starting with \u201cDatasets\u201d, line 1: real data -> real-world data\n- Page 9, paragraph starting with \u201cDatasets\u201d, line 7: add a comma before \u201cwhich\u201d\n- Page 9, Figure 2: Colours are hard to distinguish when printed black & white. It\u2019s better to use different line markers. \n",
            "summary_of_the_review": "This is a solid paper on its own. ~~but it is difficult to evaluate the novelty in the techniques as the paper is not clear on this aspect. The guarantee on expected additive error is not enticing, either.~~\n\n[Update] The techniques are mostly based on the existing ones but it is nontrivial to combine them with small twists in various places. I would recommend acceptance though it looks more like an ESA paper instead of an ICLR paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_4W22"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_4W22"
        ]
    },
    {
        "id": "3WjEc4XuXf",
        "original": null,
        "number": 2,
        "cdate": 1666955794981,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666955794981,
        "tmdate": 1666955794981,
        "tddate": null,
        "forum": "aMXD8gqsIiC",
        "replyto": "aMXD8gqsIiC",
        "invitation": "ICLR.cc/2023/Conference/Paper4467/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors consider the problem of computing the 1-Wasserstein distance (Earth Mover\u2019s distance) between two d-dimensional discrete distributions $\\nu$ and $\\mu$. In this problem the mass distributed over a set of supply nodes according to distribution $\\nu$, needs to be transported and distributed to the demand nodes in $\\mu$. The amount of mass supplied or demanded by each node is given and the per unit transportation cost between a pair of nodes is proportional to the $\\ell_2$ (Euclidean) distance between the nodes. The goal is to compute the minimum cost required to transport the mass from the supply nodes to demand nodes. A special case of this problem where all nodes have the same amount of demanded or supplied mass, is also considered. This problem is called Euclidean Bipartite Matching (EBM), since in the optimal solution a demand node will be connected to a single supply node and vice versa. While prior work on this problem had provided both additive and relative approximation guarantees, the contribution of this paper is an algorithm that combines the two types of guarantees. Specifically, for the Earth Mover\u2019s distance problem, the error is the minimum between $\\varepsilon$ and $(d\\log_{\\sqrt{d}/\\varepsilon}n) \\mathcal{W}(\\mu,\\nu)$, where $\\mathcal{W}(\\mu,\\nu)$ is the optimal cost. The second term provides an improved relative approximation compared to $d\\log n$ achieved in prior work, while the additive error is bounded by $\\varepsilon$ at the same time. \n\nSimilarly to prior work, the algorithm uses a randomly shifted hierarchical partitioning of the space recursively subdividing cells with multiple points in them. The algorithm first tries to satisfy the demands using the supply from the same cell of the partitioning and this is also done in a recursive manner, therefore starting from the lower levels of the hierarchical tree and moving up. When a particular cell has more supply than demand (or vice versa), the remainder is moved to its center to be handled by a higher level cell. This paper differentiates from prior work on relative approximation algorithms by using exact solvers for each cell, whereas faster approximate solvers are used in this paper leading to smaller cell size and better approximation guarantees. For the problem of Euclidean Bipartite Matching (EBM), the authors exploit the fact that cells in the hierarchical tree are more likely to be balanced (in terms of internal supply and demand) and they are able to improve the relative approximation to $d\\log log n$, while maintaining the additive approximation. \n",
            "strength_and_weaknesses": "Strengths:\n- This paper makes an improvement on an important problem and at the same time gives both an additive and relative approximation guarantee, which could make the algorithm even more widely applicable. \n- The paper is quite well-written and easy to follow. \n\nWeaknesses:\n- Many of the core ideas used are taken from prior work. However, the paper does seem to have technical depth on its own.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The ideas are presented very clearly, and the paper is well-written. Previously known techniques are extended in a novel way. Experiments are performed on synthetic datasets and should be reproducible. ",
            "summary_of_the_review": "I believe this paper makes a solid contribution by providing improved additive and relative approximation guarantees with a single algorithm for a well-known problem. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_LSEt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_LSEt"
        ]
    },
    {
        "id": "5OMVRPjmR0",
        "original": null,
        "number": 3,
        "cdate": 1667160780305,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667160780305,
        "tmdate": 1667160780305,
        "tddate": null,
        "forum": "aMXD8gqsIiC",
        "replyto": "aMXD8gqsIiC",
        "invitation": "ICLR.cc/2023/Conference/Paper4467/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper gives a new algorithm for computing the Earth Mover's Distance between two discrete distributions in the hypercube. This is an extensively studied problem with several theoretical algorithms papers studying it. This present paper exploits some of their efficient-in-practice techniques in order to design a practical algorithm.",
            "strength_and_weaknesses": "+ The paper makes good progress on an important problem. \n+ The algorithms are interesting and novel. \n- The experimental results are not so impressive.",
            "clarity,_quality,_novelty_and_reproducibility": "The algorithms in the paper combine known techniques but the end result is novel enough. ",
            "summary_of_the_review": "I recommend accepting the paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_8UAQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4467/Reviewer_8UAQ"
        ]
    }
]