[
    {
        "id": "KovNVFkaiYv",
        "original": null,
        "number": 1,
        "cdate": 1666536569697,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666536569697,
        "tmdate": 1666536569697,
        "tddate": null,
        "forum": "GrpU6dxFmMN",
        "replyto": "GrpU6dxFmMN",
        "invitation": "ICLR.cc/2023/Conference/Paper4241/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a feature selection method based on markov blanket under missing data regime and apply missforest after feature selection. The main contribution is the feature selection algorithm.",
            "strength_and_weaknesses": "Strength:\n1. The authors propose a markov blanked based feature selection algorithm for missing data. The selected features are then used in MissForest. \n\nWeakness:\n1. The authors should include more recent works to claim that their method is SOTA. MissForest is kind of old (10 years old). More recent SOTA should be included. For example, \nMIRACLE (Kyono et al., 2021)\nSinkhorn (Muzellec et al., 2020)\nSoftImpute (Hastie et al., 2015)\nHyperImpute (Jarrettet al., 2022)\n2. MimMB is similar to MBMF. Empirical comparison should also be included.\n3. Unlike MimMB, the authors claim that improves computational efficiency. A comparison of execution time is more persuasive. If it's trivial, the authors can correct me without making this new result of computational efficiency. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear. Markov Blanket + MissForest is novel. ",
            "summary_of_the_review": "I think this paper is at the borderline. The authors do not compare to many new SOTA methods, which I believe have better results than MissForest. But it can be the reason that MissForest is not that good so MBMF is not as good as those SOTA methods. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_p56x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_p56x"
        ]
    },
    {
        "id": "6jD3IaAItmY",
        "original": null,
        "number": 2,
        "cdate": 1666646275860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646275860,
        "tmdate": 1666646275860,
        "tddate": null,
        "forum": "GrpU6dxFmMN",
        "replyto": "GrpU6dxFmMN",
        "invitation": "ICLR.cc/2023/Conference/Paper4241/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method for feature selection to be used prior to estimating an imputation model. The method is based on finding the Markov blanket for each partially observed variable. In synthetic and semi-synthetic experiments, the methods slightly outperforms an imputation model trained without feature selection with a lower total run time (feature selection + model estimation).",
            "strength_and_weaknesses": "See below.",
            "clarity,_quality,_novelty_and_reproducibility": "See below.",
            "summary_of_the_review": "Overall, I found this paper exceptionally clear and well-written. The method is interesting and the experiments are reasonable and well-executed. My only overall concern is regards motivation. By and large, ML methods favor general regularization over using feature selection as a preprocessing step, so I was a bit unconvinced by the initial motivation that feature selection is necessary to improve imputation performance. I think this intuition is born out by the experiments which seem to demonstrate only a small improvement over the base method applied without feature selection. I think the intro would be improved with a bit more justification for the approach and, specifically, why the authors believe feature selection is the right approach here when regularization has worked so well in other settings. With that said, I still think the approach is reasonable and merits publication.\n\nMinor comments:\n1. Overall, I thought the background provided in the intro was excellent. My only quibble is that, in my experience, the most commonly used approach to missing data in statistical settings is multiple imputation and it might be worth mentioning this approach in the intro. Note that improved imputation models mean improve MI.\n\n2. Intro: Modem --> Mode\n\n3. Figures 1 and 2: I think these figures could be cleaned up by organizing them in a 3x3 grid. If you are concerned about space, I recommend sharing x and y axes within the grid.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_14vZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_14vZ"
        ]
    },
    {
        "id": "K4apls54ZU",
        "original": null,
        "number": 3,
        "cdate": 1667248792839,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667248792839,
        "tmdate": 1668764558782,
        "tddate": null,
        "forum": "GrpU6dxFmMN",
        "replyto": "GrpU6dxFmMN",
        "invitation": "ICLR.cc/2023/Conference/Paper4241/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose MBMF, essentially a feature selection procedure for a second step imputation method. With MBMF the authors aim to recover the m-graph that governs a system's missingness (in the tabular domain). Using the m-graph, the authors recover a variable of interest's markov blanket which are used as features for imputation. The second step uses the selected features to impute a missing variable. \n\nTheir experiments show that MBMF combined with MissForest outperforms the most adopted imputation strategies. ",
            "strength_and_weaknesses": "STRENGTHS\n\n* Clearly, causality and structure are important elements in imputation, particularly in the tabular domain. Imputation is an important research area that should receive more attention than it currently does.\n\n* I found the paper quite well written. Also, I find it interesting that the authors base their method on a tried and tested algorithm from 2003. \n\nWEAKNESSES\n\nI think the paper was interesting and have only a few questions I would like the authors' opinion on.\n\n* What exactly is the motivation for using the Markov blanket instead of the parents of X_i? Kyono et al. (2020) seem to be doing well with the covariate's parents? (Note that an m-graph is _causal_, saying it is recovered allows assuming that the parents of a variable are _actually_ the causes). \n\n* Would it be useful to try MBMF with other algorithms (beyond MissForest)? If so, why haven't you done this and could you? If not, why not?\n\n* It seems GAIN is not performing very well, despite it being considered the sota, could you elaborate or reason why this is the case?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper was quite well written. However, I did not find any instructions or leads to reproduce the authors' results. ",
            "summary_of_the_review": "I think the paper is well written, interesting, and touches on some interesting ideas to marry causal discovery and imputation. I was left with a few questions I hope the authors can answer in their rebuttal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_X4h7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_X4h7"
        ]
    },
    {
        "id": "6xnHY1f-B8",
        "original": null,
        "number": 4,
        "cdate": 1667602923287,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667602923287,
        "tmdate": 1669040023334,
        "tddate": null,
        "forum": "GrpU6dxFmMN",
        "replyto": "GrpU6dxFmMN",
        "invitation": "ICLR.cc/2023/Conference/Paper4241/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This submission proposes a new imputation algorithm called Markov-Blanket Miss-Forest (MBMF), which involves two phases: Markov Blanket-based Feature Selection (MBFS), and MissForest (MF) imputation (Stekhoven & Buhlmann, 2012). \n\nFor each partially observed variable V_i, MBFS finds its Markov Blanket within some m-graph which is referred to as the graphical expression of missingness proposed by Mohan et al. (2013).  Then, elements of the Markov Blanket are considered as explanatory features of V_i in the Random Forest regression model used in MF.  \n\nSome experiments are conducted to assess the usefulness of MBMF, in comparison with the original MF, and simpler imputation algorithms (Mean, Mode and KNN algorithms).",
            "strength_and_weaknesses": "Strengths\n- Markov Blanket-based Feature Selection (MBFS) and imputation is interesting\n- Experimental results show that MBMF can provide promising imputation accuracy  \n\nWeaknesses: I think the paper is interesting and I have a few questions. \n- Assumption: Is the assumption 1 \"R_i could only be a leaf node in m-graph\" made to make the problem of finding Markov Blankets easier? Or is it a theoretical guarantee?  \n- M-graphs: For each data set, can MBFS recover the m-graph which informs the missingness mechanisms? For each given incomplete data set, can the output of MBFS suggest which underlying assumption of missingness was used to create that incomplete data set?   \n- Scalability: Experiments are done on data sets with small and moderate sizes (at most 30 variables and at most 8124). Can you comment on the scalability of MBFS?",
            "clarity,_quality,_novelty_and_reproducibility": "I think the submission is well written.",
            "summary_of_the_review": "I think \"MBFS\" & \"imputation algorithm\" is an interesting imputation approach and can be implemented with different imputation algorithms. I gave a few questions in \"Strength And Weaknesses\".  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_HRJ6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4241/Reviewer_HRJ6"
        ]
    }
]