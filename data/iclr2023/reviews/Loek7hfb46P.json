[
    {
        "id": "IsDXFEIBlH",
        "original": null,
        "number": 1,
        "cdate": 1666521780337,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666521780337,
        "tmdate": 1666521780337,
        "tddate": null,
        "forum": "Loek7hfb46P",
        "replyto": "Loek7hfb46P",
        "invitation": "ICLR.cc/2023/Conference/Paper5385/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper targets at improving the sampling efficiency of diffusion model via a semi-linear ODE methods, termed as Diffusion Exponential Integrator Sampler (DEIS). The paper is well motivated with experiment observations that the changes of \u000fnoise predicted by the neural network is small for most of the sampling steps as shown in Fig. 4a in the paper. Thus the values can be reused. The author also explores a variety of functions by measuring the  discretization error. The author finally proposes a principled guideline on achieving fast sampling of DM models with High order polynomial and . The experiments on CIFAR-10 and ImageNet with image size downsampled to 32x32 support the main claims of the paper.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well written. The flow is easy to follow and the contributions of the paper is clearly presented.\n2. The background knowledge on diffusion model is well presented and the readers can easily get the main claims of the paper, which is the sampling efficiency.\n3. I like the analysis conducted by the authors. The claims are supported by the experiments results.\n\nWeakness:\n1. The paper only conducted experiment on easy & object centric datasets: CIFAR and ImageNet with 32x32 size. However, the main advantages of DM are on complex scenes where the generated images contain multiple objects. Besides, one of the well known disadvantages of DM is the high resolution images. Could the proposed algorithm achieve promising results on applied to the above mentioned cases?\n\n2. In Appendix B, authors claim that DPM-Solver is a concurrent work. The authors claim that DPM-solver is a special case of DEIS. So, how about the comparison with DPM-Solver? Does the more general exploration of DEIS outperform DPM-Solver?\n\n3. Recent popular LDM models use PLMS solver and achieves even faster sampling speed. How the proposed DEIS compared to PLMS sampler?",
            "clarity,_quality,_novelty_and_reproducibility": "The work is well presented. The quality is good in terms of analysis and writing. The paper is clean and detailed enough for reproducibility. However, there are a few of concurrent works such as DPM-Solver and PLMS sampler are not compared in the current version.",
            "summary_of_the_review": "Overall, I like the paper's style and I think the authors have put in enough efforts on this work. However, the advantages of the proposed methods are not clean enough. The experiments are relatively weak in terms of both dataset and selected baselines. Please refer to the `strength & weakness' section for the details. Nevertheless, the paper have put in enough analysis that reveals some of the properties of DM. I would vote for board-line accept for this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_HoiQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_HoiQ"
        ]
    },
    {
        "id": "6cnKpHYm-S",
        "original": null,
        "number": 2,
        "cdate": 1666637537291,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637537291,
        "tmdate": 1672877840057,
        "tddate": null,
        "forum": "Loek7hfb46P",
        "replyto": "Loek7hfb46P",
        "invitation": "ICLR.cc/2023/Conference/Paper5385/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a sampler for diffusion models based on the exponential integrator and the semi-linear structure of the probability flow ODE. The authors demonstrate that this sampler maintains strong performance for low numbers of function evaluations.   ",
            "strength_and_weaknesses": "**Strengths** \nThe formulation of the solver is relatively well-structured and motivated. The three ingredients proposed in section 3.2 and the related ablation of each on the toy problem is neat. The explanation of DDIM in terms of a first order method for the semi-linear ODE is nice, although a similar argument was already made in DPM-Solver (Lu et al) (although I acknowledge it was concurrent work, more discussion below). The reparameterization in section 4 removing the linear term in section 4 is also neat, but again the discussion overlaps with Karras et al (also discussed more below). The experimental results, primarily Table 2, are convincing, especially showing the worth of the higher order methods. \n\n**Weaknesses** \nThe experiments section is quite concise. There is quite a lot of additional content in appendices G and H. It would be good to compare to more methods in the main paper (as well as the concurrent work discussed below) and not relegate this to the appendix. It would also be good to expand on the use of the proposed sampler for pretrained models like Stable Diffusion beyond qualitative samples -- showing improved performance here over competitive approaches would be a strong result. \n\nRelated to iPNDM: 'We further propose Improved PNDM (iPNDM) that uses lower order multistep methods for the first few steps in sampling to avoid expensive warming start.' Isn't it the case that for linear multistep methods the expensive warm start is necessary? i.e. if you don't warm start an order K methods with steps of at least order (K - 1), the resulting method is bottlenecked by the lowest order used for the warm start? \n\n**Nits**\n- Intro: 'DM is not hyperparameter sensitive' - maybe less sensitive than GANs, otherwise this is too strong a statement.\n- Intro: 'extremely slow sampling' - again, 'extreme' is probably too strong a statement, compared with e.g. AR sampling \n- Figure 2: the vertical-axis isn't labeled \n- 7: 'DEIS also works amazingly in practice' - again too strong ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nI find the use of matrix notation throughout makes the paper more difficult to understand. Moreover, the matrix notation is never actually needed, since in Table 1, all of these coefficients are multiples of the identity.  \n\nIt's unclear to me why you need the general form in eq 4. with lambda nonzero. In Section 5, you mention discretizing this with lambda nonzero 'does not work well in practice', and 'We do not pursue the discretization of the SDE Eq. (4) further in this paper and leave it for future'. Why include it at all then? You also include motivation as to why we should only consider the lambda = 0 case ('From this perspective, the ODE with \u03bb = 0 is the best option since it minimizes the weight of nonlinear term.'), but why not make this case earlier and just consider the simplified version of eq. 4? \n\nOverall there is some difficulty parsing the paper. This includes some awkward phrasing (e.g. abstract: 'a fast sampling method for DMs with a much less number of steps' ->  'a fast sampling method for DMs with fewer steps') and some sentences which don't make sense (e.g. 4: 'Absorbing useful structures such as semi-linear structures through a transformation so that the transformed ODE does not possess any useful structure that one can utilize to improve generic ODE methods.'). It would be good to revise some of this. \n\nThe polynomial extrapolation and associated coefficient computation in Ingredient 3 (eqs 14 and 15) might benefit from an explicit algorithm description i.e. to make clear that the coefficients are computed once in advance when a particular discretization is chosen (if I understand correctly).  \n\n**Originality**\nThe paper has a lot in common with DPM-Solver https://arxiv.org/abs/2206.00927 (Lu et al), as you've noted in Appendix B. I appreciate that this is concurrent work, but I feel this comparison should be made in the main body of the paper, rather than in the appendix, especially since you claim these methods are special cases of your approach. It would be useful to tease out the exact correspondence to this paper, and explain the choices in https://arxiv.org/abs/2206.00364 (Karras et al) in terms of your formulation, as well as compare to both empirically. ",
            "summary_of_the_review": "Overall I think this is a well-motivated paper with convincing empirical results. A more thorough discussion and comparison of competing methods, as well as some restructuring to move results from the appendix would improve the paper further. \n\nEdit post-rebuttal: I'd like to thank the authors for their response. Some of the main criticism of the paper concerns concurrent work, which I feel the authors have attempted to address. Both the concurrent work and this paper constitute useful contributions, and I think this paper also deserves to appear in proceedings, even if the overall presentation is perhaps less clear. I've raised my score accordingly. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_xTdk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_xTdk"
        ]
    },
    {
        "id": "0KATnHhI2L",
        "original": null,
        "number": 3,
        "cdate": 1666639942886,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666639942886,
        "tmdate": 1669167673235,
        "tddate": null,
        "forum": "Loek7hfb46P",
        "replyto": "Loek7hfb46P",
        "invitation": "ICLR.cc/2023/Conference/Paper5385/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposed a fast sampling method, termed as diffusion exponential integrator (DEIS), for diffusion models with a new discretization of the reverse process. In particular, this work first investigates the existing ODE solvers for diffusion models and found that reducing the discretization error is crucial for fast sampling. This work then proposes a new discretization that is mainly based on the exponential integrator (EI) and polynomial extrapolation of the noise prediction function. Besides, this work shows that DDIM is a special case of DEIS. Experiments show that the proposed method can achieve 4.17 FID with 10 function evaluations on CIFAR-10, outperforming other ODE discretization based methods. \n",
            "strength_and_weaknesses": "Strengths:\n- The proposed idea from the exponential integrator perspective is interesting and novel to me. The motivation of reducing the discretization error using polynomial extrapolation is sound and intuitive. \n- This work provides a good insight into the understanding of DDIM from the numerical discretization perspective. That is, applying EI into the noise prediction reparameterization in VPSDE without the polynomial extrapolation becomes the DDIM sampling.\n- Experimental results on CIFAR-10 show the effectiveness of the proposed method: the best variant of DEIS largely outperforms previous ODE-based training-free methods (DDIM, A-DDIM, PNDM) when the NFE is less than 20.\n\nWeaknesses:\n- The presentation of the proposed method is not clear. I understand that this work tries to make the main idea well-motivated and general, but I think many design choices that do not work well can be moved to the appendix, such that we understand the core idea more easily. Below are some details: 1) if EI works better than Euler with the noise prediction reparameterization (while it works worse than Euler with score prediction reparameterization), we can present the idea with the noise prediction reparameterization, which has been commonly used in most diffusion models for images. The analysis for different network reparameterizations can be deferred to the appendix. 2) I don\u2019t fully understand why we need Proposition 3. In other words, why do we need to transform Eq. (10) into \u201ca simple non-stiff ODE\u201d, if the resulting $\\rho$AB-DEIS is no better than $t$AB-DEIS (Table 2)? Also, I don\u2019t fully understand why it is a good thing to apply generic ODE solvers without \u201cworrying about the semi-linear structure\u201d. 3) If DEIS does not work well for SDE, we can defer most details in Section 5 to the appendix. 4) I\u2019m not exactly sure what \u201c+optimizing timesteps\u201d in Figure 5 means. It seems that the main text doesn\u2019t directly explain its meaning.\n- The experiment settings and results are also confusing. Below are some details: 1) It mentions that the proposed method compares with other training-free baselines (DDIM, A-DDIM, PNDM) on several datasets. However, in the main text, we don\u2019t see the results of A-DDIM and PNDM at all, and there is no quantitative result on other datasets except CIFAR-10. I suggest presenting these main experimental results in a more compact and coherent way instead of deferring most of them to the appendix. 2) In the experimental setting, I think several more recent training-free baselines (e.g. [1,2]) are missing. I noticed that the authors discussed their relationship with the proposed methods in the appendix. I would prefer to discuss these relevant baselines and show quantitative comparison results in the main text. 3) I appreciate that the authors considered ImageNet as one of the datasets to evaluate the proposed method. But I think ImageNet 32x32 is a bit low resolution and difficult to visually see the generation quality. I suggest similar to many previous works (e.g., [2,3]) that consider ImageNet with a resolution of at least 64x64 for obtaining both quantitative and qualitative results.\n- Minor things: In section 2, when describing the conditional marginal distribution $p_{0t}(x_t|x_0)$, what does $\\mu_t$ mean? I suggest replacing the term \u201cDiffusion model\u201d with \u201cdiffusion model\u201d.\n\n\n[1] Elucidating the Design Space of Diffusion-Based Generative Models, NeurIPS 2022.\n[2] DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, NeurIPS 2022.\n[3] Progressive Distillation for Fast Sampling of Diffusion Models, ICLR 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I liked the idea of using EI and polynomial extrapolation for the fast sampling in the ODE version of diffusion models, which is novel and original to me. However, I think the presentations of the idea and experiment results should be largely improved. Lastly, I think the work provided sufficient details for reproducing the main results.",
            "summary_of_the_review": "Overall, I think the idea is interesting and useful, but the idea and experimental results are poorly presented, which makes me not sure how it compares with previous relevant methods. My initial suggestion is \u201cleaning to reject\u201d but I\u2019m open to adjusting my rating.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_xzme"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_xzme"
        ]
    },
    {
        "id": "4IW_DliYV-e",
        "original": null,
        "number": 4,
        "cdate": 1667419650781,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667419650781,
        "tmdate": 1668599717214,
        "tddate": null,
        "forum": "Loek7hfb46P",
        "replyto": "Loek7hfb46P",
        "invitation": "ICLR.cc/2023/Conference/Paper5385/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Authors present efficient integrator for diffusion models based on polynomial interpolation of the noise during trajectory estimation. ",
            "strength_and_weaknesses": "Strengths:\n1. Idea somewhat interesting from theoretical stand point\n2. Detailed motivation for ODE case why this should work\n\nWeakness:\n1. It's not clear why you mention application to SDE case as you mention that your method do not work for integrating SDE equation\n2. Notation is somewhat overcomplicated for no reason, e.g. \\Phi(s, t) -- why you need to mention hard matrix ODE as in your case it is always scalar multiplied by identity matrix? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems notationally and mathematically overcomplicated, idea is novel. I did not see link to the code whilst the method seems highly hard to replicate just from description as requires accurate invocation of ODE solvers.",
            "summary_of_the_review": "The paper should be simplified and made more clear, at this point it is too hard to read due to unnecessary mathematical overload and the reproducibility is under question.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_5JHW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5385/Reviewer_5JHW"
        ]
    }
]