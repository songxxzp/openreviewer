[
    {
        "id": "aB-FDcw_X6",
        "original": null,
        "number": 1,
        "cdate": 1666494588880,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666494588880,
        "tmdate": 1666494588880,
        "tddate": null,
        "forum": "MWGDhOQkr3",
        "replyto": "MWGDhOQkr3",
        "invitation": "ICLR.cc/2023/Conference/Paper4402/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work find that the inherent edge noise can perturb the graph topology and labels, which may reduce link prediction performance. Thus, the authors propose an information bottleneck guided method, namely RGIB. RGIB achieves robustness representation of graphs. The experiments show effectiveness of RGIB. This paper is very well written and the theoretical proof is very detailed.\n",
            "strength_and_weaknesses": "Pros: The paper is well written, and despite the considerable complexity of the method, its presentation is relatively easy to follow. The task of interest is well-defined, and has clearly been effectively solved on the datasets considered. The experiments provided in this paper are extensive and quite comprehensive. Specifically, the authors verified the effect and superiority of their proposed RGIB method in detail from different angles. The experimental results are also convincing. \n\nCons:\nI am mainly concerned with the following issues.\n\n(1). The baselines do not appear to be new enough. Almost all of the RGIB baselines in the experimental section are from 2020. Can the authors include baselines from 2021 and 2022?\n\n(2). The work mainly focuses on robustness. Is there a metric to evaluate robustness of these methods?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This article is clearly structured and well written. The authors have a clear definition of the problem to be addressed and use sufficient theory to prove their views. Although information bottleneck theories are not a new topic, the authors use them skillfully. For reproducibility, the authors have not provided source code.\n",
            "summary_of_the_review": "I thought the article was well written. The experimental part is slightly lacking and I hope the authors can answer the questions being asked. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_zAFv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_zAFv"
        ]
    },
    {
        "id": "8SgdcfREt7",
        "original": null,
        "number": 2,
        "cdate": 1666539995767,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666539995767,
        "tmdate": 1666539995767,
        "tddate": null,
        "forum": "MWGDhOQkr3",
        "replyto": "MWGDhOQkr3",
        "invitation": "ICLR.cc/2023/Conference/Paper4402/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a robust graph information bottleneck (RGIB) for link prediction. This paper extends the previous graph information bottleneck (GIB) in a non-trivial manner by considering the fact that if the graph structure is assumed to be noisy, the labels in link prediction (i.e., hold-out links) are also noisy, and therefore the MI maximization term in the original GIB objective can still introducing noise in learned latent representations.",
            "strength_and_weaknesses": "This paper has several strong points that I appreciate very much.\n\n1. The authors address a novel problem of label noise in the GIB framework.\n\n2. Two adverse consequences of the existence of label noise in the original GIB framework, i.e., poorer alignment and worse uniformity, are clearly identified with good visualization.\n\n3. The authors proposed a self-supervised learning-based extension to GIB, where the alignment and uniformity issues seem to be addressed with good theoretical support.\n\nMeanwhile, I  also have some questions for the authors.\n\n1. Since the target links are randomly selected from the existing links, isn't the structure loss and label noise the same noise rather than two different noises that are coupled together? Although I understand that the use of coupled noise makes it easier for the theoretical analysis for the discussion of GIB's issues and RGIB's advantages, I still think coupled noise may not be the best-fit description for the case.\n\n2. In addition, there seem to be insufficient discussions regarding the limitation of the methods. I wonder whether the strength of the RGIB will hold if the \"coupling\" between label noise and structure noise is weak. Moreover, I'm also curious whether the RGIB framework can generalize to the same problem setting of the original RGIB for node classification, where there exists noise in the node labels?",
            "clarity,_quality,_novelty_and_reproducibility": "**For clarity:**\n\nMost part of the paper is clear, but I'm not sure whether \"coupled noise\" is a good fit for the problem.\n\n**For quality and originality:**\n\nThe studied problems and the proposed method are novel to my knowledge. Although RGIB does depend heavily on the previous GIB framework, the extension is non-trivial.\n\n**For Reproducibility:**\n\nThe authors seem to promise the release of their codes.",
            "summary_of_the_review": "A good paper that theoretically extends the GIB framework to handle label noise problems in link predictions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_gCKh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_gCKh"
        ]
    },
    {
        "id": "i_5tf_9y8NZ",
        "original": null,
        "number": 3,
        "cdate": 1666620104030,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620104030,
        "tmdate": 1666620104030,
        "tddate": null,
        "forum": "MWGDhOQkr3",
        "replyto": "MWGDhOQkr3",
        "invitation": "ICLR.cc/2023/Conference/Paper4402/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on the edge noisy scenario in the link prediction task and proposes a method named Robust Graph Information Bottleneck. The self-supervised learning technique and data reparametrization mechanism are utilized to instantiate RGIB. ",
            "strength_and_weaknesses": "Strength:\n1. The coupled edge noise in the link prediction task is a good research problem and this paper proposed a reasonable solution. \n2. The motivation is clear and the idea is novel. \n3. The experimental results show that the proposed method is effective. \n\nWeakness:\n1. The inherent edge noise is defined as the additive edge noise, which seems to be not very unified since much noise for link prediction in the real world comes from missing relations. \n2. The understanding part in section 3.2 is not very formal and rigorous. It\u2019s unclear whether the quantitive and qualitative analysis by alignment and uniformity is specific to edge noise. \n3. The design of the RGIB objective function is based on intuition, and its rigor needs to be further explained. \n4. The relationship between the two instantiations, their respective advantages, limitations, and scope of application are not well explained. \n5. Most of the baselines are published in 2020 and the latest one is published in 2021. Some SOTA methods should be included for comparison. \n6. In the IB principle, the trade-off parameter is important, and needs more analysis. \n\nOther questions and suggestions:\n1. Some related works are missing. There is a recent work[1] that incorporates the IB to purify the graph structure, which should be included in the related work or included in the baselines. [2] is also a method for graph denoising from the perspective of information theory. \n2. There are many graph adversarial attack methods that perturb structures. Since this paper focuses on the robustness of link prediction, how does the proposed RGIB perform under adversarial attacks?\n3. As the scalability of graph algorithms has become increasingly important in recent years, I would like to see the performance of this method on larger datasets and its time consumption analysis. \n4. I\u2019m wondering how the distribution of H and the MI terms in the objective function change during the training process, which is helpful to understand the rationale of this method. \n5. Are the alignment and uniformity specific measurements for edge noise in link prediction? Can other denoising methods also promote alignment and uniformity? \n\n[1] Graph Structure Learning with Variational Information Bottleneck. AAAI 2022.  \n[2] Principle of Relevant Information for Graph Sparsification. UAI 2022. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Good originality. Writing and organization should be improved. ",
            "summary_of_the_review": "The research problem and the idea are good. The analysis, experiments, and writing should be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_sr13"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_sr13"
        ]
    },
    {
        "id": "DjnwafItP8",
        "original": null,
        "number": 4,
        "cdate": 1666637858999,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637858999,
        "tmdate": 1669733390719,
        "tddate": null,
        "forum": "MWGDhOQkr3",
        "replyto": "MWGDhOQkr3",
        "invitation": "ICLR.cc/2023/Conference/Paper4402/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "A method to handle graph-edge noise is introduced based on an information-bottleneck theory. It is shown that adding edge noise to real data will increase the link prediction error. The introduced method is shown to reduce this error.",
            "strength_and_weaknesses": "\nAddressing noisy edges in a graph is a sensible and practical direction of research, as it is not often considered, is likely to be present in real data and will reduce model performance error. This paper demonstrates that errors increase for the link prediciotn task with synthetically added edges to public datasets.\n\nHowever, it is many parts of this paper are unclear, how noise is added, what a graph illustration is trying to show, what the x and y values represetn, what values in a table represent, how well this approach works on the original data without synthetically added edges and more. This paper needs to explain more clearly many parts of the work.\n",
            "clarity,_quality,_novelty_and_reproducibility": "CL.\n\nFig 1. a shows two illustrations of the same set of nodes; on the left the solid lines (clean edges) are connecting one set of the nodes, and on the right they are connecting another set; the same with the blue dashed line (noisy edges). The left graph has a title noisy input A_tilde and the right noisy labels Y_tilde. I do not understand what is the input and what are the labels here? An input graph is in my understanding a set of nodes and edges, this can also include labels (class labels) for each node but why the edges on the right are changed completely I do not follow.\n\nV = {v i } but i is from 1 to ?\n\nTab. 1 has some interesting plots, which seem to indicate that the signal is lost as more randomly generated edges are added to the graph. However, it is unclear what the x and y axis are, it's unclear what dimension H_1 and H_2 are, it's unclear why both A_1 and A_2 are perturbed, I would imagine one would be clean and the other has the noise added? In the table with the values .616, .445 etc.. are representing what exactly, alignment maybe, but how is this quantified?\n\nQU.\n\n\"Other methods (Rong et al., 2020; Zheng et al., 2020; Luo et al., 2021) achieve a similar goal by actively selecting the informative nodes or edges and pruning the task-irrelevant ones.\" I am familiar with Rong et al. and they do not actively select the informative edges, they do random sampling of the edges at each epoch so this sentence is inaccurate. Also this reference is incomplete and has a typo: \"Y. Rong, W. Huang, T. Xu, and J. Huang. Dropedge: Towards volutional networks on node classification. In ICLR, 2020.\".\n\n\"Since existing benchmarks are usually well-annotated and clean, there is a need to simulate the inherent edge noise properly to investigate the impact of noise.\" Can you substantiate this claim?\n\nIn Table 2 including the clean graph results will give a reference to how well the performance can be with no randomly added edges and can also show if the proposed method can improve on the results of 'clean' data, which is likely to have false positive edges even without artificially added ones.\n\nNO.\n\nIt's not clear what additions are made to GIB to improve it's robustness.\n\n\nRE.\n\nIt's not clear how the edges are added, I assume the additional synthetically added noisy edges simply sampled uniformly over all candidate edges. Also, the updates to the labels is not clear in this experiment?\n\n",
            "summary_of_the_review": "\nSadly this paper is too unclear to follow and understand. As well as addressing the above pointed out issues, I recommend focusing on explaining more clearly the edge data generation steps, the contribution added starting from the GIB work, and explaining why these additions improve on the existing work. I look forward to see the revised version as this is a very intersting research area.\n\n[After Review Period]\n\nThe paper has a very nice contribution with respect to the motivation [identify and remove noise from graphs for link prediction] and the intuition behind the idea [extend GIB to separate the label and feature noise], and the paper is clearly structured. Many of the concerns have been addressed and modified in the paper and so I feel that the paper is closer to being ready for publication. It is still unclear how the claim that the public datasets either do not have noise, or that this noise is always FPs. Another reviewer commented that typically the noise in graphs are missing edges, which contradicts the authors comment. The experiments on the public dataset without added noise also show improvements with their method, implying that there must be some noise. This leaves a number of unanswered questions about the noise in the data. Maybe the authors can inspect samples of the edges being updated by RGIB in the clean datasets to see if qualitatively they can start to investigate these questions. Also, could the synthetically generate data to analyse the behaviour of their method? Due to this and the number of initially found issues I believe this is still below the acceptance level, although it has improved during the review period.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_m5JE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4402/Reviewer_m5JE"
        ]
    }
]