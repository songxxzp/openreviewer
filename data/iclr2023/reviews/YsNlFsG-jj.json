[
    {
        "id": "3rlldNZThky",
        "original": null,
        "number": 1,
        "cdate": 1666358622823,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666358622823,
        "tmdate": 1670341811638,
        "tddate": null,
        "forum": "YsNlFsG-jj",
        "replyto": "YsNlFsG-jj",
        "invitation": "ICLR.cc/2023/Conference/Paper5089/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposed a deep probabilistic framework for modeling the distributions of each time-series together using a soft distributional coherency regularization (SDCR) over forecast distributions. It has the advantages of 1) adapting to both strong and weak hierarchical consistent datasets and 2) producing well calibrated forecasting at all levels. The empirical results demonstrated that it improves performance on forecasting accuracy and calibration on all levels and provides robust predictions with missing data.\n",
            "strength_and_weaknesses": "Strength:\n* The paper is well motivated. It\u2019s an Interesting setting with weakly consistent datasets, where the data generation process may follow a hierarchical set of constraints but may contain some deviations. HIERE2E (Rangapuram et al., 2021) and SHARQ (Han et al., 2021) impose hierarchical constraints on the mean or fixed quantiles of the forecast distributions, but the distribution may not be well calibrated.\n\n* Convincing experiments. The work considered many relevant baselines and reported various metrics, characterizing different aspects. The 4 model variants provide data for the impact of the model choices. Replacing TSFNP with DeepAR and comparing to baselines with DeepAR separates out the effect of the base forecasting model. \n\nOn the weakness, the proposed method assumes Gaussian for the prediction, which is fair start but it limits the choices. Extending the framework to other distributions can be beneficial. \n\n=== After discussion with AC and other reviewers ===\n\nI think the idea is interesting and the empirical evaluation is quite comprehensive. But at the same time, the math behind the model especially on the ELBO, as pointed out by the AC, is alarming to me. There are steps missing and it is hard to verify the correctness of the derivations. Please see more detail in the above for this point. This negatively impacts the soundness of the work. Thus, I will lower my score accordingly.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear written, I only have some minor comments:\n* The author mentioned TSFNP is modified fromKamarthi et al., 2021, what is the difference and why? It\u2019s provided in the appendix but it will help to also summarize it briefly in the main text. \n* In eq(11), the loss is computed on the refined $\\mu, \\sigma$ or the raw $\\hat{\\mu}, \\hat{\\sigma}$?\n* Typo in the \u201cIS measures the negative log likelihood\u2026\u201d IS->LS.\n* Why not make the hyperparameter $c$ in eq(9) learnable?\n* What are the hyperparameters and training details for the baselines?\n\nThe overall writing and technical qualities are good. To the best of my knowledge, enforcing hierarchical constraints in the probabilistic space for forecasting is novel. Good reproducibility is backed up with implementation detail and code.\n",
            "summary_of_the_review": "The paper is well motivated. It fills the gap of enforcing hierarchical constraints in the probabilistic space, allowing for soft matching and improved calibration. The chosen methodology makes sense to me and the empirical work is relatively strong and convincing. It has limitations in the Gaussian output, but as demonstrated in the results, it already performs strongly compared to the baselines. The paper is mostly clearly written and the code is also provided for reproducibility. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_UgsV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_UgsV"
        ]
    },
    {
        "id": "MIHWaxFZDux",
        "original": null,
        "number": 2,
        "cdate": 1666651002711,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651002711,
        "tmdate": 1670353115841,
        "tddate": null,
        "forum": "YsNlFsG-jj",
        "replyto": "YsNlFsG-jj",
        "invitation": "ICLR.cc/2023/Conference/Paper5089/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a probabilistic hierarchical time series forecasting model that provides a coherent distributional forecast that achieves better performance in forecasting accuracy. The core idea is to use a deep probabilistic forecasting framework, i.e., the neural Gaussian process, to produce a probabilistic base forecast and then refine the base forecast using a separate module. This refinement procedure is based on a variational inference framework coupled with a distributional coherency loss. The proposed method has achieved improved performance over various baselines, particularly in datasets with missing values.",
            "strength_and_weaknesses": "Strength:\n1. This paper proposed a fully parameterized and probabilistic framework for HTS forecasting, which flexibly incorporates hierarchical information into both point and distributional forecasts by enabling parameter sharing.\n2. The proposed method obtains better performance on both point and probabilistic forecasts for various datasets.\n3. The authors have distinguished strong and weak consistency, i.e., whether time series at a lower level should strictly add up to obtain time series at the upper level, which is a useful step for many real-world applications.\n\nWeakness:\n1. Since the authors have distinguished strong and weak consistency in the main paper, it is also better to separate (or at least highlight) them in the experiment since some methods are designed for strong consistency (e.g., MinT, ERM, and HIERE2E) and some method is better for weak consistency (e.g., SHARQ). It is not fair to compare these methods from different categories.\n2. It seems that there is no formal guarantee of the robustness of PROFHIT over other baselines. The authors are using missing value imputation whereas other methods can also do. This experiment seems heuristic.\n3. Normally in many applications, time series at different aggregation levels have distinct properties over sparsity, noise distribution or sampling rate etc., which will affect the distributional assumption at each level. Since the proposed method uses a general Gaussian distribution for each level, the authors could discuss how this general assumption can be adapted to datasets with different properties.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is technically sound and well-written. The authors have clearly distinguished the novelty over prior works and compared it with the baselines. They have also provided the code to reproduce the experiments.",
            "summary_of_the_review": "This paper proposed a novel method to address an important problem. I would recommend accepting this paper upon my concerns are addressed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_eMuv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_eMuv"
        ]
    },
    {
        "id": "vxnLTUydHN",
        "original": null,
        "number": 3,
        "cdate": 1666709001109,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666709001109,
        "tmdate": 1666709001109,
        "tddate": null,
        "forum": "YsNlFsG-jj",
        "replyto": "YsNlFsG-jj",
        "invitation": "ICLR.cc/2023/Conference/Paper5089/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a new probabilistic forecasting method for hierarchical time series. Compared to existing methods, the proposed method is more robust and can deal with inconsistent hierarchies. Specifically, the method is based on a flexible Bayesian approach which includes distributional coherency regularization. Experiments on multiple datasets show that the proposed method improves accuracy compared to baselines and provides reliable forecasts even if up to 10% of input time-series data is missing.\n",
            "strength_and_weaknesses": "Strength\n- More flexibility and robustness in probabilistic forecasting methods are important for many applications.\n- The method can deal with inconsistent hierarchies.\n- The proposed method provides good accuracy for various datasets.\n\nWeaknesses\n\n- The paper lacks rigor and clarity.\n\n- Important related work is missing:\n\t- https://www.sciencedirect.com/science/article/abs/pii/S0377221722006087\t\n\t- https://arxiv.org/pdf/2103.11128.pdf\n\t- Bayesian methods\n\t\t- https://link.springer.com/chapter/10.1007/978-3-030-67664-3_13\n\t\t- https://arxiv.org/abs/1711.04738\n\n- It is not clear how the proposed method relates to existing work, e.g. MINT. Given that the authors make a gaussianity assumption, it is not clear how their method compares with MINT, for which we have closed-form expression for the entire hierarchy (for means and covariance matrix). \n\n\n- The logscore is improper with respect to incoherent predictive distributions. As a result, you cannot compare coherent with incoherent distributions with LS. See https://www.sciencedirect.com/science/article/abs/pii/S0377221722006087 for more details.\n\n- The authors claim that their method provides well-calibrated forecasts. However, this concept it not clearly defined (See Definition 3). Please use your predictive model p_M in the definition.\n\n- The authors claim that they model the joint distribution of all series in the hierarchy. However, in the sentence before Section 3, the authors refer to the marginals. This is not clear. Expression (2) gives the joint distribution of y_i for i=1, .., N, but the first sentence in \"overview\" talks about the marginal distributions. \n\n- The authors should clearly explain the factorization in (1).\n\nComments:\n- \"We performed ERM and MINT on Monte Carlo samples of TSFNP predictive distribution\": Please be more precise.\n\n- The authors use both consistency and coherency. I would suggest sticking to coherency.\n\n- CRPS does not measure accuracy and calibration, but sharpness and calibration.\n\n- Various notions of \"distributional coherency\" have been proposed in the literature. A precise definition is needed here. I think you are using sample coherency\n\n- \"Samples of distribution\": do you mean samples from the predictive distribution?\n\n- In latex, please use \\citep{} instead of \\cite{}.\n\n- What do you mean by \"time-series of employment\"?\n\n- \"both so-called strong and weakly consistent datasets\": I am not sure \"so-called\" is the right term to use here.\n\n- \"They produce unreliable confidence intervals\": I think you meant \"prediction intervals\".\n\n- In section 2, please specify the range of phi_{i,j}. Does it belong to {0, 1}?\n\n- Notations: \\hat{p}(Y_t), \\hat{y}_t, etc.\n\n- Note that the CRPS has a closed-form expression for a Gaussian distribution.\n\n- The authors should discuss the limitations of their method (computational complexity, statistical assumptions, etc)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Unfortunately, the paper lacks rigor and clarity. \n\nThe proposed method is novel, but it is not clear how it relates to existing methods, such as MINT, which makes similar assumptions. \n\nRegarding reproducibility, the authors provide code to reproduce their experiments.",
            "summary_of_the_review": "I have reviewed this paper multiple times (for other conferences), and have given many suggestions for improvement. Unfortunately, the authors have ignored important past comments. \n\nThe biggest weakness of the paper is the lack of rigor and the quality of writing (notations, definitions, etc). Understanding differences and similarities with existing methods is also very important. Calibration is also not well defined.\n\nUnless the writing is significantly improved, I do not see this paper being accepted at any top ML conference.\n\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_B3vd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_B3vd"
        ]
    },
    {
        "id": "FY7zg9x_zRr",
        "original": null,
        "number": 4,
        "cdate": 1666822032123,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666822032123,
        "tmdate": 1666822032123,
        "tddate": null,
        "forum": "YsNlFsG-jj",
        "replyto": "YsNlFsG-jj",
        "invitation": "ICLR.cc/2023/Conference/Paper5089/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to address two issues with prior work on the task of hierarchical time series forecasting (HSTF): (i) the assumption of rigid coherency (i.e. forecasts enforce the time-series values of datasets to satisfy the underlying hierarchical constraints strictly) and (ii) the lack of calibrated forecasts.\n\nTo address these issues, the paper introduces soft-distributional-coherency regularization (SDCR) that enables end-to-end learning of the forecast distribution at all levels by leveraging information from the underlying hierarchy. The method involves a two-stage process where\na network is trained to output raw predicted distributions for all time series in the dataset. Then a refinement module jointly refines the distribution parameters for all predicted distributions by leveraging the hierarchical relationships between the time series through SDCR.\n\nEvaluation across multiple datasets and missing data indicate that the proposed approach massively outperforms state-of-the-art methods.",
            "strength_and_weaknesses": "### Strengths\n\n1. The paper aims to address important limitations of past methods (that of forecasting single values rather than distributions, enforcing rigid coherency, and the lack of calibrated forecasts). Addressing these limitations of the previous work are likely to benefit the part of the community interested in these tasks. \n\n2. Empirical evaluation is comprehensive, including several datasets, methods, and metrics. \n\n### Weaknesses\n\n1. Clarity, Formatting Abuse: The paper is hard to read due to various issues in writing, notional imprecision, and formatting abuse (see notes on Clarity below). \n\n2. Reporting the results makes comparisons in a way that the improvement numbers seem large, but the comparisons aren't always reasonable. E.g. an improvement of 550% on log-likelihood is a comparison on an unbounded metric, as compared to, say, accuracy where an improvement in terms of a % improvement carries more meaning. The results would still be meaningful without such % improvement metrics in these cases. \n\n3. It's unclear if a t-test is a reasonable test to compare model performance, specifically that it's unclear why the assumptions required for a t-test hold here. \n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n\nThe paper is hard to read. The paper frequently introduces terms and concepts it only later defines. I understand there are several concepts involved and this might sometimes be hard. At the very least abbreviations should be expanded when stated first (e.g. TSFNP). Nevertheless, combined with the widespread vspace abuse and several notational issues, this makes reading the paper somewhat challenging overall.\n\n#### Notational issues:\n- Definition of H_T has \"for every i in 1...N\". However, the definition only applies to non-leaf nodes and therefore cannot apply to all N time series in the dataset.\n- If the time variable is in the superscript, I suggest being consistent and writing D_t as D^t.\n- What is u?\n- In Eq. 4, if u is a vector, what is mu(u)? Seems like here u oughht to be a random variable not a vector.\n- In Eq. 4, why is the subscript i italics in some places and roman in others?\n- When N_i is a term explicitly used, please do not denote networks as NN_1, which simply adds to the confusion.\n- Is it LS or IS? When defining the metric the paper says both LS and IS. For Q1 results, the paper says that the proposed method improves IS by up to 550% which seems like a typo. \n \n#### Other writing improvement issues/suggestions:\n- \"rigid coherency on generated forecasts generate\" -> remove last 'generate'\n- Fix citation style, citations should be in parenthesis unless using \\citet\n- \"Most state-of-art HTSF methods\" -> \"state-of-the-art\"\n- vspace abuse around the tables and figures.\n- vspace abuse around equations (see top of Eq. 2)\n\n### Quality\n\nIt is hard to evaluate the work rigorously given the writing and notational issues, and the lack of code and data in the supplementary material (the link is anonymized but could have been submitted as supplementary). The goals of the paper are reasonable and likely to be useful.\n\n### Novelty\n\nThe paper addresses important limitations/assumptions of the previous methods and is novel to the best of my knowledge. \n\n### Reproducibility\n\nHard to evaluate reproducibility without seeing the code and data. The link implies this will be available should the paper be accepted, which is better than not having any code and data. \n\n",
            "summary_of_the_review": "The goals of this paper and the proposed method are likely to benefit the community working on hierarchical time series forecasting. The issues involving unclear writing, notational imprecision, and formatting abuse make it hard to read this paper and evaluate the details. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_cEHM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5089/Reviewer_cEHM"
        ]
    }
]