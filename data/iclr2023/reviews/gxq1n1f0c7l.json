[
    {
        "id": "RSRmx9CZga",
        "original": null,
        "number": 1,
        "cdate": 1666454504955,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666454504955,
        "tmdate": 1666454504955,
        "tddate": null,
        "forum": "gxq1n1f0c7l",
        "replyto": "gxq1n1f0c7l",
        "invitation": "ICLR.cc/2023/Conference/Paper2070/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "\nThis paper presents a novel method for zero-shot multi-label classification where the model is trained on seen classes and tested on unseen classes without further model tuning. The strategy uses min-max zer-sum game between the maximizer and the minimizer with minimum cost graph cuts. The proposed method has four additional losses besides the Hamming loss applied for each element of a target vector, namely taxonomy, joint, layer-wise, and pairwise losses.  The proposed method is proven superior compared to the state-of-the-art in multi-label ZSL on NUS-WIDE and Open Images.  \n",
            "strength_and_weaknesses": "\nStrengths: \n- The proposed method is somewhat novel with a min-max graph cut strategy to tackle multi-label ZSL.\n- There are some rigorous experiments to show the effectiveness of the method and the generalization capability using the sharpness metric.\n- The performance is superior compared to some selected state-of-the-art methods for all experiments.\n\nWeaknesses:\n- The structured prediction for multi-label zero shot learning is not first proposed in this work, thus cannot be included as a contribution. Previous works by Lee et al. (\u201cMulti-Label Zero-Shot Learning with Structured Knowledge Graphs\u201d) and Huang et al., (\u201cMulti-label Zero-shot Classification by Learning to Transfer from External Knowledge\u201d) have proposed similar strategies using rstructured graph networks and relational graph convolutional networks, respectively.\n- This work has an Inconsistent term whether the problem is zero-shot multi-label classification or multilabel zero-shot learning.\n- As understood from the description in this work, there would be a drawback in representing the labels with low occurance and also create \u201cblind\u201d correlation without any causation between attributes and classes.\n- The notation and mathematical expressions of this paper are inconsistent, unstructured, and difficult to follow. Sometimes a label vector is denoted as $\\bold{y}$ and $\\bold{Y}$. Another thing is y^{entity} is written as y_{entity}. Variable x is sometimes bold.\n- The proposed method is not clear at all, the readability for this work is very low. After several times reading the mathematical expressions in Section 3, the proposed method is unclear. For instance, why does Eq. 3 uses abs(diff. between two embeddings from word vector) as the divisor? What are parameters to be optimized in Eq. 8 ($\\Theta^{i,j}$ is not clear)? \n- $P_{data}$, $P_{maxi}$ and $P_{mini}$ are not elaborated further in text.\n- Some abbreviations for comparing with all SOTA methods in all tables are not clear and referred in text (e.g., One Attention, LabelEM, and no explanation of M=10 for LESA). Please add complete references in each table.\n- There is no direct comparison with the methods with similar approaches e.g., Graph convolutional networks.\n- The \u201cDiscussion\u201d paragraph in Page 7 has no discussion at all. There are only some references and the report of the results.\n- Some grammatical errors: by Mulan dataset, features values, 1) learn 2) recognizes 3) recognizes. Please review the manuscript in more details as there are notable mistakes in writing.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed method is somewhat novel with a min-max graph cut strategy to tackle multi-label ZSL. However, this work cannot claim the first work that provides a framework using structured prediction to model multi-label ZSL. The quality of the paper is far from ready for publication. As technical writing is not very clear, it is also not clear if the proposed method and the results are reproducible.",
            "summary_of_the_review": "This work has some potentials to tackle the problem of multi-label zero-shot learning looking at excellent performance compared to SOTA. However, the presentation is lacking of clarity, and there are also some claims that need to be tone-down to make the contributions clear.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_TsJ7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_TsJ7"
        ]
    },
    {
        "id": "-iHsdPDqEBa",
        "original": null,
        "number": 2,
        "cdate": 1666672546604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672546604,
        "tmdate": 1666672546604,
        "tddate": null,
        "forum": "gxq1n1f0c7l",
        "replyto": "gxq1n1f0c7l",
        "invitation": "ICLR.cc/2023/Conference/Paper2070/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new method, Min-Max, for multi-label zero-shot learning (ML-ZSL). The proposed method is evaluated on multiple benchmarks, including ZSL, GZSL, and multi-label ZSL datasets, and shows compelling results.",
            "strength_and_weaknesses": "Pros:\n1. The proposed method seems novel in the respective area\n2. The method achieves state-of-the-art performance on various benchmarks for ML-ZSL. It also performs very competitive results on conventional ZSL/GZSL. \n\nCons:\n1. The organization of the paper can be improved. I find myself having to go back and forth to understand certain parts when reading. The presentation of the formulae can also be improved to make them more straightforward.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: As I said above, the paper can be better organized. But the authors tried to use examples to walk through the proposed method, which should be encouraged.\n\nQuality & Novelty: The paper seems novel to me as it does not resemble the prior arts. Considering its compelling empirical results, the overall quality of the paper is good.\n\nReproducibility: The authors provided the algorithm in the appendix. But it lacks enough training and implementation details to help readers reproduce the method.",
            "summary_of_the_review": "Summary: Given this paper's novelty and quality, I am inclined to accept it. However, I am not very familiar with this area, and I might be wrong regarding the novelty.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_WnWm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_WnWm"
        ]
    },
    {
        "id": "NowO-TQBIZ3",
        "original": null,
        "number": 3,
        "cdate": 1667470302509,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667470302509,
        "tmdate": 1667470302509,
        "tddate": null,
        "forum": "gxq1n1f0c7l",
        "replyto": "gxq1n1f0c7l",
        "invitation": "ICLR.cc/2023/Conference/Paper2070/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper explores a challenging task of zero-shot multi-label classification. To address this task, the authors propose to combine multiple types of feature representations to represent data, including Word-Net hierarchy, word2vec features, CNN layer-wise features and co-occurrence statistics. Based on these features, a new min-max zero-shot multi-label learning method is proposed to learn classifiers to predict test data for unseen classes. Experimental results show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Strength:\n+ The explored task is highly challenging and beneficial to practical applications.\n+ Constructing class relations based on the graph structure is interesting.\n+ Empirical results seem good compared to the presented baselines.\n\nWeaknesses or questions:\n- All these feature representation manners are simply combined without in-depth analysis. Can you provide any insights on them? In addition, how to accurately construct the relationship between seen classes and unseen classes based on these features?\n- More related studies are welcomed. For example, visual-language models have recently shown highly promising performance for zero-shot learning. It would be better to discuss them.\n- Figure 4 is unclear. How to learn the classifier for making min-cut predictions for unseen classes during training?\n- It is better to give some visualization results for some images and their prediction probabilities for different unseen classes.\n In addition, please also provide some failure cases to discuss the limitations.\n- In Section 4.1, it is better to visualize the loss surface to see whether it is flatter than other baselines.\n \nMinor issues:\n- The format of in-text citations is not good and can be improved.\n- All figures are not formal and academic. The authors are suggested to make them more formal.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the clarity can be improved, including figures, descriptions, and logical flow. \nQuality: the quality is moderate.\nNovelty: there are novelties in the proposed method but not that significant.\nReproducibility: the authors are expected to release the code to the public.",
            "summary_of_the_review": "Overall, although there are merits in this paper, some issues affect its clarity and contributions. It is better for authors to address the concerns for further improving the quality of the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_ZVzZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2070/Reviewer_ZVzZ"
        ]
    }
]