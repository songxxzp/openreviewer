[
    {
        "id": "PmvLrU6TmZ",
        "original": null,
        "number": 1,
        "cdate": 1666325772978,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666325772978,
        "tmdate": 1666410439683,
        "tddate": null,
        "forum": "OxNQXyZK-K8",
        "replyto": "OxNQXyZK-K8",
        "invitation": "ICLR.cc/2023/Conference/Paper2238/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper addresses the curse of the dimensionality problem in multiagent reinforcement learning (MARL), where the state-action space grows exponentially as the number of agents increases. To address this challenge, this paper proposes two novel implementations that exploit the permutation invariance (PI) and permutation equivariance (PE) properties. Specifically, the authors introduce the dynamic permutation network (DPN) and hyper policy network (HPN) that can guarantee PI and PE properties. Evaluations in SMAC, Google Research Football, and MPD show that the proposed frameworks outperform competitive baselines. ",
            "strength_and_weaknesses": "**Strengths:**\n1. The proposed frameworks can be applied to existing MARL methods by following the minimal modification principle and modifying the input and output layers only.\n2. Experiments are performed using the benchmark domains and show state-of-the-art performance compared to competitive baselines.\n3. The paper is generally well-written and explained clearly. \n\n**Weakness:**\nThis paper is built on three assumptions: 1) the observation and action space are factorized, 2) a different entity order in observation does not affect information (i.e., PI property), and 3) the agent has prior knowledge about the structures of its observation and action space (e.g., in Figure 1, the agent knows which information corresponds to ally and opponent agents and which actions correspond to PI and PE actions). While I agree with the authors that assumptions #1 and #2 generally hold in many MARL settings, assumption #3 can be a strong assumption and can limit the applicability of the proposed framework. For example, the deep set method exploits PI by requiring assumptions #1 and #2, which still hold in model-free MARL. However, to additionally exploit PE, this paper requires assumption #3, which is generally not available for model-free settings. If assumption #3 is strong, it would be beneficial to discuss which potential methods can be used to address assumption #3. \n\n**Questions:**\n1. The related work section states that the representation capacity of the deep set and GNNs is limited due to the use of the shared embedding layer. Do these methods have to use the shared embedding layer? If not, would it be easy to modify these baselines not to use the shared embedding layer and thus improve the representation capacity of these methods?\n2. The problem statement is based on Dec-POMDP, the standard framework for collaborative settings. However, this paper uses competitive setting examples, such as SMAC, so I wonder why the problem statement is based on collaborative settings.\n3. Regarding the PI Input Layer A in Section 4.2, the weight selection network is *learned* to select the corresponding weight matrix. Which objective is used to train the weight selection network? Also, because this network is learned, which can be noisy at the beginning of training, I would like to clarify how PI is guaranteed. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:** The paper is generally well-written and conveys the main insights well.  \n**Quality:** The amount of quality depends on how strong assumption #3 is.  \n**Novelty:** While PI and PE properties are separately studied in previous works, this work is the first paper that exploits the two properties simultaneously and explicitly.   \n**Reproducibility:** The source code is provided in the supplementary material to reproduce the results.  ",
            "summary_of_the_review": "I would like to initially vote for 6 (marginally above the acceptance threshold). After the authors' response to my concern and questions, I will make a final decision on the recommendation. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_JeYo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_JeYo"
        ]
    },
    {
        "id": "YgEbSk8tKgF",
        "original": null,
        "number": 2,
        "cdate": 1666585326074,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585326074,
        "tmdate": 1669358722867,
        "tddate": null,
        "forum": "OxNQXyZK-K8",
        "replyto": "OxNQXyZK-K8",
        "invitation": "ICLR.cc/2023/Conference/Paper2238/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on breaking the curse of dimensionality in multi-agent state space by exploiting the permutation invariance and permutation equivariance inductive biases. To achieve this, they proposed two implementations: Dynamic Permutation Network and Hyper Policy Network. A key property of this framework is that they only need to modify the input/output layer, leaving the backbone module unchanged. This property makes the work easy to add to other works. Finally, extensive experiments in SMAC, Google Football and MPE show some strength of this framework.",
            "strength_and_weaknesses": "**Strengths**\n\n1. The problem this paper considers is important. How to handle the exponentially increasing dimensionality of state space in MARL is critical and this paper provides a new method to solve it. \n2. The literature review is sufficient. Most previous works have been discussed and compared.\n3. This framework is well-motivated. To solve the curse of dimensionality in state space, using the properties of permutation invariance and equivariance in MARL might be a natural way. Though previous works have discussed these properties, this work has an advantage over others that it only needs to modify the input and output layer.\n\n**Weaknesses**\n\n1. The proposed method is not sound. (1) As discussed in Sec.2, Deep Set & GNN have limited representation capacity, due to the use of shared embedding. However, the proposed framework also uses a shared embedding $h_i$. In Sec.4.3, the hyper net $\\text{hp}_{\\text{in}}$ and module B are all shared. (2) In Sec.4.2, the observation of an entity chooses a weight matrix via probability. There is no guarantee that the entity can always choose the same weight matrix because the probability will change when this entity is in a different state. (3) HyperNet is also shared. What is the difference between $h(o_i,\\theta_h)^\\top\\cdot o_i$ and $f(o_i,\\theta_f)$?\n2. The empirical evaluation results can be improved. This work uses a complex method to match the observation and action belonging to the same entity. What if we just sort the entities according to distance from the focal agent? This might be a strong baseline. \n3. The results are not significant enough compared with baselines considering PI and PE properties, such as UPDeT-QMIX, in Figure 6. \n4. This paper does not provide any discussions of limitations. (1) Is there any observation space or action space that cannot be factored? (2) Do all actions in MARL belong to PI or PE? What if there is an action that can tie *two* enemies together with a rope? The entity-correlated action space might not be a general assumption. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to follow. The proposed framework provides a novel and pluggable way to exploit the properties of PI and PE to reduce the dimensionality of state space in MARL.",
            "summary_of_the_review": "This paper is interesting and the proposed method might be an easy way to be utilized to any other methods in the considered settings. However, the soundness and the empirical evaluations should be further verified. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_TTsq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_TTsq"
        ]
    },
    {
        "id": "ucbnG92AKP",
        "original": null,
        "number": 3,
        "cdate": 1666675572060,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675572060,
        "tmdate": 1666675572060,
        "tddate": null,
        "forum": "OxNQXyZK-K8",
        "replyto": "OxNQXyZK-K8",
        "invitation": "ICLR.cc/2023/Conference/Paper2238/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies permutation invariance (PI) and permutation equivariance (PE) for multi-agent reinforcement learning. Different from existing works which achieve PI and PE via shared embedding of graph nets, the authors proposed a hypernet-based architecture, which is referred to as Hyper Policy Network (HPN). With HPN, the authors built PI input and PE output modules which could be plugged into existing MARL architectures without modifying the backbone network. The proposed approach is evaluated on SMAC, Google Research Football and MPE. The results show that the proposed approach outperforms baseline in various tasks. \n",
            "strength_and_weaknesses": "### Strength: \n\n1. While PI and PE for RL and MARL are widely studied, the idea of using hyper-net to output weight for different input and thus achieve PI and PE are new and interesting. \n\n2. The reviewer appreciates that the proposed approach could be applied to existing architecture without changing the backbone. This is an advantage over existing graph-based PE and PI MARL approaches. \n\n3. It is impressive that the proposed approach outperforms baselines on many super-hard SMAC tasks. \n\n4. The paper is well-written and easy to follow.    \n\n\n### Weakness / Questions:\n\n1. The reviewer has concerns on the assumption that the structural information of observations and the actions\u2019 PI / PE property are available.  This is privileged information that is not used by baselines such as QMIX. This information may not be available in many real-world applications. For instance, suppose the observations are images or some feature vectors that are not interpretable. How do we apply the proposed approach? \n\n2. The reviewer has some concern regarding the scalability. Specifically, suppose there are 100 agents, does the hyper-net need to generate 100 different weights? \n\n3. While the paper highlights \u2018break the curse of dimensionality\u2019 and scalability as main contributions, the experiments only report results with few agents. For instance, in MPE, only six agents are considered. In contrast, baseline approaches such as PIC could actually scale to hundreds of agents. Results with more agents are needed to support the claims. \n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity:\nThe paper is well-written and easy to follow. \n\n### Quality:\nOverall, the paper is technically sound, but empirical results on settings with more agents are needed to support the claims about scalability. \n\n### Novelty:\nUsing hyper-nets to achieve PI and PE is novel and interesting.  \n\n### Reproducibility:\nThe code is provided and the hyper-parameters are detailed in the appendix. The reviewer thinks there is a high chance one could reproduce the results. \n\n",
            "summary_of_the_review": "In summary, the reviewer appreciates the proposed HPN, which nicely leverages the structural information of observation and builds the helpful inductive bias to achieve better performance. However, the reviewer thinks the limitations, such as assumption of the structural information of observation, should be more carefully discussed. In addition, empirical results on tasks with more agents are needed to support the claims.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_RFWq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_RFWq"
        ]
    },
    {
        "id": "enjSLnyL1B",
        "original": null,
        "number": 4,
        "cdate": 1666715751686,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666715751686,
        "tmdate": 1670267977143,
        "tddate": null,
        "forum": "OxNQXyZK-K8",
        "replyto": "OxNQXyZK-K8",
        "invitation": "ICLR.cc/2023/Conference/Paper2238/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper looks at the intersection of representation learning and MARL. The authors aim to design network architectures that are permutation invariant to reordering of agents in the input representation layer of a MARL network and also consider how to develop some output units that are only equivariant to permutations. The authors propose two architectures towards this end (DPN and HPN) with the idea of keeping the backbone intact, allowing for reuse across a variety of different MARL algorithms. The authors demonstrate significant gains in sample efficiency using HPN and DPN across popular MARL environments and algorithms including on SMAC, MPE, and GRF. ",
            "strength_and_weaknesses": "Strengths: \n- This paper is well aligned with the conference by demonstrating the value of improved representation learning in complex MARL domains. \n- The PI and PE inductive biases are indeed very common characteristics of MARL problems, making correctly encoding them a fundamental research direction. \n- The paper is clearly written and the proposed approach is clearly justified theoretically.\n- The experiments are very well done. The domains considered are large-scale and commonly used, relevant baselines are considered, important ablations are considered, and the approach is shown to be largely agnostic of the choice of MARL backbone. \n\nWeaknesses: \n- The DPN and HPN architectures are not tremendously novel and utilize well known concepts from the representation learning literature.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written in my opinion. The source code is provided. The experiments are very high quality. The novelty is not tremendously high, but I think it is a high impact use case. ",
            "summary_of_the_review": "As a reviewer, I found this paper to be a delight. It is clearly written, clearly motivated, and offers a focused yet potentially high impact solution. The experiments are also of extremely high caliber, really providing me with exactly what I would look for as a reviewer.  Ultimately, my consideration was more between strong accept and accept than it was considering that this paper should not be accepted. I believe it will make a nice contribution to the conference and believe it is likely to have a high impact on this subject area. My only concern, which is why I went with accept, is that the novelty of the proposed approach is really not that high in light of past work considering these topics in representation learning. However, I definitely think that this paper makes a strong contribution to the MARL community. \n\nUpdate After Author Feedback: \n\nI agree with the characterization provided by the authors of the source of novelty in their contribution and believe it is a nice addition to the community. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_ZC3P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2238/Reviewer_ZC3P"
        ]
    }
]