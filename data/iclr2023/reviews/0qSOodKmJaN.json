[
    {
        "id": "_M68u3Ztqf",
        "original": null,
        "number": 1,
        "cdate": 1666108001554,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666108001554,
        "tmdate": 1666108160993,
        "tddate": null,
        "forum": "0qSOodKmJaN",
        "replyto": "0qSOodKmJaN",
        "invitation": "ICLR.cc/2023/Conference/Paper1988/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes sequence likelihood calibration (SLiC) for conditional language generation. Their proposal includes a first stage where candidates are generated from a fine-tuned model, and a second one, where they calibrate the previous model by continuing training it with a new objective that aims to align candidates\u2019 sequence likelihoods by similarity to the target sequence in the model\u2019s latent space. They perform experiments on abstractive summarization, question answering, and data-to-text generation tasks. ",
            "strength_and_weaknesses": "**Strengths**\n\n* The motivation is clear, the paper is well written and is easy to follow.\n* The proposed method does not directly optimize an evaluation metric (e.g., ROUGE), and thus it\u2019s more likely to actually improve quality rather than exploiting fragilities in the evaluation metrics.\n* SLiC seems to work well without beam size optimization and length normalization.  \n\n**Weaknesses**\n\n* I\u2019m assuming that you\u2019re using your proposed similarity function for all the experiments, excluding the ablation studies in $\\S3.3$, where you also experiment with ROUGE. First, I think you should clarify that in the paper. Since the ablation studies appear before everything else, the \u201csimple recipe\u201d of that section could include the similarity function to use. Second, Table 1 suggests similar performance for both ROUGE and your method, and thus I\u2019d be interested in seeing a more extensive comparison of these approaches. \n\n**Minor comments/suggestions**\n\n* For neural machine translation, specifically, there are several works proposing alternative decoding methods that try to generate high quality outputs, related to the approach of Lee et al. (2021), discussed in $\\S4.2$, which I think are relevant for your work. Some of them are [1], [2], [3], and [4]. Besides, related to the work of Edunov et al. (2018), discussed in $\\S4.3$, is [5] and [6]. \n* In $\\S2.2.$, you should explicitly say which one \u201cis the contrastive loss used in BRIO (Liu et al., 2022).\u201d\n\n**Other questions**\n\n* Is there any reason to vary the hyperparameters between groups in Table 1? In particular, I see in App. C that the loss you used is different (sometimes *reward*, sometimes *rank*). \n* How does your method compare to common approaches for conditional language generation in terms of memory consumption and training time? The paper would benefit from such analysis. \n\n[1] Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation, Eikema and Aziz, COLING 2020\n\n[2] Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models, Sumanta Bhattacharyya et al., ACL 2021\n\n[3] Quality-Aware Decoding for Neural Machine Translation, Fernandes et al., NAACL 2022\n\n[4] High Quality Rather than High Model Probability: Minimum Bayes Risk Decoding with Neural Metrics, Freitag et al., TACL 2022\n\n[5] Beyond BLEU: training neural machine translation with semantic similarity, Wieting et al., ACL 2019\n\n[6] Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation, Kiegeland and Kreutzer, NAACL 2021. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** The paper is well organized and clear. \n\n**Quality.** See Strengths/Weakness section above. \n\n**Novelty.** The method is related to the work of Liu et al. (2022) but the proposed similarity function appears to be novel.\n\n**Reproducibility.** I believe there is no supplementary material/code. Are you planning to release the code?\n",
            "summary_of_the_review": "The paper addresses an important issue with conditional language generation models, that of uncalibrated sequence likelihood: for a given context, they are often trained with a single target sequence, and thus they lack supervision to compare (high probability) plausible hypotheses. The proposed method is interesting and the authors perform experiments that validate its applicability on different conditional language generation tasks. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_JpRY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_JpRY"
        ]
    },
    {
        "id": "RJdg-UPrtE",
        "original": null,
        "number": 2,
        "cdate": 1666253303009,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666253303009,
        "tmdate": 1666253303009,
        "tddate": null,
        "forum": "0qSOodKmJaN",
        "replyto": "0qSOodKmJaN",
        "invitation": "ICLR.cc/2023/Conference/Paper1988/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "To tackle the issue of uncalibrated sequence likelihood, this paper proposes a new sequence likelihood calibration(SLiC) stage, which extends the common paradigm of pretraining and finetuning. The specific method is to calibrate with KL divergence and low rank after selecting the checkpoint of finetuned model by perplexity and decoding candidates with beam search. \n\nWith SLiC, decoding candidates\u2019 quality significantly improves regardless of the decoding method, without showing any sign of diminishing returns with model scale, and former decoding heuristics will be never used any more. Furthermore, this paper proposes a novel calibration similarity metric between model decodes and targets, which is much better than the existing external metrics. ",
            "strength_and_weaknesses": "Strengths:\n\n- The contributions of the SLiC are important, and do not exist in prior works. Besides proposing the SLiC, the authors also proposed a novel calibration similarity metric and used many past outstanding works as candidate decoding methods.\n\n- Also, calibration benefits persist as model sizes scale up, so it has great potential for models plagued by former approaches which shows diminishing by scaling up. Also, small models can add calibration step to outperform larger ones. length normalization has minimal effect on calibrated models.\n\n- Calibrated models do not require decoding heuristics and more. Only with the SLiC, the model reaches SOTA result and even better than the model with decoding heuristics, and such heuristics has minimal effect on calibrated models. \n\n- Extensive experiments have been conducted to validate the effectiveness and relevance of the proposed method. Also, there are a lot of experiments in ablation study to get a simple and effective recipe for training.\n\n\nWeaknesses:\n\n- (1) typo in page 14, \u201cWebNLG-en\u201d paragraph, \u201cdata inputs in the from of sets\u201d -> \u201cdata inputs in the form of sets\u201d (2) typo in page 14, \u201cCommonGen\u201d paragraph, \u201cintroduces a tak\u201d -> \u201cintroduces a task\u201d\n\n- The experimentation section mainly convinces me that this architecture is good for application. However, this work lacks of explanation on the reason of the choice of calibration loss, regularization loss, candidates decoding method, etc.\n\n- Since this paper is highly theoretical and original. However, it suffers the problem that it does not make sense to many details in the method chapter. For example, as for the calibration loss and regularization loss, the literal part seems only notation, and lack of the reason for why taking these methods and the advantages of them. (Maybe it is included in the experiment part. However, I do think that it should also be mentioned in the method part.) \n\n- Lack introduction of some notations. For example, I haven't found out what theta means so far. Although it is default to represent model parameters, I think it should be explained. What\u2019s more, due to the rich content, this paper involves large amounts of parameters. Therefore, I think it is a good idea to explain the parameters in a chart. Maybe it can be appended to the appendix. In this way, the readers can follow the authors more easily.\n\n- The description of MLE method and its related works occupied a little too much space in introduction, while the motivation to proposed method was little.\n\n- In the section of ABLATION STUDIES OF CALIBRATION, the authors show us the improvement compared with fine-tuned models,but without the comparison between SLic and the fine-tuned model using the mentioned effective heuristics or solutions.\n\n-  The authors propose the Calibration stage after Pre-train and Fine-tune(MLE) stage. Since fig. 3 gives the inference compute trade-off between fine-tuned only and calibrated models, the  comparison of the running time and speed between fine-tuned only and calibrated in Table 3 is lacked.\n\nSuggestions:\n\n- The experiment results of the proposed method should be in bold.\n\n- The conclusion part lacks the description of the deficiencies and the prospects for future improvements.\n\nQuestions:\n\n- There are in total 3 hyperparameters: \u03b2 in calibration\uff0clr as learning rate and \u03bb as regularization strength. To simplify the training process, \u03b2 and lr\u2217\u03bb are set empirically, making the process tedious, and how the values are set in the paper?",
            "clarity,_quality,_novelty_and_reproducibility": "Good",
            "summary_of_the_review": "The paper proposes a novel stage called sequence likelihood calibration after the pretraining and fine-tuning stages for conditional language generation. It seems that this method has not been used in prior works and with such stage the model can outperform the SOTA results without concerning about the diminishing problems. Also the entire paper is very well-written and comprehensible, and the experimentation in this paper are quite rich.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_o62J"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_o62J"
        ]
    },
    {
        "id": "Rjg5ylzOXTK",
        "original": null,
        "number": 3,
        "cdate": 1666504695289,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666504695289,
        "tmdate": 1669040767287,
        "tddate": null,
        "forum": "0qSOodKmJaN",
        "replyto": "0qSOodKmJaN",
        "invitation": "ICLR.cc/2023/Conference/Paper1988/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Remarking that language models can assign high probability to low \u201cquality\u201d outputs, this paper proposes \u201csequence likelihood calibration\u201d (SLiC) as a solution. With SLiC, \u201cdecoding heuristics become unnecessary\u201d and \u201cquality significantly improves.\u201d The claims are empirically supported by experiments on abstractive summarization, question generation, abstractive question answering, and data-to-text generation, with results that \u201cexceed or match SOTA results.\u201d\n\nIn more detail, the high-level idea proceeds in two stages. In the first stage, for each training instance, an initial model is used to sample m candidates (a variety of decoding methods are compared, including beam search and nucleus sampling). In the second stage, the initial model is further optimised using a combination of two losses:\n\nA \u201ccalibration\u201d loss which aims to align the sequence likelihood with the similarity to the reference target sequence. Four such losses are considered, including a ranking loss, margin loss, listwise ranking loss, and expected reward. All losses rely on a notion of similarity of a candidate sequence to the reference sequence, for which a variation of BERTScore is proposed (S2.1).\nA \u201cregularization\u201d loss which penalizes deviations from the token-level confidences from the stage-one model. The cross-entropy to the reference labels and the KL divergence from the stage-one model predictive distribution are both considered.\n\nOverall, beam search using the rank \u201ccalibration\u201d loss with KL divergence \u201cregularization\u201d loss are found to work best.",
            "strength_and_weaknesses": "Overall, it is notable that the proposed approach yields models that do not appear to require decoding heuristics; this suggests that the calibration loss is doing something useful. Figure 3 is also fairly convincing in this respect, as it shows a distinct difference between the vanilla model and the calibrated one when further decoding samples are used (consistent improvement for the calibrated model). However, the experiments overall are not entirely convincing, since in several cases the degree of improvement over the baselines is marginal, while the proposed model is larger than the baselines in terms of # of parameters (2B). So it\u2019s not clear that it\u2019s the new calibration scheme that\u2019s responsible for the improvement in these cases.\n\nThe scoring function (S2.1) is a key element of the proposal. It\u2019s stated that \u201ccompared to using external metrics, [...] it differs from the metrics we evaluate the generation systems with and mitigates the risk of directly optimising towards imperfect metrics.\u201d However, the proposed similarity is related to both ROUGE and BERTScore, and so it\u2019s not clear there isn\u2019t some bias towards better performance on the target metrics.\n\nFinally, I would have liked to see probabilistic calibration addressed somewhere. Does the proposed calibration loss actually lead to more meaningful probability estimates? This could be measured at the token-level or on other events (cf https://papers.nips.cc/paper/2015/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf)",
            "clarity,_quality,_novelty_and_reproducibility": "Regarding the presentation, although the approach itself is quite straightforward, I found it difficult to follow the narrative of the paper. At various points, such as the introduction of the calibration losses, many options are considered without proper motivation or discussion of relative merits to justify their inclusion in the experiments. I found the use of \u201cTL;DR;\u201d blocks at the end of certain chapters to be out-of-place; it would have been better to provide this kind of information at the beginning of the sections, ideally framed as research questions.\n\nOn related work, the approach is conceptually similar to knowledge distillation, and would benefit from comparing and contrasting both the original Hinton paper (when it comes to the KL regularization loss) and the sequence-level extension (https://arxiv.org/abs/1606.07947) when it comes to the use of sequence-level training. Some other relevant work is not cited, such as papers in non-autoregressive decoding where it is common to train on decoded outputs from an initial \u201cteacher\u201d model.\n\nOn reproducibility, the appendix provides many details about hyperparameter choices. On the other hand, there\u2019s no obvious intent to release code, and some of the model sizes considered are prohibitive in terms of compute costs for many researchers.\n\nIn Figure 3, what is the \u201cscore\u201d in the y-axis?",
            "summary_of_the_review": "There are some good ideas here but the presentation could be improved and the experimental results are lackluster. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_YBaL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1988/Reviewer_YBaL"
        ]
    }
]