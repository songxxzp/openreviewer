[
    {
        "id": "Hkj8DSbudz",
        "original": null,
        "number": 1,
        "cdate": 1666544096927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666544096927,
        "tmdate": 1666544096927,
        "tddate": null,
        "forum": "PvLnIaJbt9",
        "replyto": "PvLnIaJbt9",
        "invitation": "ICLR.cc/2023/Conference/Paper4707/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces MAP-D, a novel approach to data archeology that leverages training dynamics to uncover a dataset's salient meta-data. In contrast to already existing approaches, MAP-D enables the simultaneous auditing of a dataset across multiple dimensions (e.g., typical data, corrupted inputs, etc).",
            "strength_and_weaknesses": "The paper's main strengths are the novelty, simplicity, and effectiveness of MAP-D. It is also reasonably well-written and organized.\n\nThe paper's main weakness is the lack of an organic, real-world dataset on which to compare MAP-D against a high-quality, human-annotated test set. The probes described in section 2.2 (i.e., typical, atypical, random labels, random input & labels, and corrupted inputs) are intuitive and easy to compute w/o human annotations. However, understanding MAP-D's performance against a human-curated test set would make the paper significantly more compelling, while also highlighting its practical strengths and weaknesses in a real-world scenario.",
            "clarity,_quality,_novelty_and_reproducibility": "The approach proposed in the paper appear to be novel. The paper is reasonably well-written and organized. However, it could be further improved by ...\n(1) making Figure 3.a/b/c readable by using six or nine graphs instead the current three, so that the curves are not so \"squashed\" against each other; \n(2) adding a paragraph to discuss in-depth the insights of what happens in Figure 3.d/e/f; \n(3) expanding the last paragraph before \"3.3\" to a comprehensive discussion of the insight from Fig. 4; \n(4) emphasizing earlier (beginning with the abstract!) MAP-D's impact on noise correction, prioritizing points for training, and identifying minority-group samples (in particular, the last two should be brought in the main paper, rather than relegated to appendices). The paper should find a way to summarize (in a compelling manner) across all 6 datasets, rather than just the two CIFARs. To save space in the main paper, the author(s) could shorten the introduction and move Figure 6 in an appendix (after all, its results could be summarize in one sentence, with the interested reader referred to the appropriate appendix). ",
            "summary_of_the_review": "The paper introduces a novel, simple, effective approach to an important problem: meta-data archeology. Overall, it is well written and organized, and it makes a strong empirical case. The paper could be further improved by (i) adding more in-depth discussions of the results, and (ii) further emphasize MAP-DF's impact on noise correction, prioritizing points for training, and identifying minority-group samples.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/a",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_3RHf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_3RHf"
        ]
    },
    {
        "id": "N4m0p6Z6E9",
        "original": null,
        "number": 2,
        "cdate": 1666587712323,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666587712323,
        "tmdate": 1668715700287,
        "tddate": null,
        "forum": "PvLnIaJbt9",
        "replyto": "PvLnIaJbt9",
        "invitation": "ICLR.cc/2023/Conference/Paper4707/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "**Note: Score updated from 6 to 8 after authors' response.**\n\nThe authors propose a data sample annotation method they term Metatdata Archaeology via Probe Dynamics (MAP-D). In this method, one first creates data subsets with known properties (\u201cprobes\u201d), such as corrupted, mislabeled, and atypical/typical samples. One then checks whether other samples have these properties by performing kNN classification on the time series of losses of unmodified data samples, with the time series of losses of the probes serving as the cluster labels. The authors apply MAP-D to six different image classification datasets and find that MAP-D performs similarly to SOTA baselines for identifying and correcting mislabeled examples, and can be used to speed up training by prioritizing training samples.",
            "strength_and_weaknesses": "**Strengths**\n\nSimple method\n\nConvincing results; method seems promising for multiple different applications\n\nWell-written and mostly easy to follow\n\n**Weaknesses**\n\nTraining speed-ups not measured in wall clock time\n\nA few clarity issues, mostly regarding explanation of the noise correction methodology\n\nSome of the more important content is in the Appendix, and some of what I would consider follow-up experiments are presented in the main text",
            "clarity,_quality,_novelty_and_reproducibility": "**Measuring Training Speed-Ups**\n\nSpeedups in units of steps or epochs do not consistently yield real-world (wall-clock) speedups. I think it would significantly strengthen the work if the authors demonstrated a wall-clock time improvement using their method for prioritized training, instead of just a step-wise speedup. At the very least, be specific about the units of speedup (e.g. \"10x stepwise speedup\" instead of \"10x speedup\")\n\n**Clarity and Organization**\n\nRelated work section is thorough, but may want to include the recently-published Sorscher et al., 2022: Beyond neural scaling laws.\n\nThe text annotations in Figure 3 are difficult to read. I recommend enlarging them.\n\nThe main text makes it seem like Figures 5 and 6 are based on using the binary (argmax) method for label noise correction with MAP-D. It requires reading the appendix and comparing Appendix Figure 8 to Figures 6 and 6 to ascertain that the values in Figures 5 and 6 are obtained using the probabilistic method. I did not notice the probabilistic method mentioned in the main text at all. Please clarify this.\n\nI think the noise correction correction protocol could be a little bit better explained in the main text. Specifically, does \u201cnumber of epochs before noise correction\u201d mean that the model is pretrained for N epochs (105 or 10 in the experiments here) in addition to the normal training duration, or that the total training duration is identical unchanged and the noise correction does not begin until N epochs into training?\n\nThe sample prioritization results are strong. Given that they\u2019re one of the key results (and mentioned in the abstract and introduction), I think it undersells them to not describe the results, and to mention in passing at the beginning of the results section simply that they\u2019re presented in the appendix. I understand space is limited, but I would suggest at least including a brief summary of the results in a dedicated subsection\u2014it could be as little as one or two sentences.\n\nI think some of the main text figures could be moved to the Appendix: specifically, Figure 3d-h, one of Figure 4a&b or Figure 4c&d, and Figure 6. This would allow moving the sample prioritization results and full related work section to the main text, as well as permitting more explanation and discussion of results.\n",
            "summary_of_the_review": "Straightforward method that shows promise for multiple different applications. I have a few suggestions to improve clarity and one to more convincingly measure a claimed training speed-up, but overall great work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_Kiey"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_Kiey"
        ]
    },
    {
        "id": "EZVgqYy2M-9",
        "original": null,
        "number": 3,
        "cdate": 1666594953204,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594953204,
        "tmdate": 1666594953204,
        "tddate": null,
        "forum": "PvLnIaJbt9",
        "replyto": "PvLnIaJbt9",
        "invitation": "ICLR.cc/2023/Conference/Paper4707/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes Metadata Archaeology, a unifying and general framework for uncovering latent metadata categories.\nThis paper introduces and validate the approach of Metadata Archaeology via Probe Dynamics (MAP-D): leveraging the training dynamics of curated data subsets called probe suites to infer other examples\u2019 metadata.\nThis paper shows how MAP-D could be leveraged to audit large-scale datasets or debug model training, with negligible added cost. This is in contrast to prior work which presents a siloed treatment of different data properties.\nThe authors use MAP-D to identify and correct mislabeled examples in a dataset. Despite its simplicity, MAP-D is on-par with far more sophisticated methods, while enabling natural extension to an arbitrary number of modes.\nThe authors show how to use MAP-D to identify minority group samples, or surface examples for data-efficient prioritized training.",
            "strength_and_weaknesses": "Pros: \n1. The motivation is clear. \n2. The paper is well-written and organized. \nCons: \n1. The main contributions are not clear. \n2. Some related works are missing, e.g., 3D Face Reconstruction from A Single Image Assisted by 2D Face Images in the Wild.",
            "clarity,_quality,_novelty_and_reproducibility": "See Strength And Weaknesses",
            "summary_of_the_review": "See Strength And Weaknesses",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_KmwB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_KmwB"
        ]
    },
    {
        "id": "RgV6QNT3VEh",
        "original": null,
        "number": 4,
        "cdate": 1666677266404,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666677266404,
        "tmdate": 1666677266404,
        "tddate": null,
        "forum": "PvLnIaJbt9",
        "replyto": "PvLnIaJbt9",
        "invitation": "ICLR.cc/2023/Conference/Paper4707/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper provides a method to infer various meta-data features of datasets such as typical/atypical data points, noisy labels, noisy and out-of-distribution data points. ",
            "strength_and_weaknesses": "*Strengths*:\n1. The paper proposes, to the best of my knowledge, the first method which jointly infers multiple meta-data features of a dataset. \n2. Simplicity: The method is simple and intuitive. \n3. Paper is very well-written. \n\n*Weaknesses*:\n1. While I do appreciate the simplicity of the methods, it is hard to believe that the method performs on par with state-of-the-art label correction methods. I believe this can only be the case when the label corruptions occur uniformly at random, which might very well not be the case, as shown by many recent paper on noisy label correction. Moreover, the papers that the authors compare with are not the state-of-the-art since methods like Confident learning proposed later outperform the methods the authors compare with. \n2. The method does not seem to detect out-of-distribution samples very well (Fig. 4 (d)). I would like the authors to explain the underwhelming performance. \n3. It would be nice and instructive to discuss failure of the method in detecting these meta-data features. Like the authors mention in the limitations, the assumption that the learning dynamics.\n4. The authors mention experiments on two different kinds on ResNet models, but (1) I do not see results from both the models, (2) experimenting with different model architectures might make for a stronger experimental result, showing the method's applicability beyond ResNet architectures. \n\n*Questions*\n1. How are out-of-distribution probes generated? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and very well written. The paper solves a novel problem. It seems to be reproducible if the code is released upon acceptance of the paper.",
            "summary_of_the_review": "I like the paper, I think it is novel, simple, intuitive, well-written with strong experimental results, but can benefit from some more experiments and clarifications. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_o59Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4707/Reviewer_o59Z"
        ]
    }
]