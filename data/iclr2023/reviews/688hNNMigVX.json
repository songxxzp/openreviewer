[
    {
        "id": "aoHGXy5R-w6",
        "original": null,
        "number": 1,
        "cdate": 1666357594020,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666357594020,
        "tmdate": 1666357594020,
        "tddate": null,
        "forum": "688hNNMigVX",
        "replyto": "688hNNMigVX",
        "invitation": "ICLR.cc/2023/Conference/Paper6357/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper firstly specifies the fact that AutoFE is underappreciated in the AutoML pipeline tailored to tabular data nowadays, and summarizes that previous AutoFE work faced two major drawbacks of unobserved data and lack of transferability. To tackle these problems, this paper proposes a novel RL-based AutoFE framework(called FETCH) by observing the behavior patterns of human experts, which is equipped with a data-driven MDP setup in its policy network. The key idea is to consider each table as a set of features and incorporate the table into the MDP state. Then FETCH learns how to map from data to feature engineering actions. Experiments show that FETCH outperforms other SOTA or popular feature engineering baselines and supports transferability by pre-training.",
            "strength_and_weaknesses": "Strengths:\n1. The proposed framework is novel, simple and effective, which is easily to follow. The pre-training technique seems like a new schema in the tabular data mining field. \n2. The paper is well-written, and the related work is covered well.\n3. The experiments are quite comprehensive. The authors also show that pre-training FETCH on more datasets results in additional performance gains, which further strengthens the claim of the model's transferability.\n\nWeaknesses:\n1. It is nice that the authors include 27 datasets as a benchmark and demonstrate that FETCH is much better than the other AutoFE baselines in most cases. However, I don't quite sure why the authors are comparing it to popular open-source AutoML packages (i.e. AutoSklearn and AutoGluon)? After all, these are two different domains. Is it to prove that AutoFE can power AutoML? Maybe I'm missing it, and please clarify.\n2. Section 4.4 only covers 3 comparison algorithms, it would be better to add the enhancement effect on more algorithms such as LightGBM and CatBoost, which will be more convincing for the adaptability of FETCH on various algorithms.\n3. FETCH seems to have been pre-trained on only 5 datasets, which seems somewhat simple. It would be preferable to have pre-training results on a larger number of datasets.\n4. The theoretical analysis is a bit lacking. It is hoped that a theoretical analysis of effectiveness and experimental results can be provided as space permits. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is overall well-written and clear. The code in the supplementary material seems to be well-organized and I believe it works as the paper claims, although I have not actually verified it.\n\n",
            "summary_of_the_review": "The idea of learning a data-driven policy network is well-motivated and novel, and the experiments are compelling.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_B9Km"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_B9Km"
        ]
    },
    {
        "id": "YboF_7p_lA8",
        "original": null,
        "number": 2,
        "cdate": 1666558200726,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666558200726,
        "tmdate": 1666558200726,
        "tddate": null,
        "forum": "688hNNMigVX",
        "replyto": "688hNNMigVX",
        "invitation": "ICLR.cc/2023/Conference/Paper6357/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Automated feature engineering is another needed ingredient in 'data science as a service.' Prior work focuses either on feature selection or feature engineering that is independent on the underlying data. The authors propose an RL algorithm that directly transforms data by applying a sequence of unary or binary operations. \n",
            "strength_and_weaknesses": "Strengths: \nThe idea of using data directly is novel. \nThe use of data enables transfer learning. \n\nWeaknesses: \nScalability is questionable. There is no deep discussion on computational times and comparisons with other algorithms. \nExplainability/interpretability is questionable. To the contrary, the resulting training data is not interpretable. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is in general well written. There are a few loose points but nothing major. \nIt is easy to read and comprehend. \nReproducibility is questionable. There are not many details about how to reproduce the results. ",
            "summary_of_the_review": "The underlying idea of using the actual data in the RL setting is very novel. It is a substantial contribution. In my opinion it outweighs deficiencies in the work. \nOnce the RL is established (the state space), everything else is standard (the network, algorithm). \n\nThe authors don't mention feature selection (forward/backward selection, etc) which is perhaps injustice. Maybe feature selection should also be benchmarks (perhaps autoML methods include them). \n\nMinor remarks: \nPage 1: next to the last paragraph states that there is significant prior autoFE work. This statement contradicts some prior statements stating there is not a lot of work in this area. \nHyperparameters being fixed is questionable since different subset of features definitely dictate possible different hyperparameters. I understand that this inclusion would be a significant complication and thus I don't take this against the authors. \nPage 3: 'specified feature x' excludes binary operations. This statement should be reworded. \nPage 4: weightheight^2 should be weightheight$^2$",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_Y4Ri"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_Y4Ri"
        ]
    },
    {
        "id": "O_96yHpG7dq",
        "original": null,
        "number": 3,
        "cdate": 1666696313771,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696313771,
        "tmdate": 1666696313771,
        "tddate": null,
        "forum": "688hNNMigVX",
        "replyto": "688hNNMigVX",
        "invitation": "ICLR.cc/2023/Conference/Paper6357/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a first of its kind architecture framework for automated feature engineering called Fetch, a system based on brand new data driven Markov decision process. The authors identify critical gaps by stating the current methods for AutoFe are insufficient when it comes resembling human effort in handling datasets as the underlying Markov decision setup is different i.e. more based on trial and error, which leads to poor generalization across datasets and higher computational costs. The new method also has a key element of transferability, which is basically the ability to enable feature engineering on new datasets using prior policy networks trained on previous datasets, without the need for additional data exploration. The authors present evidence that Fetch is superior to the existing state of the art automated feature engineering methods such as Random, DFS, AutoFeat, NFS, DIFER as well as AutoML methods such as AutoSklearn and AutoGluon. The method is also tested for transferability by application on several datasets. \n\nThe authors argue that the approach comes very close to mimicking human experts when it comes to handling new datasets when it comes to transferring experience. ",
            "strength_and_weaknesses": "Strengths: \n1. One of the key strengths of this paper is its ability to provide transferability between datasets which previous methods have not been able to provide. \n2. The method is highly flexible as it has been applied on different datasets as well different ML models. \n3. Overall there is sound discussion relevant work, gap analysis to find opportunity of development, strong mathematical rigour and experimental setup, evaluation and analysis. \n\n\nWeaknesses: \n1. The authors declare that to the best of their knowledge there aren't any autoFE/autoML workarounds for managing tabular data to accomplish transferability. However this could be supported by a stronger statement that can more concretely say if such methods exist or not by clearly stating a comprehensive survey of analysis did not yield any methods. \n2. This method is specifically geared towards tabular datasets. While tabular datasets prevail in several key applications, it would be interesting to know how this method applies/does not apply to any other form of datasets (eg. images, speech, unstructured datasets). At least there could be some discussion on consideration, if not a full scale evaluation.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty: \n1. Paper proposes a new form of markov decision process to generate features. Previous methods take number of features and only update using sequences of previous actions, iteratively. Whereas Fetch provides Feature engineering actions and constructions actions, instead of features, iteratively based on the newly generated datasets (features). \n2. According to this paper, Previous methods for AutoFE have never explored transferability between datasets, which has been done by this method.\n\n\nClarity & Quality: The paper has high clarity with explicit background provided and methods explained with sufficient depth both in terms of mathematical equations, datasets and analysis of results. There is further in-depth explanation in the appendix section around usage of material and datasets which is crystal clear. \n\n\nReproducibility: The method has been extensively tested on publicly available datasets which are linked. Algorithm and methods have been provided as well. The paper states that all experiments have been run with open source code provided.   \n",
            "summary_of_the_review": "I propose that we accept this paper on the basis of its merits around developing a new AutoFE method based on a novel markov decision process which not only is superior to the existing state of the art in terms of performance but also has a unique feature of transferability. Both strong points are well argued and evidenced in the paper throughout with sufficient gap analysis around opportunity areas, discussion of background and related work, strong mathematical rigor and sound experimental design setup, with thorough data analysis, discussion of evaluation and results. Although the work is limited to tabular data there is thoughtful coverage on several popular datasets including regression and classification examples and comparison to other AutoFE models and coverage across several ML models. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None. ",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_vD6x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6357/Reviewer_vD6x"
        ]
    }
]