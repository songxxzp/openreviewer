[
    {
        "id": "9w5_FDf2AfU",
        "original": null,
        "number": 1,
        "cdate": 1666600963320,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666600963320,
        "tmdate": 1666600999179,
        "tddate": null,
        "forum": "Mpa3tRJFBb",
        "replyto": "Mpa3tRJFBb",
        "invitation": "ICLR.cc/2023/Conference/Paper3204/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the impact of model initialization(random or pre-trained) on federated optimization methods. The experiments show that starting federated learning from a pre-trained initialization reduces the effect of both data and system heterogeneity. The experiments also show that the pre-trained initialization reduces the training time.",
            "strength_and_weaknesses": "Strength:\n\n1)The paper is well written, and the experiments are sufficient.\n\n2)The paper finds that starting federated learning from a pre-trained initialization reduces the effect of both data and system heterogeneity.\n\n3)The experiments show that the pre-trained initialization leads to communication savings and reduces the overall training time in federated learning.\n\n4)The findings in this paper suggest directions for future related work.\n\nWeaknesses:\n\n1)In Figure 1 and Figure 5, what is the representation of the curve radian?\n\n2)The \u03b1 in Figure 2 is not explained in the main paper.\n\n3)Does the model pre-trained on public data introduce security issues to users? How do we make trade-offs between security and performance?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized but the presentation has minor details that could be improved.\n\nThe paper appears to be technically sound and the experimental results convincingly support the main claims.\n\nThe paper contributes some new ideas.\n\nThe author has submitted the code and the experimental details are sufficient. The contribution is clearly presented and the experimental results are thoroughly executed. I would tend to accept this paper.\n",
            "summary_of_the_review": "The paper is significant to model initialization(random or pre-trained) on federated optimization methods. The contribution is clearly presented and the experimental results are thoroughly executed. I would tend to accept this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_EYvh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_EYvh"
        ]
    },
    {
        "id": "ceM3kYmN7H",
        "original": null,
        "number": 2,
        "cdate": 1666672089774,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672089774,
        "tmdate": 1668883014825,
        "tddate": null,
        "forum": "Mpa3tRJFBb",
        "replyto": "Mpa3tRJFBb",
        "invitation": "ICLR.cc/2023/Conference/Paper3204/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors study federated learning starting from pre-trained models in both the image and text setting. They study a wide range of FL algorithms. Some key observations are that (a) the gap of iid to non-iid closes (b) ranking of FL algorithms is different under pre-training (c) effect of heterogneity are not severed. An investigation of how pre-training helps under heterogeneity is performed. \n",
            "strength_and_weaknesses": "Strengths:\n-The evaluations are extensive covering a wide array of tasks, datasets, and federated optimization settings\n-The observations are potentially important: methods addressing heterogeneity may not be relevant in cases where pre-trained models can be used\n\nNo substantial weakness are noted \n\nSome Comments: \n- The effect of the pre-trained model is not heavily studied. It would be interesting to know if better pre-trained models lead to better results. \n- I would like to see some discussion on how the learning rates selected are different (or same) in the pre-training/random setting\n- It would be interesting to see the effect on more distant combinations of pre-training and target data. For example imagenet->medical/satellite image data\n- In Chen et al it was shown that FedAVG can benefit even from pre-training on synthetic data. It would be interesting to see if such approaches (and the change in ranking of algos) hold for the algorithms evaluated here.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The article is well written, the observations are clearly stated and some of the limitations are highlighted. Code to reproduce the experiments is also provided",
            "summary_of_the_review": "The paper has a number of important findings for guiding FL research and practice. The evaluations are thoroughly done across a wide range of datasets and tasks. Insights into the observed effects are also provided. \n\nPost-Rebuttal: I have read the rebuttal and response to other authors. My review and score stand.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_Kusi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_Kusi"
        ]
    },
    {
        "id": "qj4j9Eg9k1b",
        "original": null,
        "number": 3,
        "cdate": 1666699244133,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699244133,
        "tmdate": 1671018078660,
        "tddate": null,
        "forum": "Mpa3tRJFBb",
        "replyto": "Mpa3tRJFBb",
        "invitation": "ICLR.cc/2023/Conference/Paper3204/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies the effect of using pre-trained neural network weights on federated optimization. Several combinations of server and client optimizers are considered in combination with 2 different models for vision and language tasks. It was shown that pre-trained initialization reduces the negative effects of data and systems heterogeneity on training convergence and changes the ranking of optimization methods.",
            "strength_and_weaknesses": "## Strengths\n\n**S1.** Thorough and extensive experimental evaluation of different optimization aspects which may be useful to the field of federated learning.\n\n**S2.** Several drawn conclusions are novel and can be interesting for the community.\n\n## Weaknesses\n\n**W1.** The concept of using pre-trained weights (in federated deep learning) is not novel on its own. Some of the ideas were explored in previous works.\n\n**W2.** Some important experimental details are missing. Namely, it is not clear how hyper-parameter tuning was performed. What clients/data were used for tuning step sizes, etc (the ranges also seem very limited)? It would be very helpful to show how pre-trained initialization affects the performance of the methods for different combinations of parameters (e.g., like it was done with heatmaps in the Adaptive FedOpt paper).  What kind of random initialization was used in the experiments? Prior literature showed that various strategies can lead to different results in the centralized case.\n\nPlease correct me, if I missed these details.\n\n**W3.** The thesis \n> Starting from a pre-trained model signi\ufb01cantly reduces the difference between having non IID vs IID data at clients.\n\nis not well-supported (or inaccurately stated), in my view. It is not fully clear what is meant by IID data splits for naturally partitioned federated datasets in the paper. Was the data somehow reallocated between the same amount of clients or simply centralized training was performed? The latter case would require different wording in my view as it studies not the difference between non-IID and IID but rather federated and centralized cases. To properly show the effect of using the pre-trained model for a level of non IIDness one ideally needs to vary the level of heterogeneity for the same problem.\n\n**W4.** Some of the Section 5 conclusions are questionable and doubtful. For example, the Gradient Diversity (GD) of client updates is lower for the pre-trained model, while the original paper by Yin et al., 2017 argues that better convergence is achieved for higher GD.  As far as I understand the plots show results of single runs which is not very reliable. Cosine similarity behavior looks quite random and similar for different initialization, apart from maybe the start. The connection to theory is not really convincing.\n\nI would also like to ask how exactly the Hessian matrix was computed.",
            "clarity,_quality,_novelty_and_reproducibility": "1. The paper writing is clear and of good quality. The contributions are quite original but the comparison to prior works needs to be more detailed for the final publication. For instance, why the previous papers did not find that pre-training does not help to tackle heterogeneity issue?\n\n2. I would like to ask why these particular deep learning models were chosen. In previous works simpler CNNs were used for FEMNIST and LSTM-based models for Stackoverflow. The author's choice makes it a bit harder to compare the results to prior works. Although, this is not critical.\n\n3. It would be helpful to briefly and explicitly mention the client updates formulas in the main text or Appendix.\n\n**Minor**\n\n4. Links (references, figures, appendix) are not clickable, and the Sections outline navigation is not working properly for PDF readers.\n\n5. Typo: on page 7 $\\delta_i$ is first used instead of $\\Delta_i$",
            "summary_of_the_review": "Overall, the paper represents a piece of good-quality research. I think that there are enough insights for publication. There is also a potential for an increase in my score if some of the questions and concerns are addressed by the authors.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_aMPP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3204/Reviewer_aMPP"
        ]
    }
]