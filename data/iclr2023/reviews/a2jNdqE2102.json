[
    {
        "id": "9RqUYU81hQ3",
        "original": null,
        "number": 1,
        "cdate": 1666622639299,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666622639299,
        "tmdate": 1666622639299,
        "tddate": null,
        "forum": "a2jNdqE2102",
        "replyto": "a2jNdqE2102",
        "invitation": "ICLR.cc/2023/Conference/Paper3834/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces Knowledge-in-Context (KiC), a semi-parametric LM consisting of a parametric text-to-text LM with a knowledge-rich external memory and a knowledge selector. During inference, the knowledge selector determines the sequence-to-expert assignment and a retriever retrieves the most relevant sequence from the expert. The retrieved sequence is concatenated to the data instance and goes through the text-to-text LM. Results show that KiC outperforms LMs that are 4-39x larger by a significant margin.",
            "strength_and_weaknesses": "Strength:\n1. The paper is well-written and clear about the contributions.\n2. The performance of KiC shows significant improvement compared to baselines. \n3. The experiments are extensive, containing zero-shot task transfer (MMLU and datasets evaluated in T0), and in-domain evaluation.\n\nWeakness:\nThis paper lacks detailed ablation and analysis of the proposed method. \n1. The performance of retrieving from a mixture of 6 categories (treating a mixture of 6 categories as a single large corpus) is needed to show the effectiveness of MoE architecture for knowledge selection. A naive mixture of 6 categories would not need any knowledge selection step. \n2. Please also report the standard deviation across different evaluation prompts for each task in Table 2. Prompt sensitivity is also important in addition to median accuracy. \n3. For each task, what is the occurrence of selection of each knowledge category for Table 2? This might answer the question of \"why does KiC works?\", if there are some patterns of the target task and selected expert. \n4. Is there any ablation result showing the necessity of generalist (no external memory)? How does the performance vary if the generalist is absent?\n\nQuestions:\n1. Are there any results of KiC on a 3B (or larger) scale?\n2. Is there any quantitative result of showing the benefit of using structured knowledge resources than plain text such as Wikipedia or C4 dataset? If the effect is similar, using plain text would be simpler because it does not require any knowledge selector.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clear about the contribution and the proposed method.\nAlthough there are many lines of work related to semi-parametric zero-shot task adaptation, the method proposed in this paper is novel enough.",
            "summary_of_the_review": "This paper proposes KiC, an effective semi-parametric LM that outperforms much larger parametric LMs on various downstream tasks. The paper is well-written and the proposed method is novel enough. However, this paper lacks detailed analysis and ablation. Ablation studies on how each component of the proposed method benefits the target downstream task are needed, especially. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_mSmi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_mSmi"
        ]
    },
    {
        "id": "L0NQ7Z1Xdlv",
        "original": null,
        "number": 2,
        "cdate": 1666668674461,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668674461,
        "tmdate": 1666668674461,
        "tddate": null,
        "forum": "a2jNdqE2102",
        "replyto": "a2jNdqE2102",
        "invitation": "ICLR.cc/2023/Conference/Paper3834/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper tackles the problem of zero-shot task generalization to unseen tasks using a semi-parametric approach. In order to achieve this, they construct 6 different knowledge-rich external memory consisting of Dictionary, Commonsense, Entity, Event, Script, and Causality. Like previous work, they perform multitask prompted fine-tuning on 40+ NLP tasks but while retrieving from external knowledge sources to perform the task. Since there are six knowledge sources, they train a MoE layer that dynamically routes to which source to retrieve the external knowledge from. This approach coined Knowledge-in-Context (KiC) enables a 770M LM to easily outperform LMs that are 4-39x larger by a significant margin.",
            "strength_and_weaknesses": "The strength of the paper is that it utilizes a novel semi-parametric language model architecture that retrieves from multiple knowledge sources dynamically via an MoE layer. This simple yet effective approach boosts zero-shot task generalization results significantly. Dividing the knowledge sources into 6 different resources helps in different aspects of solving NLP tasks, which can be decided at a instance level.\n\nThe weakness is that it does not show any computational comparison compared to prior multitask prompted finetuning approaches. Initial thought is that the proposed method might require much more computation (fine-tuning stage) since the MoE layer has to be trained to be able to dynamically select which knowledge source to route to AND also train the underlying LM.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very easy to read will clear explantations in the technical parts such as the explanations regarding the MoE layer. I think the proposed method is very novel in the sense that they utilized a MoE layer to retrieve from multiple external sources and that they utilized this to tackle the important task of generalizing to unseen tasks. ",
            "summary_of_the_review": "This paper suggests a novel semiparametric architecture, retrieving from multiple fine-grained to coarse-grained knowledge sources to solve unseen tasks and achieving significant performance enhancement compared to previous approaches while having a much smaller number of parameters. Thus, I highly recommend this paper be accepted at this conference. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_TPmn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_TPmn"
        ]
    },
    {
        "id": "TDJIN6UpGp",
        "original": null,
        "number": 3,
        "cdate": 1666710792035,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666710792035,
        "tmdate": 1666749619411,
        "tddate": null,
        "forum": "a2jNdqE2102",
        "replyto": "a2jNdqE2102",
        "invitation": "ICLR.cc/2023/Conference/Paper3834/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel semi-parametric language model architecture dubbed Knowledge-in-Context (KiC) which utilizes external knowledge memories of K (K=6 in the experiments) different structured knowledge types (dictionary, commonsense, Entity, event, script, causality) to make the prediction. When a query is given, the knowledge selector classifies the query into (K + 1) classes, where the 0-th class represents that no external knowledge is required for the query. Then, the knowledge memory that corresponds to the class with the highest predicted probability is selected, and the knowledge retrieved from the selected memory is concatenated with the query to serve as the input to the text-to-text model to generate the output. This can be viewed as a mixture-of-experts (MoE) architecture where the parameters of all experts are shared, and each expert has its own external knowledge base. The authors show the effectiveness of the suggested method through extensive experiments on zero-shot setup, in-domain setup, and MMLU tasks, comparing the performance with the simple and state-of-the-art models. The authors also report that KiC seems to show emergent behaviors at the scale of 0.77B.",
            "strength_and_weaknesses": "**Strengths**\n\n- The paper proposes a novel semi-parametric method to use the external memory of heterogeneous types of structured knowledge, which demonstrates its effectiveness across many tasks in various setups with a relatively small number of parameters.\n\n**Weaknesses**\n\n- The paper lacks ablation studies to investigate the effectiveness of each component of the proposed method.\n- Several important details of the method are missing, making it less clear and the experimental results difficult to reproduce.\n\n**Suggested Ablation Studies & Analyses**\n\n- In order to see how important is the knowledge-selecting mechanism, it would be interesting to see the performance of KiC without the knowledge selector where all knowledge memories are merged into one and then retrieved (however, it might be difficult if the retrieval mechanism is different for entity and script knowledge types, which is not clearly written in the paper).\n- It would be interesting to compare the performance with the cases where unstructured knowledge source(s) is used to augment the input, in order to show the effect of using heterogeneous structured knowledge resources.\n- It would be interesting to see the ratio of the knowledge source types selected by the knowledge selector to solve each task. It would demonstrate the effectiveness of using the balancing loss and might provide the readers with further insights.",
            "clarity,_quality,_novelty_and_reproducibility": "Several important details of the method are missing, making it less clear and the experimental results difficult to reproduce.\n\n- It is not described in the paper what kind of model architecture the knowledge selector uses.\n- For script data, it is not explained how the authors \u201cretrieve the most relevant scenario\u201d given the query (Is MPNet used here as well to encode the input query and each utterance in the script?).\n- It is not described how a word is selected from the dictionary given the query, and how the authors preprocess the Wiktionary to create the dictionary knowledge that would serve as the input, especially when the word contains more than one meaning.\n- It is not clear how many knowledge instances are retrieved from the knowledge memory and attached to the query (It seems like one).\n- The actual storage footprint of each external knowledge memory is not reported in the paper.\n- [Minor point] It is not clearly written in Section 2 whether the authors further train MPNet or use it off-the-shelf (It seems to be the latter case).\n- [Minor point] The motivation behind why the authors explored the use of only structured knowledge resources and did not include unstructured knowledge sources as a type of knowledge memory such as Wikipedia, remains unclear.\n- [Minor point] The formula for the balancing loss refers to the paper of SwitchTransformer, and is missing in this paper.",
            "summary_of_the_review": "The paper proposes a novel semi-parametric method to use the external memory of heterogeneous types of structured knowledge, which demonstrates its effectiveness across many tasks in various setups with a relatively small number of parameters. However, many important details of the method and ablation studies are missing in the paper, making the need to update the manuscript essential to make the explanations clear and add several ablation studies and analyses which could provide more insights to the community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_6HCz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_6HCz"
        ]
    },
    {
        "id": "O8ZHzplPfE",
        "original": null,
        "number": 4,
        "cdate": 1666714935026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666714935026,
        "tmdate": 1669133248223,
        "tddate": null,
        "forum": "a2jNdqE2102",
        "replyto": "a2jNdqE2102",
        "invitation": "ICLR.cc/2023/Conference/Paper3834/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper constructed framework where a language model is supplied with various types of external context. The context is curated and retrieved, then concatenated with the language model. The retrieval part is frozen and the language model is initialized with LM adapted T5 and trained together with a dispatcher that selects which knowledge source to retrieve from. The model shows improvement over non-context augmented, similarly finetuned models such as T0 on a wide range of tasks. ",
            "strength_and_weaknesses": "Strength: Thorough evaluation on a wide range of tasks. Providing a broad picture of the effectiveness of the supplied context.\n\nWeakness: \n1, The paper is weak on ablations. The author should include more baseline results, in particular the result where the same (initial) model is trained with the same hyperparameters with no non-trivial knowledge sources available. In their language this baseline should have the generalist only. They also did not analyze e.g. how retrieval noise/quality affect the results. Ideally the author should look deeper into how are the retrieval results helping the model to make predictions that are otherwise difficult. \n\n2, A unified retrieval system that works across different knowledge sources and end-to-end trained with the language model would be more  elegant and removes the expert dispatcher and make the method more freely generalizable to expanded knowledge sources without retraining. But this reviewer acknowledge the value of attempting to use out-of-the-box retrieval systems. \n\n3, The paper claims to have experimental evidence that instance-adaptive selection is superior to task-adaptive selection of the context type. But this claim did not seem to be backed up by numbers. \n\n4, The author should comment in the paper on the degradation on tasks such as OpenBookQA and PIQA when going from the no-context finetuned baseline of table 1 to their flagship model in table 4. Some analysis on the win/loss patterns would be valuable. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is original enough and provides good information on training general purpose language models that can utilize external knowledge sources.\n\nThe writing quality leaves a lot to be desired:\n1, There is no listing of the 39 finetuning tasks. Making it difficult to evaluate the generalization ability of the resulting model.\n2, The author should include a reference on the \"P3 task categorization framework\" and the identity of the \"P3 tasks\".\n3, SwithTransformer -> SwitchTransformer, \n\n\n",
            "summary_of_the_review": "The paper attempts at a valuable direction of context augmented language models and provided thorough eval for their framework. The authors demonstrated incremental value of retrieved context from various datasources. It is light on ablations and analysis and rough on the edges in terms of presenting all necessary information and baselines. But overall it is a valuable paper. Improvements on the weaknesses of the paper could lead to better review ratings. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_3xue"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3834/Reviewer_3xue"
        ]
    }
]