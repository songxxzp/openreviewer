[
    {
        "id": "kTd6D24S4J5",
        "original": null,
        "number": 1,
        "cdate": 1666607852419,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607852419,
        "tmdate": 1669367482825,
        "tddate": null,
        "forum": "QIRtAqoXwj",
        "replyto": "QIRtAqoXwj",
        "invitation": "ICLR.cc/2023/Conference/Paper4721/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors proposed the spike-efficiency measurement for spiking neural networks and showed the relationship between spike-efficiency and the heterogeneity. They also performed some empirical experiments to demonstrate the significance of neuronal and synaptic heterogeneity in reducing spiking activity. ",
            "strength_and_weaknesses": "Strength:\n1. The manuscript is clearly written with sufficient details. \n2. The idea of quantifying the capacity and heterogeneity is interesting. \n\nWeakness:\nAlthough this topic appears to be interesting, there seem to lack sufficient evidence to support the claim. Specifically, I have the following concerns. \n1. The capacity can be intuitively understood as a measurement of how much variance in the past are still maintained in the current state. However, what's the relationship between this capacity and the model performance or generalization ability? As is known for the deep learning setup, overfit on the training dataset is a typical phenomenon. Thus increasing only the capacity is not enough for such cases. \n\n2. The definition of spike-efficiency is a bit random especially the factor 1000. Is there any reasoning on why we should define it as a ratio? Since both the memory capacity and spiking rate are unit-free variables, their relationship can be composed in multiple ways. Thus it would make more sense if this definition is derived under a certain criterion rather than simply claimed. \n\n3. Intuitively one may expect that if we improve the heterogeneity of parameters, it would lead to more complex models thus higher ability in memorizing certain modes. For the results in Table 2, soly increasing heterogeneity of LIF does not necessarily improve the efficiency or not. How should we understand such difference with STDP? Specially for Lemma 3.2.1, the $\\Delta Var$ is not defined. Also, it seems that the proof here is a directive corralory from the heavy-tail claim, I am not 100% sure about the reliability here. \n\n4. The experiments are on fairly simple cases. To validate the capacity and the assumption, experiments on some more complex static/dynamic dataset may be included. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written with moderate originality in the topic. ",
            "summary_of_the_review": "Overall, this is a paper that proposes an interesting question of measuring the performance of RSNN. However, the discussion remains a bit superficial.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_rFWy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_rFWy"
        ]
    },
    {
        "id": "j4VY44AWcl",
        "original": null,
        "number": 2,
        "cdate": 1666619364121,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619364121,
        "tmdate": 1666621668936,
        "tddate": null,
        "forum": "QIRtAqoXwj",
        "replyto": "QIRtAqoXwj",
        "invitation": "ICLR.cc/2023/Conference/Paper4721/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper investigates the role of neural and synaptic heterogeneity in improving the computational capacity and/or energy efficiency of spiking recurrent neural nets. It also provides an optimization procedure for determining the optimal degree of heterogeneity for a problem.",
            "strength_and_weaknesses": "Strengths:\n+ biological motivation\n+ what in hardware may be traditionally deemed as a bug becomes a computational feature of the system\n+ rigorous analysis of implications\n+ numerics are solid\n\nWeakness:\n- capacity measure somewhat restricting as a measure of computational power\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I found the writing very clear, precise and easy to follow\n\nwould be useful to expand slightly on the bayesian optimization procedure, in particular the  parameter distributions being optimized over",
            "summary_of_the_review": "Overall, a solid contribution with clear problem framing, theoretical and numerical support and robust numerical results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_MSRY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_MSRY"
        ]
    },
    {
        "id": "kcLrbtnmPm",
        "original": null,
        "number": 3,
        "cdate": 1666901754986,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666901754986,
        "tmdate": 1670001754910,
        "tddate": null,
        "forum": "QIRtAqoXwj",
        "replyto": "QIRtAqoXwj",
        "invitation": "ICLR.cc/2023/Conference/Paper4721/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The submission studies discrete-time recurrent spiking neural networks of LIF neurons with STDP both analytically and numerically.  The main analytical finding is that heterogeneity of neuron parameters increases the memory capacity of the recurrent spiking neural network. This finding is based on the fact that with increasing heterogeneity of neuron parameters (threshold and membrane time constant), the covariance is decreasing ints covariance. A lower covariance results in a higher capacity. The numerical analysis confirms that. Moreover, a SAGE-attribution analysis reveals that the main contribution to the improved performance comes from heterogeneous membrane time constants.",
            "strength_and_weaknesses": "Strength:\n* It is a rare case of an analytical study of the computational capabilities of a recurrent spiking neural network.\n\nWeaknesses:\n* The main finding is that heterogeneity of membrane time constants increases the capacity, however, in biological neurons, the membrane time constant is not a free parameter but is tightly controlled by the resistance across the membrane and the capacitance of the membrane. It is thus not biologically plausible that the brain has the freedom to choose a heterogeneous distribution of membrane time constants. A more plausible candidate for that would be the heterogeneity of synaptic time constants.\n* A direct comparison of analytical results and numerical simulations is missing. While figure 3 shows a similar trend as expected from theory, it would be desirable to actually directly compare them. \n* table 2: it would be better to measure the firing rates of the neurons in 1/s or 1/tau_m and not as 'spike count'.\n* It would be nice to relate this work to other work with recurrent networks of LIF neurons, e.g. Brunel 2000, Jahnke/Memmesheimer/Timme 2009, Deneve/Machens 2016. \n* The theoretical part seems to rely on some kind of mean-field assumption that allows to express the covariance of the activity in terms of linearized dynamics and a stationarity assumption. As LIF networks can have a very diverse set of states (e.g. oscillations, synchronization, splay-states, asynchronous irregular states, etc. see e.g. Brunel 2000), it is not clear how this assumption is justified here. Also, no direct numerical tests of the analytical results are being presented, which makes it hard to evaluate them. \n* Details the Bayesian Optimization are missing, the numerical experiments are not fully reproducible in the current version.",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: \nThe paper is written clearly\n\nQuality:\nThe quality of the theory is hard to evaluate because the analytical results are directly tested analytically.\nThe numerical evaluation seems to be done carefully, I liked e.g. convergence analysis on the supplement.\n\n\nNovelty:\nThe main theoretical results seem to be a slight extension of some previous work (Aceituno 2020). Unfortunately, the main analytical result (Equations 21 and 22) seems more of a heuristic nature. An actual analytical theory of the quantitative effects of heterogeneity of membrane time constant and thresholds in the capacity is missing, so maybe one could write it as a conjecture instead. Also, a discussion of the assumptions and limitations of the analytical derivation is missing. When is it expected to fail? Are the assumptions tested numerically?\n\nReproducibility: \nBecause no code is provided, the results are unfortunately not fully reproducible in the current form.\n",
            "summary_of_the_review": "The submission studies the role of the heterogeneity of membrane time constants and threshold heterogeneity on the capacity of recurrent spiking neural networks.\nThe two main weaknesses of the submission are a lack of biological plausibility and a lack of discussion of the scope and rigor of the \"analytical\" theory (which seems to be a slight extension of  (Aceituno 2020), i.e (including discussion of the implicit assumptions and when it would break down) and details (and code) that would make the findings reproducible.\n\nOverall, I cannot recommend the manuscript in the current form for publication.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_LwLn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_LwLn"
        ]
    },
    {
        "id": "sY6YETFzkH",
        "original": null,
        "number": 4,
        "cdate": 1667478829397,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667478829397,
        "tmdate": 1669272946485,
        "tddate": null,
        "forum": "QIRtAqoXwj",
        "replyto": "QIRtAqoXwj",
        "invitation": "ICLR.cc/2023/Conference/Paper4721/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper makes an endeavor to enhance the memory capacity $\\mathcal{C}$ with heterogeneity in neuronal dynamics, which refers to different membrane time constants. The authors also show heterogeneous STDP, which means using a probabilistic synaptic time constant, helps to suppress the firing rate while the memory capacity is maintained. The results are both analytical and empirical.",
            "strength_and_weaknesses": "**Pros**\n\nAlthough using a heterogeneous time constant is not novel in this area, the elaboration upon its effect on the memory capacity of SNNs is clearly novel to me.\n\n**Cons**\n\n1. There are some things that need to be clarified or properly placed notations.\n2. The statement in Lemma 3.2.1, that is, heterogeneous dynamics reduce the variance of membrane voltages and thus reduce the rate of spikes, seems to omit the discussion of the mean of membrane voltages.\n\n**Questions**\n\n1. The notations are a bit confusing even when the authors have made a table of notations. Here is a non-exhaustive lists\n   -  ${\\bf{w}}^{\\rm{in}}$ first appears in the statement of Lemma 3.1.1, but is first defined in short proof.\n   -  In Eq.2, the authors choose $[\\cdot]$ to express discretized variable and distinguish it from continuous one $(\\cdot)$. However, in Eq.4 and many following equations with integer $\\tau$, they still use $(\\cdot)$.\n   - When using $\\Delta$, only the meanings of $\\Delta w$ and $\\Delta t$ are clearly given. Notations like $\\Delta\\text{Var}$ in Lemma 3.2.1 are not defined and can be confusing.\n2. The statement in Lemma 3.2.1 that a lower variance of membrane voltage distribution leads to a lower firing rate is not sufficient. A zero variance (constant) voltage but higher than the threshold leads to persistent firing.",
            "clarity,_quality,_novelty_and_reproducibility": "Some notations are a bit confusing. The idea is novel.",
            "summary_of_the_review": "Many contents are confusing, and need to be clarified.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_Rdb2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4721/Reviewer_Rdb2"
        ]
    }
]