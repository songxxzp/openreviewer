[
    {
        "id": "Ir3XMaQFi3",
        "original": null,
        "number": 1,
        "cdate": 1666576089015,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666576089015,
        "tmdate": 1666931495272,
        "tddate": null,
        "forum": "HjzWIMEWipV",
        "replyto": "HjzWIMEWipV",
        "invitation": "ICLR.cc/2023/Conference/Paper3288/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Most recourse generation methods optimize for properties such as proximity, sparsity, validity, etc, but often ignore the user\u2019s preference. Recent effort in taking into account the individual preference requires a shared cost function on feature changes or user-specified feature change costs that can be burdensome on the users. The authors propose to capture user preferences in terms of user-specified- scoring for continuous features, bounds on feature values, and ranking of categorical attributes. The fractional scores on continuous attributes allow the user to indicate the contribution of each feature on the overall cost. These preferences result in a customized optimization problem that is solved by the UP-AR algorithm. The UP-AR algorithm is a coordinate wise gradient descent/ascent where the step size is influenced by the user-specified cost. The authors also propose a roll-back mechanism to reverse changes to features that are unnecessary due to a change to a categorical attribute. Experiments conducted on benchmarking datasets indicate the effectiveness of the proposed approach.\n",
            "strength_and_weaknesses": "Strengths\n\nGenerating recourses that satisfy user-preference is an important research problem. While the cost function is shared across all the users, the authors propose a novel way to define a user\u2019s preference in terms of contribution of a single feature to the overall cost. \n\nThe proposed technique is sound and quite easy to understand. The authors show that the expected cost of a feature is proportional to the user-preference. \n\nExperiments on multiple datasets indicate that the proposed method is capable of generating recourses with minimal constraint violations.\n\nWeaknesses\n\nThe fractional-score based user-preference, although novel, may not be as simple and easily expressible as proposed, especially, when the number of continuous features is large. Moreover, the preference input process puts an extra cognitive burden on the users. Evidence supporting the acceptability of such a preference elicitation process will go a long way in strengthening the paper. Separating continuous and categorical features may result in a manageable modeling task, but I wonder if a user would find it difficult to separate the two sets of features while providing the preferences.\n\nHow are the continuous features discretized? Does this have a bearing on the algorithm? \n\nI recognize the challenges in modeling heterogeneous features (categorical and continuous). However, I am not convinced with the automatic assumption that the fractional cost of categorical features changes should be higher than that of continuous features (for all categorical features listed in the user\u2019s preference rank, $ \\Gamma_i = 1 $). A user might actually prefer changes to continuous features over categorical features. How does UP-AR handle such situations?\n\nWhile the proposed method ensures that the expected cost follows the user-preference, I am unsure how this translates into practice. A user would expect a single (or at best a few diverse) recourse(s) satisfying the indicated preferences. Thus, usability of UP-AR is significantly hampered, as the preference compatibility of a single recourse cannot be guaranteed. \n\nI am also concerned about the scanty experiments on preference-enforcement. The authors\u2019 have shown pRMSE results only for single features (LoanDuration and DebtRatio). Evidence on other features, perhaps an average over all continuous features could have been reported for better insights into the empirical effectiveness of UP-AR.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and clear to follow. \nA minor comment: Certain figures are only described (for example Figures 3 and 4) but not discussed in greater detail. Readers will benefit with a detailed discussion on these results.\n",
            "summary_of_the_review": "Overall, the paper has interesting ideas that might help to push the frontiers of algorithmic recourse research. However, I have major concerns related to the preference definition, guarantees of the algorithm and lack of experiments. \n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_uWp4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_uWp4"
        ]
    },
    {
        "id": "_uvQ2onKRg",
        "original": null,
        "number": 2,
        "cdate": 1666676726686,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666676726686,
        "tmdate": 1666676726686,
        "tddate": null,
        "forum": "HjzWIMEWipV",
        "replyto": "HjzWIMEWipV",
        "invitation": "ICLR.cc/2023/Conference/Paper3288/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies how to generate actionable resources for different individuals, with their specific individual user-based preferences. Specifically, it discusses three types/formats of user preferences: (1). Scoring for continuous features; (2). Ranking for categorical features as well as (3). Bounding for feature values. Based on these three types of constraints, it proposes an optimization framework which minimizes the cost of the overall change. It further instantiated the method with a UP-AR algorithm, which consists of two stages: candidate generation using gradient-descent, followed by the redundancy and cost correction. Empirical results also show superior performance compared with baseline.",
            "strength_and_weaknesses": "Strength:\n\n<1>. This paper is very well-written and well-motivated. I enjoy reading the paper and learning from it.\n\n<2>. The problem setup it studied is novel, which considers the usage of user-preference in actionable resource optimization, and it is closely related with lots of real-world scenarios. \n\n<3>. The proposed method is solid, easy to implement, and shows great empirical performance.\n\nWeakness:\n\n<1>. The main argument of the paper is the individual user-level performance, and the proposed method is tailored to this. However, in the experiments, if i understand it correctly, it seems the set-up uses the universal user preference function? This might limit the argument from the empirical experiments. Could the authors comment more about this?\n\n<2>. The current empirical set-up for UP-AR is based on linear models, could the authors comment more about the feasibility of scaling it to more complicated neural networks? \n\n<3>. Another aspect is the actionable feature dimension, how the proposed method scale with that?\n\n<4>. Getting user preference might be tricky in real-world settings, could we utilize any signal from training data to get this information? Could the authors comment more on this?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nThis paper is well-written and easy to read.\n\nQuality and Novelty:\n\nThis paper studies a novel problem, which incorporates individual user-level preference into the optimization of the actionable resource. The proposed method is well-motivated, solid and shows strong empirical performance.\n\nReproducibility:\nAll the experiment details and implementations are provided.",
            "summary_of_the_review": "This paper is a nice paper in studying effective methods to incorporate user-level preference into the actionable resource optimization problem. The proposed method is novel and well-motivated. Empirically, it also shows strong performance compared with baselines. However, there are some issues in the current set-up of the experiment, such as the universal user-preference, the availability of the user-preference, etc. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_zS7o"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_zS7o"
        ]
    },
    {
        "id": "y4WvCNWEEvb",
        "original": null,
        "number": 3,
        "cdate": 1666880298002,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666880298002,
        "tmdate": 1666880298002,
        "tddate": null,
        "forum": "HjzWIMEWipV",
        "replyto": "HjzWIMEWipV",
        "invitation": "ICLR.cc/2023/Conference/Paper3288/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work studies Actionable Recourse (AR) and proposes to incorporate user preferences as constraints into the recourse generation process. The authors propose three forms of user preferences: scoring continuous features, bounding feature values, and ranking categorical features. An optimization approach is provided to find the recourse. Numerical comparisons were conducted to evaluate the proposed method.",
            "strength_and_weaknesses": "Strength: This work provides three types of user preferences and adopt them as soft constraints into the actionable recourse formulation. This idea is interesting and has shown helpful in generating actionable recourse. A two-stage UP-AR and some theoretical analysis are also provided to consolidate this work. \n\nWeakness: \n1) In Tab 5, though UP-AR performs well in terms of indices such as Sparsity and Redundancy, the success rate is not always the highest among baselines. For example, on the Adult dataset, its success rate is even much worse than other methods. I am wondering whether it\u2019s fair to make a comparison among different methods under this setting.\n2) This work adopts the logistic regression model during experiments evaluation, while more sophisticated models remain unexplored. \n3) Though user preference is interesting, I\u2019m not clear whether such information is always available to be used. This may limit the applicability of the method.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This work is well written with good clarity, and the presented method is interesting to me with technical novelty. The proposed method is also shown effective empirically. ",
            "summary_of_the_review": "This work proposes an interesting idea that models three user preferences for actionable recourse and designs an optimization method to generate the recourse. Some analysis is given and experiments were conducted on 2 datasets to verify the effectiveness. Nevertheless, I have some concerns (see Weakness) that need to be addressed by the authors. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_7UMN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3288/Reviewer_7UMN"
        ]
    }
]