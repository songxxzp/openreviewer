[
    {
        "id": "IGS4Mjj6as-",
        "original": null,
        "number": 1,
        "cdate": 1666264148234,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666264148234,
        "tmdate": 1666264148234,
        "tddate": null,
        "forum": "OM7doLjQbOQ",
        "replyto": "OM7doLjQbOQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2197/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed some augmentation techniques to enhance the transferability of Intermediate-level Attacks(ILA), including automated data augmentation, reverse adversarial update, and attack interpolation. This paper evaluated proposed method on both undefended and defended models, showing the SOTA result comparing with some advanced baselines.",
            "strength_and_weaknesses": "**Strength**\n\n1. The structure of this paper is clear.\n2. The experiments are conducted extensively on both undefended models and defended models,  and the proposed ILA-DA showed promising results comparing with other transfer-based attacks. \n3. Ablation results demonstrate the effectiveness of each component.\n\n\n\n**Weakness**\n1. The choice of different intermediate layers may be important. Figure 3 shows that the performance fluctuates significantly when the intermediate layer is different. It means that when we have a new model, we have to spend much time to determine the optimal layer. However, other methods expect ILA have no such restriction. Can you comapre the results between ILA-DA with different intermediate layers and other transferable attack methods, like LinBP or CTM family? Maybe you can plot a figure like Figure. 3 in paper ILA[1]. \n\n2. In AutoAugment, the magnitude of augmentation may also influence the results. Do you consider it into the optimal augmentation choice?  In addition, did you try combine multiple transforms together to augment the data? Also, after learning the $p_{\\alpha}$, will there be any trend in the data augmentation choices? \n\n3. As for reverse adversarial update, the author expect that \"the stronger the reference attack is, the better ILA performs\", can you show the attack effectiveness of $x - (x - x^{'})$ comparing with other attack methods like FGSM?\n\n**Reference**\n\n[1] Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, and Ser-Nam Lim. Enhancing\nadversarial example transferability with an intermediate level attack. In ICCV, 2019.",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: The paper is written well and the organization is good.\n\n* Quality: The quality is good since extensive experiments showed promising results of the proposed LIA-DA, compared with other transfer-based attacks.\n\n* Novelty: I think this paper is lack of novelty slightly. \n\n* Reproducibility: This work was implemented on public datasets. The implementation details are detailed, although the author did not list it as an independent section. The reference code is provided, showing good reproducibility. ",
            "summary_of_the_review": "Generally, this paper proposes a simple and effective extension of the ILA. The extensive experiments on various benchmarks showed promising results for the proposed methods. However, this paper may have some problems with the sensitivity of the results to the choice of the intermediate layer.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_vZBZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_vZBZ"
        ]
    },
    {
        "id": "X28IJSGPY_r",
        "original": null,
        "number": 2,
        "cdate": 1666353568718,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666353568718,
        "tmdate": 1670219367529,
        "tddate": null,
        "forum": "OM7doLjQbOQ",
        "replyto": "OM7doLjQbOQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2197/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an intermediate-level attack method with three data augmentation strategies. They include automated search for image transformation, a reverse adversarial update strategy, and an attack interpolation method. The proposed method can achieve higher transferability of the generated adversarial examples. Experiments on the ImageNet show the improvements over previous attack methods against undefended and defended models.",
            "strength_and_weaknesses": "Strengths:\n\n+ This paper is clearly written. It does a great effort to review previous attacks.\n+ The evaluation results are comprehensive, covering a lot of attacks.\n\nWeaknesses:\n\n- The main contribution of this work is to introduce data augmentation strategies to intermediate-level attacks. The general idea has been widely studied. The paper proposes three new strategies, but they are not novel enough.\n- The evaluation is insufficient in evaluation models. For undefended models, only CNN-based models are adopted. The authors should try transformer-based models. For defended models, only weak defenses are considered. There are new defenses on ImageNet with strong performance based on adversarial training. The authors should try these new defenses.\n- Can the new strategy, especially automated image transformation, be applied to other transfer-based methods (e.g., MI-FGSM, DIM, etc.)?",
            "clarity,_quality,_novelty_and_reproducibility": "The novel is considered limited since the general idea of using data augmentation to improve the black-box transferability has been widely studied before. Though new strategies have been proposed for a special kind of attacks, the novelty upon previous works is insufficient.",
            "summary_of_the_review": "Despite the writing clarity, the work lacks novelty and sufficient evaluation on other models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_KZsc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_KZsc"
        ]
    },
    {
        "id": "96z-FwPBMBm",
        "original": null,
        "number": 3,
        "cdate": 1666549963458,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549963458,
        "tmdate": 1666549963458,
        "tddate": null,
        "forum": "OM7doLjQbOQ",
        "replyto": "OM7doLjQbOQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2197/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper provides 3 novel techniques: automated data augmentation, reverse adversarial update, and attack interpolation to improve the transferability of ILA attack, which achieve promising performance against multiple defended and undefended models.",
            "strength_and_weaknesses": "## Strength\n1. This paper provides novel and practicla techniques on improving the ILA transfer attack\n2. Thorough ablation study is provided to show the effectiveness of each proposed technique\n3. The proposed method is evaluate on multiple datasets and models, as well as in combination with different base attack methods, further proving the general effectiveness under different scenarios.\n\n## Weakness\n1. There are some previsou feature space attack techniques that are worth mentioning and comparing to [1,2]\n2. To my understanding the propoaed attack may need additional iterations to search for data augmentation schemes and finetune the attack image. It would be good to discuss the cost of generating the proposed attack, how is it compared to baselines, and if baseline methods can be improved with more attack iterations\n\n[1] https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf\n\n[2] https://arxiv.org/pdf/2004.12519.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "This paper provides novel methods on using reverse adversarial update and attack interpolation, and apply novel application to existing AutoAugment technique into ILA generation. The paper is clearly written with high quality. ",
            "summary_of_the_review": "In summary I believe the proposed method is novel, practical, and effective. This method can be a valuabel contribution to the transfer attack community. Thus I would recommend acceptance.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_CjSu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_CjSu"
        ]
    },
    {
        "id": "-7rUirIhm9",
        "original": null,
        "number": 4,
        "cdate": 1666661593354,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661593354,
        "tmdate": 1666661593354,
        "tddate": null,
        "forum": "OM7doLjQbOQ",
        "replyto": "OM7doLjQbOQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2197/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to improve the transferability of adversarial examples. Previous studies show (1) Intermediate Level Attack(ILA) is effective, which is to finetune an adversarial example to improve transferability; and (2) data augmentation (DA) can also improve the transferability. This paper proposes a novel method ILA-DA, that combines Intermediate Level Attack(ILA) and data augmentation (DA). The results outperform both baselines.\n",
            "strength_and_weaknesses": "Strength\n1. The idea is straightforward and easy to follow. Since the high-level idea of ILA and DA are straightforward, I think readers can easily get the idea of ILA-DA, which combines them together. I also appreciate Algorithm 1, which helps people reimplement it.\n2. The experimental results show the effectiveness of the proposed method.\n3. The experiments (especially in appendix) are solid \u2013 helps readers to better understand the proposed method.\n\nQuestion\n1. The proposed data augmentation seems very effective. Wondering if it can only be applied to ILA? If my understanding is correct, the idea of the proposed augmentation is not specifically designed for ILA, and can also be applied to other transfer-based adversarial attacks?\n\nWeakness\n1. In figure 1, I see the perturbation generated by ILA+DA is more significant than I-FGSM noise. I assume this is because the human vision is not perfectly align with the perturbation budget \u03f5 = 16/255. If so, maybe it would be convincing to also test on some other perturbation budget pattern (eg, under L2 norm metric) that might align better with human vision.\n2. Writing: although this paper is easy to follow, I think readers may misunderstand that the improvement is trivial because both ILA and DA improve the transferability. Actually, I think the data augmentation is interesting and can be applied to other frameworks as well. It could be helpful if the authors can write more interesting findings and insights.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is clear and easy to follow.\n\nQuality: Quality is good.\n\nNovelty: the novelty looks okay -- although it looks like combining two items together, the results seem good.\n\nReproducibility: should be able to reproduce, everything is clear.",
            "summary_of_the_review": "This project shows good results but, if I understand is correct, the story and the writing style make the paper less interesting. I would be good to further understand the proposed method and then adjust the story.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_weXS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2197/Reviewer_weXS"
        ]
    }
]