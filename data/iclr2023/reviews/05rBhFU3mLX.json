[
    {
        "id": "e-jhiZtjPkQ",
        "original": null,
        "number": 1,
        "cdate": 1666613913302,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613913302,
        "tmdate": 1666613913302,
        "tddate": null,
        "forum": "05rBhFU3mLX",
        "replyto": "05rBhFU3mLX",
        "invitation": "ICLR.cc/2023/Conference/Paper2505/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "In this paper, the authors propose an accelerated first-order method for the optimization of the Hadamard manifold. They theoretically show that the proposed algorithm enjoys the same convergence rate as Nesterov's accelerated gradient descent method in Euclidian space, under the assumption that the objective function is geodesically-convex. Besides, they can apply the linearly convergent algorithm to solve the subproblem in each iteration, which is a constrained strongly geodesical-convex smooth problem.",
            "strength_and_weaknesses": "Strength:\n1. The designed algorithm looks very interesting because it seems to be a combination of the extension of Nesterov's acceleration gradient method on the Riemannian manifold and the mirror descent algorithm. \n2. The theoretical results are very strong since the most accelerated algorithms can only be proved to enjoy the same convergence rate as standard GD, even though they perform much better than GD in practice.\n\nWeaknesses:\n1. This paper is very hard to understand. The authors should give more background on the problem and show some examples. At least there is no formally mathematical description of the problem. Besides, For each step in the algorithm, the authors should give more intuition to help us to understand it. \n2. No concrete example or application is mentioned in this paper. Even though it is a theoretical paper, the author should mention at least one concrete example that satisfies all the assumptions and can be solved well using the proposed algorithm.\n3. No simulation results. The author should compare their method with, for example, a non-accelerated first-order method to show the strength of acceleration.  It will be great if a better convergence rate is observed. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is very hard to understand. It requires much knowledge of the background. Since the authors do not provide any concrete examples, the paper is really not clear to me. I believe the quality of this paper is good. Besides, given its strong theoretical results, the novelty is quite strong. ",
            "summary_of_the_review": "This paper should be a very good theoretical paper, even though I can not understand all the details. However, owing to the lack of concrete applications and numerical experiments, I think it may not be suitable for this conference, so I recommend not accepting this paper. I further recommend the authors submit it to a journal directly, given its amazing theoretical contributions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_S9aC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_S9aC"
        ]
    },
    {
        "id": "GtrYu3EDNw5",
        "original": null,
        "number": 2,
        "cdate": 1666650192879,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650192879,
        "tmdate": 1666650192879,
        "tddate": null,
        "forum": "05rBhFU3mLX",
        "replyto": "05rBhFU3mLX",
        "invitation": "ICLR.cc/2023/Conference/Paper2505/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a globally-accelerated, first-order method for the optimization of smooth and (strongly or not) geodesically-convex functions in Hadamard manifolds.It enjoys the same convergence rates as Nesterov\u2019s accelerated gradient descent.The most improvement is that this method without the assumption that the iterates of their algorithms stay in some pre-specifified compact set.The theoretical work is comprehensive.",
            "strength_and_weaknesses": "Strength: This paper proposed a globally-accelerated, first-order method for the optimization of smooth and (strongly or not) geodesically-convex functions in Hadamard manifolds. Technically strong, highly general results, advanced techniques",
            "clarity,_quality,_novelty_and_reproducibility": "Very clear, only minor flaws.",
            "summary_of_the_review": "Although the paper is theoretically sound, there are still some questions need to be discussed in this paper:\n1.\tIn written. Although we know what problem we study, It would be better to add  mathematical description .\n2.\tA mistake.In notation,  ||v-y||=||v-\\log_x(y)|| may be ||v-y||=||\\log_x(y)-y|| .\n3.\tAbout workload. The authors use a linearly convergent algorithm for constrained strongly g-convex smooth problems to implement the Line 8 of Algorithm 1.But from my point of view, the Riemacon instance for g-convex function is also important.Perhaps the authors want to add this in future work.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_qdaa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_qdaa"
        ]
    },
    {
        "id": "ji8LRji5v_",
        "original": null,
        "number": 3,
        "cdate": 1667467891660,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667467891660,
        "tmdate": 1667467891660,
        "tddate": null,
        "forum": "05rBhFU3mLX",
        "replyto": "05rBhFU3mLX",
        "invitation": "ICLR.cc/2023/Conference/Paper2505/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a theoretical result on accelerated methods for Riemannian optimization. In particular, it proposes  general Riemannian acceleration without iterates assumptively staying in the feasible set (which is an interesting open question posed earlier). \n",
            "strength_and_weaknesses": "Strengths:\nIt is an interesting piece of research which aims to solve an important theoretical problem in Riemannian optimization. The developments seem to be on solid foundation.\n\nWeakness:\nI find the paper far from complete. I would have liked to see some numerical experiments to see how useful Algorithm 1 is in practice to other methods. Without this, the paper looks very incomplete for the audience of this conference. \n",
            "clarity,_quality,_novelty_and_reproducibility": "A lot of discussion is at high level. As the paper claims to solve an open problem, it would have made sense to compare a bit more deeply on what were the challenges which others could not solve but was solved in the paper. E.g., which particular step made the crucial difference. Those details are missing. ",
            "summary_of_the_review": "I find the work interesting but very far from complete for the audience of this conference.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_E5FH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2505/Reviewer_E5FH"
        ]
    }
]