[
    {
        "id": "RftH_9F0i1H",
        "original": null,
        "number": 1,
        "cdate": 1666509122036,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666509122036,
        "tmdate": 1666509122036,
        "tddate": null,
        "forum": "WUWJIV2Yxtp",
        "replyto": "WUWJIV2Yxtp",
        "invitation": "ICLR.cc/2023/Conference/Paper3597/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper improves the previous path integration based model interpretation works by overcoming the limit of absolute based attribute scores. The method is mainly consisting of a) building a better \"reference\" than the manual way previously; b) identifying the interpolation point in the non-linear path through the relationship of \"variation\" and gradient; c) an efficient sampling method to make the computation tractable. The final method looks simple with a \"re-calibratable\" property on top of the current integral-based methods.",
            "strength_and_weaknesses": "**Strength**\n\n1. This paper brings a lot of meaningful technical depth. It deeply analyzes a tricky issue of the previously widely used method, and proposed the solution based on detailed mathematical analysis. A little bit surprisingly that the finally derived method seems to be simple with such a non-trivial technical setup which is impressive. \n\n2.  It is also technically sound and rigorous, with a) a good mathematical system; b) solid empirical verifications of the method.\n\n**Weakness**\n\n1. Mostly this paper is not reader friendly as the writing seems too technically heavy. In particular, a) a lot of long-sentences are used which should be further broken down; b) some concepts are introduced with a little bit sudden manner, especially in Abstract (e.g., \"attribution scores\", \"reference\" and \"local and global evaluation metrics\"). ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarify**\n\nIf taking a very deep look, the main body of this paper is clear but it is still generally reader unfriendly. I would suggest that the author improve its writing (with suggestions mentioned above) to not puzzle readers especially for those who are not exactly working in this area/technical direction (but still want to know more here given this area is quite important).\n\n**Quality and Novelty**\n\nTechnically novel enough, with several good insights like designing an appropriate \"reference\" instead of relying on manual design, finding the good interpolation points for path integral and an efficient sampling methods. \n\n**Reproducibility**\n\nGood given source code is provided. \n\n",
            "summary_of_the_review": "Overall I think this is a good paper especially for the particular area of path integration based model understanding/feature attribution. It solves a deep and tricky limitation of previous methods with enough technical novelty/depth for ICLR publications. I would vote for its acceptance conditioned on a good re-writing of the paper: currently it is presented in a too technically heavy way which is not good for the broader ICLR committee. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_rkn8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_rkn8"
        ]
    },
    {
        "id": "tME_gds2Es",
        "original": null,
        "number": 2,
        "cdate": 1666705137615,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666705137615,
        "tmdate": 1666705137615,
        "tddate": null,
        "forum": "WUWJIV2Yxtp",
        "replyto": "WUWJIV2Yxtp",
        "invitation": "ICLR.cc/2023/Conference/Paper3597/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method to create the reference image for Integrated Gradient attribution approaches to interpret model predictions. The method re-calibrates the attribution scores without the additional computational overhead of the traditional approaches. The authors suggest this strategy is more relevant to model prediction and feature interpretation. The paper considers different aspects of the attribution techniques during the evaluation and obtains promising results.",
            "strength_and_weaknesses": "+ The proposed approach is interesting and presents promising results. \n+ The idea of calibrating attribution scores to capture relevant features and interactions is promising but has been around for a while. The novelty is incremental and helps solve some limitations of the IG approach. \n+ The experiments and analysis are clear, but the discussion could be improved. The authors have the opportunity of creating a link between uncertainty and explainability by exploring more about the relationship between calibration and interpretation.\n+ The integrated gradients method can assign different attributions to features that have the same effect on the model or assign positive attributions to features with no effect. Does the proposed approach solve those problems? I miss some qualitative discussions about the method performance. \n- The authors did not discuss the limitation of the proposed method. Therefore, it will be meaningful to discuss the gap between the experiments in the current version of the paper and the real-world applications.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and logically structured. The authors suggest the code for reproducibility is in the supplementary material, but I could only find the experimental setup description, making it difficult to reproduce the experiments.\nThe novelty is incremental over existing techniques, but the results are promising. The analysis is not new but clear and consistent. I was expecting more insights from the authors.\n",
            "summary_of_the_review": "The proposed paper presents a promising approach with interesting results and analysis. The discussion is direct, but I was expecting more insights. The authors also should discuss the proposed approach's limitations.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have no ethical concerns about the paper.\n",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_FTMa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_FTMa"
        ]
    },
    {
        "id": "tl6_HzMVUo",
        "original": null,
        "number": 4,
        "cdate": 1667401279588,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667401279588,
        "tmdate": 1669363306220,
        "tddate": null,
        "forum": "WUWJIV2Yxtp",
        "replyto": "WUWJIV2Yxtp",
        "invitation": "ICLR.cc/2023/Conference/Paper3597/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a method to improve the path along which the gradients are integrated in integral-based attribution methods for explaining the decisions of deep neural networks (DNNs).\n\nThis method is based on the observation that while integrated gradients (IG) are theoretically well motivated, the necessary assumptions are often violated in common practice (e.g., by taking the absolute value of the computed attributions). To overcome this, the authors propose a method to select \"valid\" interpolation points for the integration, which are independently chosen for each input feature.\n\nIn a wide range of experiments with different datasets (CIFAR-10, CIFAR-100, ImageNet), the authors report consistent improvements according to various metrics (pixel perturbation, DiffROAR, sensitivity-n) when extending commonly used integral-based methods (IG-Uniform, IG-SG, IG-SQ, EG, AGI) with their proposed method for various networks (VGGs and ResNets).",
            "strength_and_weaknesses": "### Strengths \n- The experimental evaluation is extensive and shows that the proposed approach yields consistent improvements over a wide range of different settings, as measured by various metrics for assessing the quality of attribution methods.\n- The authors aim to address an important shortcoming of commonly employed integral-based attribution methods, namely their dependence on the chosen baselines as well as an inconsistency between the theoretical motivation for IG methods and their practical usage.\n- The paper is generally well structured and (apart from sections 4.2 and 4.3, see weaknesses) very well written and easy to follow. \n\n### Weaknesses\nWhile the experimental results show promising gains in the employed metrics for interpretability and the approach is well motivated, I am still hesitant to recommend the paper for publication in its current form. If the authors are able to address my concerns, I am open to increasing my score.\n\n- **Lack of clarity w.r.t. method and motivation**: I have the following issues with and open questions regarding the method and would appreciate if the authors could elaborate. \n\t- As far as I understand, the proposed method is motivated (apart from the described *inconsistency*) by the high spatial variance in the attribution maps of integral-based methods, as shown in Fig. 1 (top row). Commonly, the absolute value is taken to overcome this problem (see Fig. 1, second row), which the authors criticise as yielding attribution maps that are inconsistent with the underlying theory and thus do not faithfully reflect the explained model. Judging from Algorithm 1, the main difference of the proposed method is that the authors employ a ReLU activation over the pixel attributions for each reference image and average the result \u2014 *i.e.* instead of taking the absolute value to 'hide' the high variance in the attribution maps, the authors simply clamp the attributions at zero to do so. As such, while the experimental results seem to speak in favour of the proposed method, I currently fail to see how this approach is fundamentally different w.r.t. being better motivated than taking the absolute value. \n\t- There is a stark contrast between the simplicity of the actual implementation of the proposed method (Algorithm 1) and its description and derivation. To exaggerate a bit, it seems like a very complicated way of saying \"Instead of taking the absolute value, we average the ReLU-activated attributions over multiple reference images\". This is aggravated by a lack of clarity in the method description (see next bullet).\n\t- After carefully reading the method section multiple times, I am still confused as to how the reference set D is obtained. In Algorithm 1, the reference set seems to be given, while in the text it says the reference set is \"obtained by the method's own strategy\". As far as I can tell, this seems not to be referring to the authors' method, but simply to the reference set as used in prior work (e.g., uniform noise), i.e. in the respective base method which the authors extend by their approach. However, this seems to be contradicting the statement that \"we \\[...\\] modify the input image with the model gradients to construct the reference\", as well as the general notion of \"\\[computing\\] the reference along the gradient ascending direction \\[...\\] \\[similar to\\] Adversarial Gradient Integration\", which is also centrally placed in the abstract (\"The reference is computed in a gradient ascending direction on the model's loss surface\"). I would highly appreciate if the authors could clarify.\n\t- What exactly is the relevance of Lemma 1? What is different from standard Integrated Gradients, which also estimates the integral in eq. 3?\n\t- The mathematical notation / naming is not optimal, which makes the method section difficult to read: \n\t\t- In eq. (3) the index i is used to index a specific feature dimension of an input x, but also to index a specific reference sample in the set D. \n\t\t- The equivalence between x' and D_i is also confusing\u2014why not simply use D_i (optimally with a different index)? Further, using the term *variation* for the *difference* between two points is confusing. \n\t\t- What exactly is the set of signed input gradients in the second paragraph of 4.2.? What does this notation mean exactly (similarly for the variation / difference)?\n\n- **Missing reference**: Guided Integrated Gradients by Kapishnikov et al. (CVPR 2021) seems to be a highly relevant prior work that should be included in the discussion of related work as well as in the experimental evaluation. What are the main differences to and advantages over Guided Integrated Gradients?\n\nAdditional minor issues:\n- The result graphs are difficult to parse. I would recommend to additionally summarise the curves via a single number per method (e.g., AUC). This concerns all result Figs.\n- Further, the relevant comparisons (e.g., ResNet (Ours) vs. ResNet (Baseline)) are not easy to make in the current graphs, I would recommend grouping the results for better comparability. This is particularly difficult in Fig. 4\u2014here, the relevant baselines are seemingly not even included (e.g., IG-SQ* is shown, but not IG-SQ etc.)?\n- In Fig. 6, the shaded areas are not explained in the caption, what do they represent? ",
            "clarity,_quality,_novelty_and_reproducibility": "For details, please see strengths & weaknesses above.\n\nIn its current form, the submission lacks clarity, which makes the quality (apart from quantitative improvements in the metrics) difficult to judge. If I understand the proposed approach correctly (average over set of ReLU-activated IG attributions), the originality is limited. The results seem easily reproducible with the experimental description as provided by the authors.",
            "summary_of_the_review": "While the experimental results show promising gains in the employed metrics for interpretability, I am hesitant to recommend the paper for publication in its current form. If the authors are able to address my concerns, I am open to increasing my score (see weaknesses).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_brex"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3597/Reviewer_brex"
        ]
    }
]