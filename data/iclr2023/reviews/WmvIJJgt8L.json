[
    {
        "id": "ivS9TwUbxyo",
        "original": null,
        "number": 1,
        "cdate": 1665820370392,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665820370392,
        "tmdate": 1665820434629,
        "tddate": null,
        "forum": "WmvIJJgt8L",
        "replyto": "WmvIJJgt8L",
        "invitation": "ICLR.cc/2023/Conference/Paper2566/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel problem setting named adversary-aware partial label learning. The authors propose an Adversary-Aware loss function and the immature teacher within momentum (ITWM) disambiguation algorithm to tackle this problem.",
            "strength_and_weaknesses": "(+) The proposed new setting is potentially interesting.\n\n(+) The experimental results show that the proposed method is effective.\n\n\n(-) Although the setting, namely adversary-aware partial label learning, is new, I\u2019m not fully convinced by its practical significance and necessity. In other words, do real-world applications really have such problem in partial label learning? Is it possible to provide a *real* case that falls into the scope of this research? \n\n(-) The definitions of \u201cadversary\u201d and \u201crival labels\u201d need more explanations. To be specific, the name of the setting is \u201cadversary-aware partial label learning\u201d. However, when I read the paper, I notice that the authors only use a transition matrix to describe its relationship with true label. Therefore, I\u2019m not clear what is the meaning of \u201cadversary\u201d here. In fact, even for the random label noise, one may also use a transition matrix to model such relationship. Note that, for adversary, it means one intends to take some measures to degrade the model performance. However, in the developed model, I cannot see how to resist such attack or the so-called \u201crival label noise\u201d.\n\n(-) The writing needs significant improvement. Many typos can be found. For example, \u201caccordingly to the Eq.equation 17\u201d. Moreover, the writing quality in the sections of model, theoretical analyses, and experiments, is not as good as that in the introduction. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally readable. It seems that the results are reproducible, but I did not check it completely.",
            "summary_of_the_review": "This paper is potentially interesting. However, it contains some immature factors, especially the practical meaning and the handling of adversary, so I think it is not suitable to be accepted currently.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_o6Rr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_o6Rr"
        ]
    },
    {
        "id": "0H4z9K9fS2",
        "original": null,
        "number": 2,
        "cdate": 1666329606939,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666329606939,
        "tmdate": 1670656711065,
        "tddate": null,
        "forum": "WmvIJJgt8L",
        "replyto": "WmvIJJgt8L",
        "invitation": "ICLR.cc/2023/Conference/Paper2566/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper attempts to proposed a new method for so-called adversary-aware partial label learning (but the definition of this setting is not clear in the whole paper). The proposed method is an incremental improvement on a SOTA partial label learning method.",
            "strength_and_weaknesses": "Strengths:\nIt is difficult for me to tell the strengths about this paper because the extremely confusing notation system and language makes it difficult for readers to understand.\n\nWeaknesses:\n1. The paper is poorly written. \nFirstly, the paper does not have a formal definition of the adversary-aware partial label learning problem. From Eq2, the paper seems to introduce a hidden variable $Y'$ to generate the set of candidate labels $\\vec{Y}$, but in the definition on page 4, the generation of $\\vec{Y}$ is only related to the real label $Y$, which is contradictory. I am really confused about how the setting of the paper differs from the classic partial label learning.\nSecondly, most of the notations are not explained. For example, the notions that first appear throughout Sec1.3, $F, \\boldsymbol{w}, \\boldsymbol{v}, \\boldsymbol{u}$ in Sec2.1, etc.\nIn addition, the methodological and theoretical parts of the article are also very vague. Assumption2 and Lemma2 appear out of thin air on page 7.\n2. The methodology section appears to be almost an incremental improvement on PiCo, the only difference being the use of prototypes instead of queues. My bigger confusion is that the proposed method seems to be disconnected from the previous setting, as it does not use $Q$ and it is unclear how to get $T$.\n3. The experiment is not convincing. There is no explanation of how to generate the settings studied in the paper, i.e., adversary-aware partial labels, and the reproducibility of the algorithm is poor.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is poorly written, lacks novelty, and the experiments are unconvincing.",
            "summary_of_the_review": "In its current state, the paper is not ready for publication.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_8DLJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_8DLJ"
        ]
    },
    {
        "id": "qpaobDqkGM",
        "original": null,
        "number": 3,
        "cdate": 1666704254418,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666704254418,
        "tmdate": 1666704254418,
        "tddate": null,
        "forum": "WmvIJJgt8L",
        "replyto": "WmvIJJgt8L",
        "invitation": "ICLR.cc/2023/Conference/Paper2566/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed a novel problem setting of adversary aware partial label learning (PLL) and a novel solution including an adversary aware loss and immature teacher within momentum (ITWM) to solve it. Theoretical analysis are presented and some empirical results are reported.",
            "strength_and_weaknesses": "Strengths:\n\n1. The problem setting is a new interesting direction, and a solution is also presented to pave way to a new research area, with potentially profound implications in privacy enhancing PLL.\n\nWeaknesses / Major Concerns:\n\n1. My primary concern is the presentation of the paper. The current writing is very convoluted with too many concepts, without being proper introduced first. For example, the authors talk about the problem setting in Sec 1 (Page 2), but many notations were not introduced until Sec 1.2 (Page 3). Moving on, some challenges with respect to the proposed problem setting are discussed on Page 2, but it is very unclear and hard to follow (see point 2 below). With all the doubts (as a reader who hasn't read every single reference), the problem is set in Sec 1.2 (Page 3) without proper justifications (see point 3 below).\n2. Given the current writing, I find it very hard to understand the motivation of the work when reading through Sec 1 (Page 2). To give a few examples, why is the assumption that the rival is generated depending only on Y but instance X (e.g. simplification for theoretical analysis, or intractability, or practicality)? Why does the inclusion of rival imply an inconsistent classifier according to Eq 2? Then why one cannot obtain consistent classifier due to intractability of \\bar{Q}? How does the proposed ITWM help approximate \\bar{Q} hence the consistency issue? Are there other alternatives one may consider, and why ITWM in particular?\n3. The two main parts of the paper adversary aware PLL (Sec 1.2) and the ITWM algorithm (Sec 2.1) both lack clear explanation. For example, why the choice of the particular form Eq 4 for this problem (e.g. additive instance dependent noise but class dependent transition of rival)? How does the proposed setting extend and differ from Wen et al (2021) (e.g. a dedicated and elaborate section to such related works, or at least in appendix, is much appreciated)? How does instance embedding (\"prototype\") and the introduction of sparse matrix (A) help instead of obtaining true transition matrix (Page 4)? Why the positive sample set which appeared all of a sudden in Sec 1.3 without any mention throughout? In Sec 2.1, ITWM introduced a bunch of new notations that seem very disconnected from the previous texts? Then why does the adversary aware loss combine two terms (Eq 20) and how is the contrastive loss needed?\n4. With all the doubts above, I cannot properly judge the theoretical analysis (Sec 3) or the experiments (Sec 4).",
            "clarity,_quality,_novelty_and_reproducibility": "Though the paper seems to introduce a novel and somewhat significant research problem, the paper in its current form has severe issues with the presentation of the proposed problem/method.",
            "summary_of_the_review": "My major concern for the paper in its current form is the writing. Without properly rewriting the entire paper, I can hardly recommend a higher score. If the authors are willing to polish the writing significantly during rebuttal, I'm happy to have another read and adjust my recommendation accordingly.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_reQY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_reQY"
        ]
    },
    {
        "id": "2JaH1dInL9",
        "original": null,
        "number": 4,
        "cdate": 1666779763159,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666779763159,
        "tmdate": 1666779851119,
        "tddate": null,
        "forum": "WmvIJJgt8L",
        "replyto": "WmvIJJgt8L",
        "invitation": "ICLR.cc/2023/Conference/Paper2566/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a the adversary-aware partial label learning problem to protect the data privacy. The novel adversary-aware loss function, together with an immature teacher within momentum disambiguation algorithm, has achieved state of-the-art performance and proven to be a provable classifier.",
            "strength_and_weaknesses": "Pros:\n* This paper proposes to take the data privacy into account in partial label learning, which is novel and significant in practice.\n\n* The proposed method is smart and easy to follow, referring the idea of self-supervised learning. \n\nCons:\n* The theoretical analysis is based on the fully rank transition matrix. I have a concern about the existence of this condition especially when the noise is very regular.\n\n* I think the rival is essentially a noisy label for PLL. Thus, incorporating the label noise learning methods into the existing PLL methods will be an important baseline.\n\n* Some typos. For example, in the caption of Figure 2, \"the Method inWang et al. (2022)\".\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality and originality is fine.",
            "summary_of_the_review": "Please refer to the Strength And Weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_ctfM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2566/Reviewer_ctfM"
        ]
    }
]