[
    {
        "id": "hrJRCoCD75q",
        "original": null,
        "number": 1,
        "cdate": 1666568100707,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666568100707,
        "tmdate": 1666568100707,
        "tddate": null,
        "forum": "ctmLBs8lITa",
        "replyto": "ctmLBs8lITa",
        "invitation": "ICLR.cc/2023/Conference/Paper5918/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper adapts adversarial attack strategies to multivariate probabilistic forecasting models, focusing on attacks that might be difficult to detect. They also adapt defense mechanisms to adversarial attacks to the time-series forecasting setup and demonstrate how multivariate problems differ from univariate ones.",
            "strength_and_weaknesses": "The paper is well-written and motivated, covering many nuances of the problem at hand.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems to demonstrate original ideas and is clearly and understandably written.",
            "summary_of_the_review": "The paper answers a natural research question on defending against adversarial attacks in time series forecasting problems. This is a natural and well-motivated problem that is quite clearly answered and hence a non-trivial contribution to the literature.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_K2Yj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_K2Yj"
        ]
    },
    {
        "id": "M7-IbT5bSQ",
        "original": null,
        "number": 2,
        "cdate": 1666605663482,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605663482,
        "tmdate": 1668503826480,
        "tddate": null,
        "forum": "ctmLBs8lITa",
        "replyto": "ctmLBs8lITa",
        "invitation": "ICLR.cc/2023/Conference/Paper5918/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The submission studies adversarial attacks and defences in the context of multivariate probabilistic forecasting of time series. The threat model assumes that the attacker can perturb past values and that the sets of target series and perturbed series are distinct, with an additional sparsity contraint on the set of perturbed series.  ",
            "strength_and_weaknesses": "I find the main claim to be well supported as the paper covers all aspects of adversarial attacks on multivariate probabilistic forecasting. I am mostly satisfied with the mathematical treatment and the experiments appear sound. \n\nI have ambivalent feelings about the description of related work. The paper clearly differentiates from prior attacks on probabilistic time series forecasting by its multivariate setting. However, the presented attack and defense algorithms seem to be somewhat incremental on prior work, which creates a novelty concern. \n\n ",
            "clarity,_quality,_novelty_and_reproducibility": "To elaborate on my concerns above:\n- the threat model described in 3.1 seems directly taken from Dang-Nhu et al. (which you are already citing). In particular you are reusing the notation $\\chi$ and $t$ which was introduced by this paper. This is fine but it would make sens to properly attribute this. \n- as far as I understand, the \"mini-max\" defence falls into the category of standard adversarial training? I'm concerned that this section is only citing GAN papers which are distantly related. Could you please comment of the novelty of this method and properly discuss related work?\n-  My memories of randomised smoothing are somewhat distant but as far as I understand, theorem 4.1. is a rather standard and application-independent result? Are you able to explain what differences in the proof allow you to obtain a result valid for any $\\delta$ and to apply the result to a multivariate setting?\n\n\nI would also like to clarify some aspects of the contribution:\n- In the deterministic attack (3.2), since the sparsity constraint can be solved analytically, would it make sense to apply to use projected gradient descent also for this and project at each optimisation step rather than just at the end?\n- In your description of the probabilistic attack (3.3.), you are immediately factoring the distribution (last line of page 4). Not every distribution can be factored in this way. If you choose to make some kind of independence assumption in the modelling, you need to state it clearly.\n- The math of the probabilistic attack (3.3) appear sound to me, but I find this section to be a bit terse in explanations \n    - In the final step of algorithm 4, you are simply drawing $\\delta$ from the distribution. It is proven that *in expectation* this $\\delta$ will have the desired level of sparsity, but this is a probabilistic guarantee. Do you actually check that the drawn perturbation is sparse? \n    - I feel like I'm lacking some context about this probabilistic relaxation of the sparsity constraint. Is there a body of related literature? This section doesn't mention any kind of related work\n     - Algorithm 4 doesn't explain how you compute or approximate the outer expectation in equation (3.5). Does this build on the reparametrization in theorem 3.1? Is this a standard approach to reparametrizing discrete variables in a model? \n- In 5.2, you refer to increased $\\kappa$ as \"increased sparsity\". Intuitively I would see this as \"decreased sparsity\"",
            "summary_of_the_review": "I find the topic of this paper very interesting and the main claim to be well supported. However I have many questions and concerns about the clarity and novelty of the different algorithms described in the paper. I think that some additional explanations and improvements are needed to pass the acceptance bar. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_oCqG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_oCqG"
        ]
    },
    {
        "id": "4I7p8Bsd1cu",
        "original": null,
        "number": 3,
        "cdate": 1666672819694,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672819694,
        "tmdate": 1671077976451,
        "tddate": null,
        "forum": "ctmLBs8lITa",
        "replyto": "ctmLBs8lITa",
        "invitation": "ICLR.cc/2023/Conference/Paper5918/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, authors introduced an optimization-based adversarial attack to in-direct attack the forecasting performance. In addition, the authors proposed an protection approach to protect the model from the proposed attack.",
            "strength_and_weaknesses": "Strength\n1. The paper touches on an interesting paper on time series forecasting\n2. The experiment is solid\n\nWeakness\n1. The high-level idea of the method is very similar to the classical techniques used in other closed research fields such as the time series of classification as [1]\n2. Proposed method only evaluated on DeepAR and DeepVAR\n3. Lacking of graphical examples of how time series in different noise-level looks like.\n\nDetailed Comments that needs to be addressed by authors: See the summary of review.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. The solution is sort of similar to existing adversarial attacks bu only a few papers that are addressed the adversarial attack issue in time series forecasting. I did not find the source code attached to the manuscript.",
            "summary_of_the_review": "1. The proposed approach was only tested with DeepAR and DeepVAR forecasting models. First of all, why only tested in DeepAR-based models, which is not the optimal solution in general? For example, is the proposed work also can protect the Deep State Space Model from attacking? How about other non-probabilistic forecasting models? For example, NBeats or Informer. \n\n2. The technique used here is very standard. While only limited work focuses on time series forecasting, a lot of work has been done in time series classification [1]. The high-level idea of formalizing the objective equation is very similar. The authors should mention what is the benefit of the novel loss function.\n\n3. In the experiment, the model is evaluated on WQLoss. Why do we only use WQLoss? Intuitively, CRPS, RMSE, and MAE are all valid evaluation criteria. Besides, from Fig. 1, I personally do not see the attack as a success because it does not change a lot of the forecasting. You need to show what the forecasting with confidence interval looks like to justify your claim.\n  \n4. If using i.i.d based forecasting, what will happen for the in-direct attack?\n\n* Thank you for the discussion. I believe the authors successfully resolve most of my concerns. I increase my score to 6.\n\n5. The forecasting length is short compared with the long-term forecasting model. What is the performance of different lengths? Compared the performance of different lengths may be needed.\n\n6. Mini-max Defense is specially designed for the proposed attack, but if the attack is not that aggressive, what somethings could happen?\n\n7. Visually speaking, how are the noisy-added time series look under different noise-level? \n\n[1] Zhang T, Liu S, Wang Y, Fardad M. Generation of low distortion adversarial attacks via convex programming. In2019 IEEE International Conference on Data Mining (ICDM) 2019 Nov 8 (pp. 1486-1491). IEEE.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_hzNw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_hzNw"
        ]
    },
    {
        "id": "C9Oepe13DGg",
        "original": null,
        "number": 4,
        "cdate": 1667238994163,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667238994163,
        "tmdate": 1667238994163,
        "tddate": null,
        "forum": "ctmLBs8lITa",
        "replyto": "ctmLBs8lITa",
        "invitation": "ICLR.cc/2023/Conference/Paper5918/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper studies adversarial attacks on multivariate forecasting models - a problem that has not been explored in prior work but is practically relevant due to the prevalence of these models in various real-world tasks. The authors first propose sparse, white-box deterministic indirect attacks that add adversarial perturbations to a time series different from the target series.  To make the attack hard to detect, probabilistic attacks. Next, the authors design two defenses in this setting based on randomized smoothing and mini-max optimization. Experimental evaluation is performed on a variety of datasets. The results show that probabilistic attacks are more effective than deterministic ones while the defenses enable more robustness against these attacks than no defense. ",
            "strength_and_weaknesses": "Strengths:\n\n1. The threat model considered here is novel and interesting and may lead to more work in this area.\n\n2. The paper is well-organized, easy to read, and accessible to a broad audience.\n\n3. There is enough technical novelty in the design of probabilistic attacks and the formulation of mini-max defense for multivariate forecasting models for publication at ICLR.\n\n4. The experimental evaluation supports the main claims made in the paper. I provide some suggestions below to make the evaluation more compelling.\n\nWeaknesses:\n\n1. The attacks assume an offline setting. It is not clear if the attacks work in an online setting where the time series data is generated on the fly. This is particularly relevant for stock market predictions.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality: The main claims and experiments in this paper are well-described. The authors should consider providing the runtime of running attacks and defenses. Further, they should also study the attack performance when time series other than {1} are attacked as well as in the case when multiple target series can be attacked. What is the value of the threshold for the perturbation at each coordinate in the experiments? It is also not clear if the randomized defense designed here is a certified one or only provides empirical protection. If its a certified defense, then what guarantees does it give?\n\nNovelty: The high-level idea behind the deterministic attack presented here has been explored for images in https://arxiv.org/pdf/1909.05040v1.pdf. The algorithm for the differentiable probabilistic attack is new.  The randomized smoothing defense is a straightforward adaptation of RS for other domains while the formulation of the mini-max defense is novel.\n\nReproducibility: Sufficient details are provided. the authors do not mention if they will release the code of their attacks.",
            "summary_of_the_review": "In summary, this is a well-written paper that tackles an important but unexplored problem in the literature that should lead to more work in this area. The technical claims are novel and the contributions are supported by evaluation results. I believe that this paper is a good candidate for acceptance at ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_qQby"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5918/Reviewer_qQby"
        ]
    }
]