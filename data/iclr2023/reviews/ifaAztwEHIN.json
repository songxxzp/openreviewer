[
    {
        "id": "kc6nQXbLOPE",
        "original": null,
        "number": 1,
        "cdate": 1666604787112,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604787112,
        "tmdate": 1669137258969,
        "tddate": null,
        "forum": "ifaAztwEHIN",
        "replyto": "ifaAztwEHIN",
        "invitation": "ICLR.cc/2023/Conference/Paper2616/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper describes an auto-encoder setup which aims to disentangle content and style using multiple inductive biases. (1) The style given by selecting random times-slices of the encoded time series, (2) the encoded time series need to be predictable 1-step-ahead using a recurrent network R and (3) the encoded time series need to be equivariant to random translation or rotations S. The setup is tested on two synthetic datasets: a synthesized audio dataset with ascending and descending note sequences, and an short video clips of a bouncing ball. On these datasets, pitch or ball position seem to be well separated from the timber and the instrument texture.",
            "strength_and_weaknesses": "The paper is enjoyable to read and the idea is simple and well described.\n\n1) I think a more precise way to describe the inductive bias of the network architecture is that it \"separates some latent equivariant spatio-temporal features from time-invariant features\". I think it would be more didactic to spell this out in the intro and intuition section because currently the description remains on the high level description of \"physical symmetries\" or \"pitch vs. timbre\" disentanglement which I find less precise and specific to this work.\n\n2) Disentanglement of content versus style is an important topic, for instance to separate pitch, timbre and instrumental features. I am not convinced however that this technique has a strong reason to extract \"only\" the pitch with arbitrary audio because there are many other 1D features in music which can be described with a latent equivariant temporal series: loudness, note frequency, RMS ratio of high frequency vs. low frequency etc.. All these features are likely to be independent from the pitch in a real dataset and may well be what is extracting in to the latent time series z after convergence. If there is no way to prove this wrong, it might be good to report that in the discussion.\n\n3) For the reason above, I expect that the inductive bias of the model would not be expressive enough to describe the full dataset. So I would expect a substantial loss of information in the latent representation of the auto-encoder. In fact this might even be true on the simple synthetic datasets that are considered because there are no metric report the \"quality\" of the reconstruction against the beta-VAE for instance. Maybe the beta-VAE focuses on other important features which are more crucial for the reconstruction of the audio than the pitch? Or for the same argument as before, the re-constructed audio is likely to have a wrong timber, loundness, etc.. if the pitch is the only time-variable latent that is captured. Reporting a metric of audio reconstruction quality would be a good start.\n\n4) One possible flaw: the number of samples in the training sets look ridiculously small. I suspect that the model might not generalize well to the test/validation set in this setting. It is therefore crucial to state explicitly in the captions of ALL figures and tables if performance metric (or plotted data) is shown for samples from the training or testing sets.\n\n5) It is not very standard to put the related work in discussion rather than introduction. It makes the whole idea of group symmetry sound a lot model novel that it is at first sight. I would encourage the authors to put at least a few references about disentangling AEs and group symmetry in the intro for this purpose. Also i am wondering but I am not sure, wouldn't it be fair to cite some papers from the Max welling group who have used extensively symmetry groups to generate equivariant representations? Here are two suggestions:\n\nhttp://proceedings.mlr.press/v121/ilse20a.html\n\nhttp://proceedings.mlr.press/v48/cohenc16.html\n",
            "clarity,_quality,_novelty_and_reproducibility": "The figure captions are often too short to understand what is plotted. This was mainly a problem for me in Figure 3: what exactly was the procedure to plot these two figures?  In Figure 4, the normalization by the variance or squared norm of z is necessary to make sense of the y-axis across model and within a model between content and style. It might also be useful to recall the definition of $\\Delta z$ in the caption of Figure 4. I do not know what is SPS-AE in comparison with SPS-VAE in Figure 7. More information is necessary to make sense of Figure 9.\n\nThe exact definition of the random selection of times for the style vector is important: how many time steps are selected for instance?\n\nIt is not clear to me what are the instrument and timber which are used in the training set and testing sets. When reporting the sound fonts being used, more details would be necessary to know exactly which instrument (how many?), timber, loundness, are chosen, and whether the same not sequences are testing with all instruments in balanced fashion or not.",
            "summary_of_the_review": "The idea is simple and well described, but it is not clear whether this method would be capable to disentangle content and style on a real dataset because (1) it is only tested on simple synthetic datasets and (2) some simplifying 1D-latent assumptions are necessary for the network architecture to reconstruct the input faithfully.\n\nI believe I will increase my score if my comments are addressed appropriately and I become sure that the experiments and the Figures are flawless and the paper is transparent about the computed performance metrics (is that train or test? how many instruments? normalization? why choosing beta-VAE as a baseline and then GMVAE etc...)",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_rnjU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_rnjU"
        ]
    },
    {
        "id": "3Rmr7H46yN_",
        "original": null,
        "number": 2,
        "cdate": 1666971147967,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666971147967,
        "tmdate": 1666972883675,
        "tddate": null,
        "forum": "ifaAztwEHIN",
        "replyto": "ifaAztwEHIN",
        "invitation": "ICLR.cc/2023/Conference/Paper2616/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a self-supervised learning method that learns disentangled and interpretable representations based on physical symmetry from time-series data. The experiments with monotonic instrument sounds and monocular videos of bouncing ball validate the method by showing disentanglement in pitch-timbre and local-color, respectively. In addition, they suggested the representation augmentation technique that lead to lower linear projection loss and improves the disentanglement. \n\n \n\n",
            "strength_and_weaknesses": "Strengths\n- The application of physical symmetry to unsupervised representation learning is very intriguing.\n- Experimental results clearly validates that the model learns the disentangled and interpretable representations as targeted.\n- The representation augmentation idea sounds very novel. The experiment shows the effectiveness well. \n\n\nWeaknesses\n- The dataset used to validate the proposed learning model are too simple: monotonic musical instrument and monocular videos of bouncing ball. It is not clear how the model can be extended to more complicated data, for example, polyphonic and multi-instrument music and real-wold videos.\n- If the model is applied to a very long time-series data, RNN would have a limitation in learning the long-term dependency. If the Transformer model is used instead, it can be plugged in the proposed model?  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity \n- This paper is easy to read. The examples are presented well to validate the expected result. \n- The mathematics are neat and described well.\n- The choice of the audio input representation is important but it is not explained why the spectrogram with the linear frequency scale is used.  What if mel spectrogram or other log-frequency-scaled time-frequency representations (which has a shift-invariant property along the log-frequency axis) are used? \n\nQuality \n- The experiment validates the disentanglement in different perspectives using several evaluation metrics and visualizations \n- The visual examples are convincing\n- Related work are comprehensive and suitable to understand the relevant topics  \n- The supplementary materials provide more intuitive understanding of the results\n- Minor fixes :  (page 4) \"the content factor be to\" --> \"the content factor to be\" (this appears twice) \n\nNovelty \n- The proposed model is well grounded by the physics-based principle.\n- The representation augmentation also sound like a training technique \n\nReproducibility\n- The author provides the training details, and source code\n",
            "summary_of_the_review": "This paper is very interesting to read and the intuition from the fields of physics is implemented well as a model that learns disentangled and interpretable representations without any labels. Also, it suggests the novel representation augmentation technique for more effective model training. The experiment and analysis clearly show that  the model successively achieves the goal. \n\nHowever, my overall impression is that this paper is in the stage of proof-of-concept. The example data are quite simple: single harmonic pitch and single ball object. The experiment focuses on decoupling the latent space into locational features (pitch in spectrogram and ball position) and the rest. It is not trivial to apply the proposed model to more complex data where the content latent features change over time in a more complicated manner (e.g., polyphonic music). The authors should clearly envision the potential of the proposed model that be applied to the complex data. \n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_5zXw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_5zXw"
        ]
    },
    {
        "id": "K30yKu3oT9s",
        "original": null,
        "number": 3,
        "cdate": 1667164460997,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667164460997,
        "tmdate": 1667164850869,
        "tddate": null,
        "forum": "ifaAztwEHIN",
        "replyto": "ifaAztwEHIN",
        "invitation": "ICLR.cc/2023/Conference/Paper2616/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a method to train sequence models that encourages disentangling physical/dynamic features (\"content\") from constant features (\"style\"). The method partitions the latent features into two subsets and enforces certain symmetries by applying appropriate random transformations and penalizing the latent transition model (an RNN) for deviations from equivariance. Experiments on synthetic data show that the content features take on straightforward interpretable meanings, and that style changes in the input do not affect the content features.",
            "strength_and_weaknesses": "Strengths:\n  - The approach is simple and sound.\n  - It is easy to understand what is being done.\n  - The experiments are convincing, if contrived (more below).\nWeaknesses:\n  - There is no discussion of the random pooling on the style. This random pooling enforces its own symmetry -- it encourages the style representation to be constant over time. I believe that without the random pooling, the method would not work; the model would choose to convey all its information through the unconstrained style channel and not bother with the content channel.\n  - Related to the previous point, the effectiveness of the method hinges on being able to partition the latent space into subspaces and coming up with appropriate symmetries for all subspaces. The experiments are performed on synthetic data that is contrived to have this exact physical-content-plus-constant-style breakdown, and it is unclear what one would do in real-world settings where this breakdown does not make sense.\n  - The experiments that study the impact of style changes in the input use norms to measure the extent of change in the latents. Norms aren't really meaningful here; a small delta norm ||dx|| may correspond to a large change if ||x|| << ||dx||, and a large delta norm ||dx|| may correspond to a small change if ||x|| >> ||dx||. Consider using relative norms ||dx||/||x|| instead.",
            "clarity,_quality,_novelty_and_reproducibility": "I was confused for longer than I should have been about why the authors do not do full 3D transformations on the video data? Consequently in Section 4.2.3 I was confused by the dicussion of how \"the ablation model does not differently constrain z2 (corresponding to the y-axis)\". It took me a while to figure out that the y axis is special because of gravity. :-)\n\nOtherwise the paper is plenty clear.\n\nThe submission is high quality, although it is unclear if the claims will hold up on real data.\n\nI do not know the literature well enough to judge the novelty of the contribution. To be honest it feels like an obvious way to enforce symmetry, it's just that these simple symmetries almost never apply. (E.g. the symmetries used here aren't present in real audio or video.)\n\nThe authors have provided PyTorch code to reproduce their experiments.",
            "summary_of_the_review": "This is a solid contribution. My main criticism is the applicability of the method beyond very simple settings.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_AY1K"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_AY1K"
        ]
    },
    {
        "id": "GLLdTPGfaJE",
        "original": null,
        "number": 4,
        "cdate": 1667381761098,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667381761098,
        "tmdate": 1669621210558,
        "tddate": null,
        "forum": "ifaAztwEHIN",
        "replyto": "ifaAztwEHIN",
        "invitation": "ICLR.cc/2023/Conference/Paper2616/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes novel ways to enforce an inductive bias into a temporal auto-encoder model, by:\n1) enforcing that the R part of the model should be able to operate on both the original version of the time-varying embeddings and also on a transformed version.\n2) separating out the per-session and per-frame parts of the embeddings.\n\nThe motivation of enforcing 1. is to allow for an inductive bias that does not require domain expertise to design.  However, the proposal requires domain expertise to choose the S transformation, which goes against the original motivation.\n",
            "strength_and_weaknesses": "Strengths:\n- It is not trivial to experimentally assess whether the proposal is doing what the authors claim that it should be doing.  The authors go through a lot of effort to run many different types of innovative tests to assess this behaviour.\n\nWeaknesses relating to unclear description of the proposed approach:\n- How do you split z into z_s and z_c?\n- Why does transforming z through S yield a fake sequence?  What does \"fake sequence\" mean in this context?\n- The model described in figure 2 does not have any K.  Yet, section 3.3 mentions K different transformations.  Are the descriptions consistent?\n- In the beta-VAE baseline in figure 3, how is the pitch estimated from the multi-dimensional embeddings?\n- What is a \"bouncing force\"?\n\nWeaknesses relating to lack of motivation for why design choices were made:\n- What is the motivation for using random pooling in P, as opposed to mean pooling or self-attention?\n- What is the motivation for having each of the three branches in the model?\n- In the introduction, the proposal is motivated as being better than previous works, because there is no need for domain expertise.  However, S needs to be chosen with domain expertise.  Is the original motivation still satisfied?\n- What is the motivation and mathematical definition of each term in the training criterion?  \"BCE\" is not defined in the paper.  l_2 is not defined.  Why does the KL divergence measure a distance between z_i and a standard Gaussian?\n\nWeaknesses relating to ambiguity in the language used:\n- What does \"group assumption\" mean?\n\nWeaknesses relating to questionable design choices:\n- It is claimed that the proposed inductive bias separates out pitch and timbre, or location and colour.  How do you know that these are the only factors involved?  What about other factors, such as volume, speed, starting location, etc.?\n- In section 4.1.3, how do you know that the difference in magnitude of delta z_c and delta z_s is not because z_c and z_s learn to have different dynamic ranges?  Perhaps delta z_c and delta z_s should first be normalised by the dynamic ranges of z_c and z_s.\n- In section 4.2.2, why do the movement directions conveniently align with the standard basis of z?  Why do they not align with an arbitrary rotation of the standard basis of z?  Maybe the movement directions are also aligned with an arbitrary rotation of the z basis for beta-VAE?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The use of English is good.  I did not find any spelling or grammatical inaccuracies.\n\nThe concepts proposed and designs chosen in this paper are not well motivated in the text.  A reader can possibly guess why the authors made each proposal and design choice, but it would be better to not leave the reader guessing.\n\nThe paper proposes two novel forms of inductive biases that can be used, with the aim of not needing domain expertise.  However, the proposal does require domain expertise to choose S.\n\nThe data and modelling approached used in the experiments should be reproducible.  A Github repository exists for this paper.\n",
            "summary_of_the_review": "The proposal is motivated as being able to avoid domain expertise, but in the end domain expertise is needed to choose S.\nThe design choices are not well motivated in the text.\n\nIthenticate similarity is 3%, which is good.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_9KCD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2616/Reviewer_9KCD"
        ]
    }
]