[
    {
        "id": "NBvilHA9vx",
        "original": null,
        "number": 1,
        "cdate": 1666162256500,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666162256500,
        "tmdate": 1666163024189,
        "tddate": null,
        "forum": "D8ulVmpjzYX",
        "replyto": "D8ulVmpjzYX",
        "invitation": "ICLR.cc/2023/Conference/Paper5572/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper addresses the problem of continual learning with a novel exemplar selecting algorithm.\nThe authors claim that selecting the exemplars based on PCA-based direction well addresses the catastrophic forgetting problem of the datasets with high intra-class variance.\nThe experimental results on various benchmarks show the effectiveness of the proposed framework.",
            "strength_and_weaknesses": "- Strengths\n    - The proposed framework demonstrates better performance than other baselines for the newly conducted benchmarks, Sports 73 and Sports 100.\n    - The idea of sampling the most unaffected data along the principal axis seems novel and interesting.\n    \n- Weaknesses\n    - The writing quality of the paper is far behind the bar of top-tier conferences like ICLR.\n        - For instance, what is the point of the first paragraph of the introduction section? The paragraph consists of intro to CF, data distribution and class imbalance, the goal of this research, and etc. The paragraph should be split into multiple paragraphs to represent the crucial points for the authors' claim.\n        - Formatting issues\n            - Missing numbering for some subsections (e.g., Evaluation Metrics) and sections (e.g., Conclusion).\n            - Inconsistency of the format for the references.\n    - Datasets\n        - Is there any quantitative evidence that sports datasets have higher variance than other common datasets, such as CIFAR-100 and ImageNet, which are widely used for continual learning benchmarks? For me, the claim is not that convincing since many sports-based video datasets, such as UCF-101, or Fine-gym, do not have large intra-class variance. While I\u2019m not an expert on the Sports 73 or Sports 100 datasets, I\u2019m not sure why such datasets have high variance and are expected to have many outliers. Actually, when I schemed the Sport 100 datasets on the Kaggle page, it seems the datasets have less variance than CIFAR or ImageNet, since the viewpoint of camera and poses of actors seem pretty similar to each data in the same class. The claim that \u201cSports images were taken indoors and outdoors in diverse lighting conditions\u201d in the Section 5.1 also seems inappropriate since the augmenting contrast is one of the widely used augmentation strategies, and thus the diverse lighting will be considered when we train datasets like ImageNet with strong data augmentation.\n    - Possible discussion in the Methods section\n        - Selection of exemplars\n            - As far as I understand, the sampled exemplars by $i$th principal direction and $j$th (where $i < j$) direction are not related to each other much. Then, the median points sampled by $j$th direction could be the outliers for $i$th direction, since two different principal axes are orthogonal. While it might be the extreme case, I think it might happen quite often when $m$ increases since the data embeddings used for sampling lie in the high-dimensional space. The claim of the paper could be improved if the authors provide any mathematical proof or intuitive explanation for this.\n            - In the Abstract section, there is a sentence \"herding, which is a way to select a random looking sample by a deterministic algorithm\". However, the proposed PCA-based framework is also almost deterministic given the dataset except for the case that some directions share the same singular values. Moreover, what do the authors mean that herding selects a random looking sample, while it selects the samples closest to the mean class vector?\n        - Generating balanced dataset using data augmentation\n            - What is the reason for generating data only for $r_k^i = \\|c_j^i\\| - \\|c_k^i\\|$? It might be better to generate $\\|c_j^i\\|$ data for each class using KeepAugment and replace $\\|c_k^i\\|$, rather than just generating $\\|r_k^i\\|$ to boost the regularization effect.\n    - Experimental results are not sufficient to support the effectiveness of the proposed framework.\n        - The combination of other sampling algorithms and the diverse data augmentation strategy must be studied more deeply.\n            - According to Table 2, it seems KeepAugment highly affects the performance. Then, it is worth checking the performance of other baselines (RM and GDumb) equipped with KeepAugment. Moreover, the good results on TinyImageNet in Figure 5 in Appendix B also might be due to the effect of KeepAugment, since the difference is marginal. Therefore, the effectiveness of the proposed algorithm for the balanced datasets is not convincing. It might be better to show the results on CIFAR-100 datasets, which is a widely used benchmark for class incremental learning. Training details for other baselines on Sports 73 and Sports 100 datasets are also missing.\n            - What if the model employs different data augmentation strategies (e.g., CutMix, etc., ), rather than KeepAugment?\n        - It is unclear whether improvement in performance is driven by class-balancing or augmented data.\n            - What is the reason for generating data only for $r_k^i = \\|c_j^i\\| - \\|c_k^i\\|$? It might be better to generate $\\|c_j^i\\|$ data for each class using KeepAugment and replace $\\|c_k^i\\|$, rather than just generating $\\|r_k^i\\|$ to boost the regularization effect.\n    - Minor\n        - Need consistency for the term \u201cPrincipal Component **a**nalysis\u201d and \u201cPrincipal Component **A**nalysis\u201d\n        - It seems the columns of Table 2 should be exchanged with each other, according to Table 1.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity : The paper has some ambiguous parts for experimental details, as mentioned in the weakness section.\n- Quality : The presentation of the paper is not that neat.\n- Novelty : The idea of using PCA to sample exemplars seems novel.\n- Reproducibility : While the authors do not provide their source code, the implementation details for the main framework seems sufficient. However, the implementation details for the baseline algorithms should be added, since the authors conducted the experiments for Sports 73 and Sports 100 for the first time.",
            "summary_of_the_review": "Despite the paper studies some novel concepts with respect to PCA-based exemplar sampling, I hardly agree that the current version of the submission meets the bar of ICLR, since there are some missing experiments as stated in the weakness section and the writing quality should be improved.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_JcYz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_JcYz"
        ]
    },
    {
        "id": "8k4eJEjjwu",
        "original": null,
        "number": 2,
        "cdate": 1666482168604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666482168604,
        "tmdate": 1666482168604,
        "tddate": null,
        "forum": "D8ulVmpjzYX",
        "replyto": "D8ulVmpjzYX",
        "invitation": "ICLR.cc/2023/Conference/Paper5572/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Training machine learning on streaming data sets has been an important problem with the widespread use of online systems. This often requires selecting specific examples to update your model. The paper proposes a PCA-based exemplar sampling algorithm. \n",
            "strength_and_weaknesses": "The proposed technique includes a simple PCA-based dimension reduction and mapping the data along these dimensions and sample data with enough diversity. With this technique, outliers are not included in the training data. There has been a decent amount of experimentation and details provided.  I have seen some drawbacks in the paper, though.\n\n1. How big of a problem is this? What is the real-life use case and significance of the problem, and the innovation aspect (scope/impact) is not clear? \n2. The proposed solution is simple, but I would be surprised if something along these lines has never been tried (I did not do a thorough literature survey, but it seems more like a simple use case of PCA). With this regard, I think the paper lacks novelty. \n3. There can be more depth and rigor in the experimentation. For example, PCA provides good strength in eliminating outliers. It sort of smooths out the training data\u2014like a filter. However, it comes up with removing more edge/nuance cases in a data set as well. Usually, these samples are less in population and lost in the PCA analysis\u2014often considered as noise. However, they are very valuable with respect to providing unique information for the training. It is not clear what the trade-off is here in this case and how we can address selecting such under-represented groups in this framework.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The Paper is written mostly well, with a bit of unnecessary verbosity in the introduction. The concepts explained are basic  It could have benefited from more visuals and be more compact.\n",
            "summary_of_the_review": "I don't think that the paper is strong enough to be at ICLR. From experimentation to justifying the importance of the problem, the novelty in the proposed solution, there are many gaps. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_Gq7Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_Gq7Z"
        ]
    },
    {
        "id": "_Bibmw0kLq",
        "original": null,
        "number": 3,
        "cdate": 1666529007346,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666529007346,
        "tmdate": 1666529090195,
        "tddate": null,
        "forum": "D8ulVmpjzYX",
        "replyto": "D8ulVmpjzYX",
        "invitation": "ICLR.cc/2023/Conference/Paper5572/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": " In this paper, the other proposes a novel selection approach based on\nPrincipal Component analysis and median sampling. This approach avoids the\npitfalls due to outliers and is both simple to implement and use across various\nincremental machine learning models. It also has independent usage as a sampling\nalgorithm.\n",
            "strength_and_weaknesses": "Strength\uff1a\nIn general, the article has a complete structure and clear thinking.\nThe experimental setting is reasonable, experiments verified the proposed algorithms on Sports  datasets.\n\nWeaknesses\uff1a\nThe description of the proposed method is not detailed enough, and the innovation point is not outstanding enough.\nThis paper mainly focuses on the effect of the strategy, and it is suggested to add more theories to support the strategy, so that the method can be more explainable.\nThe paper points out that the median is more suitable than the mean. It is suggested to carry out relevant experimental demonstration in the experimental part.\n",
            "clarity,_quality,_novelty_and_reproducibility": "In general, the paper has a complete structure, clear thinking and some innovation.",
            "summary_of_the_review": "Overall, the article has a complete structure and clear thinking. But the content needs to be further improved, including experiment and theory.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_RPyF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5572/Reviewer_RPyF"
        ]
    }
]