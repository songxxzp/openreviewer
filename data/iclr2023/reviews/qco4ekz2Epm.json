[
    {
        "id": "auvs_nOBA1",
        "original": null,
        "number": 1,
        "cdate": 1666279188452,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666279188452,
        "tmdate": 1666279188452,
        "tddate": null,
        "forum": "qco4ekz2Epm",
        "replyto": "qco4ekz2Epm",
        "invitation": "ICLR.cc/2023/Conference/Paper4473/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work focuses on a more realistic online continual learning---learning continuously changing data distribution without explicit task boundary, which is called boundary-free setup in this paper. The main contributions can be summarized as:\n\n(1) Studying online CL with continuous data stream setup without explicit task boundary, including newly proposed periodic CL setup.\n\n(2) Proposing an online boundary-free CL method that uses scheduled transfer of past knowledge.\n\n(3) Proposing to learn to balance amount of using past and present knowledge.\n\n(4) Proposing new metrics.",
            "strength_and_weaknesses": "My main concern is about the proposed approach.\n\n(1) What is EMA? How to achieve the EMA model ($M_{\\alpha}$ or $M_{\\beta}$)? How to achieve the distillation model ($f_{SDP}(x)$)? It is necessary to describe them in details.\n\n(2) I as a little bit confused about the core ideal of proposed method. Is the distillation model used to guide training model? Please provide a detail description of your methods by understandable way, like flowchart or pseudocode.",
            "clarity,_quality,_novelty_and_reproducibility": "Good quality.\nPoor clarity.\nNice originality of the work.",
            "summary_of_the_review": "Marginally below the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_bdyM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_bdyM"
        ]
    },
    {
        "id": "d49zxcXhjC",
        "original": null,
        "number": 2,
        "cdate": 1666688620543,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666688620543,
        "tmdate": 1666689425376,
        "tddate": null,
        "forum": "qco4ekz2Epm",
        "replyto": "qco4ekz2Epm",
        "invitation": "ICLR.cc/2023/Conference/Paper4473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a novel online boundary-free CL method on the realistic boundary-free CL setting, including the newly proposed periodic setup. Moreover, new mutual information-based metric is proposed to measure the loss of past knowledge and gain of new knowledge. Comprehensive experiments have been conducted to evaluate the effectiveness of the method.",
            "strength_and_weaknesses": "Strengths:\n- The topic of boundary-free CL is interesting and important.\n- The proposed metrics to measure loss in boundary-free CL is novel.\n- The data-driven balancing part is well-motivated\n\nWeakness:\n- The description of the EMA part is a bit unclear.\n- I am not very clear about why periodic Gaussian distribution is actually challenging in the CL setting. The periodic natural of the distribution naturally serves as a \"replay\" mechanism during the CL process. Therefore, shouldn't the setting be easier than the existing Gaussian schedule setting?",
            "clarity,_quality,_novelty_and_reproducibility": "The overall quality of the paper are good, despite that some parts are not clear.\nThe topic and settings are novel.\nThe results should be reproducible with details in the paper and released code.",
            "summary_of_the_review": "I think the paper focus on an important problem, boundary-free CL, with a relatively novel solution. Therefore, I recommend weak acceptance initially.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_Y7gj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_Y7gj"
        ]
    },
    {
        "id": "1tLahIrOtFW",
        "original": null,
        "number": 3,
        "cdate": 1666885176574,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666885176574,
        "tmdate": 1666885176574,
        "tddate": null,
        "forum": "qco4ekz2Epm",
        "replyto": "qco4ekz2Epm",
        "invitation": "ICLR.cc/2023/Conference/Paper4473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a more challenging and realistic setup for online- continual learning in which there is no explicit task boundary called a boundary-free setup. Due to the lack of task boundaries, it is difficult to find past information that needs to be preserved to identify the stability-plasticity dilemma. It proposes a scheduled transfer of previously learned knowledge to address this issue. It also suggests learning to balance the amount of using past and present knowledge. Further,  this paper proposes new metrics to measure the loss of past knowledge (i.e., forgetting) and the gain of new knowledge based on information theory.\n\n\n\n\n\n \n\n\n",
            "strength_and_weaknesses": "Strengths:\n1- Most of the existing continual learning approaches have proposed the task-split setup in which task boundaries are available and well exploited\nin various offline/online CL methods. However, the task-split setup is not suitable for the realistic scenario. In contrast to the prior work, this paper proposes a boundary-free task setup that is more challenging and aligned with the realistic scenario. It removes the notion of artificial task boundary; instead, the data arrival follows a certain distribution.\n \n2- The conventional approaches require the accuracy of the previous task to measure the knowledge forgetting, which is not possible in the proposed boundary-free setup. Therefore this paper presents new metrics for measuring forgetting and the ability to learn new knowledge by computing loss and gain of knowledge based on information theory.\n\n3- To determine the amount of past knowledge to be transferred in a continuous fashion, it proposes a method to leverage the previously learned knowledge by a skewed bell-shaped weighting function in a distillation framework named scheduled data prior. \n\n4- The proposed method shows significant improvement in all the benchmark datasets compared to the state-of-the-art techniques for both the setup, task boundary-free, and disjoint task split.\n\n5-  A detailed ablation study is provided to support the significance of the proposed approach.\n\n Weaknesses:\n1-  It assumes a strict assumption that the streaming data comes from the gaussian distribution, which is not practically true because real data follows a complex distribution. Is it possible to predict the task boundaries based on identifying out-of-distribution distribution between tasks? Or it would be more interesting if it covered complex distribution.\n\n2-  The extreme case for continual learning is where the data examples are available only once, unlike the replay-based approaches, where the old data may be available for future training. Applying the proposed framework to this challenging continual setup would be interesting.\n\n\n\n\n\n\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper addressed a more realistic and challenging continual learning setup where the task boundaries are unknown. It also proposed a novel evaluation metric to identify the knowledge loss and knowledge gain for previous and current tasks. The paper includes a solid ablation analysis to support the claims.",
            "summary_of_the_review": "Overall, I found the paper interesting and conducted sufficient experiments for justifications. The paper addresses more challenging and practical issues in the existing continual learning approaches. For more details, please see the strength and weaknesses section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_1ivp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_1ivp"
        ]
    },
    {
        "id": "DRGk7SBv_Pk",
        "original": null,
        "number": 4,
        "cdate": 1667213414830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667213414830,
        "tmdate": 1668518784742,
        "tddate": null,
        "forum": "qco4ekz2Epm",
        "replyto": "qco4ekz2Epm",
        "invitation": "ICLR.cc/2023/Conference/Paper4473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies online continual learning in the boundary-free setting, i.e. we do not know when a task starts or ends (or whether it ends at all, like in the periodic setup). The paper then proposes two metrics: knowledge loss and knowledge gain, which measure the difference in performance between two time points t_1 and t_2 (i.e., how the performance improves/worsens between $t_1$ and $t_2$).\n\nTo prevent forgetting, the paper builds upon knowledge distillation strategies. To accumulate the previous weights for the teacher model, the authors propose a different schedule, which they call Scheduled Data Prior (SDP) and show that it works better than EMA. They also use a learnable coefficient to balance between the current classification loss and the knowledge distillation loss.\n\nThe ideas are tested on CIFAR 10/100 and TinyImageNet/ImageNet and the proposed approach beats the previous SotA (i.e., CLIB) by ~5-10% on them in terms of $A_\\text{AUC}$ on all the setups.\n",
            "strength_and_weaknesses": "Strengths:\n1. The overall approach is more or less simple.\n2. Authors explore more realistic setups of CL, which feels to me being a big problem.\n3. The experimental evaluation looks quite comprehensive.\n4. The writing is easy to follow.\n\nWeaknesses:\n1. While it's true that there is a lot of real-world data is periodic, I do not understand how improving on the proposed periodic benchmarks can improve the performance of some real-world system which operates on periodic data. Could you please provide me an example of some real-world system which operates on periodic data and suffers from forgetting?\n2. In terms of complexity/performance trade-off, just using EMA without learning the balancing coefficient looks better to me.\n3. The proposed metrics:\n    - are not well-motivated. It is not clear why $A_\\text{AUC}$ is bad, what important properties do KLR and KGL measure? Why should we measure KLR and KGL, they seem to always correlate with $A_\\text{AUC}$ anyway. For (2), \n    - seem to be overly-complicated. If I understood Section 4 correctly, at the end those information-theory-based metrics go down to \"average accuracy loss over some set of classes\" or \"average accuracy gain over some set of classes\". Then, why not measure these values directly? It would be both more intuitive and have better scaling (one always know the lower/upper bound for them).\n4. Learning the balancing coefficient looks tricky to me. The model can just learn to ignore rehearsing the past data completely. Could you please provide the plots of how this balancing coefficient changes? Also, how do you initialize it? Do you regularize it somehow?\n\nQuestions:\n1. Do you use any replay buffer for the knowledge distillation loss or you compute it on the currently available data?\n2. Do I get it right, that for EMA you store just a single checkpoint of the past model, and for SDP you store two checkpoints?\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**: In general, this paper is easy to follow, but there are quite some places which could be elaborated on:\n- it is not too clear how KLR/KGL are estimated in practice. If I understood this correctly, then in practice, the authors compute the accuracies/probabilities for some set of classes at different timestamps and then those accuracies/probabilities are then plugged in into the equations from Section 4 (Please, correct me if I am wrong). Ideally, a pseudo-code would help a reader to understand this better.\n- it is not immediately clear from what is the difference between \"boundary-free\" and just traditional task-free CL and I didn't find it to be discussed in the related work section.\n- it is not quite clear why \"scheduled data prior\" is called so. If I understand it correctly, there is no schedule in the models' mixing strategy, it is just an analog of EMA.\n- there are no details on the experiments from Table 1 (how many tasks, whether it is disjoint or not etc.)\n- it is not specified whether a replay buffer is used to rehearse the previous knowledge (like in DER) or not (like in LwF)\n\n**Quality**. Though, the paper would benefit from additional visualizations and ablations. For example, visualize how the loss balancing parameter change over time. Or show how the performance changes depending on the number of tasks. Also, it would be very interesting to see how much memory is being used during training (for storing the teachers and/or the replay buffer) compared to other methods. Also, the comparison to EMA was performed without tuning EMA hyperparameters.\n\n**Novelty**. All 4 contributions are novel, but seem minor or not too beneficial.\n\n**Reproducibility**. I believe that the paper contains enough details to be reproduced (up to some negligible differences). Also, the authors aim to release the source code.",
            "summary_of_the_review": "This paper feels like a \"big bag of small contributions\", where each of the contributions could be dropped without affecting the overall paper quality much. In terms of complexity/performance tradeoff, just using EMA without the learnable loss balancing coefficient still looks better to me (i.e. it would be my way to go if I would start the project on CL right after reading the paper).\n\nThe strongest part of this paper is the scores on the leaderboard, but I **subjectively** believe that just the good leaderboard scores shouldn't be a reason for acceptance for a continual learning paper, because the modern CL benchmarks are speculative and too far from the real world anyway, and the improved performance on them does not translate into a clear practical benefit of some real-world system (in contrast to, e.g., modern object detection or segmentation). I am ready to discuss this latter statement and change my mind.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_46rh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_46rh"
        ]
    },
    {
        "id": "Rze79c8bUqF",
        "original": null,
        "number": 5,
        "cdate": 1667495029353,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667495029353,
        "tmdate": 1669103269566,
        "tddate": null,
        "forum": "qco4ekz2Epm",
        "replyto": "qco4ekz2Epm",
        "invitation": "ICLR.cc/2023/Conference/Paper4473/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper addresses the continual learning problem in a more realistic situation by considering the fact that the real-world data is online and has no explicit boundaries and its distribution shifts over time. A novel setup for online task boundary-free has been proposed which modeled the arrival time of data by periodic Gaussian distribution. Then two new evaluation metrics have been proposed based on information theory and the concept of mutual information. These metrics do not depend on old and new tasks and satisfy the online condition. To train their model, they suggest a two-term loss consisting of Cross-Entropy loss for current data samples and a Knowledge distillation Loss for past samples which combines the data by a novel method using hypo-exponential distribution called scheduled data prior (SDP) which is a weighted summation of two exponential moving average functions. The method is claimed to work on both online and task-specific setups and improve the metrics by a large margin.",
            "strength_and_weaknesses": "Advantages:\n\n\n\nThis paper has a very strong mathematical background.\n\nNovel Setup, metrics and losses have been proposed for online boundary-free continual learning problem.\n\nThe method has been compared to state-of-the-art papers and achieved better results.\n\n\nDisadvantages:\n\n\n\nIt is preferable if a more detailed explanation is provided about the knowledge distillation term of loss function formula 9 on the page and its direct relation with formula 7 on page 5.\n\nH(Y GT) on page 4 has not been defined and it is only mentioned it is [the amount of information in GT.\n\nA_AUC and A_last in table 1 on page 6 are defined afterward on page 7",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty of this paper is ok\n\nEnough details for reproducibikity",
            "summary_of_the_review": "The paper is well written and also have a good novelty ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_VkR2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4473/Reviewer_VkR2"
        ]
    }
]