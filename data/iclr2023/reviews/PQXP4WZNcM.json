[
    {
        "id": "by3Zuz5F6_O",
        "original": null,
        "number": 1,
        "cdate": 1666562941844,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562941844,
        "tmdate": 1669470116120,
        "tddate": null,
        "forum": "PQXP4WZNcM",
        "replyto": "PQXP4WZNcM",
        "invitation": "ICLR.cc/2023/Conference/Paper1822/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a scheme to improve self-supervised learning for videos. This is done by randomly generating synthetic \u201csaccades\u201d which are expressed as binary masks applied to the input images. This masking and a modified loss allows to better capture semantic changes. Furthermore, a loss for semantic consistency and a prototypical clustering method is proposed to further improve the method. The authors show consistent performance improvements for linear and fine-tuning evaluations of retrieval and action recognition, on the UCF101 and HMDB51 datasets.",
            "strength_and_weaknesses": "The proposed modules are relatively intuitive and as can be seen from the ablation studies (Tab. 3 and Tab. 4), the individual contributions seem to consistently improve performance as measured via top-1 retrieval acc. on UCF101.\n\nOnce it is understood, the idea of using \u201csaccades\u201d via masked inputs sounds reasonably sensible. However, the details of how it is done is not immediately apparent and the mentions of actual human saccades mis-leads the reader (as well as Fig. 1b). Further clarity in writing would be beneficial. No study of the no. of synthetic fixations is done - despite this procedure being introduced for the first time in this paper. The authors do not discuss whether real eye-tracking data could be used here, or whether pre-trained saliency models could be applied to the training process.\n\nWhile the prototypical clustering method is reasonably well motivated, and Fig. 4 tells a meaningful story, one wonders why prototypical clustering was not built in as a more key component. That is, prototypes could have been updated every epoch, as is commonly done in methods such as DeepCluster and others.",
            "clarity,_quality,_novelty_and_reproducibility": "While the paper is reasonably easy to read, the detail regarding the simulation of saccades is not explained well despite it being a key part of the proposed idea.",
            "summary_of_the_review": "The paper proposes contributions that can be understood fairly well, and backs up these proposals with strong experimental results. While the individual contributions may have been well-inspired, the written description on \u201csaccades\u201d and \u201cprototypical contrastive learning\u201d could be improved somewhat.\n\nEdit post rebuttal: I appreciate the authors' efforts to respond to all concerns raised by the reviewers. My questions are partly addressed, and the paper's consistent performance improvements warrant a recommendation for acceptance. However, after carefully reviewing the other review texts and the authors' responses, I will not change my rating from 6. This is because the following changes would be better incorporated by a thorough re-write of the submission: (a) factors such as no. of fixations, spatial size of the fixation mask were analyzed only during the rebuttal phase, resulting in a different set of optimal parameters to the ones used in the paper, (b) the UniSAL approach show improvements over the arbitrarily designed \"synthetic saccades\" and probably should have been used as the main method of guiding positive/negative generation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_zkjU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_zkjU"
        ]
    },
    {
        "id": "XrK-8HppSZ",
        "original": null,
        "number": 2,
        "cdate": 1666604117384,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604117384,
        "tmdate": 1669015644470,
        "tddate": null,
        "forum": "PQXP4WZNcM",
        "replyto": "PQXP4WZNcM",
        "invitation": "ICLR.cc/2023/Conference/Paper1822/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Inspired by the human visual perception that saccades usually indicate semantic changes in the visual receptive field, this paper proposes a self-supervised learning method by artificially generating masks that represent saccades, and learning through Semantic-change-aware contrastive learning, semantic consistency, and representation reorganization. The proposed self-supervised learning method shows\ngood performance on both video retrieval and action recognition tasks.",
            "strength_and_weaknesses": "The strengths of this work are as follows:\n1. The bio-inspired self-supervised learning scheme is interesting and reasonable. Constructing artificial saccades rather than collecting data by eye-trackers is a clever and effective approach. This scheme is also proved by the experimental results.\n\n2. The three parts of the proposed method are designed with reasonable motivation. There are also corresponding experiments in the next section to show the effect of each part.\n\n3. The experiments are well-designed and enough to show the effectiveness of the proposed method.\n\nI list several weaknesses of this paper, if revised, could make this work better:\n1. Conducting experiments on larger-scale datasets can strengthen this work.\n\n2. There is no experiment nor explanation of the spatial size and temporal length of the fixation mask. This size may have a great impact on the quality of self-supervised learning.\n\n3. It is also good to discuss the use of pre-trained saliency/gaze prediction models in this self-supervised learning scheme, rather than the artificially generated saccades. Based on my knowledge, [A] is a related work that provides a gaze prediction model on videos consisting of the modeling of attention transition, which can be used as a simulation saccades.\n\n[A] Huang et al, \"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\", ECCV 2018.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is understandable and of good quality technically. \n\nThere is also enough novelty in this work. \n\nI believe the paper does not contain enough details for reproduction. Especially, the generation of fixation maps and the simulation of saccades are not clear.",
            "summary_of_the_review": "I think this paper proposes a novel and effective self-supervised learning scheme for videos. The method is reasonable and experiments are well conducted. I don't see major weaknesses in this paper.\n\nAfter the revision, I believe this work becomes clear and the experiments become more solid. Thus I am raising my recommendation to accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_aMU3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_aMU3"
        ]
    },
    {
        "id": "m1cAAfReFJ",
        "original": null,
        "number": 3,
        "cdate": 1666673555885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673555885,
        "tmdate": 1666673909794,
        "tddate": null,
        "forum": "PQXP4WZNcM",
        "replyto": "PQXP4WZNcM",
        "invitation": "ICLR.cc/2023/Conference/Paper1822/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a new self-supervised learning model for video representation by introducing the idea of saccades/fixations. More specifically, a semantic change aware contrastive learning is proposed such that a positive pair is from the same fixation region of the same video, followed by reorganization of prototypical contrastive learning. Further more,  semantic consistency learning module is also included to encourage the consistency between the states of two time points within the same fixation, by minimizing the prediction error of using earlier state to predict later state.\n\nExperiments are conducted for both video retrieval and video action recognition, on UCF101 and HMDB51 data sets. ",
            "strength_and_weaknesses": "Strengths:\n\n--The idea of in-cooperating saccades/fixation into SSL video representation learning is very interesting. \n\n--And the proposed model contain some novelty, e.g, contrastive learning with fixations.\n\n--There are not only experiments for classification, but also retrieval, showing the advantages of the learned representations. And the experiments are conducted on two data sets, with comparison to multiple existing video SSL methods (including contrastive ones and non-contrastive ones), making it quite convincing.\n\n\nWeakness\n\n--Some technical part is not clear. For example, how are the 5 fixations created ? The authors only mention \"simulate the pupil function of an ideal system\" without any explanation in details. \n\n--Further more, for two different frames in the same video, how do we judge whether two fixations are the same, e.g., when two fixation masks are at the same location (top right corner), or two fixation masks contain the same object, or some other way?",
            "clarity,_quality,_novelty_and_reproducibility": "The idea is quite interesting and the proposed model has some novel ideas. However, the technical part is not very clearly presented.",
            "summary_of_the_review": "Overall, the proposed idea is interesting and novel to some extent. The experiment results are also encouraging. However, some key technical aspect is unclear, making it unconvincing, so I can not give high rating for now. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_ucm9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_ucm9"
        ]
    },
    {
        "id": "9Fa4nQCe1J",
        "original": null,
        "number": 4,
        "cdate": 1666693715075,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693715075,
        "tmdate": 1666693715075,
        "tddate": null,
        "forum": "PQXP4WZNcM",
        "replyto": "PQXP4WZNcM",
        "invitation": "ICLR.cc/2023/Conference/Paper1822/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed a self-supervised video representation learning that would take advantage of artificial cascades and fixation points mimicking human eye behavior.  Using the generated fixation and saccades, they could generate  positive and negative samples for each video frame that is used later in a contrastive learning approach to bring similar examples closer and negative ones further away. \n\n",
            "strength_and_weaknesses": "The idea of using gaze data to improve the SSL is interesting and previously also has been shown promising results. The paper covered related work in depth and gave good explanation upon each work. \n\nHowever I have a hard time reading and following the paper, I find that the paper has some vague sentences or references to some papers with not clear justifications. Fro example on page 4 \"To\nthis end, we treat such representations as negative pairs and otherwise positive pairs and optimize\nthe latent feature space by minimizing the contrastive loss.\" I really have a hard time understanding such vague sentences.. \n\nI am not sure why presence of saccade should indicates a semantic change in the video, in real human gaze data we performs saccades to cover different parts of stimuli and it does not necessarily means a semantic change in the stimuli or the scene, as simply human eye fovea can not cover the whole scene in details as once.  Hence comparing the work to a biological inspired approach is over reaching as it has not been tested using real gaze data. \n\nI could not find the details how the fixation locations was generated, why 5 fixations were selected or what is the size of the mask, are these locations generated randomly? or a saliency based approach is used to generate fixations data? \n\nHow is the v_ik ' generated? What does it mean it is an augmented version of vik? \n\nOverall, I was not able to understand the paper fully as it was not written clearly and I could not really make sense of the results. \nIt is also not clear if the overall performance is due to the using more informative labels to generate positive and negative pairs? \n",
            "clarity,_quality,_novelty_and_reproducibility": "I find the paper not clear and not easy to read and follow, given lots of vague sentences and definitions, I find it hard to reproduce. \nAs I understand the main novelty of paper is to use artificial fixation and saccades to generate negative and positive samples, which I find then the novelty being very marginal. \n\n\n\n\n\n",
            "summary_of_the_review": "I think using human gaze data could be a potential use case in SSL approaches, and the idea of the paper is interesting and promising for future research. However, this paper is not written clearly, and I personally find it very hard to read and follow. \n\n\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_MEj8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1822/Reviewer_MEj8"
        ]
    }
]