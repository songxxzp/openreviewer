[
    {
        "id": "M3-s1pUxUNZ",
        "original": null,
        "number": 1,
        "cdate": 1666175725124,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666175725124,
        "tmdate": 1669202662386,
        "tddate": null,
        "forum": "7d-d0BFz6Hf",
        "replyto": "7d-d0BFz6Hf",
        "invitation": "ICLR.cc/2023/Conference/Paper3609/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an attention-based model called the mesh-independent operator learner (MIOL) to provide proper treatments of input functions and query coordinates for the solution functions by detaching the dependence on input and output meshes. The proposed models pre-trained with benchmark datasets of operator learning are evaluated by downstream tasks to demonstrate the system's generalization abilities to varying discretization formats. The paper shows the advantages of the method with some examples.",
            "strength_and_weaknesses": "Strength\n\nThis paper proposes a method that treats discretized functions as set-valued data without prior data structures and structurally separates dependencies on input and output meshes. \n\nCompared with other representative models, the proposed method is evaluated on the original and extended downstream tasks. And the results show that this model is competitive in original operator learning tasks and robustly applicable in extended studies.\n\nWeaknesses\n\nSince this method does not require mesh, why not test some equation problems on surfaces, such as spheres?\n\nIs it possible to solve 3D problems?\n\nThe error gap in figure 2 is vast, as the comparison methods are too simple. Can you show some more reasonable comparisons? For example, show some similar mesh-free methods.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This method is innovative and reproducible.",
            "summary_of_the_review": "This paper is innovative, but the presentation of results is somewhat naive. The examples shown are relatively simple. The comparison with other methods does not show the superiority of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_p5hq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_p5hq"
        ]
    },
    {
        "id": "4_OLoVKjvHQ",
        "original": null,
        "number": 2,
        "cdate": 1666769476072,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666769476072,
        "tmdate": 1666769476072,
        "tddate": null,
        "forum": "7d-d0BFz6Hf",
        "replyto": "7d-d0BFz6Hf",
        "invitation": "ICLR.cc/2023/Conference/Paper3609/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "A paper on operator learning that does not require a specific mesh structure, but allows for querying points. Presentation a bit on the heavy side and experiments could be more demonstrative.\n",
            "strength_and_weaknesses": "*Strengths*\n\n1. The problem is topical and has received recent attention also beyond purely theoretical work. The topic area itself should be of interest for the audience of the conference.\n\n2. The proposed approach appears sensible and described in good detail.\n\n3. The paper is rather detailed and covers the required technical details even for someone who is familiar with the problem domain but is not an expert in the area.\n\n*Weaknesses*\n\n4. Even if the paper reads rather well (with only minor typos), the presentation is on the heavy side. The first 4.5 pages are describing the problem/background/preliminaries, and the paper actually starts at the bottom of page 5. The problem itself is rather simple, and could be presented in a more lightweight/approachable way, which would probably widen the impact of the work.\n\n5. The experiments focus on rather standard benchmark problems and showing that the proposed method actually solves the problem at hand. This is valuable and provides an 'empirical' sanity check, but as a reader I would have expected this to be a first set of experiments with actual demonstrations and/or real-world problem show case data in the end. ",
            "clarity,_quality,_novelty_and_reproducibility": "The text contains only minor typographical errors (e.g., citation style on first line in Sec. 5.2). The presentation is heavy and could be improved. For example, additional visualisations could have helped demonstrate the points with less need for long descriptions in the text.\n\nThe approach is a combination of standard tools, but to my knowledge the proposed method is new.\n\nThe authors have not shared their code for review and do not mention sharing code. Implementation details are covered in main paper and appendix.",
            "summary_of_the_review": "This is an interesting paper that considers a topical problem. The presentation is on the heavy side and the experiments only concentrate on straightforward benchmark problems.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_YQEY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_YQEY"
        ]
    },
    {
        "id": "c6huZOXJwsr",
        "original": null,
        "number": 3,
        "cdate": 1666909848701,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666909848701,
        "tmdate": 1666909848701,
        "tddate": null,
        "forum": "7d-d0BFz6Hf",
        "replyto": "7d-d0BFz6Hf",
        "invitation": "ICLR.cc/2023/Conference/Paper3609/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Operator learning models for PDEs learn the parameter-to-solution mapping of families of partial differential equations. Since they map functions into functions, their approximation should be independent of the discretization of the respective function spaces. This is not always the case for the operator learning networks proposed until now: in practice they often evaluate the functions on finite discretizations and are not able to evaluate the inputs and outputs on different meshes, or to treat training and testing sets with different discretization meshes. The paper raises these issues and develops MIOL- a mesh-independent attentional-architecture that separates dependencies on input and output meshes. It compares its performance with the existing models on several tasks.",
            "strength_and_weaknesses": "I think the paper has his strength in raising an important question regarding discretization-flexibility w.r.t input/output functions  for operator learning models. The paper proposes an architecture that combines properties of existing operators (such as neural operators and set transformers) to address this issue and shows in experiments its performance. However, I think there are some weaknesses in the presentation of the paper:\n\n\u2013  Some more background on the used architectured would be appreciated\n\n\u2013 The paper lacks a discussion about the error bounds w.r.t the discretization chosen\n\n\u2013 The authors should go again through the text since it is at times redundant  and imprecise in the linking words and logical phrases\n\n\u2013 In the experiments, the figures need to be polished. In particular Figure 3 (fontsize of colorbar ticks too small, x and y axes missing....)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper discusses an important topic in the context of operator learning models, but I think the paper lacks in the quality of the exposition. There are wrong linking words and logical phrases in the text (check again the grammar!) and redundancies in the sentences. Some statements are vague (see below). Since the proposed model is inspired by several existing architectures, some more background information would be useful for clarity. Figure 3 seems rushed to finish.\nIn the experiments, Task 4 is claimed to be  a novelty compared to existing models, so it would be interesting to go more in depth with it (not only in the appendix).\n\nSome more detailed comments/questions:\n\n  \u2013 Some function spaces (\\mathcal{A}, \\mathcal{F}) are not specified\n\n\u2013 phrases like \u201c to capture the interactions between the elements\u201d are vague\n\n\u2013 how is (2) evaluated?  \n\n\u2013 In (5), the approximation with the integral is not clear to me. Could you please add details?\n\n\u2013 related to Task 4: with MIOL, can I then use any discretization I want in the input space, and get my approx. solution be evaluated on any discretization in the output function, independently of the discretization chosen in the input space? And if yes, what is the error I will encounter? These are I think the main questions that should be addressed.\n\n",
            "summary_of_the_review": "I think the paper raises an important issue in the context of operator learning models. However, the paper needs some polishing of the form of the exposition, a more in depth discussion regarding discretization and error bounds, and some Figure polishing.  \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_kSWf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3609/Reviewer_kSWf"
        ]
    }
]