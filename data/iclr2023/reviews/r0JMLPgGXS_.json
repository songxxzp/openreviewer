[
    {
        "id": "CyE7q8Zu-T",
        "original": null,
        "number": 1,
        "cdate": 1666507519212,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666507519212,
        "tmdate": 1671019366533,
        "tddate": null,
        "forum": "r0JMLPgGXS_",
        "replyto": "r0JMLPgGXS_",
        "invitation": "ICLR.cc/2023/Conference/Paper4421/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a novel way to train autoregressive models and to sample from them.\nThe authors argue that the standard maximum likelihood approach is overly sensitive to tiny perturbations, assigning low likelihoods to images that have been modified in a way that is Imperceivable to humans.\nAdditionally, they argue sampling results from autoregressive models are inferior due to these sensitivities.\n\nThe proposed method works by training a model to not only the distribution of the training data, but also of noisy versions of the data.\nThe model is conditioned on the noise level.\nThe authors find that their model increases sample quality and is more rout to small perturbations.\n",
            "strength_and_weaknesses": "Strengths:\n\n* The paper is well written. The problem is excellently introduced and motivated.\n* The idea is interesting and original as far as I know.\n\nWeaknesses:\n\n* As far as I understand, the argument about autoregressive models being overly sensitive to small changes is based on the assumption, that they use discrete distributions (e.g. for 8bit images) over pixel values, right? I wonder if this would hold for models that use parametric continuous distributions for each pixel.\n* I am missing some details in the paper on how exactly the PixelCNN++ architecture was modified.\n* How exactly is the model conditioned on the noise level? I think this could make quite a difference in how much more robust the model will become by forcing it to also describe the noisy data.\n\n\nMinor points:\n\n* The authors write: \"p_\u03c0 describes the distribution of points in pdata that have had their least\nsignificant bit incremented or decremented with probability \u03c0\"\nThis formulation could be more clear. What happens when a 0 valued bit is decremented?\nIs this simply about adding or subtracting one form the pixel value?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly structured and written.\nI believe the idea is completely original, deep and interesting.\nUnfortunately, I find that crucial details about the network architecture and training are missing.\n",
            "summary_of_the_review": "All-in-all, this is an interesting paper with some smaller flaws, that could be fixed in the final version.\nMost importantly, the details on training and architecture have to be provided.\nFinally, I have to admit that I am not an expert on score matching and that somebody with more knowledge of the topic might have a more informed opinion.\n\nI changed my rating regarding the novelty in light of the discussion with other reviewers and the AC.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_YYAi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_YYAi"
        ]
    },
    {
        "id": "S58Ul1CbvS5",
        "original": null,
        "number": 2,
        "cdate": 1666567210894,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666567210894,
        "tmdate": 1666567210894,
        "tddate": null,
        "forum": "r0JMLPgGXS_",
        "replyto": "r0JMLPgGXS_",
        "invitation": "ICLR.cc/2023/Conference/Paper4421/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper investigates a likelihood model for a family of increasingly noisy distributions, with the true data distribution at one end, and noise at the other. This construction is conceptually similar to the popular class of diffusion models, except the authors decided to learn a log density model of the data (and its noisy versions), instead of just learning its derivative (cf. the score-based interpretation of diffusion models). The authors motivate learning density for the whole family of noisy distributions\u2014instead of just for the data\u2014by showing that modern pixel space autoregressive image models are rather brittle to bit flip perturbations that are barely perceptible by human eye. Due to equivalence to diffusion processes, the authors propose a sampling process based on integrating the SDE in reverse as known from the diffusion literature. Their empirical results of their models improve on other explicit log likelihood models in terms test log likelihood, albeit still lack significantly behind the FID scores of SOTA diffusion models.",
            "strength_and_weaknesses": "### strengths\n* interesting observations regarding brittleness of modern pixel-space autoregressive image models\n* proposed model does seem to provide improvements over other models in the same class\n\n### weaknesses \n* the proposed model still lacks significantly behind SOTA diffusion models\n* somewhat weak motivation for why we would want to have an explicit likelihood model",
            "clarity,_quality,_novelty_and_reproducibility": "I am only familiar with the major works in the diffusion and autoregressive image modelling literature. I am thus unable to confidently evaluate most of these criteria, except for saying that the writing seems clear. With this pinch of salt, my questions and comments are below:\n\n* Given how brittle you find the current image likelihood image models to be, I find the motivation for seeking a better class of likelihood models towards the bottom of page 3\u2014OOD and adversarial defence\u2014somewhat unconvincing. (Especially given that the cited papers were presumably using models that presumably suffer from the brittleness you identify.) Given the remaining gap to score-based models (& their ability to evaluate likelihood), can you provide an alternative motivation (or refute the above) please? Do you expect it to be harder to learn the log density itself, or its gradient (as in score-based models)?\n\n* Relatedly, arguments such as https://arxiv.org/abs/2012.03808 showing that density modelling is not sufficient for tasks like OOD. A way to address this is to be more careful about choice of the space in which likelihood modelling is done. Could the brittleness you identified be addressed by modelling likelihood in some continuous or discrete (VQ) latent space, rather than the pixel-space?\n\n* Do you think similar brittleness issues exist for autoregressive **text** models?\n\n* In the second difference from diffusion models you describe on p. 6, you say that your model does not have to ensure that $p_T$ is an appropriate stationary distribution (as is the case for diffusion models). Can you please explain whether your sampling scheme based on solving a reverse SDE would still be valid if you chose a different $p_T$ for your model?\n\nNIT: In equation (2) and elsewhere, shouldn't it be gradients of the **log** density (see, e.g., the cited paper by hyvarinen)?\n",
            "summary_of_the_review": "While the empirical results are somewhat lacking behind score-based models, they, I found the paper an insightful (especially the part on brittleness of modern autoregressive likelihood models) and enjoyable read. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_4nNY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_4nNY"
        ]
    },
    {
        "id": "izedl1q1S8p",
        "original": null,
        "number": 3,
        "cdate": 1666632789893,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632789893,
        "tmdate": 1666632789893,
        "tddate": null,
        "forum": "r0JMLPgGXS_",
        "replyto": "r0JMLPgGXS_",
        "invitation": "ICLR.cc/2023/Conference/Paper4421/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes to train noise-conditional autoregressive models across a continuum of noise levels, analogously to diffusion models. The authors argue that such models improve density estimation performance under a least-significant-bit perturbation scheme, and also improve sample generation. ",
            "strength_and_weaknesses": "# Strengths\nThe paper demonstrates that training an autoregressive model as the marginal t = 0 of a noise process improves sample generation at no extra cost. \n\n# Weaknesses\n\n**Is likelihood really important?**\nIt is arguable the degree to which we should care about the likelihood (and ability to evaluate the likelihood) in and of itself, despite the paper's arguments. For example:\n- 2.1: 'therefore do not have the same asymptotic guarantees as MLE (e.g., efficiency, functional equivariance, sufficiency).' Score-matching also has asymptotic guarantees. Moreover, how much do we really believe in the guarantees of MLE in practice? For example, the parameters of any neural-network-based model will not be identifiable, meaning most of the guarantees of MLE don't apply.   \n- 2.1: 'Moreover, likelihoods have no closed-form expression, thus requiring approximate ODE/SDE solvers and hundreds to thousands of function evaluations to evaluate.' \nIf we don't need likelihoods to train, why does it matter that they're expensive to evaluate? There is no key functionality presented in the paper that relies on efficient likelihood estimation. \n\nUsually likelihood evaluation, be it exact, approximate, or through a bound, is used as a training objective for generative models. If we don't need it to train, why do we care about it? I feel this isn't well-motivated.   \n\n**Questionable claims about generative models**\nThe paper states more than once that diffusion models cannot be trained by maximum likelihood. \nIntro: 'diffusion models are poor likelihood models, as they cannot be trained via maximum likelihood.'\n2.1: 'However, they cannot be trained by maximum likelihood'\nThis is incorrect. Diffusion models formulated either as latent-variable models or as score-based models can both be fit by maximum likelihood. There is a footnote at the end of page one to say 'at best they can optimize a lower bound of the likelihood', but the main statements claiming (i) diffusion models are poor likelihood models and (ii) diffusion models cannot be trained by maximum likelihood are incorrect. Not only can score-based models be trained by maximum likelihood, but they are also effectively continuous-time normalizing flows, but can be trained more efficiently. \n\n2.1: 'Likelihood models draw samples x \u223c p\u03b8 one of two ways.' \nStating that likelihood-based models draw samples either as discrete-time flows or as AR models is reductive. This fails to include continuous-time flows or latent-variable models, and diffusion models can be formulated as either.  \n\n**Experimental results**\nIt is unclear the degree to which the model's robustness to the LSB perturbation scheme is practically useful. Moreover, the proposed score-based sampling scheme is strictly more expensive than standard AR sampling, since sampling requires D passes of the model for the initial noise sample, then taking gradients through a single evaluation of the model for each subsequent score evaluation. As mentioned before, I'm not sure of the usefulness of the likelihood measurements under LSB-perturbation for various models in Table 1, and the single FID value reported for CIFAR-10 along with qualitative samples is unconvincing.  \n\n**Nits**\n- Intro: 'AR models boast state-of-the-art performance in many domains, including images... and audio'. This is certainly not true for images anymore, and is it true for audio? \n\n- The paper repeatedly states the likelihood is a function of the data when it is a function of the parameters of the model. \nAbstract: 'Likelihood of the data under the model'\n2.1: 'the likelihood of each sample'\n3.2: 'the model\u2019s predicted likelihood of downstream tokens'\n\n- 'The goal of likelihood-based generative modeling is to approximate pdata via a parametric model p\u03b8, where samples x \u223c p\u03b8 can be easily obtained.' This is the goal of generative modeling, not likelihood-based generative modeling. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nI may be misunderstanding Section 3, but isn't corrupting the least significant bit of a pixel value just changing the high frequency content in an image? If this is the case, I'm not sure of the relevance of this approach. It is known that most of the information content (i.e. entropy) of an image is contained in the high-frequency detail (e.g. see variational diffusion models and their results which show most of the BPD contribution happens near data). This is potentially a reason why the epsilon-parameterization of diffusion models has become so popular, in that it (exponentially) downweights the loss near data and therefore cares much less about high-frequency detail which is much less relevant for human perception (and perhaps as you show, can confuse models). I feel the motivation of the LSB perturbation scheme, and why it captures some meaningful invariance we should practically care about (as opposed to showcasing a failure mode of likelihood measurement for high-dimensional image data), are both unclear.\n\n**Originality** \nA related result is presented in https://openreview.net/forum?id=rJA5Pz7lHKb, where the authors fit noisy data using an AR model, and then fit clean data conditioned on noisy data. This leads to considerable improvements in sample quality and likelihood evaluation. Though not quite the same as the setup here, I feel this paper deserves a mention, but it is not discussed or cited. ",
            "summary_of_the_review": "I feel the characterization of various generative models is lacking throughout the paper, and the contribution is poorly motivated and limited in experimental evaluation. Overall, I don't think the paper does enough to recommend acceptance. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_Vbpt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_Vbpt"
        ]
    },
    {
        "id": "74VmBJoVeb",
        "original": null,
        "number": 4,
        "cdate": 1667378502016,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667378502016,
        "tmdate": 1667379264087,
        "tddate": null,
        "forum": "r0JMLPgGXS_",
        "replyto": "r0JMLPgGXS_",
        "invitation": "ICLR.cc/2023/Conference/Paper4421/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work proposes a noise conditional likelihood-based method for training autoregressive models. Specifically, instead of directly training the model on clean images, the authors propose to train a sequence of autoregressive models on images perturbed with different noise levels using MLE. The authors show with empirical results that the proposed approach is able to improve the sample quality of autoregressive models while also achieving reasonably good likelihoods (in BPD).",
            "strength_and_weaknesses": "Strength:\n1. The paper considers a very interesting direction for autoregressive models.\n\n2. This work has a decent amount of experiments and the performance of the proposed method is reasonable.\n\nWeaknesses:\n1. Limited novelty: training generative models on images perturbed with multiple noise levels is not a new idea. Similar ideas have been explored for diffusion models [1, 2], normalizing flows [3], and also autoregressive models [4, 5]. Specifically, the main idea is very similar to [4] except that the authors now use autoregressive models to parameterize a normalized density (which can be trained via maximum likelihood estimation), while [4] uses autoregressive models to parameterize \"scores\" and trained the models with score matching on images perturbed with various noise levels. The main idea is also similar to [5] (which is not discussed), except that in [5], only two noise levels are used. The conclusion that training autoregressive models on noisy images improves the sample quality and model robustness was also mentioned in [5]. Given these related works, the novelty of this work is questionable.\n\n2. Some claims are flawed. For instance, in the Introduction, the claim that \"diffusion models are poor likelihood models and cannot be trained via maximum likelihood\" might not be correct. Diffusion models can be understood as hierarchical VAEs and can be trained by optimizing ELBO (which also optimizes likelihoods). Follow-up works [6, 7] also show that diffusion/score-based models can be good likelihood models.\n\n3. Some related works are not discussed or compared. For instance, [5] is a closely related paper and should be discussed and compared. [8, 9] also consider conditioning on different data augmentations which share similarities with the proposed method. It would be good to also compare with these approaches.\n\n4. The equations/notations are not defined properly in section 3.\n\n5. Section 3.2 is not convincing. Only intuitions are provided without rigorous arguments or proof. It is unclear whether the arguments are correct or not.\n\n6. It remains unclear why the noise-robustness experiments (section 4.1) are useful. The proposed sanity test for checking the robustness of likelihood models is not convincing or mathematically-justified It is unclear whether a better score implies better robustness. It would be more convincing to compare on some standard benchmarks for robustness.\n\n7. The empirical performance is not very impressive. For instance,  [6, 7] are able to achieve much better performance.\n\n[1] Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n\n[2] Score-Based Generative Modeling through Stochastic Differential Equations: https://arxiv.org/abs/2011.13456\n\n[3] Denoising Normalizing Flow: https://proceedings.neurips.cc/paper/2021/file/4c07fe24771249c343e70c32289c1192-Paper.pdf\n\n[4] Improved Autoregressive Modeling with Distribution Smoothing: https://arxiv.org/abs/2103.15089\n\n[5] Autoregressive Score Matching: https://arxiv.org/abs/2010.12810\n\n[6] Variational Diffusion Models: https://arxiv.org/abs/2107.00630\n\n[7] Maximum Likelihood Training of Score-Based Diffusion Models: https://arxiv.org/abs/2101.09258\n\n[8] Distribution Augmentation for Generative Modeling: http://proceedings.mlr.press/v119/jun20a/jun20a.pdf\n\n[9] Generating High Fidelity Images with Subscale Pixel Networks and Multidimensional Upscaling: https://arxiv.org/abs/1812.01608",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty is limited: the proposed idea is very similar to [1] except that the model is now a density model instead of an autoregressive score model. It also shares similarities with [2, 3]. The empirical performance is not very impressive compared to state-of-the-art DDPM and score-based models in terms of both likelihood and sample quality. The proposed evaluation metrics is not properly justified. The arguments and claims in section 3 should also be made more rigorous. \n\n[1] Autoregressive Score Matching: https://arxiv.org/abs/2010.12810\n\n[2] Improved Autoregressive Modeling with Distribution Smoothing: https://arxiv.org/abs/2103.15089\n\n[3] Distribution Augmentation for Generative Modeling: http://proceedings.mlr.press/v119/jun20a/jun20a.pdf\n",
            "summary_of_the_review": "Although this work considers a very interesting application of autoregressive models by incorporating noise-conditioning schemes from diffusion/score-based models, the technical novelty is limited and the paper presentation will also need to be improved.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_4m9N"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4421/Reviewer_4m9N"
        ]
    }
]