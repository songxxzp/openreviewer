[
    {
        "id": "_C7xmA-KVC",
        "original": null,
        "number": 1,
        "cdate": 1665878858022,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665878858022,
        "tmdate": 1665878858022,
        "tddate": null,
        "forum": "s7oOe6cNRT8",
        "replyto": "s7oOe6cNRT8",
        "invitation": "ICLR.cc/2023/Conference/Paper3613/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to add meta-adaptation into the learn-to-optimize pipeline. The authors present an algorithm for adapting L2O inspired by MAML in algorithm 1. Under standard assumptions in convex optimization (strong convexity and Lipschitz continuity) the authors then derive generalization bounds of the proposed method. The authors verify the efficacy of the proposed method on LASSO and quadratic objectives functions with small synthetic datasets.  \n",
            "strength_and_weaknesses": "Strengths:\n\n* The paper is relatively well written\n\nWeaknesses:\n\n* The novelty is limited.\n* The experiments are very limited, using toy problems and small synthetic datasets.\n* The assumptions of convexity might not hold in practice. \n* The utility or broader interest of the method is unclear.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "While the paper is mathematically intensive, the assumptions and results are stated clearly. I would encourage the authors to comment on when the assumptions in the theoretical results can be assumed to hold. \n\nWhile the paper is well written, I think the motivation could be improved. Where would the proposed method be the most useful? Currently, the experiments are small toy examples that do not demonstrate any practical utility of the method. Could more experiments with neural networks be added? If not, maybe more examples where current methods fail could be added.\n\nThe novelty of the paper is about average, I don\u2019t know of any previous papers which combine meta-learning and learning to optimize, but combining these two well-known fields is not very novel.\n\nFrom a reproducibility perspective, adding error bars to the experiment would be helpful.\n\n",
            "summary_of_the_review": "The paper combines meta-learning and learning to optimize, proposing a natural algorithm and deriving some generalization bounds for it. Experimentally, the authors show some benefits on small synthetic tasks with the lasso or quadratic objective. While the paper is technically sound, the paper does little to demonstrate any practical utility or new theoretical insight. Thus, I recommend rejection.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_2sEx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_2sEx"
        ]
    },
    {
        "id": "SuV1VVlmo7_",
        "original": null,
        "number": 2,
        "cdate": 1666496733818,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666496733818,
        "tmdate": 1668813349079,
        "tddate": null,
        "forum": "s7oOe6cNRT8",
        "replyto": "s7oOe6cNRT8",
        "invitation": "ICLR.cc/2023/Conference/Paper3613/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the problem of OOD generalization in L2O, i.e. meta-learning an optimizer that is effective on objectives not seen during training. It proposes an algorithm based on MAML (Finn et al. 2017) and analyzes its generalization ability, measured by the loss at testing time. Unsurprisingly, generalization depends on the difference between the training and testing optimizees, data size, and training length. The authors show that their algorithm M-L2O generalizes better than no meta-learning at all. Experiments are done on quadratic and LASSO benchmarks and confirm the theoretical results. M-L2O also improves on directly applying MAML to L2O.",
            "strength_and_weaknesses": "# Strengths\n- The presentation of the mathematical results is generally pretty good. The authors clearly state the assumptions and explain the results intuitively.\n- This paper makes distinctions between the optimizees used for adaptation and testing, which is unusual in the literature as far as I know. However, I think this is a better approximation of practical situations, where during testing we may have access to small amounts of data that may or may not be drawn from the current distribution of interest.\n- The proposed algorithm is a straightforward simple modification of directly applying MAML to L2O, basically adding a gradient step to the objective. The authors provide both theoretical and empirical analysis, and it seems M-L2O empirically outperforms the baselines.\n\n# Weaknesses\n- The notation is messy. In section 3.1, it is not clear where the different tasks (line 3 of Alg. 1, $g^1, g^2, g^3$) come in. I think it would be more helpful to explain the general structure of L2O algorithms first. $Q^i$ is not defined in Proposition 1.\n- Assumption 2 seems fairly strong. Intuitively it makes sense but I think it would be good to have some evidence, theoretical or empirical.\n- As far as I understand it, vanilla L2O does not contain any meta-learning, the optimizer is random. In this case, vanilla L2O would be a misnomer, and the main baselines of interest would be Transfer Learning and Direct Transfer. The figures do suggest that M-L2O may be able to improve over those two algorithms. Therefore, should Remark 2 compare between M-L2O and Transfer Learning?\n- Standard errors are not provided in the figures or tables. To judge which algorithm is statistically significantly better, uncertainty estimates would be helpful.\n\n## Minor\n- In Theorem 1 and Remark 2, are norm symbols missing from the left hand side of the inequality?\n- What form does the optimizer $m$ take in the experiments?\n",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity \nOverall, the paper is clear to understand. However, in section 3 the notation is sometimes unclear.\n\n# Quality\nThe authors provide both theoretical and empirical analysis of their algorithm, which is good. The theory appears to be sound (I only skimmed it), although assumption 2 seems a bit strong. The algorithm outperforms several baselines from previous work, although standard errors were not provided and so statistical significance cannot be confirmed.\n\n# Novelty\nThe authors differentiate between the adaptation and testing optimizees, which I think is an important novel contribution. The algorithm itself is built on MAML, with an additional single gradient step in the objective.\n\n# Reproducibility\nCode is not provided. However, the algorithm and benchmarks would be fairly simple to implement, and most of the hyperparameters are provided. Therefore, I don't think reproducibility is an issue.\n",
            "summary_of_the_review": "I think that the proposed algorithm is an interesting approach to tackle OOD generalization for L2O; it is clearly presented and the authors provide both theoretical and empirical analysis. However, there are some points described above (strength of assumption 2, remark 2, standard errors) that raise some questions about the claims made in this paper. \n\n# Update\n\nThe majority of the weaknesses I raised were adequately addressed by the authors, so I raised my score from 3 to 5.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_Sfir"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_Sfir"
        ]
    },
    {
        "id": "inZ-UWNBhr",
        "original": null,
        "number": 3,
        "cdate": 1666560570617,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666560570617,
        "tmdate": 1668844629794,
        "tddate": null,
        "forum": "s7oOe6cNRT8",
        "replyto": "s7oOe6cNRT8",
        "invitation": "ICLR.cc/2023/Conference/Paper3613/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes the M-L2O algorithm, as a substitute for the L2O algorithm, and then provides theoretical analysis and numerical experiments of the M-L2O algorithm.",
            "strength_and_weaknesses": "Strength:\n1. The theoretical analysis looks solid\n2. The numerical experiments corroborate the theoretical results.\n\nWeakness:\n1. The L2O part problem definition needs more descriptions \u2013 in section 3.1, it would be much better to introduce the different notations with better characterizations:  (a) It would be better to provide more description on the relationship between $\\phi$ and $\\theta_t$. \n(b) Is $\\xi_j$ a vector data sample or it is a parameter that indexed the task number? \n(c) What is $z_t$? \n(d) In the sentence above equation, $\\zeta_t$ is referred to as a data sample, while in the first sentence of section 3.1, $\\xi_t$ is referred to as a data sample, what is the relationship between $\\zeta_t$ and $\\xi_t$? \n(e) Where does equation 2 come from? Perhaps the author can provide more introduction/motivation on why $\\nabla_\\phi \\theta_T(\\phi)$ has the form in equation (2)?\n2. The intuition of M-L2O is not clearly stated \u2013 why is the empirical risk (equation 5) related to MAML?\n3. The notations in section 3.2 are confusing \u2013 where do $g_T^1,g_T^2,g_T^3$ appear in Algorithm 1?\n4. The assumptions need clarifications:\n(a) (Minor) Assumptions 1, 3, and 4 seem to be standard, but it would be better to address their appearance in some prior papers.\n(b) (Major) Why can we directly assume $\\widetilde{\\phi}^1_*$ and $\\widetilde{\\phi}^1_{M*}$ satisfy the conditions in assumption 2?\n5. The main result (theorem 1) is a bit confusing \u2013 the last error term in Theorem 1 has an exponential dependency on $Q$, and the author proposes to set $\\alpha\\leq \\mathcal{O}(1/TQ^{3T-4}+Q^{4T-4})$ to avoid such exponential dependency, which implies that $\\alpha$ should be exponentially small. And if the reviewer understands correctly, the new $\\alpha$ term seems to be the major novelty of this paper (as suggested in equation 5), so does this mean that the proposed M-L2O actually does not differ too much from the original L2O since we will be setting $\\alpha\\to0$ anyway?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of this work needs large improvement, as the reviewer finds the major contributions and introduction of L2O really hard to follow. Because of the lack of clarity, the reviewer cannot determine the novelty of this work. The proof seems to be reasonable (although the reviewer cannot follow the proof exactly due to the clarity issue), but it seems to be a standard convergence analysis of convex optimizations with different assumptions (Lipschitz continuity, strongly convexity, and some stochasticity). The numerical experiments seem to be reproducible.",
            "summary_of_the_review": "In summary, the reviewer cannot provide a clear evaluation of the quality of this paper due to the lack of introduction on the problem formulation, assumptions,  and clarity on the notations. The reviewer encourages the authors to largely rewrite the paper to improve the clarity on the aforementioned issue in the rebuttal.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_5uH7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_5uH7"
        ]
    },
    {
        "id": "fOaM5Z9vTb",
        "original": null,
        "number": 4,
        "cdate": 1666586953049,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666586953049,
        "tmdate": 1668629219240,
        "tddate": null,
        "forum": "s7oOe6cNRT8",
        "replyto": "s7oOe6cNRT8",
        "invitation": "ICLR.cc/2023/Conference/Paper3613/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Learning to Optimize (L2O) has emerged as a data-driven way to derive \u201clearned optimizers\u201d for specific problem classes. However, for very different unseen problems those learned optimizers can fail badly. This paper is the first to discuss L2O\u2019s test-time self-adaptation to out-of-distribution tasks, providing both theoretical and empirical results.",
            "strength_and_weaknesses": "Strength:\n-\tThis paper tackles a very important problem and inherent limitation of L2O: its performance is not ensured on tasks different from those seen in training. If resolved, that can remove a notable hurdle for L2O in practice. \n-\tThe authors formulated an MAML-like nested optimization, to locate in well-adapted region where a few adaption steps enable optimizer to generalize well on unseen tasks. The formulation is solved by meta-training with theory backups.\n-\tTheoretical analysis reveals that training-like adaptation can mean better generalization, which experiment results support. This is a meaningful new insight. \n\nWeakness:\n-\tIt is hard for me to catch whether/what the main innovations are for the theory part. The idea seems to be a direct combination of MAML and L2O, both belonging to the meta learning family. \nThe authors are invited to elaborate more on: is their theoretical result reused/re-instantiated from some known meta-learning result? Or by some direct combination of MAML result and L2O result each? Or they have actually made noteworthy theory contributions? \nI believe the clarity of Section4 will benefit a lot by adding such discussions. Currently, I find it very difficult to assess the authors\u2019 theoretical contributions as those are poorly contextualized. The whole Section 4 surprisingly has not cited or discussed a single theory paper!\n\n-\tThere are existing L2O works studying generalization by theory, such as (Chen 2020d). However, the authors fail to concretely discuss how their generalization results differ from/compare with Chen et. al.\nAnother relevant paper the authors fail to cite and discuss is: \u201csafeguarded learned convex optimization\u201d, Heaton et. al.\n\n-\tThe experiments are in general consistent and informative, but unfortunately on very simple test problems only. I would expect at least some constrained optimization, nonconvex optimization or NNs. The authors are encouraged to add some such result. This could be considered as a minor point, IF the authors are able to clarify their theoretical contribution to be major (rather than combining existing off-the-shelf ingredients).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Writing quality is mediocre, with a number of obvious typos such as \u201ca out-of-distibution\u201d, etc.\n\nNovelty is solid but also limited in some way, since the idea appears to combine two existing ideas: L2O and MAML. \n\nNo code was attached. But experiments seem straightforward and should be reproducible.\n",
            "summary_of_the_review": "In summary, I think this paper targets a very important problem and critical limitation of L2O, that will improve the applicability of L2O. The proposed solution seems reasonable with a well defined nested optimization problem, and the associated theoretical analysis well justify the motivation of the proposed solution.\n\nThere are some minor concerns in the \"Weakness\" part, if the authors can well address my concerns I would be able to change my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_GEXL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_GEXL"
        ]
    },
    {
        "id": "25cmhR_QWq",
        "original": null,
        "number": 5,
        "cdate": 1666669526090,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669526090,
        "tmdate": 1668631107542,
        "tddate": null,
        "forum": "s7oOe6cNRT8",
        "replyto": "s7oOe6cNRT8",
        "invitation": "ICLR.cc/2023/Conference/Paper3613/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper investigates the generalization of L2O on unseen test cases that substantially differ from the training distribution. It proposes a self-adapted L2O algorithm (M-L2O) incorporated with meta-adaptation. The generalization advantages of M-L2O over out-of-distribution tasks have been theoretically and empirically validated.",
            "strength_and_weaknesses": "This paper does seem to have merits, but they are largely compromised by the unclarity in the current manuscript. See below:\n\nStrength.\n- The unseen generalization is an open L2O challenge that was unexplored before. The authors demonstrate a novel solution that outperformed na\u00efve baselines, such as direct transfer learning. \n- The authors presented theoretical evidence that their meta-adaption design grants M-L2O optimizer faster adaption ability for out-of-distribution tasks and can have smaller generalization errors, compared to vanilla L2O.\n\nWeakness & Questions.\n- It is unclear to me whether the theoretical assumptions made in Section 4.1 make sense or not for L2O. As far as I know, L2O adopts an LSTM to predict the update. How can an LSTM g function be strongly convex? Also, the Lipschitz condition can easily get trivial under recurrence.\n- Experiments are short of MANY details. For example, nowhere in the main text or supplement, did the authors report what L2O algorithm they actually used for all experiments! That shows the paper was finished in a hectic rush, lacking serious proofreading and also making the comparison fairness questionable. \n- The authors conclude that a training-like optimizer adaptation task outperforms a test-like one. That is non-intuitive, and I\u2019m not fully convinced: what if we smoothly interpolate the parameters from training to testing, in a curriculum-learning way? I also suspect Figure 3 is because training/testing cases are still quite similar. \n- The optimization problems tested are too simple: only Lasso and quadratic.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Low writing clarity (missing lots of details, see above). Reproducibility is also low in the current shape due to the important experimental detail absence. I look forward to the authors\u2019 clarifications. \n\n",
            "summary_of_the_review": "Please refer to the comments on strengths and weaknesses. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_egHk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3613/Reviewer_egHk"
        ]
    }
]