[
    {
        "id": "mKwd8p-FuyE",
        "original": null,
        "number": 1,
        "cdate": 1666581599069,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581599069,
        "tmdate": 1670438044843,
        "tddate": null,
        "forum": "djpsp_fSf2G",
        "replyto": "djpsp_fSf2G",
        "invitation": "ICLR.cc/2023/Conference/Paper1537/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed a method to detect malicious nodes by converting the numerical features to rank features and then apply malicious nodes detection algorithm.",
            "strength_and_weaknesses": "Strength:\n1. The idea of converting numerical features to rank features is inspiring. Will combine them both further improve the detection accuracy?\n\nWeakness:\n1. The claim is too strong. \"To address the above, for the first time, we propose MANDERA which is theoretically guaranteed to efficiently detect all malicious gradients under Byzantine attacks with no prior knowledge or history about the number of attacked nodes.\" I seriously doubt if it is theoretically possible to detect all the malicious nodes.\n2. The main theorems are all asymptotic while in malicious nodes detection we care about non-asymptotic guarantee. \n3. The IID assumption is a too strong for federated learning. It is well-known that data/gradients in federated systems are heterogeneous [1] and can be heavy-tailed with no-bounded second moments [2]. \n\n[1] FEDERATED OPTIMIZATION IN HETEROGENEOUS NETWORKS\n[2] On the Heavy-Tailed Theory of Stochastic Gradient Descent for Deep Neural Networks\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The method is clear.\nQuality: The quality is okay.\nNovelty: The novelty is marginal.\nReproducibility: The authors provide the codebase for reproducing. I do not have the chance to run the provided code.\n\n\n------------------------------------\n\nThanks for the rebuttal. I decide to keep the original score after reading it. ",
            "summary_of_the_review": "The overall quality of the paper is okay but the limitations I mentioned in the weakness section seem to be hard to solve. As a result, I tend to reject. I will re-score if the authors can fix any of the issues.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_L24P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_L24P"
        ]
    },
    {
        "id": "i72PcNBtIfm",
        "original": null,
        "number": 2,
        "cdate": 1666582226954,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582226954,
        "tmdate": 1666582226954,
        "tddate": null,
        "forum": "djpsp_fSf2G",
        "replyto": "djpsp_fSf2G",
        "invitation": "ICLR.cc/2023/Conference/Paper1537/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors propose MANDERA that detects Byzantine gradients in the ranking space. The authors analyze the robustness of proposed MANDERA under some specific Byzantine attacks. Experimental results verify the efficacy of proposed MANDERA.",
            "strength_and_weaknesses": "Strength:\n\n- The discussed topic of Byzantine robustness in federated learning is important.\n- The paper is well-organized and easy to follow.\n\nWeaknesses:\n\n- (FATAL) Collapse under a particular attack. Let $g$ be the benign gradient and e be all one vector. Craft the byzantine gradients to be $g+\\alpha e$, where $\\alpha$ is an arbitrarily large number. Since $g+\\alpha e$ and $g$ are the same in the ranking space, this attack can easily compromise the proposed MANDERA.\n- Limited theoretical analysis. Only show the robustness of proposed MANDERA under some specific Byzantine attacks.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and easy to follow. The proposed defense is not applicable since it collapses under a well-crafted attack. The authors do not provide code for reproducibility.",
            "summary_of_the_review": "Although the idea of detecting Byzantines in the ranking space is interesting, the proposed MANDERA fails under a particular attack. \n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_9NF6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_9NF6"
        ]
    },
    {
        "id": "BFQzrSJgMZ",
        "original": null,
        "number": 3,
        "cdate": 1666649200709,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649200709,
        "tmdate": 1666677821859,
        "tddate": null,
        "forum": "djpsp_fSf2G",
        "replyto": "djpsp_fSf2G",
        "invitation": "ICLR.cc/2023/Conference/Paper1537/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new ranking based method to detect Byzantine agents that participate in federated learning. MANDERA is a novel method that is intuitive and easy to implement, and show good performance in experiments. The authors also provide theoretical analyses to support that MANDERA is guaranteed to detect all Byzantine agents under certain conditions, and analyze 4 specialized attack instances. ",
            "strength_and_weaknesses": "Strength: \n1. The proposed method is very effective in experiments with performance matching or even outperforming some existing methods (Figure 7b). \n2. The analyses of ranking based method is valuable that provide insights on why MANDERA works well in high-dimensional or large datasets regime. \n\nWeakness: \n1. The considered attack is essentially not Byzantine attack as claimed, the distinguishable distribution assumption make the attack model much more restrictive in that there are attacks [1] that have similar distributions with benign nodes but can prevent the optimization process from convergence to optimum. \n2. Another problem is how to measure the amount of distinguishability is not discussed. In what cases the clustering algorithms can detect those malicious node is not discussed. \n3. Per the previous two points, there are gaps towards to the Byzantine robustness guarantees. We know that MANDERA is robust to some restricted class of attacks, but not general Byzantine attack, some attacks that fall into this class are analyzed. We know that asymptotically there will be two clusters, but we don't know in what cases these two clusters will be correctly labelled. In conclusion, there are interesting blocks in the analysis part, but the presented arguments are not enough to obtain any Byzantine robustness guarantees.\n4. In Figure 7b, why there are only two methods compared for GA and MS cases? The proposed method is good, but it seems that it does not outperform Bulyan in all cases.\n\n[1] Baruch, G., Baruch, M., & Goldberg, Y. (2019). A little is enough: Circumventing defenses for distributed learning. Advances in Neural Information Processing Systems, 32. ",
            "clarity,_quality,_novelty_and_reproducibility": "1. The authors may put the illustration of ranking space before using this concept, i.e., Figure 2, before Figure 1.",
            "summary_of_the_review": "This paper propose a novel method with good analysis blocks and effective experiments results, but from my perspective, it lacks in the theoretical arguments to guarantee Byzantine robustness as I detailed in \"weakness\" section. I think this paper can be improved towards a very good paper if more blocks are added, but the current form is limitedly persuasive. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_HdfK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1537/Reviewer_HdfK"
        ]
    }
]