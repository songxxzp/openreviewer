[
    {
        "id": "hfSegNyPvsh",
        "original": null,
        "number": 1,
        "cdate": 1666240441749,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666240441749,
        "tmdate": 1666240441749,
        "tddate": null,
        "forum": "boNyg20-JDm",
        "replyto": "boNyg20-JDm",
        "invitation": "ICLR.cc/2023/Conference/Paper181/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "To address three applications of OOD: OOD detection, Open-set SSL and Open-set DA, this work proposes a novel data augmentation method, named HOOD. They analyze the data generation process from a causal perspective, and uses a variational inference network to disentangle the content and style from the input data. Then, they perform data augmentation on the content and style, respectively, to obtain benign and malign OOD samples. Finally, the authors use these augmented samples to improve the generalization of the model. Extensive experiments on three OOD applications demonstrate the effectiveness of this method.",
            "strength_and_weaknesses": "Strength:\n1. The proposed method can improve performance on all 3 OOD applications.\n2. The causal disentanglement method proposed in this paper can separate content and style, which is novel.\n\nWeakness:\n1. According to Algorithm 1, each iteration needs to pre-train the VAE, which consumes a lot of computational cost and running time cost. The author needs to give the time complexity of running the algorithm, and the running time of the experiment, and compare it with the baseline methods.\n2. The author only carried out three kinds of OOD applications through experiments, but what is the proposed methods in the traditional OOD setting with supervised learning, i.e., the training set and the test set do not belong to the same distribution. And how does this data augmentation method perform compared to other traditional generalization algorithms, such as ERM, DRO [1] or IRM [2].\n3. Why use adversarial data augmentation, the author did not give sufficient reasons and proofs. For example, after we can decouple the content and style, why not use random data augmentation, or other data augmentation methods.\n4. Whether the adversarial data augmentation can hurt the performance. For example, adversarial training will degrade the performance of the model on clean image.\n\n[1] Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization\n\n[2] Invariant Risk Minimization\n",
            "clarity,_quality,_novelty_and_reproducibility": "The idea of causal disentanglement is novel.\nBut authors do not conduct experiment on OOD setting or compare with other generalization algorithms.\n",
            "summary_of_the_review": "Please refer to the \u201cWeakness\u201d.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper181/Reviewer_sqif"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper181/Reviewer_sqif"
        ]
    },
    {
        "id": "A3fgrBG6aF",
        "original": null,
        "number": 2,
        "cdate": 1666501633146,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666501633146,
        "tmdate": 1669072857915,
        "tddate": null,
        "forum": "boNyg20-JDm",
        "replyto": "boNyg20-JDm",
        "invitation": "ICLR.cc/2023/Conference/Paper181/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new framework that identifies and utilizes benign and malign OOD based on the disentanglement of content and style features. The benign OOD data may contain new styles but hold contents, and so they can help improve style-invariant model training. The malign OODs are vice versa and can confuse OOD applications. The proposed method is designed as a variational inference framework based on a structural causal model. Data augmentation based on this decomposition improves performance in three representative OOD applications. ",
            "strength_and_weaknesses": "[+] The idea of defining and discriminating benign and malign OOD data based on the disentanglement of content and style is novel and interesting. \n\n[+] The paper presents a clear explanation of how to harness the ODD data with the proposed framework in several OOD problems. Its effectiveness is validated through various experiments. \n\n[-] The authors need to provide a more specific model architecture for HOOD for reproducibility. \n\n[-] It is not clearly presented how well the proposed method disentangles content and style, although its effectiveness is shown in terms of performance at OOD applications. It will help if the authors can provide at least brief validation results on this. Figure 4 is not very informative and quite hard to recognize. \n\n[-] According to Figure 3, the results seem sensitive to the number of augmented samples (benign OOD data). It is not in line with the assumption that benign OOD data can improve model performance.\n\n[Q1] In Algorithm 1, the usage of unlabeled input data is not well represented. Is it a required input or optional, or depends on the target task? Which part of the pseudo-code does it affect? \n\n[Q2] The authors explain that the pseudo-labels can be utilized in the case of unlabeled data, but I am curious about how sensitive the result is depending on how the pseudo-labels are obtained. \n\n[Q3] It will be helpful if the authors can show examples of benign and malign OOD samples using images. \n\n[Q4] The authors chose to use adversarial data augmentation that adds a learnable perturbation. I wonder if there is any other option for this, and whether it\u2019s optimal. \n\n[Q5] I wonder if there are more recent models for comparison (e.g., ODIN was introduced in 2017, and other methods shown in Table 1 are quite traditional, except OpenGAN) and how this one performs in comparison with those. \n\n[Minor]\n\n- The term ID is used without being introduced. \n- p.2:  by the blue and red lines in Fig. 1 -> by the green line and ... \n- p.9 (right above Figure 4) can effective eliminate \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized overall. However, while it uses a lot of notations (e.g., for parameters, or functions), they are not clearly defined before being used and some details are not provided sufficiently for reproducibility. Algorithm 1 could also be improved by directly referring to each input and output component in the main lines. ",
            "summary_of_the_review": "This paper introduces a novel view and framework for handling OOD instances, which seems interesting and reasonable. However, more comparisons with recent models and a clearer description of the model details would improve the paper further. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper181/Reviewer_Jm4f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper181/Reviewer_Jm4f"
        ]
    },
    {
        "id": "31HCYW1NEW",
        "original": null,
        "number": 3,
        "cdate": 1666616055204,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666616055204,
        "tmdate": 1670657973584,
        "tddate": null,
        "forum": "boNyg20-JDm",
        "replyto": "boNyg20-JDm",
        "invitation": "ICLR.cc/2023/Conference/Paper181/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new approach called HOOD to disentangling the content and style features, and then basing on them, design a data augmentation method to construct benign and malign OOD data. They validate the proposed approach on the tasks of OOD detection, open-set SSL, and open-set DA.",
            "strength_and_weaknesses": "**Strength:**\n\nThe problem studied in this paper is quite important to the community. The motivation is convincing and the logic is easy to follow. The paper is generally well written. \n\n **Weaknesses:**\n\n+ My main concern is about the causal diagrams presented in Fig. 1. \n   - In Fig. 1a, the authors assume that the style $S$ causes the environment/domain $D$. Apparently, it contradicts the common assumption widely used in the literature that the environment $D$ causes the style $S$, *e.g., Magliacane et al., 2018; Suter et al., 2019; Wang and Jordan, 2021; Sun et al., 2021; Lu et al., 2022; Quinzan et al., 2022*. Why do the authors make this assumption? Is there any particular reason for this? How practical is it in comparison with the common assumption?\n   - Also, in Fig. 1a, the authors do not assume any dependence between $S$ and $C$, which is quite limited in real world scenarios. One commonly spurious correlation between $S$ and $C$ is due to the existence of the environment $D$, see *Sun et al., 2021; Liu et al., 2021; von Kugelgen et al., 2021*. In other words, we usually have the spurious path $S \\leftarrow D \\rightarrow C$, which also contradicts the assumed causal diagram in Fig. 1b.\n   -  In fact, the caption of Fig. 1a is incorrect. Note that, a SCM is defined as a set of functional assignments accompanying with its corresponding causal diagram. Hence, Fig. 1a is only a causal diagram, no a SCM. \n   - In Fig. 1c, both causal edges and non-causal edges are mixed up, which could be misleading to readers. \n\n+ Another main concern is about the identifiability. That is, how is it guaranteed, both theoretically and practically, that the content can be distinguished from the style only from the observed data? This is one of the key problems in the thread of work on causal disentanglement, *e.g., Arjovsky et al., 2019; Sun et al., 2021; von Kugelgen et al., 2021*.\n\n+ From the experimental results, it seems that the performance improvement is small, most only having around 1% improvement.\n\n+ notation abusing, e.g., the capitals are used in Fig. 1, whilst the letters are used in the text, etc. \n+ unexplained terms, e.g., \n  - what do you mean by ID data? There exists no explanation before it first appears in the paper. \n  - no explanation on the open-set methods in the introduction.\n+ grammar errors, e.g., \n  - the first sentence in the abstract contains two independent clauses, but without a conjunction, etc.\n  - on line 6 of the abstract, the indefinite article \"a\" is missed before \"HOOD method\".\n  - on line 4, \"deep models meet with domain shift ...\" should be replaced with \"deep models meet domain shift\"?\n\n**References**\n\n- Suter et al., *Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness.* ICML 2019.\n- Wang and Jordan. *Desiderata for representation learning: A causal perspective.* 2021.\n- Quinzan et al., *Learning counterfactually invariant predictors.* 2022.\n- Magliacane et al., *Domain adaptation by using causal inference to predict invariant conditional distributions.* NeurIPS 2018.\n- Lu et al., *Invariant causal representation learning for out-of-distribution generalization.* ICLR 2022.\n- Sun et al., *Recovering Latent Causal Factor for Generalization to Distributional Shifts.* NeurIPS 2021.\n- Liu et al., *Learning causal semantic representation for out-of-distribution prediction.* NeurIPS 2021.\n- Arjovsky et al., *Invariant risk minimization.* 2019.\n- von Kugelgen et al., *Self-supervised learning with data augmentations provably isolates content from style.* NeurIPS 2021. ",
            "clarity,_quality,_novelty_and_reproducibility": "+ The paper is easy to follow\n+ The idea of disentangling the content and the style is not new, and has been widely discussed, see the above references. \n+ Also, using variational inference to estimate them is a common way in the community. \n+ The submission seemingly does not contain enough details to reproduce the results.\n",
            "summary_of_the_review": "My main concerns are on the assumptions over the causal diagrams and on the identifiability, and the experimental results also seems not quite impressive. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper181/Reviewer_MQ8c"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper181/Reviewer_MQ8c"
        ]
    },
    {
        "id": "DqKvXks-Kq5",
        "original": null,
        "number": 4,
        "cdate": 1666671988660,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671988660,
        "tmdate": 1666671988660,
        "tddate": null,
        "forum": "boNyg20-JDm",
        "replyto": "boNyg20-JDm",
        "invitation": "ICLR.cc/2023/Conference/Paper181/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors propose a data augmentation method that separates the content and style of images to solve the OOD (out-of-distribution) problem. To this end, the content and style features of the image are causally separated. By keeping one of the two features similar to the original image and widening the distance of the other features, benign OOD and malign ODD data are generated, respectively. Experimental results show that the proposed algorithm is applicable to various OOD problems.",
            "strength_and_weaknesses": "This paper is well-written and interesting. The formulations used in this paper are novel. Various organized experiments show that the proposed algorithm works practically well in various situations and datasets and, in most cases, shows SOTA performance. It was good to show the effect of using benign and malign samples in an ablation study.\n\nDespite the many advantages of this paper mentioned earlier, I am puzzled by the qualitative results of data augmentation. According to Figure 4, despite the data augmentation, the image content does not seem to change significantly between positive and negative. If more qualitative results were provided, it would be better to understand the operational consequences of data augmentation. Also, I wonder if the augmentation algorithm will work well for higher-resolution images (e.g., ImageNet image examples).\n\nComparing the effects of two data augmentation methods not covered in this paper (maintaining both content and style or moving them away) would also be helpful in an ablation study.\n\nSimple error: In chapter 3.1, on page 3, the operator for a conditional independent is duplicated twice.",
            "clarity,_quality,_novelty_and_reproducibility": "his paper is good enough in all four respects.",
            "summary_of_the_review": "Overall, I read this paper as interesting and positive for acceptance. Adding some qualitative and quantitative experiments may further improve the quality of this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper181/Reviewer_btZ1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper181/Reviewer_btZ1"
        ]
    }
]