[
    {
        "id": "nFwISSBSTF",
        "original": null,
        "number": 1,
        "cdate": 1666351471675,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666351471675,
        "tmdate": 1670384923890,
        "tddate": null,
        "forum": "Gb2Rndy5595",
        "replyto": "Gb2Rndy5595",
        "invitation": "ICLR.cc/2023/Conference/Paper846/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes to decouple the encoder and decoder space of MAE, thus improving the representation quality. Similar to contrastive learning, a Latent contextual regressor is further used to align the predicted masked patch with the encoded masked patch. Experiments on downstream object detection and semantic segmentation show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Strength:  \nGood results on downstream transferring learning, especially for semantic segmentation.  \nClear idea, decoupling the space of encoder and decoder explicitly may benefit the learning of representation.  \n\nWeaknesses:  \n(1) In fact, the \u201cContext\u201d in the Title does not correspond well with the interpretation in the main manuscript. MAE, BEiT and other Masked Image Modeling approaches can also be understood as including context information. I am not sure what specific meaning the context in the paper refers to.  \n(2) Several details and designs are not clear:  \n-- Why is the masking rate set to 50%? (Section 3.2) Why not 75% or other values?  \n-- How to balance the two loss functions? (Eq (1))  \n-- How to choose the number of layers in the Latent Contextual Regressor and Decoder? The number of layers may be related to the performance.    \n\n(3) Questions about the experiments:  \n-- In fact, the finetuning results in Table 1 are only slightly higher than MAE (0.3%).  \n-- How about removing the Decoder? That\u2019s only containing the latent contextual regressor. In addition, in Table 2, why not use the finetuning or linear probe metrics?  \n-- In Table 3, according to the MAE paper, the detection performance of MAE with ViT-B is 50.3%, not 48.4%. In addition, MAE+ViTDet [1] has already achieved higher results (ViT-B: 51.6% and ViT-L: 56.7%).  \n[1] Yanghao Li, et al. Exploring Plain Vision Transformer Backbones for Object Detection. ECCV2022.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the proposed method may be of some inspiration to the community. However, some details and experiments need to be further investigated.  \nLack of limitations (e.g. training costs analysis).  \n",
            "summary_of_the_review": "I am inclined to accept the paper if the author can dispel my concerns well.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper846/Reviewer_cbX1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper846/Reviewer_cbX1"
        ]
    },
    {
        "id": "hTgjKfhn-E",
        "original": null,
        "number": 2,
        "cdate": 1666502014635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666502014635,
        "tmdate": 1666502014635,
        "tddate": null,
        "forum": "Gb2Rndy5595",
        "replyto": "Gb2Rndy5595",
        "invitation": "ICLR.cc/2023/Conference/Paper846/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors proposed a method for self-supervised representation learning based on masked image modeling. Unlike previous approaches, the proposed method decouple representation learning part and pretext task completion part where the learning signal comes from the reconstruction in the encoded representation space rather than in image space. Alignment constraint is introduced encouraging the predicted representations to be lied in the encoded one. The experiments are conducted on three different downstream tasks; semantic segmentation, object detection, and instance segmentation, surpassing the previous approaches.",
            "strength_and_weaknesses": "** Strengths\n- Comparisons to the concurrent methods with analysis and discussion\n- Extensive experimental results achieving state-of-the-art performances on various downstream tasks\n- Clear implementation details\n- Using pretrained tokenizer for masking strategy is interesting\n\n** Weaknesses\n- The idea of reconstructing just the features of the masked patches is also used in iBOT\n- The reliance on a pre-trained tokenizer could be cumbersome. While being with 250M images as extra data, there are not many insights and improvements compared to previous works, e.g. competitive performances compared to iBOT and MAE even they don't require using such pre-trained tokenizers\n- ",
            "clarity,_quality,_novelty_and_reproducibility": "Please see Strength And Weaknesses section above.",
            "summary_of_the_review": "As the weaknesses outweigh the strengths, I lean towards 5: marginally below the acceptance threshold at this point.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper846/Reviewer_b4Df"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper846/Reviewer_b4Df"
        ]
    },
    {
        "id": "AWlwMmTGlVY",
        "original": null,
        "number": 3,
        "cdate": 1666578584566,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578584566,
        "tmdate": 1666678145709,
        "tddate": null,
        "forum": "Gb2Rndy5595",
        "replyto": "Gb2Rndy5595",
        "invitation": "ICLR.cc/2023/Conference/Paper846/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents context autoencoder (CAE), which follows BEiT and uses an additional latent contextual regressor to make predictions for the masked patches with cross attention over the visible patches. By doing that we can encourage the masked patches' representation predicted from visible patches are aligned with the one from the encoder and then benefits the learning and downstream transferring. Experiments on downstream tasks also show that it can achieve better performance compared with the baseline BEiT and MAE.",
            "strength_and_weaknesses": "The paper is well-written. The motivation of this paper is clear and easy to follow.\n\nThe proposed attentive probing is interesting and well-motivated, however, it seems that even with this metric the CAE trained with 800 epochs using ViT-B cannot surpass the contrastive learning-based model MoCo-v3 according to Table 1.\n\nPerformance wise, the downstream task results on COCO look superior, especially when using ViT-B, but when moving to ViT-L the gain seems diminished (from ~2 points to ~0.5 points compared with MAE on 1600ep).\n\nThe technical part seems to be somewhat incremental, how important/critical the alignment is? Seems like this issue only happens when making predictions in the representation space. For example, MAE without the alignment loss will not show meaningless output like Figure 3. The role of the cross-attention based latent contextual regressor is also not clear, one could also use the output from the MAE decoder's first layer to compute the alignment loss.",
            "clarity,_quality,_novelty_and_reproducibility": "In the paragraph of `Relation to BEiT and MAE.`, the authors mentioned that `In MAE (He et al., 2022), the so-called\ndecoder may play a partial role for representation learning as the representations of the visible\npatches are also updated in the MAE decoder`, which is somewhat inaccurate and makes me confused as the \"updated representation\" for visible patches is neither supervised with the reconstruction loss nor used for downstream tasks. Whether using extra layers to process representations for visible patches should not be a key difference and the cross attention used in this paper also has MLP for the key/value (which are the visible patches feature).\n\nFigure 3 is somewhat hard to follow without referring to the caption, might be better to add some illustration about how the output is generated.\n\nMisc: I believe the citation of LARS is incorrect.",
            "summary_of_the_review": "I think this paper shows some interesting findings and good performance, although the technical contribution is somewhat limited from my perspective. Thus my rating is 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper846/Reviewer_TXRx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper846/Reviewer_TXRx"
        ]
    },
    {
        "id": "hzPOF35_MB0",
        "original": null,
        "number": 4,
        "cdate": 1667286684500,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667286684500,
        "tmdate": 1667286684500,
        "tddate": null,
        "forum": "Gb2Rndy5595",
        "replyto": "Gb2Rndy5595",
        "invitation": "ICLR.cc/2023/Conference/Paper846/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed a novel contextual autoencoder framework for SSL. The proposed CAE approach introduced a cross-attention module to learn the latent space knowledge between the visible and masked patches. The paper had a comprehensive analysis between the proposed approach and the existing SSL approaches which gave some insight to the reader to understand the core contributions.  \n",
            "strength_and_weaknesses": "Strength\n1. The paper is well written and easy to follow. The comprehensive analysis between the proposed approach and the existing SSL works add a valuable insight into its contributions.\n2. The evaluation confirms the proposed approach can outperform the SOTA SSL approach on various backbone and downstream tasks.\n\nWeakness\n1. The novelty of this paper is limited. The proposed CAE is an improvement work over MAE and BEIT by further exploiting the knowledge between the masked and visible patches in the latent space. There is no sufficient evidence that the proposed cross-attention module can further improve representation performance learned by CAE.\n2. The proposed CAE approach used a random block-wise masking approach. It is necessary to add an ablation study about the performance between various masking approaches, e.g. random patch masking. Moreover, the masking ratio is set to 0.5 by default. What would the performance be for other masking ratios? An ablation study would help clarify that.\n3. Some technical details are missed in the paper. E.g. how to decode \\bar{Y}_m from \\bar{Z}_m in figure 7a is not clear. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written with most of the details clearly presented.\n\nThe paper\u2019s quality is good in general but missed some technical details.\n\nThe paper is an improvement of BEIT and MAE. The novelty is limited as the comments above.\n",
            "summary_of_the_review": "The paper is an improvement work over BEIT and MAE with some minor novelties. The proposed CAE algorithm achieved the SOTA performance on various backbone and downstream tasks. The paper can be improved by clarifying the technical details and adding ablation studies.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper846/Reviewer_KNoM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper846/Reviewer_KNoM"
        ]
    }
]