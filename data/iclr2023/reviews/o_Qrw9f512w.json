[
    {
        "id": "96GPyMdl4K",
        "original": null,
        "number": 1,
        "cdate": 1666543918257,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666543918257,
        "tmdate": 1666543918257,
        "tddate": null,
        "forum": "o_Qrw9f512w",
        "replyto": "o_Qrw9f512w",
        "invitation": "ICLR.cc/2023/Conference/Paper1330/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors of this paper present a novel perspective for the task of Class Agnostic Counting (CAC), drawing similarities with the task of Visual Object Tracking (VOT), where a pattern (VOT: patch / CAC: reference) is localized in an image (VOT: search space / CAC: query image). \n\nIn particular, the authors leverage:\n - previous finding in VOT models including self- and cross- attention mechanisms (from TransT, Chen et al. (2021) and MixFormer, Cui et al. (2022)), \n - previous findings in CAC models, including the general structure of the models and a Bilinear Matching (from BMNet, Shi et al. (2022)), \n - previous finding in crowd counting models, including the generalized loss based on optimal transport (from SDNet, Ma et al. (2021)), and\n - novel modules such as the Multi-Scale enhancement for matching and density map estimation\n - novel preprocessing of the dataset (inspired by FamNet, Ranjan et al. (2021))\n\nto build a CAC model showing state-of-the-art performances on the datasets/benchmarks FSC-147 and CARPK.\n\nThe authors provide a complete analysis of their method, with an ablation study for all the modules they have integrated.\n",
            "strength_and_weaknesses": "Strengths:\n\nThe method presented by the authors reached impressive state-of-the-art performances on the FCS-147 dataset for CAC.\nThe method is able to transfer to CARPK (with state-of-the-art performances) without the need for any extra fine-tuning.\nThe similarity of the architectures for CAC with the architectures for VOT is interesting and worth noting.\n\nWeaknesses:\n\nThe similarities drawn between the CAC and VOT tasks omitted an important analysis. In particular, VOT methods are trained to discriminate similar objects (same class) from the same image, while CAC actually wants to look at those exact objects. In VOT, those extra samples in a frame are referred to background clutter, and previous works focus on learning to discard those distractors (e.g. \u201cContext-aware correlation filter tracking\u201d, Mueller et al., CVPR\u201917 / \u201cDistractor-aware siamese networks for visual object tracking\u201d, Zhu et al., CVPR\u201918 / \u201cExploring Motion Information for Distractor Suppression in Visual Tracking\u201d, Liu et al., CVPR\u201922). Because of the nature of the tasks, I would respectfully disagree with the authors who state that \u201cthe formulation of visual object tracking task is similar to CAC\u201d (abstract), \u201cvisual object tracking formulation share similar formulation [...] as the CAC task\u201d (introduction), \u201cobject tracking excel at the task of localizing the target objects from the query image which is similar to CAC\u201d (related work), and \u201cthe setting and architecture of transformer-based trackers are similar with existing CAC models\u201d (methodology) among other places in the remainder of the paper.\n\n\nWhile the CAC and VOT architectures show significant similarities, the knowledge a tracker is expected to learn is different from the knowledge needed for a CAC task. The learning process aims at different goals, and as a result, one would not expect the knowledge pre-trained in a VOT task to transfer to a CAC task. TransT and MixFormer were both pre-trained on a tracking task, and the paper misses an analysis comparing the performance with and without transferring the negative knowledge learned from the tracking task.\n\n\nFrom the ablation study, it appears that most improvement originates from the optimal transport technique borrowed from Ma et al., and very little from the attention mechanisms, and tracker architecture. As a result, I would recommend putting the focus on that generalized loss, rather than biasing the reader into believing that the improvement originates from expensive transformer-based mechanisms or a tracking formulation. Moreover, the paper only mentions that loss without properly defining it. It is a pity and frustrating for the reader to not fully grasp and understand that loss, that contributes to most of the improvement in the ablation study.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is clear and provide quality content. The methodology appear relatively novel, but the contributions are not clearly stated. The authors promised reproducible code upon publication.\n\nThe paper missed a proof-reading. Some sentences are incomplete or missing \u201c...we adapt the transformer-based trackers for CAC since In addition, we select TransT \u2026\u201d (related work), as well as some prepositions all across the paper.\n\nThe exact contributions of this paper are not clearly stated, and most contributions appear to be borrowed from previous works in different fields. The paper would benefit from a clear statement of the contribution.\n\nThe hyperparameters scale, reach, blur and \\tau are not defined in the paper.\n\nThe dataset FSC147 is named differently in the paper (FSC-147 vs FSC147).\n\nThe aggregation of the results obtained from multiple references (e.g. for the 3-shot counting task) are not explained in the paper, hence is it unclear how the results from the multiple references are merged together.\n\nFigure 3: Would it be possible to visualize the qualitative results for the ablation study? It would validate the sharpness of the density map introduced by the GL based on OT.\n\nFigure 3: The significant figure should be truncated or averaged.\n\nTable 2: What are the performances on CARPK once fine-tuned? Also, the table is missing the SOTA method \u201cAn Accurate Car Counting in Aerial Images Based on Convolutional Neural Networks\u201d, Kilic et al., (2021) that appears SOTA on CARPK.\n\n",
            "summary_of_the_review": "The analysis of the similarities between tracking architectures and CAC architectures is interesting to be noted and analyzed. It appears that the methodology leads to SOTA results on the latest benchmarks, which is remarkable.\n\nYet, the authors claim that transformer-based trackers are strong baselines for CAC, but it appears that most of the improvement in the experiments originate from the Generalized Loss based on Optimal Transport, introduced by Ma et al. (2021) in a different task. The ablation study confirms such a statement. It is misleading to claim that the results originate from self-/cross- attention mechanisms and the transferability of trackers\u2019 knowledge to the task of class-agnostic counting.\n\nThe paper is very borderline, as I believe the analysis with trackers is a fresh perspective, yet it needs further investigations as it is misleading in the current form. As a result, I would recommend a score of 5.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_zJ5d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_zJ5d"
        ]
    },
    {
        "id": "VlE5d3U6E2",
        "original": null,
        "number": 2,
        "cdate": 1666576653485,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666576653485,
        "tmdate": 1666580744676,
        "tddate": null,
        "forum": "o_Qrw9f512w",
        "replyto": "o_Qrw9f512w",
        "invitation": "ICLR.cc/2023/Conference/Paper1330/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed to apply two existing Transformer-based trackers to class agnostic counting and evaluated their performance on public datasets.",
            "strength_and_weaknesses": "\nWeaknesses\n\n-The largest concern is the limited contribution. The authors directly apply two existing trackers to fix the counting task with minor changes by extending them to multi-scale architecture with an off-the-shelf generalized loss.  Besides, the core idea of transferring the CAC problem to a matching task between reference and query is the same with pervious arts. This paper only replaces the simple inner-production with more complex Transformer modules. I can't see any new insights for solving counting tasks in this paper. \n\n-Based on the comparison between Table 1 and Table 4, the improvement largely benefits from the used GL loss. The baseline model by using only TransTCAC is even not comparable with 'BMNet+* Shi et al. (2022)'. The current results can't support the advantage by using Transformer Trackers. \n\n-The experiments are not fair according to the current statement since the input resolution, model size, computational cost and the usage of multi-scale structure are missing in Table 1.\n\n-The statement 'Even without multi-scale setting, our models are able to achieve the best performance, proving the validity of exploiting transformer-based trackers as baselines of CAC task' in Quantitative Results of Sec. 4.3  is confusing. It seems that the listed TransTCAC(Ours)* already used the multi-scale setting according to Table 4.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The authors promise to release the code depending on the acceptance.  ",
            "summary_of_the_review": "This paper's novelty by applying siamese trackers is incremental. The used networks are directly borrowed from existing tracking methods without adaptively redesign for counting task. Besides, the performance improvement largely benefit from Transformer-based attention block which brings more computational cost. Based on these concerns, I tend to reject this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_eXTk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_eXTk"
        ]
    },
    {
        "id": "I-ePDKyS6ho",
        "original": null,
        "number": 3,
        "cdate": 1667098244434,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667098244434,
        "tmdate": 1667098244434,
        "tddate": null,
        "forum": "o_Qrw9f512w",
        "replyto": "o_Qrw9f512w",
        "invitation": "ICLR.cc/2023/Conference/Paper1330/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Paper tackles the task of Class Agnostic Counting (CAC) in a few-shot setting, which involves predicting the overall count for the object of interest in an image, given few exemplars of object of interest from the same image. Previous works on CAC such as Ranjan et al, FamNet, rely on correlation between the exemplar features and input image features to predict the density map (heatmap), and the sum of the density map serves as the overall count. Similar to the work of Shi el al, CountTR, authors replace the Resnet-50 backbone from earlier works with Transformer based backbone. Unlike CountTR, which uses Imagenet pretrained ViT backbone, authors use Transformer backbones designed for Visual Object tracking task. Drawing inspiration from BMNet, which uses bilinear matching between the exemplar features and image features, authors first draw similarities between bilinear matching and attention, and propose a attention based approach for matching the two sets of features.",
            "strength_and_weaknesses": "Strengths:\nThe main claim of the paper, that Transformer based approaches designed for object tracking are suitable for exemplar based CAC is reasonable. And the significant boost in performance achieved by the proposed approach provides some weight to the claim.\n\nWeaknesses:\n1. Original technical contribution of the paper is somewhat limited, since previous work like CounTR  has already advocated the use of Transformer for Class Agnostic Counting task.\n2. Most of the previous approaches on FSC-147 use Imagenet pretrained backbone such as Resnet-50 and ViT. Proposed approach uses backbones trained on Visual Object tracking datasets. This extra training data being used could be one of the reasons behind the superior performance of the proposed approach.\n3. Ablation study in table 4 would have been more complete had there been a row corresponding to ViT backbone (similar to the first row S1, but using ViT backbone instead of TransTCAC backbone).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is clearly written, and the proposed approach is well explained. Paper has somewhat limited novelty, given paper follows previous works like CounTR and BMNet.",
            "summary_of_the_review": "My main concern with the paper is the limited novelty of the proposed approach, as stated in the Strengths and Weaknesses section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_8qRK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1330/Reviewer_8qRK"
        ]
    }
]