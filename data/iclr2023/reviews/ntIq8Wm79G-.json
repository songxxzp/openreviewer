[
    {
        "id": "YYlLyS_z9M",
        "original": null,
        "number": 1,
        "cdate": 1666572183133,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666572183133,
        "tmdate": 1666572183133,
        "tddate": null,
        "forum": "ntIq8Wm79G-",
        "replyto": "ntIq8Wm79G-",
        "invitation": "ICLR.cc/2023/Conference/Paper5454/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors proposed a method to extract knowledge graph relations from a pretrained LM through automatic prompt creation and leveraging the pretrained LM to score the candidate entity pairs. Compared to previous works that usually rely on human annotated data or existing massive KGs, the authors' approach requires only the minimal definition of relations as inputs.",
            "strength_and_weaknesses": "Strength:\nThe proposed idea is simple and seems straightforward to implement. The proposed method needs minimal human input (only an initial prompt and 5 candidate entity pairs for each relation). It effectively leverages GPT3 to rephrase and generate better alternative prompts used for extracting new entity pairs. Overall, the paper is well written with detailed examples to illustrate the main idea.\n\nWeaknesses:\nAlthough the model shows better results than the baseline (COMET), it still lacks more analysis in the evaluation to convince the effectiveness of the proposed model. \n\nFirst, the result in Table 2 shows the precision of the prediction but not the recall. For example, the recall can be estimated on the known set of factual relations. The P-R curves in Figures 3 and 4 seem to partly answer this question. However, looking at the 0.8 level of precision, the recall is only less than 0.2, which raises another question about the overall effectiveness of the extraction method.\n\nThe baseline WebChild in Table 2 seems to extract a much higher number of tuples at 4.6M, while the proposed model ROBERTANET only extract 6741 tuples. It can be WebChild having much higher coverage, but this difference was not discussed in the paper.\n\nSecond, the quality of the extraction heavily depends on the compatibility scoring function (Eq. 1). It would be better to evaluate more on the design choice of this formula and explain why the proposed formula is optional for this purpose.\n\nThird, Looking at the extracted relations, it looks like some relations are more non-trivial than others. It would be useful to analyze more on the factual relations (e.g., the relations between named entities such as 'ceo_of', 'invent') because these relations will be more useful for downstream applications like QnA. The LAMA dataset has more of these relations so authors can extract and analyze more case studies from this dataset.\n\nAnother suggestion, in the GPT3 prompt: \"paraphrase: {sentence}\" used to extend the prompt set, would it be better to include example of all 5 seed entity pairs into the prompt to help eliminating the ambiguity?\n",
            "clarity,_quality,_novelty_and_reproducibility": "N/A",
            "summary_of_the_review": "Overall, the idea proposed in this work is simple, easy to implement and it shows promising results compared to the baselines. However, the evaluation currently lacks analysis about the coverage and quality of the extracted relations.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns"
            ],
            "details_of_ethics_concerns": "There is a risk related to the bias that can be propagated from the pre-trained LM. The filter was not discussed in this work. ",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_dt4V"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_dt4V"
        ]
    },
    {
        "id": "zomGsXHDdtD",
        "original": null,
        "number": 2,
        "cdate": 1666684154760,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684154760,
        "tmdate": 1666684154760,
        "tddate": null,
        "forum": "ntIq8Wm79G-",
        "replyto": "ntIq8Wm79G-",
        "invitation": "ICLR.cc/2023/Conference/Paper5454/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a pre-trained LMs based KG construction model aiming at identifying new entities for a single query relation. The proposed model is a bootstrapping strategy that starts from a query prompt with a few seed entity pairs and iteratively generates new pairs by means of new prompts generated by a GPT-based paraphrase model. Further, an LM-based reweight function is employed to weigh the new prompts and new pairs. The experiments conducted on crowdsourcing-based evaluation and case study to show the model is competitive to SOTA baselines. ",
            "strength_and_weaknesses": "Strength:\n1. The problem of automatically constructing KG from pre-trained LMs is well-motivated.\n2. It is interesting to combine the iterative KG construction into the current pre-trained LMs fashion.\n\nWeakness:\n1. The framework of iterative KG construction (i.e., bootstrapping) is not novel.\n2. Some important technical details, e.g., how to generate multi-token entities and how to reduce the candidate set, are missing.\n3. The experiment is not comprehensive. There is no objective evaluation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Some important technical details are missing, e.g., efficiently generating candidate entities. Please refer to the Summary of the review Q3.\n\nQuality: The model is only evaluated by crowdsourcing, with no objective evaluation. The effectiveness is not significant compared with SOTA baselines.\n\nNovelty: The idea is generally interesting, the authors bring the old wisdom of iterative KG construction into the pre-trained LM fashion. But the core technical contribution is just an LM-based reweighting. Methodological nvoelty is a shortage.\n\nReproducibility: Unable to evaluate, since the technical details are unclear.\n",
            "summary_of_the_review": "1. The proposed framework is a kind of bootstrapping-based knowledge graph construction approach, which, reminisce of the Hearst patterns for hypernym relation. My major concern is how to effectively handle the semantic drift, i.e., the semantics of new patterns and instance harvest may change drastically along with iteration or paraphrasing. But authors did not discuss this problem in-depth or provide a method with a plausible bound. What we have in the model is the LM-based paraphrasing and weighting, however, the key point is, LM does not necessarily guarantee the semantics.\n\n2. For the diversity of paraphrase (second paragraph of Section 3.1), it is not clear (1) why to use a textual measurement (i.e., edit distance) to ensure diversity of paraphrases (second paragraph of Section 3.1). It is a bit weird that the whole paper is deep learning based, except for the paraphrase generation, which adopts an old-fashioned textual similarity ED, which, is obviously out of the deep learning fashion. (2) how this ED constraint works. As ED works for a text pair, do all generated prompt pairs need to keep a certain distance?\n\n3. Some important technical details are missing:\n  (1) Efficient generation candidate entity pair generation of Section 3.2. Appendix A.5 has a few sentences talking about \"mask-filling\" but I cannot find the details of how to generate multi-token entities and how to use \"thresholding and pruning\" to reduce the candidate set.\n  (2) For computing Eq.1, it is not clear (a) how to generate the query text. Is the query text formed by inserting a specific entity (e.g., insert h into p for P(h|p))? If so, what is the difference between Plm(t|p,h) and Plm(h,t|p)? (b) how to compute the probability of Plm(h,t|p), Plm(h|p), and Plm(t|p,h). Is the probability computed by the generative probability of the LM?\n\n\n4. In addition to the manual evaluation (crowdsourcing rating), the objective evaluation based on evaluation datasets should be given. For example, the authors can select datasets adopted by relevant tasks, e.g., knowledge graph completion, such as WRNN, FB15K-237, etc. for evaluation.\n\n5. The baseline methods should be introduced in a few sentences. \n\n6. The layout of Table 2 should be fixed.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_pDgC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_pDgC"
        ]
    },
    {
        "id": "IxdYYn8CCjx",
        "original": null,
        "number": 3,
        "cdate": 1666709903510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666709903510,
        "tmdate": 1666710146009,
        "tddate": null,
        "forum": "ntIq8Wm79G-",
        "replyto": "ntIq8Wm79G-",
        "invitation": "ICLR.cc/2023/Conference/Paper5454/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "By probing pre-trained language models with prompts, the paper presents a novel and practical framework for automatically constructing knowledge graphs. The framework's input consists of relation definitions and a small set of seed entity pairs. For each relation, the framework generates and then paraphrases prompts. The extracted entity pairs of each relation are then evaluated using the proposed consistency score. Finally, it reranks these pairs and outputs the top-K results. Experiments show that the resulting KG is diverse and accurate. The proposed automatic prompt generation method is also effective. The resulting KG can serve as a symbolic interpretation\nof pre-trained language models.",
            "strength_and_weaknesses": "Pros:\n\n* The work's most significant strength is its practical pipeline for automatically constructing knowledge graphs (KGs) from pre-trained language models (LMs). Previous research on \"LMs as KGs\" or \"knowledge probing from LMs\" has primarily focused on prompt generation and does not cover the entire KG construction pipeline.\n\nCons:\n\n* One potential shortcoming of the work is that its technical contribution may not be sufficient for a research paper.\n\n* The paper also has a few minor flaws, and the writing could be improved, as listed below:\n\nMinor issues:\n\n* The multi-token issue in entity names. The authors state in Sect. 3.2 that \"Each entity consists of one or more tokens\". How to resolve the multi-token issue in the likelihood computation? Or, for example, how to compute P_{LM}(t|p,h) if the name of entity t has more than one tokens? In Appx. A.5, the authors state that \"we enumerate the number of masks for every entity\". Is there a maximum value for such a number? Is it a hyper-parameter?\u00a0\n\n* Sect. 3.2 says that \"The use of the minimum individual log-likelihoods allows us to apply rich thresholding and pruning strategies (e.g., thresholding on log PLM(h|p) for proposing the head entities), as described more in the appendix.\" However, it seems that there is no related content in the appendix. Or, is it Appx. A.5?\n\n* It would be preferable to include a subsection in Section 4.2 that simply introduces the baselines used in the experiment.\n\n* In Sect. 4.2, the authors state that \"we restrict every entity to appear no more than 10 times to improve the diversity of generated knowledge\". This, in my opinion, is not reasonable because it would result in a sparse KG. Table 2 also demonstrates this problem.\n\nTypos:\n\n* \"Those systems, however, often involves a complex set of components\" -> Those systems, however, often involve a complex set of components.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is clear, but the writing could be improved. The authors promise to release the code as well as the resulting KG.",
            "summary_of_the_review": "Overall, I think the paper has both advantages (a practical KG construction pipeline) and disadvantages (some small issues). It can be further improved.\u00a0",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_XQg6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5454/Reviewer_XQg6"
        ]
    }
]