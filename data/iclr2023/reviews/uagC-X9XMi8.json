[
    {
        "id": "HWwI1a_o1fF",
        "original": null,
        "number": 1,
        "cdate": 1666426878143,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666426878143,
        "tmdate": 1666426878143,
        "tddate": null,
        "forum": "uagC-X9XMi8",
        "replyto": "uagC-X9XMi8",
        "invitation": "ICLR.cc/2023/Conference/Paper2463/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors first theoretically present the bottleneck of graph transformers\u2019 performance with depth. The authors then propose a simple but effective substructure token based local attention mechanism in graph transformer, promoting focus on local substructure features of deeper graph transformer. Empirical results show that the proposed achieves state-of-the-art results on standard graph benchmarks with deeper models.",
            "strength_and_weaknesses": "Strengths:\n- The theory proposed looks interesting, and the corresponding transformer structure introduced also look very novel.\n- The authors conducted experiments on various benchmarks and the results look very competitive.\n- The paper is clearly written and the motivation is easy to follow.\n\nWeaknesses:\n- Why there's such a negative correlation for Graph Transformer, while for Transformer in NLP the case is the larger, the better? Does the theoretical analysis also apply to Transformer in NLP?\n- The proposed method has so many different designs so that it's hard to tell whether the proposed theory can justify what actually happened. Specifically, the authors proposed to tokenizing substructures subsampled from the graph. This is very different from the previous Graph Transformers as there's no sampling before.\n- The authors didn't discuss the runtime overhead of the proposed method. Is it feasible to scale the proposed method on larger graphs?\n- There isn't much ablation study in the paper. Specifically, the authors should study the size of substructure and how it affects the performance degradation with increased depth.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow.\nThe novelty of the proposed method looks significant.\nThere isn't much implementation detail provided so I feel it's nontrivial to reproduce the exact model.\n",
            "summary_of_the_review": "This paper provides interesting theoretical results and novel Graph Transformer design. The empirical results look good but not enough ablation studies. There's a nontrivial gap between the theory and the actual method proposed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_1tcv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_1tcv"
        ]
    },
    {
        "id": "dhDYLa4rc9",
        "original": null,
        "number": 2,
        "cdate": 1666489052782,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666489052782,
        "tmdate": 1666489052782,
        "tddate": null,
        "forum": "uagC-X9XMi8",
        "replyto": "uagC-X9XMi8",
        "invitation": "ICLR.cc/2023/Conference/Paper2463/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper shows the theoretical bottleneck on attention capacity for transformer depth scaling and proposed a new graph transformer model called DeepGraph to address it. The proposed architecture relies on substructure-based attention mechanism, where there are extra substructure tokens that correspond to sampled substructures. Specifically, each substructure token only attends to tokens within it. The model is shown to increase performance on several datasets as depth increases.",
            "strength_and_weaknesses": "Strength\n- Depth limitation of gnns and graph transformers has been a key issue in graph ML. The theoretical analysis reveals insights for solving this. \n- The proposed method is conceptually simple and motivated by theoretical results.\n- The proposed method is tested over a diverse set of datasets and tasks and demonstrates empirical gains.\n\nWeaknesses\n- The performance improvements with depth seem pretty small relative to the variances on most datasets.\n- The method seems not completely correspond to the theoretical motivation: in theorem 3 substructure based local attention is defined as  \"where each node only attends nodes that belong to the same substructures\". If I understand correctly, in DeepGraph each node can still attend to all other nodes, but only that the substructure token only attends to and by the nodes in the substructure. Can this be further justified?",
            "clarity,_quality,_novelty_and_reproducibility": "The work is novel to the best of my knowledge and seems of high quality. The paper is clearly written mostly, with small confusing bits potentially due to typos. Specifically, in the definition of M_{ij} under equation 10, should it be i \\in {...} instead of i+n \\in {...}? Or is there some special relation between node i and substructure i + n? \n",
            "summary_of_the_review": "Overall, the paper is addressing an important issue. The theoretical results and proposed methods seem sound and well tested. The concern is about the significance of the experimental results on depth improvement.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_KU4L"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_KU4L"
        ]
    },
    {
        "id": "LONNY5swPOX",
        "original": null,
        "number": 3,
        "cdate": 1666739038595,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666739038595,
        "tmdate": 1670958938898,
        "tddate": null,
        "forum": "uagC-X9XMi8",
        "replyto": "uagC-X9XMi8",
        "invitation": "ICLR.cc/2023/Conference/Paper2463/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The author studies the effect of number of layers in graph transformer model, and claims that the previously used graph transformer layer has decreasing attention capacity on attending substructures with increasing attention layers. Then the author improves graph transformer with adding sampled substructures as token along with nodes. Extensive experiments over large real-world datasets are conducted to show its improvement.",
            "strength_and_weaknesses": "**Strength**: \n1. Substructure based GNNs are widely explored last year and also influences the graph transformer area. It's interesting to see that adding substructure directly helps improving current graph transformers.\n2. The author proposes a measure to define the attention capacity for substructures. This is an interesting angle. \n3. The improvement over real-world dataset is great, especially on PATTERN dataset. \n\n**Weakness**:\n1. Notation and writing is not clear and is too hard to follow. I suggest the author to revise the paper extensively to make the notation easier to follow. For example, the author use $G^S$ for general notation of subgraph, which is really confusing as I was originally thinking that $G^S = G[S]$ representing the set S induced subgraph on G.  For general subgraph pattern, I suggest the author remove the G notation, just use something like $S$ directly, as there is no relation to G. The section 4 needs to be greatly improved. For example, even the first paragraph inside 4.1 is hard to follow. All notations of graph, subgraph, pattern, and support are too hard to follow. Also $supp(e) \\subseteq  N^S$ instead of $supp(e) \\in  N^S$. There are so many confusing notations and I cannot read and evaluate the section 4. Another example is the $\\triangle$ notation...it represents easy stuff in principle but the notation makes the easy stuff hard to interpret. Again, like $Attn_{A}$,  the underscript is never mentioned before using. \n2. Definition 1 of measuring attention capacity is questionable. There are learnable W inside and it's not possible to analyze the F norm directly, as W can have any scale to enlarge the F norm. Also, there is no relationship between small F norm and substructure indistinguishability. (a-b small doesn't imply a=b for graph separation case) I suggest the author at least give some empirical example to link the small F norm and the bad ability of identifying substructure. \n3. Theorem 1 and Theorem 2 I cannot read yet, after the author revise the section 4 I would like to check the theorem correctness. \n4. Section 5 substructure sampling is very similar to the one designed in [Zhao et al. ICLR 22]. The author should mention with reference. \n5. The designed method is a special case of [Kim et al. NeurIPS 22], and it doesn't provide much new contribution to model design. \n6. The ZINC experiment may need 500K parameter restriction in comparison. \n\n[Kim et al. NeurIPS 22] Pure transformer are powerful graph learners. \n[Zhao et al. ICLR 22] From stars to subgraphs \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity can be improved. Quality is limited by novelty in model design. However if the theoretical analysis is correct, the novelty can be improved. Please see the comments about Definition 1 and Theorem 1,2. ",
            "summary_of_the_review": "The author added substructure tokens to current graph transformer and show empirically improvement. In the meantime, the author try to answer why increasing depth doesn't benefit the performance for previous graph transformers, with a measure of attention capacity. However the relationship between the defined attention capacity and the empirical performance drop of increasing depth is not clear. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_n5aK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_n5aK"
        ]
    },
    {
        "id": "uzT-3aA9Sxc",
        "original": null,
        "number": 4,
        "cdate": 1667267514635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667267514635,
        "tmdate": 1667334887306,
        "tddate": null,
        "forum": "uagC-X9XMi8",
        "replyto": "uagC-X9XMi8",
        "invitation": "ICLR.cc/2023/Conference/Paper2463/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the limitations to deepen graph transformers and argue that substructure learning gets increasingly harder in the canonical formulation of the graph transformers. To address this limitation, the paper proposes a variant of graph transformers that explicitly models substructure attention and encoding. Empirical results suggest that the proposed DeepGraph approach is effective and competitive.",
            "strength_and_weaknesses": "Strengths:\n1) The paper tries to provide both theoretical and empirical insights on the importance of substructure sensitivity to the capacity of graph transformers.\n2) The writing is generally clear.\n3) I think the problem in itself is interesting (i.e., how can we train deeper graph transformers).\n4) Good empirical results and ablative studies.\n\nWeaknesses/questions:\n1) While it's nice that the paper provides theoretical analysis on the model capacity, it is unclear to me how meaningful they are. Specifically, for example:\n    - Inequality (6) provides an upper bound. In practice, $C_1$ and $C_2$ also depends on $H_\\ell$, so they are not independent. This makes the inequality (12) in the Appendix potentially vacuous. Moreover, while $\\alpha_i$ is accumulated in inequality (6) across layers indeed, it is unclear how $W_\\ell^{VO}$ (which is learnable) evolves across depth. Could it balance this decay process? As another example, Theorem 3 is merely comparing two upper bounds. Without any evidence on the looseness of these upper bounds, it's hard to evaluate the value of this theorem. It'd be great if the authors could elaborate on issues like these.\n    - The theoretical results applies mainly to the input level. $G_1^S, \\dots, G_m^S$ makes sense at the input layer where each node contains the information only about itself. But starting from layer 2, the hidden units already combines information from all lower-level nodes, making the substructure argument a bit vague.\n2) Given the assumptions, the theoretical results should also largely apply to the original (non-graph) transformers, such as those used in NLP. And yet we are able to train very deep transformers there, even though substructures do exist in language. Could the authors discuss more what their results imply in non-graph applications?\n3) Do techniques that allow very deep training of conventional transformers help deepen graph transformers (e.g., ReZero)? This would be an interesting ablative study that demonstrates why the substructure attention is a better alternative for graphs.\n4) For PCQM4M-LSC and ZINC, the # of nodes in these tasks is usually very small (e.g., <60). I'm a bit surprised that substructure is still very useful in these cases as global attention is not operating on a huge graph anyway.\n5) Could the authors provide the # of parameters for each model in Table 1?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally quite clear, and the empirical studies is relatively extensive. I did not check the math carefully but I did go through all of the proof. The paper provides a good insight to an important problem that exists in graph transformers, and the empirical results seem solid. However, structural encodings is not a completely new idea. The authors mentioned that the code will be provided.",
            "summary_of_the_review": "Overall, I find the paper interesting and it provides a good insight into how substructure modeling plays a role in the attention and expressivity of modern graph transformers. There is still an obvious gap between the theory section and the empirical section (e.g., the paper did not empirically verify any of the theoretical conclusions), but the empirical results are quite good. I'm inclined to acceptance on the condition that my questions can be answered satisfactorily.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_n5Mh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2463/Reviewer_n5Mh"
        ]
    }
]