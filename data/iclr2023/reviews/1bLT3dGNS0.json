[
    {
        "id": "h_9MbmEoyJ",
        "original": null,
        "number": 1,
        "cdate": 1666703307601,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666703307601,
        "tmdate": 1669298102165,
        "tddate": null,
        "forum": "1bLT3dGNS0",
        "replyto": "1bLT3dGNS0",
        "invitation": "ICLR.cc/2023/Conference/Paper2105/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates curriculum learning for graph neural networks (GNNs), aiming at selecting the most important edges in a graph for GNN training. The authors formalize the task as an optimization problem, which has a node-level predictive loss and a structural-penalty loss. A proximal algorithm is proposed for optimization. Experimental results on multiple datasets are encouraging.",
            "strength_and_weaknesses": "Strengths:\n1. The problem of learning graph structures for GNN is important.\n2. The proposed method uses the node representations learned by GNNs to measure the likelihood of each edge, which is quite intuitive.\n3. Some improvements are observed in the experiment.\n\nWeaknesses:\n1. The writing of the paper can be further improved.\n2. The improvements over existing methods are not significant.\n\nDetailed comments:\n\n1. The writing of the paper can be further improved.\nThe abstract of the paper says that a curriculum learning method is proposed, where edges are given to GNNs according to their difficulty from easy to hard, and the difficulty is measured by a self-supervised learning paradigm. However, in the model section, these claims are not well explained. The edge difficulty and self-supervised learning paradigm are not mentioned. Although readers can roughly get the idea that the edge difficulty is measured by the inner product between corresponding node embeddings, I feel like the abstract and model sections are written by different authors, making it not easy to follow.\n\n2. Many ideas of the paper are not new\nThe overall loss function of the proposed method is given by Eq. (3) of Algorithm 1. There are three parts, where the first part is a supervised loss, the second part is a graph reconstruction loss, and the third one is a regularization term. The first two terms are widely studied in the graph machine learning literature for GNN training and structure learning. Given these existing works, I feel like this paper does not bring new ideas. Although the authors introduce their method from a perspective of curriculum learning and some smoothing strategies are proposed in Sec. 4.3, I think the contribution is not so significant as the underlying ideas are not so different from existing methods.\n\n3. The improvements over existing methods are not very significant.\nThe results on real-world datasets are presented in Tab. 2, where the improvements over existing methods are not so significant, and the results on different datasets all have very high standard deviation. To better convince readers, I think it is helpful to consider some larger datasets for evaluation, where the standard deviation over different runs can be smaller.",
            "clarity,_quality,_novelty_and_reproducibility": "See the comments above.",
            "summary_of_the_review": "See the comments above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_fwhF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_fwhF"
        ]
    },
    {
        "id": "QtXXhhNk0we",
        "original": null,
        "number": 2,
        "cdate": 1666738580861,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666738580861,
        "tmdate": 1666738580861,
        "tddate": null,
        "forum": "1bLT3dGNS0",
        "replyto": "1bLT3dGNS0",
        "invitation": "ICLR.cc/2023/Conference/Paper2105/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a method for iterative construction of graph structure in GNN settings. The key is to make use of the homophily -- similar nodes tend to connect. The optimization procedures encourage more edges to be added along the training process. This results in a better optimized GNNs -- boosting up accuracy performance and improved robustness against structural noise.",
            "strength_and_weaknesses": "Strength\n======\n- The paper studies an interesting problem -- optimizing the parameter and graph structure jointly.\n- The proposed solution is sensible and is shown empirically to improve performance and robustness.\n\nWeaknesses\n==========\n- Posing the forward edge selection as curriculum learning is somewhat confusing. It is better to emphasize on the joint optimization aspects.\n- Again, adding terms like self-paced, self-supervised learning are also confusing.\n- Although homophily is a well-known properties of real-world graphs, it would be interesting to see if this assumption breaks, e.g., redesigning the kernel for graph reconstruction.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is a nice addition to the growing literature of GNNs, emphasizing on structure learning. Overall it is a readable paper, although added concepts like curriculum learning, self-paced learning and self-supervised learning make the messages unclear.",
            "summary_of_the_review": "An useful attention to the literature of graph structure learning in GNNs. I'd like to see when the homophily assumption breaks and how the method will be adjusted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_f5Ws"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_f5Ws"
        ]
    },
    {
        "id": "wMyCCMeUMg",
        "original": null,
        "number": 3,
        "cdate": 1666813052239,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666813052239,
        "tmdate": 1666813052239,
        "tddate": null,
        "forum": "1bLT3dGNS0",
        "replyto": "1bLT3dGNS0",
        "invitation": "ICLR.cc/2023/Conference/Paper2105/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper targets the problem that the edges in a graph may have different levels of difficulty to learn and proposes a curriculum learning-based model to gradually incorporate edges during learning according to their difficulties. The difficulty level is obtained by self-supervised learning. Experiments are conducted on 9 synthetic datasets (with 9 different homophily coefficients) and 7 real-world datasets.",
            "strength_and_weaknesses": "\nStrengths:\n\n1. The paper is overall easy to understand. The motivation and the background knowledge of the curriculum learning are clearly introduced.\n\n2. The idea to achieve better learning performance on graphs by investigating the difficulty of the edges is novel.\n\n3. In experiments, both synthetic datasets and real-world datasets are used. The synthetic datasets have controllable properties (i.e. homophily coefficient).\n\n\nWeakness:\n\n1. The main idea is pretty intuitive. The difficulty level of the edges is only intuitively proposed without concrete examples. Therefore, it is unclear what exactly the difficulty levels mean. Moreover, the noise seems to be one component of the difficulty, is there any other concrete factors determining the difficulty?  \n\n2. i.d.d data is not correctly used. What the authors want to express through i.d.d data should be 'independent data', in which the data have no connections. While i.d.d. data refers to different samples drawn independently from identical distributions.\n\n3. In experiments, it is unclear why the difficulty of the edges can correspond to the formation probability.\n\n4. The datasets are rather small. \n\n5. The proposed method is not consistently better than the baselines in all datasets. Besides, is there any experiment that can demonstrate that it is indeed the curriculum learning part that improves the performance, instead of other factors like model complexity?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is OK.\n\nThe quality is questionable since some key points are not clear.\n\nNovelty is good.\n\nReproducibility is unclear, and can only be checked by running the code.\n",
            "summary_of_the_review": "Overall, this paper has a novel idea, but the proposed model is not totally clear. Besides, misusing the concepts like i.d.d. makes the paper not rigorous enough.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_yJ3m"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2105/Reviewer_yJ3m"
        ]
    }
]