[
    {
        "id": "7nBgsLK41A",
        "original": null,
        "number": 1,
        "cdate": 1666613763324,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613763324,
        "tmdate": 1666613763324,
        "tddate": null,
        "forum": "49N06mWPFUm",
        "replyto": "49N06mWPFUm",
        "invitation": "ICLR.cc/2023/Conference/Paper5280/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a network diffusion process to model (user, content) feature dependent network propagation and formulate the problem as an infinite-horizon discounted MDP, with the goal to select seed users and customize contents to maximize network influence. Then it proves a sub-linear regret bound for the proposed algorithms, and validate their results empirically on both synthetic and twitter social network datasets. ",
            "strength_and_weaknesses": "Strengths: \n1. The paper proposes a network diffusion process to model (user, content) feature dependent network propagation and formulate the problem as an infinite-horizon discounted MDP, with the goal to select seed users and customize contents to maximize network influence. \n2. it proves a sub-linear regret bound for the proposed algorithms, and validate their results empirically on both synthetic and twitter social network datasets. \n\n\nWeakness: \nThe paper only compares to random policy and IMLinUCB, lack of strong comprehensive baseline comparison and empirical evaluation. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Questions: \n1. Comparing to IMLinUCB, MORIMA variants seems to have low variance, so curious to understand why that's the case? \n2. Among MORIMA variants, MORIMA without slow switching (in green) seems to be more stable over timesteps comparing to MORIMA (blue). Should we factor in stability over timesteps in choosing these variants? If so, how? \n3. In Figure (b), \"MORIMA with known A\" seems to underperform the other two MORIMA variants when timesteps reaches 200+. Is that expected or why is that? ",
            "summary_of_the_review": "The paper proposes a network diffusion process to model (user, content) feature dependent network propagation and formulate the problem as an infinite-horizon discounted MDP, with the goal to select seed users and customize contents to maximize network influence. Then it proves a sub-linear regret bound for the proposed algorithms, and validate their results empirically on both synthetic and twitter social network datasets. \n\nIn the experimentation section, the paper only compares to random policy and IMLinUCB, lack of strong comprehensive baseline comparison and empirical evaluation. In addition to that, there are some unclarity in the experimentation results, shared in below: \n1. Comparing to IMLinUCB, MORIMA variants seems to have low variance, so curious to understand why that's the case? \n2. Among MORIMA variants, MORIMA without slow switching (in green) seems to be more stable over timesteps comparing to MORIMA (blue). Should we factor in stability over timesteps in choosing these variants? If so, how? \n3. In Figure (b), \"MORIMA with known A\" seems to underperform the other two MORIMA variants when timesteps reaches 200+. Is that expected or why is that? ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_Asps"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_Asps"
        ]
    },
    {
        "id": "Nm1brgU1KTu",
        "original": null,
        "number": 2,
        "cdate": 1666684784297,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684784297,
        "tmdate": 1666684784297,
        "tddate": null,
        "forum": "49N06mWPFUm",
        "replyto": "49N06mWPFUm",
        "invitation": "ICLR.cc/2023/Conference/Paper5280/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The adaptive version of the online adaptive topic-aware influence maximization problem is considered in this work, where its primary objective is the spreading of specific content in social networks. The problem is formulated as an infinite-horizon discounted MDP, and a model-based reinforcement algorithmic scheme, called MORIMA, has been proposed that learns a policy adaptively. The authors provide a regret analysis for the proposed algorithm. Experiments have been conducted on small synthetic and real-world networks, while the proposed algorithm has been compared with the IMLinUCB algorithm.\n",
            "strength_and_weaknesses": "**Strengths**\n- The examination of the online influence maximization problem under the adaptive setting is quite interesting, as resembles what happens in the real-world. \n- The adoption of a model-based reinforcement learning algorithm for selecting seed users adaptively.\n- A regret bound is provided for the proposed algorithm.\n\n**Weaknesses**\n- In general, the paper is well written, nevertheless, some of its parts need to be clarified.\n- The exploration efficiency of the proposed reinforcement learning algorithm is not clear.\n- The applicability of the MORIMA algorithm in real-world networks with millions of users seems to be not possible.\n- Experiments have been conducted only on small synthetic and real-world networks that are  ",
            "clarity,_quality,_novelty_and_reproducibility": "The main question about the proposed algorithm is its scalability on huge graphs with millions of users. It is not obvious how the proposed algorithm can be applied in practice. For this purpose, experiments should be conducted on larger graphs in order to validate the algorithm's ability to maximize the influence of specific contents. Even the `real-world` networks are pretty small and are technically created by sampling multiple dense sub-graphs from the Twitter network.\n\nAlso, some points should be discussed further by the authors. \n- For instance, is not clear how the states are represented in the Q-learning algorithm. \n- How the agent is able to efficiently explore the environment? Is it achieved by using the bonus term? \n- What happens in the case where N is extremely large? Is it still possible to compute the covariance matrix $\\Sigma_{t-1}$?\n- Matrix $A^k$ is not well defined. The sum of the elements of each row should be equal to one.\n- The idea that a user has more than one chance to influence their neighbors and that of cumulative reward is not new.\n\n",
            "summary_of_the_review": "The authors should address the limitations of the MORIMA algorithm in a clear way. As aforementioned, the main question of this work is its applicability in real-world networks with a large number of users. The potential negative social impact of this work should be discussed further. How can this work have a positive impact on our society and what is its main objective?\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_vMK7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_vMK7"
        ]
    },
    {
        "id": "se5LL5fItC7",
        "original": null,
        "number": 3,
        "cdate": 1667474431170,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667474431170,
        "tmdate": 1667474431170,
        "tddate": null,
        "forum": "49N06mWPFUm",
        "replyto": "49N06mWPFUm",
        "invitation": "ICLR.cc/2023/Conference/Paper5280/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied adaptive content-dependent online influence maximization where the seed nodes are sequentially activated based on real-time feedback. The authors formulated the problem as an infinite-horizon discount MDP and proposed a model-based RL algorithm that only requires node-level feedback. They proved the first sublinear regret bound for the adaptive content-dependent online influence maximization problem and validated the effectiveness of the algorithm on both synthetic and real-world data.",
            "strength_and_weaknesses": "Strength\n1. This paper is the first to study the adaptive online influence maximization (OIM) problem, which is an interesting direction motivated by the recent advances in offline adaptive influence maximization.\n2. The infinite-horizon discount MDP formulation of the adaptive OIM problem is reasonable.\n3. The authors designed a model-based RL algorithm that only requires node-level feedback, while most previous works rely on edge-level feedback. They also proved the theoretical regret bound of the algorithm, which is the first sublinear regret bound for online adaptive influence maximization.\n\nWeaknesses\n1. The Bernoulli Independent Cascade Model relies on Assumption 3. However, IMHO, this assumption is relatively strong: it suggests that with larger $N$ and $K$, the A values should be smaller. This may not be reasonable in practice since the \u201cinfluence\u201d between two users should not be affected by the total number of users or contents.\n2. In the infinite-horizon discounted MDP formulation, the action at each timestep is to activate just one user-content pair; it would be more interesting to consider the action of multiple user-content pairs per timestep.\n3. I\u2019m a bit concerned about how to obtain the user feature $x$ and content feature $\\theta$ for real-world OIM problems.\n4. In the problem formulation, the authors argue they focus on the asymptotic regime of large networks where $T<<N$, while in the explements, $T$ and $N$ are close (e.g., N=300, T=1000 in Fig. 1).\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is generally easy to follow. It might be better to have more discussion on the regret results in Theorem 2 and 3. ",
            "summary_of_the_review": "This paper studied a new adaptive online influence maximization problem and provided an RL algorithm with theoretical regret bound. My main concerns are Assumption 3 for the Bernoulli Independent Cascade Model and the availability of user and content features in real problems. Also, the social networks considered in the experiments are relatively small (~2000 nodes).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_o5dv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5280/Reviewer_o5dv"
        ]
    }
]