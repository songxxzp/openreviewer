[
    {
        "id": "l4LiBF9GFV",
        "original": null,
        "number": 1,
        "cdate": 1666361785638,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666361785638,
        "tmdate": 1669205209294,
        "tddate": null,
        "forum": "okwxL_c4x84",
        "replyto": "okwxL_c4x84",
        "invitation": "ICLR.cc/2023/Conference/Paper1825/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper addresses the problem of modelling a PDE in the means of neural networks. The main motivation stems from the fact that Clifford algebras is a very popular tool in modelling physical relationships. As a consequence, the paper proposes to use the product of the algebra (instead of the products of a scalar field) to define both, convolutions and FT (Fourier transforms).\n\nWith these basic operations at hand, solutions to both, Navier-Stokes and Maxwell equations are explored. To this end, standard neural networks like ResNet and FNOs (Fourier Neural Operator Networks) are used and convolutions resp. FT are replaced with the Clifford counterpart.",
            "strength_and_weaknesses": "Strength:\n+ Every details of the Clifford algebra as well as the two new operations (C-convolutions and C-FT) is explained extensively\n+ The conducted experiments are based on well-known architecture where only the basic operations are replaced\n+ The experiments focus on physical problems, which is the motivation for these new operations\n\nWeakness:\n- For the experiments it is not clear how the data is generated. Thus, results are difficult to reproduce.\n- Section 2 takes 2 pages to explain well-known facts about Clifford algebras. This could be explained in a more compact manner.\n- The paper including appendices is too excessive with more than 55 pages. It appears a bit too long for a conference paper",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. As some point it goes a bit too much into details that might a) not be too interesting to the ICLR audience, b) not very new for people who are aware about the concepts of Clifford algebras.\n\nTo my knowledge, using the multiplicative part of Clifford algebras is rather new to the community. Nonetheless, it is important to note that the complex numbers can be seen as a special case of a Clifford algebra ($\\mathbb{C}=Cl_{1,0}$). And complex neural networks have been explored, especially for the physical motivated application of radar perception. This fact is missing in the manuscript.\n\nI have some concerns w.r.t. the reproducibility about the experiments, since the used datasets are not mentioned.",
            "summary_of_the_review": "Overall, I consider the idea behind the paper very nice and I think the concept of Clifford neural networks should be presented to the machine learning community. ~Due to the missing datasets, I consider the paper below the acceptance threshold. If the authors can provide the datasets for the final version, I would raise my vote to an acceptance vote.~\n\nEdit: Since the data set will be provided, I am happy to raise my vote to an acceptance vote.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_S1uq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_S1uq"
        ]
    },
    {
        "id": "f4Zc0W0u9vd",
        "original": null,
        "number": 2,
        "cdate": 1666412437850,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666412437850,
        "tmdate": 1666412437850,
        "tddate": null,
        "forum": "okwxL_c4x84",
        "replyto": "okwxL_c4x84",
        "invitation": "ICLR.cc/2023/Conference/Paper1825/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces Clifford neural layers for both convolution and Fourier operations in the context of deep learning. The main motivation is that Clifford algebras can describe the algebraic property (e.g. multiplication, addition) of multivector fields consisting scalar, vector, as well as higher-order components. The resulting Clifford neural layers are universally applicable, and the authors explore their usage in neural PDE surrogate models (for solving 2D Navier-Stokes and 3D Maxwell's equations). By replacing convolution and Fourier operations in common neural PDE surrogates by their Cliffold couterparts, the authors show that Clifford neural layers consistently improves their performance. ",
            "strength_and_weaknesses": "Strengths:\n\n- The proposed Clifford neural layers are novel and technically solid. Based on the observation that different fields in PDE are often related, the authors propose to leverage Clifford algebras to naturally incorporate this inductive bias into neural PDE surrogate models. As far as I know, this is the first time that people introduces Clifford algebras to neural PDE modeling.\n- The experiment results look promising.  Through experiments in three different settings, Cliffod neural layers bring consistent improvement compared to their standard counterparts. This is promising for an first attempt of this type.\n\nWeaknesses:\n\n- Some experimental results need further explanations or investigations. For example, I noticed that in Figure 7 ResNet based results, CResNet gives larger error than ResNet for low numbers of trajectories. This is different from 2D Navier-Stokes (Figure 6). It also contradicts with the claim in Sec. 5 (\"the performance gap increased with less data availability across all settings\"). Any explanation for this particular result.\n- For 3D Maxwell's equations, the paper only shows the results for FNO based architectures. There is no explanation why ResNet based architectures are note tested here. If possible, I think it's better to include them for completeness.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is clear and the provided Clifford algebras background is very helpful. The proposed approach is novel. Experiments are well conducted and the results look very promising. Overall the quality is very good.",
            "summary_of_the_review": "The proposed Clifford neural layers is a novel and solid technical contribution. The results look promising for the first attempt of this kind. Though there are some obvious limitations (e.g., slow runtime), they are potentially solvable. Therefore, I recommend for acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_ugoG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_ugoG"
        ]
    },
    {
        "id": "hDMfF6N7Xe",
        "original": null,
        "number": 3,
        "cdate": 1666558415380,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666558415380,
        "tmdate": 1666558415380,
        "tddate": null,
        "forum": "okwxL_c4x84",
        "replyto": "okwxL_c4x84",
        "invitation": "ICLR.cc/2023/Conference/Paper1825/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new architecture for Neural PDEs based on Clifford algebra. By incorporating fields with different dimensions together into one algebra system, the method yields better results when used in neural networks due to better coupling among the data.",
            "strength_and_weaknesses": "Strengths:\n1. The theory is comprehensive and self-contained. The results are promising and supportive.\n\nWeakness:\n1. In Fig. 7, it is not discussed why CResNet works worse than ResNet in some of the experiments. Please add some analysis here.\n2. Clifford algebra seems to be general and can potentially be applied to more than Neural PDE, as long as there are inputs of multiple data types. It would be great if the author can provide more insight into other applicable scenarios and future directions to achieve this.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "It is a very comprehensive and self-supportive paper. I would recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_TyjS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_TyjS"
        ]
    },
    {
        "id": "DMa-p7OjR2n",
        "original": null,
        "number": 4,
        "cdate": 1666618990904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618990904,
        "tmdate": 1666679882739,
        "tddate": null,
        "forum": "okwxL_c4x84",
        "replyto": "okwxL_c4x84",
        "invitation": "ICLR.cc/2023/Conference/Paper1825/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper the authors present Clifford neural layers that can be useful in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general.  The author emipirically validate the use of Cifford layer by incorporating them in the common neural PDE surrogates for 2D Navier-Stokes, weather modeling, and 3D Maxwell equations. ",
            "strength_and_weaknesses": "The main strenghts of the paper are:\n\n1) The paper is well-written and the main ideas are effectively presented.\n2) The background section covers the pre-requisite knowledge required to understand the clifford neural layers\n3) A novel method is proposed in this paper which can be useful in the Physical science domain\n\n\nThe main weaknesses of the paper in my opinion are:\n1) As someone who does not work in the Physical sciences I could not get much information about the datasets used from the paper. I am not sure what the training sets are for these dataset and hence can't make an informed judgement on the quality of the method. [I did not go through the supplementary material in any detail ]\n2) The baseline information is not very clear form the paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the main method is effectivley presented\nSome information about the experiement section is missing \nThe codes are not provided with the paper.",
            "summary_of_the_review": "The paper present clifford layer which can be used for application in Physical sciences. The method is tested on three datasets and the results look promising. The experiment section is missing some details which makes it a bit difficult for non-experts to read.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_EJCG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1825/Reviewer_EJCG"
        ]
    }
]