[
    {
        "id": "gQTQlyEUS3",
        "original": null,
        "number": 1,
        "cdate": 1666373461500,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666373461500,
        "tmdate": 1669996372906,
        "tddate": null,
        "forum": "yC8PKpNl4f",
        "replyto": "yC8PKpNl4f",
        "invitation": "ICLR.cc/2023/Conference/Paper3367/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new neural network architecture for the inverse folding problem (protein structure -> sequence) and develops a new benchmarking setup that the authors recommend for future work in the field. The new benchmark improves on prior practices by formalizing a train-validation-test split and by providing more diversity of proteins. The empirical performance of the proposed model is strong relative to prior work.",
            "strength_and_weaknesses": "=Strengths=\nInteresting/relevant application\nStrong empirical results\nEstablishes a benchmarking dataset to be used in future papers.\nUseful ablations to identify the impact of various aspects of the proposed method.\n\n=Weakness=\nI have a few key hesitations around the comparison to recent work, how the dataset was constructed, etc. See my extended comments below.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and approachable.\n\nOne of the missions of the paper is to provide a new dataset and train-test split for benchmark that will result in better reproducible research in the future. \n\nThe overall modeling approach leverages standard techniques from modern deep learning, but the empirical results are strong.",
            "summary_of_the_review": "I appreciate that the paper works to introduce a new benchmarking setup. This kind of work can be under-appreciated and is important to drive progress in the field. I also appreciate that the performance of the proposed method is strong.\n\nI have some key questions below:\n\nThe benchmark is based on a fairly old version of AlphaFoldDB. The current database contains ~200M structures. Using this would allow you to perhaps have a more diverse test set and to guarantee a bigger distance between the train and test sets. Why did you use an old version of the database?\n\nI don't understand why the results are stratified by organism. How does this improve the analysis? Homologous proteins will be fairly similar across different organisms. If you were to stratify, why not stratify by type of molecular function? \n\nAlso, when you constructed the clustering-based train-test split, did you cluster proteins from multiple organisms, or did you do clustering independently for each organism? \n\nI'm concerned that the paper does not benchmark against recently published papers on this topic. The paper cites the ESM-IF paper, for example, but explains that no benchmarking was performed because the work was in parallel and code has not been released. However, the paper was accepted at a prior ML conference (ICML 2022) and the code was released [1] about 4 months ago. Can you elaborate on why you do not consider the method? Is the challenge that ESM-IF would need to be retrained because you use a different train-test split?\n[https://github.com/facebookresearch/esm/tree/main/examples/inverse_folding]\n\nOne challenge of introducing a new benchmark dataset is that you have to re-run baseline methods. What protocols did you use, for example, when adapting GraphTrans, etc. to the new data? Did you re-tune any hyper-parameters?\n\n\n==Update after authors' response==\nI have raised my score to weak accept. My concern around technical correctness (the per-organism train-test split) has been adequately clarified. I wish the paper used the full AlphaFoldDB, but it would not be fair to penalize this paper when the AlphaFoldDB was updated not long before the ICLR deadline. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_QZ9p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_QZ9p"
        ]
    },
    {
        "id": "mXcLeI2U-h",
        "original": null,
        "number": 2,
        "cdate": 1666457084919,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666457084919,
        "tmdate": 1666457084919,
        "tddate": null,
        "forum": "yC8PKpNl4f",
        "replyto": "yC8PKpNl4f",
        "invitation": "ICLR.cc/2023/Conference/Paper3367/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "- The paper establishes a new benchmark on fixed backbone protein design using AlphaFold DB\n- Authors introduce a new model based on a simplified graph transformer encoder and a constraint aware decoder\n- This model achieves good results in comparison to a large number of baseline models using GVP or graph transformer.",
            "strength_and_weaknesses": "Strengths:\n- AlphaDesign's model is interesting, and does seem much faster than decoding autoregressively, especially on long sequences.\n- The paper comprehensively tests a variety of different models, showing that AlphaDesign produces good designs across species.\n\nWeaknesses:\n- The new dataset is unsound, it presumes that AlphaFoldDB is producing ground truth structures that can be used as a validation set. I recommend authors make an argument that switching to alphafold structures has no impact on design of natural proteins, otherwise it would be akin to testing on a synthetic dataset that might not transfer to real protein data.\n- It seems unreasonable not to include _any_ natural proteins in this work.\n- There's no validation set used, which means models may be overfitting on the test set, especially if the authors did more tuning on their model than the baselines.\n- The dataset is not held out in a structural manner. In Hsu et al, 2022; Ingraham et al., 2019; Jing et al., 2021b; Strokach et al., 2020, they all use CATH based topology splits to ensure that the result holds up across new topologies. One way to do this might be to use TMscore to do clustering of training / test sets.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear, but several concurrent works seem to apply a similar idea.",
            "summary_of_the_review": "The paper does not use current best practices for data splits, and also trains/tests on a synthetic database without showing that there's no domain shift issues. Additionally, many ideas have been implemented in concurrent work. Therefore, I recommend a reject rating for this work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_MXiS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_MXiS"
        ]
    },
    {
        "id": "LitXLxTrXg",
        "original": null,
        "number": 3,
        "cdate": 1666594136760,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594136760,
        "tmdate": 1666594136760,
        "tddate": null,
        "forum": "yC8PKpNl4f",
        "replyto": "yC8PKpNl4f",
        "invitation": "ICLR.cc/2023/Conference/Paper3367/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper establishes a new benchmark based on AlphaFold DB, one of the world\u2019s largest protein structure databases. Moreover, the authors propose a new baseline method called AlphaDesign, which achieves 5% higher recovery than previous methods and about 70 times inference speed-up in designing long protein sequences. The authors also reveal AlphaDesign\u2019s potential for practical protein design tasks, where the designed proteins achieve good structural compatibility with native structures.",
            "strength_and_weaknesses": "Pros: \n1. The motivation is clear. \n2. The paper is well-written and organized. \nCons: \n1. The main contributions are not clear. \n2. Some related works are missing, e.g., Multi-Human Parsing With a Graph-based Generative Adversarial Model.",
            "clarity,_quality,_novelty_and_reproducibility": "See Strength And Weaknesses.",
            "summary_of_the_review": "See Strength And Weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_dT5A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_dT5A"
        ]
    },
    {
        "id": "7K0PO_OUR2T",
        "original": null,
        "number": 4,
        "cdate": 1666640670597,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666640670597,
        "tmdate": 1670680708896,
        "tddate": null,
        "forum": "yC8PKpNl4f",
        "replyto": "yC8PKpNl4f",
        "invitation": "ICLR.cc/2023/Conference/Paper3367/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The manuscript introduces a new method for protein design (inverse folding) and a benchmark consisting of a curated set of structures from the AlphaFold Database. The authors demonstrate a substantial improvement compared to a selection of earlier methods.",
            "strength_and_weaknesses": "The paper makes good use of the recently released AlphaFold Database of protein structures, both by training a new model on these available structures, and by curating the database into a dataset which can be used as a standard for future work. Method-wise, the contribution is limited - the authors build on components from earlier work, adding three new angle features and a new decoder. However, the results are convincing and the method is therefore likely to have an impact.\n\nOverall, the paper is clearly structured. However, parts of the paper seem hastily written and in particular parts of the Methods section are not clearly explained. See detailed comments below.\n",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nGenerally, the paper is well-structured, with clear illustrations. However, the method section shows signs of being hastily written, and would benefit from some editing (see detailed comments below).\n\n## Quality\nThe work seems well thought through and executed. The manuscript could use a bit more polishing and perhaps a supporting information  appendix with some extra details about the method.\n\n## Reproducibility\nThe manuscript stresses the importance of open source and promises to provide source code when released. It also includes a benchmark with the goal of improving reproducibility in the field. I therefore trust that the results of this paper should be readily reproducible.\n\n## Detailed comments\nTitle. The title suggests that this project originates from DeepMind, following their naming style. If this paper is by another group, I would suggest that the authors change the name, to avoid confusion between AlphaFold and AlphaDesign. Especially since the proposed procedure does not seem to be methodologically related to AlphaFold in any way - other than using the structures provided by Alphafold for training.\n\nPage 1. \"may have overlooked some important protein features\" and \"few of them exceeds 50% accuracy\". These are odd statement to make in an introduction about existing work if you do not identify which features you think are missing, and you haven't yet introduced which task you are considering (50% accuracy of what?). Both things become clearer later in the paper, but I would recommend removing these statements here.\n\nPage 2. \"length-free\" (also used several other places)\nLength-free is an odd term, suggesting that the proteins have no length. Consider rephrasing to something like \"arbitrary lengths\".\n\nPage 2. Related work.\nThe authors seem to have missed some of the earlier CNN work on inverse folding:\nhttps://pubmed.ncbi.nlm.nih.gov/28615003/\n\nhttps://proceedings.neurips.cc/paper/2017/hash/1113d7a76ffceca1bb350bfe145467c6-Abstract.html\nhttps://proceedings.neurips.cc/paper/2018/hash/488e4104520c6aab692863cc1dba45af-Abstract.html\n\nPage 2. \"Sovlent-accessible\" -> \"Solvent accessible\"\n\nPage 3. \"none of the above 3D CNN models is open-source\"\nSeveral of the papers linked to above provide source code.\n\nFigure 1:\nThe figure says \"Constraint-aware Protein Decoder\" while the caption says \"confidence-aware\" protein decoder. Is this a mistake?\n\nFigure 4: \"remains exploring\"\nRephrase. E.g. \u201cis an open research question.\u201d or \u201cis subject to further research\u201d.\n\nFigure 5. Section 3.3\nThis section is not very clear. Some examples:\n1. The \"Confidence Predictor\" in Figure 4 takes a feature vector as input, while the \"Conf\" function in eq 3 takes a structure X as input. Are these different functions? I guess so, since Conf(.) is thereafter explained as \"the model containing graph encoder and CNN decoder\" - but this should be stated more clearly. \n2. It is stated that f(.) computes confidence scores, but not what input it takes. I assume z?\n3. \\hat a is used without being defined.\n4. There is a very odd footnote, which should be integrated into the main text.\n5. \"By extending \\hat a as a\" Eq (5)\". It is not clear what \"extending\" means - and Equation 5 does not seem to exist.\n\nAs a result, it is unclear how this part of the model works. Since this is the main methodological contribution of the paper, the authors should rewrite and expand this section (if space is an issue, perhaps in supporting information).\n\nPage 6\n\"systemical\" -> \"systematic\"\n\nPage 6. \"This dataset provide well-organized proteomic data\".\nThe term \"proteomics\" is usually used to describe large-scale studies of proteomes. It is therefore a bit confusing when you use it here to describe the AlphaFold protein structure database. I would recommend choosing a different term (you use it several places further down in the manuscript as well).\n\nPage 6. \"each proteomic data\" x2\nDo you mean species-specific subsets here? Again, \"proteomic\" is confusing (see above).\n\nPage 7. \"Length-free\"x2. Rephrase\n\nPage 7. \"each proteomic data\". Rephrase\n\nTable 2. Caption. Do you mean \"next best\" when you write \"suboptimal\"? Considering rephrasing.\n\nPage 9. Visual examples. It is not entirely clear what the relevance is of this test. Are you testing AlphaFold or AlphaDesign with this test - or their internal consistency? ",
            "summary_of_the_review": "The paper presents a new method for inverse folding.  The main strength of the paper lies in the reported results, which look very competitive - and in the fact than the authors provide a new benchmark to the community. The manuscript does not contain a substantial methodological contribution, and the part that is new is currently not described very clearly in the paper. However, based on the results I expect the paper could have an impact on the community. If the authors improve the clarity of the paper by addressing the concerns described in the detailed comments above, I would therefore be willing to increase my score.\n\n---UPDATE---\nThe authors have improved the clarity of the paper as requested, and I have therefore increased my score to 6: marginally above the acceptance threshold.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_QTBS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3367/Reviewer_QTBS"
        ]
    }
]