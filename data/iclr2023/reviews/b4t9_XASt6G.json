[
    {
        "id": "Nk2njK9oKCF",
        "original": null,
        "number": 1,
        "cdate": 1666643816326,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643816326,
        "tmdate": 1666643816326,
        "tddate": null,
        "forum": "b4t9_XASt6G",
        "replyto": "b4t9_XASt6G",
        "invitation": "ICLR.cc/2023/Conference/Paper816/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for doing word segmentation in emergent languages derived during a one-way signaling game. The method is based on Harris\u2019s articulation scheme, and involves tracking a branching entropy term for a rapid rise. The method is light-weight and can be derived from simple surface (n-gram) statistics, and has been used in a series of previous word segmentation papers. Perhaps more importantly, the authors propose a set of criteria (C1-C3 in Section 4) to determine whether meaningful word-like units have been discovered. This is nothing specific to the Harris articulation scheme in these criteria, and they could likely be used to assess other segmentation methods or other communication-game learning methods for meaningful words. The conclusion of evaluating the proposed method with these criteria is that the preconditions for this method have been met, but there is as of yet no evidence that meaningful units have been discovered.",
            "strength_and_weaknesses": "Strengths:\n\nThis is a very careful, thorough paper. Everything is carefully defined and described. It is dense, but ultimately easy to follow.\n\nThis paper has two paths to influence: one by reminding the community of this method and applying it to emergent languages, and one by defining criteria that can be used to assess the meaningfulness of word-like units discovered in emergent languages.\n\nThe inclusion of an assessment of a synthetic language in Appendix A is a really nice touch, and greatly strengthens the paper, providing confidence that the conditions do indeed work for languages that verifiably have meaningful words.\n\nWeaknesses:\n\nIt is unclear to me how important word formation is in current studies of emergent languages. As the authors themselves point out, most previous work implicitly assumes one-character-per-word. \n\nAs this appears to be the first paper to dive into word formation, it would be interesting to talk about the ramifications of some of the changes they\u2019ve made to the set-up. Did forcing multiple-character representations reduce the success rate or the scores of successful systems? Are there any downsides to using fixed-length messages when hoping for meaningful words? I.E. Couldn\u2019t the system then assign meanings to certain characters in certain positions? The paper mentions only experimental benefits of fixed-length messages.\n\nThe work is very specific to this particular technique. It has the feel of an author dusting off a favorite tool and aiming it at a new problem. I worry that this will cap the amount of interest this paper can draw from the emergent language community. In my review, I have tried to emphasize the portions of the paper that apply to any segmentation scheme. I think it would benefit the paper for the authors to do the same.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality:\n\nAs mentioned above, this is careful work. I see no problems with the math, the notation, the experimental design or the results. \n\nClarity:\n\nThe paper is dense but ultimately easy enough to follow. I found one typo: in the first sentence of the introduction, \u201cHAS-baseThisboundary detection algorithm.\u201d\n\nOne change that could improve clarity would be, for the assessment of synthetic languages in Appendix A, to present the data using the same Figures used to assess C1-C3 (Figures 5-8) in Section 6.3. This way we could contrast what a successful experiment results would look like against a negative result.\n\nOriginality:\n\nIn terms of technical contribution, this is a simple application of a known unsupervised word segmentation technique to a known problem. That combination is novel, though, and the method is relatively obscure and this paper serves as an excellent re-introduction to it. As mentioned above, we should also consider the assessment criteria C1-C3 to be novel and useful when assessing meaningful word formation in emergent languages.",
            "summary_of_the_review": "This paper feels a little niche, both in that I do not have a strong notion whether the word formation problem is an important one in emergent languages at this point, nor do I know whether this proposed technique is the best approach for finding word boundaries if they do exist. Regardless of the nicheness of the problem, the paper is well-written, and builds a strong evaluation framework for other groups to use, validating that framework with a synthetic language in Appendix A. The authors use this framework to draw the conclusion that for this configuration of the signaling game, no meaningful units are emerging, which definitely raises some interesting questions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper816/Reviewer_XTS9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper816/Reviewer_XTS9"
        ]
    },
    {
        "id": "5EhNet9YQ8",
        "original": null,
        "number": 2,
        "cdate": 1666646319499,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646319499,
        "tmdate": 1669887434992,
        "tddate": null,
        "forum": "b4t9_XASt6G",
        "replyto": "b4t9_XASt6G",
        "invitation": "ICLR.cc/2023/Conference/Paper816/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper investigates word boundaries in the context of emergent languages. The hypothesis is that if we want emergent languages to follow properties of natural languages like compositionality, they should have meaningful word boundaries as defined by Harris Articulation Scheme. The authors propose derived tests to check whether a given emergent language possess this property. They show that factors encouraging compositionality in emergent languages do not correlate with languages having this property.",
            "strength_and_weaknesses": "The paper proposes a new research direction/benchmark for emergent languages to be as close to natural language. The direction is indeed interesting and important for the research on emergent languages as the main goal is to achieve human interpretable languages.\n\nHowever, the analysis done in the paper is more quite limited to come to a definite conclusion. The only environment chosen to perform the tests is the reconstruction game which basically just emulates the encoder-decoder setup. I would encourage the authors to carry out similar tests for referential games and other derived games that have been used in emergent communication literature.",
            "clarity,_quality,_novelty_and_reproducibility": "The main contribution is about the Boundary Detection algorithm which makes use of conditional entropy to check for word boundaries. As I recall, one previous work [1] has done a similar study on using residual entropy for evaluating compositionality in emergent languages. There are no comparisons to this metric and how the proposed method add anything novel on top of this work.\n\nBesides does the hypothesis still hold when using visual / multimodal inputs [2] that propose different factors for compositional emergent languages?\n\n[1] Gupta et al. 2020. Compositionality and Capacity in Emergent Languages.\n\n[2] Choi et al. 2018. Compositional obverter communication learning from raw visual input.\n",
            "summary_of_the_review": "The paper is still a work in progress and I would encourage the authors to bolster their claims by adding diverse experiments and a more thorough literature survey adding comparisons with prior work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper816/Reviewer_PmT4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper816/Reviewer_PmT4"
        ]
    },
    {
        "id": "pg_5jbOVgU",
        "original": null,
        "number": 3,
        "cdate": 1666672905111,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672905111,
        "tmdate": 1669245145380,
        "tddate": null,
        "forum": "b4t9_XASt6G",
        "replyto": "b4t9_XASt6G",
        "invitation": "ICLR.cc/2023/Conference/Paper816/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper analyzes the articulation structure that could emerge in emergent language. The paper follows the studies of deep learning-based emergent communication models, which have been studied for half of the decade. In particular, the study adopts the framework of Chaabouni et al. (2020).\nThe authors tested if they satisfied HAS. HAS states that word boundaries can be obtained solely from phonemes in natural language. We adopted  HAS-based word segmentation and verified whether emergent languages have meaningful word segments. The experiment suggested they do not have. They found that the current emergent language model is still missing some necessary ingredients.\n",
            "strength_and_weaknesses": "Strength\n+ The paper clearly shows that articulation structure, HAS, does not emerge in the sense of entropy-based measure in a type of emergent communication  \n+ The paper provides an interesting suggestion about the limitation of the current emergent communication model.\n\nWeakness\n- The paper did not discover the reason why the current emergent communication model does not make HAS emerge.\n- Apparently, the property depends on the implicit definition of language models that are used in emergent communication models. This analysis is just about a type of emergent communication model and architecture.\n\n\n\nAlso, regarding word segmentation, the authors have mentioned HAS and Tanaka-Ishii studies. However, statistical models for word segmentations have made progress. The author refers to such studies. Also, even simultaneous phone and word discovery statistical models have been proposed.\n\n[Word discovery]\n[1] S. Goldwater, T. L. Griffiths, and M. Johnson, \"A Bayesian framework for word segmentation: Exploring the effects of context,\" Cognition, vol. 112, no. 1, pp. 21\u201354, Jul. 2009. \n[2] D. Mochihashi, T. Yamada, and N. Ueda, \"Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling,\" in Proc. Joint Conf. 47th Annu. Meeting ACL 4th Int. Joint Conf. Nat. Lang. Process. AFNLP (ACL-IJCNLP), Singapore, 2009, pp. 100\u2013108\n\n[Phone and word discovery]\n[3] Tadahiro Taniguchi, Shogo Nagasaka, Ryo Nakashima, Nonparametric Bayesian Double Articulation Analyzer for Direct Language Acquisition from Continuous Speech Signals, IEEE Transactions on Cognitive and Developmental Systems, Vol.8 (3), pp. 171-185 .(2016) DOI: 10.1109/TCDS.2016.2550591 (Open Access) \n\nYou may be interested in word segmentation with co-occuerence cues in relation to \"meaningful\" segments.\n[4] Tomoaki Nakamura, Takayuki Nagai, Kotaro Funakoshi, Shogo Nagasaka, Tadahiro Taniguchi and Naoto Iwahashi, Mutual Learning of an Object Concept and Language Model Based on MLDA and NPYLM, 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'14), 2014\n\nAs mentioned above, the phenomenon of the emergence of word segments depends on the implicitly designed language model, i.e., GRU in this model. Therefore, it is essential to clarify this point in the discussion of the general nature of the possibility of the emergence of articulation structure.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper's quality and clarity are satisfactory and provide interesting insight. The finding is worth sharing in the community of emergent communication. Reproducibility is also acceptable. However, the novelty is questionable.\n\n",
            "summary_of_the_review": "\nThis paper analyzes the articulation structure that could emerge in emergent language. The paper clearly shows that articulation structure, HAS, does not emerge in the sense of entropy-based measure in a type of emergent communication. However, because of the lack of theoretical insight of the architecture of emergent communication, the value of the obtained insight is limited to the model they adopted. It means this is a kind of \"case study.\" As a result, I am not sure if the paper contains a sufficient contribution to appear as an ICLR paper. \n\n\n[Update] Considering the authors' revision, I have updated my score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper816/Reviewer_nRa3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper816/Reviewer_nRa3"
        ]
    },
    {
        "id": "QCoBNZEm-pV",
        "original": null,
        "number": 4,
        "cdate": 1666683990632,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666683990632,
        "tmdate": 1666683990632,
        "tddate": null,
        "forum": "b4t9_XASt6G",
        "replyto": "b4t9_XASt6G",
        "invitation": "ICLR.cc/2023/Conference/Paper816/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "\nThis paper studies the languages that emerge between two agents that solve a task collaboratively. The main focus of the paper is on studying whether Harris\u2019 articulation scheme (HAS) holds in the emergent languages. To test for that, the authors resort to an unsupervised segmentation algorithm derived from HAS. At its foundation, this algorithm compares the branching entropy before and at a position; it is assumed that at boundaries it starts growing.\n\nNext, the problem of testing whether HAS holds is reduced to testing whether (Q1) Conditional entropy of the next symbol given the prefix is decreasing, (Q2) Branching entropy increases and decreases, (Q3) Derived boundaries are \u201cmeaningful\u201d. (Q3) is further split into testing if the boundaries behave as expected when the number of attributes and values are changed.\n\nThe experimental study is performed using a standard setup where the sender agent receives a n_attr x n_val dimensional vector encoding a point in an attribute-value space with n_attr attributes each having n_val values. The sender then sends a multi-symbol message to the receiver agent which has to recover the original vector. Both agents receive a reward.\n\nThe experiments show mixed outcomes: (Q1) and (Q2) are indeed observed while the authors find the boundaries do not have the expected properties w.r.t. changing the number of attributes and values. Finally, the paper studies the relation between the Ease-of-Teaching and HAS and whether \u201cwords\u201d obtained under segmentation follow ZLA.\n",
            "strength_and_weaknesses": "Strengths:\n* I believe the paper brings an interesting toolset to the topic of analyzing emergent languages\n* The experimental study is convincing\n\nWeaknesses:\n* Motivation: We already have a strong understanding that human language-like, interpretable features (ZLA, compositionality) often do not emerge by themselves in emergent languages. For now, looking at HAS is motivated as yet \u201canother direction\u201d to study emergent languages. I think the paper could benefit from highlighting why it is particularly worth studying. Furthermore, If HAS is important, can we take the findings of the paper and find a way to enforce it?\n* In my view, the search for \u201cword\u201d boundaries seems to be closely related to the search of compositionality, i.e. whether there are elementary units within messages with a fixed \u201cmeaning\u201d  (Chaabouni et al., 2020). I believe the text could benefit from contrasting those pursuits. For instance, if compositionality in the sense of (Chaabouni et al., 2020) is achieved, would word boundaries become meaningful? or vice-versa? \n* Further, as formulated, the word boundaries segment the messages into groups of adjacent tokens (ie. the 2nd token cannot be grouped with the 4th token w/o being grouped with the 3rd token). Is there an intuition why this should hold for the artificial agents? As far as I understand, any successful language can be modified by a fixed permutation of positions w/o sacrificing its expressiveness. For instance, the compositionality metrics of (Chaabouni et al., 2020) are specifically made permutation-invariant wrt positions to reflect this. Moreover, whether adjacent tokens tend to be related is likely architecture-dependent, e.g. while this might hold for LSTM and GRU cells which have \u201crecency\u201d bias, it most likely not hold for Transformers which are permutation invariant (modulo positional embeddings). \n* Eq (3) does not include conditional entropy. Do we need it monotonically decreasing (Q1) for HAS to hold?\n* The paper shows that the word boundaries do not behave as one would expect and thus concludes that they are not \u201cmeaningful\u201d. I wonder if it makes sense to check if, among the studied languages, there are individual words that encode specific attributes or values?\n* Minor:\n   * Typo: S2.2, first para: \u201cHAS-baseThisboundary\u201d ->  \u201cHAS-base. This boundary\u201d\n   * I believe the text does not specify what kind of reward the agents get. Is it cross-entropy of the receiver\u2019s output?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: I find that the text is generally clear;\n* Novelty: I believe the topic of the study is largely novel, however, I would appreciate if authors could better differentiate it from the body of research on compositionality of the emergent languages;\n* Reproducibility: while the authors do not mention if the code for the experiments is going to be released, it is largely based on a public codebase.\n",
            "summary_of_the_review": "Generally a clear paper with interesting experiments. My main comments can be summarized as:\n* At this stage it is obvious that emergent languages are far from human languages from many points of view. Why is finding this particular difference useful?\n* How studying word segmentation differentiates from studying compositionality of the emergent languages?\n* Segmentation assumes that \u201cwords\u201d are composed of adjacent tokens. Is it a natural assumption for the communication between artificial agents?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper816/Reviewer_zwe8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper816/Reviewer_zwe8"
        ]
    },
    {
        "id": "2Ch0km1KbK",
        "original": null,
        "number": 5,
        "cdate": 1666696291970,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696291970,
        "tmdate": 1668434509590,
        "tddate": null,
        "forum": "b4t9_XASt6G",
        "replyto": "b4t9_XASt6G",
        "invitation": "ICLR.cc/2023/Conference/Paper816/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Zellig Harrs's articulation scheme (HAS) is an unsupervised method of discovering word segmentation based on the statistics of sub-word units in natural language.\nThis paper takes uses HAS on emergent language to determine whether the statistical properties of sub-word units in emergent language behave similarly to natural language.\nThe experiments show that while some of the low level statistical properties which HAS predicts are present, the evidence for HAS discovering meaningful word boundaries in emergent languages tested is largely negative.\n",
            "strength_and_weaknesses": "### Strengths\n- [major] Unsupervised word boundary detection is genuinely useful to studying the structures of emergent language and has not been tackled before.\n- [major] The hypotheses and corresponding experiments are clear and effective.\n- [major] This paper applies a concept from linguistics to emergent language in a fitting and relevant way.\n- [minor] The empirical results of the experiments are informative vis-a-vis the hypotheses, although the results are not definitive or earth-shattering.\n### Weaknesses\n- [minor] No quantitative measure of branching entropy falling and rising\n- [minor] Tough to put the empirical results in perspective due to lack of natural language/random language baseline or ablation study.\n  Appendix A addresses this from one angle and helps make this a only a minor weakness.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n- The paper is well-organized and easy to follow.\n  - The hypotheses are clearly stated such that they are falsifiable with a straightforward experiment.\n    This is tough to find in emergent language papers.\n- Although the pseudocode of Algorithm 1 is clear, the behavior is not entirely intuitive, so some sort of diagram or step-by-step example (even in the appendix) would be helpful.\n- Section 2.1 mentions that HAS can be applied to non-phoneme sub-word units -- this is important to note early in the paper because I spent the first two pages thinking, \"The components of emergent language messages do not really behave like phonemes nor are they intended to.\"\n  - It would also be good to put the statement that \"it is not even evident, in the first place, whether they have meaningful word segments\" near the beginning.\n    I agree with this statement, and I think its presence early on helps with the framing of the motivation, experiments, and results.\n### Quality\n- Overall, the hypotheses and experiments are very well suited to looking at whether or not HAS applies to (an) emergent language.\n  - The experiments present an informative combination of positive and negative results which also provide a platform for future experimentation.\n- It would be beneficial to have comparisons to HAS applied to natural language as showing that it works is more convincing and informative than just mentioning it.\n  Ideally, we would have human data for an analogous task to the signalling game, but collecting such data is admittedly far beyond the scope of this paper.\n  Instead, it might be helpful enough just to plot HAS performance on natural language in the same way that it is plotted for the emergent language data so as to have a point of comparison.\n  - Along the same lines, ablation studies could also help give the real plots some perspective.\n    This could even be as simple as, \"what does it look like if I apply this analysis to a random language.\"\n- There is no quantitative analysis for Q2 (rising and falling branching entropy) which limits the degree to which the experiments can support the hypothesis.\n- The section on Zipf's law of abbreviation is mildly interesting but does not contribute to the overall paper.\n  It seems more appropriate to put the section in the appendix and use the space for expanding upon previous discussion or just making the paper 0.3 pages shorter.\n### Novelty\n- The HAS algorithm makes minimal assumptions about the input language and relies on information theoretic notions both of which fit in with the constraints of analyzing emergent language.\n- As the field of emergent language becomes more interested in complex structures of emergent language, understanding the nature of word segmentation in the messages of emergent language will become increasingly important.\n- Much of the previous work on compositionality in emergent language treat each component of an emergent language message as its own word.\n  Thus, this paper is novel in its approach of looking at these message components as sub-word units.\n- Overall, this appears to be a natural and successful grounding of emergent language research in linguistic knowledge.\n### Reproducibility\n- The description of the experiments is clear.\n- Since the code is not provided, I cannot comment on its quality or how easy it would be to reproduce directly.\n",
            "summary_of_the_review": "I recommend accepting the paper because it applies a linguistic framework in natural language to emergent language which (1) is genuinely useful to studying the structures of emergent language and (2) is well-suited to the constraints which emergent language presents (e.g., few a prior assumptions of structure, comprising arbitrary symbols).\nThe experiments clearly test the hypotheses, and the empirical results are generally informative.\nThe places where the results do lack do not significantly detract from the aforementioned strengths.\n\n\n### Misc.\n- `2.2`: First sentence of 2.2 needs to be checked for typos.\n- `2.2`: The little interlude about applying HAS-based boundary detection to natural language does not contribute much on its own.\n  It can probably be removed if there is no further discussion of HAS applied to natural language.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper816/Reviewer_BukJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper816/Reviewer_BukJ"
        ]
    }
]