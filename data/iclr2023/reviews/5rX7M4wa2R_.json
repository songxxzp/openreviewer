[
    {
        "id": "GfMOionZVRg",
        "original": null,
        "number": 1,
        "cdate": 1666354761014,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666354761014,
        "tmdate": 1666354761014,
        "tddate": null,
        "forum": "5rX7M4wa2R_",
        "replyto": "5rX7M4wa2R_",
        "invitation": "ICLR.cc/2023/Conference/Paper3738/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper investigates the role of regularization in the explainability of GNNs. They find that regularization pursues a balance between feature attribution and selection as well as that optimal regularization is related to the sparsity of the explanations.",
            "strength_and_weaknesses": "Strength\n======\n\n- The paper introduces GIBE, which is similar to GIB but for GNNs explainability.  To my understanding, this is novel.\n- The authors do a good job at discussing the related literature and putting their work into perspective.\n\nWeakness\n========\n\n- Figures 4 and 5 could definitely be improved by using different line formats and markers to facilitate the task of distinguishing the results.\n- Overall, the proposed methodology in the paper is not easy to digest. In particular, I'm confused about the exact implementation/derivation of the proposed SRS method. Could you elaborate more on the rationale behind it? Is it just a grid search on $\\eta$ and then scaling $\\mathbf{K}$ by the best $\\eta$?\n\nQuestions\n========\n\n- What is the role of $\\alpha$ in Eq (2) given that its optimal solution is independent of it?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is novel to the extent that GIBE is an extension of GIB for explanability of GNNs. However, the manuscript could be significantly improved when it comes to clarity, as for example, the follow up to the proposed Propositions are not as clearly discussed by the authors (see e.g., my question on SRS).",
            "summary_of_the_review": "Overall it's a promising paper, but the clarity/justification of the proposed methodology could be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_SjeN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_SjeN"
        ]
    },
    {
        "id": "R97oT4vhL4",
        "original": null,
        "number": 2,
        "cdate": 1666593081641,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593081641,
        "tmdate": 1666593081641,
        "tddate": null,
        "forum": "5rX7M4wa2R_",
        "replyto": "5rX7M4wa2R_",
        "invitation": "ICLR.cc/2023/Conference/Paper3738/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to investigate the role of regularization used in existing GNN explainers. The paper analyzes the interpretable GNN model proposed by Miao et al. 2022 by rewriting the training objective function and mapping it into two parts, the feature attribution objective and the feature selection objective. And the authors claim to derive some findings about the \"regularization\" in this rewritten objective.",
            "strength_and_weaknesses": "Strength: The topic of this paper, theoretical understanding of GNN explainers, is an important research direction.\n\n\nWeaknesses:\n\n1) The writing of this paper needs to be largely improved. Many essential concepts are not well-defined in the main paper or the appendix. For example, what are the distribution assumptions on the graph data? In section 3.2, \"Treating target GNN f' as the proxy function ...\", what is f'? What is the formal definition of \"regularization\" in GIBE? The technical content is almost unreadable due to missing definitions.\n\n\n2) The paper claims to provide an understanding of the role of regularization for existing GNN explainers. However, the analysis is specific to a particular type of GNN (proposed by Miao et al. 2022) that has a certain interpretable mechanism. It is unclear how the analysis can be transferred to the more commonly used post-hoc explanation methods that can be applied to different types of GNNs.\n\n3) Many typos. For example, \n\n- right before section 3.2, \"... of Equation 2 can be proved to equal to ...\": to be equal to. \n- Many \":\" should be replaced by \",\", e.g., \"... employing Data Processing Inequality (DPI) along the Markov chain**:** ...\". \n- Proposition 2, \"let K_i and K_j is the ...\": let K_i and K_j be the ...\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "As commented above, the clarity of this paper needs to be largely improved. It is difficult to assess the technical soundness due to the lack of clarity. As far as I can tell, the analysis seems to be limited to a specific GNN and cannot be applied to the common post-hoc GNN explainers, which limits the significance of the contribution. ",
            "summary_of_the_review": "Given the lack of clarity and the limited scope of analysis, I'm inclined to reject this paper as the problems are unlikely to be addressed during the author response period.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_eWP9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_eWP9"
        ]
    },
    {
        "id": "57vCNfafpS",
        "original": null,
        "number": 3,
        "cdate": 1666675457552,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675457552,
        "tmdate": 1666680806366,
        "tddate": null,
        "forum": "5rX7M4wa2R_",
        "replyto": "5rX7M4wa2R_",
        "invitation": "ICLR.cc/2023/Conference/Paper3738/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies GNNs' explainability from the perspective of graph information bottleneck (GIB). The authors first provide justification on why most existing methods are essentially studying the tradeoff between attribution and selection by modeling them as GIB questions. Based on this observation, the authors discuss the relationship between regularizing the selection in sparsity, stochastic attention and out-of-distribution (OOD) issue, and propose the SRS and ORS scheme. Experimental results demonstrate that the proposed SRS and ORS improves the fidelity and accuracy of the proposed method.",
            "strength_and_weaknesses": "Strengths:\n- I like the idea of unifying most existing methods with GIB.\n- There are discussions for the relationships between GIBE and sparsity, stochastic attention mechanism and OOD. \n- Experimental results demonstrate the efficacy of the proposed techniques.\n\nConcerns:\n- In section 1, is it possible to better explain why the rank is better than L1 norm? A low-rank matrix is not necessarily sparse, but L1 norm can help control the size of the graph (#edges).\n- Regarding GIB, how do Eq. (1) ensure the sparsity of subgraph? And how do we define the subgraph are sparse enough? Moreover, for some motif structure, it might not be sparse but is very important in determining specific properties of the graph (e.g., the hydroxide group -OH in some molecular graphs). In this case, should we consider such motifs if we want the explanatory subgraph to be sparse?\n- Current definition 2 is not self-contained. It is better to explain what $G*$ is in the definition.\n- A similar definition of GIBE is presented in Theorem 4.1 in (Miao et al. 2022). It would be great to discuss the similarity and difference with that formulation. \n- I think some contents in section 3 (or maybe previous sections) needs adjustment. This is actually a key section to show that most existing methods fall into this GIB-type formulation and to explain the regularization between attribution and selection. This key connection is somehow not clear in previous sections. I get the key idea of this paper until I finished reading section 3.\n- It is better not to use gap1 and gap2 in the main body, as this is specific to Figure 1 and will confuse readers.\n- I didn't fully understand the purpose of Q in Eq. (4). Analytically, why do the introduction of variational approximation Q make it constant while original marginal distribution P is not?\n- Most contents in section 3, section 4.1 and section 4.2 are already studied in (Miao et al. 2022). It is better to spend more efforts in highlighting the contributions by the authors.\n- In addition to quantitative analysis on the proposed method, I am more interested in qualitative analysis like case studies. This is related to one last long-standing question of myself: We say explainability helps understand the behavior of black-box models. But why can we trust the explanations generated by another black-box model(s)? How should we trust this black-box explanation generator?",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is overall clear. The authors make use of the figures to help illustrate the key ideas. In terms of technical novelty, the authors could better highlight their own contributions. Some contents in the current version are overlapped with existing works. ",
            "summary_of_the_review": "The paper is interesting overall. It tries to explain the inherent regularization between attribution and selection for most existing works with the GIBE formulation. With the GIBE formulation, the authors discuss its relationships to sparsity, stochasticity and OOD. The technical contributions could be better highlighted in the literature. And some qualitative analysis would be helpful in understanding the superiority of the proposed method in real world scenarios.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_HoXU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3738/Reviewer_HoXU"
        ]
    }
]