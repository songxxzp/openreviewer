[
    {
        "id": "f4ijnO6D1gE",
        "original": null,
        "number": 1,
        "cdate": 1666482168973,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666482168973,
        "tmdate": 1666482168973,
        "tddate": null,
        "forum": "ZrJPdY5k6sg",
        "replyto": "ZrJPdY5k6sg",
        "invitation": "ICLR.cc/2023/Conference/Paper975/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies differentially private empirical risk minimization (DP-ERM) and differentially private stochastic (convex) optimization (DP-SCO). The authors consider the Langevin diffusion, which is a popular continuous-time algorithm, and show that Langevin diffusion has optimal privacy and utility trade-offs for both DP-ERM and DP-SCO under $\\varepsilon$-DP and $(\\varespilon,\\delta)$-DP both for convex and strongly convex loss functions. They also obtain new uniform stability results for Langevin diffusion that are time and dimension independent. ",
            "strength_and_weaknesses": "The paper is a solid theory paper, and the authors have provided detailed and rigorous treatment in the relatively long appendix. The authors also seem to be quite familiar with the relevant literature. The topic is important and worth investigating. \n\nHowever, I have some concerns about the assumptions and especially how the paper is presented. \n\n(1) The assumptions are often confusing. For example, on page 2, when the authors introduce the problem description, one considers a constrained set $\\mathcal{C}\\subseteq\\mathbb{R}^{d}$. However, it is not clear to me when $\\mathcal{C}=\\mathbb{R}^{d}$ and when it is a proper subset of $\\mathbb{R}^{d}$. Moreover, if it is a proper subset of $\\mathbb{R}^{d}$, what is the assumption on $\\mathcal{C}$? For another example, the authors mentioned on page 3, that \"Depending on the problem context, we make additional assumptions like $m$-strong convexity...\" I am perfectly fine with this. However, it is not clear when you make such an assumption and when you do not. For example, in the statement of Lemma 1.1., you didn't mention the strong convexity assumption, so I suppose it is not used. But then, in Theorem 1.2., $m$ appears in the equation, does that mean you used this $m$-strongly convex assumption? If so, you should mention it. If not, you should mention what $m$ means in Theorem 1.2. \n\n(2) It seems that the paper is hard to read unless you go back and forth between the main body and the appendix. For example, in Theorem 1.2., it uses Algorithm 3, but you cannot find Algorithm 3 in the main paper at all. \n\n(3) Some of the assumptions might be too strong. For example, the authors assumed that the loss function is $L$-Lipschitz. That assumption is quite strong when $\\mathcal{C}=\\mathbb{R}^{d}$, because for the Langevin literature that I am familiar with, people usually just assume (strong) convexity plus smoothness, but not the Lipschitz assumption. If your $\\mathcal{C}$ is compact, you need to make an assumption and make it clear in the main body of the paper. For instance, when I look at the statement of Theorem 1.3., it seems to me that $\\mathcal{C}$ needs to be bounded. But when I'm looking at Lemma 1.1., I don't know whether you need assumption on $\\mathcal{C}$ or not. \n\n(4) I am a bit confused with equation (2), about \"Projected\" Langevin diffusion on page 3. I understand that for Langevin algorithm on a constrained domain, you can project it back to the constrained set if the algorithm exits the domain. However, in equation (2), you are considering a continuous-time dynamics. In Bubeck et al., they showed that (discrete-time) projected Langevin algorithm, in the continuous-time limit, corresponds to a Langevin diffusion that is reflected when it touches on the boundary. You are considering a continuous-time SDE in equation (2), that makes me wonder why it is not a reflected SDE, but rather involves a projection map?\n\n(5) The fact that the authors are considering a \"continuous-time\" algorithm, instead of a discrete time algorithm, makes the contributions of the paper a bit weak. \n\n(6) Langevin algorithm is used in the optimization literature usually when the objective is non-convex, so that the injected Gaussian noise can help the algorithm escape local minima; see e.g. Raginsky et al. (2017). It is not clear to me when for convex optimization, one needs to use a Langevin algorithm. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not written in a very clear way as I explained in the weaknesses previously. It is not clear to me when certain assumptions are made and when they are not. The quality of the presentation should be improved. ",
            "summary_of_the_review": "The paper studies an important and interesting topic. It is a solid theory paper. However, it has quite a few weaknesses as I mentioned previously. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper975/Reviewer_ymJu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper975/Reviewer_ymJu"
        ]
    },
    {
        "id": "UMkDfjzxw-",
        "original": null,
        "number": 2,
        "cdate": 1666629856626,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629856626,
        "tmdate": 1666630810911,
        "tddate": null,
        "forum": "ZrJPdY5k6sg",
        "replyto": "ZrJPdY5k6sg",
        "invitation": "ICLR.cc/2023/Conference/Paper975/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper addresses differential privacy using the Langevin dynamic and claims to achieve the optimal utility-privacy trade-off for DP-ERM and DP-SCO. This paper provides bounds for excess risk on the \\epsilon-DP-SCO. ",
            "strength_and_weaknesses": "Strength: \n- This is a very interesting problem to look at even though this is not the first time that DP is viewed through the Langevin dynamic. \n- Provides a comprehensive background on the topic. \n------------------------------------------------------------------------\nWeakness: \n- This paper can be hard to follow. The main body of the paper is not self-sufficient and one should constantly go to the appendix to understand the paper. Perhaps it could have been a bit more organized. \n- This paper is way too long for a conference paper.  And it feels like the main contribution is lost in the notation and the amount of unnecessary information provided in the paper. \n- It feels like the main idea stems from one of the recent papers on the use of Langevin diffusion for DP (DP guarantees for SGLD by Ryffel), without having any sort of comparison for them. Notations, use of Renyi divergence and etc are borrowed from the same paper.\n- Proofs seem to be correct as they follow the properties of LD and straightforward techniques in DP. \n- Due to the similarity of techniques (use of LD in this paper and the one by Ryffel), comparison/discussion on both these methods is required. Since some techniques are borrowed, how is this work different aside from being applied to ERM and SCO. Techniques seem to be very similar. \n- What can say about the sensitivity under the LD? \n- Are strong convexity a necessary condition? If this assumption was not made, how would the bound change?  \n- I understand this paper is meant to be understood as theoretical but some practical implications of that could be helpful. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is not clear at all and to be able to understand one should go back and forth and it feels like the contributions are lost. It somehow feels like it is written to confuse the reader. It is too long for a conference paper. This paper has some novel aspects even though some ideas are directly borrowed. The mathematical results can be reproduced. ",
            "summary_of_the_review": "This paper provides bounds on the DP-ERM and DP-SCO with the use of the Langevin dynamic. Seems like, with techniques borrowed from the literature, this paper provides bounds that claim to be \"tight\" specifically for \\epsilon-DP.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper975/Reviewer_J76Y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper975/Reviewer_J76Y"
        ]
    },
    {
        "id": "kl6G-fkrW7",
        "original": null,
        "number": 3,
        "cdate": 1666667984612,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667984612,
        "tmdate": 1666667984612,
        "tddate": null,
        "forum": "ZrJPdY5k6sg",
        "replyto": "ZrJPdY5k6sg",
        "invitation": "ICLR.cc/2023/Conference/Paper975/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the differentially privacy guarantee, empirical risk bound and population risk bound of continuous time Langevin dynamics with tunable temperature and tuning time. For convex loss, the \u03b5-DP result is cited from (Bassily et al., 2014). The \u03b5-DP result for strongly convex function is derived for some iterated exponential mechanism similar to (Bassily et al., 2014). To derive the \u03b5,\u03b4-DP guarantee this paper uses Renyi differentially privacy as a sufficient condition. The Renyi divergence of two Langevin diffusions is derived using standard combinations of post processing theorem and composition theorem. \nThe population risk for stochastic convex optimization is derived with uniform stability bound similar to (Hardt et al., 2016).\nCombining these techniques, authors show various optimal bound under privacy guarantee in a unified model ,i.e. Langevin diffusion.",
            "strength_and_weaknesses": "Strength:\n\nAlthough most techniques used in this paper exist in prior work, they are adapted to the specific problem considered here.\nCombining these techniques, authors not only recover best known bounds, but also derive new results.\nThe collection of optimal bounds under various setting manifest that Langevin diffusion is indeed capable to serve as a unified framework to analysis empirical risk and population risk with privacy constraints.\n\nWeakness:\nThe main weakness is that algorithms 2,3 in this paper are not actually algorithm, because sampling exactly from an Gibbs measure is generally not possible within finite number of operations.\nAny implementation necessarily introduce a sampling bias which decrease with computation budget. For example, DP-SGD in (Bassily et al., 2014) uses a fixed step size.\nIt is still unclear how such bias interfere with bounds provided in this paper.\n\nAnother consequence of continuous model is that the effect of stochastic gradient error is totally ignored. For example, DP-SGD in (Bassily et al., 2014) uses a mini-batch for each iteration. However, in continuous time LD, all information of the whole dataset is used at every time point.\n\nGiven these mismatch between continuous time LD and real world algorithms, it is not clear how significant results in this paper is to the development of practical differentially private algorithms.\n\nMore specifically, it seems all improvement over existing results happens for \u03b5-DP with $T=\\infty$ (please correct me if I am wrong), thus it is hard to see whether the improvement is due to better algorithm design or a bonus of infinite computation power.\n\ntypos:\n\nIn eq 34, \u03b5 in denominator should not be square.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is in general clearly written.\nThere is no experiment.",
            "summary_of_the_review": "This paper present continuous Langevin dynamics as a unified approach to the problem of differential privacy. In particular, the bounds derived in this paper recover or exceed the best known bounds in the field. At the same time, the limitation of continuous dynamics and infinite computation budget raise questions on the practical significance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper975/Reviewer_yW9T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper975/Reviewer_yW9T"
        ]
    },
    {
        "id": "Ey2rHsfFF9t",
        "original": null,
        "number": 4,
        "cdate": 1666691270269,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666691270269,
        "tmdate": 1666691270269,
        "tddate": null,
        "forum": "ZrJPdY5k6sg",
        "replyto": "ZrJPdY5k6sg",
        "invitation": "ICLR.cc/2023/Conference/Paper975/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper analyzes achieve trade-offs of privacy and utility for DP-ERM and DP-SCO via Langevin diffusion. Tight DP-SCO bounds for both convex and strongly convex are provided through the lens of algorithmic stability. For non-convex case, a lower bound is provided to show the impossibility of improvement from $\\epsilon$-DP to $(\\epsilon, \\delta)$-DP.",
            "strength_and_weaknesses": "Strengths:\n1. The main contribution of the paper is providing a framework based on Langevin diffusion to analyze privacy/utility trade-offs for DP-ERM and DP-SCO. \n2. Algorithmic stability is employed to provide the tight DP-SCO bounds.\n3. The paper is well-written and solid in theoretical analysis.\n\nWeaknesses: \n1. The comparison of tight bounds for DP-ERM and DP-SCO with related work is lacking(a table may can demonstrate the comparison better).\n2. The theorems are fairly restrictive. (i.e. For Theorem 1.2, if $p \\ll n$, the improvement from $p^2 \\log(n)$ to $p\\log(n) + p^2$ is limited; if $p \\gg n$, the bound seems to be less meaningful. The assumptions for stability bound are required strongly convex and smooth, which are also strict. The choice of learning rate should satisfy empirical case and population case simultaneously.)\n3. The experiment part is missing.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper provides a framework for DP-ERM/DP-SCO with solid theoretical analysis, which may be applicable to other problems.",
            "summary_of_the_review": "Overall, I think the contribution of this paper is to employ Langevin diffusion to provide a framework to analyze the privacy/utility trade-offs, but it does not show a significant improvement compared with previous work. Additionally, the assumptions for uniform stability seem strict. However, it indeed provides a new thinking of analysis.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper975/Reviewer_wZ3h"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper975/Reviewer_wZ3h"
        ]
    }
]