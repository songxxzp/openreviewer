[
    {
        "id": "0HZSOtk5ln0",
        "original": null,
        "number": 1,
        "cdate": 1666631351887,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666631351887,
        "tmdate": 1666631351887,
        "tddate": null,
        "forum": "Krk0Gnft2Zc",
        "replyto": "Krk0Gnft2Zc",
        "invitation": "ICLR.cc/2023/Conference/Paper6071/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to learn a successor representation and use it to cluster the states. The clusters are then treated as nodes of a graph and an (option) policy is trained to navigate the graph. The graph can be used in either a goal-oriented setting by searching; or a reward maximization setting with a lazy random walk.",
            "strength_and_weaknesses": "Strength:\n1. The idea of learning a graph and using it for hierarchical decision-making is interesting on a high level.\n\nWeaknesses:\n1. Environment of all the tasks is of very low degree of freedom (Dof=2), and the optimal policy is very simple. It's unclear whether the method can be applied to tasks with practical value. \n2. The motivation of a lot of the novel designs (the successor representation loss in eq (2), lazy random walk for reward maximization) is not well-justified and seems like can cause problems in a general setting.\n3. The baselines this method is comparing to in section 6.2 are within their framework. It's more like ablation of representation learning component of DSAA. No proper offline/online, model-based and model-free RL methods are compared to the proposed method.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: The quality of the writing and plotting is OK.\nClarity: The writing is somewhat vague on the motivation and the methodology is a bit underspecified (potentially because of the complexity of the method).\nReproducibility: The authors claim the paper will be released to the public but there's no code in the current submission. Since the whole algorithm seems quite complex, I think it may not be very easy to reproduce the results.",
            "summary_of_the_review": "This paper is an empirical one where a lot of design choices are based on the authors' intuition. However, the paper didn't provide strong empirical evidence that the method they proposed actually works in tasks with practical value. All the tasks are quite simple (2d navigation and 2d arm) and working on them is more of a proof of concept. There could be so many implicit hypotheses that the method relies on if they can only work on tasks with this low degree of freedom. Even for these toy tasks, it's not clear whether the method has any advantages over well-established control/RL methods due to the lack of baselines.\nI think this paper is not ready for acceptance for ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_TM9s"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_TM9s"
        ]
    },
    {
        "id": "Q0LM-ME5C4",
        "original": null,
        "number": 2,
        "cdate": 1666819911093,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666819911093,
        "tmdate": 1666819911093,
        "tddate": null,
        "forum": "Krk0Gnft2Zc",
        "replyto": "Krk0Gnft2Zc",
        "invitation": "ICLR.cc/2023/Conference/Paper6071/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper outlines an approach to use successor representations to drive a discrete state space abstraction. The abstract states are clusters in successor space, so \"nearby\" states have similar successors. The paper also contributes a way to utilize the abstraction learned to solve tasks efficiently by interpreting transitioning between abstract states as options, and outlines an algorithm to jointly learn the successor representations, the abstract representation and the option policies.",
            "strength_and_weaknesses": "This is a well written paper which clearly describes its motivations, contributions as well as limitations. The method is theoretically grounded and seems sound. The approach is novel as far as I am aware and cleanly described. The experiments are well thought-out and appropriate comparisons are made to prior approaches.\nThe environments are a bit simple, but given that prior approaches are less effective/noisy on them, that is justified.\nMore quantitative results could have been included for different exploration policies for learning the success features/abstractions.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the work is novel as far as I am aware.\nBecause the method is relatively simple and cleanly described it should be reproducible. The authors state that the code will be made available upon acceptance.",
            "summary_of_the_review": "This is a good quality paper, cleanly written and justified with appropriate experimentation and I recommend acceptance to ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_C2ny"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_C2ny"
        ]
    },
    {
        "id": "biDgddonbQ",
        "original": null,
        "number": 3,
        "cdate": 1667051715518,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667051715518,
        "tmdate": 1667051715518,
        "tddate": null,
        "forum": "Krk0Gnft2Zc",
        "replyto": "Krk0Gnft2Zc",
        "invitation": "ICLR.cc/2023/Conference/Paper6071/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose an approach to learn a discrete abstraction of an environment in reinforcement learning. The proposed approach creates abstract states using the successor representation (Dayan, 1993), reflecting the intuition that states should be grouped together based on \"what happens after visiting a state\", and creates abstract actions (options) that take the agent from one abstract state to neighbouring abstract states. The authors present an empirical analysis of the proposed approach in two domains: a gridworld with four rooms and a three-joint control task on a two-dimensional plane. \n",
            "strength_and_weaknesses": "Strengths: \n\n-- The authors present a plausible approach to abstraction in reinforcement learning, building on several earlier ideas and methods. \n\nWeaknesses: \n\n-- The analysis and evaluation of the approach is quite limited. \n\nFirst, the authors explore the behavior of the proposed approach in a relatively narrow range of environments. The first domain is a small gridworld with four rooms. The authors state \"We highlight that the sparse nature of reaching a specific state in the environment and the existence of bottleneck states in FourRooms makes this is a relatively difficult task for standard RL.\" Not many people would agree with this statement. On the contrary, this is quite a simple task for reinforcement learning. This domain is not only easy but also has a very simple structure, and many alternative methods would identify very similar abstractions (e.g., those based on graph clustering). It is not a particularly informative environment. The second domain is more complex than the gridworld but still relatively simple. \n\nSecondly, the analysis in each domain is relatively limited and does not give the reader a good understanding of the behaviour of the proposed approach. For instance, there is no exploration of how agent performance varies with the number of abstract states.\n\nThirdly, the analysis does not explore some existing approaches that are closely related. For example, as the authors note, Ramesh et al. (IJCAI 2019) propose a similar abstraction of the environment using the successor representation, which would be an informative baseline. Approaches based on graph cuts/clustering would also be relevant and informative. Some of these methods may not scale as well as the proposed approach but it would still be useful to see their similarities/differences and relative strengths/weaknesses explored. \n\n-- How the approach would fare in stochastic environments is not discussed or explored. \n\n-- Computational complexity of the approach is not discussed or explored.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The main novelty in the paper is the specific way the successor representation is used in defining the abstract states. An earlier paper by Ramesh et al. (IJCAI 2019) has used the same intuition of grouping states together using the successor representation. Generally, the central ideas and components of the approach have appeared earlier in the literature but the proposed approach puts them together in a novel way. \n\nThe paper is well organised but the individual sections could be better written, with more clarity and detail.\n\nI have not spotted any errors. But I would note that the experimental analysis is not strong enough to back the claims of the authors regarding how useful the approach is. ",
            "summary_of_the_review": "The authors present a plausible approach to abstraction in reinforcement learning, building on several earlier ideas and methods. The main novelty in the paper is the specific way the successor representation is used in defining the abstract states. The approach could prove useful but the analysis in the current paper does not give the reader a good understanding of the behaviour of the approach and its strengths/weaknesses relative to existing methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_icxB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_icxB"
        ]
    },
    {
        "id": "tA0ETBzzHIa",
        "original": null,
        "number": 4,
        "cdate": 1667564506976,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667564506976,
        "tmdate": 1667564506976,
        "tddate": null,
        "forum": "Krk0Gnft2Zc",
        "replyto": "Krk0Gnft2Zc",
        "invitation": "ICLR.cc/2023/Conference/Paper6071/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to use a dataset of environment transitions to divide states into N discrete clusters. They propose a Discrete VAE architecture that encodes a state into one of N discrete states and then decodes it into its successor representation. The encoder is regularized by a uniform prior leading to similarly sized clusters of states and the decoder ensures states with similar Successor Representations have the same discrete cluster. Temporally abstracted actions (options) are trained to transition between the discovered state clusters. This procedure is shown to perform well in two simple environments: FourRooms (discrete) and Arm2D (continuous).",
            "strength_and_weaknesses": "## Strengths\n- The paper is clearly written, easy to follow, has a good structure and flow, and contains sufficient background to understand the method.\n- The idea of clustering states into a discrete set of clusters and using them for option learning is interesting and seems novel.\n- The method is simple, intuitive, and achieves the paper's desiderata of uniformly sized state clusters with similar Successor Representations.\n\n## Weaknesses\n- **Are the assumptions practical?**\n    + My main concern is that the assumptions required to make the method work do not seem to be practical and would not scale to complex tasks. For instance,\n        * The idea of defining state clusters only makes sense in small and closed environments. In unknown and complex environments, it is not even clear what the number of state clusters (and options) would be.\n        * The dataset of environment transitions should cover all the states in the environment, at least those that the downstream task would observe.\n        * In search-like tasks like mazes or Arm2D, the main challenge is reaching certain states using a reward. But this paper bypasses this problem of state exploration by assuming the dataset does most of the hard job. Therefore, it does not seem practical for most problems.\n        * Equally-sized state clusters: Depending on the task family, differently-sized clusters might make more sense, e.g., guided by reconstruction or environment reward or reachability of states or semantic properties (such as objects) of states.\n    + Are there realistic applications that would still fall under such assumptions and thus benefit from the proposed method?\n- **Experimental Evaluation**\n    + **Environments**\n        * While the proposed method can work in both discrete and continuous settings, I am concerned about the complexity of tasks it can scale to. The current environments are too simplistic and deterministic: even random exploration can find the goal in 30 episodes in the FourRooms environment. The prior work (Machado et al. 2018) also uses Successor Representations and shows results on the Atari domain. \n    + **Mismatch from claims**: While the paper claims (in the introduction) that discrete state abstraction is helpful to discover discrete objects or properties and for understandability, none of these benefits are exhibited in the experiments.\n    + **Baselines**: The use-case of the proposed method is in learning state abstraction and options unsupervisedly. However, several skill discovery methods, such as Pertsch et al. (2021), discover skills from unsupervised offline datasets and use them to accelerate downstream RL. Shouldn't such Hierarchical RL methods also be compared as baselines to demonstrate the importance of discrete state abstractions?\n\n[1] Marlos C Machado, Clemens Rosenbaum, Xiaoxiao Guo, Miao Liu, Gerald Tesauro, and Murray Campbell. Eigenoption discovery through the deep successor representation. In 6th International Conference on Learning Representations, 2018.\n\n[2] Pertsch, Karl, Youngwoon Lee, and Joseph Lim. \"Accelerating reinforcement learning with learned skill priors.\" Conference on robot learning. PMLR, 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written well with clarity and original ideas.",
            "summary_of_the_review": "The paper has original ideas and is written well. However, I am not yet convinced of the importance of the problem solved and method proposed, as it may be limited to toy tasks \u2014 both, in terms of the assumptions and the experiments. I would consider raising my score if these concerns could be addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_vZz4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6071/Reviewer_vZz4"
        ]
    }
]