[
    {
        "id": "X5HuxEIJaCR",
        "original": null,
        "number": 1,
        "cdate": 1666460795096,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666460795096,
        "tmdate": 1666460795096,
        "tddate": null,
        "forum": "1ehuYMrigt",
        "replyto": "1ehuYMrigt",
        "invitation": "ICLR.cc/2023/Conference/Paper3966/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "\nThe authors address an interesting problem of the asymmetrically corrupted regression problem. They motivate the problem using several real-world examples. They propose a solution by modeling the target value as corrupted with asymmetric noise. To learn the regression function, they derive a loss function based on the data model and use gradient descent to find the solution. They use real and synthetic data to demonstrate the proposed approach. \n",
            "strength_and_weaknesses": "Strengths: The paper is well written, and the English level is satisfactory. The proposed problem is interesting with a novel solution. They prove the unbiasedness and consistency of the gradient of the proposed loss function. Several examples are provided to demonstrate the advantages of the proposed approach. \n\nWeaknesses: The authors only compare their method to simple baselines, while several solutions exist to the related problem of regression with asymmetric loss functions.\n\n\nMinor comments:\nFor clarity, please mention what K is in the caption of figure 2.\n\nPage 4 results of figure 2, I assume that the data in the test set is not incomplete, but this is not explained.\n\nPlease expand on the caption of Table 2.\n\nP9 the results related to table 2, can be viewed as a classification task, so why not compare to baselines that focus on asymmetric classification?\n\nWhy is the word Rate capitalized?\n \n",
            "clarity,_quality,_novelty_and_reproducibility": "The introduction and problem statement are clear, the paper provides a novel solution with some theoretical analysis. The experimental setting is simple and well-explained, so I believe it is reproducible. \n",
            "summary_of_the_review": "Overall the authors present an interesting problem with a novel solution. They prove that the gradient of the proposed loss is unbiased and consistent. Then, they demonstrate that the method works on synthetic and real data. This is a valuable contribution to the community, and I believe that the paper should be accepted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_mxCJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_mxCJ"
        ]
    },
    {
        "id": "qyPjqPkEHH",
        "original": null,
        "number": 2,
        "cdate": 1666484438776,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666484438776,
        "tmdate": 1666484438776,
        "tddate": null,
        "forum": "1ehuYMrigt",
        "replyto": "1ehuYMrigt",
        "invitation": "ICLR.cc/2023/Conference/Paper3966/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considered a regression problem where incomplete observations have labels biased towards lower values. The authors proposed an algorithm which utilizes only high-valued labels and discarded the lower-valued labels. They conducted several experiments on both synthetic and real-world datasets to demonstrate their algorithm.",
            "strength_and_weaknesses": "Strength:\nThe idea is explained well. Their work is motivated by real-world use cases which makes it interesting.\n\nWeakness:\nIn general I do not really buy this idea for addressing asymmetrically corrupted dataset, and the assumptions they made seem problematic. On a high level, completely ignoring the lower-valued labels, no matter they are true low values or come from incomplete observations, could potentially lose some information. Couple of questions are in order.\n\n1. As the authors showed in the experiments, Huber regression performed badly. But have you tried using Huber regression as an outlier detection step? Namely, identify observations whose (x,y) relationship differs significantly from others, and remove those from your sample set, and then apply Least Squares regression to the rest of normal data points. The logic is that, I do not think we can completely remove lower-valued labels, but instead, we can do some pre-processing to identify abnormal data points. The high-value / low-value scheme does not seem to well supported.\n\n2. Section 2.1 is not needed in my view. It is common knowledge and should be described very briefly. \n\n3. Based on your definition of upper-side labeled data, their noise \\epsion_s >=0. But technically \\epsilon_s could also be negative. So you are missing a portion of complete observations by restricting to the upper-side labeled data.\n\n4. Lemma 2.2 also seems problematic. Ideally when there is no corruption, namely, (x,y), we want to use all the data, not just data with f(x) <= y. Eq. (5) doesn't seem to establish the consistent estimator as the authors claimed.\n\n5. The authors claimed that for some loss functions, when y<f(x), the gradient of the loss function does not depend on y, e.g., Eq. (8). But notice that even when y>f(x), the gradient of this type of loss also does not depend on y. So it is about the loss function itself, not the upper or lower sides of the labels. When you switch to squared loss (which was used in your Proposal-2 in the experimental section and thus violated your assumption here), the gradient would depend on y no matter you are in the upper or lower sided region.\n\n6. In order to identify the upper or lower sides, you need to do an iterative process where you use the f_t from previous iteration to define upper or lower region. Does this unnecessarily complicate the problem?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is explained in a relatively clear way, but the quality or novelty is not sufficient for publication at ICLR. There are also problematic assumptions / results which I have brought up in the above section. ",
            "summary_of_the_review": "Overall I do not buy the idea or arguments made in this paper. For detailed comments please look at the Strength and Weakness section above.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_QdLV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_QdLV"
        ]
    },
    {
        "id": "sdQElxOFe7S",
        "original": null,
        "number": 3,
        "cdate": 1666514396082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666514396082,
        "tmdate": 1666514396082,
        "tddate": null,
        "forum": "1ehuYMrigt",
        "replyto": "1ehuYMrigt",
        "invitation": "ICLR.cc/2023/Conference/Paper3966/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This draft studies a special weakly supervised regression problem in which the labels are generalized by sensors. Therefore, the low value displayed by the sensor could either be actual or suggest that the label is missing. The author formulates this problem as a regression from asymmetrically corrupted data and proposes a new approach based on an unbiased gradient estimator to solve it. Both synthetic and real-world experiments demonstrate the effectiveness of the proposed approach. ",
            "strength_and_weaknesses": "Strength:\n+ The work is well motivated by many sensor-based applications and covers a wide range of real-world applications. To address this task, the proposed method appears promising. Also, empirical results support the proposed method's effectiveness.\n+ The proposed method has nice theoretical properties. According to certain assumptions, the proposed approach produces an unbiased estimator with asymmetrically corrupted data and thus obtains a well-generalized model.\n\nWeakness:\n- The estimation of $\\pi_{up}$ is heuristic and changes according to the training procedure based on the validation set. Therefore, the proposed method and the theoretical results do not end-to-end match exactly. Due to the small validation data set, the estimation can be unreliable and unstable due to overfitting.\n- This method can only be applied to absolute loss and pinball loss, which limits its use.\n\nThere is a question regarding the implementation of the proposed method. The proposed method relays on an adaptive estimation of $/pi_[up]$ and an upper-side labeled sample set based on the validation set. What is the size of the validation set and how does it affect the performance of the proposed method? How to avoid the overfit to the validation data?",
            "clarity,_quality,_novelty_and_reproducibility": "This draft is well-organized and easy to follow. The problem in this draft is novel and interesting. The proposed method seems promising, but the implementation is not discussed in sufficient detail.",
            "summary_of_the_review": "This draft studies a well-motivated problem that covers a wide range of real-world sensor-based applications. The proposed method constructs an unbiased gradient estimator with asymmetrically corrupted data under certain mild assumptions. There is a theoretical basis for the proposed method and empirical studies support its effectiveness.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_gU2i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_gU2i"
        ]
    },
    {
        "id": "jScqu5EU8h",
        "original": null,
        "number": 4,
        "cdate": 1666820092051,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666820092051,
        "tmdate": 1666820092051,
        "tddate": null,
        "forum": "1ehuYMrigt",
        "replyto": "1ehuYMrigt",
        "invitation": "ICLR.cc/2023/Conference/Paper3966/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of learning a decision function when the output might be corrupted by the fact that the sensor in charge of collecting it has failed to record it properly, underestimating it. Without a debiasing procedure, the decision function naturally underestimate the magnitude of the event. Under the assumption that the loss function does not depend on the prediction (when the latter is greater than the output), the authors propose an estimator of the gradient that is unbiased. Experiments complement the paper.",
            "strength_and_weaknesses": "**Strengths**\n- the paper is globally clear and well written\n- the problem studied is of interest and the proposed approach is natural\n\n**Weaknesses**\n- it seems to me that the interest of the approach is completely shortcut by the choice of loss functions, which do not depend on the label. This is a very strong limitation of the approach to me\n- in the same vein, could the authors think about other examples where to apply a similar method? This could make the contribution of greater interest\n- the experiments are pretty rudimentary, especially on real data. For instance how would a model with censorship behave, when given the information if the output has been altered or not?\n- I am also pointing out the literature on Median-of-Means (MoM)-based methods for robust regression, see in particular [1], that do not assume the outliers to be symmetric and could be interesting to benchmark\n\n[1] Robust classification via MOM minimization, Lecu\u00e9 et al. 2020",
            "clarity,_quality,_novelty_and_reproducibility": "Gloablly good, except for the following points\n- the way conditional expectation are presented is confusing to me\n- in Eq. (9), (10), shouldn't it be $y'$ instead of $y$?\n- Lem 3.4: shouldn't $\\eta$ be $1/2$ since the noise is symmetric?",
            "summary_of_the_review": "Overall, I feel the contribution of this paper might not be enough to warrant acceptance. In particular, the restricted choice of loss functions is shortcuting the interest of the approach. The experiments need strengthening. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_Sduq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3966/Reviewer_Sduq"
        ]
    }
]