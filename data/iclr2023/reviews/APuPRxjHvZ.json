[
    {
        "id": "REIvUH8XFKl",
        "original": null,
        "number": 1,
        "cdate": 1666507052283,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666507052283,
        "tmdate": 1668638025998,
        "tddate": null,
        "forum": "APuPRxjHvZ",
        "replyto": "APuPRxjHvZ",
        "invitation": "ICLR.cc/2023/Conference/Paper88/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, an interesting finds are demonstrated: instead of always finetuning the last layer of the model, tuning different layers works best for different types of distribution shifts. 3 types of shifts are discussed: (1) Input-level shift, first-layer finetuning is better; (2) Feature-level shift, mid-later blocks are better; (3) Output-level shift, last layer is better;",
            "strength_and_weaknesses": "## Strength\n- This paper present a counter-intuitive finding, with detailed experimental and theoretical analysis\n## Weakness\n- Datasets used are relatively small. It is fine that this work focus on \"fine-tune the pre-trained model on a small target dataset\". However, it would be more persuasive to show some results on large model + mid-size dataset. In industry, this is a more common setting.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity and Quality\n- Presentation is good and the paper is easy to follow.\n## Novelty\n- This paper present a counter-intuitive finding, which is novel.\n## Reproducibility\n- Opensource is not guaranteed in the paper. Experiment details are in the appendix. It should not be difficult to reproduce the paper.\n",
            "summary_of_the_review": "This paper present a counter-intuitive finding, with detailed experimental and theoretical analysis. However, the major concern is that the finding is validated on small datasets, which might not be able to generalize to larger datasets finetuning.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper88/Reviewer_Y4ag"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper88/Reviewer_Y4ag"
        ]
    },
    {
        "id": "f6fUMhEX8s",
        "original": null,
        "number": 2,
        "cdate": 1666594722035,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594722035,
        "tmdate": 1666594722035,
        "tddate": null,
        "forum": "APuPRxjHvZ",
        "replyto": "APuPRxjHvZ",
        "invitation": "ICLR.cc/2023/Conference/Paper88/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper shows fine-tuning a (contiguous) subset of layers matches or outperforms commonly used fine-tuning approaches including full fine-tuning or fine-tuning the last few layers. The authors evaluated the performance of surgical fine-tuning diverse layers of choice on 7 different distribution shift scenarios (input, feature, and output-level shifts). In addition to these empirical results, they tried to validate theoretically in an idealized two-layer neural network setup to explain why the earlier and later layer fine-tuning achieve best performance for input and output-level shifts, respectively. At last, the authors investigated several criteria for automatic selection of which layers to tune for better performance, and they empirically demonstrated that the automatic fine-tuning outperforms full fine-tuning.",
            "strength_and_weaknesses": "Strength\n\u2022 For empirical studies, they categorized distributional shifts into three main scenarios including input, feature, and output levels to analyze optimal selection of layers to tune for each scenario with plausible explanations. \n\u2022 This type of study usually reports experimental results only without theoretical verification. But this paper somehow provides theoretical verification using a simplified two-layer neural network. \n\u2022 Diverse experiments have been conducted to make their claims. \n\u2022 Beyond the explanations of the empirical results, they leveraged the findings to develop a training pipeline with automatically selecting layers to tune, and demonstrated the proposed approach achieves better performance than simply full fine-tuning which has been mostly used by researchers without any doubts. \n\u2022 In addition to supervised learning, they analyzed unsupervised learning that otherwise would be requested by reviewers. \nWeakness\n\u2022 Can you explain the rationale about why only contagious subset of layers need to be tuned instead of discrete subset of layers? \n\u2022 In this study, distribution shifts are categorized into three levels including input, feature, and outputs. However, it would be interesting to show results for combination of scenarios like input+feature, feature+outputs, inputs+outputs, and input+feature+outputs shifts. Especially, when we want to fine-tune ImageNet pretrained models on medical images (which is commonly used by biomedical researchers), do we expect full fine-tuning achieves the best performance instead of subset of layers to tune as natural images to medical images have distributional shifts of input, feature, and outputs levels. These results could be much more interesting because large distributional shift scenarios are more like real word situation compared to what\u2019s shown in this paper.",
            "clarity,_quality,_novelty_and_reproducibility": "They leveraged their empirical findings with verification of theoretical equations to propose a new training algorithm that outperforms a conventional approach. Their work is interesting to read and novel as most prior works have shown just experimental results without theoretical verification and automation of selection of layers to tune for transfer learning. The reviewer thinks most of results shown in the paper can be reproduced. ",
            "summary_of_the_review": "The authors investigated how fine-tuning can be adapted to diverse distribution shifts by showing empirical results and theoretical verification, followed by proposing a new type of regularization (several criteria to control extent of tuning per layer) to achieve a better performance than a commonly used approach (full fine-tuning). But, the paper can be more interesting to read by the potential readers if they can show results for real-world scenarios that are likely to have more than two types of distribution shifts.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper88/Reviewer_QAba"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper88/Reviewer_QAba"
        ]
    },
    {
        "id": "NlCWvztnieO",
        "original": null,
        "number": 3,
        "cdate": 1666713953194,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666713953194,
        "tmdate": 1668784694500,
        "tddate": null,
        "forum": "APuPRxjHvZ",
        "replyto": "APuPRxjHvZ",
        "invitation": "ICLR.cc/2023/Conference/Paper88/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper performs an analysis of what the fine-tuning strategy should be when encountering various distribution shifts. They classify the different distribution shifts into three categories and show that for each category of distribution shift, different layers of the model should be surgically fine-tuned. This analysis results in interesting outcomes, for example, for shifts where the inputs are changing (like CIFAR-C), contrary to the conventional wisdom of fine-tuning the last few layers to re-use the learned features, it is better to fine-tune only the early layers of the network. The paper also discusses and compares some ways to automatically decide which layers to fine-tune. ",
            "strength_and_weaknesses": "Strength(s):\n1. The paper nicely and cleanly classifies the distribution shifts into three types and empirically shows how different fine-tuning strategies are optimal for different types of distribution shifts.\n2. The synthetic experiment in the paper is clever and successfully demonstrates that surgically fine-tuning the relevant layers/blocks can result in a significant performance gain.\n3. New strategies (Auto-SNR and Auto-RGN) for automatically selecting which layers to fine-tune were a nice outcome of the theoretical analysis performed by the authors.\n4. The empirical observations to fine-tune only a subset of layers for different distribution shifts are well supported by multiple datasets having different types of distribution shifts. \n\nWeakness(es)/Suggestion(s):\n1. For table 3, in addition to the L1 regularization method, it would be nice to include other methods like gradually unfreezing or different learning rates for different layers, etc. \n\n(some methods from the existing work: \nA. Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do better imagenet models transfer better? In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 2661\u20132671, 2019. [page 1]\nB. Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran, Rahul Bhotika, and Stefano Soatto. Rethinking the hyperparameters for fine-tuning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum id=B1g8VkHFPH. [page 1, 9]\nC. Zhiqiang Shen, Zechun Liu, Jie Qin, Marios Savvides, and Kwang-Ting Cheng. Partial is better than all: Revisiting fine-tuning strategy for few-shot learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 9594\u20139602, 2021. [page 1, 9]\nD. Youngmin Ro and Jin Young Choi. Autolr: Layer-wise pruning and auto-tuning of learning rates in fine-tuning of deep networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 2486\u20132494, 2021. [page 1]\nE. Miguel Romero, Yannet Interian, Timothy Solberg, and Gilmer Valdes. Targeted transfer learning to improve performance in small medical physics datasets. Medical Physics, 47(12):6246\u20136256, 2020. [page 1])\n\n2.  Although the observation of fine-tuning different subsets of layers for different distribution shifts is an interesting one, it is not clear how the method of surgically fine-tuning a network would compare to existing methods for domain adaptation or methods that perform test-time adaptation (adjusting the covariate shift, etc.) [F,G,H]. It would strengthen the paper if authors can show that surgical fine-tuning is a better and simpler option to tackle distribution shifts as compared to training exotic models that enable robustness or allow for domain adaptation. \n\nF. Improving robustness against common corruption by covariate shift adaptation, NeurIPS 2020\nG. Adaptive Denoising via GainTuning, NeurIPS 2021\nH. Be Like Water: Robustness to Extraneous Variables Via Adaptive Feature Normalization, 2020\n\n3. Is the reported metric for CIFAR-C and IN-C (1- mean corruption error (mCE)), in Tables 1,2, and 3, and Figures 2, 3 and 4? Because mCE is a standard metric to track when dealing with corruption datasets.\n\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is explained well and has novel aspects in it. In terms of reproducibility, I was not able to find the code in the supplementary material but it should be relatively straightforward to reproduce it",
            "summary_of_the_review": "Overall, although the work has some interesting analyses and outcomes/results, it is still unclear how the method of surgically fine-tuning a network would compare to existing methods for domain adaptation or methods that perform test-time adaptation (adjusting the covariate shift, etc.). Therefore, my recommendation for this paper would be marginally below the acceptance threshold (5).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper88/Reviewer_eWpB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper88/Reviewer_eWpB"
        ]
    }
]