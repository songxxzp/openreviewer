[
    {
        "id": "JCpI425XlS",
        "original": null,
        "number": 1,
        "cdate": 1666612978078,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666612978078,
        "tmdate": 1666612978078,
        "tddate": null,
        "forum": "WL8FlAugqQ",
        "replyto": "WL8FlAugqQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3338/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose solving dag scheduling problems by using GNNs to provide node priorities in the list scheduling algorithm. The GNN is trained using good old REINFORCE. The training is made stable using logit renormalization and cost standardization, as introduced by the authors.\n\nThe authors introduce two versions of their Greedy and Sampling. In Sampling, they sample multiple node priorities from an encoded distribution. Greedy is a special case of Sampling, i.e. S(1).'\n\nThe authors evaluate their technique on several baselines, both real and synthetic. Their technique is consistently the best among all relevant baselines.",
            "strength_and_weaknesses": "The novelty of the technique is mostly incremental - the proposed technique piggy back's on REINFORCE, Gumbel top-k trick and the list scheduling algorithm. The novelty is in how to make training with REINFORCE stable, which can be notoriously hard to get right.\n\nWhat I found most interesting about the work was the authors' decision to create a Sampling version of the algorithm -- One important feature of the proposed technique is that the trained model can be used zero-shot once it has been trained on a dataset, making it extremely efficient compared to other neural-baselines. This is similar to the REGAL technique in Paliwal et al except that they use a genetic algorithm instead of the random search that the authors use in Sampling. Given that Sampling is always stronger (as it can't be worse than Greedy), I ask two things\n- why didn't the authors consider using a more powerful search algorithm instead of just random search in Sampling?\n- why didn't the authors consider using the cost of the of the best solution found by the search algorithm as the reward in REINFORCE instead of just using Greedy?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and clear.",
            "summary_of_the_review": "Overall, the paper is interesting, well written and well motivated. However, given that the novelty is incremental, the strength of the paper would lie in its empirical evaluation, hence I encourage the authors to explore more avenues such as how would their technique work using a more advanced search algorithm as proposed above.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_HjB3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_HjB3"
        ]
    },
    {
        "id": "6qjPb-0f2By",
        "original": null,
        "number": 2,
        "cdate": 1666622332894,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666622332894,
        "tmdate": 1669043741373,
        "tddate": null,
        "forum": "WL8FlAugqQ",
        "replyto": "WL8FlAugqQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3338/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers node/operation scheduling within DAGs, which is previously solved using heuristics but more recently approached with ML-based solutions. ML techniques are typically more costly, but the authors employ a \u201cone-shot\u201d encoder networks to sample node priorities in a single forward pass of the network. These priorities are then converted via list scheduling to the final schedules. This encoder can sample priorities in parallel, which makes it much faster than baselines. Although the method is still a bit slower than heuristic techniques in most cases, the proposed method is shown to actually outperform both heuristic and ML-based techniques. \n",
            "strength_and_weaknesses": "Strength:\n* The problem being addressed by the proposed method is clearly motivated and explained. It also has a big impact, as any scheduling approach must have low runtime to be usable in practical scenarios. The approach considered within this work is novel to the best of my knowledge (i.e., the differences from Gagrani et. al. seem to be significant/non-trivial, as you must find a way to obtain the schedule in a single shot). \n* The use of Gumbel variables and the Gumbel top-k trick is explained well and interesting. \n* The method seems to perform well empirically relative to neural and heuristic baselines.\n\nWeakness:\n* It would be good to provide discussion of how long it takes to train your method, how much data is needed, etc. This is probably an additional latency consideration that would be of interest to anyone trying to practically use your method. I think this discussion is needed to more thoroughly compare your approach to common, heuristic methods on a basis of practicality. \n* Time is still worse compared to heuristic baselines, but it is still close. It seems like to achieve the best performance, more time is needed. However, this is somewhat unavoidable for approaches that leverage neural networks. \n* Outperformed by constraint programming on TPC-H, but this doesn\u2019t seem to be a big issue. It is only in one case and performance of the proposed method is still pretty similar. \n\n\nSmall Comment:\n* Logit norm regularization explanation is well done. I like how you motivate the problem that exists using binary variables, then propose a solution that works well empirically. This explanation makes sense and is non-trivial. \n* In the summary of contributions \u201c(w.r.t to the makespan)\u201d, you can remove the \u201cto\u201d.\n\nQuestions:\n* Is REINFORCE the only way to train this algorithm? Are there potentially other methods (maybe even non-RL) that would be less data hungry or provide a better result? It would be good to understand a little better why REINFORCE is chosen. ",
            "clarity,_quality,_novelty_and_reproducibility": "I do not see any problems with clarity/quality/novelty/reproducibility.",
            "summary_of_the_review": "Personally, I am not familiar with reinforcement learning. As such, I am completely open to discussion of my comments with other authors/reviewers. This review reflects my initial impression of the paper given that I am somewhat unfamiliar with this area (DAG scheduling/RL). I emphasize my final score will be mostly based upon subsequent discussion that I hope will allow me to gain more perspectives on the work. \n\nI think the paper is well-written, motivated nicely, and novel (to the best of my knowledge). Empirically, the method performs very well (best in almost every case). As such, I feel that this paper provides a nice contribution to the community that is novel (AFAIK), performant, and practical. In its current form, my biggest recommendation to the authors would be to provide more details on training complexity and requirements. To better understand how using your method compares to using heuristic baseline methods, this discussion is needed. Yes, the method performs very well. But, practitioners may not use it if too much effort is required. Currently, I lack from the paper an idea of where your method stands on this spectrum -- is it practical enough to actually use?\n\nNonetheless, I thank the authors for the nicely-written and interesting paper. I think the paper is a good contribution, and I look forward to future discussion!\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_zenr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_zenr"
        ]
    },
    {
        "id": "a3AyAdkmeL",
        "original": null,
        "number": 3,
        "cdate": 1666657534907,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657534907,
        "tmdate": 1666657534907,
        "tddate": null,
        "forum": "WL8FlAugqQ",
        "replyto": "WL8FlAugqQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3338/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to use policy gradients to learn the permutation of node sequences for applications in scheduling operations. Specifically the model takes a pre-defined DAG structure which describes the job dependencies as input, and produces the logits for each job. The permutation is sampling via gumbel-topk trick and then REINFORCE gradient is used to update the policy network. Experiments on some synthetic and real-world scheduling tasks show some improvement over existing approaches.\n",
            "strength_and_weaknesses": "Strength:\n- The paper is well written and the background and problem is described clearly.\n- The empirical results seem to be good.\n\nWeakness:\n- Technically the paper is relatively straightforward and lacks novelty in terms of the technical contribution. Leveraging policy gradient or RL in general for combinatorial optimization has been studied over the past several years. The main contribution of the paper is to use a variant of the parameterization of the policy, where the encoder is from another recent paper and the gumbel-topk used for decoding from the encoded logits is not new. \n- Continuing with above, the technical part can be potentially improved in following aspects: \n1) It seems that the current approach doesn\u2019t guarantee that the generated permutation satisfies the topological order specified by the DAD (correct me if I\u2019m wrong). It would be nice to make it more compatible with the problem that is being solved, instead of using a generic approach in a straightforward way. \n2) The nice thing about the gumbel trick is that it admits a reparameterization. If the author can build something that allow end to end optimization with gradient propagates from the objective to the graph encoder, then it would be nicer and more efficient than REINFORCE, hopefully.\n\n- The paper claims that the one-shot decoding is beneficial. However it seems that it is a surrogate of the model used in [1], as mentioned by the authors in Sec 3.2. So a natural question would be, how does [1] perform in the experiments presented in the paper? The hypothesis is that [1] would yield better results but worse speed, so a trade-off is expected. More comprehensive comparison with [1] would be needed for the experimental sections.\n\n- The application for the scheduling seems to be specific, but the technique using GNN + gumbel-topk with RL seems to be general. To make it naturally aligned with the technique, there could be several ways to improve:\n1) include other combinatorial optimizations that optimize for a permutation, like the TSP mentioned by the authors;\n2) make the approach more appropriate and adapted to the DAG based optimization, as I mentioned above about the techniques.\n\nReferences:\n[1] Neural topological ordering for computation graphs, Gagrani et.al\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is presented clearly, and the quality of the current execution is ok but some more experiments can be included. The reproducibility seems fine as the approach is relatively simple. The main concern is on the novelty and the technical quality.\n",
            "summary_of_the_review": "Overall this paper presents a simple yet efficient approach for the scheduling problem. There are several aspects that need to be justified, in terms of the 1) experimental quality and thoroughness; 2) technical correctness/improvements; 3) generality to more CO problems that optimize for a permutation.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_p2nE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3338/Reviewer_p2nE"
        ]
    }
]