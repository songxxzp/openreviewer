[
    {
        "id": "UgxXbbOaFF",
        "original": null,
        "number": 1,
        "cdate": 1666527668617,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666527668617,
        "tmdate": 1666527668617,
        "tddate": null,
        "forum": "DmYnLaFGMoc",
        "replyto": "DmYnLaFGMoc",
        "invitation": "ICLR.cc/2023/Conference/Paper1462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed an active learning approach for deep anomaly detection where a k-means++ based diversified querying strategy is adopted to ensure that the queries cover both the normal data and the anomalies well and two losses for queried and unqueried samples are designed to prevent neither the queried nor the unqueried data points from dominating the learning task. This paper also provides a method to estimate the unknown contamination rate from queried samples thus avoiding the assignment of the most important hyperparameters. This paper also provides a detailed theoretical derivation and experimental verification of the assumptions and theories used in the method. The experimental results show that the proposed method outperforms the compared methods significantly. The ablation study also shows the effectiveness of the proposed method.\n",
            "strength_and_weaknesses": "Strength:\n1.\tThe proposed method can fully exploits the supervised and unsupervised information in anomaly detection.\n2.\tThe important hyperparameters in the proposed method are designed adaptively. \n3.\tThe theorems and assumptions used in the paper are theoretically derived and experimentally verified in detail and the experimental results of the proposed method are promising.\n\nWeakness:\n1)\tThe time complexity of the proposed method is not clearly. In the experiment, why the proposed method is not verified on large-scale dataset.\n2)\tIn the proposed method, a querying strategy that encourages diversity with k-means++ is proposed method. However, the main contributions of this strategy are not clearly presented.\n3)\tIn the proposed method, the equation(3) mainly deals with binary classification. How does the proposed method deal with the multiple classification setting.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written and it is easy to follow. Meanwhile, a novel active learning strategy is proposed and termed as active latent outlier exposure (ALOE). The parameters in ALOS are adaptively designed.",
            "summary_of_the_review": "This paper proposed an active learning approach for deep anomaly detection which is composed of unsupervised anomaly detection with latent outlier exposure (LOE) and supervised active anomaly detection with k-means++ querying strategy. It fully exploits the supervised and unsupervised information into anomaly detection, which ensures the diversity of the selected samples and the generalization of the scoring function to unlabeled and labeled sets. The theoretical derivations and experiments in the article are very detailed. Overall the article is novel enough and well-written.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_7TvR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_7TvR"
        ]
    },
    {
        "id": "DMCJFADvFOA",
        "original": null,
        "number": 2,
        "cdate": 1666862686603,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666862686603,
        "tmdate": 1668675472932,
        "tddate": null,
        "forum": "DmYnLaFGMoc",
        "replyto": "DmYnLaFGMoc",
        "invitation": "ICLR.cc/2023/Conference/Paper1462/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a diversified query strategy for an anomaly detector that can be applied in an active learning setup. The querying strategy is based on querying diverse cluster centers seeded by k-means++.",
            "strength_and_weaknesses": "1. Abstract: \"However, correctly identifying anomalies requires an estimate of the fraction of anomalies in the data.\" -- This has never been proven (to my knowledge). While specific algorithms might make assumptions, this is not true in general. Anomalies are by nature unknown unknowns. Even their fraction is not knowable. The paper probably makes this statement w.r.t the specific LOE algorithm discussed and should clarify that or remove this statement.\n\n\n2. Section 2: \"... not comparable to Pelleg and Moore (2004), Siddiqui et al. (2018), and Ghasemi et al. (2011), who fit a density model on the raw input data ...\" -- Siddiqui et al. is tree-based. They do not fit a density model.\n\n\n3. Section 3.2: \"... determined by the smallest radius \\delta such that ...\" -- Is the radius \\delta here an absolute distance measure, or in normalized units? It does not make sense if the distance is unnormalized and if it (distance between data points) could vary from zero to infinity.\n\n\n4. Section 3.2: \"... all unlabeled points are within distance \\delta of one queried sample of the same type.\" -- This makes strong and oversimplifying assumption about the data. It basically means assuming that data from various classes are tightly clustered together.\n\n\n5. Section 3.2: \"... we propose a querying strategy that encourages diversity: k-means++ ...\" -- Querying cluster centers is a classic active query strategy and not novel. For example, [r1] proposes an approach to query the centroids of clusters of instances that lie closest to the decision boundary.\n\n\n6. Assumption 2: I suspect Assumption 2 has fallen for a statistical fallacy.\n\nAs an analogy to the Assumption 2 made here, suppose we consider undergrad students at a top ranked US university. The average (say) SAT scores will be very high and the distribution of the scores around that (high) average will be statistical noise -- just like the off-diagonal correlation mentioned here. However, that does not mean that the distribution of SAT scores among the general population will be the same as at the university.\n\n\n7. Section 4: \"... and all |Q| queries are collected at once.\" -- This is not really an active learning setup. For comparing with active learning algorithms on a fair basis, the algorithm should iterate over multiple label feedbacks from a (simulated) human-in-the-loop.\n\n\n8. Table 2: \"For all experiments, we set the contamination ratio as 10%.\" -- Experiments should be run with actual contamination factor in the datasets, not the artificial 10%.\n\n\n9. Section 4.2: \"... which have an outlier ratio of at least 30%.\" -- This amount of anomalies does not really make it an anomaly detection problem. The set of experiments are missing some harder real-world datasets where the anomaly fraction is really small ~1-2%.\n\n\n10. Appendix C: \"Hybr2. This hybrid strategy by Das et al. (2019) makes positive diverse queries.\" -- The main query strategy for diversity in Das et al. (2019) is based on compact description. The strategy explained here is likely one of the alternatives proposed on the related github repo (https://github.com/shubhomoydas/ad_examples). This needs to be clarified. It should be noted that the compact description based approach in Das et al. is basically a clustering-based approach.\n\n\nReferences:\n\n[r1] Xu, Z., Akella, R., & Zhang, Y. (2007). Incorporating Diversity and Density in Active Learning for Relevance Feedback. ECIR.\n\n\n>>>>>>>>>>> Update after author response\n\nI thank the authors for responding to my comments. At this time I do not have sufficient reason to change my scores. Mainly, I do not see this as a true 'active learning' anomaly detection algorithm and it comes across as mostly a class-imbalanced classification problem. The paper started off with an unproven and unjustified premise that correctly identifying anomalies requires estimating the anomaly fraction. It appears that the premise might have some bearing under a few strong assumptions for a specific anomaly detection algorithm, but that is not generalizable. Some more comments:\n\n\n1. Clarification on Assumption 2 (and also Assumption 1) comment: The paper assumes that if off-diagonal elements of the score matrix constructed from a subset of data are zero, then you can deduce some properties of the general population from that. But, that is wrong as I pointed out with an example. You can have query schemes where the off diagonal correlations can be zero, but the general population's score distribution cannot be deduced from that. That is why the theory is not well-grounded.\n\n\n2. \"Different application areas require a different active learning setup.... The experimental comparison is fair because all methods are evaluated in the same setting...\" -- This is where we have a contradiction. Most (all?) of the competitor/benchmark active learning algorithms used in this paper were designed for continuous active learning. So then why compare a one-shot feedback algorithm with the continuous feedback algorithms?\n\n\n3. \"This video dataset is a benchmark dataset for anomaly detection and has the original outlier ratio of around 30%.\" -- In that case let's use more / other datasets where the anomaly ratios are very small.\n\n\n4. \"We refer to their strategy based on the description in the paragraph 'Diversity-based Query Selection Strategy' on page 12\" -- The method described in the current work is not the same as Das et al. (2019) and should be made clear.\n\n\n5. \"..reviewer i6D3 found our theoretical study novel and reviewer 7TvR said..\" -- My review not being in agreement with other reviewers is (among other things) a sign of having an independent opinion -- which I last checked is highly valued among reviewers at ICLR.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, but lacks novelty. Classic technique from classification based active learning has been adopted.",
            "summary_of_the_review": "The theory and assumptions are not well grounded. The claim that this is in an active learning setting does not match the experiment setup where instead of multiple rounds of feedback, all query instances are selected at one shot.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_uxaT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_uxaT"
        ]
    },
    {
        "id": "0rN5dTw2V6M",
        "original": null,
        "number": 3,
        "cdate": 1666942007523,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666942007523,
        "tmdate": 1666942007523,
        "tddate": null,
        "forum": "DmYnLaFGMoc",
        "replyto": "DmYnLaFGMoc",
        "invitation": "ICLR.cc/2023/Conference/Paper1462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper is a combination of Latent Outlier Exposure (Qiu 2022) and an active learning strategy from the same group. The idea is to exploit knowledge about the outlier rate to control active learning sample selection during training. The assumption is that finding anomalies in the (unlabeled) training set will improve the quality of anomaly detection in the test phase. A lot of experiments on different ML tasks (images, medical images, videos, etc.) demonstrate improvement over existing techniques. The authors also support their claims with some theorems. ",
            "strength_and_weaknesses": "I like the rigorous analysis from a theoretical perspective and the extraordinary evaluation of their method on real data. The paper is well-written and builds upon existing publications. I do not agree with the assumption or application case. In my opinion, anomaly detection is no longer such a task if you are able to identify such anomalies from the training data. It then becomes a supervised task with the anomalous events being an additional class. This statement might sound philosophical. However, if you do active learning in an supervised setting, the authors ignore methods from active learning. One example is EMOC, see Freytag et al.: Selecting Influential Examples: Active Learning with Expected Model Output Changes. European Conference on Computer Vision (ECCV). If we know that there are novel classes in our training set (the known one is the inlier data, the novel one the outlier), we shall also study methods that combine active learning in a continuous learning scenario, for example, Kaeding et al.: Active and Continuous Exploration with Deep Neural Networks and Expected Model Output Changes. NIPS Workshop on Continual Learning and Deep Networks. 2016. I find that the authors should consider such work as well and include it in the comparison. ",
            "clarity,_quality,_novelty_and_reproducibility": "This is well-done work. Novelty is a bit limited since existing methods are combined. However, I am honouring the theoretical study found in the paper as a novelty. The paper is very well written and easy to follow. I see good reproducibility. ",
            "summary_of_the_review": "The paper tackles a (from my perspective) very special (and not such common) case in anomaly detection. For me, it is not clear whether the detection of real anomalies and outliers can be improved. Real anomalies are those who have never been seen before, for example, novel classes in a continual learning scenario. It is quite natural that one can improve on anomaly detection if one can optimize the model during training on that already. Then, anomaly detection (even with only 10% outlier rate) boils down to a supervised setting (of course, an unbalanced one). Since the author missed to take this perspective as well and as a consequence to study and compare with literature in areas like normal active learning and continual learning, I am not that happy about the paper. Finally, I am missing experiments on image data beyond X-MNIST, like one can find results for normal active learning. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_i6D3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1462/Reviewer_i6D3"
        ]
    }
]