[
    {
        "id": "nPXa-oDcQBK",
        "original": null,
        "number": 1,
        "cdate": 1665939389764,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665939389764,
        "tmdate": 1665939389764,
        "tddate": null,
        "forum": "vfa7--yvtYh",
        "replyto": "vfa7--yvtYh",
        "invitation": "ICLR.cc/2023/Conference/Paper1592/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper studied the problem of self-supervised image denoising and present an method which is an extension of the existing work R2R (Recorrupted2Recorrupted [Pang et al. CVPR'21).  The basic idea is to synthesize the pair from a noisy image that can simulates the supervised pair (noisy, clean) in supervised learning, where the noise is simulated by randomly flipping the sign of residual. The experiments are conduced in several datasets.",
            "strength_and_weaknesses": "**Strength**:\n\n1. The paper is quite accessible for catching the main idea.\n \n**Weakness**:\n 1. The novelty of the work is limited, it is essentially an extension of R2R with un-justified noise simulation\n2. The key theoretical argument for discussing R2R is incorrect.  In the last sentence, the author claim as long as $n+n'$ inside $f$ and $n-n'$ outside out $f$ are independent, the R2R works. It is incrrect, the noise $n+n'$ and $n-n'$ cannot be independent. \n3. The key theoretical argument for discussing sign-flipping is wrong. Firstly, the paper claim that the simulated $\\hat n$ defined in  (9)  is independent from $n$. It is not true as there is $n$ in the definition of $\\hat n$. Secondly, the claim after (1) that $n-\\hat n$ and $n+\\hat n$ is independent, which is incorrect by the same reason in 2.\n4. The performance improvement over existing ones is quite marginal.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite clear about the main idea. The novelty is very limited and there is severe issues in its theoretical soundness. The reproducibility is reasonable.",
            "summary_of_the_review": "The paper studied an interesting problem, and presents an extension of existing works for solving it. However, the extension is based on some  procedure, and there is severe errors in their theoretical argument. The performance gain is also limited. Thus,, I don't think this paper meets the standard of ICLR for acceptance.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_c6Mm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_c6Mm"
        ]
    },
    {
        "id": "wXvLV9sEv5U",
        "original": null,
        "number": 2,
        "cdate": 1666189455472,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666189455472,
        "tmdate": 1666191171152,
        "tddate": null,
        "forum": "vfa7--yvtYh",
        "replyto": "vfa7--yvtYh",
        "invitation": "ICLR.cc/2023/Conference/Paper1592/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposed an unsupervised deep learning method for single image denoising, which only takes a set of noisy images for model training. The basic idea is combining the Recorrupted-to-Recorrupted loss with a sign flipping scheme and a pseudo supervised loss on self-generated samples. The experiments on both synthetic Gaussian noise corrupted images and the real-world SIDD dataset showed that the proposed method has certain improvement over the recent unsupervised methods such as Neighbor-to-Neighbor in some settings.",
            "strength_and_weaknesses": "Strengths\n1. The proposed method showed improvement over unsupervised methods such as Neighbor-to-Neighbor on the real-world dataset SIDD, though the improvement is somehow marginal.\n2. The combination of Recorrupted-to-Recorrupted loss with the sign flipping scheme leads to the improvement.\n\nWeaknesses\n1. Novelty is quite limited as the work is the combination of two established works.\n2. There are severe errors in the mathematical proof and logic gaps in the explanation of the proposed method.\n3. The writing needs improvement. In addition to many grammar errors and non-standard language usage, the technical part is very unclear.\n\nSee the comments below for the details about the weaknesses.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n1. The proof in Section 3.1:\na) I don't see a detailed theory or proposition corresponding to this proof. The definition of the loss L, the distributions of the noise n, n', and the assumption on the noises, are totally not mentioned. This makes the statement and the proof very vague.\nb) What's worse, there are severe errors in the proof. It is said that \" as long as n and n' are independent, it can be inferred that n + n' in f\u03b8(\\hat{y}) and n \u2212 n' are independent\". This is totally wrong! \nc) It is unclear why Equation (7) can be transformed into Equation (11).\n\n2. The motivation of using sign flipping is rather vague. The paper says the benefit is that sign-flipping generates zero-mean noise. This motivation is rather weak, as there are many other ways to generate zero-mean noise. Since the proof in Section 3.1. I could not get more information what sign-flipping brings to the proposed method. Further, I believe sign-flipping imposes a strong assumption on the noise distribution, but this is not mentioned and empirically studied in the paper either.\n\n---------------------------------------------------------------------------------\n\nNovelty:\nThe paper is combination of the existing Recorrupted-to-Recorrupted loss and a sign flipping scheme. However, the sign flipping for noise generation has been proposed in [1,2]. The proof related to Recorrupted-to-Recorrupted loss is quoted from the original work with vague explanation, and zero-mean property of the sign-flipping noise generation has been discussed in [1,2]. Therefore, I believe the novelty of the paper is rather limited.\n\n[1] Noise2Grad: Extract Image Noise to Denoise. IJCAI 2021.\n[2] Self-Verification in Image Denoising. ArXiv 2021,\n\n--------------------------------------------------------------------------\nQuality:\nThe writing is not good. Many grammar errors and non-standard language usage are found, e.g., the title of Section 3.3.\n",
            "summary_of_the_review": "This paper showed the combination of two existing techniques for unsupervised image denoising can lead to certain improvement. However, there are severe errors and many unclear points in the mathematical proof and statements. Such problems are difficult to solve in a revision.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_L537"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_L537"
        ]
    },
    {
        "id": "jeiWxyWpUgo",
        "original": null,
        "number": 3,
        "cdate": 1666610553570,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610553570,
        "tmdate": 1666610553570,
        "tddate": null,
        "forum": "vfa7--yvtYh",
        "replyto": "vfa7--yvtYh",
        "invitation": "ICLR.cc/2023/Conference/Paper1592/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed an unsupervised learning framework for denoising, without assuming noise priors. Three stages are designed, i.e., generating noise, psedo supervised learning and recorrupted2recorrupted. The results on synthetic Gaussian noise and real noise datasets show the proposed method is comparable with existing methods. ",
            "strength_and_weaknesses": "Strength: A new unsupervised learning framework for image denoising. The noise prior is not assumed, and the proposed method may be applicable to wider noise types. \n\nWeaknesses:\n1. The proposed method is somewhat complicated and is not well explained why it can work. Let us assume the denoiser is perfect, i.e., y-f(y) is exactly the true noise. Then second step does nothing since f can perfectly remove \\hat{n}, and third step forces f can remove stronger noise since y+\\hat{n} shoulbe be close to y-\\hat{n} by L_u. So the main denoising effect may come from the third step. But the contriton of these steps are not validated in ablation study.\n\n2. What is regular loss Lg? And in Fig. 1, network f is w/o gradient and the lines are dashed on Lg. I cannot understand what they mean, and there is no explanations in main context. \n\n3. The English is not inapproriate, e.g., \"we will ... perfect denoiser\", \"PSEUDO SUPERVISED\" is not suitable for section title, \"the generate noise\". Just list a few.",
            "clarity,_quality,_novelty_and_reproducibility": "The propose unsupervised framework seems to be effective for synthetic and real noises. Without noise assumption, this work is more applicable than existing methods. ",
            "summary_of_the_review": "The proposed method is effective, but it is not well explained, and the effect of each component is not well verified. The writing needs more effort to polish. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_CpLn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_CpLn"
        ]
    },
    {
        "id": "P7gGyfjlEO",
        "original": null,
        "number": 4,
        "cdate": 1667149670513,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667149670513,
        "tmdate": 1667149670513,
        "tddate": null,
        "forum": "vfa7--yvtYh",
        "replyto": "vfa7--yvtYh",
        "invitation": "ICLR.cc/2023/Conference/Paper1592/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an unsupervised method for image denoise. The noise model is generated by a residual image and a random mask. With the noise model, the input and target of the network are generated from a single noisy image. Experiments are conducted on both synthetic and real-world datasets.",
            "strength_and_weaknesses": "Strength:\n1. This paper is easy to follow and well-organized.\n2. The paper is abundant with experiments. The ablation study somewhat justifies the design choices of the method.\n\nWeaknesses:\n1. The main idea of this paper is similar to [1] and [2]. The proposed method seems like a combination of these two methods. I cannot find new technical or theoretical insights in this work.\n[1] Lin H, Zhuang Y, Zeng D, et al. Self-Verification in Image Denoising. arXiv preprint arXiv:2111.00666, 2021.\n[2] Pang T, Zheng H, Quan Y, et al. Recorrupted-to-recorrupted: unsupervised deep learning for image denoising. CVPR 2021: 2043-2052.\n2. The performance improvement is slight according to Fig.2 and Tab.1.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality of this paper seem good, but the novelty is limited.",
            "summary_of_the_review": "I think this paper is below the acceptance threshold. The novelty is limited as they just combine several existing ideas. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_XJfe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1592/Reviewer_XJfe"
        ]
    }
]