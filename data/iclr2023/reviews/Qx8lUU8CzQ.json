[
    {
        "id": "1-GVZys5e-B",
        "original": null,
        "number": 1,
        "cdate": 1666260755863,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666260755863,
        "tmdate": 1669299746702,
        "tddate": null,
        "forum": "Qx8lUU8CzQ",
        "replyto": "Qx8lUU8CzQ",
        "invitation": "ICLR.cc/2023/Conference/Paper471/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper present an end to end vectorization algorithm for generating HD map. It takes the multi-view images and LiDAR point cloud as the input and produce HD map via series keypoints. At the first stage, a BEV features are extracted from onboard sensor data. Then element keypoints are encoded via map element detector and a polyline generator is utilized to encode the polylines. Experiments on two datasets demonstrate the effectiveness of the approach.  ",
            "strength_and_weaknesses": "The proposed end-to-end vector extraction is interesting. However, some important discussion is missing, which is listed as below: \n \n1. In the ablation study, bounding box representation is stated as the optimal representation. Why not represented the polyline extraction as the instance segmentation (with boundary sequence encoding) ? The reviewer cannot figure out the advantage to instance segmentation.\n\n2. How to define the length of polyline? In the polyline generator, each element keypoints is reserved as the tokens and a lookup table is built with addition EOS. Since different polyline has different length on HD map, how to determine the minimum number of keypoints for each polyline? The reviewer notice that the author discuss the approaches to sample polylines in D.1 But the minimum number of keypoints for different type of polylines are not found. \n\n3. The author only evaluated the performance with mAP metric. How about other metrics, such as boundary mIoU, top-k accuracy (for classification branch)? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed algorithm is generally clear presented. \nBut the novelty is limited, some previous vector extraction methods are missing for comparison. For example,  E2EC for contour extraction, PolyWorld for vector extraction and the Enhanced-iCurb et al. Those end-to-end approaches also conduct vector extraction algorithm and perform well on many benchmarks and can be directly applied to HD map generation. \nThe source code is not provided and some details are missing, e.g., the length of polyline for training, which weaken the reproducibility.\n\nReference\n#1 Zhang T, Wei S, Ji S. E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (pp. 4443-4452). \n\n#2 Zorzi S, Bazrafkan S, Habenschuss S, Fraundorfer F. PolyWorld: Polygonal Building Extraction with Graph Neural Networks in Satellite Images. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (pp. 1848-1857).\n\n#3 Xu Z, Liu Y, Gan L, Hu X, Sun Y, Liu M, Wang L. csBoundary: City-Scale Road-Boundary Detection in Aerial Images for High-Definition Maps. IEEE Robotics and Automation Letters. 2022 Feb 24;7(2):5063-70.",
            "summary_of_the_review": "The topic of end-to-end vector extraction is promising. Combined with LiDAR and multi-view images, HD map can be smoothly generated. However, the main concern is not solved in the paper (see weakness parts). In addition, several related works are not presented for fair comparisons of the HD maps. \nThe reviewer  lean to reject the current form if the above concerns are not clearly presented. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There is no ethics concerns.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper471/Reviewer_oajd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper471/Reviewer_oajd"
        ]
    },
    {
        "id": "Qpm4dzQG3VU",
        "original": null,
        "number": 2,
        "cdate": 1666608612314,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666608612314,
        "tmdate": 1666608612314,
        "tddate": null,
        "forum": "Qx8lUU8CzQ",
        "replyto": "Qx8lUU8CzQ",
        "invitation": "ICLR.cc/2023/Conference/Paper471/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose the generation algorithm of vectorized HD map from onboard sensors such as cameras and LiDARs.  They represent map elements as a set of polylines and the positions are learned from extracted BEV features.  After element keypoints are detected, the trained decoder outputs polylines of every elements.  The experimental study shows that their proposed VectorMapNet achieves state-of-the-art performance on the public nuScenes and Argoverse2 dataset.",
            "strength_and_weaknesses": "Strengths\n+ The map elements are represented as a set of polylines and this can express various map components such as road boundary, pedestrian crossing and stop line.\n+ The keypoint representation is investigated in ablation study and determined.\n+ The performance is evaluated on public dataset and the proposed method achieves higher accuracy than HDMapNet.\n+ The polyline generator generates the order of polyline vertices and these are critical information for HDMap.\n\nWeaknesses\n- There are few discussions regarding the issues below.\n- How about processing time?\n- Are multi-camera input mandatory?  Can a front camera output HDMap in front of the vehicle?\n- How about the sensitivity of VectorMapNet to camera position, intrinsic parameters, extrinsic parameters?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed idea is original. The authors concisely describe the details of the method and the improvement from the existing methods.",
            "summary_of_the_review": "The proposed method is novel and achieves definitely higher accuracy than the existing methods.  I think that this paper deserves acceptance to ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper471/Reviewer_5FhD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper471/Reviewer_5FhD"
        ]
    },
    {
        "id": "OIsfenN4vo",
        "original": null,
        "number": 3,
        "cdate": 1666632428403,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632428403,
        "tmdate": 1666632428403,
        "tddate": null,
        "forum": "Qx8lUU8CzQ",
        "replyto": "Qx8lUU8CzQ",
        "invitation": "ICLR.cc/2023/Conference/Paper471/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a learned system to generate semantic 2D maps for driving based on RGB on-vehicle images and LIDAR point cloud. The novelty aspect is in using polylines to represent the map, which also influences the choice of the architecture (the paper follows Nash et al. which previously addressed CAD model generation). The experimental results show improvement over baselines.",
            "strength_and_weaknesses": "\\+ The paper addresses an important problem in self-driving.\n\n\\+ Experimental results show improvement over baselines.\n\n\\- The paper is quite difficult to read.\n\n\\- It is not fully clear how established the experimental protocol is (see below).\n\nQuestions:\n* It is not clear from the beginning what kind of map is proposed by this paper. In particular, term polyline requires an upfront explanation. Also, it is not immediately clear what polylines represent and how to use them for autonomous driving. Finally, how is coordinate system handled, does the network place the origin at the origin of the LIDAR map?\n* It is not clear how the metrics are calculated. Looking at the Figure 3, it seems like automatic comparison of the map to the ground truth is a challenging problem. Was the evaluation protocol used by this paper established in prior work (pointers?) or is it one of the contributions of this paper as well?",
            "clarity,_quality,_novelty_and_reproducibility": "* Quality is high - experiments are well-conducted and ablations are provided.\n* Clarity is low.\n* Originality is moderate.\n* Reproducibility is low - the system is complicated and the code is not provided.",
            "summary_of_the_review": "I am learning towards rejection due to low clarity.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper471/Reviewer_sk1h"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper471/Reviewer_sk1h"
        ]
    },
    {
        "id": "CWauNKRcSx",
        "original": null,
        "number": 4,
        "cdate": 1667140332631,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667140332631,
        "tmdate": 1667140332631,
        "tddate": null,
        "forum": "Qx8lUU8CzQ",
        "replyto": "Qx8lUU8CzQ",
        "invitation": "ICLR.cc/2023/Conference/Paper471/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a method for extracting compact and interpretable vector maps from input camera and lidar data. The method consists of three key components: a feature extractor, a map element predictor and a polyline generator. The feature extractor uses a CNN to extract features from the images and the point cloud. The map element predictor uses a transformer to identify and localize road boundaries, dividers and pedestrian crossings which are then described as keypoints. The polyline generator then uses another transformer-based model to connect adjacent keypoints into complete vector shapes. While this is not the first method to construct vector maps from raw sensor data, it performs significantly better than existing approaches such HDMapNet.",
            "strength_and_weaknesses": "Strengths\n\n1. The proposed method is able to automatically generate vector maps without human input. This is significant as the process of creating vector maps from sensor data usually requires significant manual effort and/or are not able to generalize to new types of sensor data.\n\n2. Nearly all commercial mapping software today uses vector representations and the proposed method can therefore naturally interface with existing map ecosystems. The output vector maps are more compact and easier to interpret than those generated by other methods which work with rasterized grids. \n\n3. The use of transformers for predicting vector elements seems well suited to the problem as vector nodes naturally map to the \u201ctokens\u201d used by transformers in other domains. \n\n4. The results are quite strong and the vector maps generated by the proposed approach are more accurate than those generated by existing methods. Specifically, the approach significantly outperforms HDMapNet (the closest existing method) on nuScenes and ArgoVerse in terms of average precision (AP).\n\nWeaknesses\n\n1. The related work described in the paper seems quite limited. Instead of only focussing on HDMapNet, there is a whole category of research [eg. 1] that deals with converting raster images to vector images which are closely related and should be included. Have transformers been used before for vectorization? \n\n2. The proposed approach works only with a single-pass mapping of a particular area. How would multiple mapping sessions be integrated to obtain higher-quality maps?\n\n3. There is no mention of the computational requirements and runtime of the approach. Does it work in real-time? Can it be run on an edge node or does it have to run on more powerful machines in the cloud? \n\n[1] Carlier, Alexandre, et al. \"Deepsvg: A hierarchical generative network for vector graphics animation.\" Advances in Neural Information Processing Systems (2020) ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is fairly well-written and contains neat illustrations. It also contains enough detail for someone with sufficient expertise to implement and reproduce the results.",
            "summary_of_the_review": "Overall, the paper makes a good contribution. While the task of predicting vector maps from raw sensor data is not new, the transformer-based approach is interesting and achieves a significant increase in performance. I would recommend the related work be updated and the questions above addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper471/Reviewer_TD4k"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper471/Reviewer_TD4k"
        ]
    }
]