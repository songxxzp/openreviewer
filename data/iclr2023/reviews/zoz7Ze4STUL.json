[
    {
        "id": "RN2OYkv_roL",
        "original": null,
        "number": 1,
        "cdate": 1665955430072,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665955430072,
        "tmdate": 1668307794866,
        "tddate": null,
        "forum": "zoz7Ze4STUL",
        "replyto": "zoz7Ze4STUL",
        "invitation": "ICLR.cc/2023/Conference/Paper2931/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a new mechanism based on the energy-models for the task of out of distribution detection on graphs. They show that the graph neural networks trained with supervised loss objective can be intrinsically effective to detect OOD data on which the model should avoid prediction. The energy based method proposed in this work can be directly extracted through simple transformation from the predicted logits of a GNN classifier. Furthermore, the proposed method is agnostic to the choice of the underlying architecture used making it highly generalizable. This is further enhanced using a simple propagation scheme, following the popular label propagation framework, that can provably improve the detection performance by increasing the margin between the in-distribution and out of distribution. Lastly, they propose a direct extension of this by utilizing the energy based scheme in an auxiliary loss regularizer that can be trained along the supervised NLL objective. Experiments performed over a diverse collection of datasets and against SOTA methods clearly demonstrate the proposed method is highly effective.\n",
            "strength_and_weaknesses": "1. The experiments clearly demonstrate that the proposed approach is highly effective. It is very interesting that the GNN-safe model alone can provide substantially high detection performance.\n2. The experiments in table 8 comparing the runtime of all the methods are further useful in demonstrating the effectiveness of the proposed approach.\n4. Eq 11 in the appendix should have a sum instead of difference.\n5. The authors mention in the last paragraph of page 4 that - \u201cIn specific, the generation of a node is conditioned on its neighbors, and thereby an in-distribution node tends to connect with other nodes that are sampled from in-distribution, and vice versa\u201d. It would be more useful to provide some citations for this. Though they mention in the subsequent paragraph that the labels and features for the neighbors can be different, in such heterophilous graphs, the opposite trend may also hold. \n6. There is strong emphasis that the energy of in-distribution samples tend to be lower than the out of distribution samples, however, the opposite trend emerges in figure 1 (a). Do the authors have some intuition of why this is happening?\n7. There is no mention of the selection of the hyperparameter $\\tau$, eq 8. Details and study of this hyperparameter will be highly relevant.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writeup of the paper is very clear and the paper is easy to follow. The hyperparameter details along with the empirical evidence presented suggest that the results are likely to be reproducible. Though there are concerns regarding the novelty of the work as the idea of energy based models has been extensively utilized in the same literature of out of distribution detection and with similar formulations.\n",
            "summary_of_the_review": "Based on the questions, comments and concerns raised in the weakness section as well as the issue concerning novelty of the work, I lean towards weak rejection of the work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_PiYE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_PiYE"
        ]
    },
    {
        "id": "Dm2v-e2C38",
        "original": null,
        "number": 2,
        "cdate": 1666616104095,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666616104095,
        "tmdate": 1666616104095,
        "tddate": null,
        "forum": "zoz7Ze4STUL",
        "replyto": "zoz7Ze4STUL",
        "invitation": "ICLR.cc/2023/Conference/Paper2931/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed an energy-based out-of-distribution detection for graph neural network. The contributions include introducing energy-based method to graph out-of-distribution detection, providing some theoretical analysis, presenting energy propagation, and conducting a lot of experiments.",
            "strength_and_weaknesses": "Strength:\n1. The paper is well-written and the motivation is clear.\n2. The numerical results showed that the proposed two methods especially GNN-Safe-r are much better than the baselines.\n\nWeakness:\n1. The main idea is almost the same as that of Energy FT (Liu et al. 2020). It seems that the major difference is the proposed methods are for graph neural network rather than MLP and CNN.\n\n2. In the experiments, what is the main difference in terms of the implementation between Energy FT and the proposed GNN-Safe-r?\n\n3. One can observe that in many cases, GNN-Safe was outperformed by Energy FT, which verified the importance of OOD exposure in the training stage. Thus, one may train a binary classifier to classify the in-distribution samples and out-distribution samples into two different classes, which should have a good performance in the testing stage.\n\n4. The OOD exposure violates the principle of OOD detection because it becomes a supervised learning problem with OOD labels.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality are good. However, considering the previous work of Liu et al. 2020, the novelty is not significant enough.",
            "summary_of_the_review": "It seems that the main improvement over existing work such as Liu et al 2020 is that the proposed method focuses on GNN. Thus the contribution is not that significant. On the other hand, the numerical results indicate that OOD exposure plays a very important role in the success of the proposed method. It is not clear whether a direct binary classification between in-distribution and out-distribution can yield good OOD performance or not. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_2RDq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_2RDq"
        ]
    },
    {
        "id": "PX5BTgqvVV",
        "original": null,
        "number": 3,
        "cdate": 1666697951783,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697951783,
        "tmdate": 1666697951783,
        "tddate": null,
        "forum": "zoz7Ze4STUL",
        "replyto": "zoz7Ze4STUL",
        "invitation": "ICLR.cc/2023/Conference/Paper2931/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed an intrinsic out-of-distribution (OOD) discriminator for semi-supervised learning on graphs based on an energy function called GNN-Safe, to enhance the reliability of the model against OOD data. The authors consider the interdependence between input data and other nodes in the graph rather than treating them independently. Experiments are compared with other models on five real-world datasets.",
            "strength_and_weaknesses": "**Strengths:**\n1. The experiments in this paper are detailed in comparison with different methods under different datasets and GNN encoders.\n2. This paper is well-written and easy to understand.\n3. The authors provide proof for all theoretical results.\n\n**Weaknesses:**\n1. In the Introduction, it is said that \u201cThe scarcity of labeled training data in graph domain requires the model to exploit useful information from the unlabeled portion of observed data.\u201d This statement is confusing because it is not the actual reason why semi-supervised learning is widely used in graph-based learning and performs well [1]. However, this paper claims to use semi-supervised learning to solve the problem of limited labeled data in graph datasets.\n2. There is no detailed description of the evaluation metrics. In addition, GPN compares OOD-Acc for different methods, which is also an important metric to evaluate the performance of OOD data [2].\n3. In figure 1, compared with chart (a), the distribution center of the green curve (in-distribution) is confusing in chart (b).\n4. In Section 4.1, it is said that \u201cuse the subgraph DE as in-distribution data and other five subgraphs as OOD data for Twitch.\u201d However, the authors don\u2019t explain why different subgraphs follow different distributions.\n \n[1] Graph-based Semi-supervised Learning: A review. Neurocomputing, 2020.  \n[2] Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification. NeurIPS, 2021.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation of the problem is clearly described in the introduction, and the proposed approach is easy to understand and well supported by several experiments and theoretical proof. The paper focuses on a novel energy-based belief propagation method for boosting OOD detection performance, which is meaningful. The experiment settings are detailed. However, there is no code in the supplementary materials.\n",
            "summary_of_the_review": "This paper is easy to read and proposes a novel approach based on the energy function to detect OOD data. Overall, this work is meaningful in OOD detection on graphs and can be further studied and optimized.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_BViK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_BViK"
        ]
    },
    {
        "id": "hJm4d6cIcA",
        "original": null,
        "number": 4,
        "cdate": 1667163866272,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667163866272,
        "tmdate": 1667163866272,
        "tddate": null,
        "forum": "zoz7Ze4STUL",
        "replyto": "zoz7Ze4STUL",
        "invitation": "ICLR.cc/2023/Conference/Paper2931/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper addresses an important problem of OOD detection and generalization for GNNs. An Energy-based discriminatory framework is explored that is shown to give a some significant advantages like model agnosticity, theoretical gaurantees and practically efficacy. This application and study of energy-based OOD detection methodology for inter-dependent data like graphs has not been done before and is novel. \n\nThey have started off with a simple instance-based energy function used to detect OOD samples, based on negative-log-likelihood loss. The authors show how OOD detection can be enhanced by propagating the energies calculated across neighbors for K-steps in a manner typical to message propagation in GNNs. Further, they have added a regularizing loss to this formulation that induces an energy boundary between in-distribution and OOD instances. \n\nThe experiments compare their variants with image-based and graph-based OOD competitors, with standard choice of metrics for detecting OOD and for calibrating accuracy. They show significant improvements in the OOD detection metrics without trading off the supervised learning of the models by too much. Their results improve upon previous work on OOD detection by a significant margin.\n",
            "strength_and_weaknesses": "Strengths:\n- The results seem significant over other state-of-the-art in OOD detection and generalization on graphs.\n- Broad choice of GNN encoder backbones, competitor architectures, datasets and experimentation strategies. Multiple ablation studies included.\n- Comparison of training times and inference times for all the models used included\n- Each variant of their proposed models are compared with each other as well as competitors and a good summary/explanation of each of the experimental data is given.\n- Have posited some insights on when regularization may be significant and when they may not help in OOD detection well citing examples from experiments.\n\nWeaknesses:\n- The gaps between methods that have access to OOD data to tune on and those that don't is significant. It would be helpful to better delineate these settings in the tables and results in the paper since the conditions in both cases is quite different.\n- Provide further justification and rationale for the choice of methodology for creating synthetic OOD data, especially the label leave-out way in datasets like amazon-photos, cora and coauthor-cs.\n- The explanation of how their approach is used to regularize learning in the supervised setting is not entirely clear.\n\n\u200bTypos\n- Appendix B.1 in Co-author CS:\n    - 6805 classes -> 6805 features\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is relatively clear and provides a number of significant advances over other approaches for OOD detection on graphs.",
            "summary_of_the_review": "This paper provides a new approach for OOD detection and generalization on graphs that incorporates the graph's topology in an energy-based message passing scheme. The approach is well described and the rationale makes sense. The authors provide strong evidence that their approach improves generalization on a number of OOD tasks established on different graph benchmark datasets in both an unsupervised and semi-supervised setting.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_QtVR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2931/Reviewer_QtVR"
        ]
    }
]