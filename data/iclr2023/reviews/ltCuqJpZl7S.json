[
    {
        "id": "NGa_H8rRij",
        "original": null,
        "number": 1,
        "cdate": 1666577884769,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577884769,
        "tmdate": 1669650617053,
        "tddate": null,
        "forum": "ltCuqJpZl7S",
        "replyto": "ltCuqJpZl7S",
        "invitation": "ICLR.cc/2023/Conference/Paper1991/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a new method to compute approximate Nash equilibria of games with continuous strategy sets. Specifically, the new method minimizes an approximation of exploitability with respect to the strategy profile using learned best-response functions. ",
            "strength_and_weaknesses": "Strength:\n1. The authors did a thorough literature review on Nash equilibrium for continuous games and also compared the proposed method with these existing ones.\n2. The authors experimented with the proposed method on variant games from a naive sign game to Kuhn poker.\n\nWeaknesses:\n1. The authors assume that there exists an explicit fully-fledged function mapping different strategies for Player 1 to different strategies for Player 2. This is a very strong assumption and not well justified. In the experiment, the authors used a linear form best-response function which is an even stronger assumption. What if there are multiplier players and there are interactions among multiple players? Will the linearity still hold?\n2. The learning rate is fixed at 0.01 for all experiments except for Glicksberg\u2013Gross game 10-4. It will be helpful to have some ablation study w.r.t. this hyperparameter if it needs to be carefully set. The same issue for the hyperparameter gamma. It is worth exploring how these two hyperparameters affect the convergence jointly.\n3. The authors claimed that 'If X is infinite and Y is nontrivial, X \u2192 Y is infinite-dimensional' and proposed neural networks to model the function b. This is an important use case but it seems that the authors did not offer any experimental results on it.\n4. In Fig. 1(a), it is not clear how the parameters of OP, SGA, CO, EG, and GNI evolve. It will help visualize the results to use different marks for different methods. The same issue for Figure 2.\n5. In Fig. 2(l), why ED(4) with rank 4 is better than the full-rank affine best response function? It is worth doing more ablation study w.r.t. the low rank when decomposing matrix A into I+UV.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presents the idea clearly and the idea of using a learned response function to compute Nash equlibria is also interesting.\nThe experimental results are extensive but it is very challenging to reproduce these results without open-sourced codes.\n",
            "summary_of_the_review": "Considering the paper's strong assumptions and their justifications (more details in Weaknesses), I would not recommend it for publication in its present form.\n\nI have read the authors' response and would like to keep the same score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_WPMd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_WPMd"
        ]
    },
    {
        "id": "V_Khfffaom",
        "original": null,
        "number": 2,
        "cdate": 1666599702102,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599702102,
        "tmdate": 1669341467628,
        "tddate": null,
        "forum": "ltCuqJpZl7S",
        "replyto": "ltCuqJpZl7S",
        "invitation": "ICLR.cc/2023/Conference/Paper1991/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies the problem computing NE for continous games. It equipes exploitability descent with learned best-response functions to provide better convergence (in empirical). Plenty of experiments are conducted to show its better performance than previous works.",
            "strength_and_weaknesses": "Strength:\n1. The iead of introducing learned best-response function is interesting. It is not surprising that replacing the observed opponents' strategy by the learned opponents' best-response will lead to better performance. On the other hand, it seems to be a simpler and more general way (like a blackbox) to doing lookahead than previous approaches by modeling opponents.\n2. Plenty of experiments are conducted to evaluate the proposed algorithms. The solved games in this paper covers many common classes.\n\nWeaknesses:\n1. There is no theoretical guarantee on convergence or approximation bound.\n2. The \"exploitability\" itself may be too simple. Anyway, there should be a comparison with simply exploitability-descent (Lockhart et al. (2019)). Some intuition is that it is the \"learned best-response\" part make more contributions. Thus, it would also be better if an approach like GNI + learned best response is further compared.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and easy to follow. The designed algorithm is basically a proper combination of exploitability descent (one previous work) and the idea of lookahead (a series of previous work) through learned best-response functions, which themselves are not novel independently. The experiments are clearly described with high reproducibility.",
            "summary_of_the_review": "The paper proposed a new algorithm to computing NE for continous games, which combines previous approaches properly. Plenty of experiments support its performance. Thus I am tend to accept it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_KfZH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_KfZH"
        ]
    },
    {
        "id": "AzrE5Qj1Yu",
        "original": null,
        "number": 3,
        "cdate": 1666674302393,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674302393,
        "tmdate": 1668701340848,
        "tddate": null,
        "forum": "ltCuqJpZl7S",
        "replyto": "ltCuqJpZl7S",
        "invitation": "ICLR.cc/2023/Conference/Paper1991/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors study the problem of finding Nash equilibria in continuous games. Their key observation is that one of the reasons why algorithms for computing Nash equilibria fail is that players spend a lot of iterations re-learning the best response to a strategy of the other players. This happens even if the same strategies are repeated multiple times during the game.\n\nThe authors propose that players should learn the parameters of a best response function that learns to best respond to the other players. This function can be parametrized as affine functions or neural networks in the most general setting. Experimental results show that across a variety of games, the proposed approach can outperform prior work.",
            "strength_and_weaknesses": "Regarding strengths, the paper is clearly written with the notation, motivation and the intuition of the approach being very clearly and thoroughly introduced. To the best of my knowledge, this is the first work to propose the learned best responses framework in its full generality where the learned best response function can be arbitrarily parametrized in terms of $\\theta$.\n\nRegarding weaknesses, the concept of learned best responses is not entirely new. For example, [1] proposes an instance of the learned best response framework where the adversary learns a weighted average of fixed smooth functions of the opponent's strategy. The individual algorithms may run GD on an objective for a fixed initialization for a fixed number of epochs. But in principle, any smooth function can be used. Even in this limited setting, one does not need to worry about cycling when using gradient ascent descent. \n\nGiven that learned best responses are not entirely new, I would suggest to the authors to highlight how/when the generality of their framework is useful or lessons learned about these problems from their experiments.   \n\n\n\n[1] Tanner Fiez\u2217, Lillian J. Ratliff, Chi Jin, Praneeth Netrapalli, MINIMAX OPTIMIZATION WITH SMOOTH ALGORITHMIC ADVERSARIES, ICLR 2022",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written and is of high quality. \n\nMy concerns about novelty are highlighted above. \n\nThe experimental settings are clearly described although code (or at least code samples) would help with reproducibility.",
            "summary_of_the_review": "In summary, I am willing to increase my score if the authors elaborate about the uniqueness/novelty of their approach or at least highlight some lessons learned from their experiments. As it is though, I am currently leaning towards rejection.\n\nAfter the responses of the authors, I have increased my score to a 6.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_u8oJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_u8oJ"
        ]
    },
    {
        "id": "ncO085tqhI",
        "original": null,
        "number": 4,
        "cdate": 1666895015076,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666895015076,
        "tmdate": 1666895159607,
        "tddate": null,
        "forum": "ltCuqJpZl7S",
        "replyto": "ltCuqJpZl7S",
        "invitation": "ICLR.cc/2023/Conference/Paper1991/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes a new dynamical system (continuous dynamics) where the players follow  a gradient ascent style dynamics per player but in order to adapt fast to their opponents, each player assumes that all the other players follow their best-response in its own strategy. At the same time, best-response would evolve as a functional with a gradient descent dynamical system.\nThe strategy profile and best-response functions are trained simultaneously, with the former trying to minimize exploitability while the latter try to maximize it. They evaluate our method on various continuous games, showing that it outperforms prior methods.",
            "strength_and_weaknesses": "In my humble opinion, this work is very incremental for the current venue. Since I want to give always the right of uncertainty, I will be really happy to read the answer of the authors in my objections.\n\nFirst of all, the continuous dynamics may hide certainly the actual complexity of the problem since it could run in exponential time. Secondly, I don't understand how much easy is to compute the best-response at every round when I have multiple players ( I refer to the case where strategies belong to some convex sets, like simplex). It is not clear, if best-response for the case of multiple players correspond to the product of constrained sets (Nash equilibrium style) or in general optimization framework (Coarse Correlated Best Response style). Thirdly, how we are sure that the BR functional is continuous, smooth differentiable ? \nHow much easy is to compute such a Best-response for a given strategy? If we use an Poly TM to compute it, why this is differentiable?\n\nAdditionally, I don't understand the intuition about the descent in the functional. Can you explain me where the concept of 'exploitability' is hidden in this setting?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: In order to increase my score, I would strongly request from the authors to explain (step-by-step) the formulation of \"full-fledged\" model. Why it is well-defined? Why this is not a Stackelberg case follower framework?\n\nQuality: Mediocre.\n\nNovelty: Incremental (See above)\n\nExtra comment: Optimistic Dynamics are dated by Popov et al and not Daskalakis et al.",
            "summary_of_the_review": "In this work, the authors propose a new method for equilibrium finding based on the idea of learned best-response functions.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Non applicable",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_5nGD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1991/Reviewer_5nGD"
        ]
    }
]