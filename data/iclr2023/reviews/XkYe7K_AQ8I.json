[
    {
        "id": "L5XfEQq6KnG",
        "original": null,
        "number": 1,
        "cdate": 1665662657954,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665662657954,
        "tmdate": 1665662657954,
        "tddate": null,
        "forum": "XkYe7K_AQ8I",
        "replyto": "XkYe7K_AQ8I",
        "invitation": "ICLR.cc/2023/Conference/Paper4311/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a model for Time Series Classification (TSC).\nThe model is made of two parts: first an encoder is trained to extract interpretable features using a VQ-VAE strategy and second, a classification head builds n-grams (in practice unigrams and bigrams) and performs regularized logistic regression on the histograms of n-grams.\n\nThe model is evaluated in terms of accuracy, transferability and interpretability.",
            "strength_and_weaknesses": "* Strengths:\n    * The paper deals with an important topic (interpretability in Time Series Classification)\n    * The overall idea to rely on unsupervised feature extraction to improve on transferability is interesting\n* Weaknesses\n    * The presentation of the state-of-the-art misses important work on the topic of interpretable time series classification\n    * The conducted experiments are not sufficient to convince the reader that the method is a good pick for transfer learning or interpretable TSC\n\nThese items are discussed in more details in the following.\n\n1. Literature review\n\nThe overall claim of the paper is that the proposed model leads to improved performance on interpretability and transfer learning.\nIn order to support this claim, a more thorough study of the literature on the topics would be necessary, in order to position the proposition wrt previous work.\n\n* One could cite:\n    * on interpretable TSC:\n\n        1. Fang et al. Efficient Learning Interpretable Shapelets for Accurate Time Series Classification (ICDE 2018)\n        2. Wang et al. Adversarial Regularization for Explainable-by-Design Time Series Classification (ICTAI 2020)\n\n    * on transfer learning for time series:\n    \n        3. Wilson et al. Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data (KDD 2020)\n\nAnd it would be helpful to use these works as baselines whenever possible on the interpretability / transferability experiments to showcase the potential superiority of the proposed method.\n\n2. Experiments\n\n    1. Evaluation of interpretability\n        * Here, interpretability is evaluated on a single example with no baseline, which makes it hard to evaluate the performance of the method in general.\n\n    2. Problems with the experimental setting:\n\n        > the unsupervised architecture is trained for the different possible time-scale reductions on the whole dataset (p.6)\n\n        * This will result in unsupervised representations that might overfit the test data, hence impair the overall evaluation\n\n        * Also, I do not understand why the related hyper-parameter $K$ is not discussed in Section 4.1.1, as it seems to be an important hyper-parameter for the method. In Figure 3, it seems that $K$ is chosen smaller for the top-scale codebook, why is that? (or did I misunderstand something?)\n\nSome additional minor comments:\n\n* Eq3 : the argmin should be over $\\mathbf{w}, b$ I guess\n* The following text appears twice in the same paragraph\n\n    > Table 2 shows the transfer accuracy for datasets where the time series are composed of 80-time steps. For more results, see Appendix A.6\n* In Section 4.3, by \"codebook length\", I guess the authors mean \"codeword length\". \"codebook length\" is misleading since it could correspond (or, at least, in my mind it does) to the number of atoms (codewords) in the codebook",
            "clarity,_quality,_novelty_and_reproducibility": "The method is rather clearly described, and Figure 1 helps to grasp the different parts of the model.\nIn terms of reproducibility, please refer to the discussion above on my concerns regarding the experiments.",
            "summary_of_the_review": "Though this paper tackles an interesting problem, my opinion is that the model is not especially novel (made of two standard blocks). \nThis would not be a problem if the experiments proved the superiority of the method wrt baselines but there are limitations in the conducted experiments that make the overall contribution too narrow.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_znQo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_znQo"
        ]
    },
    {
        "id": "COxSb_x6vJ",
        "original": null,
        "number": 2,
        "cdate": 1666579541000,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666579541000,
        "tmdate": 1666579541000,
        "tddate": null,
        "forum": "XkYe7K_AQ8I",
        "replyto": "XkYe7K_AQ8I",
        "invitation": "ICLR.cc/2023/Conference/Paper4311/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an interpretable representation learning method to extract features from time series and use them for the classification task. The authors borrow the idea from unsupervised autoencoder, vector quantization, multi-level encoding and interpretable probing tasks. Joint learning with decoding recovery loss plus losses associated with the codebook, lead to a feasible and stable training framework for representation learning in time series. The author claims such scheme offers interpretable features from encoding, and can be used in time series classification and transfer learning tasks.",
            "strength_and_weaknesses": "Pros:\n1. The interpretability in time series feature extraction, is largely of interests to the community.\n2. The paper is well written and easy to follow. The description of the complete system including the probing logistic regression task, is clear to understand. The Figure 1 helps a lot.\n3. The details of practical tricks including stop-gradient, the regularizer to stabilize training, etc, are provided.\n\nCons:\n1. The property \"we intend two identical elements of the representation to be decoded as the same pattern regardless of their position\", is not equivariance, but invariance. Equivariance requires a transformation in the input leads to a similar transformation in the output, e.g. x -> f(x), x+d -> f(x)+f(d). What described here is time-invariance or stationary process.\n2. The interpretability claim is very handwaving. From the example showed in Figure 4, one can easily detect the peak value difference from the original time series (left two figures). And shapes are also similar in the original series. The feature only verified this. To provide a more conniving example, the author should use some examples that is very hard to differentiate from the original time series, but easy to detect in the feature space, and the features (at least part of them) have a clear physical meaning for human to understand.\n3. The final performance is not as good as other TSC baselines.\n4. The transfer learning task does not have baselines to compare, thus hard to judge the value.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, with enough details and code to reproduce. The idea is novel in the time series classification domain.",
            "summary_of_the_review": "Overall, given the fact that the proposed method is not competitive to other existing methods, and the important claim of interpretability is handwaving and vague, I feel there is lots of rooms to improve this paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_icKJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_icKJ"
        ]
    },
    {
        "id": "0XpqaesS2Wo",
        "original": null,
        "number": 3,
        "cdate": 1667162757097,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667162757097,
        "tmdate": 1667162757097,
        "tddate": null,
        "forum": "XkYe7K_AQ8I",
        "replyto": "XkYe7K_AQ8I",
        "invitation": "ICLR.cc/2023/Conference/Paper4311/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a neural network based approach for managing the so called tradeoff between interpretability and accuracy in timeseries data by learning a dictionary of discrete representations. They guarantee that 1) only a small number of patterns that can be visualised easily are learnt 2) training a linear classifier over a limited number of patterns provides a more explainable decision 3) a shift equivalence property of the model that is associated with a time consistency of the representation.",
            "strength_and_weaknesses": "The authors try to tackle an important problem and provide some examples of how it works in multiple experimental domains.\n\nThe paper has several weaknesses. \n\n1) The authors never make it clear what they mean by interpretability in this particular context. Yet interpretability is inherently tied to the downstream task so its difficult to understand what any guarantees really mean here. Do the authors mean sparsity? Are sparse models all interpretable? What happens if the features themselves are not interpretable eg pixels in an image?\n\n2) The authors are missing several important contributions to understanding timeseries data. For example, Wu et al 2022 (see thesis https://dash.harvard.edu/handle/1/37371748) present a way of understanding and summarizing the crucial aspects of a time series using concepts. How does the proposed approach of learning a discrete dictionary compare to the idea of using concept bottleneck models to summarize important parts of the time series\n\n3) The biggest weakness is the lack of convincing application in the experiments section. The authors use the UCR dataset and explicitly state that validation is an issue because of lack of sample size so they instead focus on the sets of reasonable size yet not many details are provided about this. How long are the time series? How does performance vary over varying length of time series? If you learn a poor yet interpretable representation of the time series at a particular point, does it compound throughout the time series?\n\n4) The authors talk about the accuracy vs interpretability tradeoffs. I would like the authors to rethink that statement in light of this fantastic paper https://www.nature.com/articles/s42256-019-0048-x\n\n5) It is unclear how the approach generalizes across different applications and modalities of data.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall approach has promise but there are too many unanswered questions and parts that are either poorly explained or lack clarity or adequate comparisons. I also dont understand what makes the proposed approach particularly novel.",
            "summary_of_the_review": "The overall approach has promise but there are too many unanswered questions and parts that are either poorly explained or lack clarity or adequate comparisons. For this reason I am rejecting the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_5jZC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4311/Reviewer_5jZC"
        ]
    }
]