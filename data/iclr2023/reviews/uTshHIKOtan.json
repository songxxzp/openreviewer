[
    {
        "id": "uL52zGBAnt",
        "original": null,
        "number": 1,
        "cdate": 1666535972460,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666535972460,
        "tmdate": 1666536050271,
        "tddate": null,
        "forum": "uTshHIKOtan",
        "replyto": "uTshHIKOtan",
        "invitation": "ICLR.cc/2023/Conference/Paper4519/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents an approach for self-supervised training of Transformers based on the idea of masking and predicting. Two objectives have been utilized during the training process. One is patch reconstruction and the other one is named \"patch concept classification\" to learn different concepts/classes for data tokens. The results of the paper on downstream tasks show some improvements compared to some of the existing approaches.",
            "strength_and_weaknesses": "Strength:\n\t- A set of experiments have been conducted to demonstrate the effectiveness of the approach compared to some baselines.\n\nWeaknesses:\n\n1-  My main concern about this submission is the lack of novelty and proper comparison to SOTA. Recently, there are a bunch of well-known works existing in the literature with the same idea of self-supervised training of Transformers with masking and prediction. While I can see some discussions for BEiT and MAE, I can see only a footnote about iBOT as a very similar approach published in ICLR 2022 and almost no comparison with iBOT and BEiT in the experiments. These two approaches are very similar to the proposed one and there are only differences in defining tokenizer. I am not fully convinced by the note that the authors mentioned in the footnote about iBOT that it focuses on learning a dominant concept. I would like to see detailed discussions, experiments and proper comparisons to show the differences between the proposed and existing approaches.\n\n2-  Comparisons on the object detection and semantic segmentation downstream tasks are not provided while the paper claims that the proposed approach would learn all semantic concepts in an image. This claim can be evaluated better on dense prediction tasks. Most of the existing approaches with the same idea such as MAE, iBOT, and BEiT have been evaluated on dense prediction tasks as downstream tasks.\n\n3- I need more clarification on the \"Patch Concept Learning\" objective while we are feeding the image and its corrupted version to student and teacher networks. To me, it makes more sense if we learn the concept by feeding two different augmented views to the student and teacher and not the same view. This task to me seems like a trivial task at least for those patches which are not masked and are exactly the same for two networks. I would like the authors to clarify this in more detail.\n",
            "clarity,_quality,_novelty_and_reproducibility": "To me, the method is not novel enough and there are not a sufficient set of experiments to show the differences with the existing approaches.\n The implementation details are provided for the approach and it follows the same strategy as the existing approaches such as DINO, MAE, etc. I think that the method would be reproducible. ",
            "summary_of_the_review": "While there have been efforts to develop an idea for self-supervised pre-training of Transformers and evaluate it, however, there are some missing experiments that are very important to find out the benefit of this approach compared to the existing approaches in the literature. In my opinion, the paper needs major revision to fill those gaps I mentioned in the weaknesses.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_rsxz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_rsxz"
        ]
    },
    {
        "id": "MkVa0KDbY8K",
        "original": null,
        "number": 2,
        "cdate": 1666600812256,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666600812256,
        "tmdate": 1666628064137,
        "tddate": null,
        "forum": "uTshHIKOtan",
        "replyto": "uTshHIKOtan",
        "invitation": "ICLR.cc/2023/Conference/Paper4519/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper claims to achieve multi-concept learning without dependency on human annotation by applying two patch-level loss simultaneously, including the patch reconstruction loss from SiT and the self-distillation loss from DINO. Extensive experiments and visualizations demonstrate the effectiveness of the proposed method MC-SSL.",
            "strength_and_weaknesses": "- Strength:\n  - This paper organizes well with clear motivation and detailed experimental results.\n  - The paper also explores the usage of popular self-supervised methods on data-scarce situations.\n\n- Weakness:\n  - Novelty is limited, especially compared with iBOT [1], which is published in ICLR 2022.\n    - According to Table 5, the MC-SSL framework is exactly the same with iBOT combined with an extra auto-encoding reconstruction loss proposed by SiT.\n    - According to the footnote in Page 6, the authors claim that the problem of iBOT is the usage of a global DINO head - \"iBot focuses on learning a dominant concept via the classification token with DINO loss and hence, models the dominant class, which we think is a limitation of existing SSL methods.\", which, however, is also used in MC-SSL according to Table 5. It seems that the multi-concept learning ability mainly comes from the usage of the reconstruction loss of SiT.\n    - As iBOT is such an important baseline, it is not included in any of the experiments in Sec. 4.\n    - The idea of combining reconstruction loss with patch-level contrastive learning has also been explored by some recent works [2,3].\n  - Another important property of MC-SSL is the ability to learn multi-concept without annotations:\n    - Different from [4, 5] which explicitly mine inter-image variance and invariance with K-means, MC-SSL only adopts two patch-level loss, which models inter-image variance and invariance in an implicit way (i.e., the intuition in Sec. 3.2). I wonder how an implicit way can achieve a better results than the explicit solutions in [4, 5]? Could you give more explanations about this problem?\n    - It would be more interesting to report some numeric results to support the so-called multi-concept learning ability, like performance of unsupervised semantic segmentation.\n\n\n\n[1] Zhou J, Wei C, Wang H, et al. ibot: Image bert pre-training with online tokenizer[J]. arXiv preprint arXiv:2111.07832, 2021.\n\n[2] Dong X, Bao J, Zhang T, et al. Bootstrapped Masked Autoencoders for Vision BERT Pretraining[J]. arXiv preprint arXiv:2207.07116, 2022.\n\n[3] Tao C, Zhu X, Huang G, et al. Siamese Image Modeling for Self-Supervised Vision Representation Learning[J]. arXiv preprint arXiv:2206.01204, 2022.\n\n[4] Chen K, Hong L, Xu H, et al. Multisiam: Self-supervised multi-instance siamese representation learning for autonomous driving[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 7546-7554.\n\n[5] H\u00e9naff O J, Koppula S, Shelhamer E, et al. Object discovery and representation networks[J]. arXiv preprint arXiv:2203.08777, 2022.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "There is self-contradiction in this paper draft. Check the weakness part for more details.",
            "summary_of_the_review": "This is overall an interesting paper. However, the discussions can not be fully supported by the experiments. Furthermore, there exits self-contradiction and remaining unclear explanations in this paper draft version. I would like to see the author responses for more discussions.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_85mW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_85mW"
        ]
    },
    {
        "id": "8L2M9vrDUR",
        "original": null,
        "number": 3,
        "cdate": 1666627105941,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627105941,
        "tmdate": 1666627105941,
        "tddate": null,
        "forum": "uTshHIKOtan",
        "replyto": "uTshHIKOtan",
        "invitation": "ICLR.cc/2023/Conference/Paper4519/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces the MC-SSL method for self-supervised learning aimed at learning multiple concepts in images. It applies mainly two algorithmic techniques: Group Mask Model Learning (GMML) and learning of pseudo-concepts for data tokens using a momentum encoder framework. The paper is clear and interesting. The approach is novel and the results are good. ",
            "strength_and_weaknesses": "Clear and nice paper. I think the presentation was sometimes slightly too high level. I'd like to see just a few more equations around the approach, and some clearer definitions. \n\nSome other feedback:\n* Figure 1 needs to be explained more, how many clusters were used etc, difference between second and third row.\n* \"they tend to encourage modelling of one dominant class per image using holistic representation and/or disregard the learning of contextual representations\" where is the support of this claim? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clear, high quality paper. It's novel and useful for the community. Understanding and improving on the differences in what SSL models learn is important as SSL is becoming more and more ubiquitous. I see no code in supplementary material, which is a big drawback in such an empirical work. ",
            "summary_of_the_review": "Strong paper with a novel technique (the aspect of pseudo-concepts on patch level) that's interesting and with great results. Given that this is an empirical paper, I believe code should be attached for reproducibility. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_7m1Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_7m1Z"
        ]
    },
    {
        "id": "HnI8ZUGBQD",
        "original": null,
        "number": 4,
        "cdate": 1667157971607,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667157971607,
        "tmdate": 1667157971607,
        "tddate": null,
        "forum": "uTshHIKOtan",
        "replyto": "uTshHIKOtan",
        "invitation": "ICLR.cc/2023/Conference/Paper4519/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces an SSL framework that is capable of learning different concepts in an image while the previous studies can only capture the dominant concepts. To this end, they proposed MC-SSL based on the components from SiT and DINO, i.e., Group Mask Model Learning (GMML) and Patch Concept Learning (PCL) based on knowledge distillation. In their evaluations, they demonstrated that MC-SSL can perform well with small datasets in multi-class and multi-label downstream tasks. Overall, this is an interesting work with some promising results. ",
            "strength_and_weaknesses": "Strength:\n- This work demonstrated its ability to differentiate concepts learned from images on small datasets while the majority of related works can only identify the dominant concepts from data.\n- This framework avoids the common practice of using a large batch size for training in contrastive learning-based SSL frameworks, while still achieving relatively good performance.\n- The authors conduct extensive experiments on multi-class and multi-label downstream tasks to demonstrate the effectiveness of the proposed framework in two settings.\n- The results of visualized self-learned concepts are quite impressive and promising.\n\nWeaknesses: \n- The authors claim that their methods work well with small datasets. I am curious as to why not directly use smaller transformer models for these small datasets. How do the authors argue that these improvements indeed are from the proposed MC-SSL rather than related baseline approaches that are not well-trained?\n- The notation of shared weights for prediction heads in Figure 2 is somewhat unclear. How exactly does each component share these weights?\n- For the ablation studies, I am concerned about the 10% subset of ImageNet. The construction details of this dataset are missing. For example, a biased sampling strategy could cause the model to favor certain tasks or approaches downstream. This requires some clarification.\n- How are the different approaches in Table 1 evaluated? Similarly, what trained models are used for Figure 1's visualization? This requires clarification. In addition, I wonder if we feed more data and train longer for the baselines, are they able to capture different concepts? Alternatively, the authors may want to show some learning curves to illustrate this.\n- The presentation of this paper should be improved. For instance, the authors may want to highlight their most significant contributions or discuss the most significant differences between their works and those of SiT or DINO. Other minor issues: \"our thesis is...\" should be replaced with \"our hypothesis is...\". These notations should be consistent with \"Dino \u2192 DINO\".\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThis paper proposed an interesting SSL framework and presented some encouraging results regarding the learning of various concepts via their framework. However, there are still missing details regarding how the different methods are being evaluated, as well as some empirical evidence and discussion that their framework is truly capable of capturing concepts from images in various settings. In addition, the presentation and structures should be improved so that the readers can easily follow.",
            "summary_of_the_review": "Please check the strength and weaknesses for detailed comments. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_YV5g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4519/Reviewer_YV5g"
        ]
    }
]