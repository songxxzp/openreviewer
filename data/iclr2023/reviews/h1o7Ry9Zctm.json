[
    {
        "id": "dkwMiyZx6d",
        "original": null,
        "number": 1,
        "cdate": 1666681333121,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681333121,
        "tmdate": 1666681333121,
        "tddate": null,
        "forum": "h1o7Ry9Zctm",
        "replyto": "h1o7Ry9Zctm",
        "invitation": "ICLR.cc/2023/Conference/Paper4829/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper discusses the semantics-preserving adversarial attack in graph. Based on CSBMs, the constructed graphs show over-robustness of GNNs. The authors also prove that GNN+LP could be one way to reduce the over-robustness.",
            "strength_and_weaknesses": "S1: Revisiting classic graph adversarial attacks from a semantic-preserving angle is novel and interesting.\nS2: This paper leverages the synthetic graphs based on CSBMs and Bayes classifiers as reference classifiers to formulate the concept of over-robustness if the perturbation unnecessarily changes the semantics.\nS3: The robustness-accuracy tradeoff is also discussed in inductive settings based on the constructed graphs and reference classifiers.\n\nW1: Some works which propose the notion of unnoticeable perturbations mentioned in Introduction lack further comparison in the following part of this paper. whether these unnoticeable perturbations are semantic-preserving or not is unknown, at least from an experimental perspective.\nW2: It would be better if more realistic datasets are discussed in this paper. Besides, when the CSBMs violates the real graph construction also needed more discussion.\nW3: The attack algorithms used in the Results sections are targeted attacks. I wonder whether the untargeted attack like MetaAttack will also cause the same over-robustness.\nW4: There are some typos in this paper, e.g., structure using is miswritten as structureusing in page 1, APPNP has no reference in page 6 section 5.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The formulation and theoretical analysis of the semantic-preserving perturbations in graph adversarial attack is carefully defined and the proofs of the robustness-accuracy trade-off is clear. The notion of semantic-preserving for common graph adversarial attacks is novel. Moreover, the experimental setup is provided in Appendix for better reproducibility. ",
            "summary_of_the_review": "The concept of semantic-preserving perturbation and over-robustness of GNNs are interesting and attractive. The theoretical analysis based on these concepts is also sufficient. However, the authors lack more discussion with the unnoticeable perturbations mentioned in Introduction and the attack algorithm set in the experiment is relatively small.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_b2Ux"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_b2Ux"
        ]
    },
    {
        "id": "Is3unQQpkn5",
        "original": null,
        "number": 2,
        "cdate": 1666693440904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693440904,
        "tmdate": 1666767356501,
        "tddate": null,
        "forum": "h1o7Ry9Zctm",
        "replyto": "h1o7Ry9Zctm",
        "invitation": "ICLR.cc/2023/Conference/Paper4829/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors introduced a principled notion to be aware of semantic content change of an adversarial graph by  Contextual Stochastic Block Models (CSBMs). The experimental results showed for a majority of nodes the prevalent perturbation models include a large fraction of perturbed graphs violating the unchanged semantics assumption and all assessed GNNs show over-robustness - that is robustness beyond the point of semantic change. ",
            "strength_and_weaknesses": "Strength:\nThe authors revisted the robustness of graph neural network, and proposed a method to detect the semantic content change of an adversarial graph, which is interesting and meaningful. The presentation is good, and easy to follow. The experimental results demonstrated the effectiveness of the proposed method.\n\nWeakness:\n1) It is expected to give more details about Figure 1.\n\n2) There are two many symbols in the paper. I suggest the authors give a table to summary these symbols for reader understanding.",
            "clarity,_quality,_novelty_and_reproducibility": "The idea of this paper is novel. It is a nice work.",
            "summary_of_the_review": "I incline to accept this paper, because of its novelty.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_2ZaK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_2ZaK"
        ]
    },
    {
        "id": "8BiyBseD8X6",
        "original": null,
        "number": 3,
        "cdate": 1666696131959,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696131959,
        "tmdate": 1666698590710,
        "tddate": null,
        "forum": "h1o7Ry9Zctm",
        "replyto": "h1o7Ry9Zctm",
        "invitation": "ICLR.cc/2023/Conference/Paper4829/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the robustness of machine learning models for node prediction problems. It is well-known that GNN models are sensitive to small perturbations in the graph structure. However, it is difficult to justify which perturbations are semantically-preserved for graph-like input (which is easier for images as humans are often considered robust judgers). The authors used CSBMs to generate synthetic graphs with which the optimal Bayes classifier is derivable and then used it as the reference classifier for semantic changes. Using the Bayes classifier, the authors introduce a notion of over-robustness: the prediction of the studied classifier is not changed for a perturbed graph (which is generally known as adversarial robustness), but the prediction of the reference classifier does. They then showed that there is no inherent trade-off between semantic-aware robustness and test accuracy, similar to Suggala et al. (2019) work. Empirically, they show that most GNN models suffer from over-robustness, and using Label Propagation on top of GNNs does alleviate them.",
            "strength_and_weaknesses": "Overall, the results of this paper could bring more insight into the current understanding of adversarial robustness for GNNs. The main result that indicates no robustness-accuracy tradeoff for inductively classifying a newly added node is interesting, even though a similar result is introduced by Suggala et al. (2019). This work focuses on non-i.i.d data instead of i.i.d. data in Suggala et al. \n\nThe study of over-robustness seems to be appealing. However, there is a concern about its practicality, as it requires the optimal (reference) classifier. Most of the analyses in this paper are on synthetic graphs. The results in Section 5.2.1 are not very significant to me. The authors should discuss how over-robustness could be avoided in real-world applications.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Generally, this paper is well-polished and easy to read. \n\n- In the Introduction, Paragraph 2, the authors should elaborate more on the reasons other notions of perturbation sets (degree assortativity, other homophily metrics) are not semantically preserved.\n- Section 5.2: the authors examine the over-robustness for \\mathcal(B)_deg only. It would be nice to see the results with other perturbation radii.\n- Page 8: The reason MLP provides an upper bound on the over-robustness for a particular K is unclear to me.\n- The experiments should include other perturbation sets such as using degree distribution (Zugner et al. 2018) or degree assortativity (Li et al. 2021).\n\n\nMinor comments:\n- Legends of Figure 3 is not indicating dash lines.\n- Citation error in paragraph 4, page 6.\n",
            "summary_of_the_review": "My initial impression of this paper is positive; thus, I lean towards acceptance of this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_bUiK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4829/Reviewer_bUiK"
        ]
    }
]