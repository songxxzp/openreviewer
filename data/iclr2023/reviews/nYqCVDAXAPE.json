[
    {
        "id": "SUZVKukYIy",
        "original": null,
        "number": 1,
        "cdate": 1666584742171,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666584742171,
        "tmdate": 1666587493102,
        "tddate": null,
        "forum": "nYqCVDAXAPE",
        "replyto": "nYqCVDAXAPE",
        "invitation": "ICLR.cc/2023/Conference/Paper750/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper aims to propose two architectural contributions and a new task for semantic audio-visual embodied navigation. \n\nThe paper first employs a knowledge graph for encoding object-object, object-region, and region-region relations. Then, the paper introduces multiple auxiliary models to facilitate audio-visual embodied navigation. \nFurthermore, the paper proposes a new task of semantic audio-visual embodied navigation. In the new task, the agent is designed to steer toward an object without unheard sound.\n\nThe paper also demonstrates performance improvements in all permutation of settings, ie., seen/unseen houses with heard/unheard sounds.\n",
            "strength_and_weaknesses": "Pros: The paper demonstrates the overall architecture clearly in Figure 2.\n\nCons: \n- It is hard for readers to catch up on the key points of the paper. Since almost every subsection only contains one long paragraph, readers might fail to understand the meaning.\n- The paper claims to introduce pre-defined semantic information to encode object-object relationships. However, in ICLR 2019, [1] proposed a scene prior graph learned from Visual Genome dataset. It would be helpful if the author could provide a comparison between the proposed semantic information with the semantic knowledge learned in ScenePriors [1].\n- The second contribution of the paper is to establish object-object, object-region, and region-region relationships via a knowledge graph. However, in ICLR 2021, [2] proposed a transformer-based architecture to encode similar relationships in visual navigation. The author first misses this reference and second lacks the difference with VTNet [2] in building the aforementioned relationships. \n- The paper does not provide convincing analysis for some ablation experiments. For example, in both SH/HS and UH/HS, introducing $GEN^b$ alongside $GEN^v$ will lead to a performance drop compared with only adopting $GEN^v$. Could the author provide some extra explanation for these results?\n- Furthermore, it is hard for me to understand why the performance of GEN^s is lower than that of $GEN^b$ in both SH/US and UH/US settings. Could the author please provide more experiments for readers to understand these experiment results?  \n\n\n\n[1] Yang, W., Wang, X., Farhadi, A., Gupta, A., & Mottaghi, R. (2018). Visual semantic navigation using scene priors. arXiv preprint arXiv:1810.06543.\n\n[2] Du, H., Yu, X., & Zheng, L. (2020, September). VTNet: Visual Transformer Network for Object Goal Navigation. In International Conference on Learning Representations.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity & Quality:\n- The paper is a little bit hard to understand and needs more effort in organizing the structure. \n- More analysis for ablation studies are necessary.\n\n\nNovelty:\n- The paper does not provide clear and detailed explanations for the novelty of some contributions.\n- The new audio-visual navigation task is novel, while the new task does not seem to match with other contributions. \n",
            "summary_of_the_review": "Overall, the paper raises a novel audio-visual navigation task with unheard sounds. However, the other three contributions need more explanations to justify their novelty.\n\nI lean toward rejecting the current version. However, if the author persuades me that all these three contributions are meaningful, I would like to modify my recommendation to be above the acceptance threshold.\n\nBesides the review for this paper, I believe that this kind of open-set setting is interesting and will definitely benefit our community. However, the goal of raising a new task is not because it is a new task. **In my opinion, the goal should be to provide more insights or chances for the community members.** To achieve that, I recommend the author to think questions about some specific problems in open-set tasks and designing methods following corresponding motivations. At final, I hope to see the edited paper in the future.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper750/Reviewer_8Qq6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper750/Reviewer_8Qq6"
        ]
    },
    {
        "id": "HrPZzrbdkVJ",
        "original": null,
        "number": 2,
        "cdate": 1666654222392,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666654222392,
        "tmdate": 1666654222392,
        "tddate": null,
        "forum": "nYqCVDAXAPE",
        "replyto": "nYqCVDAXAPE",
        "invitation": "ICLR.cc/2023/Conference/Paper750/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies the Semantic Audio-Visual Navigation (SAVi) and proposes the use of Knowledge-driven scene priors for encoding the object-region relations, spatial knowledge, and background knowledge to address the embodied navigation problem. The method named K-SAVEN incorporates graph encoder networks to model audio and visual inputs, as well as applies scene memory transformer to capture long-term visual-audio dependencies. Numbers of pre-training tasks are defined, and a multimodal dataset is curated to support the learning. Moreover, a new SAVi task is defined to evaluate the agent performance on novel objects and sounds. ",
            "strength_and_weaknesses": "Strengths:\n\n1.\tThe paper proposes novel and effective methods and defined a valuable task to address SAVi, which will be highly beneficial to future research in relevant directions. The use of knowledge graph to connect sounds, objects and regions could be an important step towards generalizable audio-visual navigation in novel environments. Results show significant improvement over previous approaches. Moreover, the new task offers a setting for evaluating the agent\u2019s generalization ability on novel objects (and sounds).\n\n2.\tIt is great to see the comprehensive details presented in the method section and the Appendix, e.g., the knowledge graph construction and representation, including the resultant graphs in Table 3 and Table 4.\n\n3.\tOverall, the paper is clearly presented.\n\nWeaknesses:\n\n1.\tIt is wonderful to see the new experiments added to this paper, but they can go deeper. Since knowledge graph is the key novelty, I expect more experiments on using the knowledge and the graph construction (e.g., the source and type of knowledge, the connection between objects and regions, etc.). Although this work is built based on SAVi and several methods are inherited, it will be valuable to see the influence of the pre-training and classification tasks in the proposed architecture. Moreover, it would greatly strengthen the paper if the method is evaluated on more dataset such as Replica and compare with the baselines.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, figures and tables are clearly presented. The proposed methods such as knowledge graph, local prediction and direct-to-reverberant ratio estimation are novel in addressing the SAVi problem. The new task supports a more comprehensive and meaningful evaluation of the agent\u2019s performance, which should be beneficial to future research. The authors have stated to release the code and data upon acceptance, which I believe the reproducibility of this work is promising.",
            "summary_of_the_review": "This is the second time that I review this paper. Comparing to its previous ICLR and CVPR versions, it is great to see manuscript has been significantly improved and most of my previous concerns are nicely addressed, especially the new experiments in Table 1 (top), Table 2, and Table 7 are added to justify the method and designs, as well as the insightful analysis section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper750/Reviewer_tJCa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper750/Reviewer_tJCa"
        ]
    },
    {
        "id": "YHdY1hBIsZ",
        "original": null,
        "number": 3,
        "cdate": 1666657168456,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657168456,
        "tmdate": 1669008857975,
        "tddate": null,
        "forum": "nYqCVDAXAPE",
        "replyto": "nYqCVDAXAPE",
        "invitation": "ICLR.cc/2023/Conference/Paper750/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a new kind of audio-visual navigation task which requires agent to generalize to novel audio sources in 3D indoor environments from the Matterport dataset. The proposed approach leverages multiple sources of information of which objects the source is likely coming from, where they might be found, and where the source might be present in the house to tackle the task. In experiments, they show that the proposed approach significantly outperforms existing methods on unseen houses, unheard sounds. \n",
            "strength_and_weaknesses": "Strengths: \n- The task definition is interesting. Generalizing to unheard sounds is an interesting split to look at, and I am glad that this is being looked at. \n\n- The proposed approach is somewhat intuitive and seems to work well, specially on unheard sounds. \n\nWeaknesses: \n- It's not clear if the pre-training happened on all sources of sounds (seen and unseen). The formulation seems to suggest that the audio classification model was trained on all sources (seen and unseen). I think this is a bit problematic, since it makes the assumption that at test time, no novel sound source will exist. \n\n- If the pre-training involved both seen and unseen sources, then comparison with SAVI is unfair because SAVI presumably didn't have access to these sounds. \n\n- It'd be nice to show results for classification models apart from navigation results. These will help the readers understand how classification accuracy correlates with navigation accuracy. \n\n- I also think it'd be nice to replace certain parts of the model with \"oracle\" modules. For instance, if the audio classification model, or the location prediction model was perfect, how will the performance get affected. Doing these sort of analyses helps build a much stronger intuition for the task.",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paper can be clearer. There are certain mistakes -- for example, in figure 2 (b), they have GCN, but figure 2(a) have GENS. The approach was also quite hard to follow. More importantly, what do the authors mean by unheard sounds is not clear until the very end. ",
            "summary_of_the_review": "The task is interesting, and the approach is intuitive. But, I think the paper is also missing certain analyses (classification model performance, ablations by replacing with oracle modules) that will further strengthen the paper. \n\nUpdate after rebuttal: I thank the authors for providing responses to all my concerns and the experimental results for Oracle modules. I am tending towards acceptance for the paper. I am hesitating to give a strong accept is because I would have liked to see experiments where *not all sounds* are heard during the pre-training stage. Since they are building a new benchmark, it'd be nice to push the limits a little bit more and cover the case where a truly novel sound source is present during test stage. For that reason, I am only updating the score to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper750/Reviewer_djj6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper750/Reviewer_djj6"
        ]
    }
]