[
    {
        "id": "OGZHa8ZqUb",
        "original": null,
        "number": 1,
        "cdate": 1666275444990,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666275444990,
        "tmdate": 1666275444990,
        "tddate": null,
        "forum": "02Bt_4tx6r",
        "replyto": "02Bt_4tx6r",
        "invitation": "ICLR.cc/2023/Conference/Paper1418/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents a dual-stream transformer architecture using CrossViT of [Chen et al. 2021], trained under a joint adversarial training objective with rotation invariance (imposed by hard rotation-based data augmentation), that achieved the second place in the BrainScore 2022 competition. Authors discuss in depth their optimization design choices empirically to illustrate how their ViT model could achieve high explainable variances in various competition metrics as an analogous model to the biological visual stream. Several ablation experiments with respect to the proposed joint optimization scheme are performed with the same CrossViT backbone, as well as comparisons with vanilla ViT models under the same training objectives.",
            "strength_and_weaknesses": "Strength: The manuscript is written clearly and in an understandable fashion. It achieves SOTA results in several categories at the time of their Brain-Score competition submission, and empirical ablations support their results.\n\nWeaknesses: Currently the paper is restricted to explaining a set of experiments performed in the context of the competition, which appear to be outperformed to date. From a deep learning perspective, the methodological contribution is low since there is no clear architectural or algorithmic novelty proposed. This appears to be the main limitation in my opinion.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Paper is well structured and clearly written. Quality & Novelty: Authors' methodology puts together well-known adversarial training and data augmentation methods together to optimize a CrossViT, which yielded significantly high results in the Brain-Score competition, and the authors attempt to explain this observation. Hence I would say the technical novelty of this paper is limited in that sense. Reproducibility: Sufficient.\n",
            "summary_of_the_review": "I think the paper explores a very interesting problem in depth and demonstrates significant insights as to how simple adversarial training, data augmentation, and vision transformers could be combined to achieve high similarity to the biological visual stream in several metrics of the Brain-Score Competition. However I still believe the paper is not sufficiently strong at this venue without any independent novel methodological contribution. I have some specific questions to the authors summarized below:\n- Explorations on adversarial training and robustness from Section 3.1: It would be reasonable to see the model thrive in more than the Brain-Score competition ranking, when it comes to claims on better adversarial robustness. For instance, to extend simpler PGD-type evaluations in Figure 5, authors could perform evaluations on AutoAttack and demonstrate how their adversarially trained CrossViT ranks in the Robustbench ImageNet category?\n- In a similar vein, were there any explorations on the adversarial training pipeline (FAT, TRADES, standard AT etc.)? Can/did the authors explore alternative AT objectives for their model?\n- How does the adversarially trained VOneNet [Dapello et al. 2020] compare in Figure 5?\n- There have been a significant line of work on exploring adversarially trained vision transformers' generalization capabilities. Can the authors compare their baseline model with some of those?\n- Authors' explorations in Supplementary Section B.1& B.2 are of major importance to the rest of the manuscript, even though the results look unsatisfactory. Their proposed optimization approach significantly hinders out-of-distribution generalization capability of CrossViT under common corruptions (even much lower than the ResNet-50 baseline). A discussion on this should be present in the main manuscript.\n- Minor comment: Figure 8(a) legend is blocking the main results in the plot.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_ywsh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_ywsh"
        ]
    },
    {
        "id": "a3da4vcqsNB",
        "original": null,
        "number": 2,
        "cdate": 1666581253664,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581253664,
        "tmdate": 1670536444710,
        "tddate": null,
        "forum": "02Bt_4tx6r",
        "replyto": "02Bt_4tx6r",
        "invitation": "ICLR.cc/2023/Conference/Paper1418/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors challenge the common notion that transformer-like architecture is not particularly brain-like because, to the best of our neuroknowledge, the self-attention mechanism employed in transformers is not inspired by how the brain works. To that end they pick a few optimization constraints that in the past have shown to increase the Brain-Score (a metric that measures how close a certain ANN model's activity is close to brain activity is in representational space) and train a transformer architecture subject to all these constrains. And, as they discover, when trained like this, a transformer architecture is no worse that other ones, more \"bioplausible\" artificial models of vision and it scores even higher than some architectures that were manually crafted to be brain-like.\n",
            "strength_and_weaknesses": "The narrative of this work has an unfortunate break when the Section 3 starts: the first four pages very clearly outline the premises and ideas of the authors and the scientific question emerges (being something like \"can transformers score high and what would it take and what that would mean\"). In Section 2 the main answer is given -- the fact that properly \"motivated\" transformer scores high on Brain-Score. But the the transition to Section 3 is unclear, it makes the reader feel that Section 3 is where the main results is, while actually Section 3 is a collection of \"optional\" observations. I would recommend to explain *why* you are now going to \"explore how different variations of such CrossViT\u2019s change as a function of their training procedure\" and in each of those sections bring forward what does this analysis do for the main claim of the paper or how does it contribute to the \"brain-likeness discussion\".\n\nCurrently some of the points you make in Section 3 are dangling unconnected to the rest. For example model's ability or inability to classify between 2 classes in original vs texform space. Why is that relevant? Do we (humans) really use texture-like cues to perform object recognition without the need for shapes? I would disagree with that already on the bases of my personal experience -- looking at Figure 6, panel 0, texform insect -- without context I would have never classified that as an insect? I think we (humans) do need the shape quite a lot. So the fact that one model can perform well on textures while another cannot does not convince in that model's brain-likeness.\n\nSection 3.3 feels even more disconnected from the whole brain discussion. It basically just states that transformers have stronger reliance on shape information. Ok, it's a cool fact to know, but how does that connect to the topic of the paper? And how does this finding relate to the one presented in 3.2 where the whole point was somewhat the opposite -- that high Brain-Scoring model can work well in texture-form?\n\nTaken together sections 3.1 to 3.3 take the reader away from the main conversation and into some vague and as it seems irrelevant observations that blur the excitement and clarity of the message in Section 2.\n\nAddressing this broken narrative I think will do a great service to bring forward the numerous strengths of this paper:\n- clear and bold scientific question\n- logical exploration and experimental work to find the answer\n- important message for the bioplausible vision community\n- clear language",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Apart from the detour (in my opinion) in Section 3, the paper is well structured, the ideas and the approach are clearly explained and allow to follow what is being demonstrated and how it was achieved.\n\nQuality: High\n\nNovelty: The topic under investigation is not novel, but the observations and conclusions that are brought forward - are. I think this work has an important place in the discussion about Brain-Score & brain-likeness in the context of artificial models of vision.\n\nReproducibility: The steps taken are clearly described and should be reproducible. Making the code publicly available would be of great help.",
            "summary_of_the_review": "This is an interesting paper and a valuable contribution in that it should spark an important discussion on how should we go about assessing brain-likeness of an ANN architecture. To me the most important message from this paper is, as I've long suspected, that if you fiddle with any architecture long enough then you can make it score high on Brain-Score. We, as a community, should be much more careful when claiming brain-likeness based on Brain-Score, and this paper is an important voice in this discussion.\n\nThe paper is well-written, the experiments support the claims and those claims are important and/or novel.\n\nMy recommendation is to accept this work as I would definitely like to see it presented at the conference.\n\n\n------ UPDATE after having a joint call with other reviewers ------\n\nThe way I understood the main contribution of this work initially was to highlight that with enough effort one can make even a transformer-based architecture to score on brain-likeness test. The main claim of the paper as I saw it then appeared to me something like \"let's not put too much trust in such way of evaluating brain-likeness\".\n\nHowever, after reading the final version and looking at the text with the perspective other reviewers provided, I can see that this is not the main claim of the work and is a secondary message (or, it does not come out of the manuscript clearly enough). The main claim of the work becomes (as the title says) that with a certain set of add-ons a vision transformer scores high. And this, while still curious, to me does not constitute as important of a message as the one above might. In order to advance knowledge in NS this would need to have one step further, to establish a deeper connection between the evaluated add-ons and brain structure/function (and I think it was never the claim that this work advanced the knowledge in ML per se). Leaving us with a set of interesting observations, and the (surprising? or not?) outcome that it scores high on BrainScore.\n\nMy general recommendation is still to accept, but now with a score of 6 instead of 8 (there's no \"7\" available).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not applicable",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_kkk2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_kkk2"
        ]
    },
    {
        "id": "KZO4gV-lEf",
        "original": null,
        "number": 3,
        "cdate": 1666621100732,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621100732,
        "tmdate": 1668967142158,
        "tddate": null,
        "forum": "02Bt_4tx6r",
        "replyto": "02Bt_4tx6r",
        "invitation": "ICLR.cc/2023/Conference/Paper1418/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors test a neural network (NN) architecture based on vision transformers on the brain-score competition. When using adversarial training (gradient attack) and rotated data augmentation, the NN reaches state of the art performance for area V4. In contrast with other best performing models, their model is getting better and better at predicting higher visual area. Then, the authors assess the variation of training to highlight that robustness probably explains the performance ranking of the different training methods. They also draw a parallel peripheral vision to explain specifically the good performance in area V4 and show that their model is invertible. Finally, a last comparison is done against classical vision transformers.",
            "strength_and_weaknesses": "Strength:\n- high performance of vision transformer for predicting neural activity (brain score competition),\n- using an architecture that incorporate biologically plausible features (multiscale, invariance, texture features),\n- an attempt to explain the performances (robustness, texture-like computation, invertibility),\n- include models comparison \n\nWeaknesses:\n- the fact that targeted attacks result in stimuli that are perceptually aligned with human judgement is not supported by any perceptual experiment",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nOverall the manuscript is clear.\n\nIn the abstract : I don't know what is this \"all roads lead to Rome\" argument... The authors should be more specific.\n\nIn section 3.1: Perceptual alignment between an image and the attacked class is unsupported by any data. It is only a qualitative claim from the authors. \n\nIn section 3.2: the relation with peripheral vision, the use of texform stimuli and the reasons why they are used are unclear. The first sentence of the section is misleading as your are not really interested in how well the classes are getting separated when going up in the hierarchy but whether class separation is preserved when using texform (the locally texture-matched version of the image). I think you should start this section with what is stated in the 2nd paragraph (texture-like recognition in human => mid-ventral visual cortex and texture / peripheral vision => robust perception => testing that using natural images and texform and comparing classificiation). \n\nFontsize in figures should be close to the main text fontsize. \n\nFor figure 6: I suggest to use two colors for the two classes (the marker are hard to distinguish and this what is important). You can add a large frame of the right color around each column to highlight the original vs texform stimuli. \n\n\n\nQuality:\n\nGood.\n\n\n\nNovelty:\n\nVision Transformers are not yet widely tested against biological vision datasets.\n\n\n\nReproducibility: \n\nThrough brain-score competition",
            "summary_of_the_review": "Sadly, the brain-score competition is not part of a conference with proceedings... This would be where this paper belongs to.\nI am inclined to accept this paper once the authors have accounted for my comments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_2i2E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_2i2E"
        ]
    },
    {
        "id": "TnfVJmVhkp",
        "original": null,
        "number": 4,
        "cdate": 1666628609382,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628609382,
        "tmdate": 1666791637152,
        "tddate": null,
        "forum": "02Bt_4tx6r",
        "replyto": "02Bt_4tx6r",
        "invitation": "ICLR.cc/2023/Conference/Paper1418/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work shows that a vision transformer (ViT) model is able to achieve higher brain score (i.e. performance at predicting electrophysiology recordings of primates viewing images) than a more \"biologically-plausible\" alternative (a convolutional neural network + a frontal V1-like module), specifically when the ViT is trained with specific training objectives: invariance to rotation and adversarial training. The authors show that each one of these objectives individually contributes to the improvement in brain score. Additionally, this work makes some attempts to study how the representations of the well-performing ViT model change as a function of their training procedure.",
            "strength_and_weaknesses": "Strengths:\n- investigates a timely question of why transformers are so good at predicting brain recordings\n- careful evaluation of the effect of training procedure on the model representations \n\nWeaknesses:\n1. Unclear motivation for the specific investigations of the model representations, which also makes it difficult to know what to takeaway from these investigations. Why were these specific investigations chosen, and what did the authors hope to learn from each of them?\n2. There is also a need to position this work more clearly with respect to the related literature. What aspects of this model are entirely new with respect to evaluating the brain score? Even if the combination of all components is novel (ViT + rotational invariance + adversarial training), were certain components previously investigated and what is the new takeaway from the current work? Also have previous works investigated the effect of these training procedures on model representations?\n3. There are several points in the manuscript where the writing is difficult to follow and/or the claims are not supported by the evidence provided. A few examples: \n- \"interesting question that was one of the motivations of our paper: \"Are Vision Transformers good models of the human ventral stream?\" (how did you plan to answer this question by looking at data from non-human primates?)\n- \"if we find that a specific model yields high Brain-Scores, this may suggest that such a flavor of ViT-based models obey a necessary but not sufficient condition of biological plausibility\" (I do not follow this logic. Perhaps you can conclude something about a sufficient condition, but I do not see anything in the experiments in this work that can suggest a necessary condition for brain alignment) \n- \"we observed that each step independently helps to improve the overall Brain-Score\" (the observation is that each step contributes individually. The authors have not shown that the contributions are independent of each other\n- Fig 3 caption: \"As the average Brain-Score increases in our system, the distortions seem to fool a human as well.\" (is this statement based on actual human experiments or the authors' own feelings?)\n- \"Is this new excel in performance due to their..\" (excel is a verb and not a noun) \n- \"their use has been carefully limited as a model of visual computation\" (what does carefully limited mean?)\n4. Some of the figures are illegible (Fig 1 and 2)",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity can be significantly improves, especially when it comes to providing motivation for the analyses of the model representations and the significance of the findings of these analyses (see above under Weaknesses).\nIt is difficult for me to judge the novelty because the work needs to be better positioned in the related literature.\nThe quality and reproducibility of the work appear to be solid. \n",
            "summary_of_the_review": "While this work investigates an important and timely question of why transformer-based models are so good at predicting brain recordings, it can be significantly improved along several dimensions w.r.t. the motivation of the completed analyses and the significance of the finding, and the relation to other work in this area. In its current form, I do not believe it is ready for publication in a top-tier ML venue. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_84qC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1418/Reviewer_84qC"
        ]
    }
]