[
    {
        "id": "zRGGORS76P",
        "original": null,
        "number": 1,
        "cdate": 1666568328930,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666568328930,
        "tmdate": 1666568328930,
        "tddate": null,
        "forum": "T-qVtA3pAxG",
        "replyto": "T-qVtA3pAxG",
        "invitation": "ICLR.cc/2023/Conference/Paper5210/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of reducing the memory consumption of serving GNN models. In particular, it identifies that some GNN models require node features in the training set data to make accurate predictions, which can add significant memory pressure. To mitigate this issue, the paper introduces VNG, a method that replaces some training nodes with a small set of so-called virtual nodes. By doing so, the total amount of memory consumption for serving GNN is reduced. Evaluation of GCN and several datasets show that the proposed methods can lead to higher accuracy than alternative methods. \n",
            "strength_and_weaknesses": "Strengths:\n- The paper makes some interesting observations that when serving GNN models, nodes in the training sets may still be required, which leads to increased memory consumption. \n- The paper introduces the virtual node set, which decouples the memory consumption of serving GNN from the training node features.\n- Promising accuracy improvements in comparison to alternative baseline methods. \n\t\nWeaknesses:\n- Despite claiming memory is a major bottleneck in GNN serving, most datasets evaluated in this paper are rather small scale, with <500MB of memory consumption except Amazon 2M (<1.2GB), which are much smaller than the DRAM capacity. Also, it does not seem like all training features need to be loaded into DRAM at once, e.g., by loading the testing nodes and their neighbors or by loading a subset of training nodes on the fly, the memory usage can also be reduced. \n- Despite showing accuracy improvement in comparison to baselines created by the authors, the absolute accuracy drop in comparison to the uncompressed GNN is still large. For example, the accuracy drop is around 5 points for Amazon 2M. In practice, it is unclear whether such a huge accuracy drop can justify the compression ratio. Also, would other methods perform better than the proposed method at a higher accuracy target? One suggestion is to decrease the compression ratio to find a configuration that leads to similar or at least within <1% of accuracy loss compared with the uncompressed GNN and then reports the compression ratio the proposed method can achieve. Furthermore, it would be interesting to report under different compression ratios, how the proposed method compares with other alternatives. \n- Lack of comparison with quantization methods. The authors compared many methods, such as pruning and SVD. However, from the reviewer's perspective, one straightforward and also effective compression method is just to quantize the feature vectors,  e.g., basic quantization schemes using an INT8 symmetric quantizer. Would that lead to better accuracy than the proposed method (e.g., at 25% of compression ratio)? \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n- The problem setup and motivation are clear. The paper also provides details about its methodology. \n\nQuality\n- The writing quality of this paper overall is pretty decent and is easy to follow. \n\nNovelty\n- The paper has good discussions in the introduction and related work about its novelty.  Although compression has been an extensively studied topic, compressing the feature vectors for GNN with virtual node sets appears to be novel. \n\nReproducibility\n- The paper does not provide many details about its implementation and hyperparameter settings for most of its configurations, which creates difficulties reproducing its results. \n",
            "summary_of_the_review": "Despite there being some concerns about the evaluation of the proposed methods, I'm overall positive about the paper because of the identification of the challenges of serving GNN models and the promising results of achieving a high compression ratio while obtaining better accuracy than alternative methods. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_LGG4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_LGG4"
        ]
    },
    {
        "id": "wcXJea0F2SA",
        "original": null,
        "number": 2,
        "cdate": 1666595430426,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666595430426,
        "tmdate": 1666595430426,
        "tddate": null,
        "forum": "T-qVtA3pAxG",
        "replyto": "T-qVtA3pAxG",
        "invitation": "ICLR.cc/2023/Conference/Paper5210/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to compress the graph and node features when serving the online inference of GNN. The scenario is that new nodes come with their connections to existing nodes, and output vectors of the new nodes need to be computed. The authors use a k-means based algorithm to compress the feature vectors, and an SVD-based algorithm to compress the graph structure. Empirical results show that the proposed method yields higher accuracy than other baselines.",
            "strength_and_weaknesses": "Strength\n1. The setting for online GNN inference is described clearly.\n2. The two algorithms for feature vector and graph structure compression make sense. \n3. The empirical results are strong, having much higher accuracy than other methods at the same compression rate.\n\nWeakness\n1. The applications of online GNN inference are unclear. It would help if the authors could elaborate more on applications that use online GNN inference. My doubt is that the case of adding new nodes may be less common than adding/removing edges between existing nodes. For example, for recommendation and social networks, most of the nodes (e.g., users, products) may be already there but the edges experience constant changes due to user interaction. Also, in some business applications (e.g. PinSAGE), all embeddings in the graph are recomputed periodically.\n\n2. Compression yields obvious accuracy loss in the experiments. This may be unacceptable for applications such as recommendation because even marginal accuracy loss is important to revenue. Using out-of-core solutions (e.g., storing some data on SSD) may be more favorable to avoid accuracy loss.\n\n3. Experiments and presentations need to be improved. (1) Include some large graphs (e.g., MAG-240M and Papers100M) in the experiments, which helps to justify the need of compression; (2) Report the time used to compress the graphs (although analysis show that the complexity is low); (3) Adapt some graph coarsening methods (I think the task may be challenging but the results are good to have). For presentation, (1) Include the size of each dataset in Table 2; (2) Plot Figure 2 to make the axis and legends clearer; (3) On page 3, the authors mention that coreset selection has been used in training, what are the difficulties of adapting these methods for inference? Simply stating that these methods do not consider inference is not enough.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality need to be improved;\nNovelty moderate;\nReproducibility unclear as code link is not provided. \n",
            "summary_of_the_review": "The paper considers compressing graph data for GNN inference. However, the application scenarios need to be further justified and the performance loss is significant. Moreover, experiments can be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_afao"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_afao"
        ]
    },
    {
        "id": "NjBy4G6Ll0",
        "original": null,
        "number": 3,
        "cdate": 1666659923667,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659923667,
        "tmdate": 1666660645894,
        "tddate": null,
        "forum": "T-qVtA3pAxG",
        "replyto": "T-qVtA3pAxG",
        "invitation": "ICLR.cc/2023/Conference/Paper5210/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new problem of serving (test-time/deploy-phase inference) of a trained GNNs efficiently. \nMany GNN papers work on a semi-supervised node classification task. In that semi-supervised node classification scenarios, the trained GNN must retrain the huge memory load ot the entire training graphs to perform message passing of test nodes/edges. \nThe goal of this paper to reduce this test-time computatonal load in the test time infernece by compressing the training data nodes into a smaller set of virtual nodes. This is a practically valuable problem to tackle, but first introduced by this paper. \n\nEach training nodes must be mapped one of these virtual nodes. The mapping is learnf by weighted K-means of the tranining nodes. \nPropagation paths within the virtual nodes are also solved by a simple Frobenius norm minimization. \n\nThe experimental results show that the proposed method outperfroms naive methods for reducing test-time computatonl load in terms of the accuracy deteriorations from the \"full\" test prediction. \n",
            "strength_and_weaknesses": "(+) the proposed problem is interesting, practically useful, and new to the community (At the reviewer's knowledge)\n\n(+) the manuscript is well structured, easy to read, no logical jumps. \n\n(+) the proposed solutions are simple and reasonable. \n\n(+) experimental results. \n\n(-) Tecnnical novely of the proposed solutions are not high: but this is a minor problem since the main virtue of the manuscript is the proposal of a new problem. \n\n(-) preferably, compare with quantization methods. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I enjoyed the paper reviewering. \nThe manuscript is highly easy-to-read. The problem is stated clearly, proposes solutions step by step. \n\nThe huge trainng graph is problematic to deploy the trained GNN for not-so-powefull machines in the wild. \nThe manuscript identifies this problem and derives technically sound solutions. \nThe numbers in the experimental results strongly support the claims. \n\nPerferably, comparison with quantizqation methods will make the paper even stronger. They may be orthogonal to the proposed method, but it is not easy in general to deploy two approaches at the same time. \n\nThe only concern is that the GNN reseraches broaden so much that I cannot follow all of its aspecets. Thus there is always a possibility that some prior works raised the similar questions in the past, though the reviewer is not aware of. \n\nSome questions\n\n* How can we deal with grpahs with multi-type edges? for example, bond types in atomic molecular graphs, like/list/buy  relations of user-item purchase records. \n* The representations of the virtual nodes are confinedin the same space with the training node features. I guess this is due to the formulation of  Eq.(4). Is there a possibility that we can reduce the number of virtual nodes further, by allowing the virtual node features to have a larger dimensionality (>d) to augment its \"Informative\"-ness? \n",
            "summary_of_the_review": "This paper proposes a new and pracitically valuable question of reducing the computational burden of GNNs. \nThe idea is to compress the huge training graph into a smaller virtual node graph, by solving two simple optimization problems. \nThe rationale is clear, proposed optimization problems seems reasonable. \nStrong experimental results support the goodness of the proposd problem and the solution. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_f4pk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_f4pk"
        ]
    },
    {
        "id": "WSZg3SXCfan",
        "original": null,
        "number": 4,
        "cdate": 1666727643376,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666727643376,
        "tmdate": 1666727643376,
        "tddate": null,
        "forum": "T-qVtA3pAxG",
        "replyto": "T-qVtA3pAxG",
        "invitation": "ICLR.cc/2023/Conference/Paper5210/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In order to support GNN inference via a served, pre-trained model, the authors present a method for constructing a small, auxiliary graph data structure which can act as a proxy for the features and structure of a larger training graph. This behaves similarly to compressing a training graph and allows a smaller chunk of data to be passed to inference clients.",
            "strength_and_weaknesses": "**Strengths:**\n- The mechanism presented in the paper is mathematically clever, clean, and (after being explained) intuitive. Instead of attempting to brute-force the solution via direct graph/feature compression (which has extensive literature and could certainly have been applied, albeit with worse results I'd expect), they came up with a mechanism that synergizes with the behavior of GCNs. It's to their credit that the method can be accurately described as 'optimizing for GCN loss under space constraints' instead of 'optimizing for space and hoping for the best'.\n\n- The paper is incredibly well-structured. The pieces flow well from each other, and reading Section 3 was a surprisingly pleasant experience. The mathematics are accessible and clear.\n\n- The problem addressed is understudied, and the solution presented seems novel.\n\n**Weaknesses:**\n- The solution depends heavily on the formulation of the GNN model used. I suspect that the method can be generalized to other GNNs (perhaps with less mathematical simplicity), but the fact remains that it's tied to one incarnation as presented in this paper.\n\n- The problem setup is a bit artificial. While I understand the reason for using existing, widely-used datasets and classification tasks, I'm not convinced (as one who does not serve GNNs for inference as my day job) that the examples chosen are representative of the datasets and learning problems facing GNN serving. The authors don't seem to provide much support to the contrary, so it begs the question whether the choices are oversimplifying or skewing the results.\n\n- The evaluation was a bit underwhelming compared to the rest of the paper. The writing was poorer and confusing in places, key pieces of information were hard to find, the graph are not particularly readable, and the parameter sweeps were undermotivated and narrow. I suspect some of this could be fixed prior to publication, but the differences between sections 3 and 4 were palpable in the current version. Also, I noticed a distinct lack of computational performance information (the single comment at the end of section 3.2 was all I could find), which is a bit concerning in a paper which is trading compute for space.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:**\nSection 3 was, as mentioned above, a pleasure to read. The writing and mathematics were clear, accessible, and flowed well. The first two sections did a sufficient job of identifying key issues (e.g., compressing graph structure/features vs. weights) as well as identifying related approaches drawn from the graph literature outside of GNNs. Section 4 was less clear and suffered from a lack of messaging and poor plots.\n\n**Quality:**\nThe core mechanism presented is sound, well-motivated, and clever. While there are a few generality questions, the work as-presented seems solid and the results (while limited) clearly show the method succeeds at its intended purpose.\n\n**Novelty:**\nThe proxy graph constructed here is, as far as I am aware, novel. In addition, I consider the whole approach of the paper (using a smaller, synthetic, derived graph instead of attempting to compress the graph and features themselves) to be a useful shift in perspective. I believe both provide something to the community.\n\n**Reproducibility:**\nThe method seems to be described in sufficient detail to be replicated without issue. I especially appreciated section 3.3's summary and listing 1. A companion code repository would be appreciated in the un-anonimzed final version, as the algorithm does not seem onerous to implement for the public.",
            "summary_of_the_review": "Overall, the method is clever and interesting. The paper does a good job of laying it out clearly for the reader, and the results are enough to convince me it works. There are some rough edges (generality, problem definition, evaluation) that could use improvement, but they don't seem bad enough to invalidate any of the main takeaways.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_t66n"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5210/Reviewer_t66n"
        ]
    }
]