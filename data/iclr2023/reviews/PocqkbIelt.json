[
    {
        "id": "7t19K9Tr8N",
        "original": null,
        "number": 1,
        "cdate": 1666537712944,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537712944,
        "tmdate": 1666537712944,
        "tddate": null,
        "forum": "PocqkbIelt",
        "replyto": "PocqkbIelt",
        "invitation": "ICLR.cc/2023/Conference/Paper4433/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper tackles the problem is generating counterfactual (CF) explanations for neural networks. The authors propose a model that consists of an encoder, a predictor, and a CF generator. Correspondingly these models are trained by optimizing an objective function with three loss terms, prediction loss, validity loss, and change loss. Experiments show that CounterNet can generate CF explanations with reasonable performance. ",
            "strength_and_weaknesses": "Strength \n\n+ Generating counterfactual explanations is an important and interesting problem in the ML community. \n\n+ The design of the model with three terms, prediction loss, validity loss, and change loss, makes sense. \n\nWeaknesses\n\n- The proposed method has limited technical merit, especially compared to recent methods such as CounteRGAN [1]. \n\n- Some claims in the paper on major limitations of existing methods are not true. \n\n- Important and highly relevant baselines are missing.\n\n- Lemma 3.1 is incorrect or irrelevant to Eq (1) (see below for details). \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and well organized. The problem it tackles is also interesting for the ML community. \n\nOne of my major concerns is the technical novelty, especially compared to to CounteRGAN [1], which is also highly efficient and uses a feed forward CF generator. This also begs the question why [1] is not included as a baseline to evaluate metrics such as Validity and Proximity. \n\nIn terms of runtime, note that methods like CounteRGAN [1] only need one single feedforward pass to generate the CE and therefore should be much faster than the proposed method. Unfortunately, [1] is not included as a baseline, making it difficult to reliably evaluate the efficiency of the proposed method compared to the state of the art. \n\nThis is also highly related to the authors\u2019 claim that existing methods are slow because they rely on solving an optimization problem (one of the claimed major limitations). In fact [1] also contradicts the authors\u2019 another mentioned limitation that existing methods are post-hoc and do not leverage training information. Note that [1] could also potentially be trained jointly with the predictor. \n\nLemma 3.1 is problematic or disconnected with Eq (3). Note that according to Eq (3) the prediction loss and the validity loss use different $y$\u2019s as the target. Specifically, the prediction loss use $y_i$, the original label for $x_i$, as the target, while the validity loss use $\\hat{y}_{x_i}$, the predicted label, as the target. However, in Lemma 3.1, $L_1$ and $L_2$ share the same target $y$. \n\nBesides, the divergent gradient issue in Lemma 3.1 only happens when $x$ and $x\u2019$ are close. However, we can almost be sure that $x$ and $x\u2019$ are NOT close near the convergence point. Therefore, Lemma 3.1 is not related to the convergence point of the optimization problem at all. Rather, it is only related to the initialization point of the optimization problem. \n\nFor the second issue on adversarial examples, Lemma 3.2 is incomplete. Note that in practice, $L_1$ and $L_2$ are jointly optimized. In this case, the optimization process will try to train the predictor such that the prediction loss is minimized while training the CF generator to minimize the validity loss. \n\nIt would also be helpful to provide ablation study results on the performance when Eq (3) is optimized in the na\u00efve way. It seems this is included as CounterNet-SingleBP in Table 4. \n\nTable 1 shows that CounterNet has a disadvantage in terms of predictive accuracy when compared to post-hoc approaches, since post-hoc approaches could preserve the predictive accuracy of the base models fully. \n\nAccording to Table 2, it seems CounterNet does not have consistent improvement upon baseline methods. \n\nThe writing is inconsistent. In the abstract, the authors mentioned that existing CF methods suffer from two major limitations. In the introduction section, the number of major limitations becomes three. \n\nThe authors argue that post-hoc explanations are a major limitation in that they do not full make use of the information during training of the ML model. I find it somewhat vague and unconvincing. \n\n[1] CounteRGAN: Generating Counterfactuals for Real-Time Recourse and Interpretability using Residual GANs. UAI 2022. \n",
            "summary_of_the_review": "This paper tackles the problem is generating counterfactual (CF) explanations for neural networks. This is an interesting and important problem in the ML community. Overall the model design makes sense to me. My major concerns include the absence of highly related state-of-the-art baselines, several false claims or over-claims in the abstract and introduction, and the limited technical merit, especially given a related work CounteRGAN. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_Mece"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_Mece"
        ]
    },
    {
        "id": "CjVOkeXfEA1",
        "original": null,
        "number": 2,
        "cdate": 1666595678515,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666595678515,
        "tmdate": 1666595678515,
        "tddate": null,
        "forum": "PocqkbIelt",
        "replyto": "PocqkbIelt",
        "invitation": "ICLR.cc/2023/Conference/Paper4433/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work proposes a new method for generating Countefactuals for neural networks. The method consists of designing the network by having a part dedicated to the creation of counterfactuals, which is trained together with the predictive part. Through reasoned design and a special training, this new network, called CounterNet, is able to achieve accuracy on a par with other models. It can also generate counterfactuals in much less time than current post-hoc methods and achieve competitive values of widely used metrics from prior literature.",
            "strength_and_weaknesses": "# Strengths:\n\n1. Clear and concise explanation of the Counterfactual Explainability setting.\n\n2.  The key limitations of previous methods are clearly presented, as well as how the new method is able to overcome them. The limitations of this new method are also explicitly stated.\n\n3. Much appreciated is the theoretical analysis of Convergence and Adversarial Examples, which gives depth to the paper.\n\n4. Experiments seems complete, with multiple datasets, many baselines and ablation analysis about design choices.\n\n# Weaknesses:\n\n1. Although some are well shown, I think some limitations of the model need to be made more explicit. W1a) First of all, this method is not suitable for already trained networks, which makes it useless if you cannot/will not replace the model you have with this one.\n     * Does the training run slower than that of a standard NN? If so, this should be highlighted as a (small) limitation. The time of just training the predictor could be added to Table 3.\n     * I also think it should be made explicit that, considering the manifold, VCNet is still very competitive, also managing to have perfect validity, but lesser manifold on 3 of the 4 datasets.\n     * While briefly stated in a footnote, there is no experimental proof that this architecture works well in domains where alternatives neuronal structures performs best. The authors try their method with a Convolutional block, but with tabular datasets; as they say \"convolutional block is not well-suitable for tabular datasets\u201d. Likewise, is not explicit if the CounterNet used for the Image dataset is a convolutional one (Appendix I). Since this is not a good enough experimental proof to state that the method works well (as CF Generator) with other types of neural networks (as you say for images), it is necessary in my opinion to make this limitation explicit in the main paper and not only in the supplementary.\n\n2. \u201cNote that passing px through the CF generator network is analogous to feeding information about the decision boundary to the CF example generation procedure, which leverages this knowledge to find high-quality CF examples x\u2032\u201d The reason why px contains boundary information is not clear. Likewise, is not theoretically explained why the CF generator needs both zx and px (apart from the experiments in the Ablation Analysis section).\n\n3. Some claims in the Experimental evaluation section should be sustained via statistical tests.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is presented extremely clearly and, to the best of my knowledge, represents a clearly novel method for the field. Reproducibility should be high, given the publication of the code (although not personally tested). I consider the quality of this work to be very high.",
            "summary_of_the_review": "The strengths of the work far outweigh the weaknesses I have identified. Regarding these, they are mostly on the clarity of certain images or statements, which I strongly encourage the authors to follow, to make the work even more polished than it is now.\n\n## Minor remarks:\n1. In Introduction, I would advise some minor specifications:\n    * It should be specified that x2\u2019 is an instance with different (or opposite) label.\n    * \u201cMore generally, CF examples with low (high) cost of change imply high (low) invalidities\u201d. While usually true, this is not always the case. I would rephrase it, including \u201coften\u201d, \u201cusually\u201d or a synonym.\n    * \u201cNext, we describe key limitations of prior CF techniques.\u201d Seems redundant/ a repetition.\n    * \u201cFirst, all prior methods\u201d I\u2019ll add, just once and here, \u201cto our best knowledge\u201d or similar.\n    * \u201cPost-hoc explanation techniques are agnostic\u201d Not every method is agnostic.\n    * \u201cConsequently, such a post-hoc procedure does not properly balance the cost-invalidity trade-off (as explained above), causing shortcomings in the quality of the generated CF explanations\u201d This would need a citation\n\n2. In Section 3:\n    * \u201coutput is binary-valued, then y\u02c6x and y\u02c6x\u2032 should take on opposite values (i.e., y\u02c6x + y\u02c6x\u2032 = 1)\u201d. Since in a binary classification task, labels can also be (+1) and (-1), I would write \u201coutput is binary-valued (0, 1)\u201d or similar\n    * While very well designed, Figure 2 hides two flaws. First, it does not include a yx\u2019 used just for training, that is indeed cited in the text; probably adding a dotted line at the end of Predictor will fix this. Second, it should be highlighted that the connection from the Predictor to the CF Generator happens only once; otherwise, the network, in training regime, will continuously produce Counterfactuals of its own Counterfactuals in loop. Even in text, the \u201cfeedback loop\u201d from x\u2019 to input is mentioned, but not the px to CF Generator.\n    * \u201cgenerate a latent vector z \u2208 Rk (s.t. k < d)\u201d, \u201cand up-samples\u201d While generally true, there\u2019s no need to specify k < d, since, to my understanding, nothing prevents the network to work even if k \u2265 d, unless you have experiments that prove otherwise.\n    * I think that three hyper-parameters are not actually needed for the loss (1), cause what\u2019s important is the relative weight of the three losses. The additional parameter probably just ensure that there are multiple optimal configuration, fixing other hyperparameters (e.g. learning rate, decay rate, etc.). However, I don't think it should be changed.\n    * \u201cProof of Lemma 3.1 and 3.2 can be found in Appendix A.\u201d It\u2019s strange to mention Lemma 3.2 in the Lemma 3.1 section. I would move this sentence to the previous introductory paragraph, that of subsection 3.3\n    * \u201cwe update network weights \u03b8 = {\u03b8h, \u03b8f , \u03b8g} twice\u201d This is in contrast with the sentence \u201cwe only update the weights in the CF generator \u03b8g\u201d, cause you seem to update twice just the \u03b8g weights. But, if looking carefully at L1 loss, it doesn\u2019t depend on \u03b8g, so each weight is actually updated just once, if you freeze the gradient updates.\n\n3. Experimental evaluation\n    * The Ablation Analysis section is really appreciated, but in my opinion needs slightly more clarity. Perhaps even just starting a new line every time a modification is mentioned would help.\n    * \"reaches the theoretical upper bound of robustness (i.e., the robustness of base model)\". This statement is incorrect for me. First of all, I do not understand why the upper bound of robustness should be the robustness of base model. Even if it were, CounterNet exceeds it, so it cannot be an upper bound. Secondly, there is no theoretical study of the bounds of robustness, so I would avoid such a mathematically specific statement.\n\n4. Appendix:\n    * In Section G, \u201cmethods with only 2 \u0303% decrease (in average).\u201d The tilde ~ should be before the 2%",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_MUfa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_MUfa"
        ]
    },
    {
        "id": "iDL5HNbhMJs",
        "original": null,
        "number": 3,
        "cdate": 1666599933026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599933026,
        "tmdate": 1666599933026,
        "tddate": null,
        "forum": "PocqkbIelt",
        "replyto": "PocqkbIelt",
        "invitation": "ICLR.cc/2023/Conference/Paper4433/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on generating counterfactual explanations for model predictions, and then proposes an end-to-end learning framework that learns an explanation generator while training the predictive model. They also analyze the challenges in jointly training the predictor and the explanation generator and propose an iterative training procedure.",
            "strength_and_weaknesses": "Strength:\n - It proposes a new learning framework to generate counterfactual explanations(CF) for ML models, which facilitates service providers to specialize CF explanation techniques that can leverage the knowledge of their particular ML model.\n- They theoretically analyze the joint objective and address two challenges in the jointly end-to-end training procedure. It may offer some insights into the reasonability of the iterative training scheme when jointly training two modules with different roles.\n\nWeaknesses\n- On the method:\n    - The idea of intrinsic explainability is not new, though may have not been applied in generating CF explanations directly.\n    - The so-called \u201cblock-wise coordinate descent procedure\u201d is indeed an iterative training scheme, which is very common when handling two or more modules. \n    - While the paper emphasizes the proposed framework can achieve better cost-invalidity trade-off than the post-hot methods, it\u2019s not clear why the framework can achieve that. The paper says \u201cSecond, in the post-hoc CF explanation paradigm, the optimization procedure that finds CF explanations is completely uninformed by the ML model training procedure (and the resulting decision boundary). Consequently, such a post-hoc procedure does not properly balance the cost-invalidity trade-off\u201d, but it seems impossible and infeasible to obtain the decision boundary of the black-box model.\n- Others:\n    - A very similar paper seems to have been published on ICML2021.\n    - GitHub link provided in the paper seems to leak information about the author.\n    - There is a typo in the header of Table 5.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is clear and good. The reproducibility statement is also detailed. However, the novelty is limited.",
            "summary_of_the_review": "As the novelty is limited and the main argument(on cost-invalidity trade-off) is not well clarified, I am lean on the negative side.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_9tKf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_9tKf"
        ]
    },
    {
        "id": "dkd3AJpstz",
        "original": null,
        "number": 4,
        "cdate": 1667489025733,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667489025733,
        "tmdate": 1667489025733,
        "tddate": null,
        "forum": "PocqkbIelt",
        "replyto": "PocqkbIelt",
        "invitation": "ICLR.cc/2023/Conference/Paper4433/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The goal of the paper is the provide counterfactual explanations (CFs) for neural classification models. The paper makes the point that existing methods for generating CFs are posthoc -- so they are not aware of the decision boundary of the model. As a result, the approximations taken by these models lead to subpar CFs. The posthoc search also means that the process of generating CFs is time consuming. To overcome these issues, the paper proposes to generate CFs as a part of the model forward pass. Specifically, the model architecture and the objective is modified to generate CFs. Experiments are shown comparing the performance with several existing methods.",
            "strength_and_weaknesses": "### Strengths \n\n1. The topic of the paper (generating CFs) is important and timely.\n\n### Weaknesses\n\nOverall, the paper makes a bunch of adhoc choices when setting up the architecture and the loss function. The added value over the other methods is not very clear. Also, the proposed architecture does not support important criteria like diversity. See detailed comments below:\n\n1. First, it is not very clear if improving the runtime is such an important aspect that requires training the model from scratch. From Table 3, it looks like Vanilla CF seems to be able to generate a CF within 1-2 seconds which seems quite reasonable. Also, adding the CF generation to model training seems to prolong the training time (due to multiple objective and alternative updates). How large was this additional training time?\n\n2. Some of the choices could be justified better. For instance, why consider the non-standard squared loss in the training objective. The paper provides some ablation analysis but the reasoning behind moving from the standard cross entropy loss is not very clear. Similarly, why should the change loss be the squared loss (is it the L2 norm)? Why not consider the sparsity inducing distance like in Wachter et al? Similarly, should we expect the proposed method to be sparse in Section 4.1 when the objective function contains no sparsity term itself?\n\n3. Section 3.3: Why is adversarial robustness is a special concern here? Aren\u2019t usual NNs also prone to adversarial perturbations? I see the point that the addition of the validity loss might exacerbate the robustness. But then the paper should quantify the additional lack of robustness.\n\n4. Section 3.3: How does the alternate update strategy solve the divergent gradient problem? Since the models two objectives are in conflict with each other, is there an equilibrium point? How do you detect convergence?\n\n5. When measuring the manifold distance, it is not clear why the L1 metric was chosen. Why not L2 distance? Why only consider the 1-NN?\n\n6. Recent work on CFs seems to support more criteria than validity and proximity. For instance, Mothilal et al consider diversity. Schleich et al (https://arxiv.org/pdf/2101.01292.pdf) consider a combination of distance function to cap the number of feature changes and the max. change in the feature. Can these criteria be included in CounterNet?\n\n7. Since many of the gradient based methods highly depend on the init point (due to non-convexity of the CF objective), simply restarting with different random seeds could help with validity. It would be greatly helpful to add the restarting strategy to see how much the validity improves.\n\n8. Different CF methods come with different hyperparameters (e.g., balancing between sparsity and validity). How were these HPs selected?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is mostly easy to follow.\n\nQuality: I think the quality in terms of explaining the added value and the design choices can be significantly improved. See the detailed comments and suggestions above.\n\nNovelty: The idea of generating explanations as a part of the forward pass has been around for some time. Though I do not recall it being used in the context of CFs. Nonetheless, this seems to be a rather minor novelty.\n\nReproducibility: The paper links to the open source code though I have not checked it.",
            "summary_of_the_review": "Overall, it is not clear if the problem solved in the paper (improving runtime and validity of CFs) is a relevant problem to begin with. The paper also could be improved in terms of conveying the design choices which seem quite adhoc. For these reasons, I don't think the paper is ready yet. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_Ycp6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4433/Reviewer_Ycp6"
        ]
    }
]