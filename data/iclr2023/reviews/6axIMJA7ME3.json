[
    {
        "id": "2IB-TxqCiW",
        "original": null,
        "number": 1,
        "cdate": 1665873208952,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665873208952,
        "tmdate": 1665873208952,
        "tddate": null,
        "forum": "6axIMJA7ME3",
        "replyto": "6axIMJA7ME3",
        "invitation": "ICLR.cc/2023/Conference/Paper5713/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "\nThis paper introduces Compositional Task Representations, an approach to train language models to achieve strong zero-shot and few-shot performance on unseen tasks without the need to rely on prompts at test time. \n\nGiven a pre-trained LM, CTR is trained on a variety of tasks. For each task, a vector is initialized and trained. An encoder then produces a sequence of query vectors from this vector, These query vectors are used to retrieve a sequence of codes from a global set of trainable codes. Those codes are given as input to the LM, serving as a task representation meant to replace the prompt. At inference time on a new task, the authors search for a good composition of codes for the new tasks using unlabelled examples.\n\nThe authors compare CTR to a comprehensive set of recent baselines on both the zero-shot and few-shot settings on the T0 benchmark. They achieve strong results overall on both these settings, outperforming other methods. They present ablations on the use of prompts at test time for CTR and on the importance of sub-components of their loss. Finally, there is a rich analysis section showing the interpretability, controllability and generalization ability of CTR. \n",
            "strength_and_weaknesses": "Pros:\n* The paper is well-written and well-structured. The approach is well explained, related work is presented clearly and the experimental setup is clear. \n* The set of baselines is comprehensive and very helpful in assessing the value of the method presented. Having both the zero-shot and few-shot settings is also helpful.\n* The method achieves good results overall, although there may be some issues with measurement (see Cons section).\n* Both ablations are interesting and helpful.\n* The analysis section is rich and sheds light in some of the properties and benefits of CTR.\n\nCons:\n* My main concern is on the experimental setup, especially hyper-parameter tuning. For this setup, the proper way to do hyper-parameter tuning is not always obvious. Table 10 and 11 shows the authors have tried several configurations/options (at least 15) and this paper presents the best one. Given the wide variation on results and limited data of some tasks, the authors need to clarify how they performed hyper-parameter tuning for their method as well as the baselines. This will ensure the comparison in Table 1 is fair.\n* There needs to be more information on the experimental setup for the baselines. For instance, the authors introduce the \"Manual-code\" baseline but very little detail is given. For the self-training baseline, we do not know the experimental details at all. In general this section is lacking and makes the comparison of Table 1 harder.\n* There are details missing that harm reproducibility. For instance, the value of the beta parameter selected for the loss is not given, let alone how selection was done. \n* I would comment on the text that there is wide variability across tasks for Table 1. For instance, Discarding the CB outperformance the method is very similar to prior ones on the zero-shot setting. Given the aforementioned sparsity of details on hyper-parameter selection and baselines this is an even bigger issue.\n* Some further ablations would be interesting:\n  * How does the method perform if fewer tasks are provided during training (currently 319). \n  * Does the order of the latent codes matter for performance? At inference time, how does performance deteriorate if you shuffle the order of the codes selected for a task. \n  * Visualizing the task embeddings / the codes may be interesting.  \n* Minor: Typo p8 combing -> combining ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is excellent.\n\nQuality is quite good, with the lack of details on hyper-parameter selection and baselines being the main issue.\n\nNovelty is not an issue.\n\nReproducibility is a bigger issue. Not a lot of clarity on hyper-param tuning, baselines and the value of some parameters (such as /beta) are not given.",
            "summary_of_the_review": "This is a well-written paper that introduces an interesting method to train LM to have strong zero and few-shot capabilities. In addition to good results, the method offers nice advantages in terms of controllability and interpretability. The main issue with this paper is in the lack of clarity on hyper-parameter selection and details of the baselines. Given the results seem to be quite sensitive to these minutes details, this casts some doubt into the claimed performance. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_zu2t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_zu2t"
        ]
    },
    {
        "id": "IXO2hmClGH",
        "original": null,
        "number": 2,
        "cdate": 1666406732108,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666406732108,
        "tmdate": 1666406732108,
        "tddate": null,
        "forum": "6axIMJA7ME3",
        "replyto": "6axIMJA7ME3",
        "invitation": "ICLR.cc/2023/Conference/Paper5713/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a prompt-based architecture to improve the performance of large language models on zero-label learning and few-shot learning. The authors employ multi-task training to learn a discrete, compositional codebook, which is for mapping the given task to task types and then generate a task-related prompt for LLM inference.\n\nLearning a discrete latent codebook to enhance the interpretability of prompts is impressive, and the experiments are comprehensive and convincing. \n",
            "strength_and_weaknesses": "# Strength\n- The idea is useful and interesting\n- the models provide some interpretability, controllability, and generilization\n\n# Weaknesses\n- have not found any significant one\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe paper is well-written.\n\nQuestions:\n- Sometines, performance in the zero-labeling setting is better than the few-shot setting. I am wondering how much it is sensitive to the selection of codes. Plus, what is the scale of these data.  \n-- Another point is that, in some scenarios, we do have some annotated data. Can CTR also benefit from many annotated  examples?\n\n",
            "summary_of_the_review": "The idea is useful and interesting. I generally like this idea. I recommend acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_xT8s"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_xT8s"
        ]
    },
    {
        "id": "jysieU16lU",
        "original": null,
        "number": 3,
        "cdate": 1666651312566,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651312566,
        "tmdate": 1669670578752,
        "tddate": null,
        "forum": "6axIMJA7ME3",
        "replyto": "6axIMJA7ME3",
        "invitation": "ICLR.cc/2023/Conference/Paper5713/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for multitask learning of NLP tasks with compositional codes. Given a task id, a sequence of discrete codes are obtained. Code vectors obtained from these codes using an embedding table are fed as input to the language model as a task representation. The codebook and the language model are jointly trained with a language modeling loss and additional losses to enforce consistency between task ids and corresponding codes. Results show that the proposed approach performs better than prior methods in zero-label and few-shot settings. In addition, the trained control codes offer some degree of interpretability and controllability.",
            "strength_and_weaknesses": "Pros\n* Viewing task representations as compositional codes is an interesting perspective\n* Proposed method offers some degree of interpretability and controllability in task learning \n\nCons\n* The problem settings and proposed approach  are vaguely described. \n* Several aspects of the experimental setting were unclear which makes it hard to interpret the results. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Technical details in section 3.3 need to be explained with math/pseudocode and better clarity. \n* The zero-label setting is not clear to me. The problem formulation states \u201cgiven a new task along with a set of unlabelled data\u201d. What are these unlabelled instances? How are they relevant to the task? \n* \u201cgives predictions that deviate from a uniform distribution\u201d - Does this mean the proposed approach only applies to classification tasks?\n* In the few-shot learning setting, the authors mention an algorithm which iteratively changes a single bit of code, but do not discuss further details. \n\nSeveral aspects of the baselines were unclear/vague. I couldn\u2019t gauge whether the comparison is fair due to these missing details. \n* \u201cT0 reports the average results over multiple prompts\u201d - What are these prompts? Are they natural language prompts?\n* Model Tuning baseline - Is this model trained on the same training tasks as the proposed method?\n* Does CTR use any instructions?\n\nTable 1: What are the evaluation metrics for each task?\n\nHow were the results in Table 5 obtained? Some results do not look very convincing (e.g. the dialog example in the first instance). \n\nOther comments\n* FIgure 2 has poor readability, fonts are too small\n* Sec 3.1 says that the code embeddings are optionally passed through a decoder, but doesn\u2019t explain what this means. \n",
            "summary_of_the_review": "Updating score to 6 post author response. \n\nThe authors propose an interesting approach to learn task representations as compositional codes. However, due to missing details about the proposed approach, experimental setup and baselines it is difficult to gauge the impact of the approach. In addition, the claims about interpretability and controllability are not entirely convincing. See more detailed comments below.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_FsjZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_FsjZ"
        ]
    },
    {
        "id": "PeoxyGWLMsV",
        "original": null,
        "number": 4,
        "cdate": 1666682536454,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682536454,
        "tmdate": 1666682598260,
        "tddate": null,
        "forum": "6axIMJA7ME3",
        "replyto": "6axIMJA7ME3",
        "invitation": "ICLR.cc/2023/Conference/Paper5713/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies learning composable task codes for soft-prompting of language models. The authors propose an approach similar to VQ-VAE where each task is associated with a set of discrete codes and embedding of these codes from a codebook lookup table is stacked as a soft-prompt for a language model. First, a 2D embedding for each training task is learned via another lookup table. Next, each row of this embedding matrix is used to search for the nearest code embedding in codebook lookup table. The model is trained with typical language model loss in addition to commitment and embedding losses for learning codebook embeddings. By sharing codes across tasks, this approach presents a natural task compositionality. The authors propose code ensembling for zero-shot learning and bitwise searching for few-shot learning. On a set of benchmark tasks, the model compares favorably to previous models; achieving on-par or better on average. The authors also experiment with interpretability -- similar tasks share codes -- and controllability -- bitwise perturbation exhibits different behaviors.",
            "strength_and_weaknesses": "**Strengths** The paper studies a very important and interesting problem -- learning composable task codes for generalization to unseen tasks. I find the formulation of the problem using VQ-VAE natural and inference methods convincing. It is interesting to see that empirical results, especially zero-shot learning, improves compared to self-training or T0 models.\n\n**Weaknesses** There are a few points that require clarification and improvement.\n1. Does sharing a code necessarily mean that two tasks are similar in some sense? I found no evidence as to how important a code is for a task; hence, I can't say if a code is merely noise that gets ignored by the model eventually. For example, if you increase the number of codes, *L*, the model might be given more codes but not all of them would be used. There is not loss that encourages the LLM to utilize all codes as well.\n\n2. What is the effective number of codes that discrete compositional task code, *z*, has? Are all codes in z unique or are they frequently reused?\n\n3. Comparison to previous work needs clarification.\n- Are baselines multi-task learners or are they initialized with some pretrained embedding? Like, prompts can be initialized or they can be trained in mutli-task fashion.\n- What are the architectural details of other models, including model size, are they comparable?\n- What is the performance of model tuning if you use all 32 examples for training? I think it is a bit unfair to use all examples for CTR while using only half of them for others.\n- You mention that other methods update extra parameters as a weakness but this is not true. Prompt tuning only updates an additional prompt while the LLM is fixed. On the other hand, CTR updates a codebook and LLM is also fine-tuned. I think this is less scalable overall compared to parameter efficient updates.\n\n4. How do you choose hyperparameters? Like, \"CTR length\", \"codebook size\", or *N=60*. I don't see a clear pattern on final performance and no training/dev results are given.\n\n5. Could you clarify:\n- How do you combine with manual prompts? Are they appended as additional soft-prompt vectors?\n- What is the performance if you haven't updated the LLM? This would be a fairer comparison to parameter efficient models.\n- What is the performance w.r.t. increasing data size for few-shot learning?\n- Why does the model perform worse on co-reference?",
            "clarity,_quality,_novelty_and_reproducibility": "I find the composable task codes novel and the paper is well written. I believe results can't be reproducible without proper details on hyper parameters.",
            "summary_of_the_review": "I think composable task codes, VQ-VAE style training for LLM fine-tuning, and generalization to novel tasks during inference are strong points of the paper. But, there are still pieces that are unclear and needs improvement.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_BP2L"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5713/Reviewer_BP2L"
        ]
    }
]