[
    {
        "id": "4-tjKW08jt",
        "original": null,
        "number": 1,
        "cdate": 1666584283039,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666584283039,
        "tmdate": 1666584283039,
        "tddate": null,
        "forum": "m4f7Wl93fzT",
        "replyto": "m4f7Wl93fzT",
        "invitation": "ICLR.cc/2023/Conference/Paper3319/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a method to learn invariant listwise representations for ranking. A theoretical generalization bound is presented by analyzing domain adaptation for learning to listwise rank. Experimental results demonstrate the effectiveness of the proposed method on unsupervised domain adaptation for passage reRanking on a diversity of domains including biomedical and news articles. ",
            "strength_and_weaknesses": "Strength: \n\n1. This paper is theoretically sound, providing an important insight that when the domain shift is small according to the Wasserstein distance, a trained ranking model can be domain-adaptable, and its performance under regular ranking metrics can be bounded.\n\n2. The experimental results are reasonable and the proposed ListDA methods outperform baselines significantly by minimizing the source and target distributional shifts for learning domain-invariant representations. \n\nWeakness:\n\n1. Although the comparison between learning domain-invariant representation in the listwise and pointwise settings is given, the connection to the pairwise ranking has been little discussed.\n\n2. The evaluation is on the reRanking problem, that is reranking a list of candidate documents retrieved by a first-stage retrieval model in response to a search query, rather than the fundamental ranking problem. This seems to be one of the main limitations of this paper. The discussion about why the proposed method is not applied to the fundamental ranking problem can be elaborated.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper provides concrete mathematical proofs to explain the insights and illustrative diagrams to elaborate the procedure of text ranking with the proposed method. In general, the writing of this paper is clear. However, more concrete examples can be given, such as what kind of passages for which the proposed method performs better or less satisfying. \n\nExtensive experiments have been conducted and the presented results are mostly convincing. \n\nIt's theoretically novel to tailor domain-invariant representation learning to the listwise approach for learning to rank. However, the contribution of this paper is limited to the problem of reRanking candidate documents, rather than the fundamental ranking problem in general.",
            "summary_of_the_review": "An adversarial training method is introduced in this paper for learning domain-invariant representations to generalize the ranking model from the source to the target domain, in the setting of listwise ranking. Experiments on passage reRanking demonstrate the superiority of the proposed method. \n\nThe paper is clear and illustrative with concrete proofs and diagrams. \n\nHowever, the application and evaluation of this paper are limited to the reRanking problem. The contribution of this paper can be enhanced if the authors could generalize the proposed method to the fundamental ranking problem.\n\nAlso, along with listwise ranking and pointwise ranking, it'd be great if the authors could discuss more about pairwise ranking. It'd be also interesting to compare with some of the SOTA pairwise ranking methods. \n\nPresenting a complexity analysis of the proposed method and comparison to baselines is recommended, in order to show the efficiency of ListDA.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_HnLS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_HnLS"
        ]
    },
    {
        "id": "t0l8rAsvZRp",
        "original": null,
        "number": 2,
        "cdate": 1666663276332,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663276332,
        "tmdate": 1669999805152,
        "tddate": null,
        "forum": "m4f7Wl93fzT",
        "replyto": "m4f7Wl93fzT",
        "invitation": "ICLR.cc/2023/Conference/Paper3319/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper focuses on domain-adaptation of ranking problem.\nThey show generalization bound for ranking problem and propose an approach to improve adaptation to minor domain shift.\nThrough a set of experiments on some open-source datasets they show the effectiveness of their approach.",
            "strength_and_weaknesses": "Strengths:\nPaper is fairly self contained\nPaper shows both theoretical bounds and practical approach.\n\nWeakness:\nThe writing in approach section blends both previous work and their approach making a bit hard to discern their contribution.\nThe experimental set-up might have some issues:\n* Why was the better negative sampling not used for other approaches.\n* While it is true that the paper focuses on ranking and hence retrieval model can be basic, it is unclear how their approach might be affected by a better retriever that could be encoder-based.\n* The model training is a bit confusing, should the adversarial training be done for every new target distribution or can it be trained once and re-used?\n* Q-D generation is a bit questionable, if the source target dont have many documents from the new domain would it still be ok? what is the threshold that determines that? Would be good if authors mention some details.\n\nMinor comments:\n* There are assumptions made in section 3 for the proof, but not all assumptions are justified. Would be good if they can add a couple of lines on why they are reasonable.\n* There are some minor grammatical errors which sometimes make it hard to understand like: \"The final missing piece is the choice of $F_{ad}$ that can model lists $z = (z1 , \u00b7 \u00b7 \u00b7 , zl )$ of feature vectors zi \u2208 Rd and is continuously differentiable.\"\n* It would be nice to also add and show what the upper bound of metric is if trained on the training dataset (target domain) when it exists.",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is fairly clear and novelty is incremental.\nI may have missed it, but not sure if the results are reproducible with their code, they do give hyperparameter details.",
            "summary_of_the_review": "Overall I think it is a nice idea to improve the robustness of the model trained for re-ranking. \nWhile, they have bounds on domain adaptation generalization, I did not verify the correctness of the proof.\nThe experiments demonstrate superiority of their approach across three datasets.\nProvided the questions mentioned in the above section is addressed, I would be inclined to accept the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_U7gj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_U7gj"
        ]
    },
    {
        "id": "VQJpDHgU06",
        "original": null,
        "number": 3,
        "cdate": 1666707178860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666707178860,
        "tmdate": 1666707178860,
        "tddate": null,
        "forum": "m4f7Wl93fzT",
        "replyto": "m4f7Wl93fzT",
        "invitation": "ICLR.cc/2023/Conference/Paper3319/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a domain-invariant adaptation approach for listwise learning to rank (l2r). The authors extend a bound from the literature to l2r setting. Then a typical approach for domain adaptation is used with adversarial learning. The authors experiment in the textual domain with one source and three target domains. They compare with two baselines and two relevant approaches showing that the proposed method outperforms them.",
            "strength_and_weaknesses": "- This is an interesting problem/setting as in many cases it is very expensive to collect labeled data.\n- The authors extend work on domain adaptation on the l2r setting which is an important task in many applications\n- The results seem to be promising although only applied in the textual domain.\n\n- The proposed approach is not so tightly connected with the theoretical part. Indeed the authors use standard adversarial setting for domain adaptation. I would propose the authors to better describe the connection. These approaches are already presented, see for example Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. ICML 2017.\nGanin et al., Domain-adversarial training of neural networks. Journal of Machine Learning Research, 2016.\n\n- I think the authors should discuss this work \"On Learning Invariant Representations for Domain Adaptation\" regarding the optimal joint risk.\n\n- Generally, while the experimental part show promising results, the fact that is only applied in the textual domain makes it weak. Also, already the zero-shot baseline has a good performance, and to be honest I am not convinced how much this small difference would make in a production system. I am just curious here if we carefully tune the zero-shot baseline what the result would be.\n- Is there any reason to restrict to softmax listwise loss function? Did you try other ones? For example BoltzRank?",
            "clarity,_quality,_novelty_and_reproducibility": "This is generally a good paper and authors provide all the required and relevant material for the both the theoretical and experimental part. For the latter though, I cannot really comment on the reproducibility.\n\nAs explained previously, this is an extension of an existing theoretical framework. There is some originality though for the specific task.",
            "summary_of_the_review": "Generally a good paper, with a lack of connection between the theoretical and the method part. It builds upon an existing framework and extends for the l2r framework. The experimental part is weak in my opinion as it only applied on the textual domain and is hard to asses if this approach would work in other domains. Already the baseline works quite well.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_3EyT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_3EyT"
        ]
    },
    {
        "id": "uJXPQ9ILOR",
        "original": null,
        "number": 4,
        "cdate": 1666907446375,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666907446375,
        "tmdate": 1666907700370,
        "tddate": null,
        "forum": "m4f7Wl93fzT",
        "replyto": "m4f7Wl93fzT",
        "invitation": "ICLR.cc/2023/Conference/Paper3319/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on Domain Adaptation (DA) in the context of learning to rank. The authors follow the invariant representation learning approach, which they extend to the listwise learning to rank scenario. The final objective consists of a listwise ranking loss and an adversarial loss encouraging invariance across domains.  The authors also derive a domain adaptation generalization bound for listwise learning to rank scenario. The proposed method is evaluated on the passage/text re-ranking task. ",
            "strength_and_weaknesses": "Strengths.\n- The paper is well written and technically sound\n- The paper proposes a domain adaptation method for learning to rank tailored for the listwise scenario. Compared to existing methods, the proposed approach seeks invariance at the list representation level instead of the item level. \n- Theoretically, the authors derive a domain adaptation generalization bound for the listwise learning to rank case. \n\nWeaknesses.\n\n- The experiments are weak. (I) Evaluations are curried out on one task and one data type (text) only. (II) The list of baselines can be improved, for instance by including other domain adaptation learning to rank approaches, such as the one mentioned in the related work section. (III) Some results are not reported for all datasets and baselines (e.g., the results of figures 2 and 3). \n- The technical novelty of the proposed objective is somewhat limited. \n\nAdditional comments. \nI would recommend presenting section 4 first followed by the current section 3 as supportive theoretical results for the proposed objective.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Please refer to the Strength and Weaknesses section above. ",
            "summary_of_the_review": "Please refer to the Strength and Weaknesses section above. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_SYBU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3319/Reviewer_SYBU"
        ]
    }
]