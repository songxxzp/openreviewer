[
    {
        "id": "ycTEDfo_-z",
        "original": null,
        "number": 1,
        "cdate": 1666531081961,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531081961,
        "tmdate": 1666531081961,
        "tddate": null,
        "forum": "BR_ZhvcYbGJ",
        "replyto": "BR_ZhvcYbGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper3582/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper \"Explaining temporal graph models through an explorer-navigator framework\" proposes a graph neural network (GNN) explainer model for temporal graphs. More specifically, the proposed model has mainly two components which are explorer and navigator. The explorer is to find the event subsets for explanation, and the navigator is to reduce the search space. The authors conduct various experiments to evaluate the performance and show that the proposed model can achieve superior performance than others. ",
            "strength_and_weaknesses": "Strength\n- The proposed model is well designed. The authors take the advantages of search- and learning-based GNN explainer together. More specifically, the authors apply search-based explainer to explorer for finding the best results and use MCTS to reduce search time. Moreover, they train the navigator to learn the inductive relationships.\n\n- It can be a significant contribution since GNN explaining model for temporal graphs is under-explored.\n\n- Overall, the paper seems to be well-organized. In my view, the authors carefully composed the paper to understand what GNN explainer is, what the proposed model is, and so on.\n\nWeaknesses\n- Several notations are confusing to me. For example, the authors reuse the notation G^i in section 4.3.2, with (minorly) different meaning. But it can be confusing for readers to follow the paper. The reviewer expects that the authors use clear notations to be understood more easily.\n\n- Literature survey would not be enough. The authors claim that it is the first explainer for temporal graph models. But Z. Han et al., \"Explainable subgraph reasoning for forecasting on temporal knowledge graphs\" at ICLR 2021 tried to construct an explaining model for temporal knowledge graphs. In my view, although it is applied to temporal knowledge graphs, it needs to be mentioned and discussed in the related work section.\n\n- I think that several experiments are more needed. As far as I can tell, many works for GNN explainers (e.g., D. Luo et al., \"Parametrized explainer for graph neural network\" at NeurIPS 2020) illustrated the performances, and so that there can be several illustration rather than figure 5 and 6 in this paper.\n\n- Performance comparison between the proposed model with navigator and without navigator seems to be needed. The authors show the efficiency of the navigator with figure 4. But there is no performance (Fidelity, sparsity) comparison between them. If there is the performance comparison, the necessity of navigator can be more convinced. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Most of all, the proposed model is clear to understand the structure. The model seems to be quitely novel since it takes the two advantages of search- and learning-based GNN explainers, and is applied to under-explored area, temporal graphs. The experimental results with other baselines show that it can achieve superior performance than others, so it would be significant.",
            "summary_of_the_review": "In general, the paper seems to be well-organized and the proposed model can be significant. The idea of taking two advantages of search- and learning-based GNN explainer would be novel. But as aforementioned, 1) several notations need to be revised to be clearly understood, 2) enough literature survey is conducted and 3) More experiments and some illustrations seems to be needed for better version of paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_zSpG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_zSpG"
        ]
    },
    {
        "id": "0Jc6SZSblV",
        "original": null,
        "number": 2,
        "cdate": 1666665614448,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665614448,
        "tmdate": 1666665614448,
        "tddate": null,
        "forum": "BR_ZhvcYbGJ",
        "replyto": "BR_ZhvcYbGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper3582/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed a post-hoc and instance-level explainer called T-GNNExplainer for temporal graph neural network on continuous-time dynamic graphs. The paper provides experimental evaluations on the effectiveness of the proposed explainer on real-world and synthetic datasets. \n",
            "strength_and_weaknesses": "Strength:\n1. The paper proposes an interesting idea of using Monte Carlo Tree Search to select the optimal edge (event) set that explains a prediction. \n\n2. The paper proposes a navigator (multilayer perceptron) to learn Monte Carlo tree weights to speed up the Monte Carlo Tree Search. \n\n3. The paper simulates synthetic datasets by the multivariate Hawkes process and some pre-defined event relation rules. The experiments on the synthetic datasets demonstrate the effectiveness of the proposed method.\n\nWeaknesses:\n1. For related works, the paper only covered post-hoc interpretative methods, where the explanatory model is trained on top of the well-trained classification model. However, there are also many works on intrinsically interpretable models, e.g., BrainGNN[1] and dGLCN[2].\n\n2. In experiments, the proposed method has many hyperparameters, but the paper did not provide parameter sensitivity analysis. It will be nice to add hyperparameter tuning results, such as N_{r}, \\lambda. \n\n3. Furthermore, considering that the algorithm proposed by the authors is plug-and-play, the paper only validated the idea on two instance-level post-hoc methods, TGAT (2020) and TGN (2020). It will be nice to add experiments on other target models to further demonstrate the effectiveness of the proposed method. There are also some baselines from non-post-hoc explainers (e.g., dGLCN[2]) and model-level algorithms (e.g., XGNN[3]). \n\n4. The overall writing is good, but there are some minor issues. The paper should use the full spelling for the first mention of the acronym, such as GNN in the abstract, and CR on page 6. The authors should use math equation language instead of programming language in Eq. 6.\n\n\n[1]BrainGNN: Interpretable Brain Graph Neural Network for fMRI Analysis\n[2]Dual-Graph Learning Convolutional Networks for Interpretable Alzheimer's Disease Diagnosis\n[3]Xgnn: Towards model-level explanations of graph neural networks\n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall writing is good, but there are some minor issues. \n\nThe novelty of the proposed idea is somehow limited. The proposed idea uses the common Monte Carlo Tree Search with additional weight learning.\n\nThe paper claims to have codes and datasets available. The tuning of hyperparameters should be provided.\n",
            "summary_of_the_review": "The paper proposed a post-hoc and instance-level explainer called T-GNNExplainer for temporal graph neural network on continuous-time dynamic graphs. It constructed a navigator and explorer, where the navigator proposed by the paper can play the role of attention to output weights and help the optimization of the Monte Carlo Tree Search. However, the novelty of this paper is not very strong, and more experiment needs to be included. See the strength and weaknesses section for details\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_J8qS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_J8qS"
        ]
    },
    {
        "id": "lJkYFjTt6Y0",
        "original": null,
        "number": 3,
        "cdate": 1666682652148,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682652148,
        "tmdate": 1666682652148,
        "tddate": null,
        "forum": "BR_ZhvcYbGJ",
        "replyto": "BR_ZhvcYbGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper3582/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The author proposed a new method for explaining temporal graph models. Most of the previous explainer models only focus on static graphs. To achieve the goal, the authors combine the explorer framework that uses Monte Carlo Tree Search with navigator frameworks that guide the search by predicting the correlation between an event to the target event. The authors then demonstrate the benefit of the proposed model in real-world and synthetic data.  ",
            "strength_and_weaknesses": "Strengths:\n- The proposed method is one of the first graph explainer models for temporal graphs.\n- The combination of the MTCS explorer and the navigator is interesting.\n- The author shows the performance benefit on temporal graph explanation in terms of fidelity and sparsity.\n\nWeakness:\n- The idea of using parameterized navigator as well as MTCS explorer has been proposed in the previous graph explainers.\n- The use of MTCS in the solution search makes the running time relatively slow. The authors have not discussed the runtime complexity as well as the runtime comparison with the baselines. In static graphs PGExplainer runs much faster (in milliseconds). It will be good to see the runtime-performance trade-off as PGExplainer can also be modified to handle temporal graphs as well.\n- There is related work on the temporal graph explainer that was submitted to arXiv not long before the ICLR deadline, which may indicate concurrent works. However, it would still be beneficial if the author could compare and contrast with the work.\n> He, Wenchong, Minh N. Vu, Zhe Jiang, and My T. Thai. \"An Explainer for Temporal Graph Neural Networks.\" arXiv preprint arXiv:2209.00807 (2022).",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper's presentation is clear and easy to understand. There is a bit issue in terms of the novelty of the proposed model. ",
            "summary_of_the_review": "The paper has a nice contribution to temporal graph explainability. However, there are a few weaknesses, particularly in terms of the novelty of the proposed method.\nBased on the considerations above, I recommend a weak acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_3TUm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3582/Reviewer_3TUm"
        ]
    }
]