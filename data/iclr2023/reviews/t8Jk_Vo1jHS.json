[
    {
        "id": "g5tbzgNl9X-",
        "original": null,
        "number": 1,
        "cdate": 1666619177863,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619177863,
        "tmdate": 1670732044727,
        "tddate": null,
        "forum": "t8Jk_Vo1jHS",
        "replyto": "t8Jk_Vo1jHS",
        "invitation": "ICLR.cc/2023/Conference/Paper5152/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a method for federated neural architecture search, namely FedorAS, which leverages supernet for sharing knowledge across clients with device and data heterogeneity. They also introduce OPA (operation aggregation) that weighs the client updates in a frequency-aware manner. They demonstrate the effectiveness of their method against multiple existing methods.",
            "strength_and_weaknesses": "**Strength**\n- The paper is well-organized and easy to read.\n- They tackle the practical problem of federated learning where participants have device heterogeneity, i.e. computation and memory budgets.\n- They demonstrate the effectiveness of the proposed method in various modalities, i.e. vision, speech, text.\n- The results are impressive.\n\n**Weaknesses**\n- It seems better to discuss the overall costs (i.e. supernet train and model search time (ms) or # rounds, etc) and compare them to the baseline models. Since the proposed framework has three steps; (1) supernet training, (2) model search, and (3) local fine-tuning, each step may take the individual computation and communication costs. In the paper, however, I can only find the analysis for the searched models obtained from the step 3 only. More detailed discussion for overall costs is required, for example:\n    - How many rounds do the stage (1) and stage (3) need? \n    - How long does the (2) model search process take? \n    - How much overall computation and memory costs are required to get the final results for your model and baseline models?\n- Is the number of \u201ctiers\u201d the hyper-parameters? Can we have more tiers? Does varying the number of tiers affect the performance? or the overall costs for each step? \n- HeteroFL [Diao et al 21], one of the essential works tackling the same problem, is missing. The method also leverages the supernet for sampling local models considering the complexity levels, which is also similar to your tier clustering. It would be very helpful for you to discuss pros and cons and compare it with the proposed model.\n\nDiao et al, HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients, ICLR 2021\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall quality and clarity of the paper are good. There are some rooms for improving the originality of the proposed method. For example, discussion of the clear difference from some existing methods that utilizes the supernet for Federated NAS (i.e. HeteroFL). The code is not provided, thus it is hard to tell the reproducibility of this work.\n",
            "summary_of_the_review": "I enjoyed reading the paper, but several improvement seems to be required, as mentioned above.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_Zb8v"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_Zb8v"
        ]
    },
    {
        "id": "8JqbeCu6qC",
        "original": null,
        "number": 2,
        "cdate": 1667395593554,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667395593554,
        "tmdate": 1667395593554,
        "tddate": null,
        "forum": "t8Jk_Vo1jHS",
        "replyto": "t8Jk_Vo1jHS",
        "invitation": "ICLR.cc/2023/Conference/Paper5152/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a method called \"FedorAS\" which incorporates ideas from Neural Architecture Search into the domain of Federated Learning. In the scenario where the devices participating in a Federated Learning session has varying capabilities, and heterogeneous data distribution across devices, the goal of FedorAS is to provide each device with an efficiency-tailored architecture and parameters.  \n\nIn FedorAS, the participating devices are clustered into several tiers, according to their hardware capability. Using a supernet architecture, from which a subspace is sampled for each device. The client, after receiving the subspace, trains the models within the subspace by randomly sampling the subpaths. The server then aggregates the updated client weights using a weighted averaging technique which normalizes for the number of examples passed through each subpath. After training, the server performs the NSGA-II algorithm to find the best architecture for each device tier. After that, the obtained models are fine-tuned with FedAvg among devices with the same tier or above.\n\nThe authors report that FedorAS achieves better performance than other cross-device baselines, on multiple domains such as speech, vision, and text.",
            "strength_and_weaknesses": "**Strengths:**\n* FedorAS achieves superior performance over other baselines in cross-silo settings.\n\n**Weaknesses:**\n* An ablation study on the effect of the fine-tuning process is lacking. How much does the fine-tuning process affect the final performance?\n\n* Experiments on a more extreme division of the device tiers are lacking. For example, in the CIFAR-10 experiments, it is assumed that the lowest tier devices are capable of 120.9MFLOPs, whereas the highest tier devices are assumed to be capable of 716.0MFLOPs. That is only about 6x difference. However, the FLOPs difference between real embedded devices and high-performance devices is more extreme, for example, the FLOPs difference between the M1 chip and the Raspberry Pi Zero is about 500x, given the average power for each device. [1]\n\n[1] https://web.eece.maine.edu/~vweaver/group/green_machines.html",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to read and clearly written. The method proposed in the paper is novel, but the authors do not provide any code for it, which significantly undermines the reproducibility of the paper.",
            "summary_of_the_review": "FedorAS is a novel method for performing NAS in a federated learning setting, which outperforms similar existing methods. It is well-written and easy to understand, but some of the experiments are considered somewhat unrealistic, and analyses are lacking. The authors do not provide any code for reproducibility.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_djQ3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_djQ3"
        ]
    },
    {
        "id": "8T5D44Ikbny",
        "original": null,
        "number": 3,
        "cdate": 1667418282882,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667418282882,
        "tmdate": 1667418282882,
        "tddate": null,
        "forum": "t8Jk_Vo1jHS",
        "replyto": "t8Jk_Vo1jHS",
        "invitation": "ICLR.cc/2023/Conference/Paper5152/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The manuscript proposed a neural architecture search (NAS) algorithm, FedorAS, under cross-device federated learning setting. The proposed algorithm follows settings of one-shot NAS utilizing a super-net search space with weight sharing. It enables knowledge exchange between server and clients via sub-networks. And a new model weight aggregation methods is introduced to compensate sampling frequencies of sub-networks at clients. Moreover, the experimental results validate the proposed algorithm with datasets in computer vision, audio data processing, and natural language processing. The comprehensive experiments cover various FL setting including IID/non-IID data distribution, cross-device FL/cross-silo FL.",
            "strength_and_weaknesses": "<Strength>\n\n\u2022\tThe paper is well-organized and well-written.\n\n\u2022\tThe experimental results supports the claims made in the manuscripts.\n\n\u2022\tThe experiments and ablation studies are comprehensive.\n\n\u2022\tThe submitted content is related to the application of neural architecture search in federated learning, which is highly relevant to the ICLR audience.\n\n<Weakness>\n\n\u2022\tThe novelties of the proposed algorithm are limited. The idea of FedorAS is a direct combination of federated learning and single-path one-shot NAS.\n\n\u2022\tDiscussion or ablation studies are not sufficient (see below).\n\n<Comments>\n\n1.\tWhat is training and searching efficiency of the proposed algorithm?\n\n2.\tHow to determine that when to stop the searching process?\n\n3.\tDoes the training recipe (e.g., batch size) matter for the NAS outcome? Do different training recipes or different random seeds result in different Kendall rank correlation coefficients?\n\n4.\tIt is the necessary to show the gap between federated NAS (FedorAS) and the centralized NAS?\n\n5.\tIs it possible to search for different architectures with FedorAS when clients have different computing devices or budgets?\n\n6.\tHow does the number of tiers affect the performance of the proposed algorithm?\n\n7.\tThe necessary ablation study would be evaluating ranking correlations using the proposed super-net based NAS algorithm.\n\n8.\tTypo: Page 6, Section 4, \u201c\u2026 we we draw \u2026\u201d => \u201c\u2026 we draw \u2026\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is of moderate quality, with good clarity and limited novelties.",
            "summary_of_the_review": "The manuscript presented an interesting study of the proposed federated NAS algorithm. Its experiments are comprehensive. But its novelties could be limited as it is a straightforward combination of federated learning and single-path one-shot NAS.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_7XQj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_7XQj"
        ]
    },
    {
        "id": "8g0hbcpufc",
        "original": null,
        "number": 4,
        "cdate": 1667601279192,
        "mdate": 1667601279192,
        "ddate": null,
        "tcdate": 1667601279192,
        "tmdate": 1667601279192,
        "tddate": null,
        "forum": "t8Jk_Vo1jHS",
        "replyto": "t8Jk_Vo1jHS",
        "invitation": "ICLR.cc/2023/Conference/Paper5152/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents FedorAS to discover and train architectures which are suitable for devices of various scales. FedorAS leverages a server-resident supernet enabling weight sharing for knowledge exchange between clients, without sharing common model architectures. This work also provides a new aggregation method called OPA for weighing updates from multiple \u201csingle-path one-shot\u201d client updates in a frequency-aware manner. The method is demonstrated on different settings and shows a good performance while maintaining resource efficiency.",
            "strength_and_weaknesses": "The paper is well written, and the method is well demonstrated on various datasets compared with different baselines. But there are still some issues, which are discussed in the next part. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: \n(+) The paper elaborates the proposed method in a detailed way, clearly explaining the background, logic of the method and the experiments. The necessary materials are also included in Appendix.\n(-) The results are not consistent: In section 4.2, the author claims 48.7% better than CIFAR-10(\\alpha=0.1). But in the Tab.2, there is only 26.69 (81.53-54.84) improvement. It is the same for Tab.3. In the content, it says +11.6%, but there is only 9.4 (90.6-81.2). Which is the correct one?\n(-) The setting is unclear to me: After supernet training stage, does the system use the same or different model architecture for all clients? \n(a) If the model architecture is the same for all clients, how does the proposed method handle the system heterogeneity? That is, how to deal with the clients with different computational resources?\n(b) If the model architecture is the different for all clients, is aggregation with OPA still working?\n\nQuality: \n(+) This paper provides a detailed analysis of the method, and shows the importance of Supernet initialization and advantage of OPA over FedAvg.\n\nNovelty: The design is based on the idea of supernet, some of the methods are heuristic and may need further analysis or explanation.\n(-) (minor) In section 3.1 (1) Subspace sampling, it says \u201csetting the limit to half the size of a typical network \u2026 worked well in our experiments \u2026\u201d. Does it apply to other experiments (e.g., different datasets)? Any explanation for this selection?\n\nReproducibility: \nThe paper does not provide any code or algorithm block, but it clearly discusses datasets, model search space, and the package it is based on. So probably the results presented in the paper can be reproduced.\n",
            "summary_of_the_review": "The paper is overall well-written, providing a novel approach FedorAS to leverage a supernet for knowledge exchange between clients. The method shows better results by demonstrating on different datasets compared with multiple baselines. However, there are still some fundamental issues that need to be fixed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_C28f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5152/Reviewer_C28f"
        ]
    }
]