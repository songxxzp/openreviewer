[
    {
        "id": "TRBj9H4v1y",
        "original": null,
        "number": 1,
        "cdate": 1666252133605,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666252133605,
        "tmdate": 1666301329717,
        "tddate": null,
        "forum": "WA35e2vPlFT",
        "replyto": "WA35e2vPlFT",
        "invitation": "ICLR.cc/2023/Conference/Paper3181/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper points out some potential issues and limitations using \u201cpushforward\u201d models for density estimation. The main issue is that the general manifold of dimension m may not be effectively embedded in the latent space of the same dimension m. To resolve that challenge, the authors propose to construct an implicit model manifold, called MDF, so that the original data manifold lives on the null set of the MDF. The new implicit model covers a richer class of manifolds. Following this line, the authors further propose to use an energy based model to model the density over the manifold. Also the constrained Langevin Monte Carlois used to sample from the manifold.\n",
            "strength_and_weaknesses": "Strength: The challenge the authors raised was real and interesting. I feel not many people have realized that. The proposed implicit model, as well the whole procedure of optimization, are novel. \nWeakness: The empirical part of the paper is weak. Only synthetic datasets were used. If the proposed model is so powerful, why not use it on real-world datasets?\n",
            "clarity,_quality,_novelty_and_reproducibility": "It is true that embedding an m-dimensional manifold into an m-dimensional euclidean space is challenging. However, in many applications, people tend to use much higher dimensions. For example, in the flow based density estimation, people use the dimension of the ambient space n instead of the dimension of the manifold m in the latent density estimation. Frankly, in real applications, it is hard to estimate the dimension m of the manifold. Instead the dimension of the latent space is chosen empirically. I conjecture in most of those applications the dimension used in the latent space is way higher than the \u201creal\u201d dimension of the manifold. If this is the case, the impact of this paper will be quite limited. ",
            "summary_of_the_review": "Overall my review is mixed: on one hand I do like the issues/challenges raised by the authors. Also the proposed solution seems very novel. On the other hand, I feel the challenges raised may not be real in applications since people are using dimensions much higher than m in the latent space. Also there are no real-world datasets used in the experimental sections. This makes me question whether the proposed novel but complicated solution is truly better than existing \u201cpushforward\u201d models. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_sPaT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_sPaT"
        ]
    },
    {
        "id": "EpQK01QXui",
        "original": null,
        "number": 2,
        "cdate": 1667427730931,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667427730931,
        "tmdate": 1667517516572,
        "tddate": null,
        "forum": "WA35e2vPlFT",
        "replyto": "WA35e2vPlFT",
        "invitation": "ICLR.cc/2023/Conference/Paper3181/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method to learn implicit manifolds and sample from them using energy-based models. In particular, the paper first proposes a regularized method for learning submanifolds of any codimension and then shows how to fit the energy function and sample using a faster version of constrained HMC.",
            "strength_and_weaknesses": "Strengths\n-----------\n* The paper brings together a lot of disparate literature to build better manifold-learning flow methods.\n* The results show the first ability to learn topologically nontrivial manifold structures from data.\n\nWeaknesses\n--------------\n* Outside of showing that the methods (implicits, ebms, CHMC) are of practical interest, the technical contributions feel marginal. In particular, for implicits, the geometric regularization term is similar to previous work (some mentioned in the paragraph) except as a generalization to matrices, and, for CHMC, the contribution seems like an application existing random numerical linear algebra techniques (hutchinson + CG) to the standard CHMC algorithm.\n* The experimental section feels very toy. In particular, section 4.1 just shows that the method works (and validates the manifold arithmetic component). Section 4.2 is more interesting, but notably doesn't test on data that is sampled from an unknown manifold (ie it is hard to motivate the method if we know the manifold is a sphere/torus). More importantly, all of these examples are *low dimensional*. Since the developed theory is built specifically to generalize to submanifolds of arbitrary codimension (i.e. the jacobian regularization method)  or for higher dimensional spaces (i.e. the novel CHMC method is built to scale to higher dimensions), I would expect an example showing that the developed theory matters, something that isn't true for the example surfaces in R^3.\n* The proposed methodology presents several important drawbacks. First, we can't evaluate log probabilities (without resorting to evaluating the energy function on all points of the manifold, which is computationally infeasible especially for dimension $> 3$). Second, the manifold and the probability density are two separate models (in particular the EBM is trained as an ambient density, not an intrinsic manifold density). Third, sampling relies on an expensive MCMC technique. Since the purpose of manifold-learning flows was to handle these issues, the current framing as a manifold-learning flow paper is somewhat strange/out-of-place.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n-------\nThe paper is quite clear to read. However, the section on energy-based modeling felt rushed (not much of the background/methods are given), making it hard to parse for someone who is not particularly familiar with that literature. The CHMC section's clarity could be improved with better writing (ie an introduction of the method first, followed by places where the randomized numerical linear algebra techniques could be applied).\n\nQuality\n--------\nThe overall quality is reasonably high. The concepts that are developed are reasonably intensive, and the method seems like a good bridge between existing literatures.\n\nNovelty\n---------\nThe method is marginally novel. It mostly applies existing techniques to an existing problem, although it does generalize the existing techniques somewhat.\n\nReproducibility\n-----------------\nThe code is given in the supplementary zip, so it is reasonably reproducible.",
            "summary_of_the_review": "Overall, I vote to reject the paper. My reasoning is that, while the paper does deftly utilize preexisting methods to construct manifold-learning flows, the adaptation is somewhat straightforward (e.g. regularize all singular values + use random numerical linear algebra techniques + backprop for CHMC). Importantly, the experiments don't showcase the primary benefits of the developed techniques, calling into question said developments. Either the manifold structure is known a priori or existing methods (e.g. a combination of Gropp et al. + standard CHMC) should suffice since the manifold is a surface in R^3. Of secondary concern, I believe that the current framing as a \"manifold learning flow\" paper is inaccurate, as the proposed method seems to not be addressing the same issues as the field. I would instead encourage the authors to perhaps motivate it from a different lens (perhaps EBM + adding in a manifold constraint).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_VPPU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_VPPU"
        ]
    },
    {
        "id": "nNOKmvmc2hY",
        "original": null,
        "number": 3,
        "cdate": 1667515837802,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667515837802,
        "tmdate": 1667515837802,
        "tddate": null,
        "forum": "WA35e2vPlFT",
        "replyto": "WA35e2vPlFT",
        "invitation": "ICLR.cc/2023/Conference/Paper3181/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an approach to estimate a manifold using an implicit model. The authors use a constrained energy-based model to learn the data distribution within the manifold. A Langevin dynamics is used to sample from the manifold while training and at an inference time.",
            "strength_and_weaknesses": "Strength:\n- a manifold learning and density estimation on the manifold is an important problem statement for many applications;\n- the proposed approach is simple and easy to follow;\n- the authors applied the approach to several;\n- the idea of modeling a manifold as an implicit function is interesting, although it is not novel. For example, in https://arxiv.org/pdf/2011.12026.pdf (proc. of CVPR, 2021), the authors proposed to represent a manifold of images based on an implicitly defined GAN model,\n- the proposed idea of manifold arithmetic sounds rather interesting, where thanks to implicit representation, we can model various operations on a given set of manifolds.\n\nWeakness:\n- the approach is a combination of several existing and relatively standard building blocks like implicit functions based on neural networks, an energy model, a Langevin dynamics; \nthe authors did not make any ablation study proving that the proposed selections of these building blocks and their hyperparameters are optimal,\n- the proposed approach for the manifold arithmetic requires additional testing. It is not clear for which applied problems it can be used or which existing solutions it can improve,\n- the manifolds considered in the experimental section are low-dimensional. Actually, they resemble some 3D shapes of visual objects. So the difference between the proposed approach and the approaches for shape modeling based on implicit functions, see, e.g., the paper https://arxiv.org/pdf/2008.06520.pdf (Learning Gradient Fields for Shape Generation) is not clear\n- the authors did not test their approach on any standard manifold learning problems, even those proposed in 200x, see, e.g., https://lvdmaaten.github.io/publications/papers/TR_Dimensionality_Reduction_Review_2009.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "The quality and clarity of the writing are good.\nThe work is not fully original. The proposed approach combines several standard building blocks, so its novelty is limited. The code is provided, and the results seem reproducible.",
            "summary_of_the_review": "- the idea of using implicit models for manifold representation is interesting, and I have not seen papers explicitly proposing such an idea,\n- the proposed algorithm is not novel; it consists of standard building blocks,\n- the authors did not conduct any ablation study to investigate the influence of different parts of the algorithm and did not perform sufficient experimental testing of the proposed approach for manifold learning.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_aqkP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3181/Reviewer_aqkP"
        ]
    }
]