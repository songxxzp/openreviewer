[
    {
        "id": "g5iIL2A9CKo",
        "original": null,
        "number": 1,
        "cdate": 1666540489471,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666540489471,
        "tmdate": 1666540516829,
        "tddate": null,
        "forum": "-jP_rDkyfpI",
        "replyto": "-jP_rDkyfpI",
        "invitation": "ICLR.cc/2023/Conference/Paper1683/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors investigate a problem in clustering by locality-sensitive hashing for similarity search. They introduce a new method called the Polar Code Nearest Neighbor (PCNN) method that uses the polar codes to maintain a number of clusters in a high-dimensional embedding space. By utilizing the list-decoding method, they propose a multi-probe scheme for PCNN to efficiently determine the closest clusters to the query. Extensive experiments confirm the superior performance of PCNN over the classic hash clustering (CHC).\n",
            "strength_and_weaknesses": "The paper has the following strengths:\n\nS1. This paper is well-motivated. Vanilla methods often embed the original data points into a low-dimensional latent space, which usually distorts the distance for many pairs of data points. Thus, considering a high-dimensional latent space might be promising. \n\nS2. The experimental analysis is extensive. The experimental results demonstrate the superiority of the proposed approach compared with CHC. Other interesting experiments related to the impact of $\\alpha$ and \\textsf{sizenn}, robustness and extension to different LSH functions are also included in the supplementary material.\n\nThe paper has the following weaknesses:\n\nW1. Even though I like the motivation, the authors only directly leverage the polar codes and the list decoding method for multi-probing, which makes the novelty somehow limited.\n\nW2. They indeed embed the data point in a high-dimensional latent space (i.e., \\textsf{cdim} bits), but the closest clusters they aim to find for the query are represented in a low-dimensional space (i.e., \\textsf{nbit} bits). Can you provide more insights into the benefits of the high-dimensional latent space?\n\nW3. I think the \\textsf{ndis} is a good measurement if we want to ignore the benefits from the implementation level; it could be better if the author could also contain the embedding cost. For example, for the hyperplane LSH by Charikar (2002), as both distance cost and a single LSH function cost are O(d), each LSH function can be included and considered once \\textsf{ndis}.\n\nW4. The experiments provide many results about different \\textsf{cdim} values. As \\textsf{nbit} is also a vital parameter for PCNN, Can the authors also provide some more results about the impacts of different \\textsf{nbit} values?\n\nW5. They provide pre-processing time and query time complexities for PCNN. To make a complete analysis. It will be nice to provide space analysis. It would also be nice to extend the experimental analysis with a scalability study to examine how the \\textsf{ndis} evolves as the size of the input data increases.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written, and the figure makes the techniques easy to follow. \n\nA minor issue with the clarity is that readers might not be familiar with the Polar code and the list-decoding methods. They might shorten the experimental setup (e.g., simplify the datasets and provide more details in the supplementary material) to make room for moving the background of the Polar code and the list-decoding methods to the main paper.",
            "summary_of_the_review": "In summary, the authors did a good job by leveraging the Polar code and the list-decoding method for similarity search, but I still have some concerns about its effectiveness and some issues in the experiments. Thus, I initially give a borderline acceptance.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_8eNv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_8eNv"
        ]
    },
    {
        "id": "ciSuaQ-zmA",
        "original": null,
        "number": 2,
        "cdate": 1666582057937,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582057937,
        "tmdate": 1666582057937,
        "tddate": null,
        "forum": "-jP_rDkyfpI",
        "replyto": "-jP_rDkyfpI",
        "invitation": "ICLR.cc/2023/Conference/Paper1683/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Takes the idea of polar codes (and polar coding) to develop an approximate nearest neighbour scheme with some efficiency.\nInvestigates the application of that to search in three databases - all three containing SIFT visual descriptors but one containing text as well.\nThe claims and results tend to show that the method produces better recall than the competitors (principally variants of hyperplane LSH with various numbers of multiple tables; although another version of LSH using a (data dependent) hyperplane chosen using the method of Tissier et. al is also briefly investigated). \nThis better performance on recall is despite using less than the sort(D) distance computations for a dataset of size D, generally required for the comparators.",
            "strength_and_weaknesses": "The strengths are that the proposal seems sound - using polar codes seems like a good thing to do and this is supported by the experiments. The paper is well written in most ways. So I believe this is a solid paper with a solid contribution and written at least welklk enough for acceptance.\n\nAs per the next section - the novelty *whilst probably enough* doesn't seem that inspirational and that insightful *on my reading* of the *current manuscript*. In that regard, perhaps the hypothesis that the cdim=d is a good choice (mentioned in the footnote 2 and elsewhere) might be the more interesting aspect to the work from my perspective - and it's a pity there isn't more light on this. That said, the paper is solid enough to be a really strong contender for publication even in the current form.\n\nThe range of data sets seems limited. I don't want to make strong point here - however it would be better to demonstrate performance on a wider variety of database types and hence potential applications - but I am mindful of the time cost and decline pressures.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "While the paper says in part that it uses a standard (freely available) python library - it does say \"heavily modified\" and it isn't clear to me how much of the three algorithms that make up the overall scheme, are \"covered\" but the library - the placing of the aforementioned comment, in the paper, suggests only for algorithm 3. However, they declare they will make the code available. That would *suggest* that the reproducibility should be somewhat assured.\n\nThe novelty appears to be clearly in the recognition that polar codes could be used in ANNS. It seems to me, from my standpoint, that unless there is missed prior art in that respect, then the novelty is sufficient. I am not all that clear on how much of an inspirational jump it is to make the connection but at the moment I am inclined to believe it is significant. (BTW on the \"forced choice\" questions below I can only choose \"The contributions are significant, and do not exist in prior works.\" because all other options seem too strong in the implied deficiencies they offer). Somewhat ditto on empirical support - even though this is one area the paper could be improved, clearly.\n\nOverall, the clarity of the paper and the quality seem good to me. That said, I find the main part a bit slow and repetitive and suspect it would be improved by making it tighter and space saving so that more of the appendices could be fitted into the main paper.",
            "summary_of_the_review": "It seems to me the gains are sufficient to be of interest to people (working in or reliant on ANNS). It seems to me the idea is sound, and if not already published, should be. The paper is written well enough. These three things - to me - are completing for acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_FYov"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_FYov"
        ]
    },
    {
        "id": "KmhQi-RZGSG",
        "original": null,
        "number": 3,
        "cdate": 1666659722938,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659722938,
        "tmdate": 1666659722938,
        "tddate": null,
        "forum": "-jP_rDkyfpI",
        "replyto": "-jP_rDkyfpI",
        "invitation": "ICLR.cc/2023/Conference/Paper1683/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the approximate nearest neighbor search problem.  Specifically, this paper proposes a Polar Code Nearest-Neighbor (PCNN) algorithm. This algorithm uses error-correcting codes to build clusters in the latent space in high dimensionality.  Compared to classical LSH clustering, PCNN uses few hash tables to achieve the same performance. As a result, PCNN is memory efficient compared to LSH.",
            "strength_and_weaknesses": "Strength:\n1. The combination of LSH and error-correction code is novel. \n\n2. This paper is well-organized. Figure 1 is illustrative for readers to understand the functionality of PCNN\n\n3. Large ANNS datasets are used for empirical evaluation, making a fair comparison of PCNN with LSH\n\nWeakness:\n1. Stronger arguments is required for the motivation of applying  error-correction code in ANNS.\n\n2. In the evaluation, the comparison of PCNN with product quantization approaches is missing.\n\n3. For binary datasets, MinHash algorithms should also be considered as a baseline.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed PCNN algorithm is easy to follow. The paper is well-organized.",
            "summary_of_the_review": "This paper introduces the error-correction code techniques in the field of ANNS, This combination is novel since it opens a new direction for ANNS. However, both the motivation and empirical evaluation can be further improved for better quality.\n\nQuestions\n1. Is there any justification for why error-correction code should be applied in ANNS? Why is error-correction code a better way to manage LSH functions?\n\n2. Is it possible to provide theoretical guarantees on the clustering quality of PCNN?\n\n3. In ANNS evaluation, it is inevitable to compare with state-of-the-art graph/quantization approaches for efficiency-accuracy tradeoffs. In this setting, LSH-based approaches may not be the best choice for dense vectors. I would recommend a study in high dimensional and sparse regime with a comparison to Minhash\n\n4. Can we provide privacy guarantees for PCNN?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_sMa7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_sMa7"
        ]
    },
    {
        "id": "n9DeAWRx1gc",
        "original": null,
        "number": 4,
        "cdate": 1667592544485,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667592544485,
        "tmdate": 1667592544485,
        "tddate": null,
        "forum": "-jP_rDkyfpI",
        "replyto": "-jP_rDkyfpI",
        "invitation": "ICLR.cc/2023/Conference/Paper1683/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a locality sensitive hashing scheme, applicable to approximate nearest neighbor search, using Polar codes as the sparse collection of hash values.",
            "strength_and_weaknesses": "The paper does not prove any rigorous guarantees or bounds on the proposed scheme. It's validated solely empirically.",
            "clarity,_quality,_novelty_and_reproducibility": "The writeup is clear, but hard to evaluate lacking any concrete claims that the scheme generally works, or works under certain assumptions.",
            "summary_of_the_review": "It's an interesting idea, but its validation is not convincing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_96rD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1683/Reviewer_96rD"
        ]
    }
]