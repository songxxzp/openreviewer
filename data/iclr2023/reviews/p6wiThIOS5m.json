[
    {
        "id": "0kRAMeubJC",
        "original": null,
        "number": 1,
        "cdate": 1666646503361,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646503361,
        "tmdate": 1666646503361,
        "tddate": null,
        "forum": "p6wiThIOS5m",
        "replyto": "p6wiThIOS5m",
        "invitation": "ICLR.cc/2023/Conference/Paper3752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides bounds on the multi-task sample complexity of reinforcement learning in bilinear classes (recently introduced by Du et al., generalizing several existing notions) when the Bellman errors of the tasks can be parameterized in terms of a small set of common features.",
            "strength_and_weaknesses": "The main strength is that the work extends the current state of the art in the theory of RL in large feature spaces by allowing multiple tasks to share features in a natural way. The work seems sound, and fairly general.\n\nThere are three main weaknesses: first, given that one has set out to consider multi-task + RL, the work has some flavor of \"turning the crank,\" combining known approaches to feature sharing in multi-task learning with the techniques for analyzing RL from recent works. \n\nSecond, from this perspective, the bounds obtained are surprisingly weak, in that they retain a high-order dependence on Md, the number of tasks times the ambient feature dimension. In this setting, I would expect a dependence on Mk with a lower-order dependence on d (that is independent of the number of tasks). No justification is provided for why such a bound may not be possible, leaving the impression that this bound is a \"first stab.\"\n\nThird, the approach relies on an ERM oracle. While this limitation is shared with many works in RL, some recent works on linear classes (e.g., Jin et al., Yang & Wang) do not require this. The work hints that an efficient algorithm might exist for these classes, but stops short of providing one. The work would have been much more compelling if such an algorithm had been described.",
            "clarity,_quality,_novelty_and_reproducibility": "Although the notation is a little overwhelming in the formulation of the ERM problem in particular, the work is reasonably straightforward and so it is reasonably clear. \n\nAs mentioned above, the novelty seems to lie primarily in being the first to combine the two notions of bilinear classes of RL environments with feature-sharing multi-task learning. This is OK, but a bit limited. \n\nAs far as quality goes, the work seems sound but (as mentioned above) obtains weaker results than I'd expect. Proofs are included and so reproducibility is not at issue.",
            "summary_of_the_review": "On the one hand, I believe that the bounds claimed have not appeared previously in the literature. On the other hand, there does not seem to be much technical novelty involved in obtaining these bounds. The bounds seem likely to be suboptimal and the method is not computationally efficient.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_7kqp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_7kqp"
        ]
    },
    {
        "id": "x-szwaYWb9",
        "original": null,
        "number": 2,
        "cdate": 1666647044159,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647044159,
        "tmdate": 1666647044159,
        "tddate": null,
        "forum": "p6wiThIOS5m",
        "replyto": "p6wiThIOS5m",
        "invitation": "ICLR.cc/2023/Conference/Paper3752/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the multi-task learning problem with representation learning. Specifically it proposes  online representation learning algorithms to capture the shared features in the different task-specific bilinear forms. Unfortunately, the proposed algorithms are not validated on any RL problem, simulated or real. ",
            "strength_and_weaknesses": "Strengths:\nThe proposed representation learning in low-rank multi-task bilinear task seems to be a very interesting idea. However, I do not feel confident to evaluate its novelty.\n\nWeaknesses:\nThe proposed algorithms are not validated on any RL problem, simulated or real. For me this is mandatory. I suggest to include an experimental validation, even in a toy problem.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nThe paper is well-written and the analysis of the related work is appropriate.\n\nNovelty:\nI do not feel confident to evaluate its novelty.\n\nReproducibility:\nNo validation of the proposed algorithm in any simulated or real problem, therefore, it is not easy to evaluate the reproducibility of the algorithm.",
            "summary_of_the_review": "The proposed representation learning in low-rank multi-task bilinear task seems to be a very interesting idea. However, the proposed algorithm is not validated in any RL problem. My opinion is that such a validation is mandatory.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_C4vX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_C4vX"
        ]
    },
    {
        "id": "9t_h4ZfB6z",
        "original": null,
        "number": 3,
        "cdate": 1666730056854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666730056854,
        "tmdate": 1666730056854,
        "tddate": null,
        "forum": "p6wiThIOS5m",
        "replyto": "p6wiThIOS5m",
        "invitation": "ICLR.cc/2023/Conference/Paper3752/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper tackles the challenge of learning an efficient representation for multi task reinforcement learning. The authors present a learning algorithm for multi-task RL with function approximation, low-rank multi task bilinear class. This algorithm incentivizes the the RL algorithm to improve sample efficiency by leveraging information from multiple tasks at the same time.\nThe authors provides a PAC bound showing that their algorithm is more efficient than learning each task separately.",
            "strength_and_weaknesses": "Strengths:\n\n_ this paper tackles an important challenge multi task learning in reinforcement. As far as I know this paper present the first result for provably efficient multi task reinforcement learning with function approximation\n_ the PAC bound for theorem 5.2 shows the benefit of multi task learning is that it is more efficient than learning the different tasks seperately\n\nWeaknesses:\n\n_ in the definition of low rank multi-task bilinear class the paper the features W still depend on m, in practice we often try to use a single representation to solve multiple MDPs / tasks. I understand that to provide a learning bound it is necessary to have more flexibility in the representation so each tasks can be solved using the shared representation. Nevertheless could you expand a bit on the relationship between you work and using a single representation for all tasks?\n_ it would be useful to provide simple examples of the algorithm on a few simple tasks to assess its empirical performance. Moreover these experiments might highlight issues of the learning dynamics of multi-task reinforcement learning such as ray interference [1] \n_ the realizability asumption (assumption 5.2) seems reasonable to provide a theoretical result but it may not be verified in practice? Do you have an intuition on the performance of the proposed algorithm when this assumption is not verified?\n_ the benefits of the proposed algorithm is only achieved when k << d. It would be useful to provide a sense of how often this condition is verified.\n\n[1] Ray Interference: a Source of Plateaus in Deep Reinforcement Learning, Schaul et al., 2019",
            "clarity,_quality,_novelty_and_reproducibility": "The paper was overall well written however I found the notation used in the paper a bit hard to follow due to the numerous subscripts.",
            "summary_of_the_review": "This paper provides the first provably efficient multi task reinforcement learning algorithm. As such I think it improves our understanding of representation learning and multi task learning, for that reason I recommend accepting the paper.\nYet I recommend that the authors add a few sections with empirical results and discuss more the validity of the assumptions used in their proof.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_k93P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3752/Reviewer_k93P"
        ]
    }
]