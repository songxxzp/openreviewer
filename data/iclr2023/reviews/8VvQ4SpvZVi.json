[
    {
        "id": "Gg6s8_8c_1",
        "original": null,
        "number": 1,
        "cdate": 1666083291684,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666083291684,
        "tmdate": 1666083291684,
        "tddate": null,
        "forum": "8VvQ4SpvZVi",
        "replyto": "8VvQ4SpvZVi",
        "invitation": "ICLR.cc/2023/Conference/Paper3456/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a dual personalization strategy for federated recommendation, which can better handle non-iid user data and improve recommendation performance. The authors propose to use personalized scoring modules and personalized item embeddings on devices, where the model first updates the scoring module and then updates the item embeddings. Although the proposed method is simple, it is surprisingly effective. The authors also provide some discussions on its insight.",
            "strength_and_weaknesses": "Strengths:\n- This paper is clearly written and easy to follow.\n- The proposed method is very simple and easy to use.\n- The performance improvement is quite impressive.\n\nWeaknesses:\n- It seems that the devices need to maintain a large set of item embeddings, which may be somewhat unscalable. Some discussions on how to reduce the number of locally maintained item embeddings are recommended.\n- The authors seem to use sampled metrics over the top recommendation results. In fact, it may not be consistent with the results on the full ranking list (see [1]). \n- It is not clear whether the proposed method still works well for inactive users. Since the scoring module may contain much more parameters than the user embedding, it would require a larger number of samples to train.\n\n[1] Krichene, W., & Rendle, S. (2022). On sampled metrics for item recommendation. Communications of the ACM, 65(7), 75-83.",
            "clarity,_quality,_novelty_and_reproducibility": "This work is well conducted with good clarity. The contribution of this work is moderate but focused.",
            "summary_of_the_review": "This paper presents a good empirical study on federated recommendation. The proposed method is quite simple, general, and effective. Thus, my recommendation is weak accept, though its technical novelty is not very big.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_rUEH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_rUEH"
        ]
    },
    {
        "id": "_KsjdWTDlyW",
        "original": null,
        "number": 2,
        "cdate": 1666353350539,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666353350539,
        "tmdate": 1666353350539,
        "tddate": null,
        "forum": "8VvQ4SpvZVi",
        "replyto": "8VvQ4SpvZVi",
        "invitation": "ICLR.cc/2023/Conference/Paper3456/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "To learn a personalized and lightweight recommendation model for each client, this paper proposes to learn user-specific lightweight models that are deployed on the device side. Furthermore, it introduces a dual personalization mechanism to learn personalized item embedding tables and the score function for each user. Experimental results on four real-world datasets demonstrate the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Pros:\na)\tThe motivation of this paper, i.e., learning a personalized recommendation model for each user, is important.\nb)\tEmpirical results demonstrate the effectiveness of the proposed method.\nc)\tThe paper is well-written and easy to follow.\n\nCons:\na)  This paper argues that the existing federated recommendation models are cumbersome, so it proposes to learn a LIGHTWEIGHT local score function to make personalized predictions on the client side. However, under the recommendation scenario, the item embedding table generally dominates the vast majority of parameters of the model instead of the parameters of the score function. Thus, the proposed method is meaningless.\nb)  The training of the personalized score function and the fine-tuning of the item embedding table are performed locally on the device. However, the training data on each device is very limited, which makes it hard to learn an accurate model.\nc)  The technical novelty of this paper is very limited. Learning the personalized item embedding table and score functions has been studied in [1]. The authors should clarify the key difference between their work and [1].\nd)  Important baselines are missing, such as [1,2]. The authors should compare the proposed method with them.\ne)  There is a duplicate phrase, \u201coptimization framework\u201d in the third contribution on page 2.\n\nReference:\n[1] Lin, Yujie, et al. \"Meta matrix factorization for federated rating predictions.\" Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020.\n[2] Wu, Chuhan, et al. \"A federated graph neural network framework for privacy. preserving personalization.\" Nature Communications 13.1 (2022): 1-10.\n",
            "clarity,_quality,_novelty_and_reproducibility": "a)\tClarity: this paper is well-written and easy to follow.\nb)\tQuality: the quality of this paper is quite fair due to missing some important baselines.\nc)\tNovelty: the technical novelty of this paper is very limited\nd)\tReproducibility: the authors have provided enough descriptions to reproduce the method.\n",
            "summary_of_the_review": "Due to the limited novelty and missing important related work,  I recommend reject. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_kuz5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_kuz5"
        ]
    },
    {
        "id": "rL4DyIFjnf",
        "original": null,
        "number": 3,
        "cdate": 1666457005082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666457005082,
        "tmdate": 1666457005082,
        "tddate": null,
        "forum": "8VvQ4SpvZVi",
        "replyto": "8VvQ4SpvZVi",
        "invitation": "ICLR.cc/2023/Conference/Paper3456/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a new personalized federated training model architecture that does not contain user embeddings explicitly. The model relies on personalized item embedding and scoring function to achieve the personalized recommendation. When conducting federated training (global), it learns a shared embedding parameter for the items. And, during the personalization step, it conducts 1 step gradient fine-tuning for each client. The term \"Dual\" personalization simply comes from separately learned  scoring function that never been federated trained. Experiment results show promising performance improvements.",
            "strength_and_weaknesses": "The idea seems straightforward and somewhat novel in terms of reducing modeling cost.\nThe description of this paper is a bit lack polishing. \nI am also concerning the risk of overfitting of this model. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is fairly written but need some polishing to make it more readable.\nNovelty is a bit weak as encoding user representation into network parameters could be interpreted as matrix factorization where user embeddings are scoring function parameter (even the model also personalized a bit item embedding with one-step gradient). \nThe work seems reproduceable since algorithm is clearly given. But, I have no much confidence to reproduce the experiment results.\n",
            "summary_of_the_review": "The idea seems straightforward and somewhat novel in terms of reducing modeling cost. But the cost reduction is not significant (as least not demonstrated to be significant).\nThe description of this paper is a bit lack polishing. And, I have to guess what the authors try to deliver\n- 1. does \\theta^m contains item embedding? why do you use E and \\theta^m together? are they somewhat different?\n- 2. why is one-step gradient for each client sufficient? any justification or assumption?\nThe scoring functions are never transferred and there is no default scoring function. In this case, how do you handle users who lack interactions? I think this need further discussion. \nI am also concerning the risk of overfitting of this model. As the model personalizing (fine-tuning) ALL of the client parameters. The strong collaborative regularization is missing. Considering the datasets used in this paper are often showing very coherent preference (lack diversity) of each user, it is possible that the client model is simply learned to remember the user's historical interactions. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_EAiQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_EAiQ"
        ]
    },
    {
        "id": "-icz62SNPF6",
        "original": null,
        "number": 4,
        "cdate": 1666848088947,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666848088947,
        "tmdate": 1666848088947,
        "tddate": null,
        "forum": "8VvQ4SpvZVi",
        "replyto": "8VvQ4SpvZVi",
        "invitation": "ICLR.cc/2023/Conference/Paper3456/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors study the problem of federated recommendation with implicit feedback, and propose a new framework with personalized score function and personalized item embedding (without user embedding), which is illustrated in Figure 1(c).",
            "strength_and_weaknesses": "Strength:\n1 The idea of using personalized item embedding in federated recommendation is new (though it is not new in traditional recommendation).\n\nWeakness:\n1 For key issues in federated recommendation, the authors do not contribute/discuss much, e.g., communication cost, privacy protection, time complexity.\n\n2 The technical contribution is limited. For example, the contents of Section 4 are not about a formal and principled solution, but most about heuristics.\n\n3 For the studied problem, there are many recent works, which are not studied in the experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well presented, which is easy to be understood.\n\nIt is not difficult to reproduce the results (though not very easy). The authors are courageed to include more details about empirical studies, e.g., parameter configurations and data preprocessing.\n",
            "summary_of_the_review": "The authors study an important problem of federated recommendation with implicit feedback, and propose a new framework with personalized score function and personalized item embedding.\n\nMy major concern is that the technical contribution compared with existing works on federated recommendation is limited.\n\nMinors:\noptimization framework optimization framework\nIt is a federated version of FedNCF\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_2m4p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3456/Reviewer_2m4p"
        ]
    }
]