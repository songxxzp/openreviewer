[
    {
        "id": "OPabcywGd_",
        "original": null,
        "number": 1,
        "cdate": 1666531759128,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531759128,
        "tmdate": 1666535885067,
        "tddate": null,
        "forum": "0nroZT5gHsS",
        "replyto": "0nroZT5gHsS",
        "invitation": "ICLR.cc/2023/Conference/Paper2872/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed a theoretical framework to analyze the retrieval-based machine learning models for multi-class classification problems. The authors specifically focused on Local Empirical Risk Minimization~(Local ERM), in which the neighboring labeled data of a test sample is retrieved to train a model in a simple function class by minimizing the empirical risk given the retrieved data. The authors analyzed the expected excess risk of Local ERM compared to the global ERM, in which the empirical risk of all the training data was minimized to train a model in a more complex function class. The main results showed that under some assumptions, the expected excess risk of Local ERM is bounded by the sum of an approximation error term, which typically increases as the number of retrieved data increases, and a generalization error term, which typically decreases as the number of retrieved data increases. \n\nThe authors extended the analysis of Local ERM to a two-stage learning framework in which the first stage will learn a feature map whose mapping function can depend on all the training data. The authors also included the analysis of another retrieval-based framework, where the scorer jointly takes the test data and neighboring labeled data for prediction. Lastly, the authors experimentally showed that (I) There exists a trade-off between approximation error term and generalization error term in the Local ERM framework; (II) The Local ERM can achieve the result similar to the SOTA with a much simpler model. ",
            "strength_and_weaknesses": "Theoretical analysis of retrieval-based models on their generalizability is indeed interesting and timely. The presented empirical experiments have also shown the agreement with the analyses. \n\nIt may be interesting to consider how the analysis results may help guide the design and hyperparameter tuning of retrieval-based models. \n\nMore critically, as the paper is mostly on theoretical analysis, the authors may want to improve the presentation and make sure that all the proofs are correct and self-explaining. For example: \n\n1) Proof of Lemma B.2, on which the Theorem 3.4 is based, may not be correct. In the first inequality, the third term should be $8\\delta L_l||\\mathcal{F}^{loc}||_{\\infty}$ instead of $4\\delta L_l||\\mathcal{F}^{loc}||_{\\infty}$. In the second inequality, the authors should explain clearly why the expectation in the second term can be decomposed. \n2) In Appendix C, ${R}_{{U}}^{\\diamond}$ may need to be replaced with ${R}_{{U}, m}^{\\diamond}$  for consistency.\n3) The definition of $\\hat{R}^{\\text{ex}}_l(f)$ in Equation 37 seems to be wrong (should it be $\\hat{R}^{\\text{ex}}_l(f) = \\frac{1}{n}\\sum_{i\\in [n]} l(f(x_i, \\hat{D}^{x_i, r}), y_i)$?). There seems to be an unnecessary \"that\" in the following sentence. Such typos appeared at several places and the authors may want to carefully proofread the paper to improve the presentation. ",
            "clarity,_quality,_novelty_and_reproducibility": "The presented theoretical and empirical results for generalization properties of retrieval-based models are interesting. This reviewer has to apologize as there may be misunderstanding in this review due to the short review time period but the authors may need to check thoroughly their proofs to make sure that the presentation is correct and self-explaining as much as possible. \n\nIt will be more interesting to have the derived results to guide further development of retrieval-based models. ",
            "summary_of_the_review": "The authors proposed a theoretical framework to analyze the retrieval-based machine learning models based on previous generalizability and learnability results. The presented theoretical and empirical results are interesting. The authors may need to check thoroughly their proofs to make sure that the presentation is correct and self-explaining as much as possible. It will be interesting if the authors can test some new learning strategies in retrieval-based models based on the analysis. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_94k1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_94k1"
        ]
    },
    {
        "id": "91oebXKOkR",
        "original": null,
        "number": 2,
        "cdate": 1666759043589,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666759043589,
        "tmdate": 1666759043589,
        "tddate": null,
        "forum": "0nroZT5gHsS",
        "replyto": "0nroZT5gHsS",
        "invitation": "ICLR.cc/2023/Conference/Paper2872/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is motivated by the empirical success of retrieval-based classification models and therefore studies the generalization properties of these models. The models that this paper touches on broadly involve models which retrieves similar labeled examples from training data for an instance. The question that this paper seeks to answer is to provide a theoretical framework that can help analyze the retrieval set in ensuring the empirical performance of retrieval-based models.\n\nThe mathematical setup that this paper proposes is as follows:\n- It considers a multi-class classification setting. There is a training set including i.i.d. samples.\n- It assumes that the underlying data distribution follows a local-regularity structures; this ensures there exists a low-complexity function class that approximates the Bayes optimal for the local classification problem defined by these locally retrieved samples.\n\nFrom a algorithm/model aspect, this paper focuses on two approaches:\n- Local empirical risk minimization first retrieves a neighboring set; then, it identifies a local scorer/function by minimizing the empirical risk of the local set.\n\n- Classification with extended feature space learns a common function over both the original instances and the retrieved neighboring labeled instances.\n\nThe main results of this paper provide generalization upper bounds for both of the above two approaches:\n- The generalization bounds generally depend on some function that depends on the size of the neighborhood retrieval set (in the generalization errors of local ERM), the local and global optimal losses.\n- A similar (albeit simpler) statement is stated for the second approach above.",
            "strength_and_weaknesses": "Strength:\n- This paper formulates a theoretical study of the generalization properties of retrieval based models.\n- It also provides experiments to validate the generalization error bound.\n- The experiments show that the performance of local ERM varies with the size of the neighborhood. In particular, it observes a trend in which the accuracy generally increases with the size of the retrieval set but then decreases afterwards.\n\nWeakness:\n- The significance of the contributed generalization bound is unclear; although understanding the generalization properties of retrieval-based models is a valuable quest, the current bounds rely on specific data regularity conditions and are generally difficult to interpret. Here're some specific feedback:\n    - In eq (6), what does it mean that the complexity of $F^x$ is much less than the complexity of $F^global$?\n    - In theorem 3.4, are all of the terms stated in the generalization bound properly defined? it would help provide a pointer to the def. of each term.\n    - In theorem 4.1, you use $N(r, \\delta)$ in the text but $N(r, \\delta /n)$ in the equation. Is this due to a union bound over the training set?\n- From a quick gloss of the appendix, the techniques also seem standard in the literature, so the technical contribution is limited at best.\n    - It would also help if the main text could include some discussion about the technical contribution.\n- It is also unclear whether and how tight are the proposed generalization bounds.\n- The experiments are largely disconnected with the theoretical statements. There is a lack of elaboration about the benefits predicted by the theoretical results.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-organized and easy to follow for the reviewer.\n\nThe novelty is good as this paper is motivated by an interesting empirical question and attempts a theoretical formulation of the question.\n- The studied approach seems quite related to nearest neighbor methods. Perhaps this should be discussed.\n\nThe appendix provides detailed proofs for the theoretical statements. I have not checked them in length but I also don't see any problem with the proofs.",
            "summary_of_the_review": "Overall this paper provides a study of the generalization properties of retrieval-based models (in the sense of learning with several retrieved similar examples with a test instance). The main results involve generalization error bounds for two approaches (local ERM and extended feature space learning) under a local regularity condition. As stated above, the technical contribution is limited and the bounds could benefit from better interpretation and connection with empirical examples. Therefore, I'm recommending a \"reject\" for this submission.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_uQx9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_uQx9"
        ]
    },
    {
        "id": "EZuriK8pGA",
        "original": null,
        "number": 3,
        "cdate": 1666762414630,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666762414630,
        "tmdate": 1666762852826,
        "tddate": null,
        "forum": "0nroZT5gHsS",
        "replyto": "0nroZT5gHsS",
        "invitation": "ICLR.cc/2023/Conference/Paper2872/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper aims to provide theoretical characterizations of the generalization abilities of retrieval-based models. Specifically, this paper focuses on classification problems and examines two classes of retrieval-based approaches: \n\n1. A local learning framework where a model is trained on retrieved examples and then used to make predictions for the test example.\n2. A global model that treats retrieved examples as augmented features and directly make make predictions for the test example.\n\nFor the local learning framework, an empirical study is conducted to verify the theoretical results for two cases: one that uses the Euclidean distance for retrieval and the other employs a global learned neural representation. The performance of locally trained models improves as more examples are retrieved until a point where the local empirical risk minimization fails due to the lack of model capacity. This empirical study demonstrates the effectiveness of the local learning framework that allows small models to attain competitive performance.\n\nDespite the complexity of theoretical analysis, the paper is presented in a way that the main points are clear and well-motivated. Since I am not an expert of the field, I was unable to verify the correctness of proofs; yet, the implication of the empirical study is straightforward and provides indirect support to authors\u2019 argument. ",
            "strength_and_weaknesses": "See summary",
            "clarity,_quality,_novelty_and_reproducibility": "See summary",
            "summary_of_the_review": "See summary",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_bKCw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_bKCw"
        ]
    },
    {
        "id": "Mw-aiagkkY_",
        "original": null,
        "number": 4,
        "cdate": 1666963115904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666963115904,
        "tmdate": 1666963115904,
        "tddate": null,
        "forum": "0nroZT5gHsS",
        "replyto": "0nroZT5gHsS",
        "invitation": "ICLR.cc/2023/Conference/Paper2872/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper students the theoretical properties of two variants of retrieval-based models, a popular topic in improving large models. The two variants are formulated as a local empirical risk minimization problem and a classification problem in an extended feature space. Theoretical analysis are given in terms of the expected excess risk, with more detailed results for the local empirical risk minimization. Experiments are conducted to verify the theory for local empirical risk minimization.",
            "strength_and_weaknesses": "Strength:\n1. Divide the retrieval-based models into two categories: a local empirical risk minimization problem, and a classification problem in an extended feature space, which provides more clear directions for empirical designs.\n2. Detailed theoretical analysis on the local empirical risk minimization, which enable one to get better ideas on the underlying principles of the related retrieval-based models.\n3. Empirical results also verify part of the theoretical results.\n\nWeaknesses:\n1. The focus of the paper is somewhat disconnected with practical settings. This paper gives more theoretical analysis on the local empirical risk minimization setting, which is rarely applicable in practice, as it needs to learn a separate classifier for each testing samples, which is very expensive. In practice, the extended feature space setting is usually adopted. Unfortunately, there is only limited theoretical results for this case. Moreover, there is no experiments corresponding to the provided results for this setting, i.e., the experiments only focus on the local empirical risk minimization setting. I actually think experiments for the extended feature space is necessary, as from the theoretical results, it indicates that the retrieval set size needs to scale at least logarithmically in the size of the training set, which is somewhat contradicted with practical setting, where typically a few (e.g,, 10) retrieval data points are used while still being able to get good results. I would expect some empirical evidence to verify this claim.\n2. In the local empirical risk minimization setting, it is not clear how the retrieval set size impacts the generalization error. For the bound in Theorem 3.4, it seems to indicate that with larger retrieval set sizes, we can get smaller error. However, the empirical results indicates that larger retrieval set sizes can harm the performance if the classifier is too simple. I think this phenomenon is not reflected in the theoretical result. Is there a way to quantify this?\n\nAlso, do we know the increase rate of r in the (I) term in Theorem 3.4?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nThe paper is written clearly in general, but some description and notation need to be clarified. For example, the (alpha, c)-weak margin condition, is this a reasonable assumption? What does this imply?\n\nNotation: what does the \\ perp mean in Assumption 3.2? \n\nQuality: \nThe quality is fair given some missing pieces of both theoretical results and empirical evidence. See details above.\n\nNovelty:\nThe problem studied is novel. The theoretical results seems to borrow some ideas from existing works, but in my opinion, the method is novel in general.\n\nReproducibility:\nNo code is provided, although I believe the results can be reproduced.",
            "summary_of_the_review": "This paper studies theoretical properties of retrieval based models from two perspectives. It develops expected excess risk for both cases, trying to show the factors impacting the risk, including the size of the retrieval set (which I believe is the most important one). The results are nice, but there are some discrepancies between the theoretical results and the empirical results, as well as some empirical practices.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_5HmN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2872/Reviewer_5HmN"
        ]
    }
]