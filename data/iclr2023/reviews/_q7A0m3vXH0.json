[
    {
        "id": "8D1i13TkEG",
        "original": null,
        "number": 1,
        "cdate": 1666562133794,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562133794,
        "tmdate": 1666562133794,
        "tddate": null,
        "forum": "_q7A0m3vXH0",
        "replyto": "_q7A0m3vXH0",
        "invitation": "ICLR.cc/2023/Conference/Paper6294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a regularization technique for auto-encoders, when the data is non-Euclidean. Conventional regularizers encourage small MSE reconstruction error when input is noised. In contrast, the proposed method replaces MSE reconstruction error with geodesic distances along the data manifold. Empirical study shows that the method is better at estimating geometric score, and could lead to more useful learned features.",
            "strength_and_weaknesses": "The paper has some features that can be considered both as strength and weakness.\n\n1. Insights from differential geometry and manifold learning are introduced. This could educate the machine learning community but also has the risk of not being appreciated.\n\n2. The paper shows extensive empirical results. However, most of them aims at showing a more accurate estimate of geometric score. That is, the gradient of log probability distribution function. While I agree it is necessary to show effectiveness using intrinsic measure like this, I think the community may care more about the practical implications.\n\nAnother weakness is that the method relies on the metric $G(x)$ at each local coordinate. $G(x)$ may not be known a priori. In fact, $G(x)$ is often unknown for many learning problems. The paper should discuss how to handle it in a separate section. Will it require more training data, compared against the conventional regularizer, to figure out the $G(x)$?",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is well written. But as suggested before, language can be made more accessible. For example, I think the notation of Dirichlet energy can be introduced right after Eq. (2). Explain its effect as the regularization term in Eq. (2). Then in section 3.1, manifest that this paper generalizes this conventional Dirichlet energy for manifold case.\n\nThe paper seems novel to me.",
            "summary_of_the_review": "The paper imports notions from differential geometry and manifold learning. This could have pros and cons.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_hFuw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_hFuw"
        ]
    },
    {
        "id": "lZhUjjpIRX",
        "original": null,
        "number": 2,
        "cdate": 1666612664749,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666612664749,
        "tmdate": 1670337631444,
        "tddate": null,
        "forum": "_q7A0m3vXH0",
        "replyto": "_q7A0m3vXH0",
        "invitation": "ICLR.cc/2023/Conference/Paper6294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an autoencoder for data residing on a Riemannian manifold alongside a geometric regularize. The reconstruction trivially replaces Euclidean distances with geodesics ones, and the bulk of the paper is concerned with the regularization. I did not fully understand the regulerization scheme (details below), but it seems related to denoising and contractive autoencoders. Empirically, the method is shown to work well on low-dimensional data; it is unclear if the method will scale to high-dimensional manifolds, which arguably is where the dimensionality reduction associated with autoencoders is most valuable.",
            "strength_and_weaknesses": "## Strengths\n* The paper approaches an important problem as regularization on manifolds is generally understudied.\n* The idea of extending denoising autoencoders to manifold data is neat as it is really simple to work with. I very much appreciate the practicalities of this idea.\n* The empirical study is quite broad as several data sets from different manifolds are considered (see also Weaknesses below).\n\n## Weaknesses\n* In general, I found the paper somewhat difficult to read. As such, the weaknesses listed here may very well be weaknesses of the reader rather than of the paper.\n* The opening motivation for the paper is that standard vector-based regularizers do not work on manifolds. While I generally believe this to be true, I found the demonstration thereof to be somewhat thin. I appreciate the idea of empirically demonstrating the claim, but I think this demonstration should be more elaborate.\n* I didn't understand the sentence (page 4), \"use the weighted volume element $\\rho(x) dx$ instead of $\\sqrt{\\det G} dx$.\" Does this mean that you ignore the volume element of the metric? That sounds dodgy.\n* I did not understand Eq. 5, in particular the trace-term. Is my reading correct that $\\left(\\frac{\\partial r}{\\partial x}\\right)^T G \\left(\\frac{\\partial r}{\\partial x}\\right)$ is a scalar, which can be moved outside the trace-function? I did not understand why the inverse metric appears in this expression. Perhaps it's obvious, but it wasn't to me.\n* I also had trouble understanding Eq 8. Why does this use the inverse metric? I would have intuitively guessed that it should be the metric (not its inverse). Can some explanation be provided?\n* The experiments generally focus on very low-dimensional manifolds (e.g. 3x3 symmetric positive definite matrices). I would expect that autoencoder-style models have most value on high-dimensional data. I suppose that the method has difficulty scaling to high-dimensional data; what is the main bottleneck?\n\n## Minor issues\n* The paper generally talks of Riemannian latent spaces, but, as far as I could tell, mostly Euclidean latent spaces are considered. Perhaps one should here call on one of the many papers which argue that autoencoder-style latent spaces should be viewed as Riemannian (through the pull-back metric). See e.g. https://arxiv.org/abs/1710.11379",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity:\nI found the motivation of the paper to be quite clear, but I struggled with the more mathematical parts of the paper. I would have valued a bit more hand-holding along the way.\n\n### Quality:\nThe work appears sensible, and I particularly enjoyed the denoising autoencoder extension to manifolds. That's very clean and easy to understand. I have a hard time judging the remaining parts of the paper as I didn't quite understand the math.\n\n### Novelty:\nAs far as I can tell, the paper is quite novel.\n\n### Reproducibility\nI would not be able to reproduce the experiments from the paper alone. I'm happy to see that code will be released, though.\n\n",
            "summary_of_the_review": "A promising paper, that I did not fully understand. If I understand the work better during the rebuttal phase I expect to have a more positive vote.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_F6Np"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_F6Np"
        ]
    },
    {
        "id": "7dFtOYrSAd",
        "original": null,
        "number": 3,
        "cdate": 1666704285537,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666704285537,
        "tmdate": 1670299348373,
        "tddate": null,
        "forum": "_q7A0m3vXH0",
        "replyto": "_q7A0m3vXH0",
        "invitation": "ICLR.cc/2023/Conference/Paper6294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose geometrically regularized autoencoders for non-Euclidean data. The main contribution of the paper is adapting the regularization terms in the denoising autoencoder (DAE) and the reconstruction contractive autoencoder (RCAE) to the non-Euclidean setting. If the manifold from which the data are sampled are known a priori, the proposed autoencoders achieve improved reconstruction performance, and are able to estimate the score of the non-Euclidean data.",
            "strength_and_weaknesses": "**Strength**\n1. The motivation of the paper is clear. It is also very well-organized. I especially like the different notations for points on the manifold and their coordinates.\n2. Theorem 1 suggests that the geometric score can be estimated from the trained auto-encoder (a generalization of the result by Alain & Bengio, 2014 in the Euclidean setting), and the numerical results are convincing.\n\n**Weakness**\n1. My biggest concern is the increased computational cost after taking into account the geometric information (exponential maps, geodesics, etc.) This seems to be buried under the rug of the paper. I would like to see come comparison of the computational time in training the vanilla autoencoder and the proposed models.\n2. The author seems to be using one single chart for a manifold. However, general manifolds are typically not parametrizable using one chart. What would happen if $r(x)$ and $x$ appear in two different charts?\n3. It might be a good idea to elaborate, in the main text, what \"$\\approx$\" means in equation (7).\n4. Also, is RCAE actively used in the community? There does not seem to be any reference on that in the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and very easy to read. The idea of adapting the regularization to non-Euclidean data is novel and interesting.",
            "summary_of_the_review": "I think this is an interesting paper. I have some concern on the practical implementation and its implication on the computational cost. I am willing to adjust my rating based on the authors' response.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_Ts5i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6294/Reviewer_Ts5i"
        ]
    }
]