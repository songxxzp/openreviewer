[
    {
        "id": "plurI5MlMQS",
        "original": null,
        "number": 1,
        "cdate": 1666673196519,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673196519,
        "tmdate": 1668717109928,
        "tddate": null,
        "forum": "H8XpqEkbua_",
        "replyto": "H8XpqEkbua_",
        "invitation": "ICLR.cc/2023/Conference/Paper1264/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper first discusses the issues in the controversial assumptions in a recent literature. Then it proposes two differentially private dataset condensation algorithms LDPDC and NDPDC. In the experiment, it makes the evaluations on multiple datasets and the results show that the proposed two methods achieves better privacy-utility trade-off than baselines.",
            "strength_and_weaknesses": "**Strengths**\n1. The experiment results of two proposed methods show the promising improvement from the baselines.\n\n**Weakness**\n1. My major concern is that this paper misses an important and relevant literature [1], which might influence the novelty and significance of the results. The algorithm in [1] is similar to Algorithm 1 in this paper. The slight difference is that in this paper, the data batch is sampled by Poisson sampling, while [1] samples the data without replacement. Moreover, it is questionable how much improvement LDPDC and NDPDC have by comparing them with this literature.\n2. The main experiment results could be more convincible if different algorithms can be compared with the (mostly) fixed DP-Budget. It is also worth showing at which $epsilon$ the performance of NDPDC would break down. They will help understand the comparison with the baselines. They are also convenient for later work to build the comparison with this work.\n3. The writing of this paper can be improved. Below some clarity questions or suggestions are listed:\n - The abbreviation \"DM\" is not introduced.\n - The definition of $T_c$ is introduced in page 5, but appears first in page 4.\n - The number of iteration $I$ is not mentioned in the Algorithm 2.\n - Missing the description of whether the feature extractor $\\phi$ is pretrained.\n - Missing the description of data augmentation in Algorithm 2.\n - What is the privacy budget setting for Table 2\n - Which column is the \"ConvNet\" mentioned in the second paragraph of section 4.2\n\n[1] Lee, Kangwook, et al. \"Synthesizing differentially private datasets using random mixing.\" 2019 IEEE International Symposium on Information Theory (ISIT). IEEE, 2019.\n\n\n--------After Discussion-------\nGiven that the difference between [1] and LDPDC is clarified, I raised my score to 6. I recommend authors to add the discussion and solve the clarification questions in the revision.",
            "clarity,_quality,_novelty_and_reproducibility": "See the *Strength And Weaknesses*.",
            "summary_of_the_review": "I appreciate this work studies the dataset condensation with differential privacy. However, because of the missing discussion and comparison with [1], the novelty and result significance are doubt. Therefore, I recommend reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_Spfc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_Spfc"
        ]
    },
    {
        "id": "R7YJxidgI6v",
        "original": null,
        "number": 2,
        "cdate": 1666821304545,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666821304545,
        "tmdate": 1666821304545,
        "tddate": null,
        "forum": "H8XpqEkbua_",
        "replyto": "H8XpqEkbua_",
        "invitation": "ICLR.cc/2023/Conference/Paper1264/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Paper proposes differentially private dataset condensation, and improvement over the ICML'22 work [1], and shows that the proposed method provides good utility.\n\n[1] Dong, T., Zhao, B., & Lyu, L. (2022). Privacy for Free: How does Dataset Condensation Help Privacy?. arXiv preprint arXiv:2206.00240. ",
            "strength_and_weaknesses": "Paper proposes a differentially private version of dataset condensation and proposes two DP methods, linear and non-linear differentially private dataset condensation. Proposed methods claim to avoid the pitfall of [1], and provide formal privacy guarantees. \n\nEmpirical evaluation shows that the proposed DP methods perform better than DP-sinkhorn and DP-MERF, and provide tighter privacy guarantees. \n\nOverall, I like the paper. I have not checked the proofs in detail, assuming they go through, the proposed methods are potentially useful. I think a brief discussion on the utility and use of DP data condensation methods vs general DP data generation would be useful.",
            "clarity,_quality,_novelty_and_reproducibility": "Paper was easy to read",
            "summary_of_the_review": "I like the proposed method, and assuming the proofs are solid, I have no problem accepting it to the conference.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_kpgg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_kpgg"
        ]
    },
    {
        "id": "AYyOBbN77Fg",
        "original": null,
        "number": 3,
        "cdate": 1666934070706,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666934070706,
        "tmdate": 1670719524563,
        "tddate": null,
        "forum": "H8XpqEkbua_",
        "replyto": "H8XpqEkbua_",
        "invitation": "ICLR.cc/2023/Conference/Paper1264/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a data condensation algorithm that guarantees differential privacy, and demonstrated empirically that the proposed algorithm works better than existing data condensation algorithms.",
            "strength_and_weaknesses": "Strength: The idea seems interesting and the empirical results seem good.\n\nWeakness: I'm quite confused about how the algorithm works.",
            "clarity,_quality,_novelty_and_reproducibility": "I'm confused about Algorithm 2. I think the presentation might need to be improved to clarify things. And since I'm not able to follow the algorithm, I'm not quite sure about the correctness of the privacy analysis. \n- S seems to be a set but then we have S = S - eta*gradient of l. How does that work? Is S like a concatenation of vectors? \n- What is the gradient with respect to? Is theta some learnable parameter?\n- I think it would be better if you write down the gradient explicitly.\n- What does it mean by \"initialize S ... with random noise\"?\n\nSome other comments:\n- In Table 1, why don't we compare different methods under the same privacy budget?\n- I'm confused about the formulation in (1). Wouldn't it be optimal if I choose S = T? I feel like there need to be some term related to how condense / private S is, right?\n\n--- update ---\n\nThe authors' response and revision has cleared my questions. ",
            "summary_of_the_review": "The general idea seems interesting, but I wasn't able to understand Algorithm 2 to judge the correctness of privacy.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_gV1f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1264/Reviewer_gV1f"
        ]
    }
]