[
    {
        "id": "tR46hu3SV_0",
        "original": null,
        "number": 1,
        "cdate": 1666647710154,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647710154,
        "tmdate": 1666647812754,
        "tddate": null,
        "forum": "4eJ43EN2g6l",
        "replyto": "4eJ43EN2g6l",
        "invitation": "ICLR.cc/2023/Conference/Paper1783/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose to formulate sketch generation as the reversal process of sketch deformation, allowing the use of diffusion process that's more appropriate to stroke based sketch drawing. This is quite similar to [Luhman and Luhman, 2020] which use the same approach but on handwriting generation. The authors also propose recognition guided diffusion to speed up the diffusion process, and experiment on sketch completion based on perceptual metric. ",
            "strength_and_weaknesses": "Strength\n\n- the method and choice of coordinate makes sense for sketch\n\n- the results support the claim including how keeping the order is beneficial \n\n- recognition based step skipping and rectifying bad sketches are quite interesting\n\n- the evaluation seems quite extensive\n\nWeakness\n\n - I think there are a lot of similarities with existing works such as [Luhman and Luhman, 2020] down to the use of diffusion model on stroke-3 coordinate (delta x, delta y, pen state). This means the actual novel contribution of the paper is pretty small. The paper is more about applying existing methods toward a new problem than coming up with an entirely new approach, ",
            "clarity,_quality,_novelty_and_reproducibility": "Some part of the paper is quite well written, while some part can be somewhat difficult to understand. For example, the intro is quite convincing while related work can be somewhat confusing.\n\nWith that said, overall, I do think the paper is easy to understand.\n\nThe reproducibility is a bit tricky,  I don't think there is enough information to reproduce exactly the model that was used. The release of training code and pre-trained model would be required for the results to be reproducible.  ",
            "summary_of_the_review": "The paper is pretty much a borderline for me. On one hand, it's the first sketch generation that formulate as diffusion process, along with other nice properties, on the other hand there are quite a lot of similarities with previous works that I'm not sure if the current contributions is enough. The choice of model is also somewhat confusing to me; convolutional U-Net with slight modification (mapping to/from 128 embedding) on coordinate type of input/output (delta x, delta y, pen state). RNN, however, is used to learn recognizability of sketch. It just seems a bit odd, I would love some clarification on the motivation behind these choice of architecture.  \n\nOverall, I do think the novelty is not everything. I am somewhat positive about the key ideas of the paper; diffusion for sketch generation, formulate as iteratively deform/de-deform the sketch, recognizability to guide faster steps diffusion, rectifying bad sketch, etc. The evaluation is also quite extensive, with ablation that make sense (love the random stroke/point order). So my initial recommendation is a slightly more toward accept, as long as the authors can provide clarification to my concerns. But I can be convinced either way.\n\nOthers:\nthe reference for Diff-HW seems to be wrong? isn't it out 2020 instead of 2010?",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_4TYn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_4TYn"
        ]
    },
    {
        "id": "f9uTGjjUtF",
        "original": null,
        "number": 2,
        "cdate": 1666680364491,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680364491,
        "tmdate": 1666680364491,
        "tddate": null,
        "forum": "4eJ43EN2g6l",
        "replyto": "4eJ43EN2g6l",
        "invitation": "ICLR.cc/2023/Conference/Paper1783/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work introduces generating vectorized sketch by modeling the stroke-point locations and pen states via a diffusion model. One major contribution is to embed recognizability of sketch during the sampling. It explores both cases of starting from a random scattered points or an incomplete sketch. Experiments show some appealing results as well as solid quantitative evaluations, ablation study and component analysis.",
            "strength_and_weaknesses": "+ A nice addition of introducing diffusion model learning into the vector image generation, compare with tons of pixel image generation\n+ Joint modeling of both point location and pen state\n+ A new adaptive sampling strategy based on sketch recognizability\n+ The ablation in Sec. 4.1 is very impressive, covering every aspect about the proposed method so that readers know how each factor will affect the result\n\nThe diffusion process in Figure 2 (a) somehow could serve as a tutorial-like process to teach people how to draw an object. I have some minor concerns listed below:\n\nIs this diffusion model designed as class-conditioned or not? Basically, starting from a random scattered points, what type of guidance is driving those points to form the final object, or is it a one2many mapping?\n\nInstead of conditioning on an incomplete sketch to refine, one more interesting application is to invert a given sketch and generate its variations, to a simpler or a better version for different needs.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This work is clearly presented. A good combination of DM and vector data which is not explored before. Looks it is reproducible as authors clearly introduced dataset, hyper-parameters and exp settings in the paper.",
            "summary_of_the_review": "This is a good extension of applying powerful diffusion models to vector domain which is potentially useful for more complex vector design or art regardless of resolution. I do not have too much criticism towards this work. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not aware of ethics concerns",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_zdyq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_zdyq"
        ]
    },
    {
        "id": "BcBOD87Stc",
        "original": null,
        "number": 3,
        "cdate": 1666838069895,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666838069895,
        "tmdate": 1666838069895,
        "tddate": null,
        "forum": "4eJ43EN2g6l",
        "replyto": "4eJ43EN2g6l",
        "invitation": "ICLR.cc/2023/Conference/Paper1783/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed using diffusion model to generate vectorized sketches. A vectorized sketch is represented as a sequence of points, and a *pen state* indicating whether the pen is touching the paper. The authors formulated the problem as generating a fixed number of 3D points using a 1D convolution-based DDPM. To accelerate the sampling process, the paper proposed using an RNN network to predict whether the noisy example is already recognizable -- empirically, more reverse steps are needed when the result starts to become recognizable.\nThe proposed model achieved SOTA performance on sketch generation. The version using RNN-based shortcut sampling required significantly less computation compared to Naive DDPM sampling while retaining the generation quality.\nIn addition, similar to image diffusion models, the proposed model is able to perform tasks such as sketch refinement and healing.",
            "strength_and_weaknesses": "## Strength:\n* This is the first paper that applies DDPM to the task of sketch generation.\n* The proposed method significantly outperforms previous methods.\n* The proposed shortcut sampling scheme significantly reduced sampling time while retaining the quality better than DDIM given the same number of steps.\n* The proposed method has all the versatility a DDPM provides -- it can be applied to conditional generation tasks without retraining.\n\n## Weaknesses\n* The shortcut sampling technique, although worked well empirically, is not backed by theory. It will be more useful if the author can share more theoretical insights & generalize it to other tasks.\n* In section 3.8, the paper mentioned using a pretrained 2D CNN to evaluate similarity between two sketches. It is unclear how the gradient from a 2D CNN is propagated to a vectorized sketch. Is there differentiable rendering?\n* The paper used a fixed number of stroke points for each sketch. This might limit its real-world application.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written, with comprehensive visualization and numerical results. The originality of the paper lies in the application of DDPM to the new task, as well as the task-specific fast sampling algorithm. \n\n[Reproducibility] Some of the domain-specific implementation details are lacking, such as how the fixed number of points per sketch are sampled from the dataset, as well as how the guidance scores in the conditional generation tasks are obtained. The paper also did not include any promise of code release.",
            "summary_of_the_review": "The paper is well-written and the experiments are comprehensive. Being a domain-specific application of an existing technique (DDPM), the paper has not only thoroughly explored the benefits it provides, but also included some interesting new contributions, such as shortcut sampling. Although it will be better if this finding can be generalized beyond sketch generation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_ocgD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1783/Reviewer_ocgD"
        ]
    }
]