[
    {
        "id": "CinfydAUCB",
        "original": null,
        "number": 1,
        "cdate": 1666615625968,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615625968,
        "tmdate": 1666615625968,
        "tddate": null,
        "forum": "SXZr8aDKia",
        "replyto": "SXZr8aDKia",
        "invitation": "ICLR.cc/2023/Conference/Paper2165/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose FedPAC for personalized federated learning, which aims to learn a better representation by leveraging global semantic knowledge. Comprehensive experimental results multiple benchmarks demonstrate the effectiveness of the proposed framework.",
            "strength_and_weaknesses": "Strength\n\nThe structure of the proposed FedPAC is reasonable and easy to follow.\nThe studied problem (personalized federated learning) is interesting and different applications may benefit from it.\nthe experiment results are extensive and impressive\nThe authors also give a theoretical analysis.\n\nWeaknesses\n\nThe description of motivation could be improved.\nThe paper could benefit from describing personalized federated learning in more detail.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well-written and the presented results are satisfactory. The evaluation is carried out on public datasets, which can facilitate future comparisons with novel methods. An ablation study is also given to evaluate the contribution of the different losses proposed by the paper. In general, the proposed DREAM framework is not difficult to reproduce.",
            "summary_of_the_review": "I am generally optimistic about this submission. Considering the well-motivated problem, novel framework and impressive experimental results, I have no negative comments on the quality of the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_ivCQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_ivCQ"
        ]
    },
    {
        "id": "YwTySLVt2a",
        "original": null,
        "number": 2,
        "cdate": 1666807113849,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666807113849,
        "tmdate": 1666807113849,
        "tddate": null,
        "forum": "SXZr8aDKia",
        "replyto": "SXZr8aDKia",
        "invitation": "ICLR.cc/2023/Conference/Paper2165/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work solves personalized federated learning (PFL) setting by developing feature alignment mechanism and classifier collaboration. Concretely, this feature alignment minimizes the distance between local feature representations and global centroids. And classifier collaboration utilizes linear combination of multiple local classifiers to customize new classifier. The current work conducts experiments on four datasets to verify the effectiveness of proposed method.",
            "strength_and_weaknesses": "Strength:\n\n1. The improvement of experimental results is significant.\n\nWeaknesses:\n\n1. The description of some details in the proposed method is not clear.\n\n2. Need to make comparisons with some recent PFL works to verify the effectiveness.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing part should be improved, and the novelty of algorithm is limited.",
            "summary_of_the_review": "This work solves personalized federated learning (PFL) setting by developing feature alignment mechanism and classifier collaboration. Concretely, this feature alignment minimizes the distance between local feature representations and global centroids. And classifier collaboration utilizes linear combination of multiple local classifiers to customize new classifier. The current work conducts experiments on four datasets to verify the effectiveness of proposed method.\n\nHowever, I have several concerns on this work.\n\n1. Eq. (1) is the optimization goal of traditional federated learning (FL) instead of that of PFL task.\n\n2. The feature alignment regularization needs to access the global centroids which are obtained by aggregating local centroids. Under this condition, the data distribution information of each client has been leaked out, which violates the requirement of privacy protection in PFL task.\n\n3. In classifier collaboration, why the simple linear combination of local classifiers can find these clients with the similar distributions? It would be better to analyze the combination coefficients to support this point.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_Ddph"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_Ddph"
        ]
    },
    {
        "id": "XvIoG7SNOg",
        "original": null,
        "number": 3,
        "cdate": 1667430228657,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667430228657,
        "tmdate": 1670372911288,
        "tddate": null,
        "forum": "SXZr8aDKia",
        "replyto": "SXZr8aDKia",
        "invitation": "ICLR.cc/2023/Conference/Paper2165/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes to deal with the data heterogeneity in federated learning by local-global feature alignment and weighted combination of local classifiers. The whole model is decomposed into two parts, a feature extractor $f$ and a linear classifier $g$ built on $f$. The feature alignment is achieved by extracting feature centroid for each label class. The parameters of each local classifier $g_i$ is combined with other classifiers by optimized weights so as to bundle similar local clients. ",
            "strength_and_weaknesses": "**Strength**\n1. The proposed framework is novel. The decomposition of feature learning and linear classification helps customize local clients.\n2. The performance is theoretically analyzed based on a simplified model and numerically validated by experiments on several datasets.\n\n**Weakness**\n1. The heterogeneity of data considered in this paper is a specialized one. Generally, the heterogeneous local data distributions will be different in both total number of samples and number of feasible label classes. Current setting assumes each client has the same size of data and observes the full set of label classes. It is interesting to see the performance of the proposed method when the local data distributions are heterogeneous enough.\n2. In Eq. (3), the authors assume there only exists one centroid for each label class. This assumption needs to be better explained. It is likely that samples in one label class may come from two different centroids. Simply averaging all the features as one centroid may not always be true.\n3. In Eq. (4), the authors mention $\\alpha$ is optimized to reduce the local testing loss. It is not clear whether the local test data is different from the test data used to show Table 1.\n\n\n\n  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper proposes a novel idea and the presentation is good. There may exist some flaws mentioned above.",
            "summary_of_the_review": "The paper is overall well-written but there are some critical issues that need to be addressed. I'm happy to increase my evaluation if my concerns (see weakness) are addressed.\n\n----------- Post rebuttal ----------\n\nAll of my concerns are well-addressed. I increased my evaluation from 5 to 8.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_8wN3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_8wN3"
        ]
    },
    {
        "id": "plJzRlcfK-",
        "original": null,
        "number": 4,
        "cdate": 1667521407284,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667521407284,
        "tmdate": 1667522497490,
        "tddate": null,
        "forum": "SXZr8aDKia",
        "replyto": "SXZr8aDKia",
        "invitation": "ICLR.cc/2023/Conference/Paper2165/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new learning framework to tackle the label distribution skew challenge in federated learning. Specifically, the paper introduces a novel feature representation alignment technique and a classifier combination technique to exploit both shared representation and inter-client classifier collaboration. By using a local regularization term related to the global feature centroids of each class, the framework mitigates the drift of local features during the learning process. By introducing a linear combination of classifiers with optimized coefficients during training, the framework allows similar clients to share more information while avoiding negative transfer from more distinct clients.",
            "strength_and_weaknesses": "Strengths: The proposed method is well-motivated. The use of global feature centroids in local training is straightforward and practical, and the idea of forming classifiers combination coefficient selection as a quadratic programming problem is elegant. Evaluation and ablation studies seem convincing.\n\nWeaknesses: The proposed framework tackles the specific label distribution skew challenge in federated learning. It would be nice if the authors could discuss whether the method generalizes to other challenges caused by heterogeneous data distributions in federated learning, for example, when the number of classes is different (if so, whether the method needs any adaptations; if not, why the method has certain limited applications).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow. The work is original to my knowledge.",
            "summary_of_the_review": "This paper introduces global feature centroids in feature regularization and classifier combination weights selection through quadratic programming to improve personalized federated learning. The proposed method is backed by good intuitive interpretation, theoretical analyses, and convincing evaluation results. The ideas introduced in this paper could be inspiring to the relevant community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_zWd3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2165/Reviewer_zWd3"
        ]
    }
]