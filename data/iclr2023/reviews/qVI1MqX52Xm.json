[
    {
        "id": "sM6nqs_nXT",
        "original": null,
        "number": 1,
        "cdate": 1666147573605,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666147573605,
        "tmdate": 1671123333231,
        "tddate": null,
        "forum": "qVI1MqX52Xm",
        "replyto": "qVI1MqX52Xm",
        "invitation": "ICLR.cc/2023/Conference/Paper6029/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a more generic learnable loss objective which enables a joint reweighting of instances and labels at once, in order to mitigate the effect of noise labels on the model generalization. Specifically, their method dynamically adjusts the per-sample importance weight between the real observed labels and pseudo-labels, where the weights are efficiently determined in a meta process.",
            "strength_and_weaknesses": "strength:\n1. the motivation of this paper is valid to me, i.e., simultaneously adjust the per-sample loss weight while implicitly relabeling the training samples\n2. the results seem to be effective from the main tables on main benchmarks.\n3. the paper is written clearly and is easy to understand.\n\nweakness:\n1. A small unbiased and clean validation set is required in this method. Is it a strong assumption made in the current framework?\n2. One of the popular and relevant baselines is Dividemix[1], which also involves reweighting mechanism in their approach. Have the authors ever compared their method with this baseline?\n3. From fig 4, the weight before the samples is very small. It is interesting to explain why this phenomenon happens. Does that affect the learning procedure? Also, if that is indeed the case, why the authors can claim the data distribution is protected since a lot of samples seem to be ``discarded\" as well?\n\n[1] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as semisupervised learning. In ICLR, 2020.\n\n\n-----post rebuttal\n\nThank the authors for the detailed response! I would like to raise my score.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally written clearly. The method makes sense to me.\n\n",
            "summary_of_the_review": "The paper meta-learns two weighting parameters for the real label and the pseudo label for combating the label noise problem. There are some vague explanations/experiments in the paper that need to be clarified. Will consider changing my score after I see some of the other reviewers' opinions and the authors' responses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_LnzH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_LnzH"
        ]
    },
    {
        "id": "DXXSx3bT-U",
        "original": null,
        "number": 2,
        "cdate": 1666599632378,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599632378,
        "tmdate": 1671086867902,
        "tddate": null,
        "forum": "qVI1MqX52Xm",
        "replyto": "qVI1MqX52Xm",
        "invitation": "ICLR.cc/2023/Conference/Paper6029/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to meta-learn an instance-level weight for real labels and pseudo-labels when learning with noisy labels. ",
            "strength_and_weaknesses": "Pros\n\n1. The paper is well-written and easy to follow. \n\n2. Theoretical guarantee of the convergence of the proposed method is provided. \n\nCons\n\nMy major concern is that the proposed method is not comparable or compatible with the current SOTA of the methods (of combating noisy labels) which leverage self-supervised learning algorithms and data augmentation [1,2]. \n\nThe author is trying to rule those works out of the scope of this work. In the related work, [1] is categorized as \"approaches which separately handle instance reweighting and label reweighting\" In Section 4.2, the author validates themselves by saying \"Note that we mainly compare with methods which do not use any augmentation techniques, as our L2B does not rely on those.\"\n\nHowever, the methods proposed in [1,2,3] have much better performance than the method in this paper. For example, in the setting of CIFAR-10 50% symmetric noise. The proposed method L2B has an accuracy of 88.5 while the method of [1] has an accuracy of 94.5\u00b10.1\n\nI am concerned about the usefulness of L2B in real practice since it does not help improve the SOTA method. \n\n\n\n[1] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as semisupervised learning. In ICLR, 2020.\n[2] Junnan Li, Caiming Xiong, and Steven C.H. Hoi. Learning from noisy data with robust representation learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision\n(ICCV), pp. 9485\u20139494, October 2021.\n[3] Wang, Zhaoqing, et al. \"Exploring set similarity for dense self-supervised representation learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and has nice clarity. The paper proposes a novel technique of weighting losses for combating noisy labels. The significance of the paper is limited since the proposed method's performance is not comparable with the SOTA. ",
            "summary_of_the_review": "Overall, considering the clarity, novelty, and quality, the current version of the paper is slightly below the acceptance bar. \n\n===\n\nAfter rebuttal, the author shows that the proposed method can improve the performance of the current SOTA. Thus I raise my score from 5 to 6. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_vvhR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_vvhR"
        ]
    },
    {
        "id": "etAYv1akhYY",
        "original": null,
        "number": 3,
        "cdate": 1666706863927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666706863927,
        "tmdate": 1669559493914,
        "tddate": null,
        "forum": "qVI1MqX52Xm",
        "replyto": "qVI1MqX52Xm",
        "invitation": "ICLR.cc/2023/Conference/Paper6029/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "L2B is a learnable loss objective that enables a joint reweighting of instances and labels at once.  L2B dynamically adjusts the per-sample importance weight between the given labels and pseudo-labels in a meta way.",
            "strength_and_weaknesses": "Strengths:\n1)  L2B dynamically adjusts the per-sample importance weight between the given labels and pseudo-labels.\n2) The results are somehow higher than some reweighting methods but not other noisy methods.\n3) The experiments are done on different datasets.\n4) The convergence is analyzed in the paper.\n\nWeakness:\n1) should the \\alpha_{t,i} and \\beta_{t,i} in Eq.10 and algorithm line 12 be \\tilde{\\alpha_{t,i}} and \\tilde{\\beta_{t,i}}?\n2) Here is a suggestion: an ablation should be made: \\mathcal{L}( \\mathcal{F}(x_i,\\theta), \\alpha y_i^{real}+\\beta y_i^{psudo})  \\alpha and \\beta is learned as in your algorithm. This ablation can better analyze whether the re-weighting between the samples is useful or the re-weighting between the label and psuedo-label is useful.\n3) comparison of experiments results: maybe previous works [1][2][3] should be compared. Is there any analysis that the results of L2B are not higher compared to [1][2][3]? Since this work is based on the loss design, can L2B be applicable to the current SOTA noisy methods? Can you please show more results based on these works to better illustrate the effectiveness?\n4) typo: 'Eq. equation' \n\n[1] Li, Junnan, Richard Socher, and Steven CH Hoi. \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning.\" International Conference on Learning Representations. 2019.\n[2] Bai, Yingbin, et al. \"Understanding and improving early stopping for learning with noisy labels.\" Advances in Neural Information Processing Systems 34 (2021): 24392-24403.\n[3] Liu, Sheng, et al. \"Early-learning regularization prevents memorization of noisy labels.\" Advances in neural information processing systems 33 (2020): 20331-20342.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is good.\nThe novelty is not that attractive. It seems more like using meta-learning to learn loss parameters. Maybe a deeper understanding can be shown to improve the novelty.",
            "summary_of_the_review": "The parameters of the loss terms are adjusted by meta-learning. However, the novelty seems not that good in this work. Further analysis should be made to give a deeper understanding.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_7ks8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6029/Reviewer_7ks8"
        ]
    }
]