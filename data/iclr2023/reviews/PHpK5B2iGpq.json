[
    {
        "id": "lPkVUyR545",
        "original": null,
        "number": 1,
        "cdate": 1666487185475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666487185475,
        "tmdate": 1666571718614,
        "tddate": null,
        "forum": "PHpK5B2iGpq",
        "replyto": "PHpK5B2iGpq",
        "invitation": "ICLR.cc/2023/Conference/Paper3840/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "NNs are generally victim of spurious features which are strongly correlated with the label in the training set, but might not be robust for unseen samples. This paper proposes a method to reduce the reliance on spurious correlations.\n\nThe strategy is to first find examples that are bias-conflicting with a *bias model* and then train a robust, *main model* by up-weighting those examples when learning the task classifier. The bias model is trained with a rank-regularization loss which shrinks the effective rank of the the representations in the NN: a small effective rank describes a paucity of features that the network capture, and these likely correspond to easy-to-learn features in a spurious correlation setting. The authors test their approach in the unlabeled setting, using SimCLR/SiamSiam/VicREG models, regularized with their rank loss for obtaining the bias model. \n\nSummarizing the contributions, the paper mainly argues two novelties: 1) rank regularization helps in finding biased examples; 2) one can apply rank regularization also to the unlabeled setting, so that one can exploit unlabeled data for a task to prevent spurious correlations.",
            "strength_and_weaknesses": "Strengths:\n- *The paper studies an important problem*.\n- *Novel perspective on an existing problem*: it deserves to be stated more clearly in the paper, but the idea of exploiting unlabeled data to find \"easy-to-learn\" features to robustify models in the labeled setting is interesting. Also, the evidence towards establishing a correlation between effective rank and the degree of bias in the dataset is interesting and make sense.\n\nWeaknesses:\n- *Lack of motivation and clarity of exposition*: I found the paper hard to follow. It is quite dense and contributions are hard to parse at the beginning. Let me try to summarize the two contributions. The first is to propose a rank-suppression mechanism to find biased representations. The second is the will to exploit un-labeled data to mine more plausible features that could act as spurious correlations for the task, which could help for example in the absence of a lot of labeled data. I find that these two contributions can be more clearly stated along with the motivations supporting these contributions.\n\n- *A conceptual weakness does not seem to be discussed*: spurious correlations are defined with respect to the label by definition. The paper claims that rank regularization exacerbates \"short-cuts\" or \"easy-to-learn\" features. It is reasonable to think that spurious and easy-to-learn feature match in the labeled setting, but the connection between the two might be more tricky in the unlabeled setting. Is a model capturing an easy-to-learn feature lead to always better performance against spurious correlations? I could think of a synthetic dataset in which an easy-to-learn feature is perfectly un-correlated with the labels? Would your regularization scheme just learn that feature thus making classification and thus bias-conflicting examples meaningless?\n\n- *Findings lack support*: Another main weakness of the paper is that the contributions are a bit \"dispersed\":\na) With respect to the first contribution, I would expect more extensive analysis of how rank-regularization compare (in the labeled setting) to other methods of finding bias-conflicting examples e.g. JTT, and Forgettables examples (Yaghoobzadeh et. al, 2021, \"Increasing robustness to spurious correlations...\"). Right now the authors compare with ERM in Table 1, without giving much details on the experimental setting. Then, the authors could go on in justifying why rank-regularization can be used in the unlabeled setting (differently from other approaches that require labels).\nb) When talking about un-labeled data, it is natural to ask whether standard pre-trained self-supervised/supervised models can be used in this setting. In the paper, the authors limit themselves to the setting where the encoder is trained only on *unlabeled* data for the task, but what if we are starting from a pre-trained model (classical setting of JTT / Deep Feature Reweighting)? How can the approach be applied?\nc) The authors test their model in CelebA and UTKFace. Waterbirds and CelebA are classical settings for this problem, and the classical CelebA split is (hair, gender). Why do the authors skipped these settings?\n\n- *Weak results in Table 2*: In Table 2, the scores for DeFund are bolded but are less than ERM on some columns and JTT on most of the columns. I understand the model is not using Y in the pre-training phase, but the question one could ask is *why not* given that it is using those labels in the fine-tuning stage and thus the exact same information is used to report those numbers?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Questions and Remarks:\n1. Which network has been used to perform the analyses in Section 2.2? Do these analyses hold also for other architectures, e.g. ViT?\n2. Are you plotting the effective rank of the representations in the network?\n3. In Table 1 and other tables, how do you still the error set E or misclassified training examples for the baselines? How do you do it for your method?\n4. It would be good to compare to Deep Feature Reweighting, given that they also retrain the last linear layer to robustify the model",
            "summary_of_the_review": "The paper addresses an important problem. The study on the effective rank is interesting and possibly impactful. The unlabeled perspective should be discussed in more details: implications and applicability to standard pre-trained models should be discussed. Overall, the paper feels a bit dispersed at the moment: I am not sure I can confidently state that a particular technique works better than the baselines or take away a clear message from this paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_3q4H"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_3q4H"
        ]
    },
    {
        "id": "hb8Zgzrvwo",
        "original": null,
        "number": 2,
        "cdate": 1666591279149,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591279149,
        "tmdate": 1666591279149,
        "tddate": null,
        "forum": "PHpK5B2iGpq",
        "replyto": "PHpK5B2iGpq",
        "invitation": "ICLR.cc/2023/Conference/Paper3840/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a debiasing framework using low-rank regularization and self-supervised learning techinque. Specifically, Authors find that rank regularization may force deep networks to focus on spurious attributes and the biased models with strong regularization can effectively probe out the bias-conflicting samples in the training set which is robust to the unintended memorization of bias-conflicting samples. Inspired by the obervation, authors desings two-stage training framework to debias the model. Experiments are verified on UTKface (age), UTKFace (gender) and CelebA to verify its effectiveness.",
            "strength_and_weaknesses": "**Strength:**\n\n- Well motivated and intersting idea. The experiements and ablation studies are designed carefully.\n\n- The improvemnts are significant observed from Linear evaluation and Semi-supervised learning experiments.\n\n**Weaknesses:**\n\n- It would be better to report error bars to show the stableness of the result.\n\n- If this two-stage training framework would increase the training time compared to other approaches?",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is well written and organized. The code is also attached in the supplementary.",
            "summary_of_the_review": "- I am not very familiar with this direction, along with the related work. From my perspective, I think this paper has some intersting points. Thus I give the score of 6 at the current time and will make my final decision aftering reading other reviews.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_cTbQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_cTbQ"
        ]
    },
    {
        "id": "pt1Mk7EYZQ",
        "original": null,
        "number": 3,
        "cdate": 1666593284401,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593284401,
        "tmdate": 1669064622711,
        "tddate": null,
        "forum": "PHpK5B2iGpq",
        "replyto": "PHpK5B2iGpq",
        "invitation": "ICLR.cc/2023/Conference/Paper3840/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies debiasing spurious correlations and finds the inductive bias towards encoding low effective rank representations. The paper proposes a low-rank regularization method to debias. First, one bias model learns representations with low-rank regularization to amplify the bias. Then, we use the bias model to find the biased conflicting samples. Finally, use larger weights on biased conflicting samples in training the main models. Their proposed methods do not require information on target class or dataset bias information. The authors evaluate their methods on UTKFace and CelebA, and the results outperform most state-of-the-art. ",
            "strength_and_weaknesses": "Strength:\n1. The paper has a clear motivation and insights. The authors first find an interesting observation that the bias is a low-rank representation, and then provide a trivial but effective solution. \n2. The proposed methods have a good performance on some complex datasets, e.g. CelebA.\n\nWeakness and Questions:\n1. This is pure empirical work. There are some claims and statements that may need analysis support or more empirical support, e.g. (1) Why are Equations (2) and (3) a good way to estimate the effective rank? Why not use the nuclear norm, which is a convex relaxation of a matrix rank? (2) Why does the low-rank regularization guarantee learning more spurious correlations features rather than intrinsic features? If we only constrain the rank, how should we know which feature it tends to learn? Figure 1d is not enough to answer this question from my perspective. I need more evidence empirically (e.g. feature visualization for the bias model) or theoretically. \n2. In synthetic simulation experiments under Section2, the bias correlation is high, (larger than 95%). What will happen in a more natural setting, e.g. 80%? In Table 1, what is the meaning of Bias ratio =1%? Is it the same as the Bias ratio = 99%?\n3. In Figure 1f, the two curves for CIFAR10-c have marginal differences. \n4. From my perspective, the critical part of the method is to find bias-conflicting samples, or we may call them hard samples. I wonder whether low-rank regularization is the only solution. One potential idea is to use a shallow network (e.g. two-layer neural network) as the bias model rather than using low-rank regularization. I am curious about whether the shallow network method work, considering that it may just learn simple inductive bias as the authors claim. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper has a good clarification. \n\nQuality: I checked the appendix. The paper has good writing. \n\nNovelty: The paper has its novelty as far as I know. \n\nReproducibility: I believe the experiments part can be reproduced. \n",
            "summary_of_the_review": "The paper has its novelty, while some questions I mentioned in the Weakness part blocked me. I may adjust my rating based on the rebuttal. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_datJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_datJ"
        ]
    },
    {
        "id": "PPWB32OV8E",
        "original": null,
        "number": 4,
        "cdate": 1666989132510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666989132510,
        "tmdate": 1666989132510,
        "tddate": null,
        "forum": "PHpK5B2iGpq",
        "replyto": "PHpK5B2iGpq",
        "invitation": "ICLR.cc/2023/Conference/Paper3840/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a self-supervised method for debiasing models by building a highly biased model, then leveraging that model to select the training set to create an unbiased model. The method does not require any labels of the bias attributes, as many methods do, or even the target classes or attributes, which makes it quite novel. The experiments show that the method outperforms other unsupervised algorithms, even those leveraging class labels.",
            "strength_and_weaknesses": "Strengths\n\nThe goal of the work is to produce an unbiased classifier without having any labels of attributes or classes, which are typically required for debiasing methods. In this problem setup, the method must determine the relevant attributes and whether they are biased, jointly and without any labels i.e. fully unsupervised. This is a very challenging and interesting problem setup that builds upon the recent breakthroughs in unsupervised representation learning.\n\nThe method is based on the observation that model bias seems to be inversely correlated with the entropy of the representation learned by the model. The hypothesis is that spurious correlations in training data lead to a concentration of model attention on a few features, leading to poor generalization performance.\n\nThe approach seems quite novel. Other popular methods are based on GANs or other adversarial techniques, rather than unsupervised learning of bias. The idea of creating a highly biased encoder, based on rank analysis, is clever and seems to be supported by the results.\nThe experiments underlying Fig. 1 are very useful to illustrate the insight and motivation underlying the approach. Using controlled settings in simplified datasets is helpful here to illustrate the best-case scenarios that provide evidence of the theory. Many papers lack such intermediate results and rely solely on improved results of the end task to validate elements of the approach.\n\nThe experiments are performed on face datasets using combinations of standard attributes including gender, age, race, heavy_makeup that have been annotated previously. A comprehensive set of baselines are compared against, including self-supervised methods, supervised debiasing methods and algorithms that select training sets for debiasing. The proposed method handily outperforms other unsupervised methods, and supervised methods in some cases, which is impressive. The experimental protocol follows that of recent works for consistency.\n\nWeaknesses\n\nIn fig. 1 the bias ratios seem very high, 95% or greater, and the plot shows that the amount of change from 0 to 95% is only slightly larger than the change from 95 to 98%, i.e. there is little change in the effective rank when the ratio ranges from 0 to close to 95%. At face value this seems to reveal a significant disadvantage in using the effective rank as it is insensitive to the bias ratio until it becomes extreme. Is that the case?\n\nIs the matrix Z in sec. 2.3, formed from the input vectors and their corresponding feature vectors, the matrix that is used in the rank computations in Fig. 1? If so this should be stated earlier, in the discussion of Fig. 1, with a forward reference. As written the paper is unclear on what the rank of a representation might be until sec. 2.3.\n\nThere are important related works in discovering biases without attribute labels that are not cited:\n\nLang, O., Gandelsman, Y., Yarom, M., Wald, Y., Elidan, G., Hassidim, A., Freeman, W.T., Isola, P., Globerson, A., Irani, M., Mosseri, I. \u201cExplaining in Style: Training a GAN to explain a classifier in StyleSpace.\u201d ICCV 2021.\n\nLi, Z., Xu, C. \u201cDiscover the Unknown Biased Attribute of an Image Classifier.\u201d ICCV 2021.\n\nAnother one, in ECCV 2022, published after the ICLR submission deadline:\n\u201cDiscover and Mitigate Unknown Biases with Debiasing Alternate Networks\u201d\n\nThese papers all rely on GANs or other adversarial techniques, and rely on target labels to some extent. Hence they do not infringe on the novelty of the proposed method. However, the discussion of related work should be expanded to include these, and to better differentiate the novel claims.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear, and engages the reader in a clear motivational narrative supported by convincing experiments in Sec. 2. The approach appears to be quite novel. There may be sufficient detail to reproduce the results, but there could be some gaps.",
            "summary_of_the_review": "The paper presents a novel solution to the difficult problem of self-supervised debiasing, an important problem that has received little attention so far. The writing is clear, and the experiments are thorough and convincing. The paper should generate significant interest for those working in bias mitigation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_rRxe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3840/Reviewer_rRxe"
        ]
    }
]