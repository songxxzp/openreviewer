[
    {
        "id": "xDYy4jSUaq",
        "original": null,
        "number": 1,
        "cdate": 1666315923588,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666315923588,
        "tmdate": 1666315923588,
        "tddate": null,
        "forum": "tgAI50giBbg",
        "replyto": "tgAI50giBbg",
        "invitation": "ICLR.cc/2023/Conference/Paper4401/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies the delayed impact of fairness in machine learning and provides a new model that models this effect as opposed to the commonly studied static notions of fairness. The paper introduces an algorithm called ELF (Enforcing Long-term Fairness) to provide high confidence delayed impact fairness guarantees (when possible). The authors demonstrate the effectiveness of ELF empirically.\n",
            "strength_and_weaknesses": "------------------------------\nStrengths\n------------------------------\n-- The delayed impact of fairness in machine learning has not received much attention in the community (mainly due to the hardness of modeling this impact) so in that sense, it is great to see papers on this topic.\n\n--The paper is pretty well written and it is clear to follow the high-level ideas of the paper.\n\n------------------------------\nWeaknesses\n------------------------------\n--Assumption 3 is strong. While it is common in the RL community to have this assumption, this is less realistic in the algorithmic fairness literature and a possible source of bias. How can this assumption be justified?\n\n-- The theoretical analysis of the paper is rather straightforward. \n\n-- The experimental analysis is not convincing. \n(a) None of the baselines considers the delayed impact into consideration. Is it surprising to see that ELF will have a much lower failure rate compared to the baselines? \n(b) How did you come up with the form of delayed impact in Equation (4)? In general, having access to such data is a major challenge in the practicality of this work.\n(c) The number of data points needed for ELF so that it outputs a solution is very large. Does this problem become less severe when looking at lower-confidence solutions? What is the dependency on the confidence parameter? \n(d) The accuracy of the ELF is significantly lower than the baselines. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The setting is novel and I think at least the theoretical results of the paper should be easily reproducible. ",
            "summary_of_the_review": "While I think the paper tackles an interesting problem, it is hard to justify the proposed modeling and practicality of the results. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_ABty"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_ABty"
        ]
    },
    {
        "id": "hXqZdaArUfZ",
        "original": null,
        "number": 2,
        "cdate": 1666535957915,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666535957915,
        "tmdate": 1670031767304,
        "tddate": null,
        "forum": "tgAI50giBbg",
        "replyto": "tgAI50giBbg",
        "invitation": "ICLR.cc/2023/Conference/Paper4401/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper investigates the fair classification problem in the long term. It introduces a new algorithm, ELF, to solve the fair classification problem as both a classification and a reinforcement learning problem \u2014 classification for optimizing the main objective (a measure of classification loss) and reinforcement learning when taking DI into account. ",
            "strength_and_weaknesses": "+ The setting is interesting where the relationships between the delayed impact and prediction are unknown. A reinforcement learning solution is developed to infer the delayed impact from the observation using importance sampling.\n+ Given the inferred delayed impact, a classification is built to ensure DI.\n+ The theoretical analysis seems convincing.\n\n- The variable of delayed impact observation and the formulation of long-term fairness is unclear. Eq 1 defines g(theta) for DI but it is not clear why a fair algorithm must ensure Eq 1. Usually, fairness means the absence of disparity between two groups. But variable I is an observation, e.g., the rate. It is unclear why the larger I corresponds to better DI. In brief, DI and DI fairness is not well defined. The confusion makes Sec 2 hard to understand.\n- The setting of no analytic relationship between DI and prediction is controversial. Assumption 2 assumes the relationship. Otherwise, the off-policy learning cannot infer the delayed impact. In addition, it is unclear how the performance of importance sampling affects the downstream classification.",
            "clarity,_quality,_novelty_and_reproducibility": "The problem formulation is not very clear.\n",
            "summary_of_the_review": "This paper presents a solution to classification with long-term fairness constraints. A new setting is considered where the relationship between the delayed impact and prediction is unknown. To handle this challenge, the paper introduces a few assumptions and infers the delayed impact from prediction using a reinforcement learning method. Then the inferred DI is used for classification.\n\nThe method seems meaningful but the formulation is not clear. The statements about DI and fairness are confusing. It is not clear why Eq 2<0 is necessary for model fairness. \n\nAssumption 2 is contrary to the setting of the analytic relationship between DI and prediction.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_51vQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_51vQ"
        ]
    },
    {
        "id": "SwHJthwgft6",
        "original": null,
        "number": 3,
        "cdate": 1666910675547,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666910675547,
        "tmdate": 1666911208197,
        "tddate": null,
        "forum": "tgAI50giBbg",
        "replyto": "tgAI50giBbg",
        "invitation": "ICLR.cc/2023/Conference/Paper4401/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper looks at how to guarantee fairness when the impact of the decisions we make today is only seen in the long term. The paper provides a counter-factual approach to predict future impact from historical data that may be coming from a different policy than the one we aim to deploy, and aims to find a policy that does not have an unfair long-term impact across populations. ",
            "strength_and_weaknesses": "Strengths:\n- the topic of the paper is important. I.e., how do we guarantee fairness across different individuals or groups, especially when we cannot observe labels about the individuals we make decisions on and update our model immediately?\n- the approach is technically interesting: it is counterfactual in flavor and relies on learning from historical data. This data comes from previously deployed policies that may have been unfair, and the observed outcomes are informed by the previously deployed policy itself. \n- the idea of moving away from having to model a specific analytical relationship between a classifier's prediction and its observed impact is nice\n\nWeaknesses:\n\nI have the following concerns about the paper:\n\ni) Exposition and scope-wise, I am not sure whether there is anything in the paper that is specific to delayed impact and but not to counterfactual learning. Here, unless I missed something about the paper, it seems that the only way the delayed impact really comes in is that compared to a standard ML/fairness model, the observed label is defined as being, say, 2 years after the decision has been made. But the time dimension here does not actually play a role in the model:\n- the dataset itself is static, coming from a single previously deployed policy. \n- The problem is, in fact, formulated as a static problem of counterfactual learning given historical i.i.d. data. There isn't a real time dimension/aspect in which the model is updated over time and more data is collected over time. \n\nIn turn, it seems to be more of a traditional counterfactual learning problem where the delayed impact part feels \"gimmicky\" and does not impact the paper beyond its motivation. \n\nii) Assumption 1 seems to essentially say that we look at models whose predictions do not depend on group identity. This is a \"sensitive attribute-blind\" approach which contradicts much of what is known in the space of fairness. I.e., the same features may mean different things for different populations, and not taking the sensitive attribute into account is a surefire way to promote unfairness. This seems like a bit of a naive assumption which says that we can take the lessons from one population and apply it to another directly.\n\niii) I think the assumptions that the historical data is well-behaved (i.i.d and having observations of the full support) may be a bit hard to believe. What I think may be hard and interesting about time-dynamics in the space of fairness is that the deployed rule influences the observed data, and the observed data influences the deployed rule, often leading to feedback loop with a long-term negative impact. \n\nAs an example: if we only historically gave loans to wealthy white people, a naive model will learn to still only give loans to wealthy white people, and we will only collect repayment data from wealthy white people. In this case, we do not have access to i.i.d., full support data that is representative of the entire population, and have a missing data problem. It is then impossible (without collecting more data) to predict the outcomes on a different population that we have observed (almost) nothing about in the past. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of the paper is clear, the results are proved, and experiments are provided to back up the theory. ",
            "summary_of_the_review": "I think the topic of the paper is interesting. However, I think I feel that much of what makes delayed-impact fairness hard in practice is in the details and specific assumptions made about the problem (non i.i.d. data and data from a single population that cannot be interpolated to a different population), and I think the assumptions of the current work are a bit naive. As such, I think the paper is a bit under the bar in its current form",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_Sy63"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4401/Reviewer_Sy63"
        ]
    }
]