[
    {
        "id": "qHL7t42iE4",
        "original": null,
        "number": 1,
        "cdate": 1665894678369,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665894678369,
        "tmdate": 1666685476489,
        "tddate": null,
        "forum": "CDlHZ78-Xzi",
        "replyto": "CDlHZ78-Xzi",
        "invitation": "ICLR.cc/2023/Conference/Paper4575/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Cache-timing Attack (CTA) endangers privacy and security of data. However, traditional detection methods are not extendable. This work tackles CTA and detection from game-theoretic perspective by proposing a deep multi-agent reinforcement learning (MARL) approach with transformer for attackers and detectors.",
            "strength_and_weaknesses": "Strength:\n\n1. Converting detection of CTA problem into a multi-agent reinforcement learning is a fresh perspective to consider attack and detection in the area of data security and privacy.\n\n2. This work builds CTA-related gym for multi agents to benefit detect-and-terminate defense strategy.\n\nWeakness:\n\n1. Since this work is based on game theory, it is good to provide a theoretical formalization on the problem and related proofs. Otherwise, it looks less sound and people may wonder the ability of this approach.\n\n2. This work does not address explore-exploit tradeoff very well since it is usual in common RL scenario.\n\n3. Although transformer is popular and good for many sequence learning tasks, this work does not explain enough on why transformer works well in the MARL for CTA. Authors may try to consider advantages of transformer for CTA in MARL from universal-approximation perspective like \u201cARE TRANSFORMERS UNIVERSAL APPROXIMATORS OF SEQUENCE-TO-SEQUENCE FUNCTIONS? ([https://openreview.net/pdf?id=ByxRM0Ntvr](https://openreview.net/pdf?id=ByxRM0Ntvr))\u201d published on ICLR 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity & Quality: Problem statement of CTA is clear, but some details on RL does not address well. \n\nNovelty: Considering CTA with MARL (game-theoretic) approach is an unprecedented view to tackle the issue.",
            "summary_of_the_review": "Instead of heuristically iterating each possible CTA by human experts, this work provides a novel view from game-theoretic (to be specific, RL) perspective to address the issue. Compared to ML approach, this work does not simply learn behaviors of possible CTA, but it allows attackers and detectors to interactively develop accordingly. Although this work is lack of some theoretical explanations on MARL for CTA, the experiments themselves look good if they are not cherry-pick and it still worths to consider as an application work. I would like to hear from authors especially on W2 and W3, and I will also consider other reviews to make the final decision later.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_9uNr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_9uNr"
        ]
    },
    {
        "id": "-gg_myjy0g",
        "original": null,
        "number": 2,
        "cdate": 1666391293293,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666391293293,
        "tmdate": 1670223535675,
        "tddate": null,
        "forum": "CDlHZ78-Xzi",
        "replyto": "CDlHZ78-Xzi",
        "invitation": "ICLR.cc/2023/Conference/Paper4575/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "(before I begin, I report that he text of the paper contains hyperlinks to external URLs (e.g., \u201c14 grand challenges of engineering\u201d). I invite the authors to remove these and report the links either as footnotes or actual references, as it is not possible to appreciate them by those people that read the paper on printed-paper (aside from representing a security risk, as the URL is hidden). )\n\n\nThe paper tackles the problem of cache timing attacks (CTA) detection. Specifically, the paper proposes MACTA, a method that leverages \u201cMulti Agent Reinforcement Learning\u201d (MARL) to simultaneously launch CTA, and detect them. Experiments on a synthetic testbed show that the attacks \u201clearned\u201d by the \u201cattacking agent\u201d developed through MACTA can bypass existing detection methods; whereas the \u201cdetection agent\u201d developed through MACTA can not only detect the attacks of the \u201cattacking agent\u201d, but also (to some degree) those tailored for detection methods employing handcrafted heuristics, or traditional supervised learning techniques. \n",
            "strength_and_weaknesses": "\nSTRENGTHS:\n+ Simple, but interesting methodology\n+ Easy to understand\n+ The experiments consider several baselines\n\n\nWEAKNESSES\n- Poor novelty\n- Lack of a \u201crealistic\u201d use case\n- Misleading advantage\n- Everything is simulated\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the presentation of the paper is satisfactory.\n\nThe quality of the English text is mediocre.\n\nFigures and Tables are mediocre (there are some inaccuracies)\n\nThe topic addressed by the manuscript is niche, but not very investigated and relevant for ICLR.\n\nThe references are appropriate.\n\nThe contribution is (potentially) significant.\n\nThe novelty is not high: ultimately, the paper takes a well-known approach (MARL) and applies to solve a security problem. However, doing so is not new, and the results are expected.\n\nThe reproducibility is \u201cfair\u201d: the authors \u201cpromise\u201d to release the code, and the appendix is filled with details. However, from my own experience, reproducing the testbed can be very hard without disclosing the code. So I trust the authors to truly do so in case of paper\u2019s acceptance.\n",
            "summary_of_the_review": "I liked reading the paper, and it was very hard to find a \u201crecommendation\u201d. On the good side, the paper tackles an underinvestigated problem (at least in the context of Machine Learning for Cybersecurity), and the experimental evaluation is interesting enough to (potentially) inspire future work in this domain. On the bad side, the paper falls short in providing a significant advancement in the context of machine learning, some results are underwhelming/expected, and the testbed is entirely simulated.\n\nPut simply, I think this paper would be **perfect** as a workshop paper, but it is not of good enough quality for ICLR. I recommend a \u201cborderline reject\u201d. I will provide below an explanation of all the major issues that affect the paper, alongside a set of questions and potential improvements. I look forward to reading an \u201cenhanced\u201d version of this paper. Furthermore, I also stress that I will gladly engage in a discussion with the authors.\n\n\n**Unfair novelty claim.**\nAccording to the introduction, \u201cour work is the first to show a real-world hardware security problem can be addressed by jointly improving both attacks and detection.\u201d This claim is unfair: using reinforcement learning to both \u201cattack\u201d and \u201cdefend\u201d a security system is not novel at all. For instance, Apruzzese et al. [A] (published in 2020) do exactly this. The fact that this paper shows this for a \u201chardware\u201d security problem is not very relevant to support a novelty claim. (especially because the experimental evaluation is done on a simulation, and not on \u201creal\u201d hardware)\n\n**Lack of a true \u201crealistic\u201d use case.**\nAccording to Section 3, the paper will ultimately consider two cases: one in which the environment includes a malicious entity (in which the goal is *detecting the malicious actions*); and one in which the environment includes only benign programs (in which the goal is *avoiding the generation of false positives*). The paper clearly states that \u201cWe leave more complicated settings, such as scenarios with both victims and benign programs as future work.\u201d While I appreciate the transparency, I do not think that such \u201comission\u201d can be simply overlooked: a common issue in *real* detection settings is when the environment includes both benign and malicious activities, wherein the latter are typically a \u201cneedle in a haystack\u201d. I acknowledge that these may be \u201chard\u201d to model, but such a lack is a significant limitation of this paper \u2013 especially given that it is submitted to a premier venue such as ICLR. For this reason, the real-world impact of the proposed method is difficult to gauge.\n\n**Misleading (claimed) advantage.**\nThe proposed method, MACTA, ultimately attempts to overcome the limitations of \u201chuman-defined\u201d heuristics (quoting from the abstract: \u201cHowever, the current detection of cache timing attacks relies heavily on heuristics and expert knowledge, which can lead to brittleness and inability to adapt to new\nattacks.\u201d). However, since the entire RL environment (i.e., action space, reward, observation) is designed also by humans, wouldn\u2019t this simply move to problem to a different \u201csetting\u201d? In other words: the RL environment is *also* designed by humans by using their expert knowledge. At the same time, an \u201cimproper\u201d generation of the environment can lead, to an agent that can (synthetically) learn devastating attacks (and to a detector that can detect such attacks) but which may be not realistically conceivable. In turn, this can also lead to blind spots, i.e., if the environment does not take into account all the factors that can be realistically modeled (this is an implicit limitation of RL approaches).\nPut simply, I think that the authors should tone down the way MACTA is presented.\n\n**Questions/issues on Abstract, Introduction and Section 2.**\n\n\u2022\tThe abstract is filled with subjective and vague terms to present the improvement of the proposed method. For instance, \u201csubstantially outperform\u201d should be quantified in an objective way; \u201cmore stealthily\u201d should also be numerically quantified. Finally, \u201cless exploitable\u201d is also unclear.\n\n\u2022\tIn both the Abstract and Introduction, the text reports a very vague statement: \u201cThe experiments show that learned policies trained with MACTA can generalize to unseen detector/attackers.\u201d Specifically, what does the term \u201cunseen\u201d stand for? Does it mean attacks that have not been \u201cseen\u201d before the operations performed by the RL agent? In which case, it is \u201cobvious\u201d that the learned policy can also detect such attacks; conversely, if the policy can detect attacks that are not seen \u201ceven during the learning phase of the agent\u201d, then the result would be slightly more impressive (note, however, that [A] also showed a similar finding). \n\n\u2022\tWhy is the environment called \u201cMA-AutoCAT\u201d? Shouldn\u2019t it be \u201cMA-AutoCTA\u201d?\n\n\u2022\tI think Section 2.1 is redundant. It presents information that is ultimately not necessary to understand the contribution of the paper, while at the same time not providing enough details to fully allow a non-expert reader to understand the issues of CTA. I invite the authors to remove such Section (perhaps putting it in an Appendix, and maybe expanding it). The current Section 6 can replace Section 2.1, and the space obtained by such \u201ccut\u201d can be used to expand on the technical contribution.\n\n\u2022\tOn this note, something I\u2019m curious about is whether anything has been done to counter CTA not with RL, but with GANs \u2013 given the many overlaps between these two techniques.\n\n**Questions/issues with Sections 3 and 4 (method):**\n\n\u2022\tSection 3 \u201cIn our environment, the secret is reset after the attacker\u2019s attempt to guess the secret and the victim will access an address depending on the secret when triggered.\u201d Why? Please provide an explanation for this choice. If it is an original idea, then a description and a motivation is necessary. If it is drawn from well-known practices, then such practices should be referenced.\n\n\u2022\tFigure 1 (caption): \u201cCache timing channel attack is formed when the attacker process and the victim process map their memory to the same system cache.\u201d Shouldn\u2019t it be \u201csame address of the system cache\u201d? Clearly, the attacker and the victim \u201cmust\u201d use the same cache for a CTA to be conceivable\u2026\n\n\u2022\tSection 3: \u201cDetector (D) aims to raise the alarm as soon as possible when an attacker presents while avoiding a false alarm for benign programs.\u201d Presents should be \u201cis present\u201d?\n\n\u2022\tSection 4: \u201cThe CTA is a POMG with three fundamental characteristics:\u201d this is unclear. Does it mean that \u201cany CTA is a POMG\u201d, or that \u201cthe CTA we consider is a POMG\u201d?\n\n\u2022\tSection 4: \u201cIn CTA, the attacker knows whom to attack but can only see its own actions and latencies\u201d. It is unclear whether \u201cits\u201d refers to the attacker, or to the target (\u201cwhom\u201d).\n\n\u2022\tSection 4: \u201cEspecially the attacker must learn both low-level skills to perform attacks and high-level strategies to avoid adversaries\u201d are the \u201cadversaries\u201d represented by the \u201cdetector\u201d? In general, avoid using \u201cattacker\u201d and \u201cadversaries\u201d with different meanings in the same sentence.\n\n**Questions/issues on Experiments**\n\n\u2022\tSection 5.2: the experiments are carried out by simulating an 8set-1way L1 cache. Modern CPUs have far \u201clarger\u201d caches. Why did the authors consider such a simplistic setting? I believe the overall feasibility of the approach has deep connections to the architecture of the cache, and choosing such a simplistic one may (unfairly) induce favorable results for MACTA over prior baselines.\n\n\u2022\tWhy is it that, in Table 3, the \u201cIBR-PPO Detector\u201d has 0 detection rate against ALL attacks (including the IBR-PPO attack)? Furthermore, it is unfair to \u201cremove\u201d the perfect detection rate of Cyclone from Table 3. Moreover, also concerning Cyclone, I do not agree with the statement that \u201cfails to detect RL attackers\u201d: its detection rate is 20%, which is only 5% less than the proposed MACTA; at the same time, Cyclone exhibits a much better false positive rate than MACTA (4.2 vs 11.3): in these cases, Cyclone is much better than what the authors describe.\n\n\u2022\tIn Section 5.2.1, the paper states that \u201cMACTA has low detection speed\u201d: where is this reported? Note that I do not refer to \u201cepochs\u201d but to actual \u201ctime\u201d. Furthermore, what the paper does not report (afaik) is the amount of computational resources required to develop (i.e., write code and train) MACTA: indeed, I am inclined to believe that implementing MACTA requires a huge effort \u2013 potentially superior than the one used to develop, e.g, Cyclone.\n\n\nEXTERNAL REFERENCES\n\n[A]: Apruzzese, Giovanni, et al. \"Deep reinforcement adversarial learning against botnet evasion attacks.\" IEEE Transactions on Network and Service Management 17.4 (2020): 1975-1987.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_Mrpg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_Mrpg"
        ]
    },
    {
        "id": "m4FI2JRFBGa",
        "original": null,
        "number": 3,
        "cdate": 1666587389431,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666587389431,
        "tmdate": 1666587389431,
        "tddate": null,
        "forum": "CDlHZ78-Xzi",
        "replyto": "CDlHZ78-Xzi",
        "invitation": "ICLR.cc/2023/Conference/Paper4575/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper formulates cache timing channel attack and defense as Partial Observable Markov Games (POMGs). Evaluation shows that the attack/defense agents trained from POMG achieve better generalization against unseen detectors/attacks compared to other works. The authors also discover that applying Transformers as the neural encoder of policy nets performs significantly better than MLPs.",
            "strength_and_weaknesses": "Strength:\n\nInteresting problem space to apply RL\n\nWeaknesses:\n\nIntellectual difference between AutoCAT [Luo et al., 2022] and MACTA is small. The paper overall is an extension of AutoCAT where detector is formulated as part of the RL problem. On this end, the formulation presented in this work is incremental to Luo et al.\n\nThe evaluation is thin. I like the neural architecture study. However, as a security focused paper, I look forward to more security analyses providing insights that why specific attack/defense succeeded or failed. Perhaps cases studies as in Luo et al. can help.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written overall. On the novelty side, the paper is incremental from prior work. Since the code is not released yet, it's still unclear about the reproducibility.",
            "summary_of_the_review": "The paper definitely studies an important problem. However, overall I feel this paper does not contribute much on the intellectual side compared to prior work and the current evaluation is thin.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_aHoC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4575/Reviewer_aHoC"
        ]
    }
]