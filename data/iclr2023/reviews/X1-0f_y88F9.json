[
    {
        "id": "pftLbhVTZd0",
        "original": null,
        "number": 1,
        "cdate": 1666529297860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666529297860,
        "tmdate": 1666529297860,
        "tddate": null,
        "forum": "X1-0f_y88F9",
        "replyto": "X1-0f_y88F9",
        "invitation": "ICLR.cc/2023/Conference/Paper1726/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies a continual learning problem based on the previous CLIP model. COCO and Flicker datasets are investigated to determine the representation variations when continually trained on one dataset and tested on the other.  They found that the retrieval performance on one dataset would drop significantly when continually trained. They correlate this phenomenon with representation variations. To alleviate this, they introduce a new training loss to contain the predictions between current and previous predictions. ",
            "strength_and_weaknesses": "Strength\n1. The continual learning of CLIP model is challenging but very interesting.  \n2. Authors correlate the degrading performance with the representation variations. \n3. The manuscript's structure is well-organized and easy to follow.\n\nWeakness\n1. The conclusion can not drawed from the provided observations and experiments in the paper. First, only two retrieval datasets are considered, the representation differences may vary in different datasets. Second, the correlations between the retrieval performance and representation variations are not evaluated.\n2. For the proposed method, the data are different during different stages, but the training objective is modified on different training iterations. Why would the new loss alleviate the forgetting issue? \n3. The experiments are not sufficient to demonstrate the claims in the introduction. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity. \nThe paper clearly introduces the re-training issue of the CLIP model. The authors investigate what correlates with performance drop on the image-text retrieval task.\n\nQuality.\nThe formwork is clear and well-organized. \n\nNovelty.\nThey investigate the proposed problem from the representations and record the difference across several continual learning stages, which is new. But the proposed method seems irrelevant to the findings.\n\nReproducibility.\nCode is not provided. \n",
            "summary_of_the_review": "Clarity. \n The authors investigate the image-text retrieval continual learning problem based on the CLIP model. They provide several interesting findings and modify the training objectives. But the experimental results are not sufficient to support the claims of the present paper. Therefore, I tend to reject the current version.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_TamL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_TamL"
        ]
    },
    {
        "id": "2AXcf4s02d9",
        "original": null,
        "number": 2,
        "cdate": 1666652485379,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666652485379,
        "tmdate": 1666652485379,
        "tddate": null,
        "forum": "X1-0f_y88F9",
        "replyto": "X1-0f_y88F9",
        "invitation": "ICLR.cc/2023/Conference/Paper1726/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates continual learning of a multi-modal text-image model like CLIP. It investigates the angle shift of the learned representations throughout different learning sessions, and it also proposes a knowledge distillation type of loss to address the issue of catastrophic forgetting. Results showing that using knowledge distillation can significantly improve the CLIP continual learning. However, the paper\u2019s model and analyses are disconnected and there is concern on whether the model is specific to CLIP or contrastive learning in general.",
            "strength_and_weaknesses": "The strength of the paper is that it shows an interesting phenomenon of angle shifting \u2013 the relative angle between a positive pair didn\u2019t move as much as the absolute angle rotates. This suggests that the representation space is undergoing constant rotation during continual learning, which is an interesting insight. Also the experimental results clearly show that the proposed model is significantly better than baselines.\n\nThe main weakness of the paper is that it reads very disconnected. There is no intuition why knowledge distillation addresses angular shift, and neither are there results confirming that using knowledge distillation helps this issue by showing the angular shift before and after distillation. \n\nThe proposed model seems generic to any contrastive learning algorithm, and the whole paper could have been benchmarked on image-only continual unsupervised learning (e.g. Madaan et al. 2021), instead of image-text learning. There is nothing specific to multi-modality here, and you could treat the two vectors coming from either an image-text pair or a pair of two views of the same image.\n\nMoreover, the paper claims novelty on \u201ccognitive alignment\u201d, but it is basically a knowledge distillation loss (i.e. LwF Learning without Forgetting, Li & Hoiem 2016) applied directly in the context of contrastive learning (i.e. predicting image instance labels instead class labels). Since no gradient is backproped into the old model, the KL loss is equivalent to a cross entropy loss between old and new prediction. One minor difference is that the paper manually edits the old model\u2019s prediction if the label is wrong. This seems an ad hoc operation and there is no empirical evidence presented in the paper showing that it is necessary. In summary, the paper may run into a concern of over-claiming, as the proposed method is LwF/knowledge distillation re-purposed in the context of contrastive learning, but it is instead branded with a bunch of \u201ccognitive\u201d terms (\u201ccognitive disorder\u201d, \u201ccognitive deviation\u201d, \u201ccognitive align\u201d) with no real cognitive science intuitions or references.\n\nMadaan et al. Representational continuity for unsupervised continual learning. ICLR 2022.\nLi & Hoiem. Learning without Forgetting. ECCV 2016.",
            "clarity,_quality,_novelty_and_reproducibility": "A bunch of \u201ccognitive\u201d terms aside, the paper is clear to read. The novelty is not as strong as it might seem due to the similarity of a knowledge distillation loss. I cannot judge on reproducibility.",
            "summary_of_the_review": "The introduction of a multi-modal continual learning benchmark is interesting, and the analyses are insightful, but unfortunately the model disconnects from the analyses. I suggest the authors show a direct link why the analyses inform such a model, and also evaluate whether it is possible to run on image-only continual learning benchmarks or there are things that are specific to image+text. Overall I think the paper is slightly below the bar as it is hard to find a clear hypothesis throughout.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_JafF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_JafF"
        ]
    },
    {
        "id": "bpu-9ZbCL5",
        "original": null,
        "number": 3,
        "cdate": 1666783344619,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666783344619,
        "tmdate": 1666783445783,
        "tddate": null,
        "forum": "X1-0f_y88F9",
        "replyto": "X1-0f_y88F9",
        "invitation": "ICLR.cc/2023/Conference/Paper1726/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new method based on the CLIP model for continual vision-language representation learning. The authors find that simple continual training in the CLIP model degenerates the performance on multimodal retrieval tasks, named Cognitive Disorder (CD). To tackle CD, they suggest Mod-X that selectively aligns the off-diagonal information distribution of the contrastive matrices utilizing the CLIP models from current and past timesteps.",
            "strength_and_weaknesses": "**strength**\n- Introduce and analyze challenging issues for continual vision-language representation learning, named intra-modal rotation and inter-modal deviation\n- outperform baselines in both image-text and text-image retrieval.\n\n**weakness**\n- Missing detailed and explicit descriptions for many notations (e.g., ct, jt, the subscript (task index) i, the superscript T in Section 3.2.3., the capital letter S in figure 6, etc\n- The difference between Cognitive disorder and Catastrophic forgetting (or representational forgetting, referred to in Madaan et al. 2022) needs to be clarified. \n- Intra-modal rotation may happen to all non-iid task-based problems, including streaming learning and conventional continual learning, which is not new, and the following analyses are a bit straightforward in the continual learning field.\n- Including Appendix 7.1 for the mathematical derivation, inter-modal deviation is not explicitly related to cognitive disorder (the performance degeneration of retrieval tasks). It tends to, but in a strict sense, the manuscript doesn't provide evidence that increasing inter-modal deviation in each sample is always harmful to \"cognitive disorder\".\n- Only naive and old baseline (EWC) is used for validation, which is hard to evaluate how the proposed model achieves superior performance compared to recent strong methods for multi-modal continual learning for retrieval tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is easy to read since the idea is very simple, but the overall writing, including the descriptions for notations, is sometimes unclear.",
            "summary_of_the_review": "The direction of the submission is auspicious and interesting, but explanations might be required to be more kind and include the details. Also, I recommend further comparing with competitive methods for multimodal continual learning methods for solving retrieval tasks.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_4dCz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_4dCz"
        ]
    },
    {
        "id": "lTmAkuwp_1",
        "original": null,
        "number": 4,
        "cdate": 1667056324994,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667056324994,
        "tmdate": 1667056324994,
        "tddate": null,
        "forum": "X1-0f_y88F9",
        "replyto": "X1-0f_y88F9",
        "invitation": "ICLR.cc/2023/Conference/Paper1726/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses continual learning in joint vision and language model. Specifically, the paper analyses the causes for task/dataset forgetting in a continuous training regime from a geometric point of view. The analysis works as follows:\n\n1. First, CLIP is trained on COCO to obtain a baseline CLIP0 model. \n2. Next, Flicker 30K is divided into 5 subsets and the CLIP0 model is further trained sequentially on each of the subsets to obtain CLIP1-CLIP5 models. These models are also denoted as CLIP_ct models, where ct stands for continual training. \n3. In addition, the authors train CLIP on the entire COCO and Flicker 30K datasets to obtain CLIP_jt, where jt stands for joint training, which serves as an upper bound to CLIP1-5 performance. \n4. The authors measure the performance of the various models on Flicker and COCO test set, demonstrating a gradual degradation in performance of the CLIP_cp models on COCO tests set and an improvement on Flicker test set, which makes sense as the models are trained (gradually) on the Flicker dataset. They name this phenomenon \"Cognitive Disorder\". \n5. Next, the paper considers the angles between all pairs of visual representations from different models, i.e.: the angle between the visual representation extracted using CLIP_t for a sample i and the visual representation extracted using CLIP_(t+1) for the same sample i. This analysis is done on the test set and denoted as Self Angle relationship Matrix (SAM). This measures to what extent the representations are rotated during continual training, with respect to themselves. They find that those angles change slowly, therefore argue to not be the reason for the performance degradation. The change in SAM is denoted as Intra-modal rotation. \n6. The paper then turns to analyse how angles between pairs of visual embeddings from different samples change during continual learning. Specifically, they consider a matrix composed of the angles of representations from different samples i,j extracted from the same CLIP_t model. This matrix is denoted as Rotation Angle Matrix (RAM). This analysis is done for the textual embeddings as well.\n7. The authors find that the RAM matrix changes more dramatically for visual embeddings than the angle between off-diagonal elements of the textual embeddings. The change in RAM is denoted as Inter-modal deviation. \n8. From this analysis, the paper argues that the inter-modal deviation (i.e.: the fact that the two modalities are not synchronised in the amount of rotation between off-diagonal elements in different training steps) is the cause for the degradation in performance during continual learning (which is denoted Cognitive Disorder as I explained above). \n\nNow, following this analysis, the paper proposes to alleviate \"cognitive disorder\" by aligning the amount of rotation of off-diagonal elements between the two modalities during training. This works as follows: first, given the trained model on sub dataset t , we consider the contrastive matrix M_t, i.e.: the matrix whose element in the i,j position is the similarity score of the i'th sample vision embedding and the j'th sample text embedding. The method add a KL divergence term between M_(t-1) to M_t to the loss. Samples (rows) for which the model in \"timestamp\" t-1 are not corrected classified are replaced in M_(t-1) by their values from M_t.\n\nThe paper presents two experiments to evaluate the performance of the proposed method. The first experiment follows the same setting as the analysis above and in the second experiment, the authors trained a CLIP0 model on COCO and Flickr datasets and gradually trained 8 additional models on 8 subsets of SBU-1M. The experiments demonstrate that using the proposed method, the resulting models only suffer from a small degradation of performance on the \"baseline\" dataset while performing well on the \"new\" gradually added sub-datasets, compared to the baseline CLIP0 model and even perform better on the \"new\" dataset than the baseline continual training model. \n \n\n\n",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well written and easy to follow. \n2. The paper provides a thorough analysis on the causes for performance drop in vision and language models from an original point of view.\n3. The proposed method performs very well in practice, as demonstrated in the experiments. \n4. The paper showcases a real problem, provides an analysis to its cause, proposed a solution and provides experiments supporting the claims made and demonstrating superior performance of the proposed solution. \n\n\nWeaknesses and questions:\n1. First, I strongly recommend to change the terminology of \"Cognitive Disorder\". The term has little connection to the problem it describes, it's a bit far-fetched to borrow a term originally used to describe a mental health disorder and really adds nothing to the paper. A more technical term (dataset forgetting, degradation from distribution shift,...) would be much better.\n2. The analysis on the causes of the performance degradation is done on the test set. However, the proposed solution is of course implemented during training. We obviously can't add a loss term during training and optimise it on the test set, but how much of this analysis holds when you consider the training set? I would expect the model to overfit to the training set, would there be inter-modal deviation between subset t and subset t-1 during training? \n3. In table 3 alpha is set to 20. An analysis of the effect of alpha and to what extent the method is robust to the choice of alpha would be interesting to see. Of course, as alpha is increased the effect of \"alignment\" between models is increased, but I think the paper should explain how alpha was selected to be 20 and how sensitive this value is (e.g. how dramatically the results would change if a different, less ideal value would be used). \n4. A drawback of the method is that it required to store the vision and language embeddings from model t-1 during training of model t (or re-evaluate them during step t). I'm not sure how much it would be applicable to training on huge scale datasets (e.g. LAION dataset). ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, novel and the method is easy to reproduce. ",
            "summary_of_the_review": "Strong paper in my opinion. The paper identifies a continual learning performance degradation as drawback of joint vision and language embedding models. It demonstrates this drawback by training a baseline model on COCO, \"finetuning\" it on Flick and evaluating on both Flickr and COCO test set, indicating a clear degradation on COCO. The paper analyses the cause for it and finds it to be Intra modal deviation, i.e.: misalignment between the amount of rotation of diagonal elements during training between the two modalities and designs a solution via adding a term to the loss to encourage intra modal alignment. The paper provides experiments that demonstrate the affect of the solution in mitigating the drawback. I mentioned a few weaknesses and question I would appreciate if the authors could address in their rebuttal. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_7TxY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1726/Reviewer_7TxY"
        ]
    }
]