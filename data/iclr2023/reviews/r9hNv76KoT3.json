[
    {
        "id": "EaCPXfYmBu",
        "original": null,
        "number": 1,
        "cdate": 1666639063641,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666639063641,
        "tmdate": 1666639063641,
        "tddate": null,
        "forum": "r9hNv76KoT3",
        "replyto": "r9hNv76KoT3",
        "invitation": "ICLR.cc/2023/Conference/Paper453/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work is proposing a metric to measure and compare the expressivity of GNNs - the capacity of solving vertex/edge biconnectivity. It carefully revisits several popular frameworks of designing powerful GNNs with comprehensive and rigorous analysis of their capacity on biconnectivity. Then, beyond the expressive but expensive previous works, it proposes a cheaper and powerful framework - GD-WL - with its Graphormer implementation. The proposed method is evaluated with synthetic experiments of biconnectivity and real-world benchmarks.",
            "strength_and_weaknesses": "Pros:\n1. The motivation of proposing such a metric is natural and fundamental, since graph isomorphism testing is too abstract to guide practical design of GNNs. And I agree that biconnectivity plays a key role in justifying any meaningful high-order substructures, such as those in bio-chemistry.\n2. The theoretical of recent popular frameworks is pretty comprehensive. It includes almost all popular works with detailed discussion of counter-examples and proof.\n3. The proposed GD-WL is efficient but still powerful enough to solve biconnectivity. It Graphormer implementation enjoys splendid performance on synthetic experiments and real-world benchmarks against strong baselines.\n\nCon:\n1. Since there are so many results in the main text, it would be great to present all these results in a comprehensive table near the introduction, to make it easier for any audience to get the message precisely.\n\nTypo:\n1. In appendix B.4, bolded ``Note`` -> ``Node``\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality, clarity and originality of this work are great.",
            "summary_of_the_review": "I would like to recommend a strong acceptance since this work carefully presents everything necessary in this framework of biconnectivity. On one hand, it is making a significant contribution regarding theoretically understanding expressivity to the GNN community. On the other hand, instead of simply presenting counter-examples on a limited range of models like some common papers these days, it presents theoretical results of the most general frameworks with proof, which would stand a role model for future works.\n\n=== Acknowledgement ===\n\nDue to time limit, I only read the theorems in the main text but did not check the proof in the appendix.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper453/Reviewer_FHtc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper453/Reviewer_FHtc"
        ]
    },
    {
        "id": "JAj2S82TEb",
        "original": null,
        "number": 2,
        "cdate": 1666657804008,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657804008,
        "tmdate": 1666658922950,
        "tddate": null,
        "forum": "r9hNv76KoT3",
        "replyto": "r9hNv76KoT3",
        "invitation": "ICLR.cc/2023/Conference/Paper453/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes using the computation of node- and edge-level biconnectivity properties as expressivity metrics for GNNs. It analyzes four families of GNNs and finds that they fail to decide these biconnectivity metrics, except for ESAN. The paper provides insights into the power of ESAN. Based on these insights, the paper proposes a new color refinement algorithm that leverages distance between nodes to achieve expressivity in terms of the biconnectivity metrics. Experiments on the ZINC dataset show the efficacy of the proposed method in a real-world graph-level task.\n",
            "strength_and_weaknesses": "**Strengths**\n- The paper is well-written, and the authors did a good job reviewing the related literature.\n- The introduced biconnectivity metric relates to important concepts in network science and is well-motivated.\n- The paper provides theoretical insights into existing methods and represents an excellent contribution to the graph ML community. \n- The proposed Transformer-based architecture is simple, relatively novel, and naturally derives from the paper's findings.\n\n**Weaknesses**\n- Very limited empirical evaluation setup.",
            "clarity,_quality,_novelty_and_reproducibility": "Although I have no major concerns regarding the clarity and quality of the paper, here are some questions and comments:\n- Although the paper claims that the computational overhead of GD-WL is negligible, it would be helpful to report a time comparison between the proposals and the baselines (including vanilla MPNN).\n- The paper only considers one molecular dataset for graph-level tasks. Since higher expressivity doesn't imply better performance on real-world problems, I'd like to see the performance of the proposed methods on more datasets, including node-level tasks.\n- Any particular reason to use ZINC? Is there any connection to biconnectivity properties?\n- Similarly to DE-GNN (Li et al., 2020), is the class of distance regular graphs pathological for GD-WL?\n- Based on Table 3, should we expect that GD-WL cannot decide properties such as diameter, radius, conjoint cycle, and the total number of cycles? Have you proved this?\n\nOverall, the theoretical results in the paper are not trivial, and the **technical novelty is sound**.\n\n**Reproducibility**: The code is not available during the reviewing process, but the authors provide implementation details in the Appendix (section F).\n",
            "summary_of_the_review": "The paper is well-written and consists of a solid contribution to the graph ML community. The results and insights from this paper should definitely be used in further developments in the field. My main concerns revolve around empirical evaluation. Therefore, I am recommending acceptance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper453/Reviewer_kMJa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper453/Reviewer_kMJa"
        ]
    },
    {
        "id": "UtDyYFvu3V5",
        "original": null,
        "number": 3,
        "cdate": 1666670274879,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670274879,
        "tmdate": 1666670274879,
        "tddate": null,
        "forum": "r9hNv76KoT3",
        "replyto": "r9hNv76KoT3",
        "invitation": "ICLR.cc/2023/Conference/Paper453/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper discusses the graph biconnectivity and the potential of existing GNNs on recognizing it. It first proves most of the existing GNNs and 1-WL cannot distinguish biconnectivity. The author proves ESAN are powerful enough for this problem due to the subgraph aggregation policies. Furthermore, author discusses the ",
            "strength_and_weaknesses": "Strength:\n1. Very interesting and innovative study on biconnectivity problem.\n2. The theoretical discussion on ESAN and proposed Graphomer-GD are comprehensive and clear.\n\nWeakness:\n1. The organization of the paper is a bit hard to follow. I am not fully understand of explaining ESAN in the main paper since eventually author proposes a more efficient variant of graphomer. I suggest focus on Section 4 since section 3 and 4 seems quite parallel to me...\n2. The synthetic experiment is missing some details such as number of graphs and size of the graphs. The numbers reported in Table 1 lack of number of repetitions and variations.\n3. The efficiency of the proposed method. Can you share with us the amount of parameters of Graphormer-GD and other baselines ? What's the empirical running time on ZINC?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written in good quality. Although some heavy theoretical details make the paper make the paper hard to follow, I still believe it can be easily improved with minor modifications. The novelty of the paper is significant on graph theory and results on molecular graph regression is encouraging as well.",
            "summary_of_the_review": "I think this is a great paper discussing the capacity of graph neural network on one of the fundamental problem for graph. Despite I found the structure of the paper can be improved, I still think it's an excellent paper to the community. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper453/Reviewer_yHMN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper453/Reviewer_yHMN"
        ]
    }
]