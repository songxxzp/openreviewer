[
    {
        "id": "dG93g3fhxi",
        "original": null,
        "number": 1,
        "cdate": 1666367817731,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666367817731,
        "tmdate": 1666367817731,
        "tddate": null,
        "forum": "nI2HmVA0hvt",
        "replyto": "nI2HmVA0hvt",
        "invitation": "ICLR.cc/2023/Conference/Paper2500/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Interesting paper concerning unsupervised visualization of image data using neighbour embeddings that borrows ideas of ideas from contrastive learning.\nIt is motivated by the need of mapping from the high-dimensional pixel image  space into lower dimensions (two, in this study), where, as the authors pose it, \"distances in pixel space are often not capturing our sense of similarity\", so that \"neighbors are not semantically close\".",
            "strength_and_weaknesses": "Strengths:\nQuite well written.\nGood discursive didactic style.\nMarginal but useful technical novelty.\nExcellent review of existing literature.\nCode available.\n\nWeaknesses:\nMarginal/incremental novelty\nA bit too much setting-cooking, which arises some doubts as to the generalizability of the proposal.",
            "clarity,_quality,_novelty_and_reproducibility": "It is clear, the research is of fine quality and, as previously mentioned, technical novelty, even if somehow marginal, is still of interest to the data analyst with a taste for exploratory visualization. The availability of the code and data makes the results reproducible.",
            "summary_of_the_review": "Interesting paper concerning unsupervised visualization of image data using neighbour embeddings that borrows ideas of ideas from contrastive learning.\nIt is motivated by the need of mapping from the high-dimensional pixel image  space into lower dimensions (two, in this study), where, as the authors pose it, \"distances in pixel space are often not capturing our sense of similarity\", so that \"neighbors are not semantically close\".\nThe paper is quite well written and its structure is quite fresh and didactic.\nIt uses contrastive learning SimCLR method that generates high-dim image representations and it is used to directly optimize a 2D embedding.\nThe main novel contribution is the pretraining strategy required for this proposed model to work, specially given that two other recent papers seem to be chasing the same idea (Zang et al., Hu et al., both from this year) Such pretraining strategy is a bit too trial and error for my taste (in the sense that it makes you wonder whether it should be tailored to the analyzed dataset at hand), althoug, arguably, understandably so.\nThe literature background section, by the way, is excellent.\nIn section 3.3, for embedding quality assessment, authors use kNN and indicate that \"For kNN accuracy, we used the scikit-learn [...] implementation with k = 15\". Why k=15? What's the rationale for that choice? Did authors investigate other alternative values of k?\nThe experimental body, even if not being fully conclusive, provides very good evidence of the data exploratory potential of the model.\n\nOther:\nIt would be useful to clarify in the introduction that Figures referenced as A.x refer to an appendix.\nFigure 1 should be better located at the end of the introduction.\np.2, section 2: \"In this work, we are interested in an unsupervised but parametric mapping that ALLOWS embedding ...\"",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_LCjY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_LCjY"
        ]
    },
    {
        "id": "5hQOXnWnhYn",
        "original": null,
        "number": 2,
        "cdate": 1666599939987,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599939987,
        "tmdate": 1666631446113,
        "tddate": null,
        "forum": "nI2HmVA0hvt",
        "replyto": "nI2HmVA0hvt",
        "invitation": "ICLR.cc/2023/Conference/Paper2500/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In recent years, neighbor embedding methods, such as t-SNE and UMAP, are popular for visualizing high-dimensional data. Motivated by the success of contrastive learning, the authors propose a new method t-SimCNE for unsupervised visualization of image data. The proposed method builds on the popular SimCLR, but replaces the loss with a heavier-tail loss as is used in t-SNE, because it is better for visualization 2D representation. \n\nThe authors detailed training strategies for training/pre-training the new model, showing that the proposed strategies are crucial for resolving nontrivial implementation issues. The authors also present thorough experimental results, showing that t-SimCNE is good at showing revealing fine-grained representation information and subclass structure.",
            "strength_and_weaknesses": "For unsupervised visualization of image data, one challenge is how to provide as much information as possible in a 2D space. By utilizing the t-SNE loss function in the neighbor embedding literature, the authors propose a natural way to embed and visualize images, which they call t-SimCNE.\n\n**Strengths:** It is clearly shown that it is nontrivial to train the model with a loss similar to t-SNE. Moreover, the authors provide several pre-training strategies and demonstrate that their pretraining/fine-tuning with Euclidean loss strategy works the best. See Figure 2 and 3.\n\nFurthermore, it is clearly shown that data visualization t-SimCNE displays fine-grained structures that is very useful for data diagnostics and interpretation. \n\n**Weaknesses:** I do not find major weaknesses. Perhaps the authors make comments on (1) if there is dimensional collapse issue during training, especially if we do not follow the proposed training strategies, and (2) what information is lost when embedded data is restricted to 2D instead of the initial 128D.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is very clearly written. I find the reasoning and plots convincing. The method is novel as far as I know. I did not check, but it seems that the results are reproducible.",
            "summary_of_the_review": "The authors provide a very useful method for visualizing image data by combining SimCLR and t-SNE in a nontrivial way (implementation-wise). I think that this paper has potential impact, and would highly recommend acceptance of this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_nGad"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_nGad"
        ]
    },
    {
        "id": "1hW-702qshE",
        "original": null,
        "number": 3,
        "cdate": 1666635632098,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666635632098,
        "tmdate": 1668192399824,
        "tddate": null,
        "forum": "nI2HmVA0hvt",
        "replyto": "nI2HmVA0hvt",
        "invitation": "ICLR.cc/2023/Conference/Paper2500/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method for unsupervised visualization of image datasets. The proposed method relies on first training a NN using contrastive learning and using its representation to minimize another contrastive loss to project the embedding to 2D. The results are validated on standard image datasets.",
            "strength_and_weaknesses": "I'm surprised that the authors have missed an important contrastive-loss-based dimensionality reduction method, called TriMap [1], that relies on a very similar principle for generating 2D embeddings. The proposed method can be seen as a variant of TriMap where the input representation is generated by a ResNet.\n\n[1] Ehsan Amid and Manfred K. Warmuth. \"TriMap: Large-scale dimensionality reduction using triplets.\" arXiv preprint arXiv:1910.00204 (2019).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "It is unclear to me what do $i$, $j$ (i.e., the similar pair) correspond to in Eq (4)? TriMap uses the k-NN of each point $i$ to draw $j$ (the similar point), and point $k$ (dissimilar point) is drawn randomly from the remaining points that are farther away than $j$. In the proposed method, do you create new augmentations for the 2D embedding? I think this needs to be clarified further.",
            "summary_of_the_review": "The proposed approach has a significant amount of overlap with TriMap, a contrastive-loss-based dimensionality reduction method. The authors need to clarify how their method differs from TriMap, what advantages (if any) it provides, and perform a comparison.\n\n\nUPDATE: I'm increasing my score to acknowledge the authors' efforts to include additional results. However, I still believe the contributions of the paper are very limited. Please see the response to the authors' feedback.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_25XC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_25XC"
        ]
    },
    {
        "id": "EuzINSqk5C",
        "original": null,
        "number": 4,
        "cdate": 1666666540277,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666540277,
        "tmdate": 1668528558037,
        "tddate": null,
        "forum": "nI2HmVA0hvt",
        "replyto": "nI2HmVA0hvt",
        "invitation": "ICLR.cc/2023/Conference/Paper2500/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper reasons about the relationship between SimCLR, a recent self-supervised learning method, and tSNE, a popular dimensionality technique for data visualization. At the intersection of these two methods, the paper proposed a new method, based on self-supervised learning, for high-dimensional data visualization (to be used instead of tSNE). The new method, known as t-SimCNE, removes the 1-norm constraint on the standard SNE loss, replacing cosine with Euclidean loss, and trains the SimCLR network in two stages to achieve better performance. Compelling results with respect to tSNE are demonstrated in the CIFAR-10 and CIFAR-100 datasets, both qualitative and accuracy.\n",
            "strength_and_weaknesses": "Strengths\n- A novel application of self-supervised learning, dimensionality reduction, is discussed and explored. \n- Paper is clearly written\n- A mathematical relationship between the SNE and simCLR loss is derived\n- Ablation study of the different training strategies (number of training epochs, type of loss, type of training/fine-tuning) elucidates when does the proposed method works and does not work\n- Experiments are conducted on two standard public image benchmarks (CIFAR-10 and CIFAR-100 datasets)\n- Results are compelling and convincing\n\nWeaknesses\n- There is no computational analysis provided. tSNE is known as a relatively lightweight technique that can be used to quickly browse a large dataset. It is not clear whether the proposed method, t-SimCNE, can be run in a similar amount of time and amount of computational resources (batch size of 1024 is large and requires high-memory GPU). A discussion of when the proposed method would be more suitable, in comparison to tSNE, is missing. \n- The key weakness of tSNE pointed out in the intro is that it does not work well on large datasets (reader is pointed to figure A.1). However, in Figure A1, it is not clear what the problem is? Perhaps a zoom in to the graph to illustrate the mix of the labels would help\n- In Equation (3), a relationship between the stochastic neighbor embedding (SNE) and the SimCLR loss is derived. What is the relationship between SNE and t-SNE?\n- What happens if the pre-training on SimCLR is done on a different dataset (e.g., ImageNet), as a strategy to save training time?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, and all hyper-parameters to reproduce the method seem to be included. While there is some previous work that discussed the relationship between SimCLR and tSNE, no derivations or empirical results have been provided to date (so the contribution of the paper is novel). While there are some key questions in the weakness section that need to be clarified, overall, the paper would be a useful contribution.\n",
            "summary_of_the_review": "The paper offers a novel and thorough empirical and mathematical analysis of tSNE and SimCLR and derives a learning-based dimensionality reduction method. \n\nEDIT: After reading the response and comments by the other reviewers, I believe that the contribution is marginal. The paper would benefit from a more thorough discussion and comparisons to prior work, as well as ablation studies with different backbone settings. I am also concerned about the large runtime of the method, which might prevent it from being used more widely in practice.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_TNpm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2500/Reviewer_TNpm"
        ]
    }
]