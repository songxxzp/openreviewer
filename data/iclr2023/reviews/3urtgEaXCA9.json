[
    {
        "id": "xOA-GkEQQI",
        "original": null,
        "number": 1,
        "cdate": 1666388290751,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666388290751,
        "tmdate": 1666388290751,
        "tddate": null,
        "forum": "3urtgEaXCA9",
        "replyto": "3urtgEaXCA9",
        "invitation": "ICLR.cc/2023/Conference/Paper4208/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper designs an algorithm for neuromorphic chips, where weights in the final product can look different due to manufacturing imperfections. Assuming the weights are perturbed with a known distribution, this devices an alternative to SGD that aims to minimize the generalization loss with expectation not just over the data distribution, but also the weights distribution. It does this showing improvements over SGD, as well as other methods that would seem to be beneficial for this type of generalization.",
            "strength_and_weaknesses": "Strengths\n- The training strategy is a combination of weight noise sampling during training (HSV, the more obvious training method) and a minimax loss that assumes perturbation in the worst direction. A combination of both gives the best results and tests on both artificial NNs as well as spiking NNs.\n- It is interesting that methods like AWP and SAM do not exhibit better robustness in this regard. This motivates the paper.\n- Ultra-low power devices that this is discussing can have significant societal benefits, not the least in the medical domain.\n\nWeaknesses:\n- It is never verified on real hardware. It is unknown how this Gaussian perturbation distribution actually corresponds to real hardware. One of the criticisms of prior art was that it was too specific to a particular hardware. That must mean there is a great variation, so does this simple synthetic Gaussian really represent the real world? If the benefit of this is that one training algorithm can work for many types of hardware, shouldn't that also be simulated in the evaluation protocol?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well-written and easy to follow. Some editorial improvements could be made (e.g. the sentence \"Therefore, the rapid increasing direction is the solution to the problem\" -> \"Therefore, the most rapidly increasing direction is ...\" / A new line with the value 98.09 on page 6).\n\nThe paper relates this work to other relevant topics, such as adversarial weight perturbation (AWP) and sharpness-aware minimization (SAM). However, I do wonder if there is a missed opportunity to also relate this to meta learning (see MAML, Reptile, etc.), where each \"task\" could be the task of inference under perturbed weights (if not, please ignore). The paper presents novelty as evidenced by the experimental improvements over methods like AWP and SAM.\n\nSource code is promised to be released.\n\nTo readers outside the neuromorphic literature, it is a bit unclear how close this type of hardware is to productization. I know there are some startups claiming to make chips like this, but I don't know enough to judge what impact this line of work is right now. It would help if the paper discussed how and when this type of algorithm could become used in practice.",
            "summary_of_the_review": "This presents a novel algorithm specifically targeting neural network settings where final weights are hard to control exactly due to manufacturing imperfections. This does not affect the vast majority of neural networks running on smart devices today, which does limit the impact, but it could become increasingly important in the future and work in this direction seems motivated. It is sound work with good experimental results. Due to some question marks around potential practical impact and the methods being fairly straightforward, I rate this as a weak accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_RFsq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_RFsq"
        ]
    },
    {
        "id": "2L0wKhdLs9",
        "original": null,
        "number": 2,
        "cdate": 1666674486608,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674486608,
        "tmdate": 1666674486608,
        "tddate": null,
        "forum": "3urtgEaXCA9",
        "replyto": "3urtgEaXCA9",
        "invitation": "ICLR.cc/2023/Conference/Paper4208/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces two sources of noise applied during training to flatten the loss landscape and make weight more resilient to device variability: Hardware-simulated variation (HSA, gaussian noise which scales with the width of the weight distribution of each layer) and Gradient-ascent variation (GAV, added noise in the direction of steepest gradient). The proposed algorithm selects randomly between HSA and GAV during training, using (a hyperparameter $w_{th}$ as threshold and redrawing the selection at every batch. Results are presented on several neural network and spiking neural network models, on basic image classification datasets. ",
            "strength_and_weaknesses": "Strengths:\n- although the two formulation of the proposed noise is definitely not novel, their threshold-driven combination might be\n- experiments compare a range of models across fundamentally different architectures\n- experiments do show (Fig. 5) that the proposed technique achieves remarkably flatter losses than the alternatives\n\nWeaknesses:\n- paper is often confusing, often lacking in details and clear explanations, it requires further proofreading\n- the method introduces two hyperparameters, $w_{th}$ and $\\gamma$, for the noise source selection and noise scaling, respectively. It's unclear and never motivated why the selected default values (chosen on the basis of VGG5, CIFAR-10 experiments) would be the appropriate selection across different models\n- some level of noise are simulated ($\\sigma_v = 5 or 10%$ in Table 1-3) but there is no correlation of this additional parameter with the incidence of hardware noise, which this technique is supposed to address. There is not attempt to establish this relationship at all (not even with a comparison with the literature). The shape of the real hardware noise may also dramatically differ from what is being used here at test time\n\nOther comments and corrections:\n- I don't understand the meaning of this sentence in section 1: \"we expect that WVAT will help the development of society related to hardware implementation\"\n- fig 1 shows accuracy drop in the presence of \"weight variation\". I assume these variations are weight noise added entirely at the software level (simulated device variability). Is this correct? What variations are being simulated in this figure?\n- section 3: when $\\gamma$ is introduced, it should be specified that it is an additional hyperparameter (this is only mentioned later).\n- section 4: SGD-TTV explanation is unclear: \"which means when the weight of the trained model perturbs during a test phase\". Does this mean the perturbation is only applied at test time? What level of perturbation is being applied?\n- figure 4a does not specify what $\\gamma$ is being used. figure 4b results do not specify what $w_{th}$ is used and do not appear to match numerically with those in figure 4a (for example, $\\gamma=1$ gives $WVAT-TTV \\sim 88%$, which in no case matches fig. 4a WVAT-TTV curve). \n- section 4.1: I suppose $\\alpha$ is the learning rate but it is never defined\n- fig. 6 shows a single layer per network. Some visualization of the distribution broadening across the full networks would be more appropriate\n- section 5.2: what does it mean that post training quantization \"is mainly used as a baseline\"?\n\nOther typos:\n- fig 4b: \"range coefficeint\"\n- fig 7: \"qunatization\"\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is confusing, requires multiple passes to understand the scattered details of the implementation \nThere is some novelty in the joint use of two noise sources. However, the introduction of additional hyperparameters is undesirable.\nSufficient details are provided that should allow to reproduce these experiments.",
            "summary_of_the_review": "The authors demonstrated that there is value in the idea of alternating sources of noise during training to achieve flatter losses which make the model more robust to some type of noise at inference time. A correlation between actual noise encountered in hardware and this software simulated noise is lacking entirely, so it is hard to draw a conclusion on the actual effectiveness of the proposed technique in real world scenarios. The paper also necessitates extensive proofreading and polishing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_XxLX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_XxLX"
        ]
    },
    {
        "id": "ntiCWPqZ41",
        "original": null,
        "number": 3,
        "cdate": 1666751827850,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666751827850,
        "tmdate": 1666751827850,
        "tddate": null,
        "forum": "3urtgEaXCA9",
        "replyto": "3urtgEaXCA9",
        "invitation": "ICLR.cc/2023/Conference/Paper4208/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a more robust training method for neurotrophic devices ",
            "strength_and_weaknesses": "Strength:\n* The paper is well struct and easy to follow. Results are clearly listed in tables and figures.\n\nWeaknesses:\n* I think the claim of \"hardware-oriented\" is a bit of stretch as the core of the target problem in improving robustness on process variation mostly occurs in neuromorphic computing with analog in particular.\n* For having a process variation of 10%, does this mean testing with all weights with 10% shift, or up to 10% shift?\n* For figure 7, while I do understand that quantisation is an issue, comparing the performance against SGD rather than quantisation techniques seems a bit misleading. The same applies to input noise, these are covered by network robustness and attack. \n",
            "clarity,_quality,_novelty_and_reproducibility": "* This paper is clear and with decent quality. ",
            "summary_of_the_review": "This paper does propose a new training method to improve robustness towards wright variation, the applicability does not occur very broad to me other than for memristive devices. A few claims and comparison in quantisation and input noise should be fairer. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_oSwx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_oSwx"
        ]
    },
    {
        "id": "QrMZtbBsMJ",
        "original": null,
        "number": 4,
        "cdate": 1667132826862,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667132826862,
        "tmdate": 1667132826862,
        "tddate": null,
        "forum": "3urtgEaXCA9",
        "replyto": "3urtgEaXCA9",
        "invitation": "ICLR.cc/2023/Conference/Paper4208/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Spiking Neural Networks mimic the biological nervous systems for ultra-low-power NN execution.\nHowever, it can be sensitive to the weight perturbations that may lead to significant performance drop.\nThe paper aims to understand the causal relationship between the perturbations and the performance drop to devise a Weight Variation Aware Training Method.\nThe paper provides experimentation on small networks to show that it can reduce accuracy degradation.",
            "strength_and_weaknesses": "+ SNNs are interesting research topic with huge potential for ultra-low-power NN execution.\n+ Closing the gap between the ideal vs real execution (with perturbation) is important.\n\n- More details on Section 3 would help.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well written. However, the paper would benefit from more details in Section 3. The paper only spend little portion of the paper to explain the main idea.\n\nThe paper makes reasonable contribution in terms of considering the variability through imitation (HSV) and considering the worst cases of the variation through (GAV).\n\nDetails in Section 3 seems to be rather weak, which may limit reproducibility.",
            "summary_of_the_review": "The paper aims to close the gap between the ideal and the real implementation of the SNNs by devising a variation-aware training. Considering the potential upsides of the SNNs such as the low power NN execution, the paper works on an important topic. While some improvements can be made, the paper also does a good job in explaining the problem and the key ideas. \n\nThe paper provides two ideas Hardware-simulated variation (HSV) which acts as a imitation model of the hardware variability. Similar idea is presented in the following paper which should be noted. However, considering the difference (DNN vs SNN) this seems like a neat contribution.\n* Ghodrati, Soroush, et al. \"Mixed-Signal Charge-Domain Acceleration of Deep Neural Networks through Interleaved Bit-Partitioned Arithmetic.\" Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques. 2020.\nIn addition to HSV, the paper develops Gradient-ascent variation which considers the worst case.\n\nThe paper runs experiments to show the effectiveness. It seems to make a thorough comparison against baselines (SGD and SWA). The paper also provides some discussions. While the experimentation on SNNs seem reasonable, experiments with ANNs seem rather weak. Adding some datapoints (larger networks, datasets) would make the claims stronger in the paper.\n\n* Typo in Figure 7: Qunatization -> Quantization",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_giaL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4208/Reviewer_giaL"
        ]
    }
]