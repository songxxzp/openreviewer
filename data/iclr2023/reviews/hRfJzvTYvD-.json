[
    {
        "id": "A04rWFScZ7",
        "original": null,
        "number": 1,
        "cdate": 1666545515516,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666545515516,
        "tmdate": 1673287636339,
        "tddate": null,
        "forum": "hRfJzvTYvD-",
        "replyto": "hRfJzvTYvD-",
        "invitation": "ICLR.cc/2023/Conference/Paper2754/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose to identity hard-subset samples in the target dataset for transferability estimation. The main idea is to find the hard examples from the target set by computing the similarities of the source features and target features. The hard examples are used with LEEP, NCE and GBC to improve the performance of transferability estimation of these methods. ",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is clearly written and easy to understand. \n2. The idea of using hard examples for transferability estimation is interesting. \n\nWeaknesses:\n\n1. The major concern is the setting of the method. The authors assume all the source samples and target samples are available. However, in practice, in many cases we just have the pre-trained models and a subset of the target samples. This makes the method not applicable in many real-world settings.\n\n2. The method of calculating hardness is kind of ad-hoc. It is more about the similarity to the source data rather than the hardness of the samples. \n\n3. Also, many recent baselines are not considered, such as LogMe (ICML 2021).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear and quality is good. The novelty of proposed method is moderate. The idea of using hard examples for transferability estimation is interesting. The method seems easy to reproduce. ",
            "summary_of_the_review": "The authors propose a method for finding hard examples for transferability estimation. The assumption is however too strong which makes the method not widely applicable. \n\nPost rebuttal:\n\nAfter reading the rebuttal, I still tend to maintain the score. The main concern is the applicability of the method in a more broad setting for transferability setting. The assumption of having all the samples available is too strong for practical application of the method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_nxzz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_nxzz"
        ]
    },
    {
        "id": "5TKBMEtCsik",
        "original": null,
        "number": 2,
        "cdate": 1666634373974,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634373974,
        "tmdate": 1669779071355,
        "tddate": null,
        "forum": "hRfJzvTYvD-",
        "replyto": "hRfJzvTYvD-",
        "invitation": "ICLR.cc/2023/Conference/Paper2754/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes HASTE for estimating the transferability of a source domain to a target domain. Two techniques are introduced, one is class-agnostic and another is class-specific. The techniques achieve state-of-the-art compared to other concurrent baseline metrics.\n\n--post rebuttal--\n\nDear authors, thank you for going through my comments and trying to address them. However, I still think the current draft is not ready for submission. As Reviewer bePf also pointed out, the current method (HASTE) is not clearly motivated, and comparison with other transferability metrics is not properly made. Overall, this paper is not clearly written. I would suggest the authors keep polishing the draft for the next round.",
            "strength_and_weaknesses": "Strengths:\n1) The problem of estimating the transferability is interesting and important for transfer learning, and the proposed method is well-motivated. \n2) Good literature survey and comparison with three baseline algorithms. The improvement is noticeable.\n3) The authors test the proposed transferability metric on a large variety of benchmark datasets. The comparison looks quite comprehensive.\n4) Some theoretical analysis is discussed. For example, Lemmas 1 and 2 show that Haste is upper bounded by the average log-likelihood of the hard subset, and lower bounded by the NCE measure plus the log-likelihood of the source label distribution computed over the hard subset.\n\nWeaknesses:\n1) What is the definition of transferability? I think even this question is still a hot research topic, e.g., in [1], [2], and these metrics have not been discussed in the paper. The transferability definition is not clearly given either.\n2) the activation volume $\\mathcal{E}_l$ is not well defined.\n3) How would eq. (2) and eq. (4) relate to each other? They use the same notation but seem to be different definitions.\n4) In eq. (5), the authors say $\\mathcal{T}$ can be any existing transferability metric, but the main goal of the current paper is to propose a new transferability metric. Does that mean HASTE is like a \"meta\"-transferability metric that can work on top of any existing ones?\n5) The connection between the class-agnostic and the class-specific methods are not clearly shown. They seem to be two separate methods.\n6) For the theoretical analysis, the discussion of Lemmas 1 and 2 are lacking: why would showing the lower and upper bounds of HASTE be interesting and what is the meaning of it?\n7) For the experiments Table 1 and Table 2, the improvement over baselines are quite minor (~0.002 sometimes), while sometimes it helps a lot (like Table 5 and Emotion-IMDB). What is the reason for this? Why for example, does HASTE not improve over GBC at all?\n\n\n[1] Zhang, Guojun, et al. \"Quantifying and improving transferability in domain generalization.\" Advances in Neural Information Processing Systems 34 (2021): 10957-10970.\n[2] Huang, Long-Kai, et al. \"Frustratingly easy transferability estimation.\" International Conference on Machine Learning. PMLR, 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the current paper is not quite clearly written (see weaknesses above).\nQuality: the experimental section has many datasets, tasks and 3 baseline algorithms. This is quite solid. The theoretical analysis is not so strong.\nNovelty: some literature for transferability is missing.\nReproducibility: the paper doesn't attach code in the supplementary.",
            "summary_of_the_review": "In summary, this work proposes an interesting approach using the hard subset to measure the transferability. However, some parts are not clearly written, and the theoretical analysis doesn't fully explain the experiments (it only covers LEEP).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_acad"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_acad"
        ]
    },
    {
        "id": "o0x3YJGnrdk",
        "original": null,
        "number": 3,
        "cdate": 1666693329169,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693329169,
        "tmdate": 1670064739663,
        "tddate": null,
        "forum": "hRfJzvTYvD-",
        "replyto": "hRfJzvTYvD-",
        "invitation": "ICLR.cc/2023/Conference/Paper2754/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes to address the problem of estimating transferability from a source to the target domain by using examples from the harder subset of the target dataset. The authors introduce class-agnostic and class-specific techniques to identify harder subsets and show that the proposed method can be used with existing transferability metric to improve their reliability.",
            "strength_and_weaknesses": "Pros:  \n+ The work paper is easy to follow. The authors clearly present the proposed method and make detailed descriptions about the experiments.\n\n+ The idea of using hard samples to estimate transferability is interesting. \n\nCons:  \nMy main concerns about the work are two-fold:  \n- The motivation of the proposed transferability estimation method using hard samples are not well described. The observation that hard examples are more out-of-distribution and challenging than the easy samples in the transfer learning process is not a surprise. However, why using hard samples delivers higher transferability estimation performance, especially provided that the target data is usually filled with both easy and hard samples, or only hard samples (considering the case where source and target domain difference is extremely large), is not explained in the paper. Furthermore, the number of hard samples appears a very important hyperparameter in the proposed method. The ablation study show that the performance of the proposed method is very sensitive to this hyperparameter. How do we set this hyperparameter in our own problem?\n\n- Many highly relevant works are missing from the work, which leaves the superiority of the proposed method unclear. Some are listed as follows:    \n[1] Deep Model Transferability from Attribution Maps, NeurIPS2019.  \n[2] DEPARA: Deep attribution graph for deep knowledge transferability, CVPR2020.  \n[3] Logme: Practical assessment of pre-trained models for transfer learning. ICML2021.  \n[4] Representation similarity analysis for efficient task taxonomy & transfer learning. CVPR2019.    \n[5] Taskonomy: Disentangling task transfer learning, CVPR2018.    \nThe authors are encouraged to make discussions on these highly relevant works and clarify the differences between the proposed method and these prior works. Furthermore, any experimental comparisons with these works are especially appreciated.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and the proposed method is well provided. However, the motivation of the proposed method is not very strong, and the performance is sensitive to the number of hard samples. Some highly related works and the comparisons with them are missing in the paper, which makes the superiority of the proposed method unclear.",
            "summary_of_the_review": "The paper is well organized and the proposed method is well provided. However, the motivation of the proposed method is not very strong, and the performance is sensitive to the number of hard samples. Some highly related works and the comparisons with them are missing in the paper, which makes the superiority of the proposed method unclear.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_bePf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2754/Reviewer_bePf"
        ]
    }
]