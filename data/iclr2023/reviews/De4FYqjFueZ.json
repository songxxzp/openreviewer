[
    {
        "id": "7_XkO12h6w",
        "original": null,
        "number": 1,
        "cdate": 1666418357566,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666418357566,
        "tmdate": 1666418357566,
        "tddate": null,
        "forum": "De4FYqjFueZ",
        "replyto": "De4FYqjFueZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4543/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the relation between Transformer depth and its ability to solve algorithmic reasoning tasks. The authors formulate reasoning processes in terms of automata, and particularly focus on the question of why and if shallow Transformers are able to simulate automata with much longer horizons. A number of results are presented of the following flavor: Transformers of depth $o(T)$ can be used to simulate automata of length T so long as the width (of e.g., the MLP blocks in the transformer) is big enough, and enough attention heads are used. The width and number of heads needed is quantified in terms of the size of the state space. The shortcuts referred to in the title of the paper refers to the fact that these results show that Transformers can learn to simulate long processes without directly learning each step of the process explicitly. ",
            "strength_and_weaknesses": "This is a highly unusual ICLR paper. This is not to say that ICLR is an inappropriate venue for this work, since this is clearly not the case: the subject matter is of direct and high importance to the machine learning community. This work is unusual because of the breadth and depth of ideas and connections to different parts of the theoretical computer science literature, as well as very topical considerations to the ICLR community such as out-of-distribution generalization, spurious correlations, and neural algorithmic reasoning. For instance, the results presented in this paper are formulated in terms of the Transformer\u2019s ability to simulate automata\u2014-a now classical concept in AI (albeit being essentially conceptually the same as recurrent models). The analysis tools are also unusual, with many algebraic arguments used, and results from classical complexity theory are drawn upon. \n\nA few brief strengths:\n\n- A complete set of theoretical results, including general results for any arbitrary automata, sharper bounds for certain (solvable) automata, even sharper bounds for a particular class of automata (grid words), and lower bound results.\n- Experimental results validating a number of these findings on a number of algorithmic reasoning tasks, taking pains to use the experiments as a chance to bridge some of the inevitable gaps between the theory and practice (such as checking whether gradient-based training actually finds the shortcuts the theory identifies).\n- Taking care to at least discuss a number of questions a reader might have whilst reading this work, such as the connections to universal approximation, \n\nNo weaknesses come to mind, and I do not wish to work to artificially come up with problems. That\u2019s not to say that the work is perfect, of course it isn\u2019t, but I have no major concerns about the validity or significance of the results. ",
            "clarity,_quality,_novelty_and_reproducibility": "A further sense in which this paper is unusual is in the tidy, organized, and well polished presentation, which is at a level not typically seen in ICLR submissions. The paper is highly technical, and uses a considerable number of concepts that are likely new to the majority of the machine learning community, myself included, and yet the work remains relatively approachable to the extend that I am able to take away many useful points. \n\nIn terms of reproducibility, the authors commit to open sourcing their code. This is adequate for me. \n",
            "summary_of_the_review": "In all, I am strongly in favor of this paper\u2019s acceptance. I cannot pretend to have fully understood the depths of the ideas in this work - for instance I have not yet had the chance to study in detail how the attention mechanism is able to compete multiple automata steps in parallel (this is probably a good moment to make the disclaimer that I haven\u2019t properly verified any of the sizably appendix to this paper, so all results are taken on face value). However, I have read and understand more than enough to conclude that a this paper makes a contribution that is easily sufficient to merit acceptance at ICLR. I will be interested to see if any points are raised by other reviewers that I wasn\u2019t aware of, but I doubt anything will change my overall view. Congratulations to the authors on an immaculate piece of scholarship, I hope you continue to develop this line of work further. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_Czkt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_Czkt"
        ]
    },
    {
        "id": "vxsIZu3Q1d",
        "original": null,
        "number": 2,
        "cdate": 1666643643452,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643643452,
        "tmdate": 1667417569995,
        "tddate": null,
        "forum": "De4FYqjFueZ",
        "replyto": "De4FYqjFueZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4543/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This is a theoretical work about how transformer models can perform symbolic tasks.  The class of tasks considered is semiautomata (deterministic finite state machines).  The focus is on how a shallow network can compute sequences of states of length L much greater than the network depth D.  It is shown that this is indeed possible, with D \\sim log L at worst, and for a subclass of automata, constant D.\nExperiments are done to validate these predictions and to give evidence that these networks are learnable from data.\n",
            "strength_and_weaknesses": "Strengths: very interesting question and approach, solidly grounded in theoretical computer science, clearly written, strong results.\n\nWeaknesses: the scope and complexity of the ideas make them hard to fully convey in a paper satisfying the length constraints, even with the supplementary material.  In particular a lengthier comparison with the related works (and those in section A.5) would be of great interest.  We hope the authors will write a longer treatment elsewhere.",
            "clarity,_quality,_novelty_and_reproducibility": "Very clearly written and gets strong results.  The analysis makes use of deep prior results (Krohn-Rhodes theory) and thus can go far.  Possibly a breakthrough in theoretical analysis of transformers.\n\nA good computational model, much used for language processing (formal and natural), is the finite state machine (FSM or equivalently semiautomaton or deterministic Markov process).    Examples of computations naturally done by FSM's include group actions (say turning a sequence of Rubik's cube moves into the resulting sequence of face configurations) and processing regular languages (for example grouping characters into words).   Many more computations can be done with limitations.  Examples are checking properly nested parentheses with a maximum allowed nesting depth, or parsing sentences again with a limit on the parse tree depth.  There is a growing literature studying how and when transformers can learn to perform such tasks -- proposing circuits which can perform the tasks, empirically measuring the resources needed to learn the tasks, and reverse engineering the trained networks to understand their implementations.  Most of this work is referenced under \"related work\" and in section A.5.  A good part of it hypothesizes that the learned implementation is similar to a human designed circuit and looks for this structure in the trained network.  But this need not be the case and it is very interesting to have analyses based on other hypotheses or not presupposing a type of implementation.\n\nThe paper starts with the following observation.  An FSM can be implemented by a recursive neural network (RNN), which has state, in an obvious way.  However it is not as obvious how to implement a general FSM with a transformer model which does not have internal state and must compute each output as a function of the previous inputs.  A simple \"unrolling\" of the RNN leads to a circuit with depth T where T is the maximum length of an input sequence.  But transformers used in practice typically have depth 10-20, far smaller than the sequences being processed.  This is not a contradiction because attention can relate distant parts of the input, but there was no framework for understanding how this ability is actually being used.\n\nThe proposal of the paper is that one can start to understand this using Krohn-Rhodes theory, a branch of the mathematical theory of automata.  This reviewer had never heard of this theory and was not at first convinced that it was relevant, but after reading the paper finds that it makes a convincing case.  Intuitively, Krohn-Rhodes theory decomposes semiautomata into two basic units, simple group actions which are reversible, and memory units which are maximally irreversible.  The paper shows that these units and their combinations can be naturally implemented by the transformer architecture, and indeed one can see simpler (and presumably related) versions of these operations in the previous works on transformer circuits.  So this does seem to unify many previous results in a consistent framework.\n\nIn summary, this is a new and very original approach to a problem of great current interest, and which in my opinion could be developed much further.  As such it deserves to be highlighted at ICML.",
            "summary_of_the_review": "A novel approach to understanding transformers which leads to significant results.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_cJyA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_cJyA"
        ]
    },
    {
        "id": "tpuOJ1WICz",
        "original": null,
        "number": 3,
        "cdate": 1666690847015,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666690847015,
        "tmdate": 1666690847015,
        "tddate": null,
        "forum": "De4FYqjFueZ",
        "replyto": "De4FYqjFueZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4543/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper is a contribution to the understanding the capabilities of transformers to model languages. The first part of the paper provides results on the capabilities of (shallow) transformers to simulate computations of semiautomata at length T. The second part of the paper is an experimental study on whether learning allow to find such shallow transformers",
            "strength_and_weaknesses": "I am not expert in Computational Theory and Complexity Theory.\n\nPros\n\n* The theoretical contribution is dense but clear\n* The theorems seem sound\n* Experimental results complement theoretical results\n\nCons\n\n* Could be published at a conference but should be submitted at a review\n* Experimental protocols should be made more precise\n* I am not so convinced by the lessons drawn from the experiments",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is rather dense (9 pages for 60 pages with the Appendix) but it is clearly written. It should have been useful to position the study w.r.t. similar studies for LSTMs. For the theoretical part, as a non expert and because of the delay for reviewing,  I can not assert that the proofs are correct but the theorems seem sound to me. I would have liked also a discussion on the significance of simulation at length T while automata are designed as finite objects to deal with sequences of unbounded length. \n\nFor the second part of the paper, I would have liked to read more discussion with other contributions on learning automata such as the one by Bhattamishra et al. I am also always surprised that computational learning theory seems to be completely forgotten in papers along this trend of research. \n\nIt is clearly stated that the results are given by the best model but I would have liked to know how many experiments lead to good performance and how many to low performance. My main concern is about the evaluation protocol. It seems that the training set and the testing set are drawn with uniform distribution. I would have liked more on this. Indeed, when learning languages with very few positive examples such a protocol is meaningless. Also, for Dyck languages, what would be the meaning to evaluate on randomly drawn sequences of parentheses.",
            "summary_of_the_review": "I am clearly not expert enough to give a firm assessment of the paper. I tend towards acceptance because the theoretical results seem meaningful and sound to me. I would like to have more details to assert the significance of the experimental results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_zU3W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4543/Reviewer_zU3W"
        ]
    }
]