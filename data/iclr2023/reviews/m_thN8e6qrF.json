[
    {
        "id": "ODBMeV6_3HB",
        "original": null,
        "number": 1,
        "cdate": 1666496213936,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666496213936,
        "tmdate": 1666496213936,
        "tddate": null,
        "forum": "m_thN8e6qrF",
        "replyto": "m_thN8e6qrF",
        "invitation": "ICLR.cc/2023/Conference/Paper3756/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes FedDebias to address the data heterogeneity issue in federated learning. The paper observes that local features and global features are different even for the same input data and the local models classify all samples into the classes that appear in the local dataset. To address the above biased local features and local classifiers, FedDebias utilizes pseudo-data to improve local training. Specifically, it maximizes the distance between the local features of pseudo-data and local data, and minimizes the distance between the global and local features of pseudo-data. Experiments show that FedDebias outperforms the other FL approaches.",
            "strength_and_weaknesses": "Strength: The idea is clear. The experiments are comprehensive. The improvement of FedDebias is significant.\n\nWeaknesses:\n1. FedDebias needs to transfer pseudo-data during training, which is produced by averaging the raw data. Thus, additional privacy concerns and communication overhead are introduced in FedDebias, which lack analyses and discussion.\n\n2. The paper lacks theoretical analyses of the effectiveness and convergence of the proposed approach.\n\n3. The experiments can be further improved. What is the pseudo-data size generated by RSE? What is the subset size used to construct the samples in RSE? I think the pseudo-data is important in FedDebias. Thus, more investigation and experiments on the pseudo-data (e.g., changing the size of pseudo-data) are needed.\n\n4. I do not understand why it is necessary to maximize the distance between the local features of pseudo-data and local data first. The pseudo-data may have the same class with the local data. I think the paper should provide more insights into why such a min-max process can improve training. \n\n5. Typo: Page 5: maximizing local features -> maximizing the distance between \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper generally presents well. \n\nQuality: Fair. The paper does not provide solid analyses of the proposed approach.\n\nNovelty: The observation of the local bias from the feature view has been shown and investigated in many existing studies (e.g., [1,2]). The min-max process with the pseudo-data is interesting.\n[1] Model-contrastive federated learning\n[2] Federated Learning for Non-IID Data via Unified Feature Learning and Optimization Objective Alignment\n\nReproducibility: Good. The authors provide the source code.\n",
            "summary_of_the_review": "Overall, I think the paper proposes an interesting idea without solid analyses. The paper can be further improved to discuss privacy, effectiveness, and convergence of the proposed approach.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_cKx8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_cKx8"
        ]
    },
    {
        "id": "_4wa0Z2DeV",
        "original": null,
        "number": 2,
        "cdate": 1666603552797,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603552797,
        "tmdate": 1666603552797,
        "tddate": null,
        "forum": "m_thN8e6qrF",
        "replyto": "m_thN8e6qrF",
        "invitation": "ICLR.cc/2023/Conference/Paper3756/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new idea of reducing local learning bias to improve FL performance on heterogeneous data. This is achieved via the use of a validation dataset generated as either (a) random samples of local data; or (b) averaged of sampled local data. \n\nThe key idea is to solve a min-max optimization task which optimizes simultaneously for (1) a representation mapping that best distinguishes between global and local feature vectors; and (2) local representations and classifiers that produce best (local) performance and also minimize the distance to global representation of the same input. \n\nIntuitively, that means we are seeking local models that produce good local classification performance and have feature representation that cannot be \"easily distinguished\" from feature representation induced by a model trained on validation data. This means minimizing the performance of a distinguisher that learns to map features to a space on which distance between global & local features of the same input is maximized (hence, min-max optimization).\n\nThe proposed algorithm is compared with multiple FL baselines on Rotated MNIST, CIFAR-10 and CIFAR-100 datasets.",
            "strength_and_weaknesses": "Strengths:\n\n+ The paper is well-written. Key ideas are well-presented.\n+ The explanation of the model drift phenomenon under heterogeneous data setup is well put in three main causes all linked to the biased feature representation generated by local learning algorithm when client data are skewed.\n+ The key ideas follow quite naturally from the insightful interpretation of model drift.\n+ Overall, the motivation is clean & the idea is novel to me.\n\nWeaknesses:\n\n- The technical execution of the idea might not be practically feasible (although the formulation makes sense) -- more on this later\n- There is a complete lack of coverage on a very related suite of personalized FL algorithms specifically designed to deal with this issue\n- Not clear how much validation data is needed for this to work\n- Also, the validation (or pseudo) data obviously needs to be balanced -- how do we ensure that if the design of such validation data comes from random or aggregated sample of local data?",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty & Quality:\n\nThe idea is quite novel to me but I have reservations concerning its practical feasibility, mainly described in two points below:\n\n+ First, given the pseudo data is devised to be either aggregation of local samples or local samples themselves, I am not sure this method is privacy compliance. In practical setting, sending authentic data to a 3rd party is always a problematic practice; even sending aggregated (but un-sanitized) data to untrusted parties is not allowed because it would still be vulnerable to differential privacy attack and has to be avoided. While I understand that privacy preservation on the algorithmic level is not the focus here but the setting here seem to not even be privacy compliant -- I think the authors should probably discuss this at length to make it clear if this proposal is practically viable.\n\n+ Secondly, how much validation data is needed for the algorithm to work as intended? I imagine such dataset needs to be balanced in terms of label distribution but how do we guarantee that if it has to come from local samples of clients with skewed label distributions? There should also be experiments plotting the effectiveness of the proposed method vs the amount of validation (pseudo) data.\n\nFurthermore, as stated above, there is a lack of coverage & comparison with the existing literature on personalized federated learning, which is meant to address the same problem. In fact, even the prior work of (Yurochkin, 2019) also has a natural mechanism (via probabilistic modeling) that is less affected by the heterogeneous distribution of data across clients. The authors should consider with such method too. Their code is also publicly released.\n\nClarity:\n\nThe paper is mostly well-written but some algorithmic detail appear to be a bit vague & there is -- see my second point in the Quality & Novelty section. In addition, how do we decide the hyper-parameters of the proposed algorithm -- see Eq. (3) \n\nFrom Eq. (2) and (3), I am curious why phi_g is not part of the learnable parameters? Also, why is x_p \\sim D_i in Eq. (3)? Are those typos?\n\nReproducibility:\n\nThe experimental code is released so I believe this work is reproducible.",
            "summary_of_the_review": "This paper introduces a new idea to FL with heterogeneous client data. The idea is new and somewhat interesting but I have concerns regarding its practical feasibility, privacy compliance. I notice that there is also a lack of coverage over a very related FL literature that addresses the same issue. Certain aspects of the proposed algorithm have also not been discussed at necessary length (see my specific comments above). ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_p1f4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_p1f4"
        ]
    },
    {
        "id": "ckb6ScaNTp",
        "original": null,
        "number": 3,
        "cdate": 1666611664424,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666611664424,
        "tmdate": 1666611664424,
        "tddate": null,
        "forum": "m_thN8e6qrF",
        "replyto": "m_thN8e6qrF",
        "invitation": "ICLR.cc/2023/Conference/Paper3756/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on federated learning with heterogeneous data. Specifically, this paper identifies the negative effects of learning with heterogeneous in the federated framework from a representation learning perspective, which is termed local learning bias in its discussion and analysis. To handle with that challenge, the authors propose FedDebias, to reduce the local learning bias on features and classifiers. They conducted various experiments to verify the effectiveness of the proposed method and claimed FedDebias had outperformed other SOTA FL and domain generalization baselines.",
            "strength_and_weaknesses": "Strength:\n1. The focused general problem, i.e., federated learning with heterogeneous data, is significant for federated learning and is very practical.\n2. This paper provides further analysis of the pessimistic from learning with heterogeneous data, which are being unable to classify unseen data, local features differ from global features, and local features cannot be accurately distinguished.\n3. The proposed FedDebias shows empirical effectiveness in the experiments.\n\nWeaknesses:\n1. The motivation of the proposed methods seems to be based on the illustration (e.g., Figure 1), it lacks the empirical justification or some related reference to the direct evidence which can support the existence of the raised issues. Could the author provide more quantitative results to describe the issues, like measuring the local learning bias by some metrics?\n2. The three identified \"pitfalls of FL\" in this paper have been explored or discussed in previous FL literature [1-3], like FedProx, Scaffold, or Moon, which tackle the heterogeneity via analyzing the local client drift or feature level information and proposed corresponding methods. Except for the empirical superiority than previous methods in the experiments (e.g., Table 1), could the author discuss more about the uniqueness of the three identified pitfalls? \n3. It is unclear why to consider the domain generalization baseline here. The presentation of the current version is also a little bit confusing as the conventional work in learning with heterogeneity data assumed non-iid data partition for training while keeping the test set unchanged. It is hard to analyze since here the contains two research problems, e.g., federated learning with heterogeneity data and domain generalization, and the proposed methods seem to have superimposed effects on tackling each problem. It could be better if the authors could provide clear and rigorous problem setups in the preliminary (maybe at the beginning of Section 3 or somewhere). This may help to improve the presentation.\n4. For the experiments, considering the sensitivity of data partition, could the authors also report the std value in some parts of the experimental results? For the experiment parts, more advanced algorithms in both FL and DG are encouraged to compare, e.g., Scaffold, FedNova, IRM, and VREx, if they are applicable. Since none of the current baseline methods has considered both subproblems. \n\nOther question/comment:\n1. It seems to be a typo at the beginning of the 3rd paragraph of Appendix A: \"domain generation\" -> \"domain generalization\".\n2. The overall presentation of the current version seems to be a little confusing as the tackled problem is both conventional FL with heterogeneous data and FL with domain generalization. It may be better if the author could clarify more about the rigorous problem definition before analysis. \n3. It could be better if this work can has some further theoretical analysis about the debiasing effect since section 3 has introduced the definition of local learning bias.\n4. Could the authors further discuss the difference between the local bias analyzed in Scaffold with the proposed \"local learning bias\"?\n\n[1] Li, Tian, et al. \"Federated optimization in heterogeneous networks.\" Proceedings of Machine Learning and Systems 2 (2020): 429-450.\n[2] Karimireddy, Sai Praneeth, et al. \"Scaffold: Stochastic controlled averaging for federated learning.\" International Conference on Machine Learning. PMLR, 2020.\n[3] Li, Qinbin, Bingsheng He, and Dawn Song. \"Model-contrastive federated learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nSome clarification about the problem setting and identified pitfalls of FL can be further added and improved, which is better to understand the empirical results of the proposed method and disentangle the advantages of the introduced components.\n\nQuality:\nThe technical quality of this work is impressive, but the observations and definitions could be further enhanced by adding some quantitative measures or theoretical analysis.\n\nNovelty:\nThis work proposed FedDebias, which applies two key de-bias steps in a min-max approach, is technically a new framework considering the existing literature for me.\n\nReproducibility:\nThe authors have provided the source code of this paper, which guarantees reproducibility with the detailed experimental setting description.",
            "summary_of_the_review": "In summary, this paper proposed FedDebias to tackle learning with heterogeneous data. The presentation of the current version is encouraged to improve by making the focused problem setting clearer and adding more discussion except for the empirical effectiveness. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_14m7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_14m7"
        ]
    },
    {
        "id": "SEIybJVHBpv",
        "original": null,
        "number": 4,
        "cdate": 1666847640165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666847640165,
        "tmdate": 1666847640165,
        "tddate": null,
        "forum": "m_thN8e6qrF",
        "replyto": "m_thN8e6qrF",
        "invitation": "ICLR.cc/2023/Conference/Paper3756/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "- This paper proposes two techniques to alleviate the biased local update due to the data heterogeneity across the clients: 1) generating pseudo data by simply averaging a subset of data and regularizing the local model not to be biased toward skewed classes, 2) employing contrastive loss that facilitates close representation between global model and local model for the same classes, while simultaneously enforcing discriminative representation for different classes.\n- Experiments on multiple image classification benchmarks validate the effectiveness of the proposed method over SOTA federated learning and domain generalization algorithms.",
            "strength_and_weaknesses": "### Strong points\n\n- Experimental results show non-trivial accuracy gain.\n- The idea of enforcing high similarity between the global features of pseudo data and the local features of pseudo data is interesting. Also, using an adversarial projection layer to facilitate effective representation learning by the proposed contrastive loss is also straightforward.\n\n### Weak points\n\n- Toy experiments in Section 3 are not precise enough, so the results in the toy experiments may not support the claims (observations)\n    - In Figure 2, the authors plot t-SNE for two independently trained models. Even if we train two deep models with the same data, simply a different initialization can result in different representations. Since the two models are trained with different data distributions, it is not surprising that there are distinct clusters for two independent models. In my opinion, the local model should be fine-tuned from the global model with the local data and observe the representation trends.\n    - In a similar vein, the small scope of the local features for both seen and unseen classes is also not surprising since the 5-way classification problem is much easier than the 10-way classification.\n- Observation in Figure 3 is a widely known problem in existing works in continual learning.\n- For the construction of the pseudo-data, setting gt as $1/C$ may be the abuse of the prior knowledge of evaluation datasets since CIFAR10, CIFAR100, and MNIST have balanced data over classes.\n\n\n### Questions\n\n- Why the accuracy of FedDebias in Table 1 is different from the accuracy in Table 2??",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity and quality: Writing is clear and easy to follow, but the statements are not supported well by empirical or theoretical evidence.\n- Novelty: The idea of using RSM is not novel but the contrastive loss using the RSM is novel.",
            "summary_of_the_review": "At this point, this paper is borderline reject. While This paper is well-written and easy to follow. The objective of this work is clear, but the experiments are hard to understand and not convincing to support the main contribution.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_UkVs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3756/Reviewer_UkVs"
        ]
    }
]