[
    {
        "id": "yKuUnyQWRmg",
        "original": null,
        "number": 1,
        "cdate": 1666586701479,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666586701479,
        "tmdate": 1666586701479,
        "tddate": null,
        "forum": "05ff9BRSMzE",
        "replyto": "05ff9BRSMzE",
        "invitation": "ICLR.cc/2023/Conference/Paper6358/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied extreme multi-label classification problems where labels short text descriptions are available. The author proposed Gandalf, a data-augmentation technique that augmented the label text as input data, and used the label correlation graph as its soft-labels. The proposed Gandalf technique was applied to various XMC models, and showed consistent improvement on four XMC benchmarks.",
            "strength_and_weaknesses": "*Strength*\n- The data augmentation techniques (Gandalf and LabelMix) are novel in XMC\n- Promising performance gain\n\n*Weaknesses*\n- Lack of ablation study to back the effectiveness of certain component in Gandalf",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The writing is clear\n- Novelty: The idea of data augmentations are novel for XMC community\n- Reproducibility: No code provided, hence no data point to verify the reproducibility\n",
            "summary_of_the_review": "This work presented two novel data augmentation techniques, Gandalf and LabelMix, for the XMC problems. When applied to various downstream XMC  models, both Gandalf and LabelMix demonstrated consistent improvement over the baseline. Overall writing and presentation also are clear to follow.\n\nThe paper quality can be improved if the following technique questions are addressed.\n- Choice of label-to-label graph: Gandalf with Co-occurrence graph instead of LCG?\n- Sensitivity of hyper-parameters such as delta in Algo 1 and the design choice of y_tilde in Eq(9) versus Eq(8).\n- Does Gandalf enjoys larger performance gain on tail labels (e.g., label count < 5)? Can you plot the performance gain in y-axis, and the groups of label freq in x-axis?\n- I suppose Gandalf and LabelMix are complementary to each other? Can we apply both?\n- Can you apply Gandalf/LabelMix to two-tower models (e.g., DPR/ANCE) and do the evaluation on both XMC and IR benchmark datasets?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_xmDr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_xmDr"
        ]
    },
    {
        "id": "8K_Z0gGIzN",
        "original": null,
        "number": 2,
        "cdate": 1666692768659,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692768659,
        "tmdate": 1666717780112,
        "tddate": null,
        "forum": "05ff9BRSMzE",
        "replyto": "05ff9BRSMzE",
        "invitation": "ICLR.cc/2023/Conference/Paper6358/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors propose to conduct graph induction for data augmentation for extreme classification based on label features. Specifically, they capture label-label correlations based on a label-correlation graph and use label features as data points. They also leverage label features to have query-label interpolation and then sample labels for mixing up augmented labels. The experiments based on four extreme classification benchmarks with label features demonstrate that the proposed method can enhance some extreme classification models. ",
            "strength_and_weaknesses": " Strengths\n* Simple and effective approaches that potentially can apply to arbitrary methods.\n* Publicly available benchmark datasets for reproducibility.\n\nWeaknesses\n* The authors \u201cpropose\u201d LabelMix as a method as the \u201cbaseline\u201d, but the more authentic approach should be to compare with published state-of-the-art works in data augmentation for XMC tasks.\n* Experiments only cover datasets with only short text (i.e., titles), which are comparatively limited in the real-world settings. The authors should consider conducting experiments on more comprehensive datasets with general information, such as LF-Amazon-131K, LF-WikiSeeAlso-320K, and LF-Wikipedia-500K.\n* Although the proposed techniques are potentially able to be applied to arbitrary methods, some methods like AttentionXML, XR-Transformer, and SiameseXML++ are not experimented with either LabelMix or Gandalf. Especially when vanilla XR-Transformer and SiameseXML++ outperform LabelMix and Gandalf in certain cases, I cannot see why the authors do not demonstrate that the proposed techniques can further improve the best performance.\n* The proposed techniques require label features, but in real-world settings, it usually lacks label features. \n",
            "clarity,_quality,_novelty_and_reproducibility": "* For clarity, the paper needs to be polished, especially for the organization. The flow is not easy to follow, especially in the part \u201cproposing the baseline LabelMix\u201d. \n* The idea is interesting and kind-of novel, but the technical quality of experiments are unsatisfactory.\n* For reproducibility, the authors provide some implementation details.\n",
            "summary_of_the_review": "In sum, I would recommend \u201c3: reject, not good enough\u201d as there are so many flaws in the experiments.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "I found the paper is still concurrently under review in ACL ARR https://openreview.net/forum?id=hPG9DW8shI",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_k6DK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_k6DK"
        ]
    },
    {
        "id": "MvhPVXBsAJ",
        "original": null,
        "number": 3,
        "cdate": 1666717373071,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666717373071,
        "tmdate": 1666717373071,
        "tddate": null,
        "forum": "05ff9BRSMzE",
        "replyto": "05ff9BRSMzE",
        "invitation": "ICLR.cc/2023/Conference/Paper6358/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper present two data augmentation strategies, Gandalf and LabelMix, that adds label features or the instance-label interpolations as training instances in extreme multi-label classification (XMC) training. Empirical results show that the proposed Gandalf method is able improve the performance of various XMC models on the benchmark dataset where label features are present.",
            "strength_and_weaknesses": "**Strength**\n\n* The proposed method Gandalf shows relatively large improvement over 5 XMC models across 4 different XMC-LF dataset.\n\n**Weaknesses**\n\n* The proposed method, Gandalf, is rather straightforward. The core idea seems to be just applying normalization and some thresholding on top of the LCG constructed in ECLARE.\n* It is not clear to me how the Gandalf and LabelMix are related to each other. They seem to be two independent data augmentation tricks and I failed to see the necessity in introducing LabelMix in this paper.\n* In Section the authors claim that LCG is better than Label co-occurrence matrix but both are not as good as Gandalf which adopts a heuristic thresholding after row-wise normalization. However, I didn't see any empirical study that compares these three settings. It would be more convincing if there are some label-to-label augmentation baselines in the comparison.\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well presented and easy to follow. However, as mentioned above, the main method is a straightforward extension of existing work thus the novelty is limited. I have no concerns for reproducibility as long as the authors plan to release the code.",
            "summary_of_the_review": "The paper present two independent data augmentation tricks for the XMC-LF applications. Apart from the limited novelty concerns mentioned above, I think the topic of this paper is more related to a data mining venue rather than ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_g2YZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_g2YZ"
        ]
    },
    {
        "id": "q3WpWEMK9H",
        "original": null,
        "number": 4,
        "cdate": 1666751879631,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666751879631,
        "tmdate": 1670816748640,
        "tddate": null,
        "forum": "05ff9BRSMzE",
        "replyto": "05ff9BRSMzE",
        "invitation": "ICLR.cc/2023/Conference/Paper6358/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Extreme classification (or deep information retrieval) has been a popular research field that matches an input text (query) to a label that often is also a text. This paper focuses on a sub-field where both the input text and the label text are short. The proposed training algorithm is a data augmentation algorithm that generates similar examples to the observation based on the label to label similarities. Authors claim this new data augmentation technique was able to improve significantly on benchmark datasets.\n",
            "strength_and_weaknesses": "**Strength**\n* Since Gandalf is a pure data augmentation technique that can be applied to some set of algorithms easily. (however, it\u2019s a bit arguable for some other sets of algorithms that can do similar techniques more organically. see weakness #1).\n* Authors try to set up a reasonable data-augmentation baseline, LabelMix, influenced by the popular \u201cMix-up\u201d technique.\n\n**Weakness**\n* Selecting k most confusing examples via label similarities is not novel. It is sometimes called \u201chard-negatives\u201d that is widely adopted in this field (for example, DPR [1], RocketQA [2] and ANCE [3]). The main difference is to use dense label space or to use the label relationship graph (they are quite interchangeable, but the dense space has nicer properties). It is also partially observed in Table 3 as using the soft-labels from the label graph further drastically increases the performance over hard labels.\n* Defining the label graph solely based on the label co-occurrences might have its limitations because it does not use any textual understanding of each label. Commonly, the dense label space is trained jointly with the actual retrieval task [1,2,3] and hence captures deeper understanding of the label to label similarities based on both bipartite co-occurrence relationships and textual understanding. Moreover, solely depending on co-occurrence relationships can be very noisy when we have large label space (e.g. thousands of millions or billions).\n* The work was not evaluated against common dense retrieval algorithms such as [1,2,3].\n\n[1] Karpukhin, Vladimir, et al. \"Dense passage retrieval for open-domain question answering.\" arXiv preprint arXiv:2004.04906 (2020).\n[2] Qu, Yingqi, et al. \"RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering.\" arXiv preprint arXiv:2010.08191 (2020).\n[3] Xiong, Lee, et al. \"Approximate nearest neighbor negative contrastive learning for dense text retrieval.\" arXiv preprint arXiv:2007.00808 (2020).\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n* The paper can be improved on their clarity on how their proposal is presented. It is quite unclear how the actual training objectives are defined (e.g. loss functions) and how the newly generated examples are integrated into the objective.\n* Algorithm 1 should be written in pseudo-code for those who do not have prior Python knowledge.\n",
            "summary_of_the_review": "The paper does not convey a significant novelty in this field and was not sufficiently compared to many core techniques in this field.\n\n-----\nPost rebuttal response:\n\nI thank authors to provide detailed feedback. I also read other reviewers' feedback and concluded this paper does require further development to contain further contribution in this field. I still concerns the novelty of this paper (similar to Reviewer g2YZ).\n\nHere are some detailed points that the author replied.\n\n> Gandalf is only a method to leverage Label-Text/Features as data points whose ground truth labels are unknown.\n\nThis actually limits the novelty of the method. Gandalf's novelty is limited in introducing a heuristic method to generate additional labels. \n\n> Contrast to Hard Negative Mining \n\nThanks for the detailed description. I wonder then what's the actual benefit of using Galdalf's soft-labels. We often found strong negatives that are closer to the decision boundary helps achieving more discriminative models especially when the label space is large (XMC). Wouldn't it be more beneficial Galdalf to focus on closer but not positive labels?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_qcbk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6358/Reviewer_qcbk"
        ]
    }
]