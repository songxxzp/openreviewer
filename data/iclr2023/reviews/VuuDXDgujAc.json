[
    {
        "id": "7N2-3yAIeof",
        "original": null,
        "number": 1,
        "cdate": 1666471324963,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666471324963,
        "tmdate": 1666471324963,
        "tddate": null,
        "forum": "VuuDXDgujAc",
        "replyto": "VuuDXDgujAc",
        "invitation": "ICLR.cc/2023/Conference/Paper4737/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies option learning in RL, and introduces a new framework (HiT-MDP). The authors prove that HiT-MDP is homomorphic equivalent to the standard SMDP formulation, and derive an on-policy policy gradient method with the new HiT-MDP formulation. On Mujuco environments, the proposed method is shown to be effective, exhibit smaller faster convergence and enjoy better interpretability.",
            "strength_and_weaknesses": "Strength:\n* The writing is in general clear.\n* The introduced HiT-MDP formulation is novel.\n\nQuestions:\n* Can the authors provide more visualizations of the learned options?\n* From Figure 6, it seems only 2 out of 4 options are useful. Is it because the environment is relatively simple? Does more complex environments (e.g. Humanoid) result in more options?\n* Can the authors conduct similar analysis (as in Figure 5,6) for other environments, such as Humanoid or Hopper?\n* How will the proposed method work in video games like Atari or Procgen? Can it learn some interesting options?\n\nMinor issues:\n* Please consider increasing the font size in Figure 1, 2, 5 and 6.",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: Mostly good.\n* Quality and Novelty: The quality of this paper is pretty good and the proposed HiT-MDP is novel.\n* Reproducibility: The source code is provided. I would assume the results are reproducible.",
            "summary_of_the_review": "In summary, this paper introduces a new HiT-MDP framework for option learning in RL. Based on HiT-MDP, the authors derive a policy gradient method and validate its effectiveness and advantages over exiting methods on Mujoco.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_CFgS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_CFgS"
        ]
    },
    {
        "id": "rLwa0JEOW_t",
        "original": null,
        "number": 2,
        "cdate": 1666620125741,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620125741,
        "tmdate": 1666620125741,
        "tddate": null,
        "forum": "VuuDXDgujAc",
        "replyto": "VuuDXDgujAc",
        "invitation": "ICLR.cc/2023/Conference/Paper4737/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel  Markov Decision Process (MDP),  namely, the Hidden Temporal MDP  (HiT-MDP), to solve the semi-Markov\ndecision process that is unstable, unoptimizable, and inefficient in sampling ,and proves that the option-induced HiT-MDP is homomorphic \nequivalent to the option-induced SMDP. Then an efficient algorithm based on structured mutation reasoning is derived, which leads to a new \nmethod of finding stable options under the maximum entropy reinforcement learning framework. Finally, HiT-MDP shows excellent performance in a wide range of configurations.",
            "strength_and_weaknesses": "Pros:\nThe paper is very well motivated. The authors precisely present the shortcomings of the current standard option framework based on semi-Markovian decision processes and propose a new HIT-MDP that addresses the shortcomings of the original framework one by \none. It is also very clearly formulated. The arguments are clear, the derivation of formulas is rigorous. Even the lengthy appendix is fairly easy to parse, with straightforward proofs and relevant details. The most commendable thing is that the author has an innovative spirit. This paper is the first to propose an MDP equivalent to SMDP-Option, which provides reference and guidance for subsequent further research.\n\nCons:\nThe related work section is placed after the experimental section and before the conclusion and is somewhat abbreviated.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: The paper presents the first HIT-MDP and fully demonstrates the superiority of the framework over the traditional standard option \nframework with rich and detailed experiments of high quality.\n \nClarity: This work follows the process of posing an existing problem, analyzing the problem, constructing a method to solve it, and performing a formula derivation to prove the effectiveness of the strategy. The exposition is well organized, the proof process is rigorous and scientific, and the derivation of formulas is detailed and convincing. The paper is illustrated with pictures where appropriate, and the premises and details of each formula are explained.\n \nNovelty: The author's design is clever, the exposition is rigorous, and the content is original.\n",
            "summary_of_the_review": "I think this is a good paper with solid theoretical analysis and contributions, the problems analyzed are very important, the proposed \narchitecture is feasible, the proof process is complete, and needs to be understood as deeply as this work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_uUrN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_uUrN"
        ]
    },
    {
        "id": "w16vNf1PNL7",
        "original": null,
        "number": 3,
        "cdate": 1666658545725,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666658545725,
        "tmdate": 1667178149162,
        "tddate": null,
        "forum": "VuuDXDgujAc",
        "replyto": "VuuDXDgujAc",
        "invitation": "ICLR.cc/2023/Conference/Paper4737/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Mostly survey, not clear what the contribution is. The submission considers option RL. The major challenges the submission tackles is (1) the poor sample efficiency and (2) hard optimization for such a problem. The authors argue that the cause of the two challenges is the semi-MDP framework of existing option RL methods. Therefore, to deal with this issue, the submission reformulates the option RL problem into an HMM. Therefore, RL methods for HMM can be leveraged to deal with the two challenges in option RL.\n\nBoth theoretical and empirical results are provided supporting the proposed method. \n",
            "strength_and_weaknesses": "Hard to learn from the survey. No applications discussed.\n\nStrength \n\nThe submission is well motivated, focusing on two key challenges in option RL. \n\nA novel formulation of option RL is proposed, which facilitates new option RL methods.\n\nThe results provided by the submission are thorough and complete, with both theoretical and empirical support for the methodology. \n\nWeaknesses\n\nIt is not very clear to me why the proposed new formulation and methodology can have a better sample complexity than existing ones. At the beginning, the authors state that the reason for the poor sample complexity of option RL is that one option lasts for multiple steps, which wastes observations. However, this is also true under the proposed HiT-MDP formulation: in each time step, there is a high probability that the option stays the same as the previous step. Both formulations have strong probabilities to maintain the selected option for multiple steps. So, why is the proposed one more sample efficient? \n\nWould it be possible for authors to provide the option change frequency of each method in experiments? In experiments, the proposed method shows better sample complexity than existing ones. I am wondering whether this is because the proposed method changes options more frequently than the competing ones? If so, can we just manually increase the option switch frequency of existing methods to achieve similar sample complexity gain? \n",
            "clarity,_quality,_novelty_and_reproducibility": "OK writing.",
            "summary_of_the_review": "It's a survey paper with citations permeating through sections 6 and 7.\nThe submission proposes both novel formulation and novel methodology for option RL. Both theoretical and synthetic results are provided supporting the proposed method. However, I am not quite sure why the proposed method and formulation are able to provide such performance improvement. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_ySTp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_ySTp"
        ]
    },
    {
        "id": "LM5RLZNE9ue",
        "original": null,
        "number": 4,
        "cdate": 1667240681204,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667240681204,
        "tmdate": 1667240681204,
        "tddate": null,
        "forum": "VuuDXDgujAc",
        "replyto": "VuuDXDgujAc",
        "invitation": "ICLR.cc/2023/Conference/Paper4737/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to solve Semi-Markov decision processes (SMDP) by reformulating the SMDP into an ordinary MDP. In particular, the authors propose a novel MDP view of SMDP that models the options as part of the states and actions, leading to the definition of several option-value functions. The authors propose to utilize an energy-based parameterization in the transition model, which results in an entropy regularizer term in policy optimization. The authors further solve such policy optimization problems by policy gradient and propose the MOPG algorithm for solving SMDPs. Finally, the authors conduct several experiments on the MuJuCo environment and compare MOPG with several SOTA algorithms.",
            "strength_and_weaknesses": "$\\textbf{Strength:}$\nThe authors propose a novel MDP view of SMDP that models the options as part of the states and actions, leading to the definition of several option-value functions. The proposed MDP model can potentially extend various existing RL algorithms that solve MDP to the SMDP problem setup.\n\n$\\textbf{Weaknesses and Questions:}$\n\n- How does MOPG compare with Attention Option-Critic [1], which also uses attention network to encode option?\n\n\n- The theory is not sufficient for me. There is no proof or discussion on the convergence or sample efficiency of MOPG. The equivalence between SMDP and MDP could be more significant if authors can provide such type of analyses.\n\n- The contribution is limited, as the proposed MOPG still falls in the well-established PPO framework, and similar architecture was explored before in [1]. \n\n[1] Chunduru and Precup. Attention Option-Critic. (2022).\n",
            "clarity,_quality,_novelty_and_reproducibility": "See questions above. Implementation details are shared but the code is not released. Typo in p6: dynamix -> dynamics",
            "summary_of_the_review": "The idea is interesting, but the contribution is marginal to me.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_iC2w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4737/Reviewer_iC2w"
        ]
    }
]