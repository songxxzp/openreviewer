[
    {
        "id": "lvAewSXiXT",
        "original": null,
        "number": 1,
        "cdate": 1666053678800,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666053678800,
        "tmdate": 1670533436788,
        "tddate": null,
        "forum": "y4uc4NtTWaq",
        "replyto": "y4uc4NtTWaq",
        "invitation": "ICLR.cc/2023/Conference/Paper3920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes Cropshift, a new data augmentation to improve the robustness and accuracy of adversarial training. The design is based on the empirical findings that diversity matters and hardness can boost robustness at the cost of accuracy.",
            "strength_and_weaknesses": "Strength\n+ Compelling experimental results. The increase in accuracy and robustness is significant.\n+ The proposed method would be easy to implement with (promised) available codes.\n\nWeakness\n+ Although it is clear that the hardness of a data augmentation method is measured by the robustness difference between the augmented model and the unaugmented one, it is unclear how it is controlled, e.g., to 7 different levels as the paper states. Is increasing hardness achieved by changing the strength of augmentation?\n+ The idea of jointly handling hardness and diversity is not novel, which has been extensively studied in normal training [1]. Extending it to adversarial training seems incremental to me. Besides, the title looks close to [2].\n+ It is claimed that \u201cThe probability and the strength of each layer (augmentation strategy) was jointly optimized by a heuristic search to maximize the robustness.\u201d But the details of the heuristic search have not been illustrated. In this regard, it is unclear how the method optimizes the strength.\n\n[1] AugMax: Adversarial Composition of Random Augmentations for Robust Training, NeurIPS 2021.\n\n[2] Data augmentation can improve robustness, NeurIPS 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "See Strength And Weaknesses.",
            "summary_of_the_review": "The method achieves great results, but the paper fails to illustrate important parts of the underlying mechanism.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_4eAk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_4eAk"
        ]
    },
    {
        "id": "oIzh9hz3Ux",
        "original": null,
        "number": 2,
        "cdate": 1666580843789,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666580843789,
        "tmdate": 1666580843789,
        "tddate": null,
        "forum": "y4uc4NtTWaq",
        "replyto": "y4uc4NtTWaq",
        "invitation": "ICLR.cc/2023/Conference/Paper3920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work demonstrates that data augmentation alone can alleviate robust overfitting.\nThe authors investigate what factors contribute to the robustness and point out that the hardness and diversity of the augmentation significantly influence the robustness and accuracy.\nThey propose a new image transformation method Cropshift and claimed to be more diverse compared to conventional methods.\nBased on Cropshift, IDBH, a 4-layer image augmentation scheme is proposed and achieved SOTA performance and boosts a lot compared to previous data augmentation methods.\n",
            "strength_and_weaknesses": "Strength\n1. A novel finding that data augmentation alone could alleviate robust overfitting\n2. This work also investigates when data augmentation help and proposes a promising data augmentation to improve model adversarial robustness\n\nWeakness\n1. IDBH is also comparable to Regularization methods in terms of improving model robustness. It is interesting to also study whether the proposed data augmentation can be combined with regularization to further improve model robustness.\n2. The presentation remains to be improved. What is 'end accuracy'? When it can be lower/higher than 'best accuracy' in Tab. 1?\n3. The main evaluation is conducted with PGD10. Does the PGD attack converge with 10 steps on the applied dataset and models?\n4. In Tab. 3, the author aims to demonstrate that the proposed method works well across different datasets. However, some of the strong baselines in Table 2 are removed. Are there specific reasons behind this?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the presentation remains to be improved. Although the proposed solution is not significantly novel, the findings presented in the analysis section are insightful to the community.",
            "summary_of_the_review": "Given the significance of the insights provided in this work, I tend to weak accept this work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_qfhi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_qfhi"
        ]
    },
    {
        "id": "59JBvVV4P4",
        "original": null,
        "number": 3,
        "cdate": 1666615761238,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615761238,
        "tmdate": 1666615761238,
        "tddate": null,
        "forum": "y4uc4NtTWaq",
        "replyto": "y4uc4NtTWaq",
        "invitation": "ICLR.cc/2023/Conference/Paper3920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies adversarial training in the context of image classification. The authors show that data augmentation alone can improve robustness. In the previous literature, works showed that augmentation needed to be combined with other components in order to improve performance. The authors propose a new crop transformation called Cropshift which improve robust performance.",
            "strength_and_weaknesses": "Strength:\n1) Claims are well motivated with a thorough study based on hardness and diversity. The story is quite clear with data augmentations which should be adapted to the capacity of the model.\n2) The introduced data augmentation is tailored for robustness and gives indeed a significant boost in performance.\n3) Thorough experiments with many ablation studies.\n\nWeakness:\n1) Cropshift works well with CIFAR, SVHN and TinyImageNet but datasets with larger images such as ImageNet typically benefit from other types of data augmentations than small datasets. So it is not sure that Cropshift would be helpful in that case.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, novel and seems possible to reproduce.",
            "summary_of_the_review": "The idea of proposing a new data augmentation specially designed for robustness is novel and an interesting research direction. The authors provide extensive experiments to support their claims and give an interesting analysis frame with the hardness and diversity study.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_5354"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_5354"
        ]
    },
    {
        "id": "a-EyNvlMsm",
        "original": null,
        "number": 4,
        "cdate": 1666905165517,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666905165517,
        "tmdate": 1668704650605,
        "tddate": null,
        "forum": "y4uc4NtTWaq",
        "replyto": "y4uc4NtTWaq",
        "invitation": "ICLR.cc/2023/Conference/Paper3920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work aims to address the robust overfitting issue in adversarial training by using data augmentations. Prior works have shown that adversarial training does not benefit from augmentations such as AutoAugment. The authors firstly study the role of hardness and diversity of augmentations in robustness and accuracy, and find that diversity improves both, while increasing hardness can improve robustness at the cost of clean accuracy initially and later degrades both. To improve diversity, the authors propose a new augmentation Cropshift, and further use this in the proposed augmentation pipeline - Improved Diversity and Balanced Hardness (IDBH) which has better diversity and well-balanced hardness. \n",
            "strength_and_weaknesses": "Strengths - \n- The analysis on the impact of increasing hardness and diversity of augmentations is insightful. \n- The proposed method shows good improvements on PreActResNet-18 when compared to baselines. \n- The authors perform a more robust evaluation of prior work by Tack et al., and show that their claim of superior robustness using AutoAugment is incorrect. \n\nWeaknesses -\n- As the authors mention, the selection of augmentations is currently a bottleneck, which makes it impractical to use, due to the requirement of manually finding the best set of augmentations. Even using strategies like the one used in AutoAugment is expensive due to the large search space. \n- WideResNet-34 results seem to be much lower than the expected results [1]. Moreover, it is unclear why this is even lower than the results of PreAct-ResNet-18. \n- It is unclear why increasing hardness degrades clean accuracy and improves robust accuracy. If the model capacity is insufficient for learning benign samples, it should be harder to learn adversarial samples. Moreover, the argument of robust generalization can also hold for standard generalization. \n\nSuggestions - \n-  This seems a bit confusing and different from the algorithm - \"Cropshift first randomly crops a region in the image and then shifts it around to a random location in the input space.\" - could be rephrased.\n\n\n[1] Pang et al., Bag of Tricks for Adversarial Training",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well-written. The novel aspects are - understanding the impact of hardness and diversity of augmentations in adversarial training, designing Cropshift for better diversity, and the IDBH augmentation pipeline. ",
            "summary_of_the_review": "Although there are several novel and interesting aspects in the paper as mentioned above, the results of baselines and proposed approach are suboptimal for WideResNet-34 when compared to prior works. \n\n**Post-Rebuttal comments:** I thank the authors for their response which addresses many of my concerns. I suggest the authors include the explanation of - \"why increasing hardness degrades clean accuracy and improves robust accuracy\" in the paper as well, specifically the clarification that, \"model capacity is insufficient to fit benign samples under a stronger regularization from adversarial training caused by increasing hardness\". \n\nClarification on the suggestion -  Based on my understanding of the algorithm, the explanation can be updated to \"Cropshift first randomly crops a region in the image and then places it at a random location on a new blank image.\"\n\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_KVU6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3920/Reviewer_KVU6"
        ]
    }
]