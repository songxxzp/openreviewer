[
    {
        "id": "1q0AMHIii9y",
        "original": null,
        "number": 1,
        "cdate": 1666103229818,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666103229818,
        "tmdate": 1666103229818,
        "tddate": null,
        "forum": "sO1QiAftQFv",
        "replyto": "sO1QiAftQFv",
        "invitation": "ICLR.cc/2023/Conference/Paper2473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In the proposed work, the authors present E3bind, an fully-equivariant and differentiable approach for protein-ligand docking. Similar works have recently become available in the literature, the claimed advantage of the presented one being that it iteratively docks the ligand into a (possibly unknown) protein binding pocket.\n\nMost of the questions/issues for the authors are presented in the review summary section.",
            "strength_and_weaknesses": "Strengths:\n\n* Noticeable improvement over well-established benchmark\n\nWeaknesses:\n* Motivation for the architecture somewhat lacking\n* Incremental work\n* Manuscript feels rushed and reads clunkily at times\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Overall, the writing of the paper feels rushed and could use from further rewriting and language editing, as it reads very clunkily (and informal) at times.\n\nNovelty: The proposed model deserves merit, but it is somewhat incremental, especially when considering other very similar approaches such as EquiBind. Many of the base ideas of iteratively updating coordinates using the EGNN model are borrowed from the aforementioned study, albeit it is used differently.\n\nReproducibility: The authors do not provide any accompanying code with this submission, complicating potential replication of the results.",
            "summary_of_the_review": "Overall, while this is very solid work and deserves to be published, I believe it needs further work, as many of the parts feel rushed. I would have also enjoyed if the authors had provided code to back up the claims supported in the study and for overall reproducibility, as this is a field that is very rapidly advancing in the last couple of years. \n\n* In the introduction, the authors make a comparison to other methods that only output a \"scalar\" score. It should be noted that this is also the case for classical docking algorithms, whose scoring function also outputs a scalar for a specific pose. The amount of information provided is somewhat similar - I believe the comparison is not well defined here.\n* The claim on the introduction that the performance of Equibind is not strong enough needs further motivation, so as to claim that rapid generation of binding poses remains an unsolved problem.\n* On the Related Works section, there is a claim about Equibind failinf to beat popular docking baselines without finetuning which needs to be further justified/motivated.\n* Overall, figure captions on the manuscript could be heavily improved upon (within reasonable constraints of the page limit) as they are not descriptive at all.\n* In general, I think the reader would have benefited from further details about the Trioformer architecture, as it is mentioned without it being properly presented. Is this naming convention used in previous works?\n* In Section 3.1, the authors mention that they use only the carbon alpha atoms to represent the protein in the model. Was this choice made for computational efficiency issues, or did the authors compared against  a full-atom representation?\n* Why are the message passing networks of the protein (GVP-GNN) and ligand (GIN) chosen differently? There does not seem to be any motivation for this choice.\n* In section 3.3, the authors claim that the iterative refinement method allows the ligand to sense the local environment compared to the one-shot approaches, but no motivation behind this intuition is provided.\n* On the self-confidence prediction idea. The plot on Appendix Section C.2 seems to indicate that these scores are not very well aligned with ligand RMSD, as they tend to concentrate on the right-hand side of the distribution (most of them over 0.9). Could the authors consider providing an appropriate scaling as well as checking the pearson correlation between the score and rmsd?\n* In Section 3.4, is the loss only computed on predicted vs. experimental ligand coordinates?\n* In Section 3.4 (inference process), the authors mention that they use a binding site algorithm to first segment the protein into functional blocks. Are the other methods also making use of this step? Could this potentially bias the improvements shown in the results? How computationally expensive is this segmentation step - is it taken into account when computing the numbers provided in Appendix Section G? The authors also mention in this section that their model does not require binding affinity for training but this is usually never the case for docking tasks, so I do not understand why this is explicitly mentioned.\n* How is the ligand initialization done? The authors claim that it is randomly initialized in each segmented block before docking. Does this result in possible clashes with the protein target?\n* In terms of the performance on flexible self docking scenarios, it should be noted that that many standard docking pipelines (and not only GLIDE, as mentioned in the paper) actually outperform the DL-based alternatives.\n* On the \"benefit of iterative refinement\" section. How does the self-confidence score behave under non-successfully docked examples?\n\nOther notes:\n* Page 2: \n* Page 2: \"it's\" -> \"its\"\n* In the Geometry-aware pair updates section, why is the word \"neighboring\" under quotes?\n* Equations are missing commas and periods when appropriate.\n* Equation 10, the loss is missing equation number.\n* Is the \\sigma in the self-confidence prediction section a sigmoid function? \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_GTTE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_GTTE"
        ]
    },
    {
        "id": "p63q_9jgyJ",
        "original": null,
        "number": 2,
        "cdate": 1666619121473,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619121473,
        "tmdate": 1666619279356,
        "tddate": null,
        "forum": "sO1QiAftQFv",
        "replyto": "sO1QiAftQFv",
        "invitation": "ICLR.cc/2023/Conference/Paper2473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work tackles the problem of protein-ligand binding structure prediction. The authors propose an E(3) equivariant network to iteratively update the poses. Alphafold-inspired feature encoders are introduced to capture the information of proteins and ligands, respectively. The whole architecture is trained in an end2end fashion. The model could achieve state-of-the-art performance in both binding position prediction and binding affinity prediction tasks.\n",
            "strength_and_weaknesses": "Strengths:\n1. The proposed method addresses the two-stage optimization problem of previous work by performing coordinate iteration through a context-aware equivariant module, enabling end-to-end training.\n2. The paper is overall well-written and easy to follow.\n3. The proposed method shows superior empirical performance over existing baselines.\n\nWeaknesses and questions: \n\n1. The technical contributions should be further clarified. The architecture of this model is similar to the combination of Alphafold and TankBind. Although it solves the separated coordinate optimization problem of TankBind, the additional modules are mainly borrowed from Alphafold. The authors should elaborate more on their own contributions.\n2. It seems that pair embedding z_ij does not change during the iterative coordinate update. Is this on purpose or a compromise made because of computation cost?\n3. The authors could comment on why the performance on unseen protein is still worse than GLIDE as measured by RMSD <2\u00c5. Does this indicate that the model has poor generalization ability? Also, the performance gain over TankBind is not significant.\n4. There is a recent work DiffDock that can also iteratively generate poses. The authors may need to consider differentiation from DiffDock (https://arxiv.org/abs/2210.01776) or state the superiority of the proposed method.\n5. Binding affinity prediction is a key subtask for protein-ligand interaction prediction. Could this work perform affinity prediction and how?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good. The paper is overall well-written and organized. \n\nQuality: Excellent. The performed experiments are extensive.\n\nNovelty: Medium. The proposed method is based on existing methods. The key contribution is to integrate Alphafold with TankBind and address the problem of conformation refinement. \n\nReproducibility: Bad. No code is provided.\n",
            "summary_of_the_review": "Generally, I think it's a good paper. But the clarity of novelty should be improved and some of the results should be further explained. Also, no code has been released. I vote for a borderline acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_5skX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_5skX"
        ]
    },
    {
        "id": "OReat0GZx9S",
        "original": null,
        "number": 3,
        "cdate": 1666691881818,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666691881818,
        "tmdate": 1666691881818,
        "tddate": null,
        "forum": "sO1QiAftQFv",
        "replyto": "sO1QiAftQFv",
        "invitation": "ICLR.cc/2023/Conference/Paper2473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper describes a new method for molecular docking that uses equivariant neural networks. The positions of ligand atoms are refined in each step, and the per-atom translation is computed by DecoderLayer that uses equivariant graph convolution layers. The protein and ligand are encoded with graph neural networks and protein-ligand interactions are modeled by Trioformer, a transformer updating atom pair information based on triplets of atoms from both the protein and ligand. The model can be trained in the end-to-end manner. The presented results are competitive compared to the recent neural docking algorithms and the classical ones.",
            "strength_and_weaknesses": "Strengths:\n- The selection of graph neural networks for encoding the ligands and binding pockets is reasonable.\n- Trioformer is proposed to tackle the problem of preserving the geometry constraints when modeling atom pair embeddings.\n- I really like the self-confidence estimator that is trained along with the docking objective. Figure 2 clearly shows the benefits of this predictor.\n- The case study shows the usefulness of the proposed method in a real-life scenario.\n- An ablation study was conducted, where different components of the architecture were removed.\n- A quantitative evaluation of the improvement over multiple refinement steps is presented, as well as a qualitative refinement trajectory in the supplementary materials.\n\nWeaknesses:\n- Is Trioformer a new architecture that is introduced in this paper? This should be emphasized more, and the differences between Trioformer and former architectures (Evoformer, triangle attention) should be accentuated in my opinion.\n- In the problem definition paragraph, the naming of blind docking problems seems a little confusing to me. Is \u201cre-docking\u201d and \u201cself-docking\u201d used synonymously? If so, maybe the names \u201crigid blind self-docking\u201d and \u201cflexible blind self-docking\u201d would be better in this context?\n- The model does not have any formal constraints on the validity of the generated 3D structure. Atoms can move freely, and, although the shown structures look realistic, there is no guarantee that the resulting compounds are not knotted or do not include very long bonds. Can you provide a plot showing a distribution of bond lengths? Another interesting plot would be depiction of the number of invalid structures (steric clashes) as the number of refinement steps increases.\n- The code was not included in the submission, so it is difficult to assess the reproducibility of the experiments.\n\nQuestions:\n- How can you output rigid structures in the rigid docking experiment? According to the footnote on page 5, you start with the same conformation as the docked ligand structure, but do you change this conformation via per-atom position updates?\n- Only to confirm, is gradient detached from the RMSD term when training the self-confidence predictor? How do you select beta to achieve the best tradeoff between the docking performance and top pose selection?\n- In the experimental results, what corrections are applied to each model? Is the set of post-processing methods the same across different methods?\n\nMinor points:\n- Typos, e.g. \n\u201cwe achieves SOTA in most metrics\u201d -> \u201cwe achieve SOTA in most metrics\u201d\n\u201cFigure ??\u201d -> \u201cFigure 5\u201d\n\u201cprediction\u2019s\u201d -> \u201cpredictions\u201d\n\u201cuncorrcted\u201d -> \u201cuncorrected\u201d\n- Some references should be fixed, e.g. referencing Section B in Section 3.2 (it should be indicated that the appendix is referenced), referencing \u201cE\u201d in Section 4.2, and referencing Figures 5 and 7 that are not included in the main text body.\n- Section G of the Appendix should be referenced in Section 4.1, where there is a statement about superior inference speed - currently this feels like an unsupported claim.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** The paper is written in a clear way and easy to follow. The model description is supported by figures that show the model overview as well as atom pairing. Most of the experimental and implementation details are provided.\n\n**Quality.** The experimental results are convincing. The main results are supplemented by additional ablation experiments and plots. The selection of models in the benchmark is comprehensive and up-to-date.\n\n**Novelty.** The proposed model is another attempt at creating a neural-networks-based molecular docking algorithm. This is a relatively new branch of ML research that can accelerate drug discovery. The method demonstrates a different view on this problem as the atom position prediction is here formulated as a multi-step refinement procedure. It uses several novel methods for solving the system equivariance, including the proposed Trioformer architecture.\n\n**Reproducibility.** The code is not included in the supplementary material. The model description is clear, and the supplementary materials contain the algorithm pseudocode and implementation details, so it should be possible to reimplement the model. However, all implementation details can be difficult to recover without the source code because of the number of architecture elements. ",
            "summary_of_the_review": "Based on the above comments, I am leaning towards the acceptance of this paper if all the issues are addressed by the authors.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_eHD3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_eHD3"
        ]
    },
    {
        "id": "rmazTe_AFoQ",
        "original": null,
        "number": 4,
        "cdate": 1667200098747,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667200098747,
        "tmdate": 1667201844165,
        "tddate": null,
        "forum": "sO1QiAftQFv",
        "replyto": "sO1QiAftQFv",
        "invitation": "ICLR.cc/2023/Conference/Paper2473/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an end-to-end encoder-decoder approach for ligand-protein binding (blind docking) where the ligand can conform while the protein structure is assumed fixed. In the encoder part, the individual atomic representation of ligand and residue-based representation of ligand is learnt through graph networks which in turn leads to an embedding for pairs of atoms and residues and are all update within a transformer. The decoder iteratively processes the embeddings to output Euclidean coordinates for the ligand atoms where it respects the SE(3) equivariance of rotation and translations of the ligand and protein.",
            "strength_and_weaknesses": "strengths:\n+ The encoder-decoder architecture for ligand-protein binding can be considered novel although comprised of modules that have been proposed in the literature before, save for the following point.\n+ The distance-based attention mechanism to update the pair embeddings seems to somewhat respect the 3D Euclidean geometry of the individual protein and the individual ligand in an interaction.\n+ The general setup has taken many inspirations from recent works on protein structure modeling and protein binding including alphafold.\n+ From (although limited) ablation studies it seems at least some of the additions are generally successful in improving the docking performance.\n+ The results show clear improvements over recent baselines on protein-ligand binding.\n\npossible improvements:\n- The proposed method is comprised of many learnable components. It would be informative to compare the capacity of the model in some form with prior similar works, at least the more recent ones EquiBind and TankBind. Then, it would be important to empirically verify that it is not the increased capacity that explains the improved performance.\n\n- An important ablation study seems to be missing for the distance-based attention mechanism in updating the pair embeddings which seems to be the main technical novelty of the work apart from the general constellation of the approach.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper was generally an easy read and the figures and tables straight-forward to interpret.",
            "summary_of_the_review": "The empirical results are relatively strong, the work has the minimal required novelty in the general design as well as the attention mechanism. On the other hand, a conclusive message on the performance can benefit from the above-mentioned additional experiments. I lean towards accepting the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_ofea"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2473/Reviewer_ofea"
        ]
    }
]