[
    {
        "id": "TMoGZn-mtr",
        "original": null,
        "number": 1,
        "cdate": 1666653782710,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666653782710,
        "tmdate": 1666653782710,
        "tddate": null,
        "forum": "RqJZTlQMph",
        "replyto": "RqJZTlQMph",
        "invitation": "ICLR.cc/2023/Conference/Paper3794/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work extends neuro-symbolic approaches for the image manipulation task and proposes a solution referred to as NEUROSIM. Previous work requires supervised training data in the form of manipulated images or can only deal with simple reasoning instructions over single object scenes.\nThe proposed work performs complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA by parsing an instruction into a symbolic program, based on a Domain Specific Language comprising of object attributes and manipulation operations.\nThe proposed method is evaluated on the dataset collected by the author(s) named CIM-NLI.",
            "strength_and_weaknesses": "*[Strength]*\n1. This work designed novel neural modules and a training strategy that only uses VQA annotations as weakly supervised data for the task of image manipulation. \n2. This work designed evaluation metrics to better evaluate the claimed contribution.\n\n*[Weakness]*\n1. What is the performance if there is no VQA training on the visual representation network, semantic parsing module, and concept quantization network (direct end-to-end training on the manipulation task)?\n2. What is the performance of the add, remove and change manipulations, respectively?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper clarified its contributions and approach most clearly. \nIn general, the paper is novel, can be reproduced and is of fair quality.",
            "summary_of_the_review": "This paper proposed a method to solve the image manipulation problem and collected new datasets for better evaluate the contribution. Even though there is a lack of some experiments, overall, I'm leaning to accept this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_zm9X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_zm9X"
        ]
    },
    {
        "id": "KpIZkchR0f",
        "original": null,
        "number": 2,
        "cdate": 1666802556153,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666802556153,
        "tmdate": 1670911138858,
        "tddate": null,
        "forum": "RqJZTlQMph",
        "replyto": "RqJZTlQMph",
        "invitation": "ICLR.cc/2023/Conference/Paper3794/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper addresses image manipulation through text. The proposed method is based on an existing method (Mao et al., 2019) proposed for Visual Question Answering (VQA) with a neuro-symbolic approach. The proposed method leverages VQA annotations and shows better accuracy than comparative methods with weakly supervised learning. Experiments are conducted on a synthesized dataset utilizing CLEVR.\n\nOne note: Although one could imagine weakly supervision by VQA could utilize the errors from VQA in the image generation network (Niu et al., 2020), the proposed method simply trains some modules using VQA annotations.\n\nTianrui Niu, Fangxiang Feng, Lingxuan Li, and Xiaojie Wang. Image Synthesis from Locally Related Texts. International Conference on Multimedia Retrieval, 2020.",
            "strength_and_weaknesses": "Strengths\n1. Efficient method utilizing neuro-symbolic approach for image manipulation through text.\n1. A novel dataset and the source code is provided.\n\nWeaknesses\n1. This is a common issue for studies that use synthetic data, such as CLEVR, but operating in such a controlled environment does not guarantee that it will actually work on real images as expected in an application. Although this paper states that multi-hop reasoning is required as \"complex image manipulation,\" the proposed method would also need to be evaluated on real images, as done for NS-CL (Mao et al., 2019).\n1. While the proposed method does not require edited images, it requires annotation for VQA and Domain Specific Language (DSL) design. Moreover, its effectiveness has only been confirmed on controlled CLEVR-based datasets.\n1. This paper is close to system integration. It is certainly the first neuro-symbolic approach to text-guided image editing, but it is a combination of known ideas when broken down into its components. For example, the introduction of the symbolic approach to Vision & Language, the use of VQA for image generation, and the generation of scene graphs from images and images from scene graphs in the method are all existing ideas.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality\n- The manuscript should be proofread a bit more. \n  - Abbreviations such as NSCL and VQA appear suddenly in the abstract without any explanation. Their full names should be stated first.\n  - Only the parentheses for CIM-NLI are in italics.\n  - All paragraphs are long; it is difficult to grasp the structure of the text. Paragraph writing should be kept in mind.\n\nNovelty\n- The third weakness above is one about novelty. Technical novelty is not necessarily high.\n\nReproducibility\n- There is also a detailed description in the appendix, and the code is provided. Reproducibility is sufficient.\n",
            "summary_of_the_review": "Overall, the reviewer is on the borderline but slightly leans toward rejecting this paper. A response from the authors regarding the above weaknesses could improve the score.\n\n----\n\n**Updated review**\n\nThe authors have answered almost all of the reviewers' concerns. In particular, the addition of experiments beyond the CLEVR dataset, showing the strength of the proposed method for synthetic data and the challenges and prospects for real data, will contribute to subsequent research.\n\nTherefore, the reviewer improves the review score by one. However, the cause of the reviewer's still borderline judgment is a concern related to the following comments from the authors.\n\n> Moreover, it is not clear as to how we can solve the task of complex image manipulation without using either explicit supervision in the form of manipulated images or VQA examples.\n\nAs cited by the authors, Dong et al. (2017), TAGAN (Nam et al., 2018), and ManiGAN (Li et al., 2020) also propose image manipulation with weak supervision. These methods learn image manipulations from image-caption pairs. Regarding ease of data collection, these image-caption pairs are more effortless than VQA.\n\nThe authors claim that these studies do not cover multi-hop operations on images containing multiple objects. However, some papers have experimented with a dataset, COCO, containing multiple objects, and whether the methods proposed by these papers are 0-hop remains a matter of hypothesis. These methods have the possibility to generate proper images even if an instruction includes multi-hop instructions.\n\nMoreover, the authors' last point is whether these conventional methods can output images with only difference (delta) instructions for image manipulation. For example, however, Fig. 6 of ManiGAN (Li et al., 2020) shows that it is possible to manipulate images even from a simple instruction that looks like a delta.\n\nThe image manipulation performed by the authors on real image data is also low as its subjective realization. It would have been necessary to directly compare these methods to the proposed one on a common dataset.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_oHcq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_oHcq"
        ]
    },
    {
        "id": "_Z5sYjLkm1M",
        "original": null,
        "number": 3,
        "cdate": 1666960788107,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666960788107,
        "tmdate": 1666960788107,
        "tddate": null,
        "forum": "RqJZTlQMph",
        "replyto": "RqJZTlQMph",
        "invitation": "ICLR.cc/2023/Conference/Paper3794/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents an neuro-symbolic, interpretable approach NEUROSIM to solve image manipulation task using weak supervision of VQA annotations, building on existing work on neuro-symbolic.\n\n",
            "strength_and_weaknesses": "This paper is the first work that can handle multiobject scenes with complex instructions requiring multi-hop reasoning, and solve the task without any output image supervision. ",
            "clarity,_quality,_novelty_and_reproducibility": "I have no other concerns.",
            "summary_of_the_review": "The overall contribution of this paper is significant.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_nYyA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3794/Reviewer_nYyA"
        ]
    }
]