[
    {
        "id": "gnJ5p-AWZX",
        "original": null,
        "number": 1,
        "cdate": 1666346991333,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666346991333,
        "tmdate": 1666346991333,
        "tddate": null,
        "forum": "ZrEbzL9eQ3W",
        "replyto": "ZrEbzL9eQ3W",
        "invitation": "ICLR.cc/2023/Conference/Paper3042/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Inspired by the recent interest in power-law scaling of performances in large transformer-based models, this work investigates that in two-player zero-sum games with reinforcement learning (RL). By conducting experiments in two domains, Connect Four and Pentago games, authors show that the playing strengths of agents scale as a power law with the neural network size when models are trained until convergence. They also investigate the trade-off between model size and compute. Lastly, they utilise the two scaling laws to find a scaling law for the optimal model size given the amount of compute available.",
            "strength_and_weaknesses": "## Strengths\n\n- The paper takes one of the most important issues of deep learning: how the changes in model size, compute, and data affect the performance of the model. This question has been studied extensively for NLP methods. However, not a lot of analysis exists for RL, particularly multi-agent domains. For me, the problem itself is real and practical.\n- The idea of using ELO as the y-axis for RL scaling laws is interesting.\n- This paper provides a comprehensive set of experiments, including ELO performances relative to the population of agents as well as solvers.\n\n## Weaknesses\n\n- While I appreciate that the authors have restrictions for running large-scale experiments, I do still think that the choice of games for this work is limited.\n    - The authors use their results from Connect Four and Pentago to extrapolate insights about AlphaZero (Silver et al, 2017a) and AlphaGoZero (Silver et al, 2017b). This is an Apples to Oranges comparison involving different games and model architectures. I\u2019d expect at least using the game dynamics (perhaps with smaller board sizes) before being able to comfortably generalise claims based on limited data.\n    - For example, 8x8 checkers or smaller-sized Go would have strengthened the paper.\n    - This would also allow authors to analyse bigger models that do not saturate as quickly.\n    - With current results, it is unclear if such phenomena will be observed in more challenging games, such as Go and Chess.\n- The ELO ranking results depend heavily on the population of agents being used for comparison. The authors use the ELO between the population of trained agents to estimate the power-law scaling in MARL. It is unclear if these insights can hold more generally. For example, the Relative ELO relative solver in Pentago does not seem to be as neat as the ELO relative to the agent population.\n- The results suggest that the two games share exactly similar scaling exponents for playing strengths ($\\alpha_N$, $\\alpha_C$, and $\\alpha_C^{opt}$). I find this quite surprising and unintuitive. This is also among the reasons why I\u2019d like to see more games investigated in this game to assess the universality of these constants.\n- The authors factor the compute by the forward pass costs and MCTC simulations. This is sensible, considering the model architecture used. Considering that the games are relatively easy, I\u2019d be curious to see if such a power law emerges with model-free RL approaches.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, clear and easy to follow.\nThe manuscript has high quality and I have relatively few concerns.\nThere is no novelty in the paper in terms of algorithmic changes, but overall the thorough analysis of the power-law scaling for MARL using ELO as the y-axis is novel.\nThe authors open-sourced the code for reproducing the experiments. Hence, there are no concerns regarding the reproducibly of results.",
            "summary_of_the_review": "Overall, this is an interesting paper that tackles an important problem, the scaling laws in a subclass of multi-agent RL methods. The evaluation protocol is novel and the paper includes a comprehensive set of experiments to support its main claims. That said, I still have some concerns about the generality of the results achieved here. The paper could have been improved by adding more games in the experimental setup. Furthermore, there are some concerns regarding the ELO-ranking population and scaling exponent values.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_T3hx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_T3hx"
        ]
    },
    {
        "id": "0952yurWyJ_",
        "original": null,
        "number": 2,
        "cdate": 1666457682564,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666457682564,
        "tmdate": 1666457682564,
        "tddate": null,
        "forum": "ZrEbzL9eQ3W",
        "replyto": "ZrEbzL9eQ3W",
        "invitation": "ICLR.cc/2023/Conference/Paper3042/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors of this paper ran a large amount of AlphaZero-based training runs, with many different sizes of neural networks, for two different board games: Connect Four and Pentago. Based on these experiments, the paper demonstrates for both games, very similar power laws exist that predict how the playing strength (measured in Elo) scales with respect to various aspects such as compute, num NN params, and generated self-play data.",
            "strength_and_weaknesses": "**Strengths**:\n- Very clear writing.\n- Good, extensive experiments (albeit restricted to two games, plus one more in supplementary material).\n- Interesting and likely-impactful results and conclusions.\n\n**Weaknesses**:\n- I think that a few conclusions / remarks about related work need to be toned down, due to the use of only two games, and many similarities between those two games.\n\n**Detailed Comments**\n- On page 2, some motivation is provided for the selection of the 2 games is provided, **stating that they are sufficiently different** with respect to branching factors and game length. I agree that they are quite different in terms of branching factor, but in terms of game lengths they are really quite similar: they are both relatively short (25.4 vs 16.8 according to Table 2). There are many other board games out there with substantially greater durations (e.g., Chess, Shogi, Go, Amazons, Hex, Havannah, ...). These two aspects (branching factor and game duration) are also only two, relatively abstract, aspects. We can think of many other properties of board games: What is the board size? What kind of shape/tiling does the board use? What kinds of win conditions are used? What kinds of movement mechanisms are used? And so on. In almost all of these aspects, the two selected games are very similar. They have similar board sizes (and hence input shapes). They both use tilings of squares (although Pentago does at least have the thing where parts of the board get rotated). They both have line-completion goals (no checkmate or capturing or connection or racing or any other kinds of win conditions). Neither game features movement of pieces (as in Chess/Shogi/Amazons/etc.), only placement of pieces (and indirectly some movement in Pentago due to partial board rotations). Neither game features any capturing/removal of pieces. Both games naturally converge towards a terminal position (because pieces never get removed). **Considering all of these aspects together, I would argue that the two selected games are in fact highly similar, having only a few differences.**\n- Given my point above, I feel that some conclusions need to be weakened and limitations more explicitly acknowledge. **Firstly, while I do think the attempt at extrapolating to AlphaZero/AlphaGo Zero is interesting to see, everything related to this needs to be presented with a lot more nuance and acknowledgement of the major differences.** Go is a very different game from Connect Four and Pentago in many important aspects: significantly longer games, much bigger board, very different style of win condition, involves capturing of pieces, does not necessarily naturally converge to a terminal position (I guess it does under expert play when the board gets filled up, but not under non-expert play where giant portions of the board might be freed up during gameplay). The same holds for Chess and Shogi (*are these games actually included when you say \"AlphaZero\" in e.g. Figure 1?*). **Secondly, in general the main conclusions of the paper about power-law scaling being likely to exist for AlphaZero in general**, even if the exact coefficients may be different, **should again be stated with much more nuance and acknowledgement of the fact that the two evaluated games are extremely similar in many aspects**. Demonstrating this behaviour in two highly-similar board games is not representative of the overall space of board games.\n- In principle, I am fine with having used only these 2 games. I understand that computational limitations are an issue, and I also think there are very good reasons to select 2 relatively small games like this (for example because it allows for comparisons against near-perfect players). While more games, bigger games, and more variety in games could've made the work even stronger, I do not see it as a reason to reject. However, I do see it as something that needs to be more explicitly acknowledged as a limitation.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**: overall clear and good writing. Just a couple of minor errors, see minor comments below.\n\n**Quality**: see discussion of strengths & weaknesses above.\n\n**Novelty**: the paper looks good in terms of novelty to me (the authors discuss clearly-related work on similar scaling laws outside of RL, but it is interesting and novel to see something similar for RL).\n\n**Reproducibility**: good, URL with source code provided, and experiments described with sufficient clarity and amount of detail.\n\n**Minor Comments**:\n- p. 2: \"These Games are selected\" --> games should not be capitalised\n- p. 2: \"In step with scaling observed in the game Hex\" --> what does \"In step with\" mean? Do you mean \"In contrast to\" or \"Similar to\"?\n- p. 3: \"by the MCTS by counting the number of explored future states\" --> personally I find this vague, and would simply describe it as the \"number of visits\" instead of \"number of explored future states\". I suppose it's usually the same thing (if MCTS expands/explores one state every iteration), but technically visit counts is more correct for end-game situations (where some MCTS iterations might not expand any new state anymore if the tree traversal leads to a terminal state that is already part of the tree, but it does still increment the visit counter).\n- p. 9: \"but the proof of power-law scaling\" --> I'd prefer \"evidence\" instead of \"proof\". I prefer to reserve the word \"proof\" only for cases where something is actually theoretically proven. Empirical experiments just provide evidence, no matter how convincing they may be.\n- p. 10: The two \"Anonymized\" references should have just been provided in a non-anonymized form. They could just have been cited in the third person, as if they were other people's work, without mentioning it was your work. **Do not updated it now during this review cycle though**, or it would reveal your identities.\n- p. 15: \"Medium-seized\" --> Medium-sized\n\n**Question**: When evaluating playing strength of agents, do you still restrict agents by MCTS iteration counts (as in training), or by time limits? I assume that larger neural networks have greater computational overhead, and therefore could produce a weaker full (search+DNN) agent when restricted by time budgets, due to slowing down the search. This could be another reason why, for example, it might have been preferable for AlphaGo Zero / AlphaZero networks to be smaller than the predicted \"optimal\" sizes according to the scaling laws.",
            "summary_of_the_review": "Overall a good paper, but some of its limitations need to be more explicitly acknowledged, and some conclusions / statements about related work be made with more nuance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_kPYj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_kPYj"
        ]
    },
    {
        "id": "9RkA9N3CkB7",
        "original": null,
        "number": 3,
        "cdate": 1666643137422,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643137422,
        "tmdate": 1670471269901,
        "tddate": null,
        "forum": "ZrEbzL9eQ3W",
        "replyto": "ZrEbzL9eQ3W",
        "invitation": "ICLR.cc/2023/Conference/Paper3042/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the scaling law of AlphaZero algorithm in the MARL setting. Specifically, it uses the Elo rating as the performance criteria, and demonstrates that there is power-law scaling between the Elo rating and the model size (also the computation budget).",
            "strength_and_weaknesses": "# Strength\n\n- This paper is clearly written.\n-  Most of the experiments are repeated with several different random seeds, and the results displayed align well with authors' interpretation.\n\n\n# Weakness\n\n- Since there is neither new algorithm proposed nor insightful phenomenon observed throughout the experiments, I am little bit concerned with the technical novelty of this work.\n\n- It is likely that the discovered scaling law only holds under the very specific training methods, the model architecture and the game environment. Once you changed any of these factors, the scaling law might crash or hold with a very different exponent parameter. The experiments in the current submission cannot rule out such possibility. \n\n- I am also not convinced by the motivation of studying the scaling law for this very specific algorithm in these two moderate-size boardgames. It is unclear to me what insight these results can provide for both practitioners and theorists. \n\n- The authors claimed \"This scaling law implies that previously published state-of-the-art game-playing models are significantly smaller than their optimal size, given the respective compute budgets\" but to me it is more likely that (1) the previous works might have used different training (engineering) techniques from this paper, and (2) the scaling law discovered in this paper does not generalize to more complex games of different styles (like Go) and even if it can generalize, it may hold with a different exponent parameter. Therefore, I find such claim scientifically misleading.\n\n- The Elo score highly depends on the strength and the playing style of other players. In this paper, other players are generated from AlphaZero with different training configurations. It is unclear to me whether the same scaling law still holds or not if I generate the opponent players in a different way. \n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clearly written.",
            "summary_of_the_review": "So far I am fairly concerned with the novelty and significance of the current submission. I am willing to raise my score if the authors can address my concerns.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_537d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_537d"
        ]
    },
    {
        "id": "xREvkT7O7s",
        "original": null,
        "number": 4,
        "cdate": 1666714375186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666714375186,
        "tmdate": 1670421517200,
        "tddate": null,
        "forum": "ZrEbzL9eQ3W",
        "replyto": "ZrEbzL9eQ3W",
        "invitation": "ICLR.cc/2023/Conference/Paper3042/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors claim to find a relationship between compute, model size and performance (here measured by ELO). Studies are conducted over 2 games (Connect Four and Pentago) and the AlphaZero algorithm. Finally the authors combine these relationships to make recommendations based on optimal model size given the amount of compute available. \n\nThe authors also have a third game (Oware) over which they observe a scaling law, which different scaling parameters.\n",
            "strength_and_weaknesses": "### Strengths\n\nInteresting results.\nProof of existence is good\n\n### Weaknesses \n\nI think this paper misses the point of the LM scaling laws. Here Kaplan\u2019s results were only significant because we found that the log_loss score for language modeling was very indicative of success for  downstream LM tasks. Here we don\u2019t have this justification for why we should care about ELO. \n\nELO does relate to performance on the task but i\u2019d expect that to change with compute and model size - the claims for this being significant are only:\n\n* It looks like a scaling law\n* This is true for multiple games (sample size 2)\n\nFor this result to be compelling I'd either like to be shown over multiple methods (PPO, DQN)  or many many more games.  Simple games such as pong or gridworlds would also be welcomed. \n\nhe state space argument really doesn\u2019t make sense to me - I would try discrete the space or form some 1 hot encoding (as done by most PPO implementations for OpenAI gyms' continuous action problems).\n\nGenuinely i can\u2019t tell if this rule generalises to all 2player zero-sum games or a specific niche currently.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clearly communicated and well written. \n\n\n",
            "summary_of_the_review": "\nInteresting results but the claim is way too broad for the lack of empirical work done to verify it.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_6fgP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3042/Reviewer_6fgP"
        ]
    }
]