[
    {
        "id": "qC12kRD4Tp0",
        "original": null,
        "number": 1,
        "cdate": 1666341951214,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666341951214,
        "tmdate": 1666341951214,
        "tddate": null,
        "forum": "kLvYYV-YK_j",
        "replyto": "kLvYYV-YK_j",
        "invitation": "ICLR.cc/2023/Conference/Paper3440/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper introduces a benchmark for evaluating domain adaptation methods under the relaxed label shift setting. The authors leverage the introduced benchmark on various domain adaptation methods showcasing the inability of prior domain adaptation methods in coping with the relaxed label shift setting. In addition, this paper also proposes a set of meta-algorithm that could bring general improvements to existing domain adaptation methods.",
            "strength_and_weaknesses": "It is true that comprehensive and fair benchmarking of domain adaptation methods, especially in an under-explored but more realistic setting such as relaxed label shift. Therefore, the motivation of this paper is solid which investigates the effectiveness of prior domain adaptation methods under relaxed label shift in a comprehensive and fair manner. The experiments conducted are comprehensive and the observations of which generally support the authors' claims. The details of the implementation of the experiments are provided in a meticulous manner, with the rather detailed results provided in an anonymous GitHub form. These details greatly help the reproduction of the results and solidify the presentation of experiments. Overall, this paper deals with a domain adaptation setting of great research interest with comprehensive empirical results.\n\nDespite the relatively solid motivation and comprehensive empirical results, there are a few weaknesses that the authors would consider addressing:\na) Even though the authors have proposed a set of meta-algorithm such that it could be leveraged with any domain adaptation (DA) methods and improve the capability of the DA methods in tackling label shift. However, the strategies used (i.e., re-sampling and re-weighting) are not novel techniques, as have also been acknowledged in the paper. Therefore, it would be interesting to analyze why such techniques, though useful, have not been considered in past literature. Additionally, while these strategies may not be leveraged previously on DA with relaxed label shift, they have been leveraged for other tasks with solid proof. The authors should therefore not only show that such methods work empirically, but also showcase why such methods work by providing theoretical proofs or theorems. This would enable a better understanding of why such methods should be employed for DA with relaxed label shifts.\nb) Another concern about the proposed algorithm lies in the authors' claims (on Page 5, the \"Summary\" paragraph): \"we expect DA methods to adapt classifier $f$ to $p(x|y)$ shift\". This seems to contradict what the authors have stated in their review of previous domain adaptation methods in Section 2.1, where the authors noted that: \"a few papers highlighted the theoretical and empirical failure of DA methods\" for relaxed label shift setting. If so, it seems that the algorithm is only effective due to perhaps the meta-algorithm is able to adapt $f$ to the shift in $p(y)$. Can the authors elaborate on this contradiction?\nc) While the authors describe in detail their observation through comprehensive sets of empirical results, the analysis behind these observations fall short of being satisfactory. For example, on Page 8 the authors observe that \"early stopping criterion\" and \"data augmentation\" would impose certain effects on the final result. However, other than a short description no further analysis of why these effects are imposed and to what degree subsequent methods should pay attention to these two aspects.\nd) It is noted that the authors seem to take a different source/target domain setting approach than how certain domain adaptation benchmarks are normally leveraged. One example is the Office-Home dataset which normally benchmarks DA methods by setting 12 pairs of source/target domains with each domain being set as both the source and target domain. In this paper, though only the \"Product\" domain is set as the source domain. Could the authors prove that such settings would not affect the conclusions obtained? Meanwhile, to my understanding, the authors provide the average scores across all source/target domain pairs. Are there any outlier source-target domain pairs whose results are notably different than the rest? If there are, they should be discussed separately.\ne) There are some typos and sentences that are not fluent enough, hampering the clarity of the presentation. The authors may check through their papers for these minor but sometimes obvious mistakes. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, this paper is of decent quality, introducing a comprehensive benchmark for an under-explored domain adaptation setting. The paper is generally presented clearly through there are some presentation errors and details that should be elaborated on. The authors provide detailed implementations that can be reproduced, and the results are in line with the result logs provided by the authors.",
            "summary_of_the_review": "Generally speaking, this paper introduces a comprehensive benchmark that is of good significance towards the development of domain adaptation methods that are robust for real-world applications. The technical novelty of the paper may not be outstanding, but the empirical results do shed light on how relaxed label shift can be tackled if the authors could further elaborate in their analysis. I recommend a \"marginally above the acceptance threshold\" score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_kXyy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_kXyy"
        ]
    },
    {
        "id": "5QqC37TsAq",
        "original": null,
        "number": 2,
        "cdate": 1666531973630,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531973630,
        "tmdate": 1666532448336,
        "tddate": null,
        "forum": "kLvYYV-YK_j",
        "replyto": "kLvYYV-YK_j",
        "invitation": "ICLR.cc/2023/Conference/Paper3440/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper works on benchmarking the domain adaptation methods on datasets with target label marginal shift and category data distribution p(x|y) shift. The benchmark datasets are based on the current popular DA datasets with resampled target label marginal distribution by resampling target domain data. The paper proposed resampling and reweighting techniques upon the current DA methods on this benchmark, and shows improvement over DA methods commonly, in the relaxed label shift setting.",
            "strength_and_weaknesses": "1. Strength: This paper benchmarks DA considering the target label marginal mismatch in relaxed label shift setting. It compares different DA methods with the proposed reweighting method on classifiers and resampling method for balancing the target data label distribution. The proposed two techniques can commonly improve DA methods in the relaxed label shift setting.\n\n2. Weakness\n\nI overall appreciate the benchmark in relaxed label shift setting, and the extensive comparisons, especially with the resampling and reweighting techniques. However, my major concerns on this work are the limited novelty. \n\n(1) The benchmark datasets are all based on the previous popular DA datasets. The work of this paper is to resample the target domain data based on Dirichlet distribution to simulate the target label marginal shift.\n\n(2) To handle the label marginal shift, the proposed RS (resampling based on pseudo-label) and RW (reweighting classifiers) are straightforward. These two techniques are combined with the other SoTA DA methods. This is reasonable, but the novel contribution in methodology for DA is limited.\n\n(3) The RS and RW depend on the estimation of target domain label distribution, which are based on the pseudo-labels. The analysis of the accuracy of pseudo-labels and their effects on the DA performance need to be deepened.  From Table 3, it seems that the RS do not improve the target marginal estimation significantly. ",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of the paper is mostly clear. The method is easy to follow, and the codes are claimed to be published.",
            "summary_of_the_review": "The paper builds a benchmark for DA with target label marginal shift and the per-category data distribution shift. The benchmark dataset is simply by sampling target domain data using the popular DA datasets. The proposed RS and RW are reasonable for remedying the target label distribution shift, however, may heavily rely on the quality of pseudo-labels, and with limited contribution in methodology for DA. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_mTKd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_mTKd"
        ]
    },
    {
        "id": "IyRIltyTuj7",
        "original": null,
        "number": 3,
        "cdate": 1666598366534,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666598366534,
        "tmdate": 1666598366534,
        "tddate": null,
        "forum": "kLvYYV-YK_j",
        "replyto": "kLvYYV-YK_j",
        "invitation": "ICLR.cc/2023/Conference/Paper3440/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies popular domain adaptation methods under scenarios where both label distribution and conditionals may shift. Specifically, the authors introduce a large-scale benchmark for relaxed label shift settings which consists of 11 vision datasets spanning more than 200 distribution shift pairs. 12 popular domain adaptation methods are evaluated on this benchmark and several observations are provided. This paper shed light on domain adaptation methods in relaxed label shift settings.",
            "strength_and_weaknesses": "Strengths:\n+ This paper is well-written. It is enjoyable to read.\n+ This paper studies an important problem. While existing DA approaches work well under covariance shift and label shift. More general scenarios should be introduced to test the effectiveness of the proposed method.\n+ Experiments results are self-contained, and many insightful observations and discussions are provided.\n\nWeaknesses:\n+ It can be observed that some semi-supervised learning methods (e.g. Fixmatch) work well in relaxed label shift settings. Fixmatch is a consistency-based method. In experiments we find that adversarial learning based methods show worse performance than consistency-based methods. In DA, MCD[1] is an adversarial learning based method. And it is also a consistency-based method. What about this method in the benchmark?\n[1] Maximum classifier discrepancy for unsupervised domain adaptation\n+ More insightful analysis should be provided. For example, why Fix-match works better than other methods?\n+ It would be interesting if more benchmarks (more than vision datasets, for example, NLP?) can be introduced.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good, this paper is well-written.\n\nQuality: Good. Experiments are comprehensive.\n\nNovelty: Limited. But the contribution is not marginal.\n",
            "summary_of_the_review": "Strengths:\n+ This paper is well-written. It is enjoyable to read.\n+ This paper studies an important problem. While existing DA approaches work well under covariance shift and label shift. More general scenarios should be introduced to test the effectiveness of the proposed method.\n+ Experiments results are self-contained, and many insightful observations and discussions are provided.\n\nWeaknesses:\n+ It can be observed that some semi-supervised learning methods (e.g. Fixmatch) work well in relaxed label shift settings. Fixmatch is a consistency-based method. In experiments we find that adversarial learning based methods show worse performance than consistency-based methods. In DA, MCD[1] is an adversarial learning based method. And it is also a consistency-based method. What about this method in the benchmark?\n[1] Maximum classifier discrepancy for unsupervised domain adaptation\n+ More insightful analysis should be provided. For example, why Fix-match works better than other methods?\n+ It would be interesting if more benchmarks (more than vision datasets, for example, NLP?) can be introduced.\n\nOverall, the authors should give more insightful discussions to further improve the paper. And this paper can shed light on DA in relaxed label shift setups. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_PHqQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_PHqQ"
        ]
    },
    {
        "id": "JaPOTfq4e5-",
        "original": null,
        "number": 4,
        "cdate": 1666602670297,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666602670297,
        "tmdate": 1666602670297,
        "tddate": null,
        "forum": "kLvYYV-YK_j",
        "replyto": "kLvYYV-YK_j",
        "invitation": "ICLR.cc/2023/Conference/Paper3440/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper gives the empirical study of domain adaptation algorithms under relaxed label shift scenarios. Many algorithms such as domain-invariant representation learning, self-training, and test-time adaptation methods across 11 multi-domain datasets are conducted. ",
            "strength_and_weaknesses": "Strength:\n1) This paper gives a large-scale evaluation of existing domain adaptation algorithms under relaxed label shift scenarios. This helps related researchers focus on this problem.\n2) Commonly adopted datasets and many related methods are conducted.\n\nWeakness:\n1) This paper evaluated domain adaptation methods on relaxed label shift scenarios. But there is no formal definition of the relaxed label shift.\n2) The authors only report the mean accuracy of different methods. How about the variance? \n3) The observation from the experimental results all seems to be well-known conclusions. Are there some inspirational or unusual conclusions?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. But there lacks of inspirational conclusions from the experimental results. The novelty is limited.",
            "summary_of_the_review": "Based on the above discussion, I tend to reject.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_VEqd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3440/Reviewer_VEqd"
        ]
    }
]