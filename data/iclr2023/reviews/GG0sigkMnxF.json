[
    {
        "id": "jguarHLFnpW",
        "original": null,
        "number": 1,
        "cdate": 1666468754082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666468754082,
        "tmdate": 1666468815406,
        "tddate": null,
        "forum": "GG0sigkMnxF",
        "replyto": "GG0sigkMnxF",
        "invitation": "ICLR.cc/2023/Conference/Paper4731/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a method for sign language hand gesture recognition. There is no novelty in the proposed method, and the author only evaluated their method on self-collected data.",
            "strength_and_weaknesses": "Strength:\n- Sign language recognition is an important task.\n- The author provided a detailed implementation of their method. I believe the proposed method could be easily re-implemented.\n\nWeakness: \n- There is no novelty in the proposed method. The proposed method uses very basic image processing techniques and very simple contour detection. The method is too naive.\n\n- The author only evaluates their method on a small self-collected dataset. The evaluation dataset is collected from five subjects and only a few class images. There is no evidence showing the generally of the proposed method.\n\n- The paper writing could be significantly improved. There are too many parts of the paper that need to be rewritten. I suggest the author find someone who got accepted a paper in ICLR before to give them professional suggestions in writing.",
            "clarity,_quality,_novelty_and_reproducibility": "The method description is clear. There is no novelty in the proposed method. I think it is very easy to reimplement the method.",
            "summary_of_the_review": "I think this is a clear reject of the ICLR submission. I did not see the novelty of the proposed method and the evaluation was only done on a small self-collected dataset.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_jVQ2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_jVQ2"
        ]
    },
    {
        "id": "g9l88yVGVK",
        "original": null,
        "number": 2,
        "cdate": 1666483560691,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666483560691,
        "tmdate": 1666483560691,
        "tddate": null,
        "forum": "GG0sigkMnxF",
        "replyto": "GG0sigkMnxF",
        "invitation": "ICLR.cc/2023/Conference/Paper4731/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents a vocalizer that achieves real-time translation of gesture to text/voice using convex hull as the computational geometry.",
            "strength_and_weaknesses": "*Strength:\nThe key strengths may lie in the proposed framework URVoice. As the author points out, the URVoice can take the visual / audio as input from the collocutor/ computer and converts it into gesture/ text as output for the signer.\n* Weaknesses:\nFrankly speaking, the title of this paper is very confusing. Why is it called URVoice? \u201cconvex hull computation\u201d is simply too broad and vague. Although not explicitly being stated, this work focused on gesture recognition. With that being said, the main technical contributions seem to be the proposed framework to achieve translation of gesture to text/voice. However, with insufficient evidence to demonstrate the effectiveness of the proposed approaches than the state-of-the-art methods, the real impact that this work can bring to the community remains unclear to me.\nAfter reading the whole paper, I strongly feel that the proposed algorithms seem to be trivial and found nothing that excited me. For gesture recognition, there have been many excellent literatures [1,2,3] can be reference.  For the transformation of visual/text signals to speech/visual signals, many multimodal literatures [4,5,6,7] have achieved this goal.\n\n[1] H. Wang, P. Wang, Z. Song, and W. Li, \u201cLarge-scale multimodal gesture recognition using heterogeneous networks,\u201d in Proceedings of the IEEE International Conference on Computer Vision (ICCV), Oct 2017.\n[2] J. Wan, G. Guo, and S. Z. Li, \u201cExplore efficient local features from rgb-d data for one-shot learning gesture recognition,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 38, no. 8,\npp. 1626\u20131639, 2015\n[3] G. Zhu, L. Zhang, L. Yang, L. Mei, S. A. A. Shah, M. Bennamoun,and P. Shen, \u201cRedundancy and attention in convolutional lstm for gesture recognition,\u201d IEEE transactions on neural networks and learning systems, vol. 31, no. 4, pp. 1323\u20131335, 2019.\n[4] Jeonghun Baek, Geewook Kim, Junyeop Lee, Sungrae Park, Dongyoon Han, Sangdoo Yun, Seong Joon Oh, and Hwalsuk Lee. What is wrong with scene text recognition model comparisons? dataset and model analysis. In Proc. ICCV, 2019.\n[5] Zhanzhan Cheng, Yangliu Xu, Fan Bai, Yi Niu, Shiliang Pu, and Shuigeng Zhou. Aon: Towards arbitrarily-oriented text recognition. In Proc. CVPR, 2018.\n[6] Chen-Yu Lee and Simon Osindero. Recursive recurrent nets with attention modeling for OCR in the wild. In Proc. CVPR, 2016.\n[7] Baoguang Shi, Mingkun Yang, Xinggang Wang, Pengyuan Lyu, Cong Yao, and Xiang Bai. Aster: An attentional scene text recognizer with flexible rectification. PAMI, 2018.",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty of this paper is insufficient.",
            "summary_of_the_review": "In conclusion, I think the novelty of this paper is insufficient, and the current version still has a lot of room for improvement, including the improvement of the algorithm and sufficient experimental support for the proposed technology. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_SEnB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_SEnB"
        ]
    },
    {
        "id": "UalDyzCnKn4",
        "original": null,
        "number": 3,
        "cdate": 1666552862581,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552862581,
        "tmdate": 1666553007135,
        "tddate": null,
        "forum": "GG0sigkMnxF",
        "replyto": "GG0sigkMnxF",
        "invitation": "ICLR.cc/2023/Conference/Paper4731/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "\nThe paper introduces the URVoice, an Augmentative and Alternative Communication (AAC) device which is supposedly a technological innovation. It is based on the Akl-Toussaint/Graham-Sklansky convex hull algorithms for sign language recognition.",
            "strength_and_weaknesses": "Main Strengths:\n-The paper is fairly well-written and organized.\n\nMain Weaknesses:\nUnfortunately, I believe the paper is out of the scope of the conference. It is focused on the architecture of a device (the URVoice), which is based on fundamental geometrical and computer vision algorithms. The authors review such fundamental methodology, but they do not present any related state-of-the-art literature on sign language recognition. Finally, the paper does not propose any novel contribution. The experiments are also performed on limited datasets.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear. There is no novelty in the methodology. The authors present several algorithms in the text, which might allow the reproducibility. ",
            "summary_of_the_review": "Unfortunately, I believe the paper is out of the scope of the conference. I suggest the authors submit their work to another conference or journal focused on technological innovation on such a kind of devices. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_eit5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_eit5"
        ]
    },
    {
        "id": "s381DnF1yvS",
        "original": null,
        "number": 4,
        "cdate": 1666599900696,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599900696,
        "tmdate": 1666599900696,
        "tddate": null,
        "forum": "GG0sigkMnxF",
        "replyto": "GG0sigkMnxF",
        "invitation": "ICLR.cc/2023/Conference/Paper4731/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new communication device to \"translate\" from Indian sign language gestures to text and/or voice. Both Indian natural language processing and sign language processing are severely under-resourced and societally significant, hence making this contribution even more substantial.",
            "strength_and_weaknesses": "The paper proposes a new communication device to \"translate\" from Indian sign language gestures to text and/or voice. Both Indian natural language processing and sign language processing are severely under-resourced and societally significant, hence making this contribution even more substantial. \n\nThe paper unfortunately suffers from severe issues in addressing human research ethics. Although it created and used two different datasets including data from human subjects, it did not describe human research ethics at all. I would have expected that obtaining ethical approvals, research permissions, and participants' informed consent to be described in general and in particular because this study focused on a particularly vulnerable cohort of people using sign language.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper could acknowledge and appreciate prior work more. For example, citing related work is encouraged. Its reference list is very short and mostly outdated. For example, advances in Indian natural language processing and sign language processing in 2020s have not been recognized here; many original studies and literature reviews published in the last 5 years are available but none of them have been cited in this paper.\n\nThe paper does not seem to be using recommended English terminology either. My understanding is that the peak advocacy and information organizations recommend using the terms of the Deaf and Hard-of-Hearing communities. \n\nThe broader impact and ethical considerations of this study should be discussed in further depth. I find the current addressing insufficient and more generally, the paper does not seem to follow the discipline traditions in the expected structure, order, and depth/length in addressing the why and so what of the study.",
            "summary_of_the_review": "Without addressing research ethics and other concerns related to relevant human subjects more broadly (e.g., the use of recommended terminology and discussion of the broad impact of this study), I can only recommend a strong rejection of this study.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "The paper unfortunately suffers from severe issues in addressing human research ethics. Although it created and used two different datasets including data from human subjects, it did not describe human research ethics at all. I would have expected that obtaining ethical approvals, research permissions, and participants' informed consent to be described in general and in particular because this study focused on a particularly vulnerable cohort of people using sign language.\n\nThe paper does not seem to be using recommended English terminology either. My understanding is that the peak advocacy and information organizations recommend using the terms of the Deaf and Hard-of-Hearing communities. ",
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_aLeh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4731/Reviewer_aLeh"
        ]
    }
]