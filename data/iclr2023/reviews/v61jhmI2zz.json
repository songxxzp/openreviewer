[
    {
        "id": "RtCyhf_bnL9",
        "original": null,
        "number": 1,
        "cdate": 1666609477726,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666609477726,
        "tmdate": 1666676826488,
        "tddate": null,
        "forum": "v61jhmI2zz",
        "replyto": "v61jhmI2zz",
        "invitation": "ICLR.cc/2023/Conference/Paper2442/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper contributes a method to automatically find failure cases of image classifiers in an  oepn-ended manner by leverageing off-the-shelf, large-scale generative models. ",
            "strength_and_weaknesses": "Strength: Automatically discovering failures is an interesting problem; The idea of applying image-to-text generative models to discover failures and obtain human-interpretable explanation of failure is novel.\n\nWeaknesses:\nThe failure cases in this paper are all synthetic and there is still a large margin gap remaining between real-world data and data generated by generative models; Though a lot of well-trained generative models can be applied in the method, the costs of training them should not be ignored; The limitations mentioned in the paper are difficult to solve and will affect the effectiveness of the work. Due to the randomness in the process of selecting cases via generative models, it is difficult to prove that this framework can be reproduced and effective.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity Quality Novelty and Reproducibility\nClarity and quality are good while novelty and reproducibility are not good enough.",
            "summary_of_the_review": "This paper proposes a method to automatically find failure cases of image classifiers. The applying of generative models is novel, but the limitations mentioned in the paper are difficult to solve and will affect the effectiveness of the work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_v5Fg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_v5Fg"
        ]
    },
    {
        "id": "ivUauQCGMs",
        "original": null,
        "number": 2,
        "cdate": 1666862904273,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666862904273,
        "tmdate": 1667112652886,
        "tddate": null,
        "forum": "v61jhmI2zz",
        "replyto": "v61jhmI2zz",
        "invitation": "ICLR.cc/2023/Conference/Paper2442/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes utilizing off-the-shelf text-to-image and image-to-text models to discover vision models' failures automatically. The experimental results are delighting and convincing to some extent. This paper is also inspiring and potentially useful to improve the generalizability of vision models.",
            "strength_and_weaknesses": "Overall, the idea of exploiting off-the-shelf generative and captioning models to discover failures of image classifiers trained in ImageNet is interesting and novel. I am also impressed by the extensive experimental results (including visualization analysis and variants effect analysis). \n\nNevertheless, I have several small issues:\n- Although adequate experiments are conducted on ResNet-50 on ImageNet, I am curious to see experiments on a stronger network backbone such as ResNet-152. This lies in the concern that a stronger network may not be easily found failures using the proposed method. As a matter of fact, I\u2019m mostly convinced by the provided results. But I think this experiments will make the conclusions more solid.\n- Do the discovered failures can further improve the object classification model\u2019s performance? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized, technically sound and novel.",
            "summary_of_the_review": "Currently, I lean to positive for its novel idea.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_GhTH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_GhTH"
        ]
    },
    {
        "id": "Mk5FrblIlh",
        "original": null,
        "number": 3,
        "cdate": 1666902771638,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666902771638,
        "tmdate": 1666902771638,
        "tddate": null,
        "forum": "v61jhmI2zz",
        "replyto": "v61jhmI2zz",
        "invitation": "ICLR.cc/2023/Conference/Paper2442/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper describes a pipeline that can be used to identify failures of image classifiers. Proposed approach utilizes SOTA generative models to enable interpretable failure discovery of a model by providing targeted realistic images. Experiments are well conducted to demonstrate the benefit of the approach. Discussions on its limitations and potential concerns are well considered in the paper as well.",
            "strength_and_weaknesses": "Strength\n\n* Formulated the problem of finding failures of image classifier in a probabilistic framework and showed how one can use off-the-shelf image-to-text captioning model and text-to-image generative model to create an interpretable and easy-to-use debugging tool.\n* Proposed approach is more interpretable and naturalistic than existing approaches and shows promise in generalizability.\n\n\nWeakness / other comments\n\n* \u201cIn particular, we use three shots, with each shot being an image and caption pair. Images are publicly available online and are manually described using between four to seven short sentences that describe the subject of the photograph and its physical position with respect to the camera, as well as the background or context in which the subject appears\u201d \u2192 This indicates that the method requires human input with some expert knowledge which raises a question on scalability and potential bias for this process.\n* How can identified failures help improving the actual model? Further discussion / analysis on how the discovered failures could be used would be useful in order to give a better idea to the practitioners who would want to use this system to improve their model.\n* \u201cFor each label y, we manually select target labels  y\u0302 (snow leopard, bee and chainlink fence respectively)\u201d \u2192 Why was this set of y\u0302 selected? What is the impact of the choice y\u0302 on failure discovery?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "It is well written and clear enough for someone unfamiliar with the topic to easily follow. The method is technically sound for the most part. This work uses existing SOTA models but the way they combined them as a new debugging tool is fairly novel. ",
            "summary_of_the_review": "This paper clearly describes their proposed method which is well designed and backed up with proper analysis and experiments. Although I have some doubts of the claimed scalability and how practical it would be if we were to use them for model improvement, as a proof-of-concept I think it falls above the acceptance bar.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_B78A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_B78A"
        ]
    },
    {
        "id": "ARSMNtw8bP_",
        "original": null,
        "number": 4,
        "cdate": 1667108416430,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667108416430,
        "tmdate": 1669391506061,
        "tddate": null,
        "forum": "v61jhmI2zz",
        "replyto": "v61jhmI2zz",
        "invitation": "ICLR.cc/2023/Conference/Paper2442/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an approach to automatically discover the failure cases of vision models under real-world settings. Off-the-shelf image-to-text and text-to-image models are leveraged to find such failures. Firstly, a conditional text-to-image synthesis model generates synthetic data based on the ground-truth label. Then, a captioning model is used to describe misclassified inputs. Next, the descriptions generated by the captioning model are used to synthesize more images to test whether the specific description causes a higher failure rate. This pipeline can be used to find the failure modes with language explanations for the classification models.",
            "strength_and_weaknesses": "Strengths:\n1. Incorporating large-scale text-to-image and image-to-text models for diagnosing classification models is an interesting topic. The authors provide some insightful explorations.\n2. The proposed method can be used to diagnose image classification models and provide language explanations for the failure modes.\n\nWeaknesses:\nThe major limitation is that the proposed approach assumes that the text-to-image and image-to-text models are perfect. However, if error happens in text-to-image synthesis or image captioning synthesis, then the results will not be reliable. For example, what if the text-to-image synthesis model generates an image of a bee with the caption \"a realistic photograph of a fly\"? The authors only discussed this issue in one paragraph in limitations, but I think this is an important issue that should be investigated deeper. How frequently do the text-to-image synthesis and image captioning models make mistakes, and how these mistakes will affect the results? How robust is the proposed approach?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The topic of incorporating large-scale text-to-image and image-to-text models for finding the failure cases of image classification models is novel. The authors provide details of the method for reproducing the results.\n",
            "summary_of_the_review": "My major concern is the robustness of the approach. If the text-to-image models and the image captioning models make mistakes, the results will be misleading. This approach assumes that the text-to-image and image captioning models are perfect, or at least the error rate is much smaller than the image classification model. But I suspect this assumption is not always true. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_38rC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2442/Reviewer_38rC"
        ]
    }
]