[
    {
        "id": "Xuhmw3XzR8",
        "original": null,
        "number": 1,
        "cdate": 1666678251654,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666678251654,
        "tmdate": 1667342829266,
        "tddate": null,
        "forum": "FRLswckPXQ5",
        "replyto": "FRLswckPXQ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1752/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of DP optimization in the convex setting. This paper considers the problem in the setting that the loss function  is smooth but not Lipschitz and the domain is not bounded. Instead the author assumes a growth condition which basically relates the gradient of a point to the optimal gap of that point.\n\nThen, under these conditions the authors show that noisy SGD can be used to achieve an optimization gap of sqrt(d)/sqr(n)eps. Also, assuming light tail noise for the gradients the optimization gap can be improved to sqrt(d)/n eps. \n\nTheir analysis provide an approach to better clip the gradients, and using this result the authors propose a practical algorithm DP-SGD.",
            "strength_and_weaknesses": "The paper is well-written and the results are clear. In general the paper is good and provides some new insights.\n\nQuestions:\n\n1)In the following paper the authors provide some lower bounds for DP optimization. In which they show that the boundedness of the diameter space is necessary. It should be discussed in the paper why the lower bound does not hold under the growth condition.\n \nBassily, Raef, Adam Smith, and Abhradeep Thakurta. \"Private empirical risk minimization: Efficient algorithms and tight error bounds.\" 2014 IEEE 55th annual symposium on foundations of computer science. IEEE, 2014.\n\n2) In Prop 4.2, the authors provide a \"uniform\" upper bound on the excess error of every iteration. This result and growth condition imply that we can choose a clipping norm such that with a high probability, we \"never\" clip the gradients. I think given that we are operating under this event, the standard convergence results for smooth convex function work. I want to understand how the analysis in the paper differs from this.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and very clear. The authors provide proof sketch in the paper which improves readability. ",
            "summary_of_the_review": "This paper considers the DP-Optimization problem. The main result is that under a natural growth condition, the lipschitzness and boundedness assumption can be removed and we can obtain a nearly optimal convergence rate.\nI think this paper is interesting.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_aq32"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_aq32"
        ]
    },
    {
        "id": "AeYukKmMRqo",
        "original": null,
        "number": 2,
        "cdate": 1666699189355,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699189355,
        "tmdate": 1666710663636,
        "tddate": null,
        "forum": "FRLswckPXQ5",
        "replyto": "FRLswckPXQ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper suggests convergence analysis of Differentially Private SGD with gradient clipping (DP-SGD-GC) in a smooth, unconstrained setting without bounded domain and Lipschitz continuity assumptions. Obtained results match the previously obtained bounds (for a more restrictive case) under an additional light-tail-noise assumption. In addition, the authors suggest a novel value-clipping technique and compare it to standard gradient clipping in a simple numerical study with neural networks on  MNIST and CIFAR-10 datasets.",
            "strength_and_weaknesses": "## Strengths\n\n- Removal of the restrictive bounded domain and Lipschitz continuity assumptions seems a novel and significant contribution.\n- Proposed Value Clipping may be practically useful for certain settings. There is a potential for better scalability in comparison to standard gradient clipping.\n\n## Weaknesses\n\n- Numerical results are quite simple which is fine for me, as the main contributions are theoretical. Though they serve a well-illustrative purpose.\n\n- Assumption 4.1 needs to be discussed in more detail. In my view, it is not enough to mention some not-very-recent references as the optimization field progressed quite a lot from that time. Namely, when does this assumption hold in practice? I see how it makes sense for a simple case of additive Gaussian noise for stochastic gradient estimates. But what are the assumptions on the distribution involved in the expectation? Does $i \\sim \\mathcal{U}[1, \\dots, n]$ or other mini-batch samplings (better suitable from a differential privacy perspective) fit into this framework?\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. The paper\u2019s main body is well-organized and easy to follow. The contributions are very clear and the proof sketch seems helpful and quite intuitive. Regarding the Appendix, I suggest giving more details for some of the proofs. E.g. in proof of Proposition 4.2, some steps are omitted. While they may be obvious for experts in the area, it would make it more accessible for a wider audience if some of the transitions were done more explicitly: like the first inequality for conditional expectation.\n\n2. I would like to ask the authors to compare their conclusions to the results of the paper [1] as it seems that there is a contradiction to their theses based on large-scale numerical studies. Namely, it was observed that for huge models the best performance is achieved for low clipping bounds and clipping happens almost always (especially for language models).\n\n3. The name growth condition used in Definition 3.1 seems confusing taking into account recent optimization literature on SGD. In the mentioned references GC usually refers to the following condition\n$$\n\\mathrm{E} \\||g(x)\\||^2 \\leq \\alpha \\||\\nabla h(x)\\||^2 + \\beta,\n$$\nwhere $g(x)$ is an unbiased stochastic gradient estimator of $\\nabla h(x)$. It would be better not to use this term or replace it.\n\n4. I suggest providing an example of DP-SGD utility bound with a non-vanishing bias term for unconstrained smooth problems for a better illustration of the theoretical contribution.\n\n5. Regarding the proposed Value Clipping technique I recommend adding a more explicit discussion of the limitations of this method for complex models when it can not be done analytically so easily. In addition, a commentary on possible hyper-parameter tuning overhead could be very valuable.\n\n6. It would be interesting to understand the privacy-utility trade-off given the results of this work. Because as far as I see (given the same privacy budget) higher clipping threshold requires adding Gaussian noise with a larger variance which can be detrimental to training. I understand that privacy is not the main focus of this work, but adding a discussion on it could be very helpful.\n\n___\n\n\n[1] Bu, Zhiqi, et al. \"Automatic clipping: Differentially private deep learning made easier and stronger.\" arXiv preprint arXiv:2206.07136 (2022).",
            "summary_of_the_review": "Overall this is a good submission with a strong theoretical contribution and a good practical potential worth accepting to a conference.\n\n**Minor comments**\n\nI would like to ask the authors to adjust some of the citations by using the `\\citet` LaTeX command not to duplicate text. Especially in the Related Work section.\n\nSmall typos on page 18 (top): lower indexes for $z_t \\to z_i, u_t \\to u_i$ and $Z_{T-1} \\to Z_{t-1}$",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_bKYj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_bKYj"
        ]
    },
    {
        "id": "DBzUnSA80D",
        "original": null,
        "number": 3,
        "cdate": 1666772777423,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666772777423,
        "tmdate": 1666772824776,
        "tddate": null,
        "forum": "FRLswckPXQ5",
        "replyto": "FRLswckPXQ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper provides a convergence analysis of DP-SGD and proposes a certain value-clipping method as an alternative to gradient clipping of DP-SGD. The convergence analysis leads to the same or better asymptotics than state-of-the-art results with slightly weaker assumptions, and the value-clipping leads to faster compute with similar experimental results however requires certain growth condition to be satisfied (for the loss function).\n\nThe convergence analysis relies on the assumption that the SGD noise of the gradients is 'light-tailed' meaning it is sub.Gaussian and also on the RDP analysis of the subsampled Gaussian mechanisms provided by Abadi et al. (2016) which connects the level of DP noise and epsilons. This way convergence bounds w.r.t. epsilons and deltas can be provided. ",
            "strength_and_weaknesses": "Pros:\n\n- The paper is generally well written and easy to follow.\n- The convergence analysis seems solid, it is impressive that same asymptotics are obtained as in (Bassily et al., 2014) for Lipschitz continuous loss functions.\n\nCons:\n\n- The value clipping part is perhaps a bit weak part of the paper, e.g. the drop in test accuracy for MNIST is quite big (around 5%).\n- Experiments could be improved: instead of showing all those training accuracy figures, would be more interesting to see how the value clipping behaves for different values of $\\sigma$ and different values of $\\varepsilon$.\n- Some parts are a bit unclear, the presentation could be improved here and there. Let me elaborate:\n\nHow are actually the growth condition parameters $\\beta_1$ and $\\beta_2$ determined for the neural networks? I looked at Appendix E, and I only see bounds on the gradients, but there is nothing that explicitly says how to a priori bound $\\beta_1$ and $\\beta_2$. Could you elaborate on this and explicitly show how to determine them? How big is then the gap to the actual gradient norm, i.e. how loose are the bounds?\n\nYou write: \"The value clipping step (line 4 of Algorithm 3) can be realized within one forward-backward propagation if the GC parameters are given in advance. Therefore DP-SGD-VC can be as fast as the vanilla SGD algorithm.\"\n\nBut are they given in advance in the experiments? Or do you compute them using the expressions of Appendix E at each iteration? As far as I see, to have rigorous DP guarantees, that is required.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally clearly written and all the math I checked is correct. \n\nHere few more points about the writing, I believe these can be easily fixed:\n\n- You mention in Alg. 1 that \"Uniform randomly sample a batch $B_t$ with size $B$...\" However, the results of (Abadi et al., 2016) holds for the Poisson subsampling, which you do not mention in the paper. To keep things rigorous, I think this should be added/corrected.\n\n- In the first paragraph of 'NUMERICAL STUDY' Section you mention: \"In Appendix, we also present some experimental results on synthetic data with light-tailed noise.\" Does this mean that the SGD noise in the MNIST/CIFAR-10 experiments is not sub Gaussian? I.e., the theory does not hold here? If so, I think would be better to state it more directly.\n\n- Why is the main algorithm called DP-SGD-GC, when DP-SGD is a widely used acronym for the very same algorithm?",
            "summary_of_the_review": "All in all, I feel this is a borderline case and I hope the authors can clarify some of my concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_49Nb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1752/Reviewer_49Nb"
        ]
    }
]