[
    {
        "id": "-jaBiZfEJss",
        "original": null,
        "number": 1,
        "cdate": 1665693948926,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665693948926,
        "tmdate": 1665693948926,
        "tddate": null,
        "forum": "rUb1-7H4q6a",
        "replyto": "rUb1-7H4q6a",
        "invitation": "ICLR.cc/2023/Conference/Paper4913/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a technique for removing data points for standard supervised learning problems. Their best performing method partially drops data from a class with a sufficient F1 score, and shows that they can train on ~6M total less data points while only reducing ImageNet accuracy by 1 percentage point. ",
            "strength_and_weaknesses": "Strengths: Method is well motivated and an ablation is performed on each of their design decisions.\n\nWeaknesses:\n- I found the comparisons to the baselines to be very unclear. For instance, in Table 1 there are various different architectures, values of epochs, and # of datapoints, such that it is not really clear how to compare properly to baselines. So, while the method is sound, it would be extremely useful to see a comparison where the task, architecture, RT, and datapoints are matched to make a comparison.\n\nComments & Questions:\n- May be good to discuss related work such as [1,2].\n- How would the method be extended to large datasets which are often unlabelled?\n\n[1] https://arxiv.org/abs/2107.07075\n[2] https://arxiv.org/abs/2206.14486",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of presentation (clarity + quality) I enjoyed how Section 5 ablates on each element of the method. In terms of novelty I did not understand \"we do not compare with those which are so domain-/application-specific as to not be applicable to standard image classification benchmarks\" and would appreciate more detail there.",
            "summary_of_the_review": "The paper is well motivated and performs careful ablations, however, the comparison to prior methods was extremely hard to follow and discussion of key related work was missing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_tLVt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_tLVt"
        ]
    },
    {
        "id": "6Wjzqso_Km",
        "original": null,
        "number": 2,
        "cdate": 1666620080957,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620080957,
        "tmdate": 1666620080957,
        "tddate": null,
        "forum": "rUb1-7H4q6a",
        "replyto": "rUb1-7H4q6a",
        "invitation": "ICLR.cc/2023/Conference/Paper4913/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a progressive data dropout (PDD) framework that gradually discards the majority of the samples for already-accurate classes, in order to speedup the training. There are other design choices including warmup, residue and swapout. Experiments on MNIST, CIFAR, SVHN and ImageNet are performed.",
            "strength_and_weaknesses": "Strengths:\n-- The data dropout idea is well-motivated - time or \"datapoints\" spent on different classes does not have to be equal. Some classes may add little value once they are learned and it makes sense to discard them and save time.\n\n-- The experiments are performed on multiple datasets of different sizes and compared with various previous methods.\n\nWeaknesses:\n-- The results on MNIST, CIFAR and SVHN do not convincingly demonstrate the effectiveness. The time spent is drastically reduced but the accuracy is also hurt, sometimes by large margins. The comparison are done usually without controlling the time or accuracy so it is hard to draw useful conclusions. \n\n-- The baseline ResNet-18 accuracy of CIFAR-10 is at 77%. This should be around 88% instead for ResNet-18 with a reasonable recipe. It is thus hard to judge the reliability of the results given the baseline may be too suboptimal.\n\n-- On the larger scale ImageNet experiments, the saved time is too minimal (less than 1%) when the accuracy is maintained.",
            "clarity,_quality,_novelty_and_reproducibility": "The method was simple and presented clearly. The idea to drop almost entire classes seems novel. The code is in the supplement.",
            "summary_of_the_review": "Given the insignificance of the results I recommend rejection. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_De4X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_De4X"
        ]
    },
    {
        "id": "zcx1dGSP65",
        "original": null,
        "number": 3,
        "cdate": 1666650278274,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650278274,
        "tmdate": 1666723862702,
        "tddate": null,
        "forum": "rUb1-7H4q6a",
        "replyto": "rUb1-7H4q6a",
        "invitation": "ICLR.cc/2023/Conference/Paper4913/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper works on the problem of progressive data pruning, in which you attempt to reduce the number of images (in absolute quantity) during training. They do this by subsampling according to class using a dropout score, which is related to the performance of the network on a particular class in the training set. The introduce a hyperparameter (training threshold), which determines when data should be dropped wrt the dropout score. ",
            "strength_and_weaknesses": "\n##### Strengths\n\n- Method is intuitive and easy to understand.\n- Problem relevance is apparent, reducing training time would have immediate impact.\n\n##### Weaknesses\n\n- Table 3 shows that the author's reimplementation of their baseline was flawed. The results of the existing data dropout paper are reproducible.\n- It's very unclear what Tables 1 & 2 are supposed to convey. There are no comparable comparisons in any of these experiments. The authors should fix an architecture and see how many data points it takes to train to the _same accuracy_. As it is, with variations in architecture, final model performance, and # of data points, we can't draw any conclusions from these tables.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nPaper was readable and the method was understandable. However, the experimental setup was quite confusing (covered in weaknesses).\n\n**Novelty**\n\nThe method seems novel. \n\n**Reproducibility**\n\nReproducibility unclear. The author's seem to have not reproduced their baseline properly, however they did provide code which seems readable. Have not assessed in detail.\n",
            "summary_of_the_review": "I vote to reject.\n\nTheir primary experiments are flawed. As is, we cannot to properly assess the efficacy of their method (see Weaknesses for suggestions to improve).\n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_9Ung"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_9Ung"
        ]
    },
    {
        "id": "NeTuwMZEau2",
        "original": null,
        "number": 4,
        "cdate": 1667014807322,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667014807322,
        "tmdate": 1667014807322,
        "tddate": null,
        "forum": "rUb1-7H4q6a",
        "replyto": "rUb1-7H4q6a",
        "invitation": "ICLR.cc/2023/Conference/Paper4913/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel, adaptive strategy to drop classes from the dataset during training based on the f1 score of the model. They show that their approach, Progressive Data Dropout (PDD), is able to achieve similar test/val accuracies while using significantly lower data and time to train on image classification tasks.",
            "strength_and_weaknesses": "# Strengths\n- The paper is very well written and easy to comprehend.\n- The problem tackled by the paper is very interesting and important to the community as it could speed up training significantly.\n- The approach presented is novel to my knowledge and explores an interesting direction that I haven't seen before.\n\n# Weaknesses\n- The results are difficult to parse. It's really hard to compare the different approaches since they are trained for a different number of rounds using potentially different models. \n- There also seems to be a significant cost in accuracy to using PDD.\n- Why do the alternative data-dropping strategies achieve higher test accuracy than even the baseline? It seems like the baseline should be the best approach since it has access to the most data.\n- There should be more experiments with different model architectures.\n- There are no standard errors in the results.",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper was very clear and easy to comprehend.\n- The quality of the paper is not very high since the results don't clearly show the advantage of this approach.\n- The approach is novel to my knowledge.\n- I did not attempt to reproduce any of the experiments in the paper.",
            "summary_of_the_review": "While the approach considered in the paper is interesting and novel to my knowledge, the results leave much to be desired. The baseline approach considered seems considerably worse than expected, especially compared to the alternatives from the literature. There also seems to be a significant cost to using PDD in the final test/val accuracy of the model.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_YwiM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4913/Reviewer_YwiM"
        ]
    }
]