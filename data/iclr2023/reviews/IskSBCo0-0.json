[
    {
        "id": "RyR1XGAWoG",
        "original": null,
        "number": 1,
        "cdate": 1666445792967,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666445792967,
        "tmdate": 1669470949211,
        "tddate": null,
        "forum": "IskSBCo0-0",
        "replyto": "IskSBCo0-0",
        "invitation": "ICLR.cc/2023/Conference/Paper5415/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the problem of differential private machine learning (DP ML) and propose to aggreagate the checkpoint (intermediate parameters during training) for test time inference. On the experimental sides, the paper conduct experiments over standard dataset like CIFAR10 and stackoverflow and their methods improve the accuracy around 1% to 3%. It also provides some theory on convex optimization and demonstrate the advantage of averaging instead of using only the last iteration.\n\nMethod. The paper proposes to aggregate the checkpoint in a few ways: (1) average parameter (exponential averaging or uniform averaging) and (2) aggregate the output (majority vote or averaging). The DP guarantee follows directly as they are post-processing\n\nExperiments. The paper conduct experiments over CIFAR10 and stackoverflow, in both centralized setting and federated setting. I am not a specialist in experiments but the improvement seems solid/consistent, but marginal at the same time.\n\nTheory. The paper shows averaging is better than the last-iteration in the constrained convex optimization setting. It provides good insight. However, technically, their method just plug-in and play the bounds of [Shamir and Zhang'13], and they also fail to show a lower bound (this means it is not really a separation between averaging and plug-in and play, in contrast with [Shamir and Zhang'13]). Moreover, in the convex optimization setting, there are many DP gradient descent type algorithm that uses averaging, so it is not novel.\n\n",
            "strength_and_weaknesses": "Strength. Overall, I think this is a solid paper with consistent and extensive experiments. It also provides some theory explaining the insight of their method.\n\nWeakness. (1) The aggregation of checkpoint seems to be fairly straightforward idea of post-processing. (2) The experiment improvement seems marginal. (3) The theory only explains the insight at the convex optimization domain, as I mentioned, there are a tons of related literature and I believe they have better rate in convex optimization setting.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, the idea seems to be new.",
            "summary_of_the_review": "This a solid paper, but the idea/improvement seems to be marginal for a ICLR paper.\n\n--------------------------------------------------------------------------------\n\nPost rebuttal\n\nI have read the rebuttal and my evaluation remains.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_374t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_374t"
        ]
    },
    {
        "id": "Ax0UM_bZaI",
        "original": null,
        "number": 2,
        "cdate": 1666671088753,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671088753,
        "tmdate": 1666671088753,
        "tddate": null,
        "forum": "IskSBCo0-0",
        "replyto": "IskSBCo0-0",
        "invitation": "ICLR.cc/2023/Conference/Paper5415/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies re-using the intermediate checkpoints during DP training for two purposes: 1. improve the accuracy; 2. construct reasonable uncertainty quantification. The contribution is on the methodology and empirical results.",
            "strength_and_weaknesses": "Strength: This paper is clearly presented. The contribution is solid and the experiments are convincing and well-designed. The new method has no cost in terms of privacy guarantee, improves the accuracy, does no incur additional computation, and particularly the UPA trick is better than EMA in that no additional hyperparameter $\\beta_t$ needs extra privacy budget to tune honestly.\n\nWeaknesses: I have some concerns on the novelty (see details in next comment) and not comparing carefully to existing work. For example, although the work claims above Section 2.3.3 \"we improve the SOTA baseline of De et al. (2022) from 70.6% to 75.51% at \u03b5 = 1 and from 77.6% to 80.8% at \u03b5 = 8\". De et al. is not SOTA: CIFAR100 has achieved 83.0% at \u03b5 = 1 and 88.4% at \u03b5 = 8 without using any checkpointing like EMA, by \"Scalable and Efficient Training of Large Convolutional Neural Networks with Differential Privacy\". Testing on this setting is important.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of this paper is solid and the clarity is good. My concern on the novelty of uncertainty quantification with DP, which has been studied in [1] (see Section 5). Therefore the argument in Section 3 \"(Naive) uncertainty quantification, and its hurdles\" are already known results. [1] studies DP-SGLD which includes DP-LD in this work's Section 3 as a sub-case. Though this work provides some theoretical analysis, using DP Bayesian approach to do uncertainty quantification is not new.\n\nAlso, using checkpoints is already explored as in EMA and DP-SGLD in [1][2] (e.g. Algorithm 2 in [1], the output line), whose computational advantage over multiple runs is clear so some novelty is comprised too.\n\n\n\n[1] Bu et al. \"Differentially Private Bayesian Neural Networks on Accuracy, Privacy and Reliability\" (https://arxiv.org/pdf/2107.08461.pdf). \n[2] Li et al. \"On Connecting Stochastic Gradient MCMC and Differential Privacy\" (https://arxiv.org/pdf/1712.09097.pdf)",
            "summary_of_the_review": "Overall I think this is a borderline paper and needs non-trivial revision on the related work discussion and experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_PDAE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_PDAE"
        ]
    },
    {
        "id": "WPZ0V0LTZZ",
        "original": null,
        "number": 3,
        "cdate": 1667559285414,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667559285414,
        "tmdate": 1670805477472,
        "tddate": null,
        "forum": "IskSBCo0-0",
        "replyto": "IskSBCo0-0",
        "invitation": "ICLR.cc/2023/Conference/Paper5415/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper investigates whether aggregating intermediate checkpoints of DP-SGD algorithms enable better privacy-accuracy trade-off and uncertainty estimate (when compared to those of last-iterate model). They provide empirical evidence that a variety of check point aggregation methods enables improved test accuracy for centralized and federated learning tasks. They also show that for strongly convex smooth loss function, check-point aggregation enables accurate variance estimate for bounded statistics of last-iterate model. This estimation error decays exponentially with the burn-in time and the minimum interval between any two sampled checkpoints. ",
            "strength_and_weaknesses": "Strengths:\n- Averaging intermediate models is a promising direction for improving privacy-accuracy trade-off for differentially private learning.\n- Utilizing checkpoints for uncertainty estimates is an attractive methodology that may enjoy lower computation cost.\n\nWeaknesses:\n- In terms of empirical result, it's not really clear what averaging method one should use and why. In the paper, the various aggregation methods (including one method from existing work De et al.) perform similarly for most tasks. For a few tasks where the differences between methods are more significant, the winning method is also not consistent. The authors may want to clarify why their methods are better than prior works for certain tasks but not others. How does this depend on the data distribution or learning tasks?\n- In terms of theoretical results, to my understanding, the paper's main contribution is Theorem 3.1. which shows improved uncertainty (variance) estimate as the burning time and intervals between checkpoints increase. However, I do not see the effect of the number of checkpoint models in this theorem. It's not clear whether we should use more checkpoints for variance estimation and why. \n- In terms of the motivation of using checkpoints for uncertainty estimate, the authors emphasize computation efficiency of re-using checkpoints when compared to training multiple independent last-iterate models. However, the total number of training epochs increase in order to produce good quality checkpoints (with reasonable interval between them). These computations are not parallelizable. I think the authors need to support this motivation with more evidence, e.g., how much is the additional computation cost for longer training? Is it negligible when compared to multiple independent runs of the training algorithm (which could be done in parallel)?",
            "clarity,_quality,_novelty_and_reproducibility": "Some authors' statements need more support . After Theorem 3.1, the authors claims that \n> Per Harvey et al. (2019), in general this log(n) factor cannot be removed by a better analysis of the last iterate of DP-SGD as instantiated in Theorem 2.1.\n\nHowever, Theorem 2.1. does not provide any technical lower bound that about why the log(n) factor \"cannot\" be removed. The reference Harvey et al. (2019) also does not provide any privacy analysis. Therefore it is difficult to understand how this statement is supported. The authors may want to add more detailed explanations. Finally, it is not clear what \"in general\" means. The authors may want to clarify the conditions for this claim, and add more reference for other settings where the log(n) factor could be removed, such as [a] [b] and [c]. Otherwise, the current claim is too strong and potentially misleading.\n\n[a] Jain, P., Nagaraj, D., & Netrapalli, P. (2019, June). Making the last iterate of sgd information theoretically optimal. In Conference on Learning Theory (pp. 1752-1755). PMLR.\n[b] Feldman, V., Koren, T., & Talwar, K. (2020, June). Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing (pp. 439-449).\n[b] Chourasia, R., Ye, J., & Shokri, R. (2021). Differential privacy dynamics of langevin diffusion and noisy gradient descent. Advances in Neural Information Processing Systems, 34, 14771-14781.",
            "summary_of_the_review": "The paper shows interesting potential of using intermediate model aggregation to improve privacy-accuracy trade-off and uncertainty estimate of differentially private learning. However, at current state, the paper does not offer clear investigation of which aggregation method works best in different setting and why. And the paper's Theorem 3.1, motivation for aggregating checkpoints, and some of the claims need more support and explanations. Therefore, my assessment is borderline.\n\n\n======\nPost authors' response\n\nMy main concern is still that the paper still needs better (more consistent) explanations for the gain in privacy-utility trade-off or uncertainty estimate by utilising intermediate checkpoints.\n\n=====\nResponse to author's followup comments:\n> The increase in training process length is unavoidable for a worst-case analysis; even for a simple loss such as a one-dimensional quadratic loss, obtaining k near-independent samples from a distribution close to the distribution of DP-SGD\u2019s outputs using o(k) times the number of gradient accesses as a run of DP-SGD (i.e., o(k) times the privacy budget) would violate privacy lower bounds.\n\nI appreciate the authors' lower bound argument. But at the current form, it needs more explanation, perhaps a formal statement and some references, to be interpretable and convincing. \n\nSecondly, \"obtaining k near-independent samples from a distribution\" is not a necessary condition for good uncertainty estimate. There are many uncertainty estimation methods, such as MC-dropout, that rely on correlated samples. The idea of using intermediate checkpoints intrinsically may involve analyzing how to use correlated samples and their benefits. Reducing the analysis to nearly-independent runs of MCMC (via large checkpoint interval) lack the perspective for explaining the advantage of performing checkpoint aggregation compared to independent runs of the training (fine-tuning) process. \n\n> We disagree with this performance analysis of UPA (i.e., uniform tail average). First note from Tables 1 to 3 and Figures 1 and 2 that UPA always performs better than the last checkpoint by large margins. Furthermore, note from Tables 1 and 2 that for the Stackoverflow dataset, UPA always performs better than all other aggregation methods.\n\nIn Table 1 and Figure 1 for the performance of UPA: For CIFAR10, under epsilon = 8, the performance improvement of UPA is 2.21%, which is only 0.33% larger than the standard deviation of the baseline (1.46%) plus the standard deviation of UPA (0.52%). Therefore, this test accuracy improvement almost falls in the range of standard deviation, which is marginal. For stackoverflow, in Table 1, the test accuracy improvement of UPA is below 0.5%, which is marginal. \n\nThe test accuracy gain of UPA in Table 2-3 and Figure 2 is indeed more significant. However, the experiments for Table 2 and 3 and Figure 2 are under periodic distribution shift or data-dependent checkpoints aggregations, which the current Theorem 2.1 does not apply to. To explain the benefits in Table 2 and 3 and Figure 2, the authors would need new analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_J6hu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5415/Reviewer_J6hu"
        ]
    }
]