[
    {
        "id": "FZC3DM4UGUr",
        "original": null,
        "number": 1,
        "cdate": 1666572096021,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666572096021,
        "tmdate": 1666572096021,
        "tddate": null,
        "forum": "ashPce_W8F-",
        "replyto": "ashPce_W8F-",
        "invitation": "ICLR.cc/2023/Conference/Paper964/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a detailed and comprehensive theoretical analysis to the problem that existing DRO approaches do not bring significant performance gain over ERM. The analysis focus on the GRW framework that minimizes the weighted empirical risk. The authors show that for linear models and wide neural networks, the resulting model yielded by GRW is closed to that obtained by ERM on both regression and classification tasks, namely, GRW does not improve over ERM. The authors further show that the effect of adding small regularization is of no help on alleviating this problem. With the theoretical results, principal ways are presented to improve DRG.",
            "strength_and_weaknesses": "Strength: The theoretical analysis is comprehensive and convincing, which I believe could bring new insights to the community in designing DRO methods. The authors also conduct experiments to support their theoretical results.\nWeaknesses: As the authors have pointed out, the analysis relies on some strong assumptions, which could be the major weakness of this work. Besides, previous work [1] has the similar results that minimizing the weighted empirical risk is equivalent to minimizing the vanilla empirical risk. The author should make comparison and explain the differences in detail. I also wonder whether the linearly independent gradients assumption in Theorem 4 could be satisfied in real applications.\n\n[1] Does Distributionally Robust Supervised Learning Give Robust Classifiers? Weihua Hu, Gang Niu, Issei Sato and Masashi Sugiyama.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well organized and easy to follow. This work is of good quality with convinced theoretical results. The novelty seems to be incremental since a related reference is omitted (See weaknesses). Considering that this is a theory work and there is no new proposed method, reproducibility is not appliable.",
            "summary_of_the_review": "This paper studies a vital problem that existing DRO approaches do not bring significant performance gain over ERM from theory perspective. The authors provide detailed analysis of two representative models, linear models and wide neural networks, on regression and classification tasks. Experiments are also provided to support the results. My major concern is the relation between this work and previous work (See weaknesses). The authors are encouraged to provide detailed comparison and explain the differences.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper964/Reviewer_Zc4T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper964/Reviewer_Zc4T"
        ]
    },
    {
        "id": "Y1sAPZjB-3G",
        "original": null,
        "number": 2,
        "cdate": 1666659052470,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659052470,
        "tmdate": 1666661587984,
        "tddate": null,
        "forum": "ashPce_W8F-",
        "replyto": "ashPce_W8F-",
        "invitation": "ICLR.cc/2023/Conference/Paper964/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies whether generalized reweighing algorithms can improve out-of-distribution generalization.\n\nFirst, it defines \"generalized reweighting\", and then shows that generalized reweighting algorithms have the same implicit bias as ERM, meaning the model converges to the same parameters given the same initial training point.\u00a0\n\nThis paper proves this result for both regression and classification with overparameterized linear models (including L2 regularization) and wide neural networks.\n\nFor linear models, the theorems are more straightforward.\n\nThe theorems for the wide neural nets are based on the theoretical results of neural tangent kernels.\u00a0",
            "strength_and_weaknesses": "Strength\n\n- This is a very important and interesting problem.\n\n- the introduction is well-written.\u00a0\n\n- The paper clearly states what it contributes and how it relates to existing papers.s.\n\n- The paper clearly states its limitations.\n\nMain weakness\n\n- After reading this paper, I don\u2019t think I gained an intuitive understanding of why generalized reweighting does not improve over erm.\nIt would make the paper more accessible to a wider audience if parts of the paper were devoted to explaining these technical descriptions in plain English.\n\nMinor points\n\n- Currently, the related work section appears to be an afterthought. It appears in the appendix and does not explain how this work fits into existing literature.\nAs an example, in the section on group fairness, it is unclear how the subpopulation shift problem in this paper is related to group fairness. It does not specify how this work relates to these papers.\n\n- Furthermore, there is a large literature on distribution generalization, which is not included in this paper. Of course, there is no need for the authors to cite every paper in a\u00a0 growing field. However, I would like to see some examples of what constitutes a generalized reweighing algorithm and what does not.\n\n- Some jargons are not well defined (e.g., sub-population shift, implicit bias)\n\nOverall, I like the motivating problem and think this could be a high-impact piece of work. The paper could be improved if some of the issues outlined above were addressed.\n\nI am willing to change my score if the issues mentioned are addressed.",
            "clarity,_quality,_novelty_and_reproducibility": "see above ",
            "summary_of_the_review": "This paper provides a theoretical analysis of why some DRO algorithms do not improve over ERM. There is a good motivation for the problem and it is an important one;  the main paper is somewhat clear.  The main problem is that the paper does not provide intuitive explanations but instead relies only on technical theorems to answer the motivating questions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper964/Reviewer_ZGFE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper964/Reviewer_ZGFE"
        ]
    },
    {
        "id": "Qja3DmbwBT",
        "original": null,
        "number": 3,
        "cdate": 1666659368738,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659368738,
        "tmdate": 1666659486778,
        "tddate": null,
        "forum": "ashPce_W8F-",
        "replyto": "ashPce_W8F-",
        "invitation": "ICLR.cc/2023/Conference/Paper964/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the phenomenon that Generalized Reweighting (GRW) and distributionally robust optimization (DRO) do not significantly improve over ERM in real applications with distribution shift. This paper shows for a linear model or an NTK\nneural network trained with GRW, the resulting models are close to that obtained by ERM. This paper also shows that L2 regularization only works when it is large enough to lower the training performance. The empirical results verify the arguments in this paper.\n",
            "strength_and_weaknesses": "### Strengths:\n- Distribution shift is common in real-world applications and reweighting is a popular method to deal with this problem. Thus, understanding whether GRW is useful and why is of great importance.\n- This work extends the previous theoretical results to the settings: (1) wide neural networks. (2) general reweighted algorithm (3) both regression and classification tasks. The extensions are non-trivial.\n- The results are well-supported and instructive, which deepen our understanding of GRW.\n\n### Weaknesses:\n- About the strong assumption: as the authors have discussed in Section 6.2, the results of this paper are established on assumptions that the models are linear or wide NN. Based on the assumption, GWR is shown to share similar implicit bias with ERM. I am concerned that these assumptions are too strong to explain the empirical observations for DNN. For example, the proposed GRW also takes the importance weighting algorithm as an example, but with the DNN model, the method is shown to be empirically effective for distribution shift problems by updating the weight dynamically [1]. In this sense, the significance of the proposed theorems seems limited to me.\n\n- About the GRW with L2 regularization: I am not sure whether Theorem 6 can support the claim that GRW does not achieve better DRG than ERM. Then theorem has shown that with a small regularization, the GWR will have a similar testing performance as ERM. But, when the regularization is large, the performance GWR could be different from ERM. Although the training error of GWR (with large regularization) could be worse than ERM, the comparison of their testing performance is still unclear.\n\n- A similar conclusion that DRO will perform just like ERM has also been drawn by the previous work [2]. Their analysis is independent of the model. I think it would be important to provide a discussion on the difference between the two works.\n\n[1] Rethinking Importance Weighting for Deep Learning under Distribution Shift. T Fang, N Lu, G Niu, M Sugiyama.\n[2] Does Distributionally Robust Supervised Learning Give Robust Classifiers? W Hu, G Niu, I Sato and M Sugiyama.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: this paper is well-structured and clearly written. Discussions on the future direction and the limitation are provided.\n\n- Quality: the results provided by the paper seems correct, but the assumptions are strong to me.\n\n- Novelty: a similar conclusion that DRO performs like ERM has been shown in the previous work. But the paper has shown more general results for general reweighting algorithms and wide NN.\n\n- Reproducibility: proofs for the theorems are provided.\n",
            "summary_of_the_review": "This paper has shown that the general reweighting algorithm does not necessarily achieve better robustness than ERM. The analysis of GRW framework is novel to me, and the results are solid. My main concern is that the paper has made strong assumptions about the linear or wide NN model. It is unclear whether the results still hold when extended to the DNN (please see the first point of the weaknesses for more details). Besides, the significance of Theorem 6 is unclear to me (second point of the weakness). I will raise my score if the authors can provide a convincing response to the concerns. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper964/Reviewer_NJFN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper964/Reviewer_NJFN"
        ]
    },
    {
        "id": "UqnTKev3gn",
        "original": null,
        "number": 4,
        "cdate": 1666834413264,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666834413264,
        "tmdate": 1666834413264,
        "tddate": null,
        "forum": "ashPce_W8F-",
        "replyto": "ashPce_W8F-",
        "invitation": "ICLR.cc/2023/Conference/Paper964/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "From a theoretical viewpoint, this paper studied Generalized Reweighting (GRW) algorithms that include importance weighting and Distributionally Robust Optimization (DRO) variants, which were designed for learning with a distributional shift. The authors showed that when used to train overparameterized linear models or wide NN models, GRW algorithms do not improve over ERM due to the existence of implicit biases. It is also shown that adding small regularization which does not greatly affect the empirical training accuracy cannot help. Based on the theoretical results, it is concluded that to pursue distributionally robust generalization, one needs to develop non-GRW approaches or devise novel classification/regression loss functions that are adapted to GRW approaches.",
            "strength_and_weaknesses": "Strength:\n\n1. The authors conducted a systematic study to theoretical understand why generalized reweighting does not improve over ERM. The results may apply to various existing reweighting schemes. \n2. The conclusion of the paper is useful and inspiring. It may lead to more future work on addressing the related robust learning problems.\n\n\nWeaknesses:\nNone identified.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and well presented. The established theoretical results are novel, and the contributions are solid. ",
            "summary_of_the_review": "See above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NONE",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper964/Reviewer_cgwJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper964/Reviewer_cgwJ"
        ]
    }
]