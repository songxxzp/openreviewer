[
    {
        "id": "LC89-Jyam6",
        "original": null,
        "number": 1,
        "cdate": 1666050669571,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666050669571,
        "tmdate": 1666050669571,
        "tddate": null,
        "forum": "Idusfje4-Wq",
        "replyto": "Idusfje4-Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper3326/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a more efficient approach for finding a topological ordering based on identifying low variance entries along the diagonal of the Hessian of the log density. Unlike the previous approach, this method does not require iteratively reestimating the entire Hessian to identify each leaf node. The approach is implemented using diffusion models, since they approximate the score function. The resulting method performs comparably to the previous state of the art but is more efficient in high dimensions.",
            "strength_and_weaknesses": "Strengths:\n- New theoretical insights are provided, which generalize the results from Rolland et al. (2022) \n- A more efficient algorithm is provided \n- Empirical results demonstrate the gain in efficiency \n\nWeaknesses:\n- Too much emphasis on the diffusion models aspect makes the contribution confusing (see below)\n- More explicit connections between the technical results and the correctness of the algorithm would improve clarity ",
            "clarity,_quality,_novelty_and_reproducibility": "While the paper makes two solid technical contributions, they are somewhat obscured by the paper\u2019s overemphasis on diffusion models (currently a hot topic in generative modeling), which have more to do with the implementation that the novel contributions. Ultimately, the paper (i) extends the results from Rolland et al. (2022) to not require Gaussianity assumptions and (ii) introduces a more efficient way of computing the elements along the diagonal once given access to the score function using backpropagation. While this is described as \u201cdiffusion models for causal discovery\u201d, diffusion models are only leveraged for their estimates of the score function (as opposed to their generative modeling capabilities) - any nonparametric density estimation approach (with backprop) could be used in place of the diffusion model. Ultimately, this is an advantage of the approach, but the treatment of diffusion models as a necessity related to the contribution (rather than a means for implementation) impacts the overall clarity.",
            "summary_of_the_review": "The paper proposes an improvement to causal discovery based on estimating the variance of the Hessian log density diagonal that generalizes the causal discovery method and improves efficiency. The paper makes two core technical contributions and empirical results demonstrate the gain in efficiency. The clarity of the paper could be improved to emphasize the specific contributions made and the role (and necessity) of diffusion models in the proposed approach.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_vVJW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_vVJW"
        ]
    },
    {
        "id": "Mwq2w8lgIxF",
        "original": null,
        "number": 2,
        "cdate": 1666633540854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633540854,
        "tmdate": 1668818227523,
        "tddate": null,
        "forum": "Idusfje4-Wq",
        "replyto": "Idusfje4-Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper3326/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The structure of the Hessian of the data log likelihood carries information about topological ordering.  Since this information is learned by score based generative models, DPMs carry within them information necessary to reconstruct topological orderings.  The paper runs with this insight to obtain a practical algorithm with interesting scaling properties for causal discovery.",
            "strength_and_weaknesses": "Strenghts:\n* The paper presents a timely analysis of how causal relationships may be uncovered using diffusion models.  Given that both causality and diffusion models are of interest to many in the community, the possible connections are certainly on the minds of many (including my own!).  \n*The paper runs with this direction and does a very nice job rigorously establishing some of what is possible with the Hessians of the log densities learned within diffusion probabilistic models.\n*The paper is clearly written and the was enjoyable to read.\n\nWeaknesses:\n* Why not do the same analysis on a Gaussian kernel density estimate (KDE) of the data distribution? In my opinion, the paper is unpublishable without explicitly acknowledging this alternative route to the same ends, and how it would compare to the proposed method involving diffusion models.  In particular, in the limit of a large enough network / good enough optimization the Hessians computed coincide with what would obtain with the KDE.  So why go through the trouble of the diffusion model?  And is there anything special about diffusion models in this paper other than the fact that they provide computationally tractable Hessians (which is also possible with energy based and likelihood based models)?\n* There may be good reasons to use a neural network here (e.g. amortization of Hessian computation, or the generalization properties may lead to better estimates of the Hessians of the population distribution as compared to the KDE). But these possibilities should be made explicit.  Without acknowledging that the approach involves what may be viewed as an approximation of something that may in principle be computed analytically, I view the paper as disingenuous.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and the application of diffusion models for topological ordering is novel.\n\nThe theory around uncovering the topological ordering appears fairly generic to me.  And I did not understand what aspects of it were novel.  Could the authors say more about how their theory relates to prior work? E.g. in what sense is Lemma 1 \u201cmore general\u201d than Rolland 2022; I would have thought that the restriction to constant second-order derivatives would make the present result _less_ general by comparison.",
            "summary_of_the_review": "Please provide a short summary justifying your recommendation of the paper.\nThe paper rigorously explores a topic of interest to the community but does not comment on what would seem to me to be a more direct approach to solving the same problem (i.e. using a KDE).  The authors should comment on such alternatives to computing / approximating these Hessians that do not rely on diffusion models.\n\nIf the authors do not provide an explanation for why other approaches to computing the Hessian are ill-suited, or discuss how they might be applied here instead, I will significantly lower my score (to a reject recommendation).\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_YaE5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_YaE5"
        ]
    },
    {
        "id": "g5jc9M9zFx",
        "original": null,
        "number": 3,
        "cdate": 1666675655804,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675655804,
        "tmdate": 1670096304030,
        "tddate": null,
        "forum": "Idusfje4-Wq",
        "replyto": "Idusfje4-Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper3326/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers non-linear causal discovery under the same setting as Rolland et al., (2022). The authors proposed to replace the scoring function in the SCORE method proposed by Rolland et al., (2022) with diffusion probabilistic models (DPMs). This allows them to update the learned Hessian without re-training the neural network and perform ordering over a batch, and thus they can large-scale data at a relatively faster speed. However, in total, the novelty of the approach and the profound impact are both limited. In addition, the main methodology and numerical results require additional justification.",
            "strength_and_weaknesses": "*Strength*\n\n- The paper considers an important problem in causal discovery and leveraged a popular machine-learning tool.\n\n*Weaknesses*\n\n- The proposed DiffAN method highly depends on the SCORE method proposed by Rolland et al., (2022), by replacing the scoring part with diffusion probabilistic models (DPMs). More justification on novelty is needed. For instance, can the authors comment on if their method can be extended to other causal discoveries for non-linear models? In addition, please comment on why we cannot decouple DPMs from the SCORE method and consider a new causal discovery method built upon DPMs. I am also curious whether DPMs are really necessary for this approach. Why not consider other deep learning approaches since we are not handling images/texts?\n\n- Although firstly introducing DPMs into causal discovery in this paper, the authors did not well explain why simply dropping the leaf in DPMs is sufficient for updating the score function without retraining. For instance, according to Algorithm 1, the scoring step is batch-dependent. If I understand correctly, when we update the score by pruning DPMs, it is not matching to the distribution of the next batch of data. In particular, the data $x$ is changing over batches in Equations 4 and 8. More theoretical justification is needed besides Figure 4.\n\n- The numerical studies did not show the best performance of the proposed method. Indeed, Figure 3 suggests that both CAM and SCORE are better than the proposed DiffAN method. In addition, the runtime of SCORE in Figure 3 is still reasonable. Similarly, both GraN-DAG and SCORE perform better than the DiffAN method in real data  I would suggest running more studies that vote for the authors' method. Finally,\nwhy not consider batches in SCORE so we can improve the run time as well? \n \n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper overall is clear, while more justification is needed on their method, algorithm, and motivation.\n\n- I mainly have concerns regarding novelty. As I commented above the proposed DiffAN method highly depends on the SCORE method proposed by Rolland et al., (2022). More clarity on the originality of the work is needed.",
            "summary_of_the_review": "Though the paper considers an important problem in causal discovery for the non-linear additive noise model, the novelty of the approach and the profound impact are both limited. In addition, the main methodology and numerical results require additional investigation.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_1RL4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_1RL4"
        ]
    },
    {
        "id": "-Kmsaprj-K",
        "original": null,
        "number": 4,
        "cdate": 1666804402683,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666804402683,
        "tmdate": 1666804402683,
        "tddate": null,
        "forum": "Idusfje4-Wq",
        "replyto": "Idusfje4-Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper3326/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed DiffAN, a topological ordering algorithm that leverages DPMs for computing the Hessian. The algorithm updates the learned Hessian without re-training the neural network and performs ordering over a batch, which allows scaling to datasets with more samples and variables. In the experiments, they show that the method scales up well and achieves SOTA results. ",
            "strength_and_weaknesses": "Strength:\nIntegrating causal discovery and diffusion models is novel and interesting. The proposed method using diffusion methods to compute the Hessian of distribution scores is interesting.\n\n\nWeakness:\nThe method only achieves comparable results on the data sets. The author should give detailed reasons why the method could not beat existing methods given that deep neural nets can provide better representations. ",
            "clarity,_quality,_novelty_and_reproducibility": "The structure of the article is good. There are some small issues, e.g.,   in definition 1, p(x)  should be a scalar, why p(x)  $\\in R^{d}$? ",
            "summary_of_the_review": "The proposed method is novel and interesting.  The author should discuss the reason why the method cannot outperform the score-based method. \n\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_F1bu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3326/Reviewer_F1bu"
        ]
    }
]