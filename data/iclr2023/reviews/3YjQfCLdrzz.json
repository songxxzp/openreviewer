[
    {
        "id": "Vx3_gbaddm",
        "original": null,
        "number": 1,
        "cdate": 1666152282767,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666152282767,
        "tmdate": 1668787892958,
        "tddate": null,
        "forum": "3YjQfCLdrzz",
        "replyto": "3YjQfCLdrzz",
        "invitation": "ICLR.cc/2023/Conference/Paper2038/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a graph rewiring method, which aims to tackle the oversquashing problem in GNN literature. The proposed method greedily adds edges for maximizing the spectral gap of the graph sequentially. The authors also propose the use of relational GNNs to preserve the original graph topological information. The experimental results show that the proposed method achieves better test accuracy on graph classification tasks compared to several recently proposed rewiring methods.",
            "strength_and_weaknesses": "## Strengths\n\n- Proposing the use of relational GNN to preserve the original graph topological information is reasonable.\n\n- The proposed edge-adding method, FoSR (First-order Spectral Rewiring), can maximize the spectral gap in a greedy but effective way.\n\n- The experimental results on the graph classification task demonstrate the superior performance of the proposed method in terms of test accuracy.\n\n- The experiment setting is rigorous. The code seems to be well-documented.\n\n## Weaknesses\n\n- The criterion of maximizing the spectral gap for adding edges seems not well-motivated.\n\n- The experiment results do not support or validate the theoretical analysis and claims. Also, the efficiency (i.e. time complexity) of FoSR is not reported and compared with baseline methods.\n\n- Some naive baselines (i.e. fully connected graph at the last layer) and transformer-based methods are only mentioned but not included in the experiments.\n\n## Detail comments\n\nI have mixed feelings about this work. On one hand, I like the idea of leveraging relational GNNs to preserve the original graph information is great for graph rewiring-based methods. I also love how rigorous the authors prepared their experiments and make their code well-documented (at least specifying the environment).\n\nOn the other hand, I have several concerns about the paper. I explain all the listed weaknesses below.\n\n### The criterion of maximizing the spectral gap for adding edges seems not well-motivated. \n\nAs the authors mentioned in the Section 3, once we introduce relational GNNs, we will not suffer from losing the original topological information (i.e. $\\mathcal{E}_1$). As also mentioned by the authors, using a complete graph can maximally resolve the oversquashing issue, albeit it comes with the cost of losing original topological information. However, this is not a problem when we consider relational GNNs. Hence, should not we simply choose $\\mathcal{E}_2 = \\mathcal{E}/\\mathcal{E}_1$? I do not get the motivation why we need a special design of $\\mathcal{E}_2$ for solving the oversquashing problem theoretically.\n\nNote that the naive approach abovementioned has an obvious drawback, which is its scalability on large graphs similar to the transformer-based method. However, given the fact that the authors only consider graph classification tasks, I feel like there is no need for the proposed FoSR method. Maybe I miss something, please correct me if I do. If not, I would suggest the authors test these rewiring methods on node classification tasks, where the graph can be huge.\n\n### The experiment results do not fully support or validate the theoretical analysis and claims. Also, the efficiency (i.e. time complexity) of FoSR is not reported and compared with baseline methods.\n\nI notice that the authors demonstrate that their method indeed achieves a higher spectral gap compared to the baselines in Figure 1. I wonder if the authors also report similar results for their main experiments? Note that this is quite important, as the authors claim in the introduction that the spectral gap is a measure of the oversquashing effect.\n\nAlso, one major contribution of the paper is their first-order approximation formalism, which makes the FoSR algorithm much faster in theory. However, I wonder how the running time of FoSR compared to the other baselines. Does FoSR win in both test accuracy and time complexity? If not, what does the trade-off look like?\n\n### Some na\u00efve baselines (i.e. fully connected graph at the last layer) and transformer-based methods are only mentioned but not included in the experiments.\n\nOne major drawback of the experiments is the selection of baseline methods. As mentioned by the authors in the introduction, some naive methods can resolve the oversquashing problem. For example, leveraging a complete graph in the last layer of the GNN. The other naive baseline would be the one that I proposed earlier, which simply chooses $\\mathcal{E}_2 = \\mathcal{E}/\\mathcal{E}_1$ for relational GNN. Finally, note that the transformer-based methods will not suffer from oversquashing and perform pretty well on graph classification tasks recently. I wonder how the proposed methods compare to transformer-based methods. Do we still need these rewiring techniques for graph classification? As I mentioned earlier, if the authors want to prevent comparison with transformer-based methods or methods leveraging complete graphs, they should conduct experiments on node classification tasks with large graphs.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: the paper is well-written and easy to understand the main idea of the method. \n\n- Quality: I have some concerns about the motivation and the experiments. Please see my comments above.\n\n- Novelty: The proposed method seems novel to me. I like the idea of leveraging relational GNN especially.\n\n- Reproducibility: The code is complemented with a well-documented readme file. I believe the results are reproducible, albeit I do not reproduce them directly.\n",
            "summary_of_the_review": "The authors attempt to tackle the oversquashing problem and propose a new rewiring method and the use of relational GNN. Their proposed method aims to add edges that maximize the spectral gap. My major concern about the paper is its motivation, where the complete graph can simply resolve the oversquashing problem and the original graph information can be preserved by the use of relational GNN. The experimental results only demonstrate the better test accuracy of the proposed method on graph classification tasks, where some simple baseline and transformer-based methods are ignored. Also, the comparison of the time efficiency is not presented. Hence, I believe the paper needs some revision before publishing.\n\n====================post rebuttal===========================\n\nI thank the response by the authors. Most of my concerns are well-addressed but one still remains (please see my response below). Nevertheless, based on the merits of the current paper, I raise my rating from 5 to 6. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_T9j4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_T9j4"
        ]
    },
    {
        "id": "KSJzzdxco0",
        "original": null,
        "number": 2,
        "cdate": 1666456352104,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666456352104,
        "tmdate": 1666625943625,
        "tddate": null,
        "forum": "3YjQfCLdrzz",
        "replyto": "3YjQfCLdrzz",
        "invitation": "ICLR.cc/2023/Conference/Paper2038/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper deals with oversquashing in GNNs, that is, when information flows between nodes (receptive field large enough), but is too compressed (squashed) into the (finite) features to be correctly exploited for prediction (because number of neighbors grows exponentially with radius of receptive field).\n\nThe paper has 2 contributions: \n\n- First a key idea, which is that in a rewiring procedure, one can label the added edges differently from the original ones, so that the GNN knows they are \"fake edges\", only here to help propagate information.\n\n- Second, based on spectral gap/graph Laplacian mathematical arguments, they propose a new rewiring algorithm. The rewiring algorithm is inspired from the arguments, but does not guarantee the best rewiring (largest increase in spectral gap) at each step: instead it is approximate, so as to be reasonably cheap (computationally).\n\nBoth these contributions are backed by experiments, comparing with 2 other rewiring methods.",
            "strength_and_weaknesses": "Weaknesses: \n\n- Section 3 is hard to read, and contains some general theorems in which the proof is in a sense \"disappointing\" (theorem  3): the weight matrices \\Theta used in the proof are trivial (proportional to identity)\n- The experiments are described a bit too succinctly, making it hard to infer exactly how experiments were performed (more details later in the review).\n\nStrengths:\n- the two contributions seem to be genuinely good ideas, with practical added value: the special label for added edges seems to indeed improve accuracy. \n- The rewiring algorithm is not too expensive (actually seems pretty cheap, under some conditions), and also clearly works well (better than the two previous method it's compared to).",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nThe paper is overall rather clear, apart from a few mathematical points that are a bit heavy for someone unfamiliar with the Graph Laplacian and the notion of spectral gap.\n\nI found section 4 easier to read and understand (in the details) than section 3.\n\nI think the paper would benefit a lot from a few more \"intuitive\" explanations. For instance, I feel like the spectral gap, i.e. the value of the second eigenvalue of the normalized Graph Laplacian, should somehow relate with the second eigenvalue of (normalized) A: I know that the first mode of A corresponds to the stationary distribution of the Markov Chain associated to A. The second mode (eigenvector) of A corresponds to the first excitation of this stationary probability distribution, and the eigenvalue relates to the associated timescale (with a relation like tau = - log(lambda_2). Look at \"Perron Cluster Cluster Analysis\" for details on these ideas (not mine !)\n\nRelating these ideas with the spectral approach could increase the readership a lot (or increase the fraction of happy readers).\n\nOther point that would need more intuitive explanations, for me at least: the definition 2: why is there a sup ? \n\nAlso the end of section 4 (last paragraph, bottom page 7) is mysterious and would need more explanations (it is said that one can \"often\" compute the minimal value... -> what if often ? What are the conditions ? (and why can we replace a full search over pairs by single index-searches ? -- I didn't get it).\n\nTop of page 8: why can we relax some conditions ? This paragraph was really not obvious to me. Probably just a bit more discussion would enlighten me.\n\n\nQuality:\n\n- the paper seems sound and correct. I did not re-run experiments. I checked the maths only to some extent. I found a few typos, by the way (see lower).\n\n- The paper is well introduced and situated within literature: I did not know of oversquashing, and now I (think I) know about it.\n\n- The background on spectral graph theory is ok, could provide a few more intuitive views, e.g. in terms of Markov chains (random walk on the graph).\n\n\nIn terms of novelty.\n\n- Disclaimer: I am not aware of the rest of the literature on oversquashing (neither oversmoothing, but it's less relevant). I have to believe that the experiments, esp. the comparison with other SOTA methods, were done in good faith. \n\n- After a very quick literature search, however, it seems the paper cites the recent relevant works.\n\n- I did not find other recent rewiring methods than the 2 this papers compare to. I could have missed one.\n\n\nReproducibility: \n- the code is available, I haven't run it but is seems well organized.\n- Here I have a question:\n    I would like to know how the iteration counts presented in table 3, used for experiments, where chosen.\n     Was it by checking out figure 1-style results, i.e. a form of saturation of the spectral gap with added edges, or was it optimized for performance ?\n\n---------- \nClarity: improvements suggestions in detail\n\nAlthough GNN models are presented in sec. 2.2, it is unclear to me what are the models presented in experiments.\nThe GIN acronym is never defined.\nI think authors should make this much clearer, as it's a key point, and for now it's quite confusing.\nIn the same line of comments, I think they should stress out where the different nature of rewired (Added) edges appears in the GNN architecture, how it is dealt with. So far, I understand it just comes as a separate channel, but is mixed (added with learned weights) with the regular edges). It seems almost too simple !\n\n\n\n------------\ntypos:\nin proof of theorem 3, 3rd equation: \n- an X becomes (1-alpha)X ? One could just choose Theta=(1-alpha).I and get this (or I missed something).\n- last =, = (I - alpha L), an X at the right is missing.\nAlso, I guess it's obvious that A=A1+A2, but maybe you could mention it ?\n\nBefore proposition 5: you assume symmetric matrices. So you deal only with undirected graphs, correct ? This should be mentioned/discussed.\n\n\n\n",
            "summary_of_the_review": "The paper is overall good, and if the ideas presented are indeed new, should be published. The 2 contributions seem to be directly applicable, and yet are avenues for future work (improved architectures that well exploit the added edges with new label, and other approximations or schemes for adding edges, in the spirit of increasing the spectral gap).\n\nTechnically and empirically, contributions are somewhat new, in that the rewiring and the way to process are indeed new, but the very idea of rewiring, and the very idea of fighting oversquashing, are not themselves new.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_2pg5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_2pg5"
        ]
    },
    {
        "id": "tlBvZoPgP8",
        "original": null,
        "number": 3,
        "cdate": 1666649540416,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649540416,
        "tmdate": 1668767033758,
        "tddate": null,
        "forum": "3YjQfCLdrzz",
        "replyto": "3YjQfCLdrzz",
        "invitation": "ICLR.cc/2023/Conference/Paper2038/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The work addresses the issue of oversquashing in GNN in proposing a new approach of rewiring graphs so as to improve the spectral gap of the graph (as it has been studied that spectral gap is a key feature in preventing oversquashing). The proposed rewiring algorithm comes from a study of perturbation of the Fiedler vector  and spectral gaps when adding one edge. The methods is conceptually simple and relevant and some numerical results show its performance.",
            "strength_and_weaknesses": "Strength:\n\n1- The idea and derivation of the first order spectral rewiring is very well explained in Section 4 (even if it relies on known tools or algorithms, the idea is, for me, new in this context).\n\n2- The resulting method shows improvements in effeiciency as compared to contenders, and the numerical experiments are extensice enough to assess that.\n\n3- Globally the article is clear and it's a nice read, without any superfluous elements.\n\nWeaknesses\n\n1- The issue addressed, navigating the trade-off between oversquashing and oversmoothing, exists yet I am not certain it is a major one and several works have already discussed and addressed the issue. The contribution is, on this side, incremental.\n\n2- The algorithm relies on approximate (perturbation-based + power-method eigenvectors computation + approximation of argmin (y_i y_j) which appear to work yet are not really controled or checked. What would happen with difference choices of k, r and of the argmin method ? Are the results robust ? What would be the choice of r if k has to be increase ?\n\n3- there don't appear to gave results comparing the computation time to methods from contenders. Also, parameters (as in D.1) could be varied a little bit, at least to check robustness against ther variation.  \n\n Minor questions :\n\n- results on ENZYMES appear to be low as compared to what I have seen in other works; Why that ?\n\n-   the number of digits in the numerical results (5 digits on percentages) appear to be high. Is it really trustable ? Even with 100 runs, I wold expect less precision of the accuracy results.\n\n- the datasets are rather small size (in average number of nodes and/or number of graphs). Given the  dicussion about computational complexity and the approximations leveraged in the method, I would have expected results on larger datasets as well.\n\n- I don't think that Appendix A is useful (I think that expected readers are familiar with that).\n\n- Figure 1 should be larger so as to be more readable. ",
            "clarity,_quality,_novelty_and_reproducibility": "The article is well written and clear. The code is available and the artile appears to be reproducible.\n\nThe novelty is fair, yet incremental in some aspects. Maybe the novelty and improvement in performance (Empirical Novelty And Significance) would be rated stronger if the weaknesses 2 and 3 + the minor questions are addressed satisfactorily.",
            "summary_of_the_review": "My recommandations is for marginal accept, because it is a sound work on an existing issue, even if the work is in part incremental.\n\n\nUpdate after revision: I increase the score to 8: Accept.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_j5dr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_j5dr"
        ]
    },
    {
        "id": "5bwYoxqc9tR",
        "original": null,
        "number": 4,
        "cdate": 1667358016983,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667358016983,
        "tmdate": 1669047141410,
        "tddate": null,
        "forum": "3YjQfCLdrzz",
        "replyto": "3YjQfCLdrzz",
        "invitation": "ICLR.cc/2023/Conference/Paper2038/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper investigates the oversquashing phenomenon in Graph Neural Networks from the perspective of graph rewiring methods. The purpose of graph rewiring is to alleviate structural bottlenecks and facilitate the flow of information between more distant nodes. The contribution of the paper is twofold: 1) for any graph rewiring approach, a relational GNN implementation is proposed, which is able to make use of the augmented edge set without forsaking the information contained in the graph topology; 2) First-Order Spectral Rewiring is proposed as an efficient rewiring mechanism, which provides a principled way for selecting edges by maximizing the change (up to first-order approximation) in the spectral gap. In support of 1), a theoretical result is provided, which seems to hint that the proposed R-GNN formalism might be able to make use of the augmented index set without exacerbating a related phenomenon called oversmoothing. Experimental results demonstrate the benefit of both proposed techniques compared to non-relational GNNs and alternative rewiring methods.",
            "strength_and_weaknesses": "### The paper has several strengths:\n- It is remarkably well-written and the exposition is very clear.\n- The proposed techniques are elegant and innovative, but mostly nontrivial.\n- Theoretical results hint at the benefits of the approach.\n- Detailed experiments demonstrate the benefit of both techniques, individually and also when combined.\n\n### Notable weaknesses:\nOverall, there are some missing points in the discussion which make me a bit unsure about this paper on a second read. Depending on how these points are addressed, I can be incentivized to modify my rating in either direction.\n\n- Missing discussion about spectral gap maximization.\n\nThe paper does a good job at conveying the core ideas from related work without overloading the reader. One thing I was missing is an overview of previous results for why graph rewiring via spectral gap maximization is a worthwhile approach for alleviating oversquashing. Since this seems to be the foundation on which the corresponding FoSR algorithm is built, I think it would go far if there was an intuitive overview of the core idea. \n\n- Theorem 3 does not tell the whole story.\n\nTheorem 3 seems to be a useful result regarding the flexibility of R-GNN. However, I have some doubts whether it tells the full story. Specifically, when the weight matrices $\\Theta_1$ and $\\Theta_2$ are reduced towards zero, the rate of smoothing reduces as the contribution from the direct and indirect neighbours decrease. In the corner case of $\\Theta_1 = \\Theta_2 = 0$, only the self-loops remain with the R-GNN becoming a node-wise linear transformation, and this setting also clearly achieves minimal oversmoothing. However, the structural information is lost in this case as well. In this way, Theorem 3 does not tell the whole story because somehow we are trying to maintain propagation along the important edges while maintaining a low rate of smoothing. It seems there is a missing component here to really guarantee the strength of these R-GNNs in practice. It would be interesting to know more about how this interaction happens with the graph rewiring approach utilized.\n\n- Experiments do not report investigation regarding the realized spectral gap and associated trade-offs.\n\nThe experiments demonstrate improved downstream performance after applying the proposed rewiring approach. On the other hand, no investigation of robustness is carried out in terms of the realized spectral gap itself. I would be curious about the following comparison for the compared rewiring methods: number of rewiring iterations - realized spectral gap - downstream performance. In this case, other model hyperparameters could be treated as fixed. This also connects to the previous point, as it looks like simply maximizing the spectral gap is not sufficient (otherwise we could just choose a larger number of rewirings). Although the R-GNN can learn to reduce oversmoothing, it seems like it's main method for doing so is to effectively eliminate the newly introduced connections, hence making the R-GNN more similar to classic GNN. It seems like we are still somehow trying to balance both phenomenons (oversmoothing and oversquashing) with some added flexibility. For example, how this trade-off happens with respect to the rewiring steps could be investigated and explained in more detail empirically.\n\n- Robustness of FoSR approximation is unexplored.\n\nDuring the derivation of FoSR, several involved calculations are carried out where the spectral gap is approximated (first the order-1 Taylor expansion, and then an asymptotic argument to discard some of the terms from the maximand). Consequently, as with most approximations, there is some error incurred. At the moment, there is no intuition about when (just from the point of view of spectral gap maximization) this rewiring approach is expected to work well, or if it could fail in certain cases. Some discussion would be interesting here.\n\n- Motivation of tools utilized for oversmoothing analysis.\n\nSection 3 first sets the foundation for the theoretical analysis by introducing a carefully chosen set of tools. I found the associated references to be somewhat scarce. The Dirichlet energy associated with the graph is referenced, but I did not see references for the associated rate of smoothing \"metric\". Is this something that the authors propose themselves, or was this used in previous works? In the former case, I think it would be worthwhile to provide a more detailed justification about why this is a good quantity to measure oversmoothing.\n\n\nPOST-REBUTTAL: Rating increased to 8 in view of significant improvements.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The writing of the paper is high quality. It reads well and it does a great job at conveying the key ideas. Some additional discussions would help round out the motivation and make the paper more self-contained, but overall it is well-written.\n\n- Novelty: The main contribution of the paper is novel and original. It has multiple elements: a new graph rewiring approach called FoSR, an associated relational GNN formalism and corresponding theoretical results.\n\n- Reproducibility: The paper includes a reproducibility statement, and code is provided to aid in it. I have not run the experiments by myself.",
            "summary_of_the_review": "The paper investigates oversquashing and oversmoothing. It communicates the ideas particularly well. The proposed techniques (R-GNN and FoSR) are novel and original. Some theory is provided to motivate the R-GNN with some open questions at the moment. Experiments demonstrate the benefit of the both techniques with interesting results compared to alternative rewiring approaches and non-relational GNN. Discussion of trade-offs and some theoretical questions would help strengthen the message. As mentioned above, I am looking forward to the authors' rebuttal regarding my questions, which may affect the final rating (in both ways).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_42Gr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2038/Reviewer_42Gr"
        ]
    }
]