[
    {
        "id": "UrhUktLD_Q",
        "original": null,
        "number": 1,
        "cdate": 1666526758147,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666526758147,
        "tmdate": 1669127126757,
        "tddate": null,
        "forum": "wXdEKf5mV6N",
        "replyto": "wXdEKf5mV6N",
        "invitation": "ICLR.cc/2023/Conference/Paper5484/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper performs a comparison of different active learning strategies on tabular data sets when trained with deep learning models that are pre-trained with self-supervised learning. The key result is that margin sampling, which is also one of the easiest active learning strategies, consistently outperforms other strategies.\n",
            "strength_and_weaknesses": "Strengths\n- The experiments cover a large number of data sets and seeds\n- The paper concludes with clear guidelines for practitioners\n\nWeaknesses\n- The focus of the study seems narrow. The paper focuses on (1) tabular data with (2) deep learning models. This is limited as the vast majority of tabular ML in practice is done not with DL but with GBT, RF, etc.\n- The statistical testing seems inappropriate in that the number of tests that are being made is massive. My understanding may be incorrect so please correct me if I am wrong, but there are 49 x 20 x 3 tests performed and then the results are collated. At the very least it should be possible to reduce the number of tests to 16 x 16 by considering multiple measurements (i.e., seeds) and just doing a single test per method x method pair. An even simpler analysis would be for each data set, to perform a single ANOVA (if assumptions are met) with margin and other methods to demonstrate that margin actually outperforms all methods on each data set. This reduces the number of tests down to 49. There are statistical setups that could also be considered.\n- Why do you use a larger p-value in one setting and not in the other? The p-value is supposed to be a priori fixed and not modified to increase the number of wins. If the result is not significant for the pre-determined p-value then that in itself is a result\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear, but does require prior knowledge of the experimental setup in a previous paper.",
            "summary_of_the_review": "Overall, the paper seems limited in scope and performs statistical analysis that is not clear. It could be my understanding of the stat analysis is wrong and if I am incorrect, I am happy to increase my score, but I am not yet sure about how to address the scope limitations.\n\n\n==============\nAFTER REBUTTAL\n\nI appreciate the authors for carefully considering my comments and exploring a more robust statistical setup to compare their methods. I have raised my score accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_58Ep"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_58Ep"
        ]
    },
    {
        "id": "ltLuHytxKJ",
        "original": null,
        "number": 2,
        "cdate": 1666557242773,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557242773,
        "tmdate": 1666557242773,
        "tddate": null,
        "forum": "wXdEKf5mV6N",
        "replyto": "wXdEKf5mV6N",
        "invitation": "ICLR.cc/2023/Conference/Paper5484/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper compares a variety of active learning algorithms on 69 tabular datasets using a multilayer perceptron model (with and without unlabeled pretraining). The results show that margin-based (i.e. best versus second best) uncertainty sampling performs the best.",
            "strength_and_weaknesses": "Strengths:\n - This paper empirically analyzes active learning algorithms (which is much needed) rather than defining yet another algorithm.\n - This paper studies tabular datasets which are under-explored in active learning experiments. \n - This paper compares a large variety of active learning algorithms and large number of datasets.\n\n\nWeaknesses:\n - This paper only evaluates with one model, a multilayer perceptron, which may be suboptimal for tabular datasets compared to tree-based methods.\n - With the very large number of active learning algorithms, it is admittedly hard to pick a list. However, I was surprised to see BADGE and BAIT were not on the list. While BADGE is computationally intensive, for image classification tasks, it works very well.\n - The evaluation criteria (performance after k rounds in 3 different batch settings) seems a bit arbitrary without much discussion.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and is original in its choice of models/datasets for an active learning empirical survey. \n\nIn terms of writing, I think more discussion regarding choices in the evaluation would be very helpful. For example:\n - Why the specific settings for small, medium, large?\n - Why performance after k iterations rather than area under the active learning curve, or some other metric?\n - Why the particular MLP model rather than tree-based methods?\n - What was the process for choosing the active learning methods?",
            "summary_of_the_review": "This type of active learning evaluation paper (especially for tabular datasets) is a very useful addition to the active learning literature. However, the quality of the evaluation could be improved in some ways though.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_h2sD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_h2sD"
        ]
    },
    {
        "id": "FKQxXSQt98",
        "original": null,
        "number": 3,
        "cdate": 1666623630059,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623630059,
        "tmdate": 1666623630059,
        "tddate": null,
        "forum": "wXdEKf5mV6N",
        "replyto": "wXdEKf5mV6N",
        "invitation": "ICLR.cc/2023/Conference/Paper5484/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper is an empirical study of deep active learning (especially for margin based approaches). This paper consider different tasks (openml) and how model pre-training affect the performance.",
            "strength_and_weaknesses": "Strength: this empirical study tests many DAL approaches (mostly are margin-based approaches) on openml datasets. A meaningful finding is that margin-based approachs perform consistently better than random sampling across multiple various tasks.\n\nWeakness: some directions need to dig deeper.\n\n1. For w/ and w/o pre-training techniques, this paper only provide an overall performance, however, how w/ and w/o pre-training techniques affect the AL performance is complex, it is related to the similarity btw target and source domain and perform different on different tasks like [r1] (section 3.4, considering dataset with distribution shift). The author should dig more informations either from existing experimental results or conduct more experiments.\n\n2. For evaluation methods, both win matrix and box plots only present the performance on one round. As for Figure 4, there are too many curves with mixing colors. It's really hard to distinguish which is better across varying batches. Can use Area Under the Budget Curve (AUBC) [r1] or AUCLOG, which is the AUC of the learning curve when the X-axis is in log-scale [r2] or the average performance across multiple rounds (not recommended) to present an overall performance. Aslo, Figure 4 (and the similar figures) need to be re-designed by selecting more distinguishable color schemes or zoom in on some areas like [r3].\n\n3. A deeper and more confidential analysis of the experimental results is needed. For instance, at the end of Page 7, \"Methods that tied\nor slightly underperformed margin on the win plots have a comparable relative gain over random, whereas the gains for others are near zero or negative (in the case of BALD). We observe that Power-BALD outperforms BALD \u2013 this is, most likely, not because BALD is ill-suited for the batch AL setting but because PowerBALD\u2019s additive noising process mimics (biased) random sampling.\" Firstly, \"most likely\" seems not confidential. Comprehensive study needs reasonable and confident analysis. Then, Why BALD is ill-suited for the batch AL setting? Does the author try different batch settings or there are some publications support the opinion? \n\n[r1] Zhan X, Wang Q, Huang K, et al. A comparative survey of deep active learning[J]. arXiv preprint arXiv:2203.13450, 2022.\n\n[r2] Mozafari B, Sarkar P, Franklin M, et al. Scaling up crowd-sourcing to very large datasets: a case for active learning[J]. Proceedings of the VLDB Endowment, 2014, 8(2): 125-136.\n\n[r3] Kothawade S, Beck N, Killamsetty K, et al. Similar: Submodular information measures based active learning in realistic scenarios[J]. Advances in Neural Information Processing Systems, 2021, 34: 18685-18697.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clealy written and easy to follow, it tests many margin-based DAL approaches across 69 datasets. From the aspect of the empirical study, the quality is high, the novelty is not appliable for empirical study. The author does not provide the re-implementations of their experiments thus it is not reproducible. ",
            "summary_of_the_review": "This is a well-written emprical study with sufficient comparative experiments about margin-based DAL approaches, however, the experimental analysis is somewhat weak and need to be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_TZgZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5484/Reviewer_TZgZ"
        ]
    }
]