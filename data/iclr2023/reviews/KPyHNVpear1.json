[
    {
        "id": "IdYcw5BPDu",
        "original": null,
        "number": 1,
        "cdate": 1666558518006,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666558518006,
        "tmdate": 1666558518006,
        "tddate": null,
        "forum": "KPyHNVpear1",
        "replyto": "KPyHNVpear1",
        "invitation": "ICLR.cc/2023/Conference/Paper4264/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper conducts empirical investigation regarding the best practice of building cascade models. Specifically, the paper investigated the impact of early-exist condition and the choice of model calibration on the efficiency-accuracy performance of the cascade, and investigated the performance of both vision and text models. The experiments reveals that the maximum softmax achieves most improvement overall, and temperature scaled calibration hurts performance.",
            "strength_and_weaknesses": "Strength: \n* A comprehensive and careful study of some key design decisions of cascade models.\n* Extended evaluation to the text domain.\n\nWeakness:\n* Novelty is a bit limited: the paper investigated some common obvious choices (in terms of choice of confidence metric and calibration procedure) and provided some empirically-supported conclusions. Otherwise, the cascade model itself is not too different from previous work (e.g., [Wang et al. 2022](https://openreview.net/pdf?id=MvO2t0vbs4-)). ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly structured and well written. It appears the result should be reproducible.",
            "summary_of_the_review": "As mentioned in the weakness, the paper investigated some common obvious choices (in terms of choice of confidence metric and calibration procedure) and provided some empirically-supported conclusions. Otherwise, the cascade model setup is not too different from previous work (e.g., [Wang et al. 2022](https://openreview.net/pdf?id=MvO2t0vbs4-)). \nWhile it is useful to share empirical results, I feel the submission in its current form is sufficient as a high-quality workshop submission, but does not carry sufficient scientific significance to justify a publication at top venue like ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_Bbfc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_Bbfc"
        ]
    },
    {
        "id": "RK4RqmKfmuy",
        "original": null,
        "number": 2,
        "cdate": 1666645824180,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666645824180,
        "tmdate": 1666645824180,
        "tddate": null,
        "forum": "KPyHNVpear1",
        "replyto": "KPyHNVpear1",
        "invitation": "ICLR.cc/2023/Conference/Paper4264/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work explores model cascades as a way to improve the accuracy-efficiency trade-off of deep neural networks. They conduct experiments to evaluate different design choices in model cascades, such as the confidence metric, number of models in the cascade, and whether to calibrate the logits before ensembling. Experimental results on image classification and text classification are provided to support the analysis of model cascades.\n",
            "strength_and_weaknesses": "The results presented in this work largely make sense to me. But a major concern is that the difference between this work and previous work [A] is unclear. Many conclusions presented in this work were already verified in [A] except that [A] focuses on image classification while this work provides both image & text classification results.\n\nFor example, the first contribution \u201c2-model cascades dominate the accuracy-compute Pareto front\u201d was shown in Figure 7 in [A]. The comparison of different confidence metrics (entropy, margin, etc) is similar to Figure 3 in [A].\n\nTherefore, I am unsure about the new value this work could add to the existing knowledge about model cascades.\n\n[A] Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models. ICLR 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The results are reproducible due to the simplicity of model cascades. The clarity needs to be improved, particularly what\u2019s the motivation of conducting these experiments and what new knowledge the community could benefit from this work needs to be made much clearer (considering the existing results in [A]).\n",
            "summary_of_the_review": "This work does not propose new techniques but rather analyze the various design choices of an existing method (model cascades). This is fine as long as the analysis results are informative. However, considering a very similar prior work [A], the contribution of this work is unclear and seems to be modest. So I vote for rejection.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_J6Fm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_J6Fm"
        ]
    },
    {
        "id": "Ft9V9sPDb18",
        "original": null,
        "number": 3,
        "cdate": 1666663550405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663550405,
        "tmdate": 1666663550405,
        "tddate": null,
        "forum": "KPyHNVpear1",
        "replyto": "KPyHNVpear1",
        "invitation": "ICLR.cc/2023/Conference/Paper4264/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors conduct a thorough investigation of cascading methods with deep neural networks, including threshold tuning, cascades of various depths, heterogenous cascades with different types of architectures and methods of ensembling predictions when early exiting is not possible. The authors demonstrate the efficacy of these techniques for both vision and text tasks.",
            "strength_and_weaknesses": "I found the paper to be clear, focused and interesting. One strength of the study is their experiment design - in particular, taking advantage of the large number of pre-trained models available through frameworks like TIMM and HuggingFace to answer questions about cascading methods convincingly. The insights from the study are also impactful, with 2-5x reductions in computation and up to 3x reductions in measured inference time.\n\nOne question I had was about the precision of the thresholds used. In each of the tables I see four digits of precision used for softmax thresholds. Is this level of precision necessary? What would the results look like if fewer digits are used?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and their experimental methodology is high quality. I expect their results will be easily reproducible given the use of publicly available models and data. I think the novelty of the study is high and the results are potentially impactful.",
            "summary_of_the_review": "This paper is well written, well organized and thorough in their analysis of cascading methods for deep neural networks. The results are novel and potentially impactful.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_CNbJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_CNbJ"
        ]
    },
    {
        "id": "qlnpG7saIcD",
        "original": null,
        "number": 4,
        "cdate": 1666792359785,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666792359785,
        "tmdate": 1666792359785,
        "tddate": null,
        "forum": "KPyHNVpear1",
        "replyto": "KPyHNVpear1",
        "invitation": "ICLR.cc/2023/Conference/Paper4264/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper discusses conditional execution of models from the early-exiting angle; showing that a 2-cascade of models can improve upon baseline performance of executing a single model across the entire pareto front in terms of efficiency and accuracy. The paper takes several combinations of 2 models, and picks good ones, where a threshold is learned to switch from execution from the simple model to a more complex model. The paper also evaluates several techniques for doing the thresholding/cascading. ",
            "strength_and_weaknesses": "Strengths:\n- The paper is well written\n- It is always good to have more results for topics like this, reaffirming what is commonly known through literature.\n\nWeaknesses\n- The paper essentially just reconfirms something that is very well known in the conditional computing literature. Early-exiting/cascading helps significantly in models to create a better efficiency trade-off. This has been shown in the past in many studies; although generally at least some part of the network is shared as not to recompute simpler features at the start of the network. Even in relatively new language and vision transformers, many variants of early-exiting have been discussed. For this specific version of early exiting, within a single model, there's already 7 papers out on this topic, showing that it helps to early exit simpler examples.\n- This paper really does nothing new on top of what is already known. Although it's good to reconfirm what is known, there is nothing novel in this paper. There are no new insights in this paper worth mentioning. \n- The setup is quite archaic, compared to the more commonly used set-up where at least some features are shared, as opposed to using an entirely new network. I don't think it's relevant to show results in this setup anymore, as it is not a very efficient setup to do  early exiting on. \n- The fact that temperature thresholding does not work very well has been discussed at length in many early-exiting papers, and things like 'patience' metrics have become more popular for doing early exiting in monolithic networks. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, and easy to write. The authors mention that they will release the code, making it reproducible. \nFor the work that was done, the quality seems good.",
            "summary_of_the_review": "Reading this paper knowing about conditional computing and early exiting, it does not provide any novel insights. It does reconfirm something that scholars in this area already know, but provides little new insight to the discourse. It has an interesting experimental setup, comparing cascaded ensembles of many existing networks, but this setup will likely not be optimal compared to the more common setup of a monolithic model being early exited from.\n\nAll in all, since the paper does not meaningfully contribute to my understanding of early-exiting, nor provides a new method on how to make more efficient networks, I would reject this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_Q4Xh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4264/Reviewer_Q4Xh"
        ]
    }
]