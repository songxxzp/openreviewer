[
    {
        "id": "uIZBcOWxwh",
        "original": null,
        "number": 1,
        "cdate": 1666368605632,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666368605632,
        "tmdate": 1666368605632,
        "tddate": null,
        "forum": "x9tAJ3_N0k",
        "replyto": "x9tAJ3_N0k",
        "invitation": "ICLR.cc/2023/Conference/Paper5445/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes score-based transport modeling (SBTM), a particle-based method to solve the Fokker-Planck equation. This is based on the transport map approach (TE) where the key challenge is to estimate the score of the distribution at the current time. Such a challenge is resolved by learning the score with neural networks using the current set of particles, using an objective derived from Stein's identity. Two synthetic experiments are done to demonstrate the effectiveness of the proposed method.\n",
            "strength_and_weaknesses": "## Strengths:\n* The idea of learning the score from particles while simulating particles along the probability flow of the Fokker-Planck equation using the score is a very interesting one. \n* Theoretically there are some interesting perspectives on viewing SBTM in Lagrangian or Eulerian frames, and the KL divergence with respect to the true flow can be controlled by the error of the score.\n\n\n## Weaknesses:\n* The motivation for learning the score during the flow is not super clear to me when you can simply simulate the SDE. The authors suggest you can obtain more quantities like the density of the flow, yet to me, the only new quantity you obtain is the score. And to obtain the score, you could also just simulate the SDE using Euler, and learn the score as a post-processing step using (7), i.e., I don't see any practical benefit of learning the flow while simulating the particles which can be very costly. The only way I can think of to obtain the density is to keep the *entire history* of the particles (which can be very memory intensive) and then compute the density using (5), but this is not demonstrated in any experiment. \n* I found Proposition 1 quite misleading and not relevant to the actual algorithm proposed. What is the role of $G_t$? Isn't it just the true score? The constrained optimization in (SBTM) formulation is never actually done (it is mentioned only in passing that it can be solved using the adjoint method). The function $\\lambda$ appears to not matter as it is simply taken to be a dirac delta in the sequential SBTM (wouldn't this also break the assumptions in Proposition 1? Dirac deltas are not positive functions). \n* Equation (seqSBTM) seems identical to me as (7). It is possible that I entirely misunderstood, but to me Algorithm 1 has very little to do with the theories developed in Section 3 and can be simply obtained by applying (7) to get the score and then integrating the ODE (3)+(4).\n* I found the experiments section quite weak. Despite the main selling point of the proposed algorithm being its ability to access quantities like the density, it is never demonstrated in what occasions these quantities are useful. It is only verified that these quantities are accurate. What downstream applications can these quantities facilitate? The authors should also compare with the naive solution which is to simulate the corresponding SDE using Euler scheme and then estimate these quantities as postprocessing steps, such as using kernel density estimation. I would also hope to see more interesting instances of Fokker-Planck equations rather than the two toyish examples shown here.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the paper is good. However, the source code is not provided.\n",
            "summary_of_the_review": "Given the lack of motivation for the proposed method and the somewhat misleading theoretical development, I am leaning toward rejection of this paper.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_LTVr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_LTVr"
        ]
    },
    {
        "id": "TLGBABJKJv",
        "original": null,
        "number": 2,
        "cdate": 1666627891288,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627891288,
        "tmdate": 1666776548307,
        "tddate": null,
        "forum": "x9tAJ3_N0k",
        "replyto": "x9tAJ3_N0k",
        "invitation": "ICLR.cc/2023/Conference/Paper5445/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper considers the transport-map approach to learn the score function along the solution trajectory of the Fokker-Planck equation. In contrast to the score-matching approach, the proposed proposed sequential SBTM method does not require to simulate the underlying SDE. Instead, the particles are propagated via a sequentially constructed estimation of the score function. Experiments are conducted to show the empirical advantage of the proposed method.",
            "strength_and_weaknesses": "Strength: While the score-based transport model is similar to a recent work (Shen et al. 2022), as acknowledged by the authors, the authors generalizes the previous art by considering a non-constant diffusion coefficient and show that the objective of SBTM controls the KL divergence between the hypothesis density and the ground-truth density, which improves over the previous Wasserstein-type bound.\n\nWeakness: \n1. Algorithm 1 can be memory consuming since it requires a individual neural network model for the score function at every time-stamp. Please correct me if I am wrong. \n2. I do not see how Proposition 3 differs from the standard score matching technique. This seems the exact score-matching technique for approximating $\\nabla \\log \\rho_t$.\n3. It is not clear how the optimization problem (SBTM) is solved and the analysis on how Algorithm 1 solves SBTM, e.g. the convergence guarantee, is missing.\n4. Since SBTM is proposed as an improvement over SBDM, it seems reasonable to include SBDM in the empirical study, but I do not seem the comparison between SBTM and SBDM.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written. There is an overlap with some recent work, which is acknowledged by the authors. ",
            "summary_of_the_review": "Overall I think the self-consistency based approach is a promising direction for score estimation and this paper makes a good contribution. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_qgFR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_qgFR"
        ]
    },
    {
        "id": "vzAn3w2kt3L",
        "original": null,
        "number": 3,
        "cdate": 1666638833208,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638833208,
        "tmdate": 1669174382713,
        "tddate": null,
        "forum": "x9tAJ3_N0k",
        "replyto": "x9tAJ3_N0k",
        "invitation": "ICLR.cc/2023/Conference/Paper5445/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In high dimensional setting, it is typically impossible to approximate the solution $\\rho_t$ to a Fokker Planck Equation (FPE) with conventional grid-based methods. A  standard method consists in considering the associated SDE a simulate many trajectories from this SDE to collect statistics of the solution at any future time $t$. This methods allows to compute any moment $\\int \\mathcal{O}(x) \\rho_t(dx)$ of the solution (eg. Monte-Carlo method), but the evaluation of $\\rho_t(x)$ is typically not available with this basic approach.\n\nThe article proposes to express the solution of the FPE as a transport equation $\\partial_t \\rho_t = -\\nabla \\cdot (v_t \\rho_t)$ with a velocity field $v_t$ that is expressed as a function of the score $s_t$ of $\\rho_t$ itself, $s_t = \\nabla \\rho_t$. This motivates the following particle approach:\n\n1. start from $N$ samples $x_1, \\ldots, x_N$ samples from $\\rho_0$\n2. use (some variant of) score matching to evaluate the score of $\\rho_t$ and construct the velocity field $v_t$\n3. push forward the particles through the transport equation to get a particle approximation of $\\rho_{t + \\Delta t}$\n4. iterate: go back to 2\n\nThe advantage of this approach is that, because $\\rho_t$ is expressed as transport equation, is is straightforward to evaluate $\\rho_t$ along trajectories of the transported particles (contrarily to the SDE approach).",
            "strength_and_weaknesses": "**Strength:**\nThe method is very intuitive and appears to work well on simulated examples.\n\n**weakness:**\n1. the proposed scheme does not seem to very stable in the sense that errors in estimating the score may amplify as the particles are propagated. In some sense, the vanilla approach consisting in simulating forward the associated SDE appears to be much more stable in that respect. Is this true? Can the authors discuss and possibly illustrate this empirically.\n\n2. I think that the simulation should take compute-time into account. The vanilla Monte-Carlo approach (ie. simulate forward the SDE) is extremely scalable. The proposed approach requires implementing score-matching at each step.\n\n3. Evaluating $\\rho_t$ from samples is basically a density estimation problem. I think the authors should consequently consider comparing their method to Vanilla-Monte-Carlo + density estimation (eg. normalising flow, or something of that sort). Indeed, there are also quite a few ways to estimate differential entropies, and mutual information, from samples!\n\n4. The network architectures are exploiting quite a lot the structure of the problem. One may argue that this structure could also be used to estimate the density out of samples much more efficiently than a completely problem-agnostic approach ... \n\n\n**minor question**:\n1. is it $-\\alpha$ in Equation (11) or $+\\alpha$",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nThe text is clearly written, easy to follow, with appropriate references to the literature.\n\n## Quality\nI think that quite a bit of work should be done to do comparison with reasonable baselines (i.e. take compute time into account and compare to density-estimation procedures exploiting the same problem-structure)\n\n## Novelty\nExcept the related work of (Maoutsa et al) that exploit similar ideas but in lowish dimension, the proposed methodology appears to be new.\n\n## Reproducibility\nall good",
            "summary_of_the_review": "The proposed method is natural and very interesting. I would like to encourage the authors to work on their simulations in order to more convincingly demonstrate the appeal of the approach when compared to more standard methodologies.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_1NXr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5445/Reviewer_1NXr"
        ]
    }
]