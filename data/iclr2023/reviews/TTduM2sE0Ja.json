[
    {
        "id": "QARtlQFS2S1",
        "original": null,
        "number": 1,
        "cdate": 1666529311092,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666529311092,
        "tmdate": 1670666002235,
        "tddate": null,
        "forum": "TTduM2sE0Ja",
        "replyto": "TTduM2sE0Ja",
        "invitation": "ICLR.cc/2023/Conference/Paper3299/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The author(s) study the model aggregation strategy in federated learning. The author(s) conduct a theoretial analysis on the impact of the model aggregation strategy. In particular, the author(s) show that the model aggregation can lead to a trade-off between convergence rate and convergence error (a non-vanishing bias term). Experiments on real-world datasets under various settings are conducted to support the proposed method.",
            "strength_and_weaknesses": "Strengths:\n- The paper is well-motivated and well-writtem, the story line and the theoretical analysis are easy to follow.\n- Experiments are thorough.\n\nWeakness:\n- The theory developed (Theorem 1) is not very strong. The definition of $\\Gamma$ and $\\Omega$ actually depends on $T$, so it is more accurate to write them as $\\Gamma_T$ $\\Omega_T$. As a result, the convergence error (the non-vanishing bias term) depends on $T$, which could potentially goes to 0 as $T \\to \\infity$. The relationship between the bias term and $T$ making the trade-off between convergence rate and convergence error less clear. Please also see my questions below.\n\nQuestions:\n1. Theorem 1 assumes full participation, is it possible to extend it to the parital participation case? This seems to be important because the full participation assumption is too strong for FL.\n2. Consider the proportional aggregation strategy, the bound in Theorem 1 reduces to\n$$\nE[ F(W^t) ] - F(W^*) \\leq \\frac{L}{\\gamma + T} O(1) + \\frac{L}{\\mu} \\min_{t \\in [T]} \\sum_{i=1}^N \\rho_i ( F_i( W^t ) - F_i(W^*) ) \\\\\n\\leq \\frac{L}{\\gamma + T} O(1) + \\frac{L}{\\mu} \\min_{t \\in [T]} \\sum_{i=1}^N ( F(W^t) - F(W^*) )\n$$\nwhich is trivial since $L/\\mu > 1$. This sanity check indicates that the inequality is rather loose. Is it possible to tighten the bound so that we can get a non-trivial bound for proportional aggregation?\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written, and is novel to my knowledge, reproducibility is unclear to me.",
            "summary_of_the_review": "The paper is well-written and the experiments are thorough and clear to me. My only concern is on the theory side, please see my questions in the \"Strength And Weaknesses\" section. I will raise my score if these questions can be addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_gbV4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_gbV4"
        ]
    },
    {
        "id": "vBJ6dXA0zJ",
        "original": null,
        "number": 2,
        "cdate": 1666674382336,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674382336,
        "tmdate": 1666674382336,
        "tddate": null,
        "forum": "TTduM2sE0Ja",
        "replyto": "TTduM2sE0Ja",
        "invitation": "ICLR.cc/2023/Conference/Paper3299/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "By analyzing the effect of time-varying aggregation weights in FL, the authors obtain a tradeoff between the convergence rate and the convergence error, where FedAvg favors the latter. Further, setting the aggregation weights proportional to the change in local loss after the local steps, the authors obtain a new aggregation strategy, $Exp-\\alpha$. This algorithm outperforms proportional aggregation across several baseline FL algorithms on several FL datasets, in terms of both the convergence rate and the final convergence error.\n",
            "strength_and_weaknesses": "Strengths\n- The theoretical analysis using time-varying aggregation weights reveals that setting proportional weights is a suboptimal strategy, especially in terms of the convergence error.\n- Thorough experiments across different datasets and with different types of heterogeneity.\n- The proposed aggregation strategy, $Exp-\\alpha$, is easy to apply in practice and  outperforms baseline proportional aggregation in all scenarios.\n\nWeaknesses \n\n- **Metrics** : I assume that the authors report test accuracy of the global model averaged across clients. This wasn't clarified in the Experiments section or the appendix. Additionally, it would be  interesting to see the performance of the global model only on the heterogeneous clients, i.e., the ones which $Exp-\\alpha$ down-weights during aggregation. Further, robust algorithms perform well under low levels of corruption, so it would be interesting to see the performance of $Exp-\\alpha$ when half of the clients are corrupted.\n\n- **Theoretical results hold only for strongly convex cases** : Since the authors have not adapted proofs for convex or non-convex cases, the exact expression of proportional aggregation might be different in these cases.\n\n- **Domain Shift Experiments**: From Table 3, I could see that $Exp-\\alpha$ performs worse than proportional aggregation on several domains, however, the average accuracy is better. Could the authors provide an explanation for this? I expect that the aggregation weights for clients from these domains should be small but a further analysis of how heterogeneous these domains are, might help.\n\n- **Effects of $\\alpha$, heterogeneity and number of local steps** : Appendix A.5 is difficult to parse, especially Figures 3,4 and 5. (No legend in Figures 3 and 4 and Figure 5 is too small). While the authors do have all these sets of experiments, they do not compare how aggregation differs wrt increasing heterogeneity and number of local steps. I think that the value of $\\alpha$ controls how different the proportional weights are, with lower $\\alpha$ providing larger difference. Using this explanation, increasing heterogeneity among clients or increasing the number of local steps, should increase the deviation between local models and global models and should require a smaller $\\alpha$ to handle it. Could the authors provide more details on this?\n\n\nSuggestions \n- **Explaining Experiments** : The set of experiments are exhaustive, however, some analysis of the experimental results in terms of behavior wrt number of local steps, the value of $\\alpha$ and the cases where proportional aggregation outperforms $Exp-\\alpha$ would greatly benefit the paper.\n\n- **Possible connection to robust aggregation**: Note that several robust aggregation algorithms, for instance Trimmed Mean[1], discard or decrease the weight of clients which differ severely from the average. Here, $Exp-\\alpha$ also gives lower weights to clients which differ a lot from the average iterate and should ideally also provide some \"robustness\" in the aggregation.\n- **$Exp-\\alpha$ for stateful algorithms**: Working out the proof using a baseline stateful algorithm, for instance SCAFFOLD[2], should provide more insights into whether stateful algorithms also suffer from the issue of suboptimal convergence rate with proportional aggregation or not.\n\n\n### Typos --\n- Theorem~1 : What is the max over? and doesn't it require Assumption 1 (Strong Convexity)\n- Figures 3 and 4 in the appendix do not have legends so it is difficult to figure out exactly what is the effect of $\\alpha$.\n\n\n### References --\n\n[1] Yin, D., Chen, Y., Kannan, R. &amp; Bartlett, P.. (2018). Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates. <i>Proceedings of the 35th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 80:5650-5659 Available from https://proceedings.mlr.press/v80/yin18a.html.\n\n\n[2] Karimireddy, S.P., Kale, S., Mohri, M., Reddi, S., Stich, S. &amp; Suresh, A.T.. (2020). SCAFFOLD: Stochastic Controlled Averaging for Federated Learning. <i>Proceedings of the 37th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 119:5132-5143 Available from https://proceedings.mlr.press/v119/karimireddy20a.html.\n",
            "clarity,_quality,_novelty_and_reproducibility": "See the detailed strength/weakness section",
            "summary_of_the_review": "See the detailed strength/weakness section ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_CKau"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_CKau"
        ]
    },
    {
        "id": "UeGXvDuP0bo",
        "original": null,
        "number": 3,
        "cdate": 1667171412361,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667171412361,
        "tmdate": 1667171412361,
        "tddate": null,
        "forum": "TTduM2sE0Ja",
        "replyto": "TTduM2sE0Ja",
        "invitation": "ICLR.cc/2023/Conference/Paper3299/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considered the impacts of model aggregation in federated learning (FL). The authors first derive the convergence performance of FL with a more general time-varying aggregation scheme for FL. Then by specializing the time-varying convergence result to the conventional proportional aggregation, the authors argued that the conventional proportional aggregation has its limitation in favoring convergence error while sacrificing convergence rate performance. Then, the authors proposed an exponential-type aggregation scheme called Exp-$\\alpha$ and empirically showed that Exp-$\\alpha$ achieves good performance.",
            "strength_and_weaknesses": "Strengths:\n1. This paper considered model aggregation, which is an important aspect of FL.\n2. The revealed insights based on a more general time-varying aggregation scheme are interesting.\n\nWeaknesses:\n1. Although this paper provides a fresh perspective on model aggregation in FL, the strong convexity (Assumption 1) and bounded local gradients (Assumption 4) are quite restrictive and not very interesting in the state-of-the-art convergence analysis of FL. \n\n2. The main theoretical results in Theorem 1 have not been presented clearly. Specifically, $\\Gamma$ and $\\Omega$, the two most important quantities in Theorem 1, are quite confusing. For a while, it appears to the reviewer that they are asymptotic and independent of $t$. But later in Sec. 3.3, it seems that they are only for finite time $t$. I suggest changing the notations to $\\Gamma_t$ and $\\Omega_t$ to avoid such confusion. Also, the authors seem to have an incorrect understanding of the terminology \"convergence rate,\" which typically characterizes the finite-time error of some convergence metric (gap w.r.t. the optimal value of the problem in Theorem 1) w.r.t. $T$. In Theorem 1, it is unclear how $\\Gamma-\\Omega$ scales w.r.t. $t$ when the proposed time-varying aggregation scheme is used. On the other hand, $\\Gamma-\\Omega = 0$ when the conventional proportional aggregation scheme is used. Thus, it is inaccurate to claim that the time-varying aggregation can achieve an improved convergence rate. In fact, the time-varying scheme may even hurt the convergence rate performance since $\\Gamma_t - \\Omega_t$ could have a convergence rate worse than $O(1/T)$.\n\n3. For the proposed Exp-$\\alpha$ aggregation scheme, the authors also didn't provide any theoretical analysis on its convergence rate in terms of $\\Gamma-\\Omega$. Thus, it is hard to know theoretically how fast the convergence rate performance of the Exp-$\\alpha$ scheme is.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to follow. The novelty of this paper is good, although the proposed time-varying aggregation and the Exp-$\\alpha$ scheme are only limited to restrictive assumptions. The reproducibility of this paper seems to be good. ",
            "summary_of_the_review": "This paper considered the impacts of model aggregation in FL and proposed a time-varying model aggregation scheme to improve the convergence of FL over the conventional proportional scheme. Although the paper reveals some interesting insights for the proposed time-varying scheme and empirically shows the performance of the Exp-$\\alpha$ scheme, there are some confusions and potential misunderstandings of convergence rate in the theoretical results in this paper. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_Cggb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_Cggb"
        ]
    },
    {
        "id": "15fj7ky8JgI",
        "original": null,
        "number": 4,
        "cdate": 1667522135074,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667522135074,
        "tmdate": 1667522749188,
        "tddate": null,
        "forum": "TTduM2sE0Ja",
        "replyto": "TTduM2sE0Ja",
        "invitation": "ICLR.cc/2023/Conference/Paper3299/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper considers federated learning with non-iid data. Under the non-iid data, standard methods do not work well. For this problem, the authors first consider the effectiveness of proportional aggregation. Then, they find a trade-off between convergence rate and convergence error. Based on this finding, they propose a novel method, called Exp-$\\alpha$, which achieves the stronger convergence rates at the theoretical costs of a non-vanishing convergence error. Through several experiments, the authors confirm the empirical effectiveness.",
            "strength_and_weaknesses": "The authors consider an intriguing problem in federated learning. Based on a finding on the proportional aggregation, the authors propose insightful framework, analysis, and methods. Unfortunately, I have not studied federated learning and cannot evaluate the significance. However, it seems that the theoretical results are sound, and the authors develop non-trivial methods based the theoretical results. In particular, the idea of time-varying aggregation is outstanding. Overall, I felt that the paper is high-quality and well-written. ",
            "clarity,_quality,_novelty_and_reproducibility": "I checked the mathematical arguments of the main body and confirmed that there was no serious error. I could not check the detailed proof. There are several notations that are not defined well, e.g.,\n- Definition 1 is strange because there is no clear definition of some notations, such as $F$. If this is not a standard in this literature, there should be clear definitions of such notations. Besides, the spaces of $\\rho_i$ and $W$ are needed.\n- On page 2: what is $\\rho^t_i$. We can guess, but there is no definition.\n- In Assumption 1, what is the definition of L2 norm? I firstly though that the expectation in the norm is taken over $W$ and $V$, but it is written that the assumption holds for all $W$ and $V$. I could not understand the definition of the norm. ",
            "summary_of_the_review": "Unfortunately, I am not familiar to this topic and cannot evaluate the significance of this paper. However, the paper is well written, and there is no serious error in mathematical statement .",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_cWRm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3299/Reviewer_cWRm"
        ]
    }
]