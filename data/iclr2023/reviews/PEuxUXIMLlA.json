[
    {
        "id": "7noJBPbx0A",
        "original": null,
        "number": 1,
        "cdate": 1666619570970,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619570970,
        "tmdate": 1666619570970,
        "tddate": null,
        "forum": "PEuxUXIMLlA",
        "replyto": "PEuxUXIMLlA",
        "invitation": "ICLR.cc/2023/Conference/Paper2976/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Paper proposes a novel method to decompose a scene into representation of concepts such as object appearance, background, and angle of object rotation. This is done through an encoding-decoding architecture which represents the concepts as latent variables. These concepts are then recomposite via a decoder network to generate the target images.\n\nPaper further proposes to use Neural Processes (CLAP-NP) to instantiated each learnt concepts for inference purposes. Different experiments were ran to validate the model performance against baseline models for the intuitive physics, abstract visual reasoning and scene representation tasks. The proposed method significantly overperforms all baseline methods with the MSE and new derived metric, Selection Accuracy (SA).\n\nFinally, paper also shows that the method can be used to edit the individual concepts to generate new samples.",
            "strength_and_weaknesses": "Strengths\n1. Paper is well-written and well-motivated.\n2. The concepts are clearly explained with formulas and diagrams\n3. Claims are sufficiently supported by experiments.\n\nWeaknesses\n1. Paper introduces several concepts which are not mainstream. However, this is rectified by providing the reader with references and extensive Appendix material.",
            "clarity,_quality,_novelty_and_reproducibility": "1. Paper is clear and concise.\n2. High quality with good references and formulas.\n3. Work seems highly original. Although some parts are drawn from previous work.",
            "summary_of_the_review": "Overall, this work seems excellent and of high impact. However, due to my unfamiliar with the technique described, it is difficult for me to review this work properly.\n\nThe experimental results are convincing. But I note that there is no comparison with any SOTA methods for tasks.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_4jVq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_4jVq"
        ]
    },
    {
        "id": "Xzfz4lZ254L",
        "original": null,
        "number": 2,
        "cdate": 1666699269002,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699269002,
        "tmdate": 1666705060142,
        "tddate": null,
        "forum": "PEuxUXIMLlA",
        "replyto": "PEuxUXIMLlA",
        "invitation": "ICLR.cc/2023/Conference/Paper2976/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a latent variable model to capture concept-specific laws from images/videos. The laws are encoded as Latent Random Functions (specifically, Neural Processes), and can be composed with one another. ",
            "strength_and_weaknesses": "Strengths:\n- Multiple datasets with different focus\n- Illustration of compositionalilty\n- Demonstration of failure cases\n\nCons:\n- Choice of baseline: neither NP nor GQN seem like strong, obvious baselines. Wouldn\u2019t a system like [Aloe (Ding et al. 2020)](https://arxiv.org/abs/2012.08508) offer a better comparison?\n- Based on Tables 3 and 4, I worry that the model needs careful tuning to work or several runs for a winner to emerge. The best hyperparameters vary significantly across datasets. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the writing is easy to follow and the figures are carefully drawn. No specific concerns, but here are a couple of suggestions:\n- __On choice of notation__: I found it confusing to think about concepts A and context C. It would be easier if concepts were denoted C, and if you used S for the source/context frames, used to predict targets T. \n- It would be useful to have a __summary table__ describing exactly what $x_t$ is for each dataset (e.g. timestep for BoBA, azimuth/altitute for MPI3D).\n",
            "summary_of_the_review": "The following questions will help me assess the work better:\n- Is anything preventing you from __assessing__ the __disentanglement__ of the LRFs? It would be useful to have those metrics (e.g. see https://github.com/google-research/disentanglement_lib). \n- What would be __other potential realizations__ of CLAP which don\u2019t use Neural Processes?\n- __Future work__: how do you expect LRFs would perform on the [Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge)? Would that be an ideal target domain?\n- __How to generate future predictions__: You could generate an extended rollout (e.g. on BoBa) by applying the model autoregressively on the most recent generated frames. For example: to generate 20 target frames after 5 context frames, you could first generate frames 6-10, then use those to generate 11-15, etc. Alternatively, you could evaluate one-shot using a \\eta=20/25. Which one do you expect would work better? The former strategy would allow you to re-infer the concepts and global latent at each application.\n- On specific figures:\n  - Figure 7: The newly generated example on CRPM-T doesn\u2019t have the same color law as matrix 3 right? I expected the triangles in the top row to be dark and identically colored. Rather, the triangles in the top row seem to be following a pattern that is different from all other top rows (from the context image). How is that possible?\n  - Figures 4 and 5: could you confirm you\u2019re using a single model on each dataset (but multiple test configurations)?\n  - Figure 14: do you learn any latents on CRPM-DT which change the size/rotation of the outer triangle?",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_rEh1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_rEh1"
        ]
    },
    {
        "id": "cJWSL_gt3v",
        "original": null,
        "number": 3,
        "cdate": 1666763512654,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666763512654,
        "tmdate": 1670619325549,
        "tddate": null,
        "forum": "PEuxUXIMLlA",
        "replyto": "PEuxUXIMLlA",
        "invitation": "ICLR.cc/2023/Conference/Paper2976/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper brings compositionality into the Neural Process framework. It decomposes the input into multiple concepts, each represented by a latent vector. A Neural Process is learned for each concept to capture its law, so that the concept can be generated at query points given a few context points. The full pipeline is trained end-to-end via variational inference without supervision. Experiments on three diverse datasets show that the proposed model can produce more accurate pixel predictions and more consistent latent space than NP and GQN. It is also qualitatively shown that one can compose different laws by combining the corresponding neural processes.",
            "strength_and_weaknesses": "- Strengths\n    - The experiment results are quite extensive. The failure of NP and GQN is clearly shown. The law manipulation result (Figure 7) is very interesting and shows that the learned neural processes can indeed be composed.\n    - The paper is well organized, and introduces sufficient background knowledge for readers to follow.\n- Weaknesses\n    - At a high level, the proposed method is similar to [ROOTS](https://www.jmlr.org/papers/v22/20-1176.html), which brings compositionality into GQN and focuses on compositional understanding of 3D scenes. Both of them can be thought of as a compositional NP framework. ROOTS has similarly shown better generation quality than GQN, and can compose novel scenes by combining the object-level GQNs. However, I think there is still merit in this paper, as it seems more general and not limited to 3D scenes. I encourage the authors to highlight their novelty compared to ROOTS.\n    - The datasets look visually simple. Some compositional video scene understanding methods (e.g., Kosiorek et al., 2018; Jiang et al., 2019; Lin et al., 2020a as listed in related work) can deal with more complex scenes. Can you clarify why they are not considered baselines?\n- Questions and Minor Issues\n    - How many concepts did you use and what is the dimension of the latent vector for each concept?\n    - The bouncing ball dataset is sometimes referred to as BoBa and sometimes BaBo.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity\n    - The paper is generally well written and easy to follow. The figures are of high quality.\n- Quality\n    - The evaluation makes sense, and there are some interesting results.\n- Novelty\n    - The novelty compared to ROOTS is not sufficiently discussed.\n- Reproducibility\n    - Dataset, architecture details and hyperparameters are provided in Appendix.",
            "summary_of_the_review": "I am leaning toward reject for the paper in its current form, mainly because the novelty needs more clarification.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_Fbxt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_Fbxt"
        ]
    },
    {
        "id": "_uetkGqS6ty",
        "original": null,
        "number": 4,
        "cdate": 1666792216284,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666792216284,
        "tmdate": 1666792216284,
        "tddate": null,
        "forum": "PEuxUXIMLlA",
        "replyto": "PEuxUXIMLlA",
        "invitation": "ICLR.cc/2023/Conference/Paper2976/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a latent variable model that parses dynamic scenes into independent laws represented as neural random functions. The model is trained to reconstruct the image sequence while keeping the distribution of concepts and random functions not changing over time and concepts. The evaluation on various datasets shows that it can predict the target images well. The qualitative examples show that the decomposed laws correlate with the changing visual concepts and can be swapped to generate novel samples.",
            "strength_and_weaknesses": "Strength\n- This is an interesting paper that focuses on learning disentangled laws to interpret dynamic scenes.\n- This paper also proposes a novel approach to learning concept-specific laws with Neural Proces. \n- The paper shows several qualitative examples to show how the results are interpretable and the composition of learned latent functions is meaningful.\n\nWeaknesses\n- It is unclear how the authors determined the number of laws for learning. What if we choose too many/little laws? Or how many laws we may need to interpret a realistic video?\n- The current quantitative evaluation focuses on MLE and selection accuracy to show the improvement of semantic error but these two don\u2019t really represent the model learns the right laws. The MLE can be a result of better visual encoding, the selection accuracy shows better representation. If the model learns compositional laws, it can generalize better to novel combinations of concepts that are not in training, e.g. new colors. The paper currently only shows one generalization example in the appendix. The evaluation will be much stronger to show a quantitative evaluation of generalization capability.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well presented and the appendix includes details of datasets, hyperparameters, and network architecture. The author also submitted source code as supplemental material for reproducibility. \n\nThe empirical evaluation is based on simple datasets. It will be beneficial to the community if the authors can discuss the limitation of the proposed model, e.g. what can be represented as compositional laws and what is needed if we apply this approach to more complex scenes.\n",
            "summary_of_the_review": "The paper proposes a novel approach to interpret dynamic scenes. It is well presented and easy to follow. It provides several examples of learned compositional laws. It will be much convincing if the authors can provide quantitative evaluation of compositional generalization.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_HFjB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_HFjB"
        ]
    },
    {
        "id": "cnVunz9mwd",
        "original": null,
        "number": 5,
        "cdate": 1667196780235,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667196780235,
        "tmdate": 1667196780235,
        "tddate": null,
        "forum": "PEuxUXIMLlA",
        "replyto": "PEuxUXIMLlA",
        "invitation": "ICLR.cc/2023/Conference/Paper2976/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a model for compositional law parsing that is capable to accurately represent different \"laws\" of semantic concepts. The laws are built with random functions, and the proposed system can combine these functions to achieve flexibility and generality in different law parsing tasks.\n\nThe model uses an encoder-decoder architecture that represents concepts as latent variables, and laws are operationalized as concept-specific functions built with neural processes.\n\nThe authors claim that the proposed framework outperforms other methods in scene representation, intuitive physics and abstract visual reasoning tasks. ",
            "strength_and_weaknesses": "## Strengths\n- Powerful concept with several meaningful abstractions\n- In-depth mathematical formulation explaining the formalities of the proposed framework\n- Detailed experiments, including multiple different benchmarks with very different setups and objectives\n- Very strong performance against baselines\n\n## Weaknesses\n- The abstract is not very good at exemplifying the proposed framework. More information, and possibly examples, describing what each law and concept can be would be great so that the concept becomes clear from the get-go.\n- The explanation of the Neural Process in Section 3 is hard to understand. Clarifying that paragraph might be of great help to readers unfamiliar with NPs.\n- General clarity. The paper is not easy to follow without substantial previous knowledge of the field, and it is hard to judge the \n- Baselines used: the set of baselines used is small, and an inclusion of other works could improve the experiments section. Importantly, comparing to task-specific networks might be interesting to observe how this general framework competes. \n",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nThe figures are clear and the concept of the paper is understandable. The presentation, however, could be improved: the abstract is not explicit enough to ground the main concepts, sections 3 and 4 are detailed but lack simpler explanations to tie together the main concepts.\n\n## Quality\nThe quaility of the paper is high. The figures, mathematical formulations and experiments are laid out with care. The overall detail of the paper is high and the framework proposed appears to be carefully crafted and quite powerful.\n\n## Novelty\nThe ideas appear to be generally novel.\n\n## Reproducibility\nThe paper appears hard to reproduce from the manuscript alone. Great care is taken to ensure that the mathematical framework is explained in detail, but specific implementation procedures and explanations related to experimental details are lacking.",
            "summary_of_the_review": "The paper introduces a novel and powerful concept. The experiments are thorough and the mathematical formulation appears to be thoroughly supported. Its main weakness is tied to clarity: the manuscript assumes large amount of previous knowledge related to NP and other topics, and clarity could be improved to ensure more fluid reading. In general, the paper establishes a powerful framework with strong improved performance over baselines over several benchmarks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_i5ZN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2976/Reviewer_i5ZN"
        ]
    }
]