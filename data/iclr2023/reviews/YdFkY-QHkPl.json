[
    {
        "id": "a02INeviT1",
        "original": null,
        "number": 1,
        "cdate": 1666169556434,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666169556434,
        "tmdate": 1666169556434,
        "tddate": null,
        "forum": "YdFkY-QHkPl",
        "replyto": "YdFkY-QHkPl",
        "invitation": "ICLR.cc/2023/Conference/Paper1591/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work adopts the feature learning framework by Allen-Zhu and Li (2021), and further introduces latent orthogonal feature views. The authors prove that under certain assumptions on features, a two-layer smooth-ReLU network can learn all features with midpoint mixup, whereas ERM can only learn one feature.",
            "strength_and_weaknesses": "Strength:\n1. On top of Allen-Zhu and Li (2021), the authors further decompose the input into multiple orthonormal feature views. This allows the authors to analyze the contribution of each individual feature and their gradient correlations.\n2. Although the change of data settings (section 3.1) and assumptions (3.10) is simple, the authors provide significant efforts in proving the feature learning under the mixup loss.\n\nWeakness:\n* Theory:\n1) In Eq. B.34, do you need a lower bound or dependence on the training iterations, such that the feature correlations will not be over-corrected?\n2) Could you add more intuitive explanations of the meaning of function f in Assumption 3.10? Is it possible to analytically prove the monotonicity of f?\n\n* Experiments:\n1) Thm 3.9 and 3.11 did not directly imply better test accuracy (generalization). Instead, is it possible to empirically verify the one or all feature(s) (v) learned (defined by 3.8) by the Midpoint Mixup?\n2) It would be better to add variances in Table 1.\n3) Many test errors in Table 1 are far worse than random guess (90% error rate). From Eq. 4.1, I did not see any noise is introduced. What is the reason for this large test error?",
            "clarity,_quality,_novelty_and_reproducibility": "1. Overall the paper writing is clear and easy to follow.\n2. As mentioned above, the main novelty of this work is to prove the benefit of the mixup in feature learning under the multi-view data setting.",
            "summary_of_the_review": "In general, I believe this work contributes significantly to the feature learning topic.\nI hope the authors could fix my concerns above and add more clarifications.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_9dJZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_9dJZ"
        ]
    },
    {
        "id": "Dd6yeNe0tBn",
        "original": null,
        "number": 2,
        "cdate": 1666487492626,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666487492626,
        "tmdate": 1666487492626,
        "tddate": null,
        "forum": "YdFkY-QHkPl",
        "replyto": "YdFkY-QHkPl",
        "invitation": "ICLR.cc/2023/Conference/Paper1591/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on mid-point mixup (a variant of mixup) and provides theoretical analysis on the effect of using mid-point mixup on multi-view data. The theoretical result is specific to the setting of the 2-layer convolutional networks and the datasets where samples at each class have 2 features. Under this setting, this paper shows that empricial risk minimization learn only single feature at each class, while mid-point mixup learns both features at each class. ",
            "strength_and_weaknesses": "- Strength\n    - The direction of analyzing mid-point mixup on mulit-view data is new and interesting.\n\n- Weakness\n\n    - Theory\n        - Why is the assumption of Lemma 2.1 (z_{i,j} is unique for all i,j pair) true in practice? Simple 2-dimensional dataset where each class follows Gaussian distribution cannot follow this assumption. (how about high-dimensional case?)\n        - It seems like Lemma 2.1 is important to show that Midpoint Mixup is not poor, but the proof of Lemma 2.1 is not fully understood on my side. (I put the details in the questions section)\n\n    - Experiments\n        - This paper shows that when L is large, Mid-point Mixup is having less error than ERM. Of course if L is large, it will go to the ideal multi-view dataset this paper is assuming, but then why don\u2019t we even start with real data? Instead, making a synthetic multi-view data to show the effectiveness of the theory seems more reasonable. I personally feel the experiments in this paper is similar to just \u201csimulation\u201d instead of real-world experiments.\n        - In Table 1, the authors are comparing \u201ctest error 96%\u201d versus \u201ctest error 97%\u201d, when we have 100 classes. What does it mean to increase 1% test error from \u201cnearly random guessing\u201d? Does these empirical results have any positive impact on the practical deployment of mid-point mixup?\n\n    - Writing\n        - The assumptions and results are less organized (thus I have many questions below). The definition 3.4 has no intuitive explanation or visualization.",
            "clarity,_quality,_novelty_and_reproducibility": "The problem itself seems to be novel, but the theoretical results are unclear. Below I wrote some questions to clarify them. \n\n* I couldn't fully get the proof of Lemma 2.1. Why does the \u201cexistence of well-defined h simultaneously optimizing each term of eq.2.3\u201d implies \u201cRHS of (2.4) is achieving the minimum\u201d, so that we have \u201c$g^{y_i} (z_{i,j}) = g^{y_j} (z_{i,j})$ for all $z_{i,j}$\u201d?\n\n* I couldn't get the sentence \"J(g, X) by just taking $\u27e8w_y, v_{y,1}\u27e9 \\rightarrow \\infty$ for every class y\" in the paper. I thought setting $w_c = v_{y,1}$ was enough to make the empirical loss = 0?\n\n* I couldn't get what footnote 1 means.\n\n* Sec.3.1 title is \u201clinear model\u201d and Sec.3.2 title is \u201cmulti-view data setup\u201d. But it seems like Def.3.1 in Sec.3.1 is also multi-view. What is the criteria differentiating Sec.3.1 and 3.2? Maybe because Sec.3.2 for general model, not limited to linear model? If so, the section name is misleading.\n\n\nI am also adding minor comments\n* The first sentence of Definition 3.4 is \u201cIdentically to Definition 3.4\u201d. Maybe typo for \u201cIdentically to Definition 3.1\u201d?\n* Typo: themself \u2192 themselves",
            "summary_of_the_review": "This paper focuses on an interesting problem, but has much room for improvement in terms of organizing the results, validating the assumption, and explaining how the experimental results are helpful in practical settings. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_uhyy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_uhyy"
        ]
    },
    {
        "id": "jK95Ubo3e-6",
        "original": null,
        "number": 3,
        "cdate": 1666674014414,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674014414,
        "tmdate": 1670464607729,
        "tddate": null,
        "forum": "YdFkY-QHkPl",
        "replyto": "YdFkY-QHkPl",
        "invitation": "ICLR.cc/2023/Conference/Paper1591/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies a specific instance of Mixup data augmentation: Midpoint Mixup. It provides a theoretical characterization of the learning dynamics of neural networks with mixup-augmented data, and proved how it can improve feature learning by helping the neural network pick up diverse features, under the multi-view data framework proposed by Allen-Zhu and Li.\n\n\n[1] Zeyuan Allen-Zhu, Yuanzhi Li, Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning",
            "strength_and_weaknesses": "Strength: Most of the paper is clearly written and it provides a rigorous analysis of the subject it studies. Mixup is an interesting data augmentation technique and tries to explain why it can help in improving the feature learning of neural nets. The theory result goes beyond the previous works that are based on linear models (as they are based on nonlinear neural networks) and is reasonable due to the feature learning technique it uses. It might be an important paper if the authors can fix the issues I find below.\n\nWeaknesses: \n1. The authors did not provide sufficient motivation why they specifically study Midpoint Mixup rather than the general mixup augmentations. Moreover, they did not provide an empirical comparison between the original mixup and the midpoint mixup, making it hard to justify their choice of study. A potential improvement is to explain the technical difficulty of analyzing the original mixup, and justifies that the midpoint mixup is competitive (or particularly interesting).\n2. Assumption 3.10, which seems to be the key assumption to migrate the proof technique in [2] to the setting of this paper, is very technical, without intuitive explanation, and without support from empirical evidence. It is hard to make sense of this assumption as assembling any real-world structure. This weakens the validity of the proposed explanation as the theory result could be just an artificial construction.\n3. The experimental results in this paper are not informative, as many of their metrics are too low. I do not understand why this paper constructs such special data by mixing images using Dirichlet distribution (see equation 4.1 and Fig 1) to compare ERM with Midpoint-Mixup. Moreover, the test errors often exceed 60%-90% for experiments on CIFAR-10/100 when L>1 (that is over the special dataset rather than the original Cifar10/100), meaning that the model struggles a lot to predict the mixup label. I don't think these experiments are sufficient to support the authors' choice of study or their theoretical claims.\n\n\n[1] Ruoqi Shen, Sebastien Bubeck, Suriya Gunasekar, Data Augmentation as Feature Manipulation\n[2] Zeyuan Allen-Zhu, Yuanzhi Li, Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is decent. the novelty is partially limited because the proof/data framework is largely inherited from prior work, while the original part (such as assumption 3.10) lacks enough explanation.",
            "summary_of_the_review": "This paper studies an interesting instance of Mixup augmentation and obtained some decent theory results with the help of an established theoretical framework, but the authors are not good at justifying their choice of study and their theoretical claims, and they fail at explaining the key technical ingredient of the paper, as well as how well their assumptions can connect to practical scenarios. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_Pxqu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1591/Reviewer_Pxqu"
        ]
    }
]