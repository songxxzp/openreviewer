[
    {
        "id": "pv_dhO7fGi",
        "original": null,
        "number": 1,
        "cdate": 1666297647012,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666297647012,
        "tmdate": 1666375203550,
        "tddate": null,
        "forum": "OMwyBv1UBh",
        "replyto": "OMwyBv1UBh",
        "invitation": "ICLR.cc/2023/Conference/Paper4434/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the subgraph-level Federated Learning (FL), where each client has the individual subgraph of the larger global graph. Then, to tackle this task, the authors propose to reconstruct the neighborhood information of the subgraph based on the rooted tree structure. In particular, the rooted tree for the particular node in the local client has the information for its neighboring nodes in the other clients, which is done by aggregating information of nodes in that other clients as well as the nodes in the local client. After that, the authors decode the neighborhood structure of the subgraph with the information in the rooted tree. The experimental results show that the proposed method outperforms the subgraph FL baseline, namely FedSage+. ",
            "strength_and_weaknesses": "### Strengths\n* The concept of the rooted tree structure for encoding the neighboring information for nodes in both the local client and the other clients is interesting. \n* The experimental results show that the proposed method outperforms the recent subgraph FL baseline, namely FedSage+.\n\n### Weaknesses\n* The proposed subgraph FL method is unrealistic, and not applicable to real-world scenarios. In particular, for the node in the local client, the authors define its neighboring nodes in other clients, and use the information of nodes in other clients based on the edge between the local client and the other clients. However, in privacy-preserving FL, since we cannot share information across clients, we cannot have the information whether two nodes in two different clients have the edge or not.\n* Also, the proposed information transmitting process between clients is unrealistic. To share k-hop neighboring information across clients, every client participating in FL should be in the same forwarding process. In other words, when the proposed method shares the information of 2-hop neighborhoods, every client should calculate the 1-hop neighborhood information and share them simultaneously. However, in realistic FL, it is unnatural to share k-hop neighborhood information of all clients simultaneously (i.e., one particular client may update k-hop neighborhood information, meanwhile, the other client may update (k-3)-hop neighborhood information). \n* The authors point out that one particular limitation of existing subgraph FL is the communication cost. However, since the proposed method considers k-hop neighborhoods of the root node and consequently all clients should recursively transmit k-hop node information, it seems the proposed one is also highly slow. \n* The compared baseline is weak. The authors compares only one subgraph FL baseline, namely FedSage+. I am wondering the authors can further compare the discussed relevant works in the paper: Peng et al., 2021; Yao & Joe-Wong, 2022; Chen et al., 2022.\n* There is a related work [1], which tackles the missing neighborhood problem, yet does not rely on neighborhood expansion. This work should be discussed. \n\n---\n\n[1] Personalized Subgraph Federated Learning, arXiv 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n* The exclusion of the father node in the rooted node structure is not convincing. The authors claim that the neighborhood information encoded by the rooted tree of the certain node is the same as the information by the node's ego network. However, if we ignore the farther node, the information of the rooted tree that ignores the father node is different from the information of the ego network that considers the father node.\n* The FL dataset generation process is unclear. The output of the used Louvain algorithm is not the number of clients; thus, the authors may merge many different subgraphs, partitioned from the Louvain algorithm, to the subgraphs of the client number (e.g., 10 or 15).\n\n### Quality\n* The quality of evaluation is weak. The authors compare only one subgraph FL baseline, namely FedSage+. Also, the efficiency of the proposed method is unclear, while the authors point out that the limitation of existing subgraph FL methods is communication efficiency. \n\n### Novelty\n* The proposed method is fundamentally incremental from the existing subgraph FL [2] that proposes to expand the neighborhood of the subgraph, yet the novelty for additionally considering the rooted tree structure is acceptable. \n\n### Reproducibility\n* The authors provide the source code, thus the reproducibility is high.\n\n---\n\n[2] Subgraph Federated Learning with Missing Neighbor Generation, NeurIPS 2022.",
            "summary_of_the_review": "The biggest concern is that the proposed method is not applicable to real-world scenarios (See first two weaknesses). Also, the evaluation of using one subgraph FL baseline is weak, and the analysis of communication costs is further required. Therefore, I cannot recommend the acceptance.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_53S9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_53S9"
        ]
    },
    {
        "id": "2wN19ZwEgA",
        "original": null,
        "number": 2,
        "cdate": 1666568124847,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666568124847,
        "tmdate": 1670218858210,
        "tddate": null,
        "forum": "OMwyBv1UBh",
        "replyto": "OMwyBv1UBh",
        "invitation": "ICLR.cc/2023/Conference/Paper4434/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a federated learning model for learning deep GNNs to solve node-level prediction tasks. Their idea is based on reconstructing the neighborhood information of nodes that accounts for neighborhood graph structure as well as their features in a principled manner. For aggregating neighborhood structure information, they proposed a rooted tree graph approach, whose node embedding is the same as the node\u2019s eco-graph. Reconstructing feature-based information for a given node is handled by an encoder-decoder framework with some information loss. Their experiments show improvement over SOTA.\n\nUpdate: The authors have addressed my questions to certain extent and I've updated my ratings to reflect the same. Although, due to my lack of breadth in federated learning, the confidence in my assessment is on the lower end.",
            "strength_and_weaknesses": "Pros:\n1. The related works are well explained with their strengths and drawbacks nicely pointed out. \n2. The construction of the rooted tree and then the procedure to do k-hop neighborhood reconstruction seems correct, though I have not verified the proofs given in the Appendix.\n3. The set of experiments chosen are well thought-off, although I do share certain concerns with the size of the datasets. \n\nComments: \n1. (Fig error) In fig.1(b) the node below (i) should be (m2). Also, please number all the equations.\n2. Can you please comment on the scalability of the method? The experimental datasets are very small sized graphs. In general, it will be of interest to the readers to get a sense of the time required for rooted tree construction, aggregation steps etc.? \n3. How does the memory requirement scale while creating the rooted tree for every node? Do you foresee issues with larger graphs in this regard?\n4. Any best practice on choosing the value of K (layers)  ?\n5. How can one do BFS vs DFS tradeoff while aggregating neighborhood information using the rooted tree graph structure? \n\nI think this work is novel, clearly presented and interesting. Although, I am not entirely confident about the scalability of their approach and have listed some of my concerns in the comments above. I will be happy to reconsider my ratings after replies from the authors. \n",
            "clarity,_quality,_novelty_and_reproducibility": "<included in the comments above.>",
            "summary_of_the_review": "I think this work is novel, clearly presented and interesting. Although, I am not entirely confident about the scalability of their approach and have listed some of my concerns in the comments above. I will be happy to reconsider my ratings after replies from the authors. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_YSgt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_YSgt"
        ]
    },
    {
        "id": "X8LpnGyJ6V",
        "original": null,
        "number": 3,
        "cdate": 1667183907755,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667183907755,
        "tmdate": 1667183907755,
        "tddate": null,
        "forum": "OMwyBv1UBh",
        "replyto": "OMwyBv1UBh",
        "invitation": "ICLR.cc/2023/Conference/Paper4434/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors develop a method for federated learning of deep GNNs. The main idea is to reconstruct the neighborhood information of nodes using a graph structured named rooted tree, and use the rooted tree for encoding neighborhood information. ",
            "strength_and_weaknesses": "The authors claim that the node embedding obtained by encoding on the rooted tree is the same as that obtained by encoding on the induced subgraph surrounding the node. This is captured in proposition 1. The proof is included in Appendix A. One suggestion is, given the importance of the proposition, it is necessary to include at least a sketch version of it in the main doc. \n\nI don\u2019t quite get the challenge of the proposed setting. This paper assumes that every node knows its one-hop neighbors, no matter whether the neighbors are in the same host or different host. Is that a reasonable assumption? If yes, the information can of course help to identify k-hop neighborhoods. Is that a challenging setting? \n\nThe authors criticize Yao & Joe-Wong, 2022 for making the assumption that the weight matrix is calculated in advance. Which weight matrix? There are no detailed explanations. Given a similar idea were proposed in that paper, it is important for the authors to explain the underlying reasoning.\n\nBuilding a root tree for each node is expensive. The authors do not seem to have experimental evaluations to evaluate the efficiency of the proposed method. What were the criteria of experiments for comparing different methods? The same amount of running time, or same number of iterations? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear, but some parts of the paper needs further explanations.",
            "summary_of_the_review": "The paper proposes to build rooted tree for each node in a GNN for federated learning. The approach in general makes sense. However, the practicality of the proposed method might be somewhat limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_SQ7X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4434/Reviewer_SQ7X"
        ]
    }
]