[
    {
        "id": "7wiY0nCSKdq",
        "original": null,
        "number": 1,
        "cdate": 1666559197385,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666559197385,
        "tmdate": 1666559197385,
        "tddate": null,
        "forum": "7mgUec-7GMv",
        "replyto": "7mgUec-7GMv",
        "invitation": "ICLR.cc/2023/Conference/Paper2958/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work presents a interesting approach to achieve group robustness without group label by re-sampling training data based on last-layer gradients, the work is simple, comes with rigorous theoretical justification and extensive experiments.",
            "strength_and_weaknesses": "Strength: \n* Comparing to previous approach, this current paper proposed a distinct signal (gradient magnitude) for quantifying the learning difficulty of examples, and proposed a simple learning-time resampling approach to debiasing. \n* The proposed methodology is simple and general purpose, and therefore worthwhile put it out there for the community.\n* The method is comprehensively evaluated across multiple benchmarks and comes with sufficient ablation study.\n\nWeakness:\n* None.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written with solid theoretical justification and extensive experiments.\n\n\n",
            "summary_of_the_review": "As stated in the summary, I find the work to be simple, comes with rigorous theoretical justification and extensive experiments. Therefore I believe it carries sufficient scientific novelty and empirical significance to justify an acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_Lo2Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_Lo2Z"
        ]
    },
    {
        "id": "skX5uvr_Qu",
        "original": null,
        "number": 2,
        "cdate": 1666623584644,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623584644,
        "tmdate": 1668537962834,
        "tddate": null,
        "forum": "7mgUec-7GMv",
        "replyto": "7mgUec-7GMv",
        "invitation": "ICLR.cc/2023/Conference/Paper2958/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Machine Learning models tend to take shortcuts when learning, taking advantage of dataset biases (or spurious correlations) within the data features, that make the task considerably easier to solve. However, these correlations are, indeed, nothing but spurious, and they may not be present during testing, making the model brittle and prone to errors. Existing approaches to solve this dataset bias problem focus either on leveraging human-labelled information, or on using attributes of the network such as their output, loss values, or feature space. This work, instead, focuses on the gradient of the samples with respect to the model parameters, and proposes a novel approach which: i) trains a biased model; ii) detects the biased samples based on their gradient; and iii) trains a new model with importance sampling to correct these biases. Theoretical and empirical results show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "**Strengths:**\n- S1. The algorithm is clear, simple, effective, and therefore of interest to the community.\n- S2. Experimental results are strong, and different ablation studies were performed.\n- S3. Theoretical justification is appealing and sensible.\n\n**Weaknesses:**\n- W1. Different ablation studies would be needed to understand where does the improvement come from. Specifically, the proposed approach is clearly inspired by LfF, and the difference are: i) sequential training of both models, instead of interleaved steps; ii) different weighting function; iii) re-sampling instead of re-weighting gradients (+ data augmentation). A proper ablation study should shed some lights on which steps are giving an edge to the proposed approach with respect to LfF.  \n   - **Edit.** I do not want to remove the point, as I think it is still important to clarify in the main paper, but I have just read Appendix C6 and C7 where part of these studies are done. After reading them, it is unclear to me whether using the gradient norm improves the results, as the proposed method with single-stage and reweighting performs similar to LfF. \n- W2. I am not sure how fair it is to introduce the data augmentation as part of the approach. Table 4 clearly shows that data augmentation is really helpful, and I think a fair comparison would apply data augmentation to the other methods as well.\n- W3. I don't see a reason to run only three seeds on these experiments, as they are not that heavy. Also, there are not statistical tests performed, but rather the best on-average results are marked in bold.\n- W4. While sensible, the theoretical analysis makes quite some assumptions. I am particularly concerned with how realistic is the first point of assumptions 2 ($\\nabla_\\theta^2 \\log f(y|x,\\theta)$ is independent of the class labels $y$). However, while I find the toy example really confusing (more on that later), Figure 3 is quite helpful.\n\n**Questions/Comments:**\n- Q1. Results on CCIFAR, CMNIST, and BAR on Vanilla and LfF are significantly different from those reported by LfF. Could the authors explain where do the differences come from?\n- Q2. Are you sure the cross-entropy loss is right? I think it is missing terms. See, for example. [here](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html).\n- Q3. What is \"an official dataset (e.g. MNIST)\" supposed to mean? What does a dataset \"official\"?\n- Q4. Was data augmentation used in the appendix C7?",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** While the idea of the paper is rather intuitive and easy to follow, the writing needs a full revision. A lot of phrases are rather confusing, or directly grammatically incorrect (e.g., \"PGD outperforms dataset bias\", \"Almost hair color of female images are blond\"). More on this note, I could not understand the 1D toy, as I couldn't parse the phrase \"elements in each set share the same loss function\".\n\nRegarding clarity, section 5 and the appendix are specially difficult to parse, with heavy maths that contrast the rest of the paper. I am confident it could be written in a more understandable way.\n\n**Quality.** I think quaility is ok, disregarding the rest of points I've made. _I have not checked the proofs._\n\n**Novelty.** While the method is novel, I do believe it used LfF a lot for inspiration, which might be worth mentioning. This is specially clear when trying to understand design choices such as using GCE for the first model, but then evaluating in CE. To understand the reasoning behind these choices, I had to go back to the LfF paper and re-read it.\n\nRegarding connections, I find the objective in Eq. (6) to be quite similar to that of [non-probabilistic robust optimization](https://en.wikipedia.org/wiki/Robust_optimization#Probabilistically_robust_optimization_models), so it might be worth mentioning.\n\n**Reproduciblity.** I have not checked the code myself, but it should be reproducibe. On this note, differences with the results from the LfF paper should be clarified.",
            "summary_of_the_review": "I think this is an interesting paper that addresses an important problem. However, I feel that it is a result of a number of systematic steps starting from LfF, and it is not entirely clear whether all the steps are necesssary to obtain good results (specially the gradient norms, which have not been tested in isolation).\n\nThis, combined with a lack of clarity, and the need to clarify some experimental results, lean me towards rejection for now. I am sure a polished version of the current work will be a pretty good paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_oD49"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_oD49"
        ]
    },
    {
        "id": "XxR6nfCYEs_",
        "original": null,
        "number": 3,
        "cdate": 1667378050029,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667378050029,
        "tmdate": 1669779024357,
        "tddate": null,
        "forum": "7mgUec-7GMv",
        "replyto": "7mgUec-7GMv",
        "invitation": "ICLR.cc/2023/Conference/Paper2958/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper debiases models by resampling with probabilities proportional to gradient norms. It uses the generalized cross-entropy loss from LfF to train a biased model and debiases the main model by sampling probabilities from gradient norms. It leverages the observation that rarer samples tend to have higher gradient norms, so their resampling scheme assigns higher weights to rarer samples.",
            "strength_and_weaknesses": "Strengths:\n\n[S1] The approach is simple and logical. It leverages the fact that rarer samples have higher gradient norms. This seems to be the first paper to use gradient norm instead of the commonly used output space-based measures for re-sampling/re-weighting.\n\n[S2] Mathematically, the paper interprets the debiasing problem as that of min-max (minimizing loss) of maximally difficult samples, which can be relaxed to minimize the trace of inverse Fisher Info. They show how the gradient norm minimizes this theoretically for 1D and empirically for higher dimensions. This provides a strong justification to the choice of gradient norms.\n\n[S4] The results on image classification datasets used by previous debiasing methods and Civil Comments (from WILDs) show gains over existing methods. However, I have a concern in [W1]\n\nWeaknesses:\n\n[W1] Sec 4.2 mentions 8 baselines, but not all comparison methods are run on all the datasets. For example, EIIL seems to be reported only for CivilComments and BPA only for CelebA. I did not find a good justification for this in the paper; it seems like all the methods can potentially be run on all the datasets.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The novelty lies in the usage of gradient norms. It has sufficient details in the paper and also provided code for reproducibility.\n",
            "summary_of_the_review": "Overall, I think the approach is simple and has practical applications -- from the results it seems to be the SoTA amongst all the implicit de-biasing methods. \nHowever, the paper does not report all their comparison methods on all the datasets, which is really strange.\nI am willing to raise the score if the authors properly justify why that is the case.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_jyHT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2958/Reviewer_jyHT"
        ]
    }
]