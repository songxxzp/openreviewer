[
    {
        "id": "7CjAfeEr1i",
        "original": null,
        "number": 1,
        "cdate": 1666521200920,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666521200920,
        "tmdate": 1666521388482,
        "tddate": null,
        "forum": "jBPvRLKP_n_",
        "replyto": "jBPvRLKP_n_",
        "invitation": "ICLR.cc/2023/Conference/Paper2547/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "[NOTE: the citations I make below can all be found in the bibliography of the paper under review.]\n\nThis paper studies methods for doing lossy compression using a diffusion model, under the constraint of 'perfect realism'. 'Perfect realism' is defined in the introduction to the paper as the requirement that the marginal distribution of the reconstructions approximately matches the marginal distribution of the data (perhaps 'approximate realism' might be a better term for this property?).\n\nA fairly detailed theoretical analysis was presented, as well as experiments which confirmed the analysis and showed that the method could perform well, assuming that the compression rate of a method in the paper of Li & El Gamal (2018) could actually be achieved. Unfortunately, the computational complexity of this method is exponential in the dimensionality of the latent space, and the authors did not attempt to implement actual compression.",
            "strength_and_weaknesses": "### Strengths\n - The paper is very well written, and was enjoyable to read.\n - The paper was relatively honest about the limitations of the method.\n - I think the mathematical results were rigorous.\n### Weaknesses\n - I'm concerned about the practicality of the methods presented in the paper, and particularly the use of methods like that of Li and El Gamal, which have computational complexity that scales exponentially with dimension (there are a number of other papers with which I have the same issue, such as Ho et al. 2020; Flamich et al. 2020; and Havasi et al. 2019). Normally we would refer to such methods as intractible, rather than merely 'computationally expensive' (pg. 4, fourth paragraph). The paper under review does explicitly mention the exponential scaling, but only in the 'Discussion' section at the end of the paper. Given that we are unlikely to get a perfect model for natural images (at least not this year), approximate realism is the best we will be able to achieve anyway, and therefore I want to know why we can't try a method which we can actually run, such as straightforward deterministic quantization of the latents, at least as a baseline.\n - Related to the above point, I was very disappointed that the authors didn't manage to implement their compression method, even for small-scale data. The comparisons to other methods, both quantitative and qualitative, seem unfair given that (as far as I know) all of those methods have actually been implemented, whereas the methods in the paper under review have not. Particularly the claims of 'simplicity' of the method. If it's really so simple then why not implement it?\n - I also felt that the novelty of diffusion model lossy compression with 'perfect realism' was limited. In particular I am comparing the paper to Ho et al. 2020, which presented rate distortion results (also not implemented, and IMHO problematic for similar reasons to the paper under review) for a diffusion model, the only difference being the 'perfect realism' constraint. IIUC Ho et al. mentioned that one could do this (though they don't use the term 'perfect realism') just below eqn. 15 in their paper. This is not a criticism of the mathematical analysis, which I did not have enough time to thoroughly comprehend, I hope other reviewers are able to comment on the novelty and significance of this.\n\n### Minor points, typos and questions\n - In the first sentence of section 5, the authors say \"we implemented DiffC based on VDM\", perhaps this could be rephrased as \"we measured the performance of DiffC based on VDM\".\n - Typo in the second sentence of the second paragraph of section 5.2: \"This is line\" should be \" This is in line\".",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nThe paper was very well written, and easy to read.\n\n### Novelty\nSee third point under 'weaknesses' above.\n\n### Reproducibility\nThe authors did not provide code (or promise to do so). It would therefore be difficult, but probably not impossible to reproduce the results from the paper.",
            "summary_of_the_review": "This was a very well written paper and enjoyable to read, but I have serious concerns about its substance, particularly regarding the (im)practicality of the method presented, the fact that the authors were unable to implement the method, and the similarity to existing work, particularly Ho et al. 2020, therefore I judge it to be marginally below the acceptance threshold for ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_22JQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_22JQ"
        ]
    },
    {
        "id": "hG7_ov3afGb",
        "original": null,
        "number": 2,
        "cdate": 1666667072377,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667072377,
        "tmdate": 1666667072377,
        "tddate": null,
        "forum": "jBPvRLKP_n_",
        "replyto": "jBPvRLKP_n_",
        "invitation": "ICLR.cc/2023/Conference/Paper2547/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new lossy image compression paradigm based on unconditional diffusion models. The noise corrupted image is compressed and sent to the decoder via reverse channel coding, and the reconstruction of the input image is done through the denoising process applied to the received noise corrupted image. Effort was made to understand the theoretical RD behavior of such a new coding paradigm. The authors also try to compare it with BPG and some other learned codecs on ImageNet 64x64.\n",
            "strength_and_weaknesses": "Strengths:\n\n(1) The idea of using unconditional diffusion models for lossy image compression is novel. It has the striking feature that the encoding of an image can be done easily by corrupting the image with a (preferably non-isotropic) Gaussian noise. \n\n(2) The theoretical analysis presented in this paper is thorough and rigorous. \n\n(3) The authors made an early attempt to compare the proposed method with BPG and some learned codecs on ImageNet 64x64. \n\n(4) The conclusion section of this paper is insightful, and provides a good summary of the pros and cons of the proposed method. \n\nWeaknesses:\n\n(1) The experimental results on ImageNet64x64 are inconclusive and less convincing. Apparently, BPG is not optimized for coding small-resolution images. This may also be true for HiFiC. \n\n(2) While this is a good theoretical paper, the authors are alerted to a relevant work (Lossy Image Compression with Conditional Diffusion Models) that uses \u201cconditional\u201d diffusion models for lossy image compression. The proposed method is a direct contrast to this one.\nhttps://arxiv.org/abs/2209.06950\n\n(3) Complexity aspects are not fully addressed, although mentioned briefly. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the theoretical analysis is thorough. The novelty is good. But, it may be difficult to reproduce the results, given that the implementation details are missing. ",
            "summary_of_the_review": "This is a good theoretical paper. However, the experimental results on ImageNet64x64 are inconclusive and less convincing. BPG is not optimized for coding small-resolution images. This may also be true for HiFiC. As a result, it becomes unclear whether the proposed method is really worth further investigation. Complexity aspects are mentioned briefly but not addressed fully. It is expected that both the denoise process and reverse channel coding are complex. Their practicality is in question. Overall, this is an early attempt to use \"unconditional\" diffusion models for lossy image compression. It is to be noted that another late publication approaches lossy compression using \"conditional\" diffusion models and provides more empirical results. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_sBei"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_sBei"
        ]
    },
    {
        "id": "h5O294xTqf0",
        "original": null,
        "number": 3,
        "cdate": 1666674457979,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674457979,
        "tmdate": 1666674457979,
        "tddate": null,
        "forum": "jBPvRLKP_n_",
        "replyto": "jBPvRLKP_n_",
        "invitation": "ICLR.cc/2023/Conference/Paper2547/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a diffusion based lossy image compression approach. In the evaluation, the proposed method outperforms a baseline. ",
            "strength_and_weaknesses": "Strength:\n1. The topic of using diffusion for lossy compression is interesting. \n\nWeaknesses:\n1. It\u2019s hard to justify the originality of the proposed main methodology. The contribution is marginal. As far as I understand, all technologies of this paper is introduced from other paper, like diffusion and reserve channel coding.\n2. Although the author claim they have some improvement, but they only compared with HIFIC.  As far as I know, there are plenty of lossy compression works every year [1, 2, 3]. The author should compare with these works, too.\n3. The author claim in abstract, that this method is efficient. However, there\u2019s no following experiment or number that can prove this claim.\n4. The lossy compression techniques are also widely applied on video coding area, too. The author should add experiment on video compression.\n\n[1] Cui Z, Wang J, Gao S, et al. Asymmetric gained deep image compression with continuous rate adaptation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 10532-10541.\n[2] Xie Y, Cheng K L, Chen Q. Enhanced invertible encoding for learned image compression[C]//Proceedings of the 29th ACM International Conference on Multimedia. 2021: 162-170.\n[3] Deng X, Yang W, Yang R, et al. Deep homography for efficient stereo image compression[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 1492-1501.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is written in a needless complex way. Unless further clarified, it is hard to justify the originality of this paper.",
            "summary_of_the_review": "As the major technical contribution of this paper is not clear, I recommend a reject. I would raise the score if the authors provide a good clarification.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_JDSJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2547/Reviewer_JDSJ"
        ]
    }
]