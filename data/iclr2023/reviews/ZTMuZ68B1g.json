[
    {
        "id": "VKzXTw-Q0ut",
        "original": null,
        "number": 1,
        "cdate": 1666558781864,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666558781864,
        "tmdate": 1669950511677,
        "tddate": null,
        "forum": "ZTMuZ68B1g",
        "replyto": "ZTMuZ68B1g",
        "invitation": "ICLR.cc/2023/Conference/Paper1153/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new acquisition function Balanced Entropy Acquisition (BalEntAcq) for active learning, which captures the information balance between the uncertainty of underlying softmax probability and the label distribution. The new acquisition is designed to be computed without relying on other data points, which allows parallelization in computation. With the Beta distribution approximation of the marginal distribution, the authors derive a closed-form expression of the proposed acquisition. The authors run experiments and show the efficacy of the proposed method.",
            "strength_and_weaknesses": "Strength:\n1. This paper proposes a theoretically-motivated (Thm 4.1) acquisition function BalEntAcq that can select a diverse set of data points near the decision boundary (at least in the toy example studied in Section 4.2). \n2. The acquisition function can be computed without relying on other data points, which allows parallelization in sampling/computation.\n3. Empirical results show the efficacy of the proposed acquisition function.\n\nWeaknesses:\n1. It seems that the calculation of BalEnt relies on the Beta distribution approximation of the marginal probability. How difficult is it to calculate the acquisition function without the Beta distribution approximation?\n2. It would be great if the authors can add further explanations for the choice of BalEnt[x]^{-1} in BalEntAcq. Currently, it seems to me that such a choice is mainly motivated by the empirical results shown in Appendix A.13.2.\n3. Since one selling point of the proposed acquisition function is that it can be computed without relying on other data points, many existing methods (e.g., BADGE) do. I think the authors should add a discussion on the computational gain of the proposed method (e.g., what is the computational complexity of your proposed method, and what is the computational complexity of BADGE).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written and easy to follow. The proposed acquisition function looks novel to me, and it is theoretically motivated. I suggest the authors address the above-mentioned weaknesses to improve the quality of the paper.",
            "summary_of_the_review": "The proposed acquisition function is theoretically motivated and allows parallelization in computation; empirical results also confirm the efficacy of the proposed method. Overall, I am inclined to accept this paper. However, I believe this paper can be made stronger if the authors can address the weaknesses mentioned above. \n\n====after rebuttal====\n\nI would like to thank the authors for their response. I have read the response and the comments from other reviewers, and I would like to remain my scores.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_MCdP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_MCdP"
        ]
    },
    {
        "id": "OAfeMmA63Ep",
        "original": null,
        "number": 2,
        "cdate": 1666650984463,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650984463,
        "tmdate": 1666650984463,
        "tddate": null,
        "forum": "ZTMuZ68B1g",
        "replyto": "ZTMuZ68B1g",
        "invitation": "ICLR.cc/2023/Conference/Paper1153/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper tackles the problem of selecting the batches from unlabelled datasets to be labelled that are the most informative for a classifier trained on the data. This problem is traditionally studied within the paradigm of active learning, where the data to be labelled is collected sequentially in batches. The batches are selected using some notion of information gain to the current classifier. The paper presents a novel acquisition function for batch selection in active learning. The authors first examine the standard Bayesian Neural network paradigm used in active learning, and study the behavior of existing acquisition functions like BALD. The authors then outline the Balanced Entropy acquisition function, which is the ratio between the marginalized joint entropy and the entropy (plus a constant). The authors then study the behavior of this acquisition function theoretically as well as through a toy experiment. Finally the authors present an empirical study of their approach on large realistic datasets. ",
            "strength_and_weaknesses": "**Strengths**\n\n- The paper is very clearly written and easy to follow. The systematic analysis of Bayesian NNs and existing approaches in active learning approaches is quite insightful.\n- The proposed acquisition function is conceptually simple and can be easily adopted in practice. The toy experiments are also quite helpful in illustrating the effect of the acquisition function - selection of _diverse_ and _informative_ points.\n- The acquisition function also enjoys strong empirical performance in realistic large datasets, performing on par with or better than more sophisticated and expensive-to-evaluate acquisition functions. The experimental analysis is also quite thorough and provides useful insights. \n\n**Weaknesses**\n\n- I believe the key weakness of the approach to me is that the acquisition function is stated directly in a form without much motivation. It would be nice to understand how the particular ratio comes and the motivations behind said choice. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe paper is quite well written and thorough with sufficient details and examples. \n\n**Quality and Novelty**\n\nTo the best of my knowledge the proposed acquisition function appears to be novel. The paper is also well framed and results in significant empirical improvements. \n\n**Reproducibility**\n\nThe authors provide code with the submission along with sufficient details in the paper to reproduce the results. ",
            "summary_of_the_review": "In summary, the paper presents an novel acquisition function for active learning resulting in significant improvements on realistic large datasets. The paper is well written and accompanied with thorough analysis. The motivation for the exact form of the acquisition function is somewhat lacking and would be useful to add. I lean towards acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_gjo6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_gjo6"
        ]
    },
    {
        "id": "FDMRkG0VapC",
        "original": null,
        "number": 3,
        "cdate": 1666664788641,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664788641,
        "tmdate": 1668697341496,
        "tddate": null,
        "forum": "ZTMuZ68B1g",
        "replyto": "ZTMuZ68B1g",
        "invitation": "ICLR.cc/2023/Conference/Paper1153/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a novel acquisition function to improve active learning performance in Bayesian neural networks.\nThe acquisition function, referred to as Balanced Entropy Acquisition (BalEntAcq), serves as an uncertainty measure that aims to capture the information balance (or lack thereof) between the uncertainty of the underlying softmax probability computed by the Bayesian neural network and the label to be predicted.\n",
            "strength_and_weaknesses": "Strength:\n\nThrough extensive simulations and comparison with some of the existing popular active learning (AL) schemes, the paper demonstrates the potential benefits of the proposed uncertainty measure, BalEntAcq.\nEspecially, BalEntAcq has been shown to lead to the acquisition of diversified labels for data points in the pool that are well spread along the decision boundaries, thereby resulting in more efficient model enhancement through label acquisition.\nFurthermore, the computational cost of the proposed strategy seems to be fairly low compared to many AL strategies based on Bayesian experimental design (BED), thanks to the approximation of the marginal distributions based on Beta distributions.\nThis makes the proposed AL method possibly much more scalable compared to the BED, which is an important potential merit of the proposed scheme. \nOverall, the authors have shown that AL via BalEntAcq generally leads to performance improvement over other popular schemes based on several widely used benchmarks.\n\nWeakness:\n\nWhile scalability is one of the main advantages of the proposed method, direct performance assessment results demonstrating the scalability of BalEntAcq appears to be missing in the current study.\nIt would be interesting and important to see the comparison between the proposed method compared to other schemes, in terms of computational cost and scalability, especially with methods that the paper mentions to be too costly or not scalable (e.g., BADGE, CoreMSE, and other BED based schemes).\nFurthermore, it would be helpful to provide experimental support for \"linear scalability\" and \"exponential savings\" that can be attained via AL using BalEntAcq as claimed in the current study.\n\nThe implications of the sign of BalEnt, the proximity of BalEnt to 0, and its relevance to the location of the corresponding data point with respect to the decision boundaries could (and should) be better explained, considering their importance in how BalEntAcq leads to enhancing the AL performance.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper provides a comprehensive review of relevant existing methods, providing a good context for the proposed work.\nThe technical details, motivation, and main contributions of the proposed uncertainty measure, BalEntAcq, are fairly clearly stated, and the expected merits of the resulting AL scheme are sufficiently supported by extensive performance assessment results.\nThe proposed scheme is reasonable and moderately novel, but its main strength would be its enhanced AL performance in a variety of practical settings and its low computational cost and scalability rather than novelty.\n\n",
            "summary_of_the_review": "This paper presents a new uncertainty measure, BalEntAcq, that has the potential to improve AL performance in a variety of settings while still being scalable (e.g., compared to other existing Bayesian schemes).\nThe authors support their claims based on extensive performance evaluation results using widely used benchmarks, which demonstrate the potential advantages of the proposed AL acquisition function.\n\n---------\n\nThe scores have been updated after reviewing the authors' clarifications to the review comments.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_VNzQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1153/Reviewer_VNzQ"
        ]
    }
]