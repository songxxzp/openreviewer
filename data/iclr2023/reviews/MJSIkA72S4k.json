[
    {
        "id": "PW3ELKElX16",
        "original": null,
        "number": 1,
        "cdate": 1666582294776,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582294776,
        "tmdate": 1666632984961,
        "tddate": null,
        "forum": "MJSIkA72S4k",
        "replyto": "MJSIkA72S4k",
        "invitation": "ICLR.cc/2023/Conference/Paper3376/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to understand the generalization of deep neural networks. It characterizes the effective depth as the first layer for which sample embeddings are separable using the nearest-class center classifier. Then a generalization bound based on the effective depth is suggested as an indicator of generalization performance. Some experiments are conducted to validate the effectiveness of this bound in estimating the generalization. \n\n\n",
            "strength_and_weaknesses": "Strength:\n- Several insightful phenomena are observed (or validated): the network collapses until very late. The collapse in the middle layers matters for generalizations. \n- A theoretical generalization bound in effective depth is proposed, the bound can serve as a good indicator for MLPs and ConvNets.\n\nWeakness:\n- The experiments are only done for ConvNets and MLPs, how does this estimation work for more practically used architectures such as ResNets or Transformers? \n- The plots are very difficult to read because they are way too small.\n- The author did not provide enough support on why the current bound is better than what have defined before. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to understand, but the figures are bad. ",
            "summary_of_the_review": "This work points to a new angle of understanding the generalization performance -- how neural collapse in the middle layer affects generalization. The neural collapse in the middle layer is further quantified by the \"effective depth\". The only concern that comes from the reviewer is the gap between theory and practice. It would be nice to see some experiential results on more \"advanced\" neural networks. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_VKrE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_VKrE"
        ]
    },
    {
        "id": "adBlg-VGke",
        "original": null,
        "number": 2,
        "cdate": 1666625320918,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625320918,
        "tmdate": 1666690275294,
        "tddate": null,
        "forum": "MJSIkA72S4k",
        "replyto": "MJSIkA72S4k",
        "invitation": "ICLR.cc/2023/Conference/Paper3376/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for evaluation the generalising capabilities of neural networks through neural collapse",
            "strength_and_weaknesses": "Strengths:\n- I kind of like the idea of evaluating neural collapse for measuring generalisation.\n- Mathematical analysis seems interesting (although I did not check it in detail).\n\nWeakneses:\n- I am not convinced that this is better measure than what is already present as there is real no proof of that. In the introduction and other parts it states \"In many practical settings [...] making the bounds vacuous\". This is repeated several times, but I failed to see an in-depth analysis of those \"practical settings\" and what are those \"vacuous bounds\". One finds something at the end of section 3 but is the same repetition about vacuous bounds and sqrt(m), and not an in-depth analysis in how it compares to the other \"classical measures\". It all becomes very vague and repetitive when addressing the advantages of the presented measure when compared to those \"classical\" ones.\n- All plots are awful as they are barely visible. Labels must be font size 2.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality is not the strength of this paper as plots are ridiculously small and one can barely guess what they show. Reproducibility I did not see a link to the code used to produce the values in tables and figures.",
            "summary_of_the_review": "I have mixed feelings. I am up for new ideas, but the paper does not do a good job on:\n\n 1. Showing that is better measure than other measures. Instead of repeating over and over that \"classical measures\" provide \"vacuous bounds\", how about using that space for and in-depth analysis and comparison with each one of those measures?. and \n\n2. I do not think authors spent the time necessary on the figures so that the reader would not need a microscope to see what is plotted there.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_JHSQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_JHSQ"
        ]
    },
    {
        "id": "r6IzIObmg9",
        "original": null,
        "number": 3,
        "cdate": 1667373882874,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667373882874,
        "tmdate": 1667373882874,
        "tddate": null,
        "forum": "MJSIkA72S4k",
        "replyto": "MJSIkA72S4k",
        "invitation": "ICLR.cc/2023/Conference/Paper3376/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new generalization bound for deep neural networks based on the effective depth. The idea is motivated by the empirical observation that neural networks\u2019 representations exhibit neural collapsing. The authors define the notions of effective depth and minimal depth of a neural network, and establish a generalization bound based on the comparison between them. The paper also provides empirical estimation of the bound which is shown to be tighter than previous bounds.",
            "strength_and_weaknesses": "Strength:\n- The idea of establishing a generalization bound based on the neural collapsing phenomenon is novel and interesting.\n- The experiments are comprehensive and details are provided.\n\nWeakness:\n- It's unclear whether some of the technical settings are necessary. For example, I don't see how the specific structures of Conv-L-H and MLP-L-H come into play in the theory.\n- I somehow feel the first term in the bound could be pretty large, hence making the bound vacuous. The authors provide some experiments to justify that the term is small, however, the way they compute d_min is by relying on the implicit bias of SGD, which is really not reliable since SGD may not be able to find really the best shallow network that fits the data. I wonder we can find a smaller d_min with the following algorithm: given some target depth d, we train a (d-1)-layer NN classifier to achieve less than eps error, then we embed the last linear layer into an additional layer by add a bunch of 0 weights. Would this lead to a d-layer NN with epsilon error? If so I feel this might give us a smaller depth than train d+1 layer NN and then chop off the last linear layer.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and novel, the writing is of reasonably good quality.",
            "summary_of_the_review": "I think this paper provides a novel perspective of generalization bounds from the angle of neural collapsing. Although the theory is not complicated, it's idea is novel as far as I can tell, and could be of interest to many theoreticians in the ML community. Thus I would be happy to see this work getting accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_nZgi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3376/Reviewer_nZgi"
        ]
    }
]