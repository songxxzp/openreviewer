[
    {
        "id": "F-IrA0qJgr",
        "original": null,
        "number": 1,
        "cdate": 1666548047630,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666548047630,
        "tmdate": 1666548047630,
        "tddate": null,
        "forum": "rLguqxYvYHB",
        "replyto": "rLguqxYvYHB",
        "invitation": "ICLR.cc/2023/Conference/Paper2756/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a two-stage regression method to estimate the average treatment effects under back-door and front-door adjustment. Both stages use neural network models to learn the relevant functions. They conducted several experiments to illustrate the performance of their proposed method, using several state-of-the-art methods as baselines.",
            "strength_and_weaknesses": "Strength:\n\n1. This paper has a thorough literature review.\n\n2. I think the proposed method is flexible to handle multiple treatments or continuous treatments. That is an advantage compared to other methods in the literature. But on the other hand, I also have doubts / questions on the effectiveness of the method, as outlined below.\n\nWeakness:\n\n1. On a high level, in either back-door or front-door adjustment, how do you get the adjustment variables, X or M in the paper? Some intuitions might help the reader understand better about the problem. Also, in the experiments, you took X or M to be a noisy version of U. If the noise is small, does it imply that we have too good an adjustment variable?\n\n2. Even though the paper claims that their method was developed in a front-door or back-door adjustment scenario, the truth is that, the authors simply assumed the existence of an adjustment variable (X or M), and developed a method that applies to the adjustment variables. In this sense, it is no different than other methodologies which make the assumption that all confounders can be observed. This is also why the proposed method can be directly compared to, e.g., dragonnet, which assumes observable confounders. \n\n3. One big problem I can see with the proposed method is that, it does not take into account the problems with doing causal inference on observational data, namely, the distribution of X in different treatment groups could be very different. That is why various methods have been developed in the literature to account for this treatment assignment bias, e.g., doing distributional matching in Tarnet (Shalit, U., Johansson, F.D. and Sontag, D., 2017, July. Estimating individual treatment effect: generalization bounds and algorithms. In International Conference on Machine Learning (pp. 3076-3085). PMLR.) \n\n4. The other disadvantage I can see with this two-stage regression method lies in that, the estimation of the regression models in the two stages is somehow independent. In other words, the 1st stage model cannot be informed by the 2nd stage. This is the shortcoming of a two-stage model compared to a joint model.\n\n5. I am also curious that, when you have discrete treatments, does it pose any challenge for you to estimate the \\phi_A function? How do you estimate \\phi_A in this case?\n\n6. I think you need a better way to illustrate your algorithm, either graphically or a step-by-step procedure.\n\n7. On Page 4, bottom line, left equation, is it a typo to use f_{\\phi(M)}(a)? Should you use \\phi_M(m)?\n\n8. In the experimental section, when you compared with other methods such as dragonnet, did you ensure that you used the same neural network architecture for a fair comparison? I know that the original paper of dragonnet used a very simple 2-layer neural net to estimate the conditional outcome. I am wondering if you used a more complex neural network in your method which could explain the better performance of yours. Also, dragonnet can be extended to multiple treatments case, which can also serve as a baseline in your multi-treatment experiment. You might also want to include tarnet as a baseline in the binary treatment experiment.\n\n9. In terms of the metrics, why did you use MAE in Table 1, but MSE in Figs. 2 and 3? Also in the IHDP dataset, you did not have a front-door or back-door adjustment, right?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written in a clear way. But I do not think the quality or novelty is sufficient for publication at ICLR.",
            "summary_of_the_review": " I think the proposed method is flexible to handle multiple treatments or continuous treatments. But there are some major issues with the proposed method which I outlined in the Strength and Weakness section, e.g., it does not take into account the treatment assignment bias in the observational data. I also have doubts in the reliability of the experimental results, e.g., whether they did a fair comparison with other methods.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_VeMx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_VeMx"
        ]
    },
    {
        "id": "c9KTQh0Eat",
        "original": null,
        "number": 2,
        "cdate": 1666595653831,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666595653831,
        "tmdate": 1670834961823,
        "tddate": null,
        "forum": "rLguqxYvYHB",
        "replyto": "rLguqxYvYHB",
        "invitation": "ICLR.cc/2023/Conference/Paper2756/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work studies front-door and back-door adjustment using tensor product of learned kernels, generalizing Singh et al (2021) which employed fixed-form kernels.  The authors establish consistency for the estimators, and demonstrate improved performance on IHDP and a synthetic high-dimensional benchmark.\n\n---\n\nPost-rebuttal update: Thank you for your response. I'm raising my score given the new experiments.",
            "strength_and_weaknesses": "The proposed method combines the tensor product formulation, which simplifies the estimation of ATT, and kernel learning, which leads to improved flexibility.\n\nMy main concerns are the relative lack of novelty, and the significance of the contribution: \n* Broadly speaking, the idea of using learned kernels in kernelized estimators for causal effect have been well-studied (Xu et al, 2021a; 2021b).  For the specific problems of back-door and front-door adjustment in this work, the generalization of the corresponding kernel estimator (Singh et al, 2021) is straightforward, and does not appear to introduce new challenges.\n* The lack of novelty will not be an issue if the benefits of the proposed method are more clearly demonstrated, but I'm not really sure if this is the case here: on the theoretical side, the authors established consistency results with worse rates than Singh et al (2021); thus, no provable benefits over fixed-form kernels were demonstrated.  On the empirical side, the empirical improvements are mainly demonstrated on the dSprite dataset, which is highly synthetic, and does not appear to relate to real-world problems well.\n\nIn aggregate, I feel there should be more demonstration of the contributions from either side, before there is a compelling case for acceptance.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is well written\n\nReproducibility: the authors provided code, and the algorithm appears easy to implement.\n\nNovelty: I am a bit concerned about novelty, as detailed above.",
            "summary_of_the_review": "Pros:\n\n+ Proposed algorithm is a natural and intuitive extension\n\nCons: \n\n- Novelty is lacking\n- Neither theoretical nor practical benefits were clearly demonstrated",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_Cbhn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_Cbhn"
        ]
    },
    {
        "id": "NTrCVATXDy2",
        "original": null,
        "number": 3,
        "cdate": 1666663848046,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663848046,
        "tmdate": 1670279688601,
        "tddate": null,
        "forum": "rLguqxYvYHB",
        "replyto": "rLguqxYvYHB",
        "invitation": "ICLR.cc/2023/Conference/Paper2756/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "A method is presented for estimating causal treatment effects from observational data using neural networks for the sake of modeling flexible nonlinear relationships in the relevant conditional expectation functions. Techniques for both backdoor and frontdoor adjustments based on the directed acyclic graph causal inference theory of Pearl are presented.  The conditional expectation of outcome Y given treatment A and backdoor control X is assumed to be a linear combination of a separable tensor product of individual neural network transformations of A and X. The method has better scaling properties than competing neural-network-based causal inference methods when treatment effects are continuous and/or the problem space is high dimensional. Theoretical results based on Rademacher complexity convergence theory demonstrating the consistency of the methodology is presented. Positive experimental results on semi-synthetic health policy data and synthetic benchmark image data often used for causal inference research on images are presented.",
            "strength_and_weaknesses": "The methodology is novel to the best of my knowledge.\n\nFor the most part, I think the paper is very well written, although there are a few spots where I think the paper makes claims which are a bit too overbroad (I will elaborate shortly). \n\nThe experimental results look reasonably strong but I have a few concerns there. One concern is that ReiszNet(DR) does beat the proposed method on the health policy dataset, to a degree that may not be large but does seem to be reasonably statistically significant. I commend the authors for having the honesty to report this result, but it does weaken the case for neural mean embedding at least slightly. For the dSprite experiment, I thought the relationship between the backdoor control X and the hidden confounder U was disappointingly simple  (X1, X2 are just U1, U2 + noise). I would have thought/hoped that the authors would want to demonstrate the merits of their neural network-based technique by demonstrating the ability to capture a more complex relationship between the hidden confounder and the backdoor control.\n\nThe main overstated claim I see is that the abstract claims \"Alll functions and features (and in particular, the output features in the second stage) are neural networks learned adaptively from data, with the sole requirement that the final layer of the first stage\nshould be linear\"...but in fact, that is not the sole requirement. At the bottom of page 3, an assumption is made that g(A,X) can be represented as a linear combination of a separable function of individual neural net transformations of A and X.  I say \"separable\" here because that would seem to be an appropriate term, given that g has to be a linear combination of a tensor product of neural_net_1(A) times neural_net_2(X).  So A and X cannot interact arbitrarily in a nonlinear way. On page, 4, the authors refer to the advantage of this specific functional form and I don't doubt that there are advantages, but there is also the disadvantage of the possibility that some g(A,X)'s may not be implementable by the architecture, regardless of the number of hidden units used in either of the neural nets (unless I have misunderstood something). So the final layer of the first stage being linear is not the \"sole requirement\". I feel like the implications of this separability choice needed to be discussed/justified more. In my opinion, that would be a better use of space than the Rademacher complexity consistency/convergence stuff, which strikes me as perfectly OK but unsurprising...in general, we know that a neural net with a given number of hidden units has finite Rademacher complexity and you will converge on the correct hypothesis in the infinite data limit ...so this section seems unsurprising.\n\nThe other clarity concern I have is more minor but I would still like to see it cleaned up. There are a few spots where the writing could be taken to suggest that you can always solve the problem of having an hidden unobserved confounder with a backdoor adjustment. In fact, you have to be lucky enough to have an observed backdoor variable which closes the backdoor path between treatment and outcome. The abstract says \"the goal in both cases is to recover the treatment effect without having an access to a hidden confounder\".  The introduction says that \"In health care, patients may have underlying predispositions to illness due to genetic or social factors (hidden), from which measurable symptoms will arise (back-door variable)\".  I don't think \"will arise\" is appropriate here...you might be lucky enough to have access to measurable symptoms which close the backdoor paths from treatment to outcome via the hidden factors, but you also might not have access to any such measurable symptoms. Not a big problem, but some readers might get the impression that you can always deal with hidden confounders this way, and that is not true- you might not have any observed backdoor variable. \n\nI am open to persuasion during the rebuttal phase, however.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe quality is fine aside from the lack of justification of the separability assumption made for g(A,X) and some minor/moderate deficiencies in experimental results which I outlined in the previous section. \n\nThe clarity is mostly very good aside from skipping over the separability assumption and aside from the implicit suggestion that you can always deal with hidden confounders. \n\nThe research is original to the best of my knowledge. ",
            "summary_of_the_review": "A method is presented for estimating causal effects from observational data using neural nets to model conditional expectations. The abstract promises no assumptions or requirements for the functions to be learned aside from linearity in one output layer, but in fact the method assumes a separability between neural net transformations of the treatment and the backdoor variable. Experimental results are resonably strong but the method does not always win and one of the experiments chooses a very simple relationship between hidden confounder and backdoor variable which does not seem to take full advantage of the upside of the flexible neural net methodology.\n\n***Update post-rebuttal ***\n\nIn light of the newly added approximation theorem and the new dSprite experiment with a more complex nonlinear control variable relationship, I have raised my score to a 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_BgB4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_BgB4"
        ]
    },
    {
        "id": "QQqogRENce8",
        "original": null,
        "number": 4,
        "cdate": 1666922241604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666922241604,
        "tmdate": 1666922241604,
        "tddate": null,
        "forum": "rLguqxYvYHB",
        "replyto": "rLguqxYvYHB",
        "invitation": "ICLR.cc/2023/Conference/Paper2756/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper targets continuous intervention and counterfactual problem which is usually handled by back-door and front-door adjustment in causal inference. In particular, the authors aim to improve two-stage regression limited by fixed pre-specified feature maps. To improve, the authors propose employing two neural networks to extract adaptive features and estimate the mean embedding, respectively. The loss function is the regression loss with regularization. More importantly, the authors provide with theoretical analysis of the consistency of the proposed method using Rademacher complexity, which bounds the estimated ATE, assuming all the functions in the hypothesis space are Lipschitz continuous. Lastly, the authors demonstrate the proposed method on two popular causal data sets to support their claim. \n\n",
            "strength_and_weaknesses": "Strength:\n1) The authors focus on the important problem, treatment effect, in the causal inference community. They leverage the approximate power from the neural networks to focus on back-door adjustment and front-door adjustment. \n2) The idea is straightforward and intuitive. The theoretic analysis provides insights into the proposed method. \n3) The experiment results are promising. \n\nWeaknesses:\n1) It seems that it assumes the best approximation function exists in the hypothesis function space. However, what if that is not the case?\n2) It is a bit unclear to me why the function form of g(a,x) is designed in the way stated in the paper. Maybe more explanation will be better. \n\nQuestion:\n1) Could you please explain a bit more about why you design the L2 loss function in Equation 2?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and follows naturally. The idea and statement are clearly stated. The proposed method is novel and straightforward. The provided theoretic analysis is interesting. ",
            "summary_of_the_review": "The paper proposes to train two neural networks for estimating treatment effect, an important question in causal inference. The two neural networks are trained based on regression objectives, which can be easily reproduced. The authors then provide with the theoretic analysis to bound the estimated treatment effect for intervention and counterfactual setting. The experimental results look promising and intriguing. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_jNzo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2756/Reviewer_jNzo"
        ]
    }
]