[
    {
        "id": "ox94-byhyLi",
        "original": null,
        "number": 1,
        "cdate": 1666124892245,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666124892245,
        "tmdate": 1666124892245,
        "tddate": null,
        "forum": "p49GcKDM_XH",
        "replyto": "p49GcKDM_XH",
        "invitation": "ICLR.cc/2023/Conference/Paper986/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper empirically demonstrates that SGD learns single-hidden-layer neural networks with near-optimal sample complexity efficiently which matches the theoretical bound of an optimal learner in JV22, while according to theoretically lower bounds achieving the optimal sample complexity is intractable in the worst case. ",
            "strength_and_weaknesses": "Strength:\nThe experimental results are solid with adequate details.\n\nWeaknesses:\n1, the title is somewhat ambiguous and over-selling. The scope of experiements is focused on learning single-hidden-layer neural networks, I suggest changing the title to be more specific, for example \"SGD learns single-hidden-layer neural networks efficiently\".\n2, the main result of this paper is empirically showing that SGD learns single-hidden-layer neural networks efficiently. However, this is not surprising because SGD is known to generalize well on large-scale neural networks. Re-showing this phenomenon empirically on toy models doesn't feel interesting to me. It would be interersting to prove it theoretically though.\n\nQuestion:\nCan you give more details on how you generate the parameters of teacher networks? If all the weights are iid Gaussian, is the resulting teacher network still \"random\"? In particular, in the single-hidden-layer setting, there are works on the infinite width limit of such random neural networks. I'm concerned that the empirical results only applies to the class of fucntions \"favored\" by random neural networks, which might be very different from practical fucntions we care about.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. However I believe the title can be improved.\n",
            "summary_of_the_review": "The empirically results are solid but not significant enough in my opinion, thus I lean to rejection.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper986/Reviewer_nw89"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper986/Reviewer_nw89"
        ]
    },
    {
        "id": "BDoM1l3GNpd",
        "original": null,
        "number": 2,
        "cdate": 1666681869746,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681869746,
        "tmdate": 1666727370859,
        "tddate": null,
        "forum": "p49GcKDM_XH",
        "replyto": "p49GcKDM_XH",
        "invitation": "ICLR.cc/2023/Conference/Paper986/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper empirically studies fitting single-hidden-layer neural networks where data is also generated by single-hidden-layer ReLU teacher networks. This paper demonstrates that stochastic gradient descent (SGD) with automated width selection attains small expected errors for a specific experiment setting.   They finally claim that this result further suggests that SGD nearly achieves the information-theoretic sample complexity bounds.",
            "strength_and_weaknesses": "Strength:\n1. Well organized, and the message is clear\n2. the explanation of synthetic experiments is comprehensive. I believe that the result is reproducible.\n\nWeakness:\n1. This paper only conducts experiments for a specific case. In particular, they assume that the teacher network has independent Gaussian weights. Therefore, this is only a special case of the ReLU data-generating process.\n\n2. There are no theoretical results. If one wants to claim that SGD can nearly achieve the information-theoretic sample complexity bounds under a certain condition, one would better derive some rigorous upper bound for the proposed algorithm. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clear. However, the novelty of this paper may be limited given Jeon &Van Roy (2022).",
            "summary_of_the_review": "This paper empirically studies fitting single-hidden-layer neural networks where data is also generated by single-hidden-layer ReLU teacher networks. Since there are only some simple experiments for two-layer NN on the synthetic data, this paper would better be viewed as an extended appendix of Jeon &Van Roy (2022). I highly recommend the authors add some theoretical results, even for some special cases.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper986/Reviewer_CY12"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper986/Reviewer_CY12"
        ]
    },
    {
        "id": "hP3BYjP3m1",
        "original": null,
        "number": 3,
        "cdate": 1666823397890,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666823397890,
        "tmdate": 1670441239939,
        "tddate": null,
        "forum": "p49GcKDM_XH",
        "replyto": "p49GcKDM_XH",
        "invitation": "ICLR.cc/2023/Conference/Paper986/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper tries to show that SGD is effective in learning a ReLU teacher network. The results seem to suggest that the sample complexity is linear in input dimension and width. ",
            "strength_and_weaknesses": "strength:\n\na) The goal of the paper is well-motived.\n\nweaknesses:\n\na) The title of the paper over claims the purpose of the paper. It only focuses on learning a ReLU teacher network, rather than provides general validation for SGD\n\nb) Even though the current theoretical results only provide worse-case guarantees, I am not fully convinced that the experiments in this paper can illustrate the expected error of an algorithm for the following reasons: i) experiments can only validates some cases and the experiments in the paper are not extensive; ii) there are many versions of SGD, which can hugely affect the results. For example, the paper uses Adam stepsizes, and other stepsize schemes may lead to totally different observationsi. \n\nc)  I also suggest to try networks with more layers.\n\nd) The writing needs improvement. There are same sentences in the abstract and introduction. ",
            "clarity,_quality,_novelty_and_reproducibility": "I believe the work is original. The paper is easy to read. ",
            "summary_of_the_review": "See above. \n\n\n-----------------------------------------------------------------\nI read authors' response and I will keep my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper986/Reviewer_SPUX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper986/Reviewer_SPUX"
        ]
    },
    {
        "id": "VUsJXIp3bJP",
        "original": null,
        "number": 4,
        "cdate": 1666985203275,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666985203275,
        "tmdate": 1666985203275,
        "tddate": null,
        "forum": "p49GcKDM_XH",
        "replyto": "p49GcKDM_XH",
        "invitation": "ICLR.cc/2023/Conference/Paper986/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work fits the single-hidden-layer neural network to data generated by a teacher network with Gaussian parameters. Conclusion is drawn from experimental results that SGD with automated width selection has both sample and query complexity scaling linearly with the input dimension and width, which complies with the information-theoretic sample complexity bounds and is significantly more computationally efficient than the worst-case query lower bound suggests.\n",
            "strength_and_weaknesses": "**Strength**\n- It\u2019s of value to empirically measure both the sample complexity and the iteration complexity for learning with neural network of algorithms as simple as SGD. This work further simplifies the dynamic by running simulations on the data generated from a teacher single-hidden-layer Relu network and learning with a student single-hidden-layer Relu network whose width is automatically chosen. The motivation for this setup is straightforward to bring up the gap between the theoretical worst-case guarantees and the empirical performance in expectation. \n- The results also showcase the efficiency of SGD in training single-hidden-layer NNs, which may applies to NNs with more advanced structures. The experiments are designed in a well-organized way, and so are the results shown.\n\n**Weakness**\nThough many theoretical results were established for single-hidden-layer NNs, and it may be the reason why this work focuses on this simple structure: to directly contrast the results from the theory side and the practice side, results in this work may not bring sufficient insight why SGD trains NNs well  to the deep learning community.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written with good clarity. Comments on quality and novelty are summarized in Strength/Weakness. I didn\u2019t check the reproducibility but I\u2019d like to believe the results are reproducible.\n\n",
            "summary_of_the_review": "This work focuses on a the open question that how well SGD trains NNs in terms of its sample and query complexity and draws a conclusion matching our expectiaion on empirical performance v.s. theoretical bounds . However, it's heavily limited by the overly simplified NN sturcture and the insufficient insight that could be drawn from the experimets. So I recommand a reject/weak reject.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper986/Reviewer_7vtM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper986/Reviewer_7vtM"
        ]
    }
]