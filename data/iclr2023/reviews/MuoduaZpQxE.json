[
    {
        "id": "LgJVAWyszhY",
        "original": null,
        "number": 1,
        "cdate": 1666362846472,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666362846472,
        "tmdate": 1666362846472,
        "tddate": null,
        "forum": "MuoduaZpQxE",
        "replyto": "MuoduaZpQxE",
        "invitation": "ICLR.cc/2023/Conference/Paper5967/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a MAML-like approach for neural operators aimed at transferring learning across slightly varying physical systems. It builds on recent work on implicit Fourier neural operators and proposes a meta-learning method that uses MAML for the (first) lifting layer, while the remaining layers (including the Fourier layers) are meta-learned but not adapted at meta-test time. The proposed method is experimentally evaluated on simulated PDE data as well as a real-world physical tissue response setting.\n",
            "strength_and_weaknesses": "Strengths:\n* Relevant problem with clear application\n* Real-world experiments\n* The first meta-learning approach based on neural operators\n\nWeaknesses:\n* The presentation of the work could be improved a lot\n* No standard errors are reported in the experiments. Were experiments even repeated with multiple seeds\n* Not enough experiment details to reproduce experiments\n* Assumptions in Section 3.3. are not motivated\n\nMinor typos:\n* 3rd paragraph on page 3: \u2018neural operators requires\u2019 -> \u2018neural operators require\u2019\n* Page 4, \u2018we denote the set trainable parameters\u2019 ->  \u2018we denote the set of trainable parameters\u2019\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the paper could be improved a lot. In particular:\n* Section 2 is very verbose and could be made much more concise\n* The formal problem setting which is introduced in the intro with formulas (i.e. Eq. 1) is not very clear since relevant concepts have not been introduced yet at that point. For instance, it is not clear at all how $\\mathbf{b}$ interacts with the rest of the PDE model. While the intro already talks about the solution of Eq. 7, the formula is only introduced 4 pages later. I think it would be more pedagogical to first talk about the \u2018normal\u2019 neural operators and then introduce the multi-task structure later.\n* The notation is heavy and not very well explained. Since mathematical symbols often re-appears 2 pages later again without any reminders of their meaning, I found myself often scrolling back to find out how each symbol was defined. For instance, it would help the reading flow a lot if you would write \u2018a function from the space of property fields B to the loading fields A\u2019  instead of \u2018a function from B to A\u2019\n* A lot of the formalization and explanation in the paper is very specific to mechanical engineering & physics. This makes the paper not very accessible to the broader machine-learning audience at ICLR.\n* Assumptions 1 & 2 are not motivated much. If you make assumptions to prove a theorem you should explain why they are necessary and when they hold in practice.\n\nThe paper is novel in the sense that it is the first work I know of that does meta-learning with neural operators. The proposed approach itself is a straightforward combination of gradient-based meta-learning and Fourier neural operators. I do not find the universal approximation result very useful or enlightening. From how it is presented, it seems like the authors just assumed whatever they needed so that theory of Lu et al. (2019, 2021) goes through. \n\nWhile the experiments include relevant baselines and appropriate evaluation problems, there are not enough details to reproduce the experiments. More critically, it seems like the experiments have not been repeated with multiple seeds, and no standard errors are reported. This casts serious doubts about the experimental methodology and the reliability of the presented experiment results.\n\n",
            "summary_of_the_review": "Overall, I think that the studied problem is relevant and the proposed method has its merits. Unfortunately, it is not very well presented which makes the paper hard to read. In addition, there are serious shortcomings in the experimental methodology and documentation. At the moment, I do not think the paper is ready for publication. Since I consider the proposed method relevant, I encourage the authors to seriously re-work and improve the writing of the paper based on my comments above. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_evBd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_evBd"
        ]
    },
    {
        "id": "h34vXWNlD8",
        "original": null,
        "number": 2,
        "cdate": 1666522363525,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666522363525,
        "tmdate": 1666592775812,
        "tddate": null,
        "forum": "MuoduaZpQxE",
        "replyto": "MuoduaZpQxE",
        "invitation": "ICLR.cc/2023/Conference/Paper5967/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Authors propose a (somewhat) novel method that combines meta-learning with a popular operator learning model (based on the Fourier-Neural Operator learning paradigm) and develop a few-shot learning framework to learn PDE based domains. Additionally, authors also introduce a novel modification to the few-shot inner-loop model update wherein the updates are only localized to the \u201clifting\u201d layers in the FNO based operator framework. ",
            "strength_and_weaknesses": "## Strengths: \n\n**[Novel Few-Shot Operator Transfer Learning]**: Authors address an important problem of few-shot learning in the context of knowledge transfer across PDE domains. Specifically, the proposed MetaP, MetaP+ methods learn to effectively transfer knowledge with only a few instances of data from the target task of interest. \n \n\n**[Demonstration on Synthetic and Real-world Data]**: The proposed framework not only demonstrates good results on a set of synthetic PDE based domains but also on real-world task of learning to estimate mechanical response of biological tissue specimen from displacement tracking measurements. \n \n\n**[Effective Few-shot Performance]**: The MetaP, MetaP+ models demonstrate very effective few-shot generalization performance with as little as 2 instances required to achieve <5% prediction errors on synthetic data with similar results also on real-world datasets.  \n \n\n**[Baseline Comparison]**: Authors compare with popular meta learning models MAML [2], ANIL [3] and a version of the base model [4] without meta-learning as ablation baselines. The proposed models outperform all baselines under few-shot learning settings.   \n\n \n\n## Weaknesses: \n\n**[Some Baselines Missing]**: A related few-shot operator learning baseline model [5] based on one-shot-learning with deep operator networks is missing. \n \n\n**[Out-of-Distribution Results Require Further Clarity]**: Some of the out-of-distribution based experiments seem to produce results that are better than in-distribution test results. Without qualitative visualizations of training and testing regimes (out-of-distribution case), it is hard to comprehend the degree of challenge posed by out of distribution data regime. \n \n\n**[Limited Novelty]**: Although the problem is well motivated and results of the proposed pipeline are somewhat convincing, the proposed framework itself is not significantly novel. Specifically, the sole contribution of the authors may be considered to be the insight of transfer learning by fine-tuning the \u201clifting layer\u201d in the neural operator (backed by theoretical and quantitative results) instead of the last layer as in traditional transfer-learning paradigms. Other parts of the model (I.e., based model , meta-learning framework) are directly employed from previously published work. \n \n**[Typos]**: Paper has a few typos (e.g., Eq. 7 is referenced in multiple places in reference to the solution operator `G` , but Eq. 7 contains no such symbol. \n\n## Questions for Authors: \n\nHow has model architectures (number of layers, activations) selected? What is the validation set size and how was it selected?  \n \n\nPlease provide an explanation in terms of a performance breakdown for why the out-of-distribution test error of the proposed MetaP model is lower than in-distribution test error? This seems surprising considering the challenge of the task?  \n \n\nCould you please provide justification about the difference in the domain characteristics in the training and testing regimes for out-of-distribution tasks? For example, please comment on what about the test regimes makes (e.g., more stiff) make them a true test of out-of-distribution performance?  \n \n\nHow were out-of-distribution ranges selected for synthetic datasets in section 4.1? \n\n \n\n## References: \n\n1. Li Z, Kovachki N, Azizzadenesheli K, Liu B, Bhattacharya K, Stuart A, Anandkumar A. Fourier neural operator for parametric partial differential equations. arXiv preprint arXiv:2010.08895. 2020 Oct 18. \n \n\n2. Finn C, Abbeel P, Levine S. Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning 2017 Jul 17 (pp. 1126-1135). PMLR. \n \n\n3. Raghu A, Raghu M, Bengio S, Vinyals O. Rapid learning or feature reuse? towards understanding the effectiveness of maml. arXiv preprint arXiv:1909.09157. 2019 Sep 19. \n \n\n4. Li Z, Kovachki N, Azizzadenesheli K, Liu B, Bhattacharya K, Stuart A, Anandkumar A. Neural operator: Graph kernel network for partial differential equations. arXiv preprint arXiv:2003.03485. 2020 Mar 7. \n \n\n5. Lu L, He H, Kasimbeg P, Ranade R, Pathak J. One-shot learning for solution operators of partial differential equations. arXiv preprint arXiv:2104.05512. 2021 Apr 6. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the proposed model, experiments and results indicate a good quality paper. Unable to verify  / reproduce results due to non access to the source code. ",
            "summary_of_the_review": "The paper proposes a novel few-shot learning based neural network based operator learning framework. Although the results are convincing, the proposed model is significantly based on previously proposed research efforts and the main contribution of the paper is their insight about fine-tuning the \"lifting layer\" instead of the final layer as in traditional transfer learning paradigm. Overall, the novelty of the proposed method is somewhat lacking but the incrementally novel proposed model does produce effective few-shot transfer learning results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_GCvR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_GCvR"
        ]
    },
    {
        "id": "szTHm1Kamjm",
        "original": null,
        "number": 3,
        "cdate": 1666661119858,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661119858,
        "tmdate": 1666661684414,
        "tddate": null,
        "forum": "MuoduaZpQxE",
        "replyto": "MuoduaZpQxE",
        "invitation": "ICLR.cc/2023/Conference/Paper5967/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work developed a novel meta-learnt method to transfer learning knowledge between neural operators. Different from typical\nfinal-layer transfer in existing meta-learning methods, this paper adapted the first layer of the neural operator model to capture hidden\nparameter field. Evaluation on both synthetic and real world datasets demonstrate the efficacy of the proposed approach. ",
            "strength_and_weaknesses": "* Strength\n1. The idea of transferring knowledge between neural operators is interesting and novel\n2. It adapted the first layer of the neural operator model to capture hidden parameter field in contrast to the final-layer transfer in existing meta-learning methods\n3. Conduct extensive experiments on benchmark and real-world datasets to verify the effectiveness of the proposed approach \n\n* Limitations\n1. It only adopted Fourier Neural Operator to show the effectiveness of the method, and it would be better to study more neural operators to verify this idea.\n2. Please repeat the experiments multiple times and then report the average error and standard deviation.\n3. A couple of grammatical issues. For example, \"As an motivating example,\" on page 1; and \"ANIL In \" on page 5, I am curious if a reference is missing?\n4. Questions:\n[1] In fig 2, why the accuracy of OOD task is better than ID task? Please provide possible explanation on it in more detail.\n[2] I am curious where could we access the real-world dataset: biological tissue specimens from DIC displacement?\n[3] I am wondering if the proposed method could learn multi-tasks from different PDEs rather than one common PDE with different physical parameter?",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of this paper is clear and decent. The idea is novel and interesting. It would be better if the author could release the source code for readers to reproduce the experimental results.",
            "summary_of_the_review": "It is interesting and novel to transfer the knowledge between neural operators. It would be much better to explore more neural operators to further verify the effectiveness of the proposed method. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_koC6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_koC6"
        ]
    },
    {
        "id": "qGdNiROSPZr",
        "original": null,
        "number": 4,
        "cdate": 1666661586496,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661586496,
        "tmdate": 1666661754401,
        "tddate": null,
        "forum": "MuoduaZpQxE",
        "replyto": "MuoduaZpQxE",
        "invitation": "ICLR.cc/2023/Conference/Paper5967/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an approach to use MAML-based meta learning to learn a neural operator that approximates complex PDE-based equations with different physical parameters. Instead of optimizing all parameters of the base model during inner optimization (like vanilla MAML) or only the last layer (like ANIL), this paper's main contribution was to show that the first layer of the neural operator should be optimized. Experiments were conducted both on synthetic data, benchmark data, and a real-world data that describes mechanical response of biological tissue specimens from DIC displacement tracking. Experiments were mainly concerned with baselines using the neural operator without the presented meta-learning formulati",
            "strength_and_weaknesses": "Strengths:\n\nTo be able to learn a neural operator for complex PDE-governed physics without varying parameters is important. The use of meta-learning is intuitive. \n\nThe experiments attempted various types of dataset beyond benchmark data, which is appreciated.\n\n\n\nWeakness:\n\n- A major concern is regarding the baseline. The primary baselines includes a \"single\" model trained on the meta-training data with multiple tasks, and three variants of meta-formulation. The comparison with the \"single\" model however is not fair. All the meta-models are further optimized to the context data (referred to as test data in the paper) at meta-test time; this was not accessible to the \"single model\". Two stronger baselines need to be added. One is the \"single\" model fine-tuned to the same meta-test support data (used to optimize the model for all the other meta-models during meta-testing). The other is the \"single\" model trained to the \"single\" task used in the meta-training set (and fine-tuned to the meta-test task depending on how different the tasks are). \n\n\n- Another major concern is regarding the comparison to alternative models used to approximate PDE-based physics -- there is currently a large set of literature that does this; some of them are designed to generalize across different parameter settings (examples below). These works should be included for comparisons.\n\nYin et al. LEADS: Learning Dynamical Systems that Generalize Across Environments\nWang et al. Meta-Learning Dynamics Forecasting Using Task Inference\n\n\n- The rationale for the choice of meta-learning formulations is not clear. There are many different frameworks for meta-learning, some of them do not require test-time optimization. Why this formulation versus alternatives?\n\n\n- The difference between ANIL and MetaLast is not clear -- both does inner optimization to the projection layer? Please clarify.\n\n- Intuitively, since MAML optimizes all parameters of the base model, it is not clear why it would be sub-optimal then optimizing only the first layer (except for computational overhead)? Comments on this would be appreciated.\n\n- The wording of this paper is in general somewhat confusing, since it did not utilize the standard terminology of context/target samples for meta-learning. Assuming that N_test is referring to the context set size (i.e., size of meta-test samples used for inner loop adaptation at meta-test time), what is the corresponding context set size during meta-training? Is it the same as what is used at test time? Fig 2 showed how the test error changes as N_test changes. Is this N_test only referring to the context set size used during meta_test, or is the same parameter changing during meta_testing. In all experiments, N_test is given but not the size used during meta_training. This needs to be clarified. If N_test is different from the context set size used in meta-training, the effect of the latter would be more interesting to see in ablation studies.\n\n\n\n- In synthetic experiments, it'd be good to more specifically describe exactly which parameters are used for meta-training, and which for meta-testing. i.e., it is good to have a sense of the distance between training and test task for in-distribution tasks.\n\n- In real-world data experiments, it was mentioned that \"we have 500 available data pairs\" for each specimen, but it was then stated that MetaP was trained based on but N test = 500 samples and then evaluated on another 200 samples? If only 500 pairs are available, how can we use all of them as the context set? Please clarify\n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned above, the paper describes a meta-learning methodology without using the standard terminology for meta-learning. For instance, what is exactly N_test (is it context set size) and what is it counterpart during training is not clear. Because of this, the clarity of the paper is affected.\n\nNovelty of the paper as mentioned above is limited. It involves apply MAML to neural operators, and the main contribution seems to be at identifying that in neural operator the first layers should be adapted. It lacks discussion and comparison with related works that deal with approximating PDE-solvers, especially those with a meta-learning or generalization focus.",
            "summary_of_the_review": "This paper applies a MAML variant to a neural operator for learning to approximate PDE-based physics for various parameters. The motivation is intuitive, and the point on having to adapt the first layer of the neural operator is interesting. Overall, however, this paper can be improved both in its novelty in relation to existing works, and stronger baseline/comparison methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_dEyR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5967/Reviewer_dEyR"
        ]
    }
]