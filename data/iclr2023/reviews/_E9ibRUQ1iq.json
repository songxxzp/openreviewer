[
    {
        "id": "roR6v90lCU",
        "original": null,
        "number": 1,
        "cdate": 1666601232557,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601232557,
        "tmdate": 1666601232557,
        "tddate": null,
        "forum": "_E9ibRUQ1iq",
        "replyto": "_E9ibRUQ1iq",
        "invitation": "ICLR.cc/2023/Conference/Paper2550/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes two open intent classification methods based on the label-smoothing method, C-LC, and C-ADB. More specifically, the label smoothing method takes a weighted average of the ground-true label and the uniform 1/k vector. The experiments \nevaluates the proposed methods on real-world datasets with previous baselines.",
            "strength_and_weaknesses": "Strength:\n\nThe main idea of the paper is clear. The experimental part is solid with sufficient empirical results and analyses.\n\nWeaknesses:\n\nAbout the Novelty: the proposed method is more like an empirical trick or a modification to the previous baseline LC and ADB. The motivation and justification to use the label smoothing trick remain unclear. \n\nAbout the Experiments: The proposed methods did not significantly outperform the previous baseline. On the OOS dataset, the proposed C-ADB even got worse performance than the original ADB, which makes the effectiveness of the proposed method unconvincing.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is good. The quality and novelty are not fair enough. The experiments seem reproducible.",
            "summary_of_the_review": "The method described in the paper is more like an empirical trick than a well-designed method. The motivation and justification for the method are not clearly stated. The experimental results did not show significant improvement when applying the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_UJRs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_UJRs"
        ]
    },
    {
        "id": "IahYvj2XtS",
        "original": null,
        "number": 2,
        "cdate": 1666627450013,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627450013,
        "tmdate": 1666627450013,
        "tddate": null,
        "forum": "_E9ibRUQ1iq",
        "replyto": "_E9ibRUQ1iq",
        "invitation": "ICLR.cc/2023/Conference/Paper2550/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the open intent classification problem. There are standard supervised learning approaches for this task, but the authors hypothesize that cross entropy based objective in the existing open intent classification problem leads to predictions which are overly biased towards known intents, leading to poor performance on open intents. It has been presented with empirical evidence that changing a learning objective in a more calibrated manner can lead to better performance and outperforms the existing state-of-the-art. Authors also investigate the reason for the supremacy of the calibrated model and highlight its connection with higher layers in the model.",
            "strength_and_weaknesses": "Strengths\n\nS1: It is an interesting idea to utilize model calibration towards open intent classification.\n\nS2: The proposed approach has been applied to text and image domain state-of-the-art methods.\n\nS3: The paper presents a detailed set of experiments.\n\nS4: The paper is easy to follow, but writing needs improvement.\n\n\nWeaknesses\n\nW1: The proposed approach has been empirically verified on two state-of-the-art methods, which are Adaptive Decision Boundary (ADB) and Logit-based classifier (LC). It could have been interesting to see if the approach generalizes to a few others out of domain intent classification methods.\nW2: It will be interesting to investigate the behavior of other calibration methods like temperature scaling with the proposed approach. This will add the element of completeness in the research question being investigated.\n\nW3: Logit-based classifier should be one of the baselines.\n\nW4: There are various grammatical mistakes and typos in the paper.  i) For example, in section 4.3, \u201cwe assume the adequate calibration strength will be differ from the C-LC\u2019s optimal one.\u201d  ii) Similarly, in section 4.2 in results section, \u201cwe resulted that calibration itself is beneficial\u201d. iii) Typo \u21d2 \u201coptinmal calibration sterngth\u201d\n\nW5: Figure 1 has enough empty space which can be utilized for increasing the subplot sizes. Especially, legend is difficult to read.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper presents an interesting dimension to investigate the benefits of model calibration in open intent classification problem. For establishing concrete results, at least one other calibration method should be used for drawing the conclusive evidence that indeed model calibration incorporates the inductive bias into open intent classification setup. One more out of domain intent classification method can be used in addition to ADB and LC.",
            "summary_of_the_review": "Overall, this paper investigates an interesting question. For the thorough investigation and establishing the claims, more experimentation is required.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_HHjh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_HHjh"
        ]
    },
    {
        "id": "Xyj4ujIoj5j",
        "original": null,
        "number": 3,
        "cdate": 1666885833435,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666885833435,
        "tmdate": 1669909591228,
        "tddate": null,
        "forum": "_E9ibRUQ1iq",
        "replyto": "_E9ibRUQ1iq",
        "invitation": "ICLR.cc/2023/Conference/Paper2550/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In general, this paper proposes to use the label smoothing method to calibrate the model in open intent classification problem, based on two previously used method logit classifier (LC) and adaptive decision boundary (ADB). The result in low KLR (Known Label Ratios) shows the superiority of the proposed method over previous methods, while the result in high KLR does not. Extensive experiments are taken to demonstrate that the proposed method can achieve improvements in inductive bias, representation landscape and open intent classifier performance. ",
            "strength_and_weaknesses": "**Strengths**\n1. The proposed method is clear and simple;\n2. The analysis and experiments are somewhat comprehensive.\n\n**Weaknesses**\n1. The authors claim the benefit of calibration by the proposed method, but fail to show an evaluation of the calibration performance in terms of expected calibration error (ECE).\n\n2. The experiment evaluation should be further strengthened. The following related prior works are missing and should be compared.\n\na. Likelihood ratios and generative classifiers for unsupervised out-of-domain detection in task oriented dialog, AAAI 2020\n\nb. Joint Energy-based Model Training for Better Calibrated Natural Language Understanding Models, EACL 2021",
            "clarity,_quality,_novelty_and_reproducibility": "see above.",
            "summary_of_the_review": "see above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_HPLr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2550/Reviewer_HPLr"
        ]
    }
]