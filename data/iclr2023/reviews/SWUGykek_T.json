[
    {
        "id": "5A7yS03BpK7",
        "original": null,
        "number": 1,
        "cdate": 1666675889904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675889904,
        "tmdate": 1666675889904,
        "tddate": null,
        "forum": "SWUGykek_T",
        "replyto": "SWUGykek_T",
        "invitation": "ICLR.cc/2023/Conference/Paper200/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new adversarial training scheme that leverages the semantic information from language embeddings to improve the robustness of the model to adversarial attacks. The proposed method is evaluated against various adversarial attacks and compared to multiple methods, showing competitive results.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well organized. The writing is clear, and it is very easy to follow.\n2. The idea of maintaining the semantic information of the class labels during adversarial training is sound.\n3. The proposed method is evaluated on benchmark datasets with various adversarial attacks. The performance is generally competitive compared to prior arts. It also conducts extensive ablative studies on the components of the method.\n4. The paper provides clear details on reproducing the method.\n\nWeakness:\n1. The improvements over previous methods are not convincing enough. The margins are small, especially considering that the proposed method requires more information, i.e., a pretrained word embedding. This might require more resources in real-world applications than other methods, making it less attractive.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is well-written and easy to follow.\n\nQuality & Novelty: The paper seems novel and has some potential. But the empirical results are not convincing enough to show significant advantages over existing works.\n\nReproducibility: The paper contains enough information to reproduce the method.",
            "summary_of_the_review": "This paper proposed a novel adversarial training method that enforces the alignment between the visual feature and the label semantics from a pretrained word embedding to improve the robustness of adversarial attacks. It shows some potential, but I am not very convinced by the results, considering it requires much more resources than other methods that do not rely on external information. Therefore I am more inclined to rejection.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper200/Reviewer_ARcW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper200/Reviewer_ARcW"
        ]
    },
    {
        "id": "rDi19kNH-P",
        "original": null,
        "number": 2,
        "cdate": 1666738505693,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666738505693,
        "tmdate": 1666738505693,
        "tddate": null,
        "forum": "SWUGykek_T",
        "replyto": "SWUGykek_T",
        "invitation": "ICLR.cc/2023/Conference/Paper200/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose to improve the adversarial robustness of image classification models by adding constraints between visual representations and semantic word vectors. The authors first demonstrate the correlation between visual representations and semantic word vectors and how robust features are aligned with semantic word vectors. Then they propose an adversarial framework (SCARL) to learn robust visual representations through regularizing the structure of visual representations and that of semantic word vectors. As the result, the authors demonstrate the proposed framework improves the model's robustness compared to current approaches.\n",
            "strength_and_weaknesses": "Strength: \n1. The intuition and analysis of the correlation between robust visual representations and semantic word vectors are interesting and meaningful. This opens another lens for understanding the adversarial robustness of vision models and robustness of visual representations.\n2. The paper is well-written and the proposed methods are clearly formulated.\n3. The theoretical analysis for the lower bound is helpful. But some comparisons between the results w/ and w/o utilizing this estimated lower bound would be appreciated.\nWeakness: \n1. The similarity analysis in Figure 2 is not well interpreted. How such similarity metrics are normalized is crucial for interpreting the results.\n2. The claim in caption of Figure 1 that FGSM is always less robust than standard AT lacks supporting evidences.\n3. Comparison with existing methods can be improved. Some of the existing methods can trade off accuracy over robustness (.e.g. TRADES). It might be fairer if the authors also include results of TRADES with different settings.\n4. There is a significant performance gap on natural accuracy of models trained with SCARL in CIFAR-10. That is an interesting phenomenon that might be due to limited richness of semantic information in the visual representations. The authors should discuss more on this and other potential limitations.\n\nSome minor things:\nP3: nor-robust -> non-robust\nFig 2,3 visible margins of the images. They are also redundant in the appendix.\nOther suggestions:\n\tThere is a line of research exploring how semantic word vectors improve the generalization/robustness of the vision models [1] might also be related. Some discussion of differences and future directions would be interesting.\n\n[1] Grounded Language-Image Pre-training\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper did not provide the code. Hope they can release the code. ",
            "summary_of_the_review": "See above. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper200/Reviewer_FuyA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper200/Reviewer_FuyA"
        ]
    },
    {
        "id": "JJcF2Co1JdN",
        "original": null,
        "number": 3,
        "cdate": 1667101594056,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667101594056,
        "tmdate": 1667101594056,
        "tddate": null,
        "forum": "SWUGykek_T",
        "replyto": "SWUGykek_T",
        "invitation": "ICLR.cc/2023/Conference/Paper200/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to utilize semantic information for defending against adversarial attacks. The motivation seems interesting. ",
            "strength_and_weaknesses": "Strengths:\n- The motivation for applying semantic information in defending against adversarial attacks seems interesting.\n\nWeaknesses:\n- There lacks the SOTA defending models in comparison, such as [A],[B]. The performance gain looks limited compared to the comparison methods (not the latest ones).\n- It is not clear how these semantic features come.\n\n[A] \u201cLearnable boundary guided adversarial training.\u201d CVPR 2021.\n[B] \u201cAdversarial feature desensitization.\u201d NeurIPS, 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Applying semantic information in defending against adversarial attacks seems novel.",
            "summary_of_the_review": "The motivation for applying semantic information in defending adversarial attacks seems interesting. However, the effectiveness of the proposed method is not well justified.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper200/Reviewer_Xby6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper200/Reviewer_Xby6"
        ]
    }
]