[
    {
        "id": "bkz_QjE7ac",
        "original": null,
        "number": 1,
        "cdate": 1666561800372,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666561800372,
        "tmdate": 1666561800372,
        "tddate": null,
        "forum": "SMYdcXjJh1q",
        "replyto": "SMYdcXjJh1q",
        "invitation": "ICLR.cc/2023/Conference/Paper4692/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, a deep convolutional neural network pretrained on an\nobject classification task is fine-tuned tp encourage\nrepresentation alignment of a specific layer with recordings from IT\ncortex in macaques. The behavior of the trained network is\nanalyzed, finding that representational alignment with IT correlates\nwith a closer behavioral similarity to human behavioral patterns on\nthe task, and with better resilience to adversarial attacks.",
            "strength_and_weaknesses": "## Strengths\n1. The paper contains a wealth of experimental data, including human\n   psychophysics and monkey electrophysiology. The number of monkeys\n   is large for this type of study (6), which allows to test\n   similarity metrics on held-out animals.\n2. The evidence supporting the results is generally convincing.\n3. The paper clearly underscores one limitation of the current\n   approach/set of results, by pointing out how the increase in\n   behavioral match between humans and network with increasing\n   representational alignment does not hold for object categories\n   not included in the training set. Some possible ideas for a way\n   forward on this issue are proposed in the discussion.\n\n## Weaknesses\n1. I could not find a link to the experimental data collected for this\n   work, or a promise to publish such data upon acceptance.\n2. Section 3.2 states that \"the label information during training\n   helps on the behavioral task, but is not required for the trend [of\n   better representation alignment improving behavioral match between\n   humans and deep nets] to hold\". This is correct, but in my opinion\n   this underplays the fact that label information is still used for\n   the pre-training of the network. Perhaps this passage could be\n   rephrased to remind the reader that label information is\n   nevertheless still available from the pre-training, even when it's\n   not included in the fine-tuning process.\n3. If I have understood correctly, the monkey data was recorded\n   specifically for this work. However, the phrasing around this fact\n   in the supplement is somewhat confusing. Please clarify, stating\n   explicitly that the data previously recorded from these monkeys for\n   various research objective is different data that was not used in\n   this work.\n4. I urge the authors to consider raising their compensation for human\n   subjects in future experiments. Psychophysics subjects were paid 4 USD an hour in this work (Supplementary Material). This seems very low\n   considering that the experimenters are based in Massachusetts\n   (based on the information in the paper), and the minimum hourly\n   wage is 7.25 USD federally and 14.25 USD in MA.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, and the work is of high quality and\naddresses an interesting quesion with novel data and reasonably novel approaches. The\nexperimental and analysis procedures are described in sufficient\ndetail, but I could not find links to data (human or monkey) or code.",
            "summary_of_the_review": "This is a solid paper, which will be of interest to the ICLR\ncommunity. However, the reproducibility of the results and the\npossibility for other groups to build upon the ideas presented here\ncould be hindered by lack of access to the experimental data collected\nfor this work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_Bkvv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_Bkvv"
        ]
    },
    {
        "id": "h7rgSC-Xy8W",
        "original": null,
        "number": 2,
        "cdate": 1666623522559,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623522559,
        "tmdate": 1666623522559,
        "tddate": null,
        "forum": "SMYdcXjJh1q",
        "replyto": "SMYdcXjJh1q",
        "invitation": "ICLR.cc/2023/Conference/Paper4692/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors show that aligning the internal representations of CNNs trained on image classification with macaque inferotemporal cortex renders those nets' image-to-image error patterns more aligned with humans and improves their adversarial robustness.\n",
            "strength_and_weaknesses": "### Strengths\n\n + Simple idea well executed\n + Improved alignment of CNNs with human perception\n + Improved adversarial robustness\n + Paper is well written and easy to read\n\n\n### Weaknesses\n\n 1. Unclear to what extent this result generalizes to other network architectures\n 1. Improvements are relatively small\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall I think it is a great paper that presents a simple idea in a clear manner and is well executed. As far as I can tell, demonstrating that aligning CNN and IT responses leads to more human-like behavior of the net is novel, while previous works have hinted at increased robustness by aligning CNN representations to the brain, albeit at earlier stages of the visual system.\n\nReproducibility should not be an issue, since the experimental manipulations are straightforward and well documented. However, unfortunately a statement regarding availability of code is missing.\n",
            "summary_of_the_review": "Great paper that presents a simple idea in a clear manner and is well executed. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_LQZr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_LQZr"
        ]
    },
    {
        "id": "ObuMa06OMC3",
        "original": null,
        "number": 3,
        "cdate": 1666723499359,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666723499359,
        "tmdate": 1666723499359,
        "tddate": null,
        "forum": "SMYdcXjJh1q",
        "replyto": "SMYdcXjJh1q",
        "invitation": "ICLR.cc/2023/Conference/Paper4692/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors analyze how a better reproduction of brain responses related to object recognition in artificial nets (1) improves their robustness to adversarial attacks, and (2) makes them more aligned with human behavior in object recognition. \n\nThe authors propose retraining of classification networks to enforece alignment with the response of the IT region of brain primates. The correspondence between the network and experimental measurements in IT is enforced by using the Centered Kernel Alignment (CKA).\nThe authors start from CORnet-S [Kubilius et al.19], but, in principle, the proposed loss function could be applied to other classification nets.\n\nThe results support the above points (1 and 2) when classifying objects used in the physiological experiments and using one behavioral metric proposed in [Rahalingham et al. 18].\n",
            "strength_and_weaknesses": "* Strengths: \n\n(a) The understanding of the abilities of biological neural networks in a language that can directly be incorporated in the imporvement of artificial networks is a fundamental topic for the ICLR audience.\n\n(b) The work uses original experimental results from IT (that I guess will be shared with the community) to improve nets previously fitted with general-purpose BrainScore, making them more suited to classification. And they succesfully show that the nets are not only closer to IT (as expected from the loss function), but they also improve the explanation of certain behavioral behavior and the classification performance.\n\n(c) This works represents an advance in the literature that deals with the comparison between artificial and biological networks.\n\n* Weaknesses:\n\n(a) The authors make a really interesting claim that I dont see clearly supported by the results (or I'd like to see it better stressed). In the last paragraph of the introduction and in the first paragraph of the discussion they say that increasing robustness to adversarial attacks does not necessarily imply being more close to IT. This is very interesting from the neuroscience point of view because solving the eventual problems of artificial networks in a specific task (such as classification) does not necessarily make them more human. This implies that eventhough the classification goal may be functionally sensible, the architecture or the actual strategies used by the artificial nets to get the goal are so different from the biological mechanisms that improving the performance of the artificial nets does not do them \"more biological\", and hence they provide little insight on what the brain may actually be doing. \nI see that Figs. 4 and 5 show that improved similarity with IT leads to better robustness in classification (blue points or blue lines, respectively), but in Fig. 5 I dont see how similarity with IT is measured in the orange curve. And in Fig. 4 it is not clear to me how the orange dots were trained: were they trained enforcing robustness to adversarial attacs but not imposing alignments with IT? (is this what \"random IT\" means?).\n\n(b) Reproduction of behavior is limited to a single experiment. This is fine for a conference paper but the authors should acknowledge that a single experiment does not summarize the rich aspects of visual psychophysics [Bowers et al. BioArxiv. 21]. In this regard, there is literature that proposes that biologically sensible alternatives to the current artificial neurons in conventional artificial architectures improve robustness to adversarial attacks [Bertalmio et al. Sci. Rep. 20] (in line to what is proposed in this work), but also reproduce a range of classical psychophysical (behavioral) results on brightness and texture perception. Similarly, Gomez-Villa et al. Vis.Res. 20 and Li et al. J.Vision 22, show that simpler (more human) architectures better reproduce classical color illusions and the Contrast Sensitivity Functions. The need for more exhaustive connections between physiology/architecture and behavior (wider range of psychophysics) should be acknowledged in the introduction or discussion.\n\n(c) I think readers would appreciate a mathematical expression for the \"CKA\" loss function rather than the verbal descrioption given in section 2.4\n\n* References:\n\n[Bowers et al. 22] Deep Problems with Neural Network Models of Human Vision \nhttps://psyarxiv.com/5zf4s/\n\n[Bertalmio et al. 20] Evidence for the intrinsically nonlinear nature of receptive fields in vision. Sci.Rep.\nhttps://www.nature.com/articles/s41598-020-73113-0\n\n[Gomez-Villa et al. 20] Color illusions also deceive CNNs for low-level vision tasks: Analysis and implications. Vision Research\nhttps://www.sciencedirect.com/science/article/pii/S0042698920301243\n\n[Li et al. 22] Contrast sensitivity functions in autoencoders. Journal of Vision\nhttps://jov.arvojournals.org/article.aspx?articleid=2778843",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity could be improved by making the loss function more explicit and the meaning of the examples trained just to improve the classification robustness (with *NO* IT information) in Fig. 4 (orange dots?).\n\nThe quality of the work (topic and good combination of original experimental data and well engineered methods) is remarkable, and the results are novel and interesting.\n\nI expect that the authors makes the recordings and associated stimuli public so that the community can use these input-output pairs in the future.",
            "summary_of_the_review": "I enjoyed this convincing report showing the improvement of the performance of classification networks when one enforces stronger alignment with biology (and in particular with original IT responses). Limitations are acknowledged and solutions for future physiological experiments are suggested.\nAs stated above, some clarification in the loss function and in the description of some results is desirable, as well as the acknowledgement of the need for wider check with visual psychophysics (the physiology/architecture-behavior connection is critical), but I definitely think that this work should be presented in ICLR.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_KMTQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4692/Reviewer_KMTQ"
        ]
    }
]