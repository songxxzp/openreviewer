[
    {
        "id": "nHaooR2qvz",
        "original": null,
        "number": 1,
        "cdate": 1666553126736,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666553126736,
        "tmdate": 1666553126736,
        "tddate": null,
        "forum": "I9J8gIyqRE",
        "replyto": "I9J8gIyqRE",
        "invitation": "ICLR.cc/2023/Conference/Paper4111/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a new solution for the task of Sketch healing, where corrupted or unfinished sketches are reconstructed without the corruption. This task is commonly accomplished through representation learning. The manuscript describes a method focused on \u2018stable representations\u2019, where complete and corrupted sketches should have similar representations; this is a concept not dissimilar to the principles of representation learning in self-supervision models. To achieve such stability the model is composed of a CNN-based autoencoder with least mean square error reconstruction (Lmser) blocks that reconstruction raster sketches plus an RNN-based decoder that reconstructs vector sketches. The manuscript also has empirical evidence supporting this new model as the State-of-the-Art on sketch healing.\n",
            "strength_and_weaknesses": "The strength is in the core contribution of the paper: the choice of using the Lmser blocks is well motivated by the need for stable representations for complete and corrupted sketches; the idea is new to the sketch literature; the empirical results show the effectiveness of using this new representation combined with the traditional recurrent decoder.\n\nFor weaknesses, I\u2019ve found the comparison agains the SketchLattice baseline to be flawed. The input requirements for that model should have been followed to allow for fair comparison. Furthermore, other competing models such as SketchHealer-2.0 have presented results aligned with the original SketchLattice papers in their comparisons. I am also curious as to how well the model would work when only trained with the CNNs, without the vector decoder. I understand the RNN decoder to be essential for the output to not be blurry, but is it also essential for obtaining a stable representation?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Writing can be improved specifically on the Introduction. More notes will follow at the end of this comment. \n\nI believe this is a paper with a single contribution, which is the application of Lmser to the task of Sketch Healing. It is focused and delivers on the experimental results; that said I find it is not necessary to break this single contribution into three which are each derived from the previous one.\n\nIn the related work section, I find it odd that the authors define reconstruction as \u201cconditional generation\u201d and class-conditional generation as \u201cunconditional generation\u201d. The task of sketch healing is similar to the one of reconstructing images from noisy inputs and unless there is a pattern in the sketch literature for this naming convention it would be better to follow the general computer vision conventions.\n\nThe authors mention the LSTM model is referenced from Sketch-RNN, does that include the GMM model at the output?\n\nIn section 3.1, the manuscript mentions that corrupted sketches are obtained by \u201crandomly rounding off a certain percentage of strokes\u201d, which would make corrupt sketches always be the same as unfinished sketches. It is not clear however when this corruption technique is used since in section 4.1 another common method is described to be applied for the experiments. Was the first method used for training the model and the second used for testing?\n\nThe naming and explanations of the metrics Rec and Ret could be amended to better explain what are the actual metrics used. Is Rec simple top-1 accuracy? Is Ret precision@K? The short names can be used on the tables but please make meaning explicit within the text.\n\nExtra notes:\n- Sec 1. \u201cdue to the difficulty in learning\u201d can be removed from the abstract and introduction\n- Sec 1. \u201cit is not always available\u201d needs a better connective \u201cbut this information\u201d would work\n- Sec 1. \u201cSketchLattice is a lightweight model which limits its performance\u201d is not always a true statement for lightweight models. \n- Sec 1. \u201cDifferent to [\u2026] we expect the network to learn stable sketch representations\u201d. This motivator does not explain why a cnn would be better than a gnn at learning stable representations\n- Sec 1. \u201cand even more\u201d should be \u201cand worse\u201d or similar\n- Sec 1. \u201coin\u201d should be \u201cin\u201d\n- Sec 3.3. \u201craseter\u201d\n",
            "summary_of_the_review": "The paper applies the existing Lmser AEs method to the task of learning stable representations for sketches, with the final goal of performing sketch healing. The authors combine the Lmser AE with the usual recurrent decoder for vector sketch generation. While there are flaws with one of the baseline comparisons and the ablations could be more thorough at figuring out why this model works, the performance gains are significant and I believe this model would be a good addition to the sketch community\u2019 literature. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_po7R"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_po7R"
        ]
    },
    {
        "id": "csa1S5tqsS1",
        "original": null,
        "number": 2,
        "cdate": 1666650949467,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650949467,
        "tmdate": 1666651045370,
        "tddate": null,
        "forum": "I9J8gIyqRE",
        "replyto": "I9J8gIyqRE",
        "invitation": "ICLR.cc/2023/Conference/Paper4111/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes LMSER-PIX2SEQ for sketch healing. The method is an encoder-decoder similar to VAE and performs very good with respect to the other baselines.   ",
            "strength_and_weaknesses": "**Strength**\n\nThe paper is well-written and the method shows great performance in the experiments.\\\n\n\n**Weaknesses**\n- The method's novelty is limited.\n- I'm not familiar with the literature but I think the paper might be a better fit for a computer vision conference (like the other baselines).\n- In section 4.1 there is a discussion about the information leakage in the dataset preparation in sketchhealer.1 and also changing the Ret evaluation from what the other baselines have previously reported on. How much of the performance gap shown in tables 1 and 2 is coming from these factors, especially the updated Ret metric?\n- typo: page 2, the second paragraph above the Related Works, \"oin\" should be \"in\"\n\n- Question: Why do the authors think that their method is beating the other baselines with a big margin in Ret ( table 2) but getting closer numbers in Rec (table 3) ?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and the method shows very good performance. \\\nThe novelty of the method is a bit limited. Regarding reproducibility, I think that the draft is clear enough for reproducing the method but I encourage the authors to release the code, the new Ret metric, and the revised data feeding mentioned in section 4.1.  ",
            "summary_of_the_review": "I think this study is a much better fit for a computer vision conference. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_hWp5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_hWp5"
        ]
    },
    {
        "id": "tskvBul9_gX",
        "original": null,
        "number": 3,
        "cdate": 1666859410391,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666859410391,
        "tmdate": 1666859410391,
        "tddate": null,
        "forum": "I9J8gIyqRE",
        "replyto": "I9J8gIyqRE",
        "invitation": "ICLR.cc/2023/Conference/Paper4111/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper is an attempt to solve the problem of \u2018sketch healing\u2019; trying to recover the original sketch from the corrupted one. The authors propose Lmser-pix2seq, which consist of Lmser block (an encoder-decoder for healing rasterized sketch) and an LSTM decoder (to convert from latent embedding from lmser to full sequence). The evaluation is done on 1) if the recover sketch can be classified as the same class as the complete sketch and 2) if the embedding of the recovered sketch can be used to retrieve the full sketch. The results are better than previous works on both metric, however only slightly in the recognition test.",
            "strength_and_weaknesses": "Strength\n - The self supervised manner of training is pretty clever. \n - The learning of y from the mini task of healing rasterized sketch is also interesting\n - The output is a sequence S of sketch, so should be more useful than rasterized output\n - The qualitative result comparison looks great and shows the strength of the proposed method against others.\n\nWeakness\n - The 2 quantitative metrics used aren\u2019t really satisfying. The R_ret comes from feeding the rasterized version of the generated sketch and the full sketch into the proposed encoder, which was trained for this method to match the two. It doesn\u2019t seem fair to other methods when comparing them. The R_rec is less problematic but the improvement of the proposed method over other methods is very small. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well written.\nWould probably need the full code release from the authors to ensure reproducibility.",
            "summary_of_the_review": "While I like the cleverness of the approach, I\u2019m a bit concern about the actual problem and its usefulness. Sure sketch healing is great for recover the missing details of the sketch, but in the current setting this is only applying to this specific corruption method. I think it would be great to have another section about generalization for example how this can be applied to actual sketch corruption various source, or how much will this help if we use it as data augmentation method for sketch related task. R_rec sort of try to cover this by showing how it can help with the sketch classification task, but the proposed method only gain small amount of improvement. So as it is currently I\u2019m a bit hesitant to recommend acceptance. \n\nOthers:\nAlso, all these discussion about sketch corrupting, sketch healing, etc. seems like it would be a natural extension to apply diffusion model to it. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_rRmX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_rRmX"
        ]
    },
    {
        "id": "ltr7CzgEN2",
        "original": null,
        "number": 4,
        "cdate": 1666944092503,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666944092503,
        "tmdate": 1666944092503,
        "tddate": null,
        "forum": "I9J8gIyqRE",
        "replyto": "I9J8gIyqRE",
        "invitation": "ICLR.cc/2023/Conference/Paper4111/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper addresses the sketch healing problem. In other words, it addresses the problem of removing corruptions from sketches. In this work, the authors have proposed the least mean square error reconstruction (LMSER) block for the same, which essentially falls within the encoder-decoder paradigm. The model takes a corrupted sketch as input, then the LMSER encoder computes the embeddings of structural patterns of the input, while the decoder reconstructs the original sketch from the latent embeddings. The decoder is constructed by a recurrent neural network which recreates the sketches from the features captured by the LMSER block.\n",
            "strength_and_weaknesses": "**Strengths**\n(1) The proposed model has reported state-of-the-art performance on existing datasets for the sketch healing tasks.\n\n**Weaknesses**\n(1) The proposed model combines LMSER and Pix2seq models for the sketch healing task, which is incremental. Furthermore, the difference from sketch-pix2seq and RPCL-pix2seq is not clear. I understand that the latter models have been proposed for sketch generation, but joining them with a sketch encoder is not really difficult.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written. It's clear and easy to follow, but the novelty may be limited.",
            "summary_of_the_review": "The paper combines two existing models for sketch healing task, whose novelty is incremental.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_oNd8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4111/Reviewer_oNd8"
        ]
    }
]