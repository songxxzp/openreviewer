[
    {
        "id": "PRg5oAoqyv",
        "original": null,
        "number": 1,
        "cdate": 1666156074345,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666156074345,
        "tmdate": 1666156074345,
        "tddate": null,
        "forum": "3BOwNcqM_Wq",
        "replyto": "3BOwNcqM_Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper5238/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper finds that relational reasoning is a key component of mathematical reasoning, whether using natural language or abstract symbols as indicated by our experiments on the GSM8K and the unit conversion tasks. Training the models with relational abstraction can outperform models trained using numerical expressions only, and making these abstractions more salient improves performance\nfurther still. It also find that even when all the relational and numerical components are present, how they are ordered makes a significant difference. Among all the variants, performing the relational reasoning step just before the numerical computation step is most advantageous, outperforming cases where the full relational plan must be generated at the outset. ",
            "strength_and_weaknesses": "Strength:\n\n1. This paper proposes to decompose the problem solving process into relational abstraction and arithmetic expression, which is amenable to large language models and is a middle-ground between neurosymbolic, natural language-based, and arithmetic-only approaches.\n\n2. This paper finds relational abstraction improves problem solving performance when supplied either during training or testing, making it a crucial component to study separately.\n\nWeaknesses:\n\n1. The key contribution, i.e., relational abstraction, are not described clear. The author should provide a general methodology that are formal and easy to follow. \n\n2. The experiments are not comprehensive. This paper only uses one dataset for validating the ideas, which is far from enough.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The method section of this paper is not clear. The results are not significant. ",
            "summary_of_the_review": "More efforts required on the methodology and experiment sections.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_XGS4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_XGS4"
        ]
    },
    {
        "id": "c75qDvgzoH7",
        "original": null,
        "number": 2,
        "cdate": 1666381082714,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666381082714,
        "tmdate": 1669048448489,
        "tddate": null,
        "forum": "3BOwNcqM_Wq",
        "replyto": "3BOwNcqM_Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper5238/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper defines 4 different ways to fine-tune language models with intermediate reasoning steps for multi-step mathematical reasoning datasets. After being asked a question requiring multiple symbol manipulations, a model can:\n - Baseline: output the answer directly\n - A : output the chain of numerical expressions before the final answer\n - B : output the chain of logical expressions followed by the chain of numerical expressions before the final answer\n - C : output the chain of logical expressions interleaved with the chain of numerical expressions before the final answer, or \n - D : output either the chain of logical expressions or the chain of numerical expressions before the final answer, based on some prompt at test time.\n\nExperimental results on GSM8k and a synthetic task demonstrate that fine-tuning models with these intermediate steps (in particular methods B, C, D) improves the overall answer accuracy of the model.\n",
            "strength_and_weaknesses": "**strengths** : This work explores different ways of combining mathematical reasoning into large language models, which offers insight into what can improve current models performance.\n\n**weakness (w1)** : However, the paper is not easy to follow as some concepts are not explicitly defined, and the methodology and experimental results are difficult to parse (see the clarity section below) \n\n**weakness (w2)** : Results so far only cover the final answer accuracy. The paper should make an effort to also measure the accuracy of the intermediate reasoning steps being generated during test time. This would tell if the model is actually able to generate interpretable reasoning steps that are useful to answer the final question.\n\n**question** : In the unit conversion task, how does the numbers in Table 4 compare with the baseline model that tries to output the final answer directly? Table 4 should have an extra line for the baseline model.\n\n**suggestion** : It would be nice to show that the conclusion found in this work holds true for other mathematical datasets and not just for GSM8k. Other datasets could include: AQuA-Rat (Ling et al., 2017), MATH Dataset (Hendrycks et al., 2021), MathQ (Drori et al., 2021).\nSimilarly, previous work (Gontier et al., 2020) has also explored what type of intermediate steps are better to train language models to perform multi-step reasoning. Discussing how this work differs could benefit the paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Find below some clarification that are required to make this a better paper:\n\n**clarity (c1)** : \u201crelational abstraction\u201d is mentioned 9 times in the introduction, yet it is not clear what is meant by it. An illustrative example at the beginning of the paper would probably clarify what the authors mean by \u201crelational abstraction\u201d. Another possibility is to rephrase the sentences and try to explain what is meant by saying something like \u201c*giving logical formulas as intermediate step before the final answer*\u201d\n\n**clarity (c2)** : The paper introduces 4 ways of creating intermediate steps before an answer in Figure 1: A, B, C, D. The paper would be a lot more clear if the same references were used throughout the paper. For instance, in Table 2 and Table 4 it is not clear which row refers to which of these A, B, C, D techniques. Adding these labels in each row could potentially make the results easier to read.\n",
            "summary_of_the_review": "Overall, this is an interesting paper that shows what type of logical formulation can be used to improve language models to solve multi-step mathematical problems.\nHowever the paper could benefit from some clarifications (see **w1** referring to **c1** **c2** in the sections above) and some extra analysis (see **w2** in the sections above).\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_wEws"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_wEws"
        ]
    },
    {
        "id": "zLW3dDPbC4",
        "original": null,
        "number": 3,
        "cdate": 1666741619672,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666741619672,
        "tmdate": 1666741619672,
        "tddate": null,
        "forum": "3BOwNcqM_Wq",
        "replyto": "3BOwNcqM_Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper5238/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of how to improve language models\u2019 ability to perform reasoning. In particular, the authors focus on the task of mathematical reasoning: on both GSM8K and a synthetic task called unit conversion, the authors showed that by training models to generate abstract representations (referred to as relational and numerical in paper) of the reasoning steps, the models perform better at solving reasoning problems. The authors also conduct ablation studies on how the order of relational/numerical sequences affects model performance. The abstract representations for GSM8K are annotated by humans and that for the unit conversion task are automatically generated.",
            "strength_and_weaknesses": "One major concern about the proposed approach is that annotating the training examples with relational/numeric representations requires significant human efforts. Though the authors\u2019 claim: \u201cthe challenge that model face lies primarily in constructing the relational plan\u201d is indirectly supported by their experiments, they do not provide a very practical solution for tackling this problem. Regarding ablation studies, the authors do not provide enough insight on why certain ways of presenting the annotated relational and numeric sequences help the language models to perform better. \n\nThe authors used GPT2-M and GPT2-XL for solving GSM8K; however, for the synthetic setting, the authors instead use a 4-layer transformer encoder with no pre-training and the motivation for this model choice is unclear.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall clearly written and provides some details for reproducing the results.",
            "summary_of_the_review": "The authors show by experiments that incorporating abstract relational representations can help language models to perform reasoning, but they do present an effective approach to accomplish that. Apart from the major claim of the paper, the analysis/ablation studies do not provide any other insight into this problem.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_YJ77"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_YJ77"
        ]
    },
    {
        "id": "bZK-Rw1Th2",
        "original": null,
        "number": 4,
        "cdate": 1666898348813,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666898348813,
        "tmdate": 1666898813667,
        "tddate": null,
        "forum": "3BOwNcqM_Wq",
        "replyto": "3BOwNcqM_Wq",
        "invitation": "ICLR.cc/2023/Conference/Paper5238/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "1) This paper proposes to incorporate relational abstractions into mathematical reasoning.  Hand-crafted a number of ways to combine relational abstractions and equations.\n2) This paper presents empirical evaluations on GSM-8K and a unit conversion dataset.",
            "strength_and_weaknesses": "Strengths:\n1. A very simple idea but brings a large performance improvement\n2. Writing and presentation is very clear\n\nWeaknesses:\n1. The authors only tried very large models, I would like to see how this method scales w.r.t. model sizes.  Does it only work on larger models?\n2. The results on the unit conversion dataset can benefit from more analyses.  For example, after adding the relational abstractions, there are not any natural language involved, and it is just a completely symbolic task.  Therefore, can the units be replaced with any number?  Or the units actually have meaning in the GPT models?  Would be interesting to figure out.\n3. more datasets are needed.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Novelty And Reproducibility are good!\nQuality of the work needs to be improved.",
            "summary_of_the_review": "Very well written paper, simple idea, strong experimental results",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_cUHL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5238/Reviewer_cUHL"
        ]
    }
]