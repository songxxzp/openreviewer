[
    {
        "id": "WBCCS7RX1f",
        "original": null,
        "number": 1,
        "cdate": 1666621576172,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621576172,
        "tmdate": 1666621576172,
        "tddate": null,
        "forum": "1EVPT82ttr",
        "replyto": "1EVPT82ttr",
        "invitation": "ICLR.cc/2023/Conference/Paper3517/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the author designed a new model,named Branch-to-Trunk network (BTNet), to match faces with different resolutions, and the experimental result demonstrates that the method is feasible. A possible potential contribution of this paper is the design of the network structure, mainly the introduction of multiple branches.",
            "strength_and_weaknesses": "Strength: The design of the model structure, but the pyramid structure is already very common in other work and cannot be considered as a very innovative point.\n\nWeakness: \nThere are several points in the article that confused me, as follows:\n1. In Table 4, the number of parameters of Pretraining + BCT is 43.59, while the number of parameters of Pretraining + BCT + Fix Trunk is 2.29. It seems unreasonable.\n2. As can be seen from Table 4, it is the model distillation operation that provides the largest performance improvement across multi-resolution and same resolution task. What puzzles me is: 1) whether distillation is capable of such a significant improvement and 2) if the distillation operation can improve to such an extent, then the innovation points claimed in this paper may not be reliable and more gains come from the distillation operation.\n3. The task of this paper is to obtain a better cross-resolution representation, and I think it may be more intuitive to visualize it using t-SNE.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is well presented, logical and clear, with standard citations.\n\nQuality: This article is of average quality and is not recommended for acceptance.\n\nNovelty: I feel that this article is not innovative enough.\n\nReproducibility: This article may be reproduced.\n",
            "summary_of_the_review": "  The quality of this article is average and not recommended for acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NO",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_FLmy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_FLmy"
        ]
    },
    {
        "id": "Vy-LmduoS1G",
        "original": null,
        "number": 2,
        "cdate": 1666636472815,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636472815,
        "tmdate": 1666636472815,
        "tddate": null,
        "forum": "1EVPT82ttr",
        "replyto": "1EVPT82ttr",
        "invitation": "ICLR.cc/2023/Conference/Paper3517/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a multi-resolution face recognition algorithm. It is based on a CNN encoder backbone (e.g. ResNet50), denoted trunk Net, and multiple lateral resolution-specific nets, denoted BTNets. Each BTNet receives as input an image with a specific resolution producing a representation of the same resolution. This representation is combined with the backbone at the layer with a resolution matching that of the BTNet. The experimentation shows how different components of the model contribute to the final solution. It compares favorably with the state of the art on a low resolution data set.",
            "strength_and_weaknesses": "Strengths.\n\nThe paper addresses a relevant problem in the literature, namely, multi-resolution face recognition.\n\nWeaknesses. \n\nThe experimentation needs to be improved. It only compares with the state-of-the-art in a low-resolution data set. If it it claims to learn a multi-resolution representation, it should be compared with other competing algorithms and on many more data sets with different resolutions/characteristics.\n\nThe writing should also be improved. The paper is difficult to understand. Important information is missing, e.g. how is the representation produced by BTNet combined with the backbone. In section 4.1 it reads that the  experimentation has been performed with 6 data sets that go missing in the paper. Some tables at the end of the paper were not cited in the text.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not easy to read. It could not be reproduced with the information provided. However, some coded has been provided as supplementary material.",
            "summary_of_the_review": "The paper addresses a relevant problem in face recognition. However, the presentation of the approach is difficult to follow and is not complete. The experimentation is weak. It compares with the state of the art in only one data set, failing to evaluate its multi-resolution performance against its competitors.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_JeWQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_JeWQ"
        ]
    },
    {
        "id": "mheZL_WeER",
        "original": null,
        "number": 3,
        "cdate": 1666684351058,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684351058,
        "tmdate": 1666684351058,
        "tddate": null,
        "forum": "1EVPT82ttr",
        "replyto": "1EVPT82ttr",
        "invitation": "ICLR.cc/2023/Conference/Paper3517/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a Branch-to-Trunk network for multi-resolution face recognition. In this paper, by setting multiple branches and inputting images with different resolutions into different branches, the interpolation error caused by up-sampling is reduced. It requires less computation amount and parameter storage. The paper conducts experiments on six face verification benchmarks and QMUL-SurvFace dataset.",
            "strength_and_weaknesses": "Strength:\nMost low-resolution face recognition works require up-sampling low-resolution images to a fixed size (112*112). This paper proposes a multi-branch network to reduce the interpolation error by piecewise processing the input image according to the resolution, which is a good idea. Meanwhile, this method only stores the learned branches and resolution-aware BNs, which requires less computation amount and parameter storage.\n\nWeaknesses:\n1. For the training set MS1Mv3, we need to first down-sample the high-resolution image to the low-resolution. Although this paper avoids up-sampling by branching strategy, down-sampling will still introduce interpolation errors and there is no solution for this question. \n\n2. For the test on real low-resolution face images, the model does not know the specific resolution to select the branch. If the face resolution needs to be judged according to the image size, many images of QMUL-SurvFace are not full face (after face alignment), and the image collected in real scene may have background and need face detection. But low-resolution face detection is difficult to achieve. At this time, there is no judgment strategy for face resolution, which make it difficult to select branches.\n\n3. This paper inputs images with different resolutions by adding branch headers in front of the backbone network, which is not novel enough. \n\n4. The paper lacks experiments compared to the SOTA methods, such as 1:N face identification on SCFace dataset, 1:1 face verification on QMUL-SurvFace dataset and 1:N face identification on QMUL-TinyFace dataset.\n\n5. In Table 2, the paper does not provide results for each of the six datasets. Tables 4 and 5 do not indicate which dataset the experiment was performed on. In figure 8, further allocation (floor/near/ceil) lacks a specific explanation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and novelty of this paper is not good enough. The reproducibility of this paper is good.",
            "summary_of_the_review": "See Strength And Weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_Lmwt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_Lmwt"
        ]
    },
    {
        "id": "rKr0EoFGpR",
        "original": null,
        "number": 4,
        "cdate": 1666686953153,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686953153,
        "tmdate": 1666686953153,
        "tddate": null,
        "forum": "1EVPT82ttr",
        "replyto": "1EVPT82ttr",
        "invitation": "ICLR.cc/2023/Conference/Paper3517/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a Branch-to-Trunk network (BTNet) for multi-resolution face recognition, which consists of a trunk network (TNet) and multiple branch networks (BNets). With branch distillation and backward compatible training, BTNet transfers discriminative high-resolution information to multiple branches. Experiments on face recognition benchmarks show the better performance of the proposed BTNet for multi-resolution face verification and face identification.",
            "strength_and_weaknesses": "Strength:\n+ The paper is well written and easy to read.\n+ The proposed BTNet obtains the state-of-the-art performance on the challenging QMUL-SurvFace 1: N face identification task.\n\nWeaknesses:\n- Waht are contributions of the proposed BTNet compared to existing dynamic resolution network (Zhu et al., NeurIPS 2021)? And the paper should compare with dynamic resolution network.\n- The paper evaluate the proposed BTNet on the challenging QMUL-SurvFace dataset, and it is recommend to conduct comparisons on more fae recognition benchmarks, e.g., WebFace260M [1].\n[1] Zhu et al., WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition, CVPR 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality and clarity is good, and the originality of the work is fair.",
            "summary_of_the_review": "The main concerns of the work are its weaknesses as\n- Waht are contributions of the proposed BTNet compared to existing dynamic resolution network (Zhu et al., NeurIPS 2021)? And the paper should compare with dynamic resolution network.\n- The paper evaluate the proposed BTNet on the challenging QMUL-SurvFace dataset, and it is recommend to conduct comparisons on more fae recognition benchmarks, e.g., WebFace260M [1].",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_yRHk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3517/Reviewer_yRHk"
        ]
    }
]