[
    {
        "id": "CmQX_-GMtg9",
        "original": null,
        "number": 1,
        "cdate": 1666351787310,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666351787310,
        "tmdate": 1670384691632,
        "tddate": null,
        "forum": "azCKuYyS74",
        "replyto": "azCKuYyS74",
        "invitation": "ICLR.cc/2023/Conference/Paper3821/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper mainly investigates the principle differences between contrastive learning (CL) and masked image modeling (MIM). That\u2019s the CL is shape-biased, which learns low-frequencies, and the MIM is texture-biased, which exploits high-frequencies. The Conclusion is interesting and the analysis is thorough.",
            "strength_and_weaknesses": "Strength:  \nWell-written, clear analysis and easy to understand.  \nThe conclusions drawn in the paper may be instructive to the self-supervised learning community.  \n\nWeaknesses:  \n(1) The main concern lies in the quantitative experiments. In fact, the paper lacks experiments on downstream tasks, like image classification, object detection or segmentation. The authors should provide corresponding downstream experiments to support the effectiveness of the conclusion other than visualization of principle analysis.  \n(2) The principle analysis occupies a large amount of space in the paper, on the contrary, the method derived from the conclusions is rarely involved. Actually, the corresponding method (Section 5) is also the core of the paper.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Well-written, interesting conclusions, but lack experiments.",
            "summary_of_the_review": "I am inclined to reject the current version of the paper since the experiment and the corresponding method are not well explored.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_Gfy8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_Gfy8"
        ]
    },
    {
        "id": "foDa4iCGnmY",
        "original": null,
        "number": 2,
        "cdate": 1666552120625,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552120625,
        "tmdate": 1666552120625,
        "tddate": null,
        "forum": "azCKuYyS74",
        "replyto": "azCKuYyS74",
        "invitation": "ICLR.cc/2023/Conference/Paper3821/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents comparative studies on various facets of two widely used self-supervised learning methods - contrastive learning and masked image modeling. The studies show opposing properties of the two methods: image information (image-level vs. token-level), features representations (low- and high-frequency) and different lead role components (later- and early-layers). The study also demonstrated that their misture outperforms individuals of them.",
            "strength_and_weaknesses": "Strengths of the this paper - \n\nThe entire paper, in its current form, is easy to follow. The examination of certain components in each method is clearly understandable. The evidence presented in the paper seems reasonable.\n\nWeaknesses of the paper - \n\nThe major weakness is the lack of novelty and comprehensiveness. The comparisons show the examination of two methods, given a large number number  of similar approaches reported in the community. \nAnother weakness of the paper is that the mixture of the two methods is to simply use the weighted combination of the two methods. In spite of its simplicity, this combination form lacks clear motivation and clear discussion on the merging form, e.g. why this form is the best way, and how to merge them in the level of components?\n\nActions to be taken:\n\nMore similar techniques must be taken into account. The comparison aspects should be considered, e.g. components and layers of the systems. The integration of the systems should be properly reasoned.",
            "clarity,_quality,_novelty_and_reproducibility": "Originality of this paper: Weak and missing. This paper is only about the evaluation of two standard methods.\n\nQuality of the research: Limited contributions towards the topic. The evidence to justify the argument may be further improved - more metrics and comprehensive evaluation to be undertaken. \n\nClarity of the paper: In general, the entire paper is easy to follow. The major concern is that the combination of the two methods is not well explained.",
            "summary_of_the_review": "This paper presents the comparisons of two standard methods with several evaluation metrics. The strength of the paper is the easiness to understand the presented work. The major weaknesses of the paper include the missing depth and width of the comparisons. This paper and its presentation in the current form will not be recommended for acceptance. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Datasets used in this study come from the publicly accessible databases so no concern on ethics. ",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_n5hD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_n5hD"
        ]
    },
    {
        "id": "1o1_jHI5w_",
        "original": null,
        "number": 3,
        "cdate": 1666648892939,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666648892939,
        "tmdate": 1666648892939,
        "tddate": null,
        "forum": "azCKuYyS74",
        "replyto": "azCKuYyS74",
        "invitation": "ICLR.cc/2023/Conference/Paper3821/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper compares two self-supervised classes of methods for vision transformers, namely contrastive learning and masked reconstruction.\nThrough several quantitative analyses of pre-trained models, the authors expose a series of findings on the learning properties of these methods.\nThe main findings for contrastive learning are: it captures global low-frequency patterns, its intermediate representations are rather homogeneous, and self-attention is its key component.\nConversely, for masked reconstruction, the main findings are: it focuses on local high-frequency patterns, its intermediate representations maintain diversity, and the MLPs are its key component.\n",
            "strength_and_weaknesses": "Strengths:\n\n- The paper tackles interesting questions in self-supervised learning and provides answers that are thoroughly supported by empirical evidence. With a possible risk of confirmation bias, the findings in this paper validate the anecdotal evidence that has been observed in the community for a while.\n\n- From the reader's perspective, the paper is well-written and well-organized. The authors have done a great job of outlining the research questions and their findings in the introduction.\n\n- The research presented in this work is quite extensive. I appreciate that the authors did not stop at the first finding and instead insisted on probing the models with different tools to highlight their differences from various perspectives.\n\nWeaknesses (or rather suggestions for improvement):\n\n- Complement the discussion by mentioning the findings of \"High fidelity visualization of what your self-supervised representation knows about\" (Bordes 2022). This work, concurrent with the authors' work, offers qualitative evidence that broadly agrees with the findings of this paper.\n\n- L59-61 \"early layers are usually known to capture low-level features, e.g., local patterns, high-frequency signals, and texture information, and later layers capture global patterns, low-frequency signals, and shape information\". In the context of convolutional networks, due to their limited receptive field and pyramidal architecture, this statement is considered common knowledge and is supported by a large body of studies. However, this paper focuses on transformers, where this behavior is still under investigation. I suggest providing references to support this statement and possibly clarifying its scope.\n\n- Most of the discussion points compare MoCo vs. SimMIM. However, there are parts that would be more convincing if more methods were added to the discussion. An example of this, L257-267 discuss the difference between SimMIM and MAE in terms of decoder depth, why not include MAE in figure 11?\n\nMinor points:\n\n- Improve figure 1 by adding a grid, separating the plots more, and tweaking the font size. Actually, most figures would benefit from a grid.\n\n- L67: \"As shown in Figure 1\". Figure 1 deserves a bit of introduction, e.g. what models and methods are being compared and on what, before discussing its meaning. I see that the caption contains all the required information, but it is weird to read the first line of section 2 without knowing what the figure is about.\n\n- Improve figure 10 by connecting all MLP markers with a line, and connecting all self-attention markers with another line, rather than relying on white/gray background to distinguish them. Alternatively, if you want to use a single line for each method, change at least the markers of MLP and self-attn layers.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: high. The core idea is relevant and the execution is well done through a series of well-discussed experiments.\n\nClarity: high. The paper is well-written and well-organized. The various sections are connected in a logical way.\n\nOriginality: low. No new idea is introduced, apart from combining contrastive learning and masked image modeling which can be found in other concurrent works. No new \"tool\" for probing the learned representations is introduced either. However, new tools and ideas are not always required and the paper shines for the quality of the execution and the discussion.\n\nReproducibility: high. Although the code is not yet available, it should be possible to fully reproduce the experiments in the paper based on the referenced methods.",
            "summary_of_the_review": "This paper offers a quantitative study of various properties of contrastive learning and masked reconstruction in self-supervised vision transformers. Such a study is valuable as it validates what has been observed empirically in the community and provides a tentative analysis of the reasons behind these observations. The paper itself is well-written and clearly outlined. For these reasons, I recommend the paper for publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_wzZN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_wzZN"
        ]
    },
    {
        "id": "u08nKphA9",
        "original": null,
        "number": 4,
        "cdate": 1666783966059,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666783966059,
        "tmdate": 1670487832123,
        "tddate": null,
        "forum": "azCKuYyS74",
        "replyto": "azCKuYyS74",
        "invitation": "ICLR.cc/2023/Conference/Paper3821/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents comprehensive analyses of self-supervised vision transformers, which provide some new insights about the differences between CL and MIM. For instance, ViTs pre-trained with CL focus on global patterns compared with MIM, collapse into homogeneity while MIM shows more diversity, and reduces the high-frequency signals of the representations but MIM amplifies them. These analyses are helpful for understanding the self-supervised ViTs and show instructions for designing new SSL methods.",
            "strength_and_weaknesses": "**Strengths**:\n\nThe paper is well-written and easy to follow. The analyses are comprehensive and thorough.\n\n**Weaknesses**:\n1. Some expression and figures need to be revised (see below).\n2. The proposed method that jointly pre-training with CL and MIM is somewhat not practical due to large training cost, though it is not the key contributions of this paper.\n\n**Questions**:\n1. In Figure1, the authors claim that *CL outperforms MIM in small model regimes*, which is inconsistent with the analyses in [a] with MAE. Some explanation should be presented.\n2. Since most of the analyses are based on ViT-B, are the observations generalized to larger ViTs (*e.g.*, ViT-L or ViT-H)?\n3. In Figure 3, the behaviors of MoCo are rather odd, which are also inconsistent with the observations in [b]. Are the differences from the different settings or the variance of the pre-trained models? My main concern is the reproducibility about the results. Maybe the code and weights to reproduce the results are helpful.\n4. The claim in L86 that *the representations of CL contain shape information, so it can help ...* is not well-supported by the analyses on the attention distance in this paragraph.\n5. I'm not sure whether L118-127 should present in Sec.2 rather than Sec.3, which focuses on the analyses of layer representations. \n6. In Figure 10, it is not clear to me the meanings of \"1e-1\" and \"1e-4\" on top of the figure. And it seems that the changes for CL are larger than MIM, which appears to contradict the observations in Figure5(b) with CKA similarities.\n7. The linear evaluation in L247-267 only reveals the linear separability of the representations, which could not support the claim that \"Later layers of CL and early layers of MIM are important\" well. Is the claim generalized well under the fine-tuning setting?\n\n[a] Wang, S., Gao, J., Li, Z., Sun, J., & Hu, W. (2022). A Closer Look at Self-supervised Lightweight Vision Transformers. ArXiv, abs/2205.14443.\n\n[b] Xie, Z., Geng, Z., Hu, J., Zhang, Z., Hu, H., & Cao, Y. (2022). Revealing the Dark Secrets of Masked Image Modeling. ArXiv, abs/2205.13543.",
            "clarity,_quality,_novelty_and_reproducibility": "**Quality & Clarity**: the paper is in general well written. The figures are neat with detailed captions.\n\n**Novelty**: the analyses and findings are largely original and interesting, though the analysis tools used in the paper are borrowed from other works.\n\n**Reproducibility**: Though the code for pre-training and fine-tuning the models are provided in supplementary material, the code to reproduce the figures (or analysis results) is absent, which is the key of this work.",
            "summary_of_the_review": "The paper focuses on the self-supervised pre-trained ViTs, and presents several interesting findings, which may help to understand the different behaviors of pre-training with CL and MIM. It may guide future SSL method design and advance research in this field.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_54TF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3821/Reviewer_54TF"
        ]
    }
]