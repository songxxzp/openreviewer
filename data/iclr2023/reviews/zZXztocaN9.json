[
    {
        "id": "FwfYbEQjvK",
        "original": null,
        "number": 1,
        "cdate": 1666710856334,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666710856334,
        "tmdate": 1666710856334,
        "tddate": null,
        "forum": "zZXztocaN9",
        "replyto": "zZXztocaN9",
        "invitation": "ICLR.cc/2023/Conference/Paper4003/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a framework that combines expert knowledge and AI for improved experimental design. The principle is to let humans drive the discovery/optimization process while the AI provides additional data to overcome the strong exploitation bias of humans. The AI model consists of a GP that is fit using data from human + AI-recommended designs and employs a GP-UCB acquisition function. For simulation and theoretical developments, the human model consists of a misspecified model and employs an acquisition (EC-GP-UCB) function with parameters chosen to simulate human biases. The paper reports results on both synthetic and real-world experiments.\n",
            "strength_and_weaknesses": "Strengths\n- The paper proposes a principled way to incorporate expert knowledge while providing theoretical guarantees in the form of improved sublinear regret bounds wrt AI-alone BO.\n- The paper reports experiments with humans on relevant experimental design tasks.\n- I like the simplicity of the idea, which basically equips humans with AI (GP) that leverages their designs and helps them to explore outside their strong beliefs.\n\nWeaknesses\n- Some modeling choices seem arbitrary and mainly motivated by following existing works.\n- It needs to be clarified if the experiments are fair, e.g., if the baselines use the same number of data samples.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I have a few comments/questions regarding clarity, quality and novelty:\n\n- For the experiment in Figure 2, do the Generic-BO, and Simulated Human approaches use the same number of samples as Human+BOMuse? If not, wouldn't it be an unfair comparison? For instance, if we do 50 iterations of BO-Muse this leads to 100 function evaluations. Does the AI-alone baseline use 100 function evaluations too?\n- In the experiments with SVMs and RFs, on average, how often was the best design obtained from AI suggestion? \n- Does the paper implicitly assume that the cost of getting a design from humans is negligible compared to evaluating the objective function? It seems that this is not discussed in the paper. \n- Unlike the synthetic experiments, the real-world ones do not report performance for the AI-alone model. Thus, it is hard to assess if humans are helpful.\n- I understand that the paper focuses on AI-assisted experimental design (humans drive the process). However, it would be interesting to compare BO-Muse to $\\pi$BO (https://arxiv.org/abs/2204.11051) which allows experts to specify informative priors over the design space and then run regular BO (AI model). This would allow us to verify if BO-Muse is the best way to leverage expert knowledge for these experimental design tasks.\n- Some of the choices are justified by being adopted in previous works. For instance, \"Motivated by Borji and Itti, we assume the human expert in effect generates their recommendations using EC-GP-UCB...\". How would BO-Muse perform using another human acquisition function on the synthetic experiments?\n\nReproducibility: the authors have submitted their code for the experiments on synthetic datasets. \n",
            "summary_of_the_review": "Overall, the paper reads well and proposes a relatively novel framework. Although the technical novelty is limited, the paper analyzes the proposal, providing theoretical regret bounds. I have some issues, mainly regarding the fairness of experiments. Thus, I am inclined toward accepting the paper.\n\n-------\nGiven the limited time, I acknowledge that I have not checked the proof in the Appendix.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_LH2r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_LH2r"
        ]
    },
    {
        "id": "erH2qh1Pia",
        "original": null,
        "number": 2,
        "cdate": 1666744489630,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666744489630,
        "tmdate": 1666744489630,
        "tddate": null,
        "forum": "zZXztocaN9",
        "replyto": "zZXztocaN9",
        "invitation": "ICLR.cc/2023/Conference/Paper4003/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed a bayesian optimization framework for human-AI teamwork in collaborative tasks such as experiment design and optimizing blackbox functions. The authors assume that humans are likely to over-exploit, and thus propose the AI's role as a source of exploration, and they validate their method on synthetic and real-world optimization experiments. ",
            "strength_and_weaknesses": "Strengths: I overall really like the idea of bridging bayesian optimization / experiment design with human-AI collaboration, and think this is a promising direction. \n\n\n\nW1: The notation throughout the analysis could be significantly improved in terms of clarity and description. Even as minor as stating \"dataset\" before introducing \\mathcal{D}, \"kernel function\" before K (before Eq 1) would be good to have, as I think the strength of this paper could be its appeal to those who work in human-AI co-creative applications, and thus a more clear  and concise description of Bayesian optimization and GPs for such readers would significantly improve the paper quality (and since the paper's novelty is not on the BO side, and more an application-oriented, I'd argue such clarity is necessary). Sometimes variables are mentioned throughout the paper, and could benefit from reminders on what they are (e.g. max info gain \\gamma). It would also help to use more distinctive markings for AI / human suggestions (maybe super scripts AI and H?). \nFinally, the regret bounds in 3.3. feel quite isolated from the rest of the paper, and it's not clear what the central takeaway of that section is apart from just providing regret bounds -- without high level implications for parameter selection, it's not clear this is a more valuable part of the paper than, for example, experiment details that were pushed to the Appendix. \n\nW2: Assumptions of human model - The novelty of this paper rests in the application of BO to human-AI co-creativity / experiment design, so I wish there was more thoughtful handling of the assumptions being made about the human in BO-Muse. For example, does the assumption that humans are conservation reasonable for all tasks and settings? Why can we assume the number of features (m_s) in the human model is non-decreasing (a human may discover a major highly predictive feature only later on)? Why can the convergence of the human's max info gain be stronger than the AI's? Why are linear/polynomial models sufficient for the human? It would have been really interesting to even see real-world experiments that try to validate some of these assumptions.\n\nW3: Thoroughness of experiments - It would be helpful if the experiments in the main part of the paper had more thorough details provided. Were ablations over \\Beta done for Ackley and Levy functions, so we could get a sense of sensitivity to parameter vs. method? In the Appendix for the Matyas function, why does Simulated Human to better than the proposed BO-Muse method? How does sensitivity to \\beta change between tasks? \n\nWith the real-world human experiments, how do we know that the benefit of BO-Muse is not just due to humans receiving additional information, regardless of how well-optimized that information was for the task (e.g. a random acquisition heuristic)? \n\nMinor:\n- the template and font appears different from other ICLR papers \n- could the authors provide more discussion on the limitations of assuming f^star is drawn from the AI's GP?\n- there were quite a few grammatical issues , the authors should do another pass to edit for clarity ",
            "clarity,_quality,_novelty_and_reproducibility": "As discussed earlier, my primary concern is with the paper's clarity -- I don't believe it sufficiently discusses theoretical assumptions or experimental details thoroughly. This clarity does hurt reproducibility a bit - which parameters of BO-Muse were chosen for the different experiments should be clearly stated. \n\n",
            "summary_of_the_review": "I am really excited by the problem this paper addresses. Unfortunately, I don't believe it's ready for acceptance in its current state (largely due to clarity and presentation issues), but would be very excited to see this work in a more polished form. While the overarching idea -- providing a formalism for incorporating human domain expertise in optimal experiment design -- is very interesting and timely given the exciting progress we have seen in recent years of neural networks aiding humans in creative tasks / search problems,  I believe the paper focuses too much on the synthetic settings and a rather dense analysis of the Bo-Muse algorithm, leaving room for only minimal real-world experimental details (e.g. the space shield design set-up is almost entirely in the Appendix, whereas I feel like such experiments should be thoroughly analyzed and discussed, even if that means being presented on their own in a separate venue). ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_XANP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_XANP"
        ]
    },
    {
        "id": "XL1b8aAVLUf",
        "original": null,
        "number": 3,
        "cdate": 1666978929867,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666978929867,
        "tmdate": 1666978929867,
        "tddate": null,
        "forum": "zZXztocaN9",
        "replyto": "zZXztocaN9",
        "invitation": "ICLR.cc/2023/Conference/Paper4003/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work solves a problem of sample-efficient experimental design with teaming of a human expert and AI.  Since an AI starts to solve the experimental design from scratch, a human expert can help the AI to accelerate the design process.  To fully utilize such knowledge from human experts and AI system, the authors propose a batch Bayesian optimization technique.  Finally, they provide the experimental results that show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "### Strengths\n\n* It solves an interesting topic that considers a realistic scenario with human experts.\n\n* The introduction section is very well-written and plausible. In particular, the motivation is strong.\n\n### Weaknesses\n\n* The proposed method is not novel.  I think that it is a simple combination of existing methods.\n\n* Regret analysis is limited, since the regret bound heavily relies on the bound by the AI system.  Since it utilizes the knowledge of human experts that controls how humans know the exact location of solutions, the bound is meaningless.\n\n* Baseline methods are not enough.  I think it should be compared to diverse existing baselines.",
            "clarity,_quality,_novelty_and_reproducibility": "### Questions\n\n* Since the problem formulation of this work is similar with the formulation of batch Bayesian optimization, the proposed method should be compared to batch Bayesian optimization strategies.  How do you think about this issue?\n\n* Did you assume a time gap between AI and human recommendations?  I think if there exists the time gap, it encourages us to formulate a more interesting problem.  For example, it can be viewed as an asynchronous Bayesian optimization problem.\n\n* I think the regret bound should be controlled by the amount of human knowledge.  It seems like such a controlling factor does not exist.\n\n### Other issues\n\n* I think that the authors modify a conference template style.  It might violate the policy of conference submissions.",
            "summary_of_the_review": "Please see the text boxes above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_xwm5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4003/Reviewer_xwm5"
        ]
    }
]