[
    {
        "id": "s0ysX37ukuz",
        "original": null,
        "number": 1,
        "cdate": 1666176623160,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666176623160,
        "tmdate": 1666176623160,
        "tddate": null,
        "forum": "LfdEuhjR5GV",
        "replyto": "LfdEuhjR5GV",
        "invitation": "ICLR.cc/2023/Conference/Paper2847/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses the problem of robustness for self-supervised MDE (monocular depth estimation). The focus is on physical world attacks that place an image on a board in front of the camera in order to create an incorrect depth estimation.\n\nThe proposed approach follows the adversarial training setting, by including these \"board images\" during the training phase. Self-supervised MDEs work with stereo cameras where, e.g., the right camera provides the labeling for the left camera. Therefore, a \"board image\" perturbation on the left image creates a specific perturbation on the right image. The proposed method models this effect from data (left image) to label (right image) via the known relative 3D locations of the cameras.\n\nTo create photo-realistic \"board images\", the approach starts with a realistic 2D image and perturbs it with respect to small 2D changes.\nWhile the goal is to provide small L0 perturbations, this is done in an approximated manner (using tanh as an approximating function for L0)\n\nThe experiments start with state-of-the-art MDE models and evaluate the proposed methods on recent MDE attacks.",
            "strength_and_weaknesses": "Strengths:\n+ The proposed method is explained in detail and every derivation is easy to follow\n+ The challenges of creating adversarial examples for the presented regression problem is well motivated and convincingly executed\n+ The paper use SOTA models as well as SOTA datasets for the training and SOTA attacks for the evaluation\n\nWeaknesses:\n- MDE can also be attacked by having an arbitrary painting on a board. This is neither addressed by the approach nor evaluated in the experiments\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presented method appears to be new and is well written.\n\nIn particular, I like the effort that is put into Section 1 to first explain how a 3D attack can be executed and then, to hint that this effort can be reduced by simulating this during training. Therefore, it becomes very clear what kind of attack the paper is focused on, before the derivation of the 3D geometry-based simulation is described.\n\nI can imagine that this paper is a very nice read for everyone who wants to get familiarized with the topic without having too much prior knowledge.",
            "summary_of_the_review": "Overall, I like the ideas, the evaluation and the presentation of the paper very much.\nDue to the mentioned weakness, I cannot give the paper the highest rate, but I would like to see this paper presented at ICLR'23.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_fV94"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_fV94"
        ]
    },
    {
        "id": "aeu0lb-DS-0",
        "original": null,
        "number": 2,
        "cdate": 1666545079744,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666545079744,
        "tmdate": 1669209272574,
        "tddate": null,
        "forum": "LfdEuhjR5GV",
        "replyto": "LfdEuhjR5GV",
        "invitation": "ICLR.cc/2023/Conference/Paper2847/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new adversarial training method for self-supervised MDE models without depth ground truth. The training utilizes the the reconstruction consistency from one view to the other view. And to improve the adversarial robustness against physical-world attacks, $L_0$-norm-bounded perturbations are utilized in training. Results on two MDE networks demonstrate the robustness achieved by the proposed methods.",
            "strength_and_weaknesses": "Strength:\n\nThis paper propose a self-supervised adversarial training strategy for MDE with view synthesis, and the results is obviously better than the supervised learning baseline and a contrastive learning baseline.\n\nWeakness:\n\n1. The proposed approach is limited on the MDE task with self-supervised setting, while practical depth estimation network are trained with supervised learning. Can the proposed approach be utilized for the situation where the ground truth is provided?\n\n2. The experiments are only conducted on the KITTI which is an outdoor dataset, and I wonder if the robustness can be hold for the indoor scenes, e.g., conduct the experiments on the NYUD dataset.\n\n3. Monodepth2 and DepthHints are not SOTA MDE frameworks. Although the authors have proved the superiority of the proposed self-supervised adversarial training with these two networks compared with supervised loss, more experiments should be conducted with SOTA MDE networks, like [A, B]\n\n[A]The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth, CVPR2021\n[B]Exploiting Pseudo Labels in a Self-Supervised Learning Framework for Improved Monocular Depth Estimation, CVPR2022\n\n4. The meaning of each method setting should be well shown in Tables 1 and 2.\n\n5. This is one important baseline to compare: minimize the outputs of trained MDE networks with the inputs of clean and adversarial samples.",
            "clarity,_quality,_novelty_and_reproducibility": "I think this paper proposes a new strategy for the adversarial training of MDE networks. But the experiments are not sufficient to support the effectiveness of the proposed strategy. \nAnd this paper has not provided enough materials to guarantee the reproducibility.",
            "summary_of_the_review": "This paper needs more experiments to demonstrate their importances and effectiveness. And the paper should be organized with more details.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO.",
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_9eWp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_9eWp"
        ]
    },
    {
        "id": "VqrcGkT5auy",
        "original": null,
        "number": 3,
        "cdate": 1666621235152,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621235152,
        "tmdate": 1666621235152,
        "tddate": null,
        "forum": "LfdEuhjR5GV",
        "replyto": "LfdEuhjR5GV",
        "invitation": "ICLR.cc/2023/Conference/Paper2847/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper targets at the task of MDE against the physical attack in a self-supervised manner. This paper proposes a reconstruction pipeline that pasting the projection of a 3D object onto two views and perturbate one of them, and then minimize the reconstruction error for the adversarial training. In this way, the ground-truth labels are no longer required. A loss is proposed to mimic physical attack.     \nExperiments are conducted on the KITTI with several attack mode, white box, black box and physical-world attack. ",
            "strength_and_weaknesses": "A working pipeline for the MDE task under the self-supervised training.\nThe image synthesize contains some issue. ",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty is somewhat limited. However, as long as it works, it is fine",
            "summary_of_the_review": "Combine figure 1 and figure 2, figure 2 can be a subfigure of figure 1.\n\nWhen summarize the contribution, pls make them concise. Some part of the description of summarized contribution can be moved out to the introduction part.  \n\n\u201cthe image in one view can be transformed to yield the image from the other view. For instance, I_t can be acquired by shifting I_s to the left\u201d. This is not that intuitive, which requires dense depth, and the accurate image inpainting process of the possible `holes' caused by scene disparities during the view shift. The situation becomes more challenging when using consecutive frames of video. \n\nThere are image issues, such as inconsistent environment lighting between the scene and object, if we pasting the projection of a 3D object directly onto the image plane. Using a virtual rendering engine, as mentioned in the paper, faces the similar issue. \n\nUsing the warp figures is not that informative for illustrate a figure. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_jvhn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_jvhn"
        ]
    },
    {
        "id": "m4zx7O6_F4",
        "original": null,
        "number": 4,
        "cdate": 1666947862866,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666947862866,
        "tmdate": 1670512579667,
        "tddate": null,
        "forum": "LfdEuhjR5GV",
        "replyto": "LfdEuhjR5GV",
        "invitation": "ICLR.cc/2023/Conference/Paper2847/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes an adversarial training method for self-supervised MDE models based on view synthesis without using ground-truth depth. It uses L0-norm-bounded perturbation in training to improve adversarial robustness against physical-world attacks. The experiments demonstrate the proposed methods can maintain similar performance on the raw data while defending PGD Patch attacks effectively. The idea of using self-supervised MDE is interesting and the novel framework seems novel. My main concerns are about the detailed designs and experiments.",
            "strength_and_weaknesses": "Strength:\n1. The idea is interesting and seems novel. The structure of this paper is clear. \n2. The paper appears to be technically sound and achieves some improvements over the existing methods.\n\nWeakness:\n1. The support of not using L_2 L_inf for adversarial training should be included in the experiment sections. \n2. The experiment is inadequate. This paper only uses L0-norm-bounded attacks and PGD attacks for black-box and white-box attacks. More types of attacks should be added to demonstrate the robustness of the model.  Existing experiments only contain the PGD attacks while ignoring more powerful attacks like Autoattack, which affects the convincing. Besides, are the adversarially trained models still robust to the natural perturbation-based adversarial attacks like adversarial blur attacks, and adversarial light attacks? \n3. The reason for the baseline selection is unclear. The authors can further explain why they were chosen as baselines and at what point they contrast with the newly proposed model. \n4. It claims the synthesized views are realistic. However, there are no experimental supports. \n5. How about the influences of inaccurate projections on view synthesis?\n6. The pictures in the article are somewhat misleading. The paper mentions that Figure 1 provides a conceptual illustration of their technique. It seems that in Figure 1 Cs and Ct are provided by two cameras, but the technique uses view synthesis in fact. Although they mention it in section 3, it would avoid misunderstanding if the authors could stress this in the figure.",
            "clarity,_quality,_novelty_and_reproducibility": "The structure of this paper is well-organized and clear. But there are still some parts that could be more specific and precise. This paper is likely to provide new methods to improve adversarial robustness against physical-world attacks. However, more experimental evaluation could be added to make their technique more convincing.",
            "summary_of_the_review": "This work proposes an adversarial training method for self-supervised MDE models based on view synthesis without using ground-truth depth. It uses L0- norm-bounded perturbation in training to improve adversarial robustness against physical-world attacks. The paper is well organized but the presentation has some details that could be improved. More experiments should be added to justify their technique.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_QLeq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2847/Reviewer_QLeq"
        ]
    }
]