[
    {
        "id": "wf8hqZQ2RFM",
        "original": null,
        "number": 1,
        "cdate": 1666371888969,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666371888969,
        "tmdate": 1670683097439,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors consider  data distributions of participating and unparticipating clients are drawn\nfrom a meta-distribution and use classic Rademacher complexity- and local Rademacher complexity-based generalisation bounds to develop excess risk bounds for unparticipating clients and fast semi-excess risk bounds for participating clients.  \n",
            "strength_and_weaknesses": "Strength: Studying federated learning in terms of learning is certainly an important direction, which has not been addressed in the current literature. I think the paper is well-written and the authors  did a good job in terms of going beyond convergence analyses and using known Rademacher complexity-based generalization bounds to obtain (semi) excess risk bounds. \n\n-----\n\nWeakness: Although the authors emphasized much about the relevanece of their bounds to FL in practical settings, in particular cross-device FL with a large pool of unparticipating clients, there are major concerns regarding the considered model, the correctness of results, and conditions under which main theorems hold, which will be elaborated in the following. Also, it is unfortunate that the paper lacks convincing experimental results to validate that the developed bounds indeed explain whether \"unparticipating clients benefit from the model trained by participating clients?\" \n\n-----\nDetailed comments: \n\n \"We argue that this assumption is reasonable in practice. For instance, in cross-device federated learning, the number of total clients is generally large and it is natural to assume that there exists a meta-distribution\"\n\nThis is not really convincing. What if some clients have data distributions that are quite different from others. Also what if the distribution of clients changes over time.  Another major issue is  how should such meta-distribution be modelled? Will you use parametric or non-parameteric models? Given that the authors emphasize much about practical scenarios and settings where several clients may not even participate in training, how can one model/estimate the meta distribution? Imagine that a practitioner does not have even a sample drawn from distributions for the major of clients (unparticipating clients).  \n\n-----\n\nThe symmetrization step in the proof of Lemma 1 should be expanded. BTW, the first line after \"By symmetrization, we have\" cannot be an equality. \n\nMore importantly, the definitions for ${\\cal R}_{mn}({\\cal F})$ in pages 14 and 15 are different, which makes the proof hard to read. The same issue exists in Lemma 2. In addition, $Z_1$,..., $Z_m$ in the proof of Lemma 2 are undefined. So I am not confident about the correctness of the results. \n\n-----\n\nTheorem 2 requires $n=\\Omega(d)$, which does not hold for typical overparameterized models whose number of parameters far exceed the number of training data.  This is even worse in Theorem 4 where $m$, which is claimed to be relatively small is required to be larger than $d$. \n\n-----\n\nThe techniques used to prove Theorem 2 are pretty standard based on (Bartlett et al., 2002, Sridharan et al., 2009, Yousefi et a.., 2018). Is there any technical difficulty in the problem of bounding semi-excess risk compared to previous work?\n\n\nKarthik  Sridharan, Shai Shalev-Shwartz, and Nathan Srebro. \"Fast rates for regularized objectives.\" Advances in neural information processing systems (NeurIPS),  2008.\n\n\nPeter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. \"Localized rademacher complexities.\" International Conference on Computational Learning Theory (COLT), 2002.\n\nNiloofar Yousefi, Yunwen Lei, Marius Kloft, Mansooreh Mollaghasemi, and Georgios C Anagnostopoulos. Local rademacher complexity-based learning guarantees for multi-task learning. The Journal of Machine Learning Research, 19(1):1385\u20131431, 2018.\n\n\n\n-----\n\nWhy not considering the excess risk instead of semi-excess risk for participating clients? It seems that the bounds will not be better than those for unparticipating clients.\n\n-----\n \nThe bound in Theorem 1 will be vacuous when using overparameterized models and a small $m$. The authors emphasized that $m$ is a moderate value in their settings.  which does not lead to a meaningful generalization results.  \n\n-----\n\nAssumption 2: $X_i^1$ in Assumption 2 is drawn from $D_i$, which is not $D$. Assumption 2 (a) does not seem to be compatible with Definition 1.  \n\n-----\n\n\nIt will be nice if the authors elaborate on what specific problems in ML lead to sub-Weibull loss  distributions with $\\alpha\\neq 1,2$ for $h$ as in Theorems 5 and 6. Also it is a bit confusing since in the introduction the authors claim that they consider sub-Weibull loss functions while they indeed consider sub-Weibull classifiers in Theorem 5,6. \n\n-----\n\nThe definition of  VC major class, which is the main building block of Theorem 1 should be provided in the main paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well-written but there were issues in the proofs, which should be properly addressed to improve clarity of the paper. \nI think the paper's quality can be improved. The techniques based on Rademacher complexity- and local Rademacher complexity to develop generalisation bounds are pretty standard. The reproducibility is not applicable as there are not experimental results. \n\n",
            "summary_of_the_review": "The authors  did a good job in terms of going beyond convergence analyses and developing (semi) excess risk bounds for participating and unparticipating clients. However, there are major concerns regarding the considered model, the correctness of results, and conditions under which main theorems hold. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_8Tvp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_8Tvp"
        ]
    },
    {
        "id": "smviZE10Wu",
        "original": null,
        "number": 2,
        "cdate": 1666647120973,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647120973,
        "tmdate": 1666647120973,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies generalization bounds in federated learning with unparticipating clients. A two-level distribution framework is proposed, where the data distribution of each client is sampled according to a meta distribution, then the data samples at each client is sampled from the client's data distribution. Afterwards, upper bounds on the generalization error are shown for two classes of loss functions. ",
            "strength_and_weaknesses": "Strength:\n- The analysis of generalization in federated learning is interesting and not often seen in the literature.\n- This paper is a solid piece of theoretical work which may inspire future work in this direction, although checking all the details is beyond my capacity.\n- The consideration of unbounded and heavy-tailed losses is an interesting theoretical contribution. \n\nWeakness:\n- It is not clear how clients are selected to participate or not participate. My conjecture is that the participating clients are selected independently from the underlying data distribution. If so, this setup does not fully consider some practical scenarios, such as where certain populations may generally have low-end phones or poor connections so that it is difficult for them to participate in federated learning. It would be more realistic if participation can be modeled as correlated to the underlying dataset, but I also understand the difficulty here.\n- The results depend on VC dimension, which is a way of quantifying the complexity of classical models but it generally does not capture the empirical behaviors of deep neural networks. Therefore, the theoretical bounds may not reflect what will really happen when training deep neural networks. \n- In Section 3, the assumptions are much stronger than what is usually used in the analysis of SGD-based federated learning algorithms. So the paper should not emphasize too much on obtaining 'fast' rates, as it is not fair to compare the rates obtained under different assumptions.\n- The paper considers clients that either participate or do not participate. For the participating clients, it assumes that the minimum empirical risk can be obtained by $\\hat{h}$. In reality, some clients may participate in more rounds and other clients may participate in less rounds, which may result in an inaccurate $\\hat{h}$ that does not give the true minimum of empirical risk. Such varying degrees of participation has not been considered in this paper.\n- The paper is mathematically heavy and lacks discussions on new findings and insights that can guide the understanding and design of practical federated learning systems. More discussions on what the bounds tell us intuitively (in plain words) about how federated learning algorithms will behave would be very useful.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper may be mathematically heavy for most people working on federated learning nowadays. Further discussion on new insights obtained from the theoretical results would be very useful, especially those that are not known in the field of federated learning as of today.\n\nQuality: The paper appears to be technically solid, although it is beyond my capacity to check all the details.\n\nNovelty: The work seems sufficiently novel.\n\nReproducibility: This is a theoretical paper with no experiments, so reproducibility is out of scope.",
            "summary_of_the_review": "Nice theoretical work, but it would be helpful if connections to practical federated learning systems and new insights can be discussed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_zSzo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_zSzo"
        ]
    },
    {
        "id": "kcZ42dw43JR",
        "original": null,
        "number": 3,
        "cdate": 1667460874685,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667460874685,
        "tmdate": 1669175257536,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "After the rebuttal, my main concerns have been resolved.\n-------------\nThis paper studies the generalization bounds for federated learning (FL) with heterogeneous local data. Similar to recent works (e.g. Yuan et al. 2021), a two-level distribution framework is considered, i.e. the local distribution is drawn from the meta-distribution, and the local data is drawn from the local distribution. Compared to previous works on the generalization of FL, this work can decouple the generalization bounds for participating and nonparticipating clients while showing fast rates under different sets of assumptions. ",
            "strength_and_weaknesses": "\n**Strength**\n- The problem studied in this paper is interesting and challenging. \n- Proof techniques seem to be new in the context of the generalization property of FL. Some open problems seem to be answered (e.g. unbounded loss, high-probability bounds).\n- The assumptions come with examples to back them up (e.g. Appendix B.1 for Assumption 2). Since this paper uses different assumptions compared to previous work, the examples make me better understand the contributions. \n\n**Weakness**\n- Some statements and claims in this paper are confusing to me (see the \"Clarity\" section below). \n- No empirical verifications (although this is not a big issue for a theory paper).\n\n\n\n\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe following parts of this paper are not clear to me. \n- Theorems 5 and 6 look weird to me. If $\\iota \\in (0,\\frac{1}{4})$ (say $\\iota = \\frac{1}{8})$, the second part of the rate is of $\\left(\\frac{1}{m}\\right)^{-\\frac{1}{4} + \\iota}$, which diverges as $m\\rightarrow \\infty$. It does not recover the $\\frac{1}{m^{\\frac{1}{4}}}$ rate shown in Table 1.\n- Assumption 3 states that $\\mathcal{H}$ is a family of bounded functions while the first sentence below that assumption claims that ``Assumption 3 is a mild assumption is the function classes are bounded.'' Could you please explain this?\n- Both column 2 and column 3 in Table 1 are some assumptions of the loss function (e.g. \"bounded\" in column 2 and \"Smoothness, SC\" in column 3). Why list them separately?\n- In several places in the appendix, I see both $(X,Y)\\sim D_i$ and $X\\sim D_i$.\n\n**Quality**\n\nThis paper is well-motivated and the research goal is easy to understand. However, there are a couple of typos and minor mistakes:\n- The last terms in Lemma 1 and Lemma 2 should be $3M\\sqrt{\\frac{\\ln(1/\\delta)}{2mn}}$ and $3M\\sqrt{\\frac{\\ln(1/\\delta)}{2m}}$?\n- \"state of art guarantees\"\n- \"Convering number\"\n- \"Uniformly entropy number\"\n- \"produc\"\n- Several missing references to equations in the appendix \n\n**Reproducibility**\nN/A\n",
            "summary_of_the_review": "In summary, this paper presents some interesting results on the generalization properties of FL. However, some technical claims seem to be problematic to me (especially the first bullet in the \"Clarity\" section). Disclaimer: This is probably due to my limited time for reviewing (It was assigned to me too late) and my lack of expertise on this topic. I am more than happy to raise my score if concerns are resolved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_yZwY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_yZwY"
        ]
    },
    {
        "id": "FosJCT3zcXR",
        "original": null,
        "number": 4,
        "cdate": 1667488213526,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667488213526,
        "tmdate": 1667488213526,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This is a theoretical work on the analysis of the generalization error in federated learning with heterogeneity of the losses and partial participation of the clients in the training process. The authors address the question: \"Would the unparticipating clients benefit from the model trained by participating clients?\". They provide a statistical analysis of the generalization error. The main assumption behind is that  the local distributions are sampled from a meta-distribution.",
            "strength_and_weaknesses": "The paper provides interesting theoretical insights about heterogeneity and the important challenge of partial participation in federated learning (FL).\n\nI am an optimizer, not a statistician. I develop optimization algorithms for FL and I am not familiar with these aspects. With this disclaimer in mind, I have the following questions:\n1) Is there a connection between your setting and the literature on personalized FL? Indeed, from the point of view of the nonparticipating clients, the obtained model is not personalized enough. I am thinking for instance of the paper Hanzely et al. \"Lower Bounds and Optimal Algorithms for Personalized Federated Learning\"\n2) I have come across the paper \"With a Little Help from My Friend: Server-Aided Federated Learning with Partial Client Participation\" of Yang et al. (https://openreview.net/forum?id=xT6d2Ghtkv) which also studies the generalization error of heterogeneous FL with partial participation, and study server-aided FL as a possible remedy. Could you comment on their findings?\n3) Characterizing heterogeneity is important, as well as the study of the convergence speed of learning algorithms, depending on the amount of heterogeneity: intuitively, convergence is faster in the homogeneous setting, since there is redundancy, than in the heterogeneous setting. For instance in the paper \"Permutation Compressors for Provably Faster Distributed Nonconvex Optimization\"\nby Szlendak et al., they introduce the notion of \"Hessian variance\", which characterizes the similarity between the individual loss functions of the clients. Since the losses are date-fit terms with respect to the individual datasets, this is directly related to the amount of heterogeneity. Could you comment on this aspect?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written.",
            "summary_of_the_review": "The paper provides some new insights on partial participation, which is a timely and important problem in modern distributed learning settings. The paper studies the impact of partial participation from the mathematical/statistical point of view. These findings are interesting but there is no contribution from an algorithmic point of view, on how to mitigate the effects of partial participation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_zYTD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_zYTD"
        ]
    },
    {
        "id": "78UhsHcnCz",
        "original": null,
        "number": 5,
        "cdate": 1667531569009,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667531569009,
        "tmdate": 1667531569009,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the generalization property of federated learning under the two-level distribution framework: client D_i is sampled from a meta-distribution P, and sample Z_i^j is sampled from D_i. Excess risk for unseen clients and semi-excess risk for seen data are analyzed under various conditions in high probability form. For VC major class, O(1/\\sqrt{mn} + 1/\\sqrt{m}) rate is  established; for stronger Bernstein condition, O(1/{mn} + 1/m) is achieved; for sub-Weibull/heavy tailed losses, O(1/{mn}^{1/4} + 1/m^{1/4}) rate is achieved. \n",
            "strength_and_weaknesses": "The paper is generally well written and clear. I appreciate the summary in Table 1. Though I did not check the details of the proof, the results look reasonable. \n\nGeneralization in federated learning is a timely topic, and the two-level distribution analysis makes a lot of sense. \n\nI have a few \u201ccliche\u201d comments for a theoretical paper. \n\nMaybe I missed it, could the authors comment more on the connection to practice. Specifically, in table 1, compared to assumptions in previous papers, do new assumptions make more sense in practice? I understand that the results themselves are interesting: Lipschitz is probably more general than bi-classifiation; Bernstein can be more general than smoothness+SC (maybe?) and a probability form rather than expectation form is shown; sub-Weibull/heavy tailed losses are analyzed for the first time for FL. \n\nAnother bonus point: what are the main insights for federated learning? \u2013 it is nice to know that the risk gaps close when clients m and samples n are increased, but anything more? For example, what is the role of heterogeneity for seen and unseen clients? For semi-excess risk, why m and n seem to play a similar role? How does the assumptions interact with two-level distribution \u2013 any common or difference compared to centralized setting? \n",
            "clarity,_quality,_novelty_and_reproducibility": "See comments on strengths and weaknesses. \n",
            "summary_of_the_review": "I like the topic of the paper, and the results seem to be reasonable. I would encourage authors to provide stronger motivation for analyzing generalization in FL under the proposed conditions, and the insights from these analysis. I will try to read in more detail for technical correctness and understand the difficulty of the analysis. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_Uj7L"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_Uj7L"
        ]
    },
    {
        "id": "ibWDBsec7p",
        "original": null,
        "number": 6,
        "cdate": 1667532139827,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667532139827,
        "tmdate": 1667532686057,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied generalization of federated learning. They first consider Bernstein function class, and achieve faster rate in risk bound: $O(1/mn)$ for participating clients and $O(1/mn)+O(1/m)$ for nonparticipating clients. They further proceed to the unbounded loss setting, with small-ball condition assumptions. To prove generalization in the bounded loss setting, they borrow the standard local Rademacher complexity based analysis from [1], where they controlled the variation of the loss function i.e., $Pf^2$ and relating localized class to full class. For unbounded loss setting, they borrow the technique from seminal work Learning without concentration~[2][3], where they assume a small ball condition on hypothesis class.  \n",
            "strength_and_weaknesses": "Strength\n\n1. This paper used a bi-level distribution framework to model the federated learning, and assume the nonparticipating client's distribution comes from meta-distribution $P$. Then, they treat the generalization risk on nonparticipating distribution as the expected risk on a distribution sampled from $P$.  This formulation looks novel to me, even though I still have some concern about this setting which I will discuss later. \n\n2. To get sharper risk bound, they employed seminal local Rademacher complexity based generalization analysis. To my best knowledge, in federated learning community, these techniques are new (analysis on Bernstein class, local Rademacher complexity, small ball method etc), and no one before use them to analyze FL's generalization bound.\n\nWeakness\n\n1. Assuming all clients' distributions obeys the same meta distribution, and assuming clients are sampled i.i.d. from this meta distribution are strong. Hence, in the risk bound for nonparticipating clients, we cannot see the impact of discrepancy between distributions used in training and target client distribution. To show the dependency of distribution discrepancy in nonparticipating client's risk bound is important, since based on that we can design domain adaptation algorithms to make nonparticipating client benefits more from collaborative learning. \n\n\n2. From a technical perspective, the novelty in the proof is limited. To me this paper is more like applying existing generalization analysis of Bernstein class, and small ball condition class on federated learning. The only difference is that here we are not drawing samples from one distribution but $m$ of them. However, this does not change the game too much since it is still an unbiased sampling: we draw a multi-sample from the product of distributions, and we examine the population risk also on the product of these distributions. For examples, when the authors prove Theorem 2, they borrow the proof procedure of Theorem B.3, Theorem 9 of [1], controlling the variance of the loss function i.e., $Pf^2$, bounding the local Rademacher complexity, and relating the local class to full function class. The proof without a bounded loss setting is also similar to seminal work [2][3]. I suggest the authors can elaborate more on their technical contributions beyond these existing works [1][2][3].\n\nQuestions:\n\n - In Theorem 2, should not the first term in the risk bound depend on VC dimension?\n\n- At the beginning of Page 19, the definition of $V(f) = \\frac{L^2}{m}\\sum_{i=1}^m \\mathbb{E}(h(X) -\\hat{h}^*(X) )^2$ , it seems that the index of $X$ is missing? I guess the expectation is taken over $X \\sim D_i$.\n \n- The typo right after the computation of $R(F^*,r)$: Condiser $\\mapsto$ Consider\n  \n- At the beginning of Page 25, definition of $B$ norm, should not it be $\\|g\\|_{B}=\\sup_{f\\in F} |g(f)|$?\n\n[1] Yousefi, Niloofar, et al. \"Local rademacher complexity-based learning guarantees for multi-task learning.\" The Journal of Machine Learning Research 19.1 (2018): 1385-1431.\n\n[2] Mendelson, Shahar. \"Learning without concentration.\" Journal of the ACM (JACM) 62.3 (2015): 1-25.\n\n[3] Mendelson, Shahar. \"Learning without concentration for general loss functions.\" arXiv preprint arXiv:1410.3192 (2014).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is well-written and easy to follow.",
            "summary_of_the_review": "In summary, this paper introduces classic finer generalization analysis technique to federated learning, and does achieve better rates, but I am not sure how much the technical contribution are novel in the context of  existing works as discussed above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_QQ79"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_QQ79"
        ]
    },
    {
        "id": "c17Y0m3G7q",
        "original": null,
        "number": 7,
        "cdate": 1668392713511,
        "mdate": null,
        "ddate": null,
        "tcdate": 1668392713511,
        "tmdate": 1670350910514,
        "tddate": null,
        "forum": "-EHqoysUYLx",
        "replyto": "-EHqoysUYLx",
        "invitation": "ICLR.cc/2023/Conference/Paper2925/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors study the generalization behavior of federated learning in a meta-distribution framework by characterizing two error terms: the empirical-population gap on clients that participate in training as well as the gap between participating-population at the clients level. They establish such bounds for bounded losses, but also unbounded losses for the case of least squares regression with sub-Weibull noise condition and a small ball inequality. \n\n**EDIT**: I have raised my score from 5 to 6 after the rebuttal.",
            "strength_and_weaknesses": "I should start with the disclaimer that I only have a passing familiarity in the techniques used in this work. \n\n**Strengths**: \n- First work to consider generalization of a federated learning to clients that do not participate in learning. Assuming a meta-distribution over clients is a natural idea for cross-device federated learning that has been suggested in the literature yet a precise analysis of this generalization has eluded us. \n- Studying unbounded losses in this setting is technically challenging. It is possible to sweep under the rug subtle differences across clients with bounded loss/gradient assumptions in the federated setting. Avoiding such assumptions is a plus. \n\n**Weaknesses**: \n\n(W1) Interpretability: The biggest weakness for me is the lack of interpretability of the results, especially in Section 4. \n- The unparticipating generalization bound must show some measure of the *spread* of $P$ as a bound on the heterogeniety. In the degenerate case that every client is completely different from each other, it should not be possible to bound the unparticipating gap. Likewise, if also the clients are identical, this gap should be 0. \n- My best guess is that these details are hidden in the $\\kappa_m$ and $\\omega_m$ objects (or in the previous sections, in the bound on the loss). It would be extremely helpful if the authors could elaborate on this dependence. \n- More details on this below. \n\n(W2) Lack of clarity: it is nearly impossible to understand this paper without a deep familiarity with a fairly advanced and niche area in learning theory. To make the paper more accessible to the federated learning community, it would be helpful to precisely define all of the mathematical objects used (at least in the appendix), point to textbooks for a condensed background (if applicable), and discuss several simple special cases such as linear regression and binary logistic regression. \n",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity\n\nThere are several issues with clarity. \n- There seems to be an implicit assumption that $\\mathcal{Y} \\subset \\mathbb{R}$. Does the framework handle multi-output regression or multiclass/multilabel classification? \n- **Bernstein condition**: The Bernstein condition is not very interpretable. That it holds for linear regression is clear from Appendix B. Does it hold for other settings such as binary logistic regression? If yes, under what assumptions? What are the values of $B$ and $\\beta$ in this case? I would suggest that these details, if proved in previous papers, can be recalled in the appendix for the reader's convenience. \n- What is $\\mathcal{F}$ in theorems 2, 3, 4? It is not defined.\n- *Sub-root function* in Theorem 3 is not defined. It might be easier for the exposition to combine Theorems 3 and 4 into one. \n- Small-ball condition: In Definition 4, the quantity $\\mathbb{P}( | h| > \\tau \\| h\\|_{L_2})$ appears. What is the probability over? I'm assuming you mean $h(X)$. But what distribution is $X$ drawn from? \n- The bounds in section 4 are on $\\| h_1 - h_2\\|_{L_2}$. How do these translate to vanilla generalization bounds, such as the ones developed in the preceding sections? \n- The definitions of $\\omega$ and $\\kappa$ are not interpretable. What do these terms scale like? What do you they look like for simple special cases? \n- The readability of the proofs would be greatly helped with a description of the high level idea and refactoring the proofs into smaller logical units. \n- There are far too many (??) in the appendix and the manuscript looks incomplete.  \n- Definition 7 in Appendix A is not a real definition. \n- Appendix B.1 is not rigorous and can be improved. First, $X$ and $Y$ are dropped everywhere and it is hard to read. Next, the form of the Bernstein condition used here is different from the one in the main paper (and more like the one in Yousefi et al.). Equalities and inequalities in the first display of Section B.1.1 seem to be interchanged. For Section B.1.2, $\\mathcal{F}$ is unclear. Further, \"$\\hat h^*$ is the projection of $Y$ in the space $\\mathcal{F}$\" is too casual. The inner product in $\\langle Y - \\hat h^*(X), h(X) - \\hat h^*(X) \\rangle$ is not defined. The $L_2$ norm in this space has not been defined either.  \n\n# Novelty\n- The results appear to be somewhat straight-forward extensions of the existing literature (please correct me if I'm wrong). This in and of itself is not necessarily a negative, especially if the results give a novel perspective on the federated learning literature. However, there are one or two more steps required in translating these results into ones that make sense from a federated learning context. \n\n# Reproducibility\n- I have not had the time to carefully check the proofs. Furthermore, the fact that I cannot interpret the definitions (as mentioned previously) means that I really do not know what exactly the statements of Section 4 convey. \n\n# Minor\n- There might be some technical difficulties in defining the two-level framework in full rigor, for instance, measurability, compactness, etc.\n- There are several instances of comparing bounds in expectation versus high probability, e.g. in Remark 3: \"... in high probability form, which is more emergent and challenging\". Could you explain this further? As far as I can tell, both convey the same information, except for technical differences.",
            "summary_of_the_review": "While the setting of the paper is very timely and there are many technical difficulties in the process, I feel like this paper is still a work in progress. These results look very much like intermediate results to me and are missing a final level or two of translation into statements that are more directly applicable in the federated learning setting. I would urge the authors to take steps to make the paper more accessible and specialize the results to interpretable special cases. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_KoJF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2925/Reviewer_KoJF"
        ]
    }
]