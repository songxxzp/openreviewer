[
    {
        "id": "568lW8yjeJ0",
        "original": null,
        "number": 1,
        "cdate": 1666621974112,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621974112,
        "tmdate": 1666622042258,
        "tddate": null,
        "forum": "6FEULL9vSUt",
        "replyto": "6FEULL9vSUt",
        "invitation": "ICLR.cc/2023/Conference/Paper3773/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an approach to predict parameters of the model for unseen datasets given a fixed model. To do so, the paper proposes to leverage hypernetworks to predict model parameters for unseen datasets. The proposed pipeline is validated on three sets of datasets simulated from standard ML datasets (CIFAR-100, Fashion-MNIST, and ImageNet) and three simple CNN architectures (3-layer CNN, ConvNet-3, and a Resnet18). The reported results highlight the benefits of the proposed pipeline. Moreover, the authors stress-test the pipeline on one cross domain setup by training the model on CIFAR100 and testing it om Animals 10.",
            "strength_and_weaknesses": "Strengths:\nThe topic studied in the paper is of interest to the ML community.\nThe paper is well written and easy to follow\n\nWeaknesses (details in next section):\nThe validation of the paper could be strengthened by considering more challenging setups and models.\nPositioning the paper w.r.t to transfer learning, few-shot and zero-shot literature is missing\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nThe paper is well written and easy to follow. The reviewer has only some minor comments suggestions re clarity:\n\n- Any reason why the authors refer to dataset embeddings as sketches and not as embeddings?\n\n- It would be nice to present the details of the dataset used to validate the ideas in the introduction. \n\nQuality:\nThe quality of the paper could be improved along two axes: (1) Improved positioning w.r.t. prior art, and (2) stronger validation.\n\n- The core of the idea is to predict parameters for unseen datasets while training the model on seen datasets. This idea is at core of other well studied topics in ML that go beyond hypernetworks and efficient optimization. The authors should discuss how the introduced ideas relate to topics such as generalization, transfer learning, few-shot learning and zero-shot learning. \n\n- Introduction. The paragraph starting with: \u201cIn this paper, we investigate a new training paradigm for deep neural networks\u201d should contrast what is new in current submissions with the line of works of GHN for network parameter prediction (Ha et al., 2017; Knyazev et al., 2021).\n\n- A relevant paper to consider could be: https://arxiv.org/pdf/1606.02185.pdf\n\n- The paper is validated on rather simple scenarios where the training and the testing datasets are derived from a single dataset e.g. ImageNet. Only one relatively simple cross domain setup is considered (CIFAR-100 -> Animals-10). Adding additional more challenging scenarios would benefit the paper, e.g. training on ImageNet and validating on places datasets and vice-versa.\n\n- Similarly, adding more challenging architectures would also strengthen the validation of the paper, e.g. ResNet50, ResNet101, ViT, ResNext, etc.\n\n- The importance of dataset embedding is not ablated. Adding ablation of a variety of dataset embeddings would strengthen the paper. \n\n- In the current dataset embedding function, how important is the choice of feature extractor? Which extractors have been considered? Is the feature extractor pretrained?\n\nNovelty:\nThe paper could have some edge of novelty however the positioning of the idea should be strengthened by differentiating the current pipeline w.r.t. transfer learning, few-shot and zero-shot learning ideas.\n\nReproducibility:\nThere is no mentioning about code release. However, based on a reading of the paper, there seem to be enough details to enable the reproduction of the reported results.\n",
            "summary_of_the_review": "Overall, the paper is interesting, well written and easy to follow. However, prior to recommending the paper for acceptance the reviewer would like to see improved validation and better positioning of the introduced idea/pipeline.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_VS2g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_VS2g"
        ]
    },
    {
        "id": "sDb0FRnD8C",
        "original": null,
        "number": 2,
        "cdate": 1666679458830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679458830,
        "tmdate": 1666679688363,
        "tddate": null,
        "forum": "6FEULL9vSUt",
        "replyto": "6FEULL9vSUt",
        "invitation": "ICLR.cc/2023/Conference/Paper3773/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "To overcome heavy burden of computational cost and time to learn network parameters, this work propose a method that predicts parameters of the network on the given unseen dataset. For this, they allow the new hypernetwork to directly predict the network parameters with forward process, by learning mapping between datasets and their corresponding network parameters. With only 0.5 GPU seconds, this method can predict the network parameters of ResNet-18 which is competitive performance compared with the parameters trained on the dataset from scratch.",
            "strength_and_weaknesses": "- Strengths\n    - Writing is clear and easy to follow.\n    - Novel concept idea. This work reveals that there is correlation between datasets and the network parameters.\n    - With a single hypernetwork, this work can predict the parameters of multiple datasets. I think this is quite new.\n- Weaknesses\n    - The main concern is that the experiments to validate the proposed method are limited and weak.\n        - While experimental setting is similar with the existing meta-learning methods for the classification task, the most recent or powerful meta-learning methods are not compared.\n        - In addition, I think that such similarity with the existing few-shot classificaiton tasks for the meta-learning are not attractive and not challenging. The most architectures are small (3 CNN layer ~ ResNet-18) and the small number of classes in each task, most unseen tasks are sampled from the in-distribution dataset with the seen tasks. I think this work need to more focus on the cross-domain setting or different architectures.\n        - For the fair comparison, I think Meta-dataset [1] can be used.\n     - There is a related work [2] that a single hypernetwork can predict parameters for unseen architectures. I recommend to add discussion with this related work.\n\n[1] Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples, ICLR 2020\n[2] Parameter Prediction for Unseen Deep Architectures, NeurIPS 2021",
            "clarity,_quality,_novelty_and_reproducibility": "Regarding writing, the clarity and quality is good. Hypernetwork supporting multiple datasets is novel.",
            "summary_of_the_review": "I think the experimental setting is rather limited to support or validate the proposed method. As I mentioned in the strengths and weaknesses section, I hope the authors address my concern by showing the solid and extensive experimental results on more realistic settings.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_AS8e"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_AS8e"
        ]
    },
    {
        "id": "DZmv6m3unH",
        "original": null,
        "number": 3,
        "cdate": 1667101189927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667101189927,
        "tmdate": 1667101189927,
        "tddate": null,
        "forum": "6FEULL9vSUt",
        "replyto": "6FEULL9vSUt",
        "invitation": "ICLR.cc/2023/Conference/Paper3773/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to predict the parameter of a neural network via a hyper-network.\nIt mainly consists of two components, a compression method to capture the feature of a dataset, and a GRU-based network to generate the per-layer parameter.\nSome empirical results are very interesting and surprising.",
            "strength_and_weaknesses": "### Strengths\n- I'm not familiar with the area of generating network weight for unseen datasets. But to me, this paper is well-motivated and novel.\n- The organization of this paper is pretty good, first using an experiment to demonstrate the correlation between the dataset and the trained weight, then three main components of the method, it's easy to follow and interesting to read.\n- Empirical evaluation is thorough and have some interesting results. Although the performance still lay far behind a fully-trained network, it can achieve reasonable results.\n\n### Weaknesses\n- The core of the proposed approach is that it can generate parameters for unseen datasets. The paper only shows CIFAR-100 -> Animals-10, I would expect some other evidence. For example, CIFAR-10 -> ImageNet.\n- One interesting I notice in the method is that it trains a weight generator, which allows generating parameters of different sizes. However, I don't see any evidence in the experiment part. For instance, can you use the network to generate a larger ResNet-50 and show the accuracy?\n- The ablation study reveals the effectiveness of different parts. Despite this, it could be better if the authors can provide more insights and intuitions in the method part. Some part is a bit ad-hoc to me. For instance, adding an additional classification head and trying to match the two predictions.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nThe paper is well-written and clear.\n\n### Novelty\nAlthough the employed techniques like the dataset compression are not new, the whole framework is novel to me.\n\n### Reproducibility\nThe dataset split, training details are provided, but I don't see any code.\n",
            "summary_of_the_review": "The paper is novel and interesting to me in general. However, there are some missing empirical evaluations and intuitions, which I would like to hear from the authors in the feedback phases.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_y6gY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3773/Reviewer_y6gY"
        ]
    }
]