[
    {
        "id": "BIG7iEY-gN",
        "original": null,
        "number": 1,
        "cdate": 1666534474772,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666534474772,
        "tmdate": 1666534474772,
        "tddate": null,
        "forum": "H9LxwdiXlh",
        "replyto": "H9LxwdiXlh",
        "invitation": "ICLR.cc/2023/Conference/Paper881/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed Additive Poisson Process (APP), which models higher-order interaction effects of the intensity functions in Poisson processes using projections into lower-dimensional spce. The intensity function is modelled using a log-linear model, whose parameters are learned by minimizing the KL divergence between a sample distribution in lower-dimensional projections and the distribution with an intensity function. The empirical experiments showed promising results on synthetic datasets and a real world dataset. \n",
            "strength_and_weaknesses": "Strength:\n* The idea is interesting. The problem of modelling the intensity function in multi-dimensional Poisson processes is challenging due to sparse observations. Approximating the high-dimensional intensity function using low-dimensional projections and framing it in an GAM form is a nice idea.\n\nWeakness:\n* a log-linear model is proposed in APP, which is a bit restrictive in its functional form. How easy it is to extend the method to richer class of (non-linear) models? \n* Is it not obvious to me that such a low-dimensional representation always exists. Related to this, How big of k (i.e., the truncation level of the order) is sufficient? Have you thought about ways to improve/constrain APP such that k needed can be low? On the contrary, as the authors also pointed out, large k may result in overfitting, how should one pick k in practice? \n* The hyperparameters M and h are learned with grid search, which may be expensive in high-dimensional problems. \n* The experimental results are all on synthetic data expect one on the New York taxi dataset. More extensive results will make the paper stronger. \n* the number of parameters grows exponentially with the dimension and there is no structural dependency between the theta's. Will it help to enforce some dependency between them (for examples, theta_{1,2} depends on theta_1 or theta_2)? \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation and clarity of the paper in terms of typos and notations can be improved. For example, g in Theorem 2.1 is not defined; Introduction -> introduction in the first line of page 5; caption in Figure 3 should include first-order Poisson process too. \n\nAuthors included code in the supplementary material.\n",
            "summary_of_the_review": "The paper presents a framework for modelling the intensity function in high-dimensional Poisson processes. There are potential improvement area in terms of the presentation, more thoroughly analysis/experiments and discussion, but overall I think it is an interesting idea. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper881/Reviewer_2omy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper881/Reviewer_2omy"
        ]
    },
    {
        "id": "iKbDL1V2MQ",
        "original": null,
        "number": 2,
        "cdate": 1666613985380,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613985380,
        "tmdate": 1666613985380,
        "tddate": null,
        "forum": "H9LxwdiXlh",
        "replyto": "H9LxwdiXlh",
        "invitation": "ICLR.cc/2023/Conference/Paper881/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces an inference model for learning the intensity function of a multidimensional Poisson process. The approach is presented as an application of generalized additive models to Poisson processes. One key point comes from information geometry for the log-linear model which shows that the likelihood function of the model at stake is convex.",
            "strength_and_weaknesses": "This paper makes an interesting connection between multidimensional Poisson processes, generalized additive models, and information geometry. The approach seems to me original and deserves to be studied.\n\nHowever, the two key points of the paper (the model itself, obtained as an application of generalized additive models, and the convexity of the optimization problem) do not require any deep theoretical or empirical development. This is not necessarily an obstacle but, in this case, I would expect at least some theoretical guarantees on the quality of the estimate obtained by the method, which are lacking.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite well written and organized, but I have the following comments, in order of importance:\n\n- Part of the state-of-the-art in the introduction has been deferred into the supplementary material, which seems to me quite unusual. Moreover, the approaches cited in this appendix are not used as references in the numerical study of the paper. In particular, Poisson factorization appears to be a very relevant baseline.\n\n- Selection of hyperparameters should be investigated in more than few lines at the beginning of the numerical section. For example, we can think that hyperparameters should be selected in a coupled way. Moreover, they have a strong effect on the complexity of the algorithm, which should be taken into account.\n\n- At the beginning of subsection 2.2, the time window is discretized, which avoids to evaluate an intractable integral that appears in the likelihood. I would expect further explanations on this point, like a control of the error induced.\n\n- I am rather surprised that the largest dimension considered in the numerical part is 4.\n\n- Page 3, after equation (2): The authors introduce function $g$ then select $g=\\exp$. How critical is this choice? For example, it appears in subsection 2.3 that the optimization problem is convex because the model is log-linear.\n\n- Introduction: There is no Fig. 1b.\n\n- Typo: spacial (page 5)",
            "summary_of_the_review": "The approach followed in this paper is in my opinion interesting but requires further developments, both theoretical and numerical, to be published in this conference.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper881/Reviewer_x4an"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper881/Reviewer_x4an"
        ]
    },
    {
        "id": "6eP6JdfjJqs",
        "original": null,
        "number": 3,
        "cdate": 1666623062510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623062510,
        "tmdate": 1666623078431,
        "tddate": null,
        "forum": "H9LxwdiXlh",
        "replyto": "H9LxwdiXlh",
        "invitation": "ICLR.cc/2023/Conference/Paper881/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors consider the problem of learning the intensity function of an inhomogeneous Poisson process (PP) over higher dimensional spaces:\n 1. The authors propose a certain family of generalized additive models (GAM) to model the log-intensity function of the PP and call their method the additive Poisson process (APP).\n 2. They propose to learn the parameters of the GAM by minimizing the Kullback-Leibler (KL) divergence between a tractable kernel density estimate (KDE) approximation to the empirical intensity and the intensity given by the GAM.\n 3. The authors test their method on two synthetic and one real-world dataset.",
            "strength_and_weaknesses": "## Strengths\nThe authors consider a relevant problem, and their proposed solution is sound and holds some promise for estimating the intensity functions of low- to medium-dimensional PPs.\n\n## Weaknesses\nWhile the paper has some good ideas, some of the presented theoretical connections are dubious, and I am not convinced that the empirical results bear out all of the authors' claims. Concretely:\n - The authors choose to model the log-intensity function with a GAM, but I do not see how this modelling choice is supposed to constitute any sort of deeper connection. I am hung up on this point because the authors seem to dedicate a significant part of Section 2 to this claimed connection, which appears to only consist of trivial algebraic manipulations.\n - The authors' claim that their method scales better to higher-dimensional problems is dubious. While strictly speaking, their learning process does scale better than other methods, it still scales exponentially in the dimensionality of the space. Hence, their method is limited to moderate-dimensional problems.\n - Some of the empirical results on problems that are supposed to be favourable for APP do not seem convincing. A well-known issue of GAMs is that due to their flexibility, they can heavily overfit, which appears to be precisely the case in Figure 4. Especially in the right plot, the APP intensity is wholly concentrated on the data points, while the KDE fit seems far more reasonable.\n - Similarly, as shown in Figure 3, KDE outperforms APP on the process with higher-order interactions. The authors note this but claim that \"Figures 3a and 3b show that KDE is sensitive to changes in bandwidth, which means that, for any practical implementation of the model, second-order APP with a less sensitive bandwidth is more likely to learn a more accurate intensity function when the ground truth is unknown.\" - However, I don't think Figure 3 demonstrates that APP would be much less sensitive to the kernel bandwidth than KDE. \n - I also think the name for the authors' method is quite misleading. \"Additive Poisson process\" would suggest that the family of processes described is a subclass of PPs for which some nice additive property holds (e.g. stability under addition). However, this is not the case, and I would like to ask the authors to pick a more fitting name.\n - The authors claim, \"Based on the Kolmogorov-Arnold representation theorem, generalized additive models are able to learn the intensity of the higher-order interaction between Poisson processes by using projections into lower dimensional spaces.\" - This cannot be true, as GAMs use a more restricted family of functions, so the K-A theorem does not necessarily apply. It would be necessary to discuss the approximation properties of the particular family of GAMs they use to make this claim precise.\n - The experimental methodology is not properly described in the case of synthetic data experiments. It is unclear what data the methods were tested from which the plots were generated.\n - The authors invoke a lot of mathematical machinery, e.g. the poset formulation for the model and information geometry, without seemingly relying on it too much. I think the method and training process could be described in much simpler terms which would heavily improve the paper's readability.\n - The authors claim to use natural gradients to solve their proposed optimization problem. However, they never demonstrate the utility of this over standard gradient descent.\n\n## Questions\n - \"Our model combines the techniques introduced by Luo & Sugiyama (2019) to model higher-order interactions between Poisson processes and by Friedman & Stuetzle (1981) in generalized additive models to learn the joint intensity function using samples in a lower dimensional space\" - a lower dimensional space compared to what? Also, this sounds very similar to the approach in the paper. How do they actually differ?\n - \"The learning process in our model is formulated as a convex optimization problem to arrive at a unique optimal solution using natural gradient, which minimizes the Kullback-Leibler (KL) divergence from the sample distribution in a lower-dimensional space to the distribution modeled by the learned intensity function. This connection provides...\" - the previous sentence is not explaining a connection to anything. What are the authors referring to here?\n - What do the authors mean by \"higher-order intensity function\"? Do they mean higher-dimensional? Perhaps they meant to use it analogously to the phrase \"higher-order interaction\", but I don't think \"higher-order intensity function\" is standard terminology.",
            "clarity,_quality,_novelty_and_reproducibility": "The text contains some very long and hard-to-parse sentences and questionable stylistic and typographic choices. For example:\n - After reading the introduction, it is hard to ascertain what the authors are claiming as their contributions. Therefore, I would suggest they list their claimed contributions at the end.\n - I discourage using $\\mathbb{N}$ for the counting process, as this symbol is usually reserved for natural numbers. Perhaps use $\\mathbf{N}$ instead?\n - \"Each J \u2286 [D] determines the condition of the occurrence of the event.\" - what does this mean?\n - \"To flexibly consider any combination of possible states, [D] is composed of possible states across all dimensions.\" - what does this mean?\n - \"For example, in the taxi pick up example in Introduction, domains of x, y, W are discretized to disjoint sets as ...\" - this is very confusing. I thought these three variates were each one-dimensional. It is unclear whether the authors mean to say to quantize/ bin the values of continuous variates or simply that multivariate variates can be concatenated to form one big multivariate state. In the latter case, using the phrase \"discretizing domains\" is incorrect.\n - \"We define the functional prior\" - This is misleading, as the authors only set the functional form but do not define a prior distribution over log-intensities.\n - \"replacing the range with $I \\subseteq J$\" - this is not what the authors actually mean. They mean that the range becomes the power set of $J$.\n - Sections 2.2 and 2.3, containing the authors' methodology, should be separated from the earlier subsections describing the technical background.\n - The definition of $Z$ in Eq 10 is incorrect. As it is currently defined, $Z$ would necessarily equal 1. The authors should either define $\\hat{p}$ as an unnormalized probability or define $Z$ as a sum of the $\\sigma_I$ terms.\n - The size of the plots in Figures 3-5, but especially the font size of their labels, need to be increased as they are currently close to unreadable.\n - Figure 4 is cluttered and hard to read.",
            "summary_of_the_review": "The authors present a fine idea, but the presentation quality is low, and the empirical results seem weak.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper881/Reviewer_8qDw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper881/Reviewer_8qDw"
        ]
    },
    {
        "id": "EhAMs-6CNw",
        "original": null,
        "number": 4,
        "cdate": 1666669967838,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669967838,
        "tmdate": 1666669967838,
        "tddate": null,
        "forum": "H9LxwdiXlh",
        "replyto": "H9LxwdiXlh",
        "invitation": "ICLR.cc/2023/Conference/Paper881/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "I reviewed this same paper last year for ICLR 2022. By comparing the current manuscript and the manuscript from last year, I did not find significant differences. Therefore, I will reiterate my questions from last year.\n\nThis paper proposes a method to estimate the multi-dimensional intensity function of a Poisson process with a lower-dimensional projection. The proposed method is motivated by perspectives of information geometry and generalized additive models in statistics. The performance of the proposed method is extreme through synthetic examples and real data analysis.\n\n ",
            "strength_and_weaknesses": "Strength: The paper is overall well written and the presentation is clear. \nWeakness:  The major issue I have with this paper is that the proposed approach has long existed in the statistics literature for decades, under the context of generalized additive models. In particular, in chapter 5.6 of [1], the tensor product bases are more flexible than the approach proposed in this paper. In my opinion, the lower-dimensional approximation proposed in this paper is essentially a piecewise constant approximation of the intensity function (in lower dimension), which is a special case of the tensor product basses. If comparisons should be made, they should be between the proposed method and the GAM with tensor product bases, instead of the RKHS formulation.\n\nIn addition, the partial order in formulation (7) seems to rely on the assumption that all dimensions have the same common support [0, T], which is not the case for the spatial-temporal processes considered in this paper. How is this issue addressed?\n\nFor the proposed method, the most difficult task should be to determine the value of hyper-parameters M and h. If M is too large, it can easily lead to overfitting. If M is too small, there will be a large bias in the estimated intensity functions. Please provide more details on how cross-validation is performed to choose an optimal combination of h and M.\n\nAnother difficult task with the proposed method is how to justify the use of lower-dimensional approximation. For example, is it justifiable to assume that there is no need to consider spatial and temporal interaction in a spatial-temporal point process? In GAM, one can do this by performing an analysis of variance (ANOVA), see, e.g., section 5.6.3 of [1]. Could this be done with the proposed approach?\n\nMinor points:\n\n1. In the motivating example, the time coordinate is the day of the week, which is discrete. Such an example is not coherent with the definition of the Poisson process, which should be with continuous coordinates.\n\nReference:\n[1]. Wood, S.N., 2017. Generalized additive models: an introduction with R. CRC Press. (2nd Edition)",
            "clarity,_quality,_novelty_and_reproducibility": "I think the novelty of the paper is limited.",
            "summary_of_the_review": "I think the paper is well written, but I do not see the methodology proposed to be better than the existing ones.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper881/Reviewer_Cwen"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper881/Reviewer_Cwen"
        ]
    }
]