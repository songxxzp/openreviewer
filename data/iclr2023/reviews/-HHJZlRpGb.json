[
    {
        "id": "0s1FyqlK5Jc",
        "original": null,
        "number": 1,
        "cdate": 1666002764699,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666002764699,
        "tmdate": 1666002764699,
        "tddate": null,
        "forum": "-HHJZlRpGb",
        "replyto": "-HHJZlRpGb",
        "invitation": "ICLR.cc/2023/Conference/Paper160/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a variational autoencoder strategy to offer robustness to hospital-specific X-ray characteristics. The methodology aims to disentangle these centre-specific measurement characteristics from the features predictive of the condition. The paper presents theoretical intuition and evidence of the stronger robustness of malignancy classification on 4 mammogram datasets by demonstrating how their model trained on a subset of these datasets generalizes better to a dataset external to the training set.",
            "strength_and_weaknesses": "The paper clearly presents the motivation and the studied problem, which is highly relevant to the medical community. The paper is well structured and written which makes the proposed model clear even if complex. Moreover, the authors propose relevant ablation studies and thorough evaluation against state-of-the-art methodologies. \n\nThe main weakness of this work is the mathematical proofs, particularly the one in Appendix. Specifically, the theorem in the main text is not quite precise, nor particularly intuitive. It is also not easy to connect with the provided proof (the comment following 3.1 is much more valuable). The notations (such as log vol) should also be introduced and simplified as much as possible. References to equations should be numbered, instead of \u2018the one with y_k\u2019, \u2018the one with d_t\u2019 which makes it difficult to follow.\n\nMinor updates that could improve the paper: \n- Displaying confidence in the tables (it is currently not clear if the results are significantly better)\n- Adding in Appendix a robustness metric, i.e. the difference in performance when trained in the same set and transferred. The performances should be computed on exactly the same test set.\n- Adding reference to graph convolutional network (also it is referenced once as 'graph convolution network'),\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clear introduction of the model with a well-motivated problem. While the model is complex, the authors did a good job of describing it in detail. Only the maths could be clarified.\n\nThe paper tackles the important problem of robustness when models are transferred between centres. The approach is an elegant solution to disentangle the centre-specific characteristics from the features predictive of the outcome of interest. \n\nNote on reproducibility: it is not mentioned if the data and code will be made publicly available, which may endanger the work reproducibility. As the trained model and data may disclose patients' data, I think only the model's code could and should be released due to the high model's complexity.",
            "summary_of_the_review": "Good paper, clear with great experimental and technical work. Would benefit from clearer proofs of the main theoretical result.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper160/Reviewer_kDRU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper160/Reviewer_kDRU"
        ]
    },
    {
        "id": "J_Vtq6y6zRB",
        "original": null,
        "number": 2,
        "cdate": 1666590502158,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590502158,
        "tmdate": 1666590502158,
        "tddate": null,
        "forum": "-HHJZlRpGb",
        "replyto": "-HHJZlRpGb",
        "invitation": "ICLR.cc/2023/Conference/Paper160/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this study, the authors proposed Domain Agnostic Representation Model (DarMo) based on variational auto encoder, a learning framework to disentangle disease-related features from domain-related (center-related) effects to achieve robust prediction. They claimed that their work is the first to prove the disentanglement is feasible and their model can achieve state-of-the-art performance in terms of robustness to distributional shift for breast cancer detection using a public (DDSM) and three in-house datasets. ",
            "strength_and_weaknesses": "Strength\n\u2022The authors implemented lots of prior works as baselines and evaluated their performances using the public and three in-house datasets to compare with their proposed model. \n\u2022The main problem they are interested in, causal relationships between domain, macroscopic, and microscopic dependent features, and their proposed model based on VAE are well described with appropriate example images, sufficient explanations, informative diagrams, and equations. \n\u2022They performed ablation studies to verify the effectiveness of each component in their DarMo, which helped the reviewer understand why each element is needed.\n\u2022They shared visualizations of reconstructions of latent variables to show that their proposed model learned disentangled features.\nWeakness\n\u2022Can you elaborate how the domain-aware BN layer is implemented? If there are 4 domains (centers), each center image is fed into each layer of DADI encoder (that means 4 channels)? Is the BN layer just the regular BN layer without modification? \n\u2022In Figure 3, the latent variables extracted from DADI encoder are just combined with the features extracted from DADR encoder to generate input images using \u201cmedical image decoder\u201d. The reviewer is not sure how the domain-aware disease-irrelevant features affect the classification of benign and malignant masses which is the main output of this model.\n\u2022Can the authors provide more details on how the four datasets are different in terms of domain effects including imaging acquisition, manufacturer, patient population, etc. It would be more interesting to see visualizations for each domain effect.\n\u2022Is the input data to the model a mammogram image or a patch of lesion region? Are the evaluation based on study level or image level? If all the results reported in this study are image-level, the reviewer would suggest that study-level results are better to be used for comparisons as study-level interpretation are usually needed in a clinical setting. \n\u2022In addition to the empirical results, it would be good to show an analysis on disentanglement using simplified datasets like different manufacturers including Hologic and GE machines. With DarMo, the domain-specific features (of each manufacturer) can be visualized and more informative to the potential reader. Visualization results shown in Figure 4 do not give the reader what domain-aware features are learned. \n\u2022The reviewer might miss it, but did the authors evaluate performance of conventional CNNs (like ResNet50) as results shown in Table 1? Also, it would be good to show performance of model trained on all datasets (InH1+InH2+InH3+DDSM) and evaluated on each dataset. If their proposed model performance is comparable or superior to it, it would be nice to demonstrate the robustness of the proposed model to distributional shift. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Their idea of learning disentangled features in terms of domain effects is interesting enough for the potential reader. Also, they showed results from the prior works by training and testing on their datasets. But, with more experiments suggested above, their claim can be more strengthened.",
            "summary_of_the_review": "In general, their work and claim are well explained and verified with experimental results, ablation studies, and visualizations. However, some additional experiments might be needed to improve the quality of their study. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper160/Reviewer_RBtC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper160/Reviewer_RBtC"
        ]
    },
    {
        "id": "Fqbxg0V0ud",
        "original": null,
        "number": 3,
        "cdate": 1666745248802,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666745248802,
        "tmdate": 1666745248802,
        "tddate": null,
        "forum": "-HHJZlRpGb",
        "replyto": "-HHJZlRpGb",
        "invitation": "ICLR.cc/2023/Conference/Paper160/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a model DarMo to disentangle disease-related features from domain-related effects to achieve robust prediction in the healthcare domain. \nThe proposed model is guided by structural causal modeling to explicitly model disease-related and center effects. \nExperiments on four real-world datasets demonstrate the effectiveness of DarMo.\n",
            "strength_and_weaknesses": "S1: The methodology part is written in a clear way and well addressed the main claims in the introduction part. \n\nS2: It is an interesting idea to apply structural causal modeling to encode medical\nprior knowledge and to disentangle disease-related features from the domain effect.\n\n\nW1: It is better to provide complexity analysis. On top of accuracy and AUC, time efficiency should be considered in practical application.\n\nW2: It is better to involve more components, e.g., loss functions, in Section 3.2 to make it clearer.\n\nW3: Sun et al., 2021a is duplicated.\n\nW4: The source codes are not available to validate the experimental results.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is well organized. Most parts of the paper are written in a clear way. \n\nQuality: The quality of the paper can be further improved. \n\nNovelty: The novelty is fair. \n\nOriginality: Good. \n\nReproducibility: There is not source codes provided.\n",
            "summary_of_the_review": "Above the acceptance threshold. \nPlease see Strength And Weaknesses for detail.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper160/Reviewer_eNnv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper160/Reviewer_eNnv"
        ]
    }
]