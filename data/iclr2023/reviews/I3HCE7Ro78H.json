[
    {
        "id": "gxqVuUZJpC",
        "original": null,
        "number": 1,
        "cdate": 1666101194708,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666101194708,
        "tmdate": 1668806442178,
        "tddate": null,
        "forum": "I3HCE7Ro78H",
        "replyto": "I3HCE7Ro78H",
        "invitation": "ICLR.cc/2023/Conference/Paper6599/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors point out that the interpretation of Danskin's Theorem that was used to motivate the Adversarial Training paradigm in the seminal paper from Madry et al. (2018) relies on a misunderstanding of the notion of directional derivative employed in the theorem. As a consequence, PGD, the most commonly employed adversarial training scheme, might not follow descent directions. The authors present a solution to this, assuming finitely-many global optimizers of the inner maximization, and show that it helps in practice in setttings where Danksin's Theorem would hold.",
            "strength_and_weaknesses": "The authors raise awareness about a mistaken interpretation of Danskin's Theorem when motivating adversarial training, and demonstrate its relevance through counter-examples and empirical evidence. A solution to this problem is presented (DDD), and its relative effectiveness on smooth networks (without BatchNorm) is shown. \nAt this stage, the contribution is purely technical: the practical relevance of the presented method is limited because of its inferior performance in the setting that attains the maximal robust accuracy (ReLU + BatchNorm). Furthermore, DDD greatly increases the runtime per iteration, making its practical employability limited.\nNevertheless, I believe the findings to be of great interest to the community. \n\nIn my opinion, the strength of the paper could benefit if the authors addressed the following limitations:\n- Typically, in the context of adversarial training, the inner maximization is not run to convergence. Indeed, this holds also for the presented experiments. Therefore, DDD is not guaranteed to yield a descent direction for the robust loss even when the conditions of Danksin's Theorem hold. It would be important for the authors to comment on why DDD helps in this setting. Indeed, getting to a guaranteed global optimum of the inner maximization would require running a complete verification algorithm based on Branch and Bound (it would be nice if the authors touched on this, and mentioned relevant methods in the literature). \n- Practical limitations (in practice the overall best-performing method remains PGD) should be stated in intro and abstract (as the authors do in the conclusions) . The statement on the early stages should be limited to the smooth setup (the difference in Figure 4b seems to be too small to be statistically reliable).\n\nAs a minor point: why not Frank-Wolfe for the smooth simplex-constrained optimization problem that arises from DDD?\nFinally, the fact that the inner maximization in AT is not run to global optimality would be visibile if the authors provided a magnified version of the high-loss region of Figure 2.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, the content is well-presented and organized. To the best of my knowledge, the problem the authors point out is not well-known in the adversarial training literature, for which the presented solution is novel.",
            "summary_of_the_review": "The authors point out an interesting problem in the adversarial training literature: while the practical effectiveness of the presented method is limited at best, and the presented solution is never used in the setting for which it is motivated (the inner maximization is never run to convergence, as that would require running formal neural network verification), I believe the paper is a first step towards more principled adversarial training algorithms.\nNevertheless, the authors should be more direct about the limitations of the proposed solution and its empirical relevance, from the beginning of the paper. I will be willing to increase my score after this and the other weaknesses I pointed out are addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_wzJU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_wzJU"
        ]
    },
    {
        "id": "o1sO26Ek0A",
        "original": null,
        "number": 2,
        "cdate": 1666656301899,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656301899,
        "tmdate": 1668448772148,
        "tddate": null,
        "forum": "I3HCE7Ro78H",
        "replyto": "I3HCE7Ro78H",
        "invitation": "ICLR.cc/2023/Conference/Paper6599/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The starting point for this paper is the observation that one of the key theorems in (Madry et al., 2018) is incorrect.  In particular, the authors show that the interpretation of Danskin's theorem in (Madry et al., 2018) uses the incorrect form of the directional derivative.  They provide several counterexamples to demonstrate this flaw, which yield interesting insights on the problem of adversarial training.\n\nBased on these observations, the authors propose Danskin's Descent Direction (DDD), an algorithm that is designed to solve the standard minimax formulation of adversarial training.  They show that their method is more stable than PGD on several benchmarks, although the empirical gains are somewhat modest at convergence.  ",
            "strength_and_weaknesses": "### Strengths\n\n**Soundness.**  This paper seems to be technically quite sound.  It is certainly the most rigorous paper that I have reviewed in my batch of papers this year at ICLR.  The analysis of Danskin's theorem and of the result in (Madry et al., 2018) appears to be correct, which indeed calls into question one of the foundational assumptions underpinning adversarial training.  \n\nThe counterexamples shed new light on the problem as well.  I particularly appreciated the fact that after disproving the theorem from (Madry et al., 2018), the authors took it one step forward.  They ask: In the case when I'm not at a locally optimal point, is the result of (Madry et al., 2018) still incorrect.  And via a more intricate, although still pleasingly elementary, construction, they show that another counterexample exists.  This is thorough work, and I believe that it should be commended.\n\n**Algorithm.**  The algorithm proposed by the authors seemed relatively natural.  While it is clearly up for debate whether the set of maximizers is finite, I think it's not an unreasonable assumption to make.  And the authors provide some nice empirical evidence that at the very least, the set is not a singleton.  Given this, Thm. 2 makes sense given the context of the paper, and it leads to a relatively practical algorithm.  Nice!\n\n**Well written.**  This paper is relatively well written.  The related work was thorough.  And in general, the logic and flow of the paper was solid.  I really enjoyed reading it!\n\n### Weaknesses\n\n**Minor inconsistencies in notation.**  One point of confusion: if $\\delta\\in\\mathbb{R}^p$, then $\\mathcal{S}\\subset\\mathbb{R}^p$ in (1).  In (2), we have $\\delta_i\\in\\mathbb{R}^p$, and therefore $\\delta$ seems to be an element of $\\mathbb{R}^{p\\times k}$, meaning that $\\mathcal{S}\\subset \\mathbb{R}^{p\\times k}$ (or perhaps of $\\mathbb{R}^{pk}$).  This is a bit inconsistent, as it would be nice to think of $\\mathcal{S}$ as belonging to a particular space.\n\n**Confusing presentation of the key theorem.**  One key step of this paper is to present the theorem of (Madry et al., 2018), which is done in Corollary 1.  Before presenting this result, the authors say that\n\n> \"Corollary 1 is an equivalent rephrasing of Madry et al. (2018, Corollary C.2.), and is derived as a consequence of Theorem 1. \n Unfortunately counterexample 1 shows that it is false:\"\n\nLet Thm. 1 (Danskin's theorem) be A and let Cor. 1 be B.  Based on my reading, this sentence says that A implies B, since \"derived\" (to me) means \"correctly derived.\"  The authors then say that B is false.  By the contrapositive, this would imply that A is false.  Based on the rest of the paper, I know that this is not what the authors are trying to say.  So I would suggest rewording this part to emphasize that A does not imply B, as some readers may get confused by this point, and that is quite undesirable given that this is one of the most important points in the paper.\n\nI would also recommend defining a \"descent direction\" before it is mentioned in Cor. 1.  This would make it easier to understand the result in Cor. 1 without having to read on until a later section.  \n\n**A minor recommendation.**  I would recommend removing the phrase: \"a basic concept in multivariable calculus.\"  This may only be my opinion, but I feel that this phrase may be perceived by some readers as a little bit disrespectful to (Madry et al., 2018), especially given that (Madry et al., 2018) is a relatively influential paper.  Yes, this idea is often introduced in a college-level calculus course.  But it took until now for anyone to notice this subtle distinction. \n\n**Explain Madry et al.'s results in more detail.**  I think it's well worth spending more time on the results of the original paper.  The discussion at the bottom of page 3 is relatively terse.  In particular, I believe that it would be beneficial for the authors to expand on the sentence:\n\n> \"However, we cannot guarantee that the function will decrease if we move in the opposite direction...\"\n\nDuring my first pass through the paper, I didn't understand this part.  Underscoring the fact that Madry et al. assume that $D_\\gamma \\phi(\\theta) > 0$ *implies that* $D_{-\\gamma} \\phi(\\theta) < 0$ is essential here, because it is at the heart of why the original result was not correct.  It may be worth proving that for the two-sided directional derivative, this property does hold.  Although elementary, I think this would help build intuition for the reader.\n\n**Oracle?**  I didn't understand what the authors meant by a \"heuristic oracle.\"  The word \"heuristic\" seems to defeat the purpose of an oracle.  Could the authors explain more here?\n\n**Computation time.**  A downside of the proposed method is obviously the computation time.  It seems clear that at convergence, DDD doesn't offer a significant improvement over PGD given that it seems to get 10x more steps.  I may have missed this, but did the authors compare PGD-100 to DDD-10, which would constitute a comparison where each algorithm got roughly the same computational budget?",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.**  The paper was easy to read.\n\n**Quality.**  The results were technically sound, and the experiments were thorough.\n\n**Novelty.**  The algorithm seems novel, and this work offers a fresh perspective on adversarial training.  \n\n**Reproducibility.**  This seems relatively easy to reproduce based on the details given in the paper.",
            "summary_of_the_review": "Overall, I thought this was a really solid paper.  It makes some interesting insights, and the result is an algorithm that seems to have some nice empirical properties.  There are a few drawbacks, such as the increased computation time.  Most of the weaknesses listed above are relatively minor.  Therefore, I think this paper should be accepted.\n\n---\n\n**Post rebuttal comments.**  The authors have addressed each of my concerns.  Therefore, I will raise my score, as I believe that the additional clarifications and theoretical results improve the paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_FpN3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_FpN3"
        ]
    },
    {
        "id": "lEro0UqyznM",
        "original": null,
        "number": 3,
        "cdate": 1666719174742,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666719174742,
        "tmdate": 1666719174742,
        "tddate": null,
        "forum": "I3HCE7Ro78H",
        "replyto": "I3HCE7Ro78H",
        "invitation": "ICLR.cc/2023/Conference/Paper6599/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper points out an issue in a recent theoretical result that motivates the adversarial training algorithm. The authors construct counter examples and provide explanations about the issue they identify, and then further propose a Danskin's Descent Direction for training robust neural networks.",
            "strength_and_weaknesses": "Strengths: \n\nThe claims of the paper seem solid, and the paper is well written. \n\nThe proposed method is backed up by experiments.\n\nWeaknesses: \n\nTheorem 2 is based on the assumption that the set of optimal adversarial perturbations is finite. This is a strong and sometimes unrealistic assumption.\n\nAccording to the authors' discussion, it seems that Madry et al. (2018, Corollary C.2) could be made rigorous by adding an assumption such as \"$\\phi(\\theta)$ is differentiable at $\\theta$\". Even with this additional assumption, this result seems sufficient to motivate the adversarial training algorithm. \n\nBecause of the above reasons, the advantage of the proposed DDD method over the adversarial training method is not very clear. After all, the theoretical guarantee for the proposed DDD method (Theorem 2) is also based on an unrealistic assumption. The DDD method also seems to be computationally more expensive than adversarial training. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly and the results are novel.",
            "summary_of_the_review": "This paper points out an important issue in adversarial training. The paper is well written and the claims seem solid. However, the proposed method is still questionable and more justification is needed to demonstrate its advantage over existing methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_UVpf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_UVpf"
        ]
    },
    {
        "id": "FuXQN3OwFn_",
        "original": null,
        "number": 4,
        "cdate": 1666997263676,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666997263676,
        "tmdate": 1666997263676,
        "tddate": null,
        "forum": "I3HCE7Ro78H",
        "replyto": "I3HCE7Ro78H",
        "invitation": "ICLR.cc/2023/Conference/Paper6599/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper pays attention to the computation of adversarial training, by pointing out that even in the simple case (nonsmooth), the descent direction is not given by the worst-case perturbation, as opposed to common practice in the AT community. The paper then proposes a method that, under the assumption of a finite number of worst-case perturbations, computes the correct descent direction. ",
            "strength_and_weaknesses": "Strength:\n\nI appreciate the conceptual idea of this paper a lot. The starting point of the paper is the observation that the descent direction not necessarily corresponds to the worst-case perturbation. Given the fact that this is typically assumed always be the case in the AT community, this paper has provided a refreshing perspective on how should we do AT correctly. The constructed counterexamples are also easy to understand. \n\nWeakness:\n\nThe potential downside of this paper is that the proposed method (DDD) is inherently computationally expensive. As the authors advocate the usage of multiple worst-case perturbations, adopting DDD would require at least several times of computational effort compared to the already expensive standard AT procedure. \n\nAnother concern that I have is the similar final performance achieved by both AT and DDD. It seems that their performance differs by some margin only in the initial stage of the training, but is getting much closer to the final stage. This to some extent, has limited the potential practical impact of the proposed method. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: \nThe paper is very well written. Delivers a simple yet interesting observation clearly. The observation is to the best of my knowledge novel in the literature of AT. \n\nClarity: \nThe paper is well organized. The constructive counter-examples are well explained and the authors have done a good job maintaining their simplicity. \n\nOriginality: The main claim and the proposed methods are novel. I appreciate the paper being bold and challenging the mainstream practices. ",
            "summary_of_the_review": "This paper focuses on the bring forward the issue that (a single) adversarial example might not give the descent direction, challenging a common belief adopted in the practice of this field. It did this with simple examples making its arguments. This is the strongest point of this paper. The proposed method, on the other hand, is computationally expensive compared to the original AT, and the final performance is comparable to AT, which is to some extent surprising given the fact that AT is supposedly not a correct method, the main theoretical claim made by this paper. The practical side of the claim and method proposed in this paper seems a little bit limited by its current shape. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_gFkW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6599/Reviewer_gFkW"
        ]
    }
]