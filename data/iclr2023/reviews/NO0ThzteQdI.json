[
    {
        "id": "rJG6j0OnGcT",
        "original": null,
        "number": 1,
        "cdate": 1665838185200,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665838185200,
        "tmdate": 1666598144448,
        "tddate": null,
        "forum": "NO0ThzteQdI",
        "replyto": "NO0ThzteQdI",
        "invitation": "ICLR.cc/2023/Conference/Paper2211/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a method for real image denoising. Specifically, it firstly estimates Gaussian and Poisson noise parameters. Then, it learns a style encoder to map a raw image into rgb one. In this way, it can synthesize noisy-clean image pairs to train the denoising network. The provided experiments show the proposed method performs better than existing methods.",
            "strength_and_weaknesses": "Strength:\nThe provided experimental results show it outperforms better than other methods.\n\nWeaknesses:\n1. Even though Table 1 shows the proposed method can estimate noise parameters accurately and Figure 7 shows downscaling with blurring can make the variance difference between clean and noisy image closer, there lacks theoretical proof why the proposed method can accurately estimate noise parameters and analyzing the possible deviations in the proposed method. According to Figure 7, the variance of noisy images is still higher than clean ones. In this way, the estimated noise parameters based on Eq. 3 should be smaller.\n2. In Figure 7, why will downsampling the clean image without blurring not change the variance of the image obviously? What is the downsampling method used? Why will downsampling 2 times have a smaller variance in (a) and (c)?\n3. It is not clear whether the noise parameters are estimated for every image or for the whole dataset. According to my understanding, the proposed method estimates fixed Gaussian and Poisson parameters for the whole dataset. This is not correct. Since these parameters depend on the sensor gain or ISO. In this way, the experiment in Table 1 seems unfair. Since other methods estimate noise level image by image while the proposed one estimates it according to the whole dataset.\n4. Also, using reparameterization to estimate noise parameters may be too complicated. Why not directly search all possible Gaussian and Poisson parameters and find the settings to minimize Eq. 3?\n5. It seems the blur kernel and downsampling rate are important for the noise level estimation. Can the authors demonstrate how the proposed method selects the settings? More experiments are needed.\n6. For isp estimation, the proposed method seems to use spatially-invariant linear operators. It may be not that accurate. In the camera isp, the processing is spatially variant e.g. lens shading, local tone mapping, contrast enhancement, etc. In addition, the number of parameters in camera isp is much larger than 3 which is the number of style parameters in the proposed method. I want to know the accuracy of the generated rgb images compared with the ground truth.",
            "clarity,_quality,_novelty_and_reproducibility": "There are many concerns in the novelty of the proposed method. Please see the weaknesses above.",
            "summary_of_the_review": "Even though the provided experimental results are better than other methods, there exist plenty of concerns regarding noise level estimation as well as isp estimation. The authors should address them completely.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_nCCv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_nCCv"
        ]
    },
    {
        "id": "WceNzqVbkAF",
        "original": null,
        "number": 2,
        "cdate": 1666549317772,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549317772,
        "tmdate": 1668849956508,
        "tddate": null,
        "forum": "NO0ThzteQdI",
        "replyto": "NO0ThzteQdI",
        "invitation": "ICLR.cc/2023/Conference/Paper2211/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel method for training image denoising techniques, called NERDS.  The paper makes the observation that a noisy image can be downsampled to produce a pseudo-clean image, as the downsampling operation removes noise.  Based on the noise statistics between the psudeo-clean image and the original image, a noise model can be estimated in a learnable way using a reparametrization trick.  The paper also models the \u201cblack box\u201d of an ISP disentangling style, and thereby is able to generate large amounts noisy/pseudo-clean pairs using the model and data augmentation.  These pairs are then used for training denoising methods like DnCNN.  Experimental results show the method outperforms state of the art methods.",
            "strength_and_weaknesses": "Denoising of images is a fundamental problem in computer vision and has seen considerable attention in the last decade particularly with the advent of deep learning.  However, as argued by the paper, supervised methods require paired noisy/clean data which is difficult to obtain.  The paper addresses this problem in an appealing way by only requiring noisy images \u2013 which are easily acquired.  A clean counterpart isn\u2019t needed, which greatly simplifies data collection for training a denoiser.  This approach is used to synthesize noisy RGB images.\n\nStrengths:\n\n1.\tThe paper\u2019s approach that only requires noisy RGB images as input.  This is appealing as capturing paired data often involves tedious work.  The method is able to produce noisy RGB images for RGB denoisers.  This reviewer appreciates the approach of trying to generate pairs from noisy images. \n\n2.\tThe reparametrization trick to estimate the noise parameters, while simple, was interesting and something new for this reviewer.  This could be relevant for other researchers working in noise modelling and estimation. \n\n\n3.\tThe modelling of the ISP, whilst not entirely new, was useful in this paper to produce noisy RGB images for training an RGB denoiser.  The disentangling of style was appreciated by this reviewer.\n\n4.\tThe experimental results compare the method to a variety of recent methods, with the method producing convincing results.  \n\nWeaknesses:\n\n1.\tThis reviewer is concerned about the downsampling technique to create \u201cclean\u201d images.  Clearly the images aren\u2019t clean \u2013 for example in Figure 1, the \u201cclean\u201d image in part (d) is much noisier than the clean image in part (a) of the figure.  So there is remaining noise after downsampling.  The paper doesn\u2019t really discuss this issue, although the supplementary material provides some context.  Downsampling can\u2019t remove the image noise because it applies a low pass filter (averaging filter) to the data.  So the noise is reduced through the averaging, but not removed.  Therefore, this reviewer would prefer if the in the main paper, instead of calling it a \u201cclean\u201d image, the downsampled image was called a \u201cpseudo-clean\u201d image as done in the supplementary.  More importantly, it would be helpful if the paper could comment on the impact of this remaining noise in the downsampled image \u2013 does it impact the results negatively?  Would downsampling by a factor of 4 help more than by a factor of 2?  This reviewer was somewhat surprised to see the results in Table 1, it does appear NERDS can produce a good fit despite the remaining noise.  Perhaps the author rebuttal could comment on this point. \n\n2.\tNoise is harder to remove in the RGB domain than the RAW domain as the statistics are simpler in the RAW domain before the noise becomes more spatially correlated due to demosacing and other operations.  Why develop a denoiser to run in the RGB domain? Conceivably the method could be used to denoise in the RAW domain.  Relatedly, it could be interesting to compare the approach to the Brooks et al. paper from CVPR 2019.\n\n\n3.\tThe reviewer is also worried about the domain gap between a \u201cblack box\u201d ISP and the ISP that is used in the paper.  Clearly there may be a domain gap as the ISP used in the paper is only an approximation to a \u201cblack box\u201d ISP.  Does this domain gap cause any limitations in the method?  Perhaps the proposed method does not generalize well to some phone models.\n\n4.\tWhy call it NERDS?  Is this an acronym for something?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Generally the paper is clearly written and of good quality.  There are some small issues listed below.  \n\nThe main originality comes from the noise modelling approach through downsampling and noise model fitting.  This appears to be a good advance although the reviewer has some concerns about remaining noise articulated above.\n\nIt wasn\u2019t clear if code will be released should the paper be accepted.  Perhaps the author rebuttal could comment on this.\n\nSmaller issues: \n\n\u2022\tFigure 1 caption, extra period, please remove\n\n\u2022\tPage 2, please replace \u201can other\u201d to \u201canother\u201d\n\n\n\u2022\tPage 2, footnote, please replace \u201cSonny\u201d with \u201cSony\u201d\n\n\u2022\tPage 3, please replace \u201cRELATED WORKS\u201d with \u201cRELATED WORK\u201d as work is already plural\n\n\n\u2022\tPage 2, please replace \u201ctest noises\u201d with \u201ctest noise\u201d as noise is not countable.  This issue is also on Page 4, \u201cunseen noises\u201d with \u201cunseen noise\u201d; Page 6 \u201clearning noises\u201d with \u201clearning noise\u201d\n\n\u2022\tPage 4, it\u2019s true modern smartphones provide multiple image styles; note however these can be applied even without user edits.  The camera will recognise the scene (e.g. beach) and optimise the ISP for that scene.  Therefore the qualifier \u201cwith user edits\u201d is not needed. \n\n\n\u2022\tWhy are the results so poor for SCUNet in Table 2?\n",
            "summary_of_the_review": "In summary, this paper is addressing a fundamental computer vision problem of removing noise from captured images.  It brings some new ideas in terms of how to model the noise from a noisy image.  Whilst the formulation might not be perfect, it provides a practical approximate way to estimate the noise which is appealing as it can be used to generate noisy/clean pairs for image denoising.  The results are appealing as the method outperforms papers recently appearing in the literature.  Overall I think the paper has merit but it\u2019s let down a bit by overstating assumptions and remaining gaps (e.g. residual noise in the \u201cclean\u201d image, differences between real and \u201cblackbox\u201d ISPs).  Still this reviewer believes there are some interesting ideas here.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_2oSJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_2oSJ"
        ]
    },
    {
        "id": "MpIhbKzHC0",
        "original": null,
        "number": 3,
        "cdate": 1666585259510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585259510,
        "tmdate": 1669656800461,
        "tddate": null,
        "forum": "NO0ThzteQdI",
        "replyto": "NO0ThzteQdI",
        "invitation": "ICLR.cc/2023/Conference/Paper2211/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper a learning-based camera denoising framework is introduced. Noisy raw/RGB image pairs are used for training, while the method takes a noisy RGB image only at test time for denoising. The authors designed a framework that models the raw sensor noise and ISP transformed noise separately. \n\nInstead of relying on paired noisy/clean images for training, the authors exploited the use of image downsampling and optimization-based noise estimation and synthesis to create pseudo noisy/clean image pairs at lower resolution, purely from noisy images. For estimating the Poisson-Gaussian coefficients for the raw sensor noise, a re-parameterization trick is applied and an optimization problem is solved such that the pixel variances can match between synthesized low-res noisy image and the original full-res noisy input. While P-G parameters are often provided by camera manufacturers in metadata, they may not be accurate and the authors proved that the proposed approach leads to more accurate estimation than prior arts. \n\nFor the RAW2RGB conversion, this ISP process is posed as a style transfer problem, where the style is learned from the raw-RGB noisy image pair (at original resolution) and is used to convert the raw image to RGB.  \n\nOnce the P-G model (N) and RAW2RGB conversion network T are determined, a given denoiser network can be trained on the synthesized low-res noisy/clean image pairs with a number of data augmentation tricks. The overall objective function can be seen in Eq (8).\n\nThorough qualitative, quantitive, as well as ablation studies have been conducted on various datasets, demonstrating the effectiveness of the framework, and justifying the design decisions.  \n\n",
            "strength_and_weaknesses": "Strength:\n- Creative way of synthesizing raw noisy/clean image pairs based on the observation that true image texture is more robust to pixel variance through downscaling than real noises. \n- Poses the ISP estimation as a style encoding and transfer problem. This, in combination with the innovation above, greatly relax the dataset requirements on real noisy/clean image pairs, ISPs, metadata etc. which are not always available or accurate especially at test time. \n- While key proposals such as pseudo clean image generation via downsampling may seem to be empirical, the authors made an attempt to justify this with data. The ablation study also seems adequate. \n- NERDS outperforms previous works with simpler denoiser network, demonstrating the effectiveness of the noisy/clean image pair synthesis, style disentanglement-based ISP estimation, as well as the rich data augmentation. \n\nWeaknesses:\n- The work still relies on raw/RGB noisy image pairs for training, although only RGB noisy image is required for denoising at test time. I would recommend that the authors rethink the title, \"NERDS: A GENERAL FRAMEWORK TO TRAIN CAMERA DENOISERS FROM SINGLE NOISY IMAGES\", as the claim on training from single noisy images may be ambiguous and potentially misleading (it actually requires both raw and RGB noisy images for training and testing ideally, thus the \"s\" in \"images\"). \n- While the authors have made an attempt to explain why the pseudo clean image (with residual noises) works in practice due to various observations / hypothesis, it may add more insights if ablation study can be conducted to assess the relative contribution from factors such as blurring strengths, downscaling factor, augmentation for noise parameter, scale/intensity, and style etc.\n- Although it is claimed by the authors that PG parameters in metadata may not be accurate, and that NERDS-raw does a better job, the audience may still appreciate more justification on this. For example, what is the impact of inaccurate PG parameters on the overall RGB denoiser performance? \n- On reproducibility, it would be helpful if the authors could clarify if the PG optimization, ISP network T training, and denoiser D training are done subsequently or jointly.  \n- I recommend that the authors consider referencing the supplementary material in the main paper, as the audience may walk away with many questions just by reading the main paper only. ",
            "clarity,_quality,_novelty_and_reproducibility": "The reviewer would like to appreciate the quality and novelty of this paper. \n\nOn clarity and reproducibility:\n- See my comments in the previous question on optimization / model training procedure. \n- One question that remains is the modern ISPs may contain denoising block. As the RAW2RGB process is learned from real noisy raw/RGB image pairs, it is possible that some degree of denoising is already learned implicitly in T, which potentially may impact the denoising strength of D. \n- Generalizability: please clarify if at test time, D needs to be fine-tuned / retrained for device specific noise levels and ISPs. Based on Sec A.1.3 it looks like this is required and time-consuming to get the best denoising performance, meaning that we will also need to access the noisy RGB/raw image pair at test time training. If so, please clarify if the comparison in table 2 was done fairly, i.e. did the other methods have access to training set at test time? \n\n\n",
            "summary_of_the_review": "While minor clarity issues remain, NERDS is a novel and effective framework for camera denoising. The main drawback (and overselling) though, seems to be the claim on requiring single noisy images only -- in practice, both the raw and RGB noisy images are required to get the best performance out of the denoiser. Please consider making the problem setting and contribution more concrete and transparent. Please also consider referencing some key justifications in the supplementary material from the main paper, as the readers may otherwise believe some design decisions lack sufficient justification (empirical, theoretic). As such, I recommend a borderline accept (6) for the work, and lean towards score 7 if these can be addressed in the revision. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_aUMk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_aUMk"
        ]
    },
    {
        "id": "HOamr7gvfP3",
        "original": null,
        "number": 4,
        "cdate": 1666605811335,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605811335,
        "tmdate": 1669393786006,
        "tddate": null,
        "forum": "NO0ThzteQdI",
        "replyto": "NO0ThzteQdI",
        "invitation": "ICLR.cc/2023/Conference/Paper2211/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes and evaluates a training method for neural network-based image denoising when raw images and corresponding processed (e.g. demosaiced) rgb images are available. It leverages the known observation that SNR increases when spatially downscaling an image, and thus realistic low and high-noise images can be generated at lower resolution. The method consists of several carefully chosen ingredients, e.g. (1) a scheme for estimating parameters of a Poisson-Gaussian noise model on raw images, (2) a scheme for estimating parameters of a signal processing pipeline converting raw to rgb, (3) augmentations using the estimated parameters, (4) supervised training on noisy/clean low-resolution rgb image pairs simulated from raw images. The method is evaluated for two different neural networks and compared to sota methods that have not been trained or real (hard to get) noisy/clean images. In this comparison the proposed method performs preferably.",
            "strength_and_weaknesses": "Strengths of the paper are in the well-designed, easy to understand ingredients of the method and the improved denoising performance wrt. competitors. It is overall well-structured and presents clear experiments. It also provides a rich overview on related work.\n\nMain weaknesses are language issues that sometimes lead to unclear train of thoughts within sentences or paragraphs (see examples below).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Minor hiccups in argumentation exist, e.g.\nP6L19 claims \u2018To avoid learning identity mapping from the input y to the output \\hat{y}, we first adopt image scale augmentation (SA) that changes the image resolution.\u2019 Comparing Figure 4, there is no path from y to \\hat{y} allowing to learn identity, even without SA. The next sentence then claims \u2018[\u2026] SA randomly samples the scaling factor to prevent the encoder from learning noises\u2019. It should be written clearly, for what purpose SA has been introduced and it would be informative to see, if performance of the method really drops when removing it.\n\nClarity is mainly reduced due to language issues. E.g. the paper frequently violates the rule that the definite article (the) is used before a noun to indicate that the identity of the noun is known to the reader or before unique nouns. It is somewhat distracting, when this rule is not kept, as it leads the reader to consider if they overlooked a previous mentioning.\nOther examples of language issues, notation:\n\nP1L5: \u2018Intuitively, downscaling easily removes high-frequency noises than natural textures.\u2019 The word \u2018more\u2019 is missing, allowing to use comparison by \u2018than\u2019: \u2018Intuitively, downscaling removes high-frequency noise more easily than natural textures.\u2019 Same on P5L16: \u2018This phenomenon indicates that the true signal z is robust to the pixel variances through downscaling than real noises.\u2019\n\nP1L-10: \u2018The first line of works synthesizes the realistic noise from clean images [\u2026]\u2019. It remains unclear, how noise can be synthesized from clean images, and if this is really meant. Presumably noisy images are generated, where the noise not necessarily depends on the clean image.\n\nP1L15: \u2018synthetic raw images\u2019: no synthetic raw images are used in the paper. Only rgb images are simulated.\nP5, paragraph \u2018Optimization\u2019: the notation $a \\times e^y$ is unusual. Either use $ae^y$ or $a \\times 10^y$ .\n\nNovelty: The noise parameter estimation, as well as the estimation of the raw2rgb converter are new, the underlying models are not but this is also not claimed. Using down-sampling for noise reduction in order to then add noise to produce noisy/clean image pairs seems to be new. All simple but effective. However, the observation, that down-sampling increases SNR is not new and obvious in Fourier space, as high-frequency regions have lower SNR in typical images. This observation should therefore be presented less pronounced.\n\nReproducibility: While the method is clear overall, details of implementation are not. Especially exact network architectures remain unclear. A table, figure, or code would help.\n\nResults in Tables 2 and 3 seem to be inconsistent, as numbers presented for NERDS+D in SIDD (with full augmentation in Table 3) are different.\n\n",
            "summary_of_the_review": "Overall a paper with merits due to its simple but novel and effective content. However, it suffers from language issues. This brings the paper well into the range of being acceptable, but keeps it from being a \u2018good paper\u2019 overall. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_HZ4f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2211/Reviewer_HZ4f"
        ]
    }
]