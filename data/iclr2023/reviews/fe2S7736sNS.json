[
    {
        "id": "iooYfnqXjZ",
        "original": null,
        "number": 1,
        "cdate": 1666662944864,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662944864,
        "tmdate": 1666662944864,
        "tddate": null,
        "forum": "fe2S7736sNS",
        "replyto": "fe2S7736sNS",
        "invitation": "ICLR.cc/2023/Conference/Paper4546/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes kNN prompting, a novel retrieval-based model for more accurate inference accuracy. kNN prompting queries LLM with the training data and get the representation as anchors. In the prediction phase, kNN prompting only performs nearest neighbor for a better accruacy.",
            "strength_and_weaknesses": "The kNN prompting idea is novel. It aligns with the retrieval philosophy that we can make full use of the trained large language models for a better inference. The strength can be summarized as follows:\n\n1. The kNN prompting is a gradient-free paradigm for deploying LLM.\n\n2. The kNN prompting integrates the idea of the nearest neighbor in the inference of LLM, improving the LLM performance without further tuning.\n\n3. The empirical results are promising, especially for long sequences. ",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty: the major novelty of this paper is the proposal of kNN style inference over the representations of the training data. It opens an interesting direction for the efficient deployment of LLM.\n\nQuality: this paper is well-organized and well-presented, with a clear introduction to the kNN prompting.\n",
            "summary_of_the_review": "This paper proposes a novel idea for deploying large-scale LLM in practice. This paper is also well-written with clear illustration of kNN prompting.  The empirical evaluation also suggest the strength of kNN prompting in long sequences.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_SRJJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_SRJJ"
        ]
    },
    {
        "id": "L8rc7db9kIm",
        "original": null,
        "number": 2,
        "cdate": 1666734294807,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666734294807,
        "tmdate": 1666734294807,
        "tddate": null,
        "forum": "fe2S7736sNS",
        "replyto": "fe2S7736sNS",
        "invitation": "ICLR.cc/2023/Conference/Paper4546/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In-context Learning (ICL) is one of the most prevailing paradigms for inference with large language models (LLM) without parameter update. However, as the sizes of context windows are limited for LLMs, only a small number of training examples can be used for prompting, preventing ICL from scaling to larger training set. To overcome this bottleneck, this paper proposed a new method for LLM inference with no parameter update called kNN prompting: unlike ICL, where labels are directly predicted based on next-token distribution, kNN prompting make predictions by leveraging/retrieving training examples (when available) that share similar next-token distributions with the test example. Empirical results show that kNN prompting not only scales effectively as the number of training examples increase but also outperforms vanilla ICL on some datasets in the few-shot setting. Moreover, when a relatively large training set is available, kNN prompting even outperforms the (relatively smaller) fine-tuned models as the number of parameters of LLMs exceed a certain threshold (6B). To summarize, this paper proposed a simple yet effective way of scaling LLMs inference to large training sets with no parameter update.\n",
            "strength_and_weaknesses": "Strengths:\nkNN prompting is a simple yet very effective approach for scaling LLMs inference to large training sets; comprehensive ablation study demonstrates the robustness of the approach across different choices of hyper parameters (k) and random seeds. \n\nWeaknesses:\nThe discussion (Sec. 4.3.5) on why kNN prompting outperforms vanilla ICL in a few-shot setting is very interesting: it seems to suggest that kNN prompting is implicitly solving the issue of \u201csurface form competition\u201d where some answers have higher probabilities in the prior distribution of LLM. I wonder how kNN prompting compares against to other calibration techniques [3] that solves the same problem.\n\nIn terms of novelty, the method itself is more of a variation of the methods proposed in prior works that retrieve extra data via kNN to help model inference [1, 2].\n\n[1] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generalization through memorization: Nearest neighbor language models. In International Conference on Learn- ing Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.\n[2] Weijia Shi, Julian Michael, Suchin Gururangan, and Luke Zettlemoyer. Nearest neighbor zero-shot inference. arXiv preprint arXiv:2205.13792, 2022.\n[3] Min, Sewon, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. \"Noisy channel language model prompting for few-shot text classification.\" arXiv preprint arXiv:2108.04106 (2021).\n",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of presentations, the paper is overall well-written except:\n\n1. In Table 2, the results for MPQA with m=32 are the exactly same for ICL and kNN prompting; such typos also appear in other parts of the table.\n\n2. The notations introduced in Section 3, which is used throughout the paper, are heavier than need and could be further simplified: for example, the authors may want to remove \\theta from the formulation and the subscripts are a little bit messy.\n\nThe authors provide enough details of experiments for reproducing the results.",
            "summary_of_the_review": "Overall this is a good paper that proposes a simple and elegant approach with strong empirical results. The only weakness is the limited novelty of the methodology itself; to provide more unique insights, the authors may want to provide a more detailed analysis about the question discussed in 4.3.5.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_vijR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_vijR"
        ]
    },
    {
        "id": "6Gye9EFUISq",
        "original": null,
        "number": 3,
        "cdate": 1667080716832,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667080716832,
        "tmdate": 1667080716832,
        "tddate": null,
        "forum": "fe2S7736sNS",
        "replyto": "fe2S7736sNS",
        "invitation": "ICLR.cc/2023/Conference/Paper4546/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes kNN Prompting, which addresses the problem of in-context learning (ICL) that the context length is limited, so that the performance cannot scale with the number of available training examples. Similar to ICL, kNN Prompting also formulates the downstream tasks as prompt completion tasks. Differently, at inference time, kNN Prompting not only relies on the demonstration examples in the context of the input, but also will retrieve anchor examples from a datastore built by taking all the training examples. \n\nThe paper conducts experiments on ten downstream tasks, with different model sizes and different scales of training set. They find kNN Prompting outperform ICL under few shot settings and can scale up with as many training examples as are available. Ablation studies and analyses are conducted to study the model design choices. ",
            "strength_and_weaknesses": "Strengths:\n- In general, the paper proposes a simple and effective solution to enable the prompting methods to leverage more training examples, instead of merely relying on the demonstrations in the context. The approach is very interesting and the results are strong. \n- The motivation of the paper is clear and makes sense to me; and the paper is positioned well. I appreciate the authors' efforts on addressing the sequence-length issue when using ICL. I believe that this is a crucial problem of using LLMs on downstream tasks in a full supervision setting and the community should facilitate addressing this problem.\n- The paper is presented clearly. \n- I also like the discussion section where the authors raise potential concerns for the existing retrieval-based models. I believe addressing these problems can further reveal the capacity of retrieval-based models.\n- The paper has conducted ablation studies for understanding the model designs, e.g., KL divergence vs L2 distance; the sensitivity of the number of demonstrations/anchors in kNN Prompting. These studies are informative.\n\n\nWeaknesses:\n- What confuses me is that during inference of kNN Prompting, the method will retrieve anchor examples that have similar predicted probability distributions (measured by KL divergence). Intuitively, this means that the predictions are likely to be the same (or at least very similar) to the current testing example. That means it is not likely that the prediction will be different. I expect detailed discussion about how retrieving anchor examples can actually help the predictions.\n- The predictions are made based on majority voting of retrieved examples. This method may suffer when the labels are imbalanced. For example, when one label has much fewer examples compared to other labels, this label will not be favored by the majority voting system.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity & Quality: the paper is generally well-written and easy to follow. One thing confusing me is Table 1 -- I did not see authors mentioning Table 1 and the numbers in Table 1 seem contradictory to other tables.\n\nNovelty: The method/idea is built based on existing retrieval-based models. The technical novelty is limited -- however, the paper provides insightful and interesting results to the field.\n\nReproducibility: The results should not be hard to reproduce, especially the authors claim they will release the code.\n",
            "summary_of_the_review": "In summary, I think this paper is well-motivated and is written clearly. It presents very interesting and insightful results. I hold a positive attitude towards accepting this paper.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_wqbJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_wqbJ"
        ]
    },
    {
        "id": "5WL63ncjFn",
        "original": null,
        "number": 4,
        "cdate": 1667123067498,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667123067498,
        "tmdate": 1670750425500,
        "tddate": null,
        "forum": "fe2S7736sNS",
        "replyto": "fe2S7736sNS",
        "invitation": "ICLR.cc/2023/Conference/Paper4546/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work considers application scenarios that utilize large language models in a in-context learning paradigm with training data that cannot fit the context due to the input-length limitation.\nTo alleviate the challenge posed by the maximum length limit of language models, this work proposes the knn prompting method.\nThe key idea of knn prompting is to store the information of a large amount of training data in an additional memory cache.\nDuring the inference process, the output is generated by the nearest neighbor voting for a given input in the memory cache, rather than by the model directly.\nThis work claims that knn prompting can greatly improve in-context learning, especially in low-resource or fully\nsupervised scenarios.\n\n",
            "strength_and_weaknesses": "# Strength\n* This work proposes knn prompting that can help the large language models to better suit the application scenarios with enough training data rather than a few shots.\n* For the proposed knn prompting, this work conducts further analysis and shows the robustness of this method. The qualitative analysis illustrates the explanations behind the performance of this method.\n\n# Weakness\n* **Lack of comparisons with previous retrieving-based in-context learning methods**. For the scenario considered in this work, a line of closely related work is about prompt retrieving, which also considers to store the extra training data in an additional memory and utilizes similarity-based choosing. I suppose the main difference between retrieving methods and knn prompting is that the former requires to store the whole data while the latter only need to store a probability distribution. But I suppose both of them do not go beyond your considered scenarios. For instance, [1] considers to retrieve prompting examples from the example bank with knn selection. Since you have mentioned this work in your related work, why not experimentally compare with it?\n**In a word, a line of previous work can also deal with the challenge considered in this work, but this line is neither clearly mentioned nor experimentally compared**.\n\n* **The basic idea behind knn prompting (i.e., calibration) is not clearly introduced and compared**. It seems that the the basic idea behind knn prompting is to calibrate the output probability of the model. Such an idea (along with in-context learning) has also been explored in many previous works, such as [2]. Actually, [2] is already mentioned in the paper but you didn't clearly show the relevance. **In a word, the basic idea of calibration should be clearly introduced to readers and further compared with previous works**.\n\n* **Potential misleading on the novelty of this work**. It seems that this work wants to highlight its novelty on the considered application scenario (i.e., length limitation for in-context learning) and proposed methods (i.e., probability calibration for in-context learning).\nBut in my view, both two points are not novel enough (according to the two weakness mentioned above).\n**For several highly related works, this work simply lists them but avoid to show a clear relevance and comparison, causing a potential misleading on its novelty**.\n\nAll in all, both the considered application scenario and the basic idea of proposed method in this work have been explored in many previous works, but neither the conceptual relevance nor the experimental comparison is mentioned.\n\n[1] What makes good in-context examples for GPT-3?\n\n[2] Calibrate before use: Improving few-shot performance of language models.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**: Not good enough. The method is clearly introduced, but related works are not clearly mentioned or compared.\n\n**Quality**: Not good enough.\n\n**Novelty**: Low and not clearly compared with previous work.\n\n**Reproducibility**: High.",
            "summary_of_the_review": "There is a potential misleading on the novelty of this work, since neither the conceptual relevance to previous work nor the experimental comparison with previous work is clearly mentioned in this work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_P4ZY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4546/Reviewer_P4ZY"
        ]
    }
]