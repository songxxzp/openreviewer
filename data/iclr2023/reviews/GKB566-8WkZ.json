[
    {
        "id": "M2rjTrCqgW",
        "original": null,
        "number": 1,
        "cdate": 1666583768512,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666583768512,
        "tmdate": 1670094213076,
        "tddate": null,
        "forum": "GKB566-8WkZ",
        "replyto": "GKB566-8WkZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4790/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies amortized instance-wise feature-selection methods. It proposes Latent Variable as Explanation (LEX), a new framework that frames interpretation as a statistical learning method using a unified probabilistic likelihood, and shows how various existing methods can be understood under the LEX framework. The paper proposes two new datasets, a switching panels dataset constructed using MNIST and FashionMNIST, and the CELEBA SMILE dataset, to help evaluate various amortized evaluation methods. Using the proposed LEX framework, the paper demonstrates the advantage of multiple imputation over the combination of constant imputation with surrogate predictors.",
            "strength_and_weaknesses": "### Strength\n\n- The LEX framework is conceptually appealing, and on a high level is presented in a way that is easy to follow.\n- The two new datasets are well-designed and make a lot of sense of evalaution of instance-wise feature-selection methods.\n- The observation on the advantage of multiple imputation is valuable and intuitive.\n\n### Weaknesses:\n\n- The main weakness lies in the clarity of the presentation.\n    - While on a high level, the LEX framework is presented in a way that is easy to follow, the paper seems to be carelessly written, and is filled with typos, grammar errors, undefined terms and inconsistent notations. A non-exhaustive list of examples include:\n      - Figure 1 caption, a standard approaches uses\n      - In Section 2.3, why is f_theta is a classifier? It's just a function mapping the input to the parameters of some distributions.\n      - In equation 4, why aren't we optimizing the parameter iota? Does the imputation involve any parameters?\n      - First sentence of last paragraph in Section 2.4, missing a product in the definition of R?\n      - The regularization function R is not consistent between Section 2.4 and Section 2.5. What exactly is the domain of function R?\n      - Many terms don't seem to be clearly explained. What is 0 imputation? What is surrogate posthoc?\n      - Section 3, data distribution q, why do we call it a data distribution? It seems data distribution should be p_data. And how is q different from p_{\\iota}? Why do we change notation here again?\n      - What is multiple imputation? Seems like just using a generative model to approximate the true imputation distribution derived from the joint data distribution? Need to be defined in the main text.\n      - Section 4 2nd paragraph, want to use of \u2192 want to use.\n      - Maximum/minimum ground truth selection, used without definition.\n      - Section 4 2nd paragraph last sentence, provides \u2192 provide\n      - Section 4 3rd paragraph, features k s? Typos?\n      - InSitu or In-Situ?\n      - Section 4 says all the experiments are conducted in the In-Situ regime, but there are two In-Situ regimes according to Section 2.6. What exactly is the setup? Also according to Table 1, several existing methods are not in the In-Situ regime, which seems to suggest the paper is not including any of those methods as baselines.\n      - Section 4 mentions a 100 feature importance maps. It's not immediately clear what it means. Also in the next sentence it becomes 100 features instead of 100 feature?\n      - Section 4 4th paragraph, three measures, not measure.\n      - Section 4.1, selection evaluation, it's not clear what selection rates mean.\n    - Too much materials are pushed into the appendix, to the point that it becomes challenging to evaluate the paper based just on the materials in the main text. Some examples include:\n        - Section 2.4 talks about different regularization approaches. But which regularization does this paper use exactly?\n        - Section 2.5 there should be brief discussions on how existing methods fit into the LEX framework in the main text.\n        - Section 3, since multiple imputation is an important point that this paper tries to make, there should at least be brief discussions on what multiple imputation means, what are some of the methods this paper is using in the main text.\n        - Section 4.1, just from the main text it's close to impossible to understand what the 3 synthetic datasets look like. There should be at least a brief description. But some of the existing detailed setups can potentially be moved into the appendix.\n- Additionally, the way the baselines are set up seems problematic:\n    - The paper frames three existing methods (L2X, Invase and REAL-X) under the LEX framework. However, in the experiments the paper only compares multiple imputation with variants in the LEX framework that only loosely correspond to L2X, Invase and REAL-X. For example the paper uses a customized gradient estimator to handle the discrete latent variables, while existing methods adopt other ways of obtaining gradients estimation (e.g. gumbel-softmax and rebar). This makes the comparison difficult to interpret due to multiple moving parts. It would be helpful to also include performance of the original methods in the comparison (e.g. can we use multiple imputation similarly in the original methods? How does that compare with the optimal setup under the LEX framework? How do the original methods perform on the two newly proposed, more complicated datasets?)\n- Finally, while the LEX framework is conceptually appealing, the paper does not do a very good job at demonstrating how the framework can benefit the study of instance-wise feature-selection methods. In the experiments the paper mainly demonstrates the benefit of multiple imputation. While intuitive, it seems to me even without the LEX framework we can similarly try to incorporate multiple imputation and study its benefits. It would be beneficial if the authors can more clearly illustrate the benefit of the LEX framework for understanding and improving existing methods. For example, does it lead to insights with which we can design new methods to improve upon existing methods? The lack of fair comparison with existing methods (as explained above) makes it hard to access this point.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarify: as explained above, there are major issues with clarify in the paper.\n- Quality: the LEX framework seems technically sound. Too many materials are pushed into the supplementary, and it is a bit challenging to evaluate the other parts of the paper based just on the main paper.\n- Novelty: the LEX framework and the results with multiple imputation seems new.\n- Reproducibility: seems good.\n",
            "summary_of_the_review": "While the proposed LEX framework is conceptually appealing, and the newly proposed datasets are well-designed and useful, the paper in its current form is poorly organized and lacks clarity. Additionally, the baseline setups seem problematic. In my opinion the paper is not ready for publication in its current form, but I encourage the authors to improve the writing and organization and include some additional baseline comparisons and resubmit in the future.\n\n------------------\n\nUpdate after rebuttal: I thank the authors for revising the paper and taking into account my comments. However, after discussing with other reviewers and the AC, we still feel that the paper should either rephrase as presenting the benefits of multiple imputation, or put more efforts into demonstrating the usefulness of the general LEX framework. As a result I am keeping my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_sxVY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_sxVY"
        ]
    },
    {
        "id": "_V_MO0n99Zc",
        "original": null,
        "number": 2,
        "cdate": 1666896076042,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666896076042,
        "tmdate": 1670652652824,
        "tddate": null,
        "forum": "GKB566-8WkZ",
        "replyto": "GKB566-8WkZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4790/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new method for jointly learning a predictor and an interpretability model. The method\noffers a general framework that has LEX, INVASE, and REAL-X as special cases. The paper also introduces two more\ndatasets synthetically created from FashionMNIST and CelebA with ground truth selected features.\n",
            "strength_and_weaknesses": "The paper is clearly written and makes a real contribution. The\nframework outlined really does seem to add flexibility by allowing for\na more generic imputation strategy to be used. I am curious, why\ncouldn't the existing methods be adapted to just use multiple\nimputations?\n\nMy main concern is that the main benefit is the ability to use\namortized imputation methods than necessarily any other portion of the\nframework. This comes across a bit incremental, as all other methods\ntrivially allow changing the selector network and predictor network.\n\nI have some quibbles with the title as it's hardly the first paper that\nlearned an explainable model as a statistical inference task, but perhaps\nthis is best cleared up with clarifications of the ways this paper is statistical\ninference and Chen et al are not.\n\nIt is mentioned that selector when using LEX should still end up encoding the predictor,\nbut I didn't really see any experiments demonstrating that.\n\nUpdate: given the contribution seems to be the framework, I think the paper would greatly benefit from some rewriting to better highlight the strengths of that framework. Though I should stress I think the imputation methods discussed in this work are very interesting and would be a great contribution on their own.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is strikes me as novel and original. The paper was very\nclearly written and straightforward to follow. The only change I would\nwant is greater clarification of the contributions of the paper in the\nintroduction.\n\nThe experiments are well thought out and while I still feel the\ndatasets introduced are fairly synthetic they are much more realistic\nthan previous datasets used in the literature.\n\nWhile no code was included, the appendix provided enough information\nthat work seems reproducible.",
            "summary_of_the_review": " Interesting and significant contribution to the interpretability\n literature. Paper would benefit from clarifying its unique\n contributions.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_DxL9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_DxL9"
        ]
    },
    {
        "id": "Zt1EHtkTxv",
        "original": null,
        "number": 3,
        "cdate": 1667527255511,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667527255511,
        "tmdate": 1667541440802,
        "tddate": null,
        "forum": "GKB566-8WkZ",
        "replyto": "GKB566-8WkZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4790/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to frame the model interpretability problem as a statistical inference problem and develops a general probabilistic model that trains a predictor and a selector network via maximum likelihood to produce interpretable predictions. The proposed framework LEX is modular and able to encompass existing models including L2X, Invase, and REAL-X. The paper also introduces two datasets with ground truth selection for evaluating the proposed method.",
            "strength_and_weaknesses": "Strengths: The proposed method offers a general framework for casting the interpretability problem as a statistical inference problem, encompassing existing methods such as L2X, Invase, and REAL-X. In addition, the insights on using multiple imputation in the proposed procedure could be useful to others.\n\nWeaknesses: The evaluation is not sufficiently convincing. The paper mainly demonstrates the effectiveness of multiple imputation over other imputation variants under the LEX framework, instead of directly comparing LEX with the other existing methods. Moreover, the technical contribution of their proposed method over existing ones has not been stated clearly in the paper. For example, though it does provides a unified framework, it is not the first paper framing the interpretability problem as a statistical inference problem.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow. The method is well-motivated. However, there are a number of typos and undefined terms and symbols. There is no source code provided to directly reproduce the results.",
            "summary_of_the_review": "This paper proposes a unified probabilistic framework to solve the interpretability problem as a statistical inference problem, which could be inspiring to the community. However, the authors need to clarify their main contribution and justify why the current baseline comparison experiments are sufficient to demonstrate the proposed method's effectiveness.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_Hv7W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4790/Reviewer_Hv7W"
        ]
    }
]