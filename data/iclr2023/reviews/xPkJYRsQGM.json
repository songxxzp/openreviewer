[
    {
        "id": "s3G7rbHRl2",
        "original": null,
        "number": 1,
        "cdate": 1666645703057,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666645703057,
        "tmdate": 1666645703057,
        "tddate": null,
        "forum": "xPkJYRsQGM",
        "replyto": "xPkJYRsQGM",
        "invitation": "ICLR.cc/2023/Conference/Paper4095/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a contrastive learning and adversarial training-based approach to accomplish domain adaptation for time series data. The paper is rooted in strong motivations in healthcare where such a transfer is important for reliable operations. The results are convincing and the ablations are much appreciated. ",
            "strength_and_weaknesses": "### Strengths\n+  Well motivated\n+ Well written and paper is well organized.\n+ Extensive applications\n+ Ablation study \n\n### Weaknesses\n- While the paper tackles time series, it seems that the model can only handle same length time series in the problem formulation (see comments)\n- Some recent works on UDA for time series (video analytics) which also use contrastive learning are not compared to/referred to (see comments)\n- the motivation for design of certain components can benefit from further explanation (see comments)\n- Some components of the overall model are not well explained (see comments)\n\n\n### Comments/Questions: \n\n1. Can the model be applied to different length time-series? If yes, how will the architecture change?\n2. [1] (CoMix) Also uses a similar contrastive learning approach for temporal data in Video domain adaptation. How does the method compare to that work. Consider including it in your literature review. \n3. While the authors use certain components like adversarial training, contrastive learning via certain loss functions, and gradient reversal layers. This combination and choice of each of these components is interesting. Can the authors justify why these were chosen, and what were the other alternatives? With some addition motivation on how these come together in the optimization?\n4. Figure 2 is perhaps the most difficult to parse. For instance, it seems that $x_k^s$ is transformed to $z_k^s$ (bottom left corner) without any transfortmation function? Also it is unclear what \"queue\" is here. I recommed redrafting this figure, with additional labels for multiple components listed here, and then describing them in the caption and in the write-up.  \n\n\n[1] Sahoo (2021). Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing, NeurIPS 2021. ",
            "clarity,_quality,_novelty_and_reproducibility": "The work is well written, and the contributions are clearly laid out, the results are interesting. The anonymous link to the code is made available.",
            "summary_of_the_review": "While I list these weaknesses, I think the authors can address these during the rebuttal period, and I look forward to hearing from them. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_ZBbo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_ZBbo"
        ]
    },
    {
        "id": "ecxIq_IPSjt",
        "original": null,
        "number": 2,
        "cdate": 1666660048264,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666660048264,
        "tmdate": 1670964287173,
        "tddate": null,
        "forum": "xPkJYRsQGM",
        "replyto": "xPkJYRsQGM",
        "invitation": "ICLR.cc/2023/Conference/Paper4095/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a framework for unsupervised domain adaptation of time-series.Their approach has 3 components, a feature extractor, discriminator and classifier. Essentially the framework is a combination of the usual classifier/discriminator setup used in domain adaptation with an unsupervised learning objective based on MoCo.",
            "strength_and_weaknesses": "Strenghts:\n- The paper is clear, well-written and motivated.\n- The empirical results are strong: the model appears to outperform baselines conclusively.\n\nWeaknesses:\nx No major weaknesses found.\n\nEdit: to add on this comment, I have responded to the post titled \"global response to reviewers\".",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Clear.\nQuality: Good.\nNovelty: As far as I can tell, novel.\n",
            "summary_of_the_review": "I found multiple positive points in this submission, as listed above. The idea seems straightforward enough that I suspect it might have occured independently in other fields (such as computer vision) but was unable to find a reference. For this point I will defer to another reviewer more experienced in unsupervised domain adaptation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_X1Eq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_X1Eq"
        ]
    },
    {
        "id": "kSybY_7Nbv",
        "original": null,
        "number": 3,
        "cdate": 1666665814523,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665814523,
        "tmdate": 1666665814523,
        "tddate": null,
        "forum": "xPkJYRsQGM",
        "replyto": "xPkJYRsQGM",
        "invitation": "ICLR.cc/2023/Conference/Paper4095/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors aim to propose a framework for unsupervised domain adaptation of time series by doing a weird combination of existing models without good justification/motivation for what they introduce.  Specifically, they combine the model introduced in \u201cdomain adversarial training of neural networks\u201d by a type of contrastive learning model. ",
            "strength_and_weaknesses": "Strengths:\n1-\tDomain adaptation for Time series data is not much directly addressed in the literature. \n\nWeakness:\n1-\tThe authors fail to motivate or justify the approach taken in this work\n2-\tSome important baselines are missing.\n3-\tThe paper is difficult to follow sometimes because it is not written well.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not well-written and it is hard to follow at some places. I have serious doubts about novelty and reproducibility. ",
            "summary_of_the_review": "Not sure if I understand the authors claim that the existing approaches for this problem from computer vision cannot be applied to time series. Time series and images are very similar, and the difference is that one is 1D and the other is 2D. That is why one can simply adapt any convolutional based model from images to time series. The authors need to better explain why the existing models for vision cannot be adapted for time series.\n\nAnother unsupported claim by the author: existing works for UDA of time series merely align the features across source and target domain.  \n\nNot sure how the approach introduced in this paper is different from the one in \u201cdomain adversarial training of neural networks\u201d work? It seems exactly the same formulation and approach. Figure 1 in this paper is exactly the same as Figure 1 in that paper. Equation 1-2 in this paper are also components of Equation 18 in that paper. The idea seems to be exactly the same thing. The authors combined this later in Section 4.4. with a nearest neighbor contrastive learning. However, they do not motivate the need for this approach in the paper. The authors also fail to explain the details of Figure 2. I am very much confused by this extra loss function as the loss function in Equation 3 aims to make sure that the learned embedding is good for both domains.  Interestingly, the authors do not compare their results with \u201cdomain adversarial training of neural networks\u201d, i.e. Figure 1, either. \n\nSome examples of writing problems:\nBeginning of Section 2: while pushing dissimilar samples \uf0e0 while pushing dissimilar samples away.\nBeginning of Section 3 and 7: An abbreviation for Unsupervised domain adaptation is already introduced.\n\n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_xEBG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_xEBG"
        ]
    },
    {
        "id": "XnP9qXJ5XC",
        "original": null,
        "number": 4,
        "cdate": 1666884224050,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666884224050,
        "tmdate": 1666884224050,
        "tddate": null,
        "forum": "xPkJYRsQGM",
        "replyto": "xPkJYRsQGM",
        "invitation": "ICLR.cc/2023/Conference/Paper4095/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an unsupervised domain adaptation model for time series combining nearest-neighbourhood contrastive learning and adversarial learning.",
            "strength_and_weaknesses": "S\n\n+ extensive experimentation and ablation tests\n+ strong results against baselines\n\nW\n\n+ lack of comparisons with already cited works (NCL)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, of high quality and reproducible (code available).",
            "summary_of_the_review": "The paper proposes a comprehensive method for unsupervised domain adaptation with strong results against baselines. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_DXHp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4095/Reviewer_DXHp"
        ]
    }
]