[
    {
        "id": "Nf4Zc5_vgc",
        "original": null,
        "number": 1,
        "cdate": 1666144215474,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666144215474,
        "tmdate": 1670427306525,
        "tddate": null,
        "forum": "kkpL4zUXtiw",
        "replyto": "kkpL4zUXtiw",
        "invitation": "ICLR.cc/2023/Conference/Paper1493/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposed bi-level PINNs for solving PDE-constrained optimization problems. Bi-level PINNs have an inner loop optimization and outer loop optimization. In the inner loop, PINNs are used to solve PDE constraints, and in the outer loop, the control variables are optimized using Broyden\u2019s hypergradients. Numerical experiments are performed to demonstrate the effectiveness of bi-level PINNs, and better results are achieved.",
            "strength_and_weaknesses": "Strengths\n- The idea of bi-level optimization is not new, and the main contribution here is applying Broyden\u2019s\nmethod to efficiently approximate the hypergradients in the outer loop. Also, an error bound is derived for the approximation error of the hypergradients, although this is relatively straightforward from existing results.\n- Several numerical examples are tested, and the method achieved good accuracy and speed.\n\nWeaknesses\n- Poisson and heat equations are simple, and NS is more challenging. However, in all the examples, the control variables are either scalers or 1D function, which are still simple. Problems with control variables of 2D functions should be tested. (Also, it is worth mentioning in Table 1 what type of the control variables is, scalers or 1D functions.)\n- The paper only chose deep learning methods as the baseline. Traditional methods should also be used for comparison.\n- In Introduction, \u201cthis is the first attempt that solves general PDECO problems using a bi-level optimization framework that enjoys scalability and theoretical guarantee\u201d is not correct. There are traditional bi-level optimization methods for general PDECO problems. Probably this is first deep learning based bi-level optimization framework, but I am not sure.\n- In Introduction, \u201cWe conduct extensive experiments and achieve state-of-the-art results on several challenging PDECO problems with complex geometry or non-linear Naiver-Stokes equations.\u201d \u201cstate-of-the-art results\u201d is not correct. As shown in the paper, traditional adjoint method is used as the Reference method and is better than the proposed method in many cases.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.",
            "summary_of_the_review": "New method is proposed in the paper, and the results look good. However, the tested problems are still simple, and more challenging problems should be tested.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_1sqe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_1sqe"
        ]
    },
    {
        "id": "Xge_eCokOKT",
        "original": null,
        "number": 2,
        "cdate": 1666530420424,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530420424,
        "tmdate": 1666530420424,
        "tddate": null,
        "forum": "kkpL4zUXtiw",
        "replyto": "kkpL4zUXtiw",
        "invitation": "ICLR.cc/2023/Conference/Paper1493/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on an emerging and interesting research topic, Physics-informed neural networks (PINNs) for PDE constrained optimization. Different from existing works that use the regularization-based paradigm which is hard to set a proper weights to balance the optimization targets and regularization terms, this paper, for the first time, transforms the constrained optimization problem into a bi-level optimization problem. In addition, by leveraging Broyden\u2019s method to approximate the IHVPs, the authors can more precisely estimate the hypergradient for the outer-loop hypergradient. Extensive experiments on several constrained PDE optimization problems demonstrate the effectiveness of the proposed reformulation.",
            "strength_and_weaknesses": "Strength:\n1. The idea of the proposed reformulation is straightforward and extensive experiments verify the effectiveness of this succinct idea.\n2. The paper is well-written, and the main idea is easy to follow.\n3. The authors conduct a series of ablation studies, especially on the hypergradient approximation, to show the superiority of the recently-proposed Broyden\u2019s method.\n\nWeaknesses:\n1. The idea is hard to say exciting, and the contributions can only be summarized as the simple reformulation and the adoption of the recently-proposed IHVPs method.\n2. The theoretical analysis mainly inherits from the cited paper [1] with less new findings.\n\n[1] Anton Rodomanov and Yurii Nesterov. Greedy quasi-newton methods with explicit superlinear convergence. SIAM Journal on Optimization, 31(1):785\u2013811, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The idea is straightforward, the writing is easy to follow, and the authors also provide open-source codes for reproducibility. However, the novelty seems to be marginal.",
            "summary_of_the_review": "This paper is generally well-written and the authors focus on an interesting research problem. Although the novelty seems to be marginal, I'd like to accept this paper to encourage more attempts in the area of deep learning for science.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_yrSS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_yrSS"
        ]
    },
    {
        "id": "Caa5EhWOiex",
        "original": null,
        "number": 3,
        "cdate": 1666594311627,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594311627,
        "tmdate": 1670433729694,
        "tddate": null,
        "forum": "kkpL4zUXtiw",
        "replyto": "kkpL4zUXtiw",
        "invitation": "ICLR.cc/2023/Conference/Paper1493/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper formulates the PDE-constrained optimization problem as a bi-level optimization problem. The gradient of the bilevel problem (using implicit function theorem) involves an inversion of the Hessian. This paper use Broyden's hyper gradient to approximate the inverse of the Hessian.",
            "strength_and_weaknesses": "Strength:\n- The bilevel formulation is interesting and novel.\n- The experiment is solid compared to other learning baselines.\n\nWeakness:\n- No discussion about algorithms used in bi-level optimization. The reviewer also has no idea of popularly used algorithm for bi-level optimization. I think it would be great to see popularly used bi-level algorithms as a baseline. PINN doesn't use large network. Inverse a Hessian will not be so expansive in my mind. \n- No baseline using traditional methods provided. I still doesn't know the benefit of using a NN for PDE in low dimension.\n- number of parameter and time of computation is not provided in this version.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. ",
            "summary_of_the_review": "Overall this is a novel paper definitely.  But this paper lacks literature review of bi-level optimization and PDE constrained optimization at this point.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_RMiZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_RMiZ"
        ]
    },
    {
        "id": "6Hm_9-YcayN",
        "original": null,
        "number": 4,
        "cdate": 1666640196847,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666640196847,
        "tmdate": 1668755742896,
        "tddate": null,
        "forum": "kkpL4zUXtiw",
        "replyto": "kkpL4zUXtiw",
        "invitation": "ICLR.cc/2023/Conference/Paper1493/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a bi-level optimization method to solve constrained PDE. The key is to compute a hyper-gradient with a high-efficiency and accuracy. The paper has some unclear notations, making it hard for me to understand the main results. ",
            "strength_and_weaknesses": "The proposed method uses an interesting way to compute the hyper-gradients which is not so standard literature (i.e. to solve eq (8) by eq (9)), but this does not seem to be new. The strength of this paper is to show that the proposed method works well on a wide range of constrained PDE. ",
            "clarity,_quality,_novelty_and_reproducibility": "I have a few questions regarding the clarity. \n- What is the evaluation metric to measure the performance in Table 1 and 2? This is not clear from section 5.1. Do you have any alternative for evaluation in case that the FEM of PDE is not avaiable?\n- The z in eq 11, is it z_i?\n- What is t in Assumption 1, and Theorem 1? What is d_2 J? Why the w in the last last point of the assumption 1 and when it holds for PINNs with p_t \u2192 0?",
            "summary_of_the_review": "REVISED: I now understand that the evaluation metric is used to show how well how control variable is found by the proposed method. The main results (table 1) show that it work better state-of-the art methods. Therefore I think the paper could be considered to be published. However, I still think that the evaluation on how well the pde is solved for a given control variable, should also be evaluated (maybe in a future work). For this reason, I raise my score to 6 . ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "na",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_isLd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1493/Reviewer_isLd"
        ]
    }
]