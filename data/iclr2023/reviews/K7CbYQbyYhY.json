[
    {
        "id": "j6GCVZBOM2",
        "original": null,
        "number": 1,
        "cdate": 1666363206559,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666363206559,
        "tmdate": 1666363206559,
        "tddate": null,
        "forum": "K7CbYQbyYhY",
        "replyto": "K7CbYQbyYhY",
        "invitation": "ICLR.cc/2023/Conference/Paper4873/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper adresses OOD generalization by learning an ensemble of diverse predictors. Diversity can be very handy to overcome distribution shifts between a training and a test set. Indeed, if a model has learnt a spurious correlation, a second will be likely not to, due to the diversity constraint. Diversity is enforced by adding an \u00ab\u00a0agreement\u00a0\u00bb term between individual models in the loss function that is minimized during training. The sought disagreement is enforced on OOD (unannotated) inputs. At inference time, the average of the trained models is used to issue predictions.",
            "strength_and_weaknesses": "Pros : \n- The paper is very well written and clear.\n- The claims are supported by both theoretical arguments and empirical evidence\n- The methods successfully avoid spurious correlations \n\nCons : \n- Some parts of the paper are a too quick on some choices (agreement loss term, number of learners in the ensemble, weights of the ensemble ..)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and there is obviously a lot of work behind it. \nThe contributions are fairly novel and the addressed problem is very relevant to the community. \nA link to the code repo is provided, thus the method is easy to reproduce. ",
            "summary_of_the_review": "My most important remark is concerned with the definition of the ensemble model $h_{ens}$. Information in this respect in the paper is really insufficient. On page 2,  the authors say \u00ab\u00a0the ensemble can either be used by forming a weighted average of the probability distribution from each hypothesis, or by tuning the weights on a downstream task.\u00a0\u00bb but later in the text they give no information on actual mechanisms to decide on these weights. \nIt is possible that a majority of trained learners will not perform very well on OOD data so a mere average aggregation seems risky to me. In the experimental section, the authors say \u00abAmong the two models of the ensemble, the best model is selected according to its validation accuracy.\u00a0\u00bb. While I agree that section is a special form of weighted averaging, the philosophy is a bit different and should be stated earlier in the paper. Also, what is this validation data ? Annotated OOD ones ? \n\nThe choice of the agreement loss term is not sufficiently justified in the main body of the article. More details can be found in the appendices (F.7) but I was expecting more context on this choice. \n\nHow does the approach scale to increasingly many learners in the ensemble ? Most of the text and experiments use only two learners.  Fig 10 shows an experiment with more learners but again it is in the appendices. Is there a stopping rule to know that sufficiently many learners have been trained. \n\nIn the experiment of Fig. 1, OOD points are generated through adversarial perturbations. In the case where OOD points are not available, is this way to generate OOD data recommended ?\n\nHave the authors considered a scenario where the ensemble is trained on a pair of distributions (training and OOD one in the paper notations) but is evaluated on a third one ? In other words, does D-BAT also improve transferability ?\n\nMinor : some typos\n\nPage 3 : \u00ab\u00a0set constrains the output\u00a0\u00bb -> \u00ab\u00a0set constrains on the output\u00a0\u00bb \nPage 5 : \u00ab\u00a0to minimize our training data\u00a0\u00bb -> \u00ab\u00a0to minimize risk on our training data\u00a0\u00bb ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_3kp3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_3kp3"
        ]
    },
    {
        "id": "is-WNnU-cK",
        "original": null,
        "number": 2,
        "cdate": 1666631779949,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666631779949,
        "tmdate": 1666631779949,
        "tddate": null,
        "forum": "K7CbYQbyYhY",
        "replyto": "K7CbYQbyYhY",
        "invitation": "ICLR.cc/2023/Conference/Paper4873/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper seeks to tackle the simplicity bias issue of GD algorithms highlighted in prior work. To this end, the authors propose the Diversity-By-disAgreement Training (D-BAT) objective to learn predictors that make diverse predictions on OOD unlabeled data while agreeing on the labeled in-distribution data. Experiments across several different benchmark datasets show the efficacy of the proposed objective.",
            "strength_and_weaknesses": "**Strengths**\n- This paper tackles an important problem and is nicely written. The paper is easy to follow and very clear in its description in every section\n- Nice motivation for the proposed method is provided in Section 3\n- Experimental evaluation is interesting. The proposed method is evaluated for diverse tasks ) including mitigating shortcut learning,\nbypassing simplicity bias, and generalizing to OOD distributions. \n- All the experimental details and code is available to reproduce experiments from the paper\n- Interesting discussion highlighting the weaknesses and limitations of the paper is provided in Section 5\n\n**Weakness** \n- Discussion on how should one choose the weight $\\alpha$. While the paper presents some results, it is unclear how this hyperparameter is picked in the experiments. It would also be good to discuss the impact of this hyperparameter in different settings for practitioners. Is there a general recipe that authors observed while choosing different weight parameters $\\alpha$. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarification questions/suggestions**\n- Abstract should make it clear that this paper only leverages unlabeled OOD data with their DBAT objective. ",
            "summary_of_the_review": "Overall, the paper makes an interesting contribution and is nicely written. The proposed D-BAT objective is well-motivated with an interesting set of experiments across diverse tasks. I recommend acceptance of the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not applicable",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_Yjzs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_Yjzs"
        ]
    },
    {
        "id": "K3MiPX4FUM",
        "original": null,
        "number": 3,
        "cdate": 1666649945277,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649945277,
        "tmdate": 1666649945277,
        "tddate": null,
        "forum": "K7CbYQbyYhY",
        "replyto": "K7CbYQbyYhY",
        "invitation": "ICLR.cc/2023/Conference/Paper4873/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors introduce D-BAT, a diversity-inducing regularizer for training ensembles of diverse predictors. They derive D-BAT mathematically, and evaluate it on several datasets to demonstrate that the induced diversity can help to (i) tackle shortcut learning, and (ii) improve uncertainty estimation and transferability.",
            "strength_and_weaknesses": "Strengths:\nThe authors tackle an important problem, and present a nice approach with a relatively simple intuition. I think their proxy for identifying OOD items is clever.\nThe mathematical derivation is thorough (though I have not checked its details)\nTheir evaluation is convincing\n\nWeaknesses:\nI'd like to see an explicit evaluation of their proxy for identifying OOD items\nIt would be nice to see more of a qualitative evaluation of which type of items their approach improved performance over, and which it didn't. Is the improvement randomly distributed over all OOD items, or are there qualitative properties of some items that dictated how well it would work?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the writing is clear and, considering the appendix provided, likely provides sufficient information for reproducibility. I am not fully up to date on the latest literature in the sub-area, but from what I am aware, I believe the authors' approach is novel and that their related work is thorough.",
            "summary_of_the_review": "I think this paper provides an interesting and novel approach that makes progress on an important problem, and documents it well. I recommend acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_nyu8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_nyu8"
        ]
    },
    {
        "id": "ZIluVRcFMk7",
        "original": null,
        "number": 4,
        "cdate": 1666662310877,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662310877,
        "tmdate": 1666710188666,
        "tddate": null,
        "forum": "K7CbYQbyYhY",
        "replyto": "K7CbYQbyYhY",
        "invitation": "ICLR.cc/2023/Conference/Paper4873/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes D-BAT, a method for training diverse predictions by maximizing disagreement between the models on an OOD dataset. The authors provide a theoretical motivation for the method, and demonstrate improved performance on some OOD generalization and uncertainty estimation benchmarks.",
            "strength_and_weaknesses": "## Strengths\n\n**S1**: The paper is interesting, and overall well-written. The presentation is logical\n**S2**: The proposed method is intuitive\n**S3**: The experiments show a big improvement in performance on the Camelyon17 dataset compared to strong baselines\n**S4**: Experiments on uncertainty estimation show nice results.\n\n## Weaknesses\n\n**W1**: The theory is somewhat confusing.\n**W2**: The improvements over the ERM are quite small on Waterbirds and Office-Home.\n**W3**: The Camelyon17 experiments appear to use a somewhat different setup compared to the baselines (although I don't think it provides a significant advantage to D-BAT).\n**W4**: Would be nice to have a direct comparison with [1] in the experiments.\n\nI expand on the weaknesses below.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity (W1)\n\nThe paper is overall well-written. The one part I found confusing is the theory on page 5. You say\n>  Thus, the error on OOD data might be very high\n\nand then proceed to _upper-bound_ the error on OOD data: $L_\\text{ood}(h_\\text{ERM}, h_\\text{ood}) \\le \\max_{h \\in H^*_t} L_\\text{ood} (h, h_\\text{ood})$. Then, you say that ideally we would like to minimize the right hand side. It is not clear what exactly you mean, minimize what with respect to what. I would guess that you mean that we wish to find a solution $h$ that minimizes the OOD loss $L_\\text{ood} (h, h_\\text{ood})$.\n\nThen, you say you derive a proxy: $L_\\text{ood}(h_1, h_\\text{ood}) = \\max_{h_2 \\in H^* \\cap H^*_\\text{ood}} L_\\text{ood}(h_1, h2)$. I don't see why this equality would hold. Maybe it should be $\\le$ and not $=$? \n\nFinally you arrive at the bound\n$L_\\text{ood}(h_1, h_\\text{ood}) \\le \\max_{h_2 \\in H^*} L_{\\text{ood}} (h_1, h_2)$, which makes sense. However, how does this bound suggest that\n> we want to pick $h_2$ to minimize our training data, but otherwise maximally disagree with $h_1$ on the OOD data\n\n? I would agree that this point is suggested if our goal was to upper-bound the OOD loss of $h_1$, but it is not clear why this would be a good strategy for finding a solution $h_2$ with low OOD loss. I don't think the theory suggests it.\n\n## Novelty (W4)\n\nThe authors mention the work [1] which has similar ideas, but trains diverse classifiers with a fixed feature extractor. I think it would be nice to include an explicit comparison with this method for a subset of your experiments. [2] suggests that fixed feature extractors may be sufficient, at least for datasets such as waterbirds and [3] suggests the same for Office-Home. \n\nMore generally, it would be nice to verify that diverse features are actually learned, rather than diverse classification heads on similar features.\n\n## Experiments (W2, W3)\n\nThe improvements on Waterbirds and Office-Home are fairly small, especially given that ERM is the only baseline. In particular, on Waterbirds the standard metric in the spurious correlation literature is the worst group accuracy, which for strong methods is above 90%. For the authors, the average accuracy on the test set is 88%, suggesting that the worst group accuracy is probably much lower.\n\nThe only natural dataset where the method shows really impressive results is Camelyon17, where the authors seem to achieve state-of-the-art. My understanding is that the baseline numbers are reported from  the WILDS leaderboard (https://wilds.stanford.edu/leaderboard/#with-unlabeled-data-2). One difference I notice is that the methods in the leaderboard use a DenseNet-121 model, while you are using a ResNet-50 model. \n\n**Q1**: Generally, did you use the official WILDS scripts to evaluate your method? If you switch the architecture to a DenseNet-121, would your method count as a \"standard submission\" by the WILDS leaderboard definitions (https://wilds.stanford.edu/submit/)?\n\n**Q2**: Another question I have is why are the ensemble results missing for both ERM and D-BAT on all the synthetic datasets?\n",
            "summary_of_the_review": "Overall, this is an interesting paper which proposes an interesting method. I hope that the authors can address my questions above during the rebuttal.\n\n\n## References:\n\n[1] Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization\nDamien Teney, Ehsan Abbasnejad, Simon Lucey, Anton van den Hengel\n\n[2] Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations\nPolina Kirichenko, Pavel Izmailov, Andrew Gordon Wilson\n\n[3] Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient for Out-of-Distribution Generalization\nElan Rosenfeld, Pradeep Ravikumar, Andrej Ristesk",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_Xnkg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4873/Reviewer_Xnkg"
        ]
    }
]