[
    {
        "id": "cRZlFWj5vT",
        "original": null,
        "number": 1,
        "cdate": 1666549261823,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549261823,
        "tmdate": 1670438437663,
        "tddate": null,
        "forum": "vDFA1tpuLvk",
        "replyto": "vDFA1tpuLvk",
        "invitation": "ICLR.cc/2023/Conference/Paper1971/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work presents a retrieval-based framework for controllable molecule generation. The framework consists of:\n\n- A mechanism to retrieve a set of molecules that (partially) satisfy a set of desired properties the generated molecule should have (e.g. similarity to the input molecule, enhanced drug-like properties);\n- A fusion module that combines the retrieved molecules with the input molecule through cross-attention;\n- A novel self-supervised objective to train the fusion module, consisting in reconstructing the nearest neighbor molecule of the input molecule (as opposed to the classical self-reconstruction objective);\n- An iterative refinement process to update the retrieval database with the generated molecules.\n\nThe fusion module can be plugged-in into any pre-trained encoder-decoder architecture (in this work, they use the SMILES representation of molecules and the ChemFormer model), which is frozen (i.e. only the fusion model is trained for efficiency). \n\nThe proposed approach is evaluated in three controllable generation scenarios, one real-world drug design scenario (find novel inhibitors for SARS-COVID protease), and the GuacaMol benchmark. In every case, it obtains an improvement over a range of different metrics such as success rate or docking score.",
            "strength_and_weaknesses": "**Strenghts**\n\n- Strong performances in what appears to be a well-designed set of experiments;\n- Training is very efficient (just the retrieval module); inference is not affected too much since we are adding a small number of parameters with respect to the large size of the encoder-decoder backbone;\n- Works with a small set of retrieved molecules (up to 23 in the experiments), which is ideal when one wants to generate alternative molecules from limited data;\n- The nearest neighbor training objective is a simple but very clever idea that works experimentally.\n\n**Weaknesses**\n\n- Not sure it would be applicable in cases where no exemplar molecules to be retrieved are unavailable (as stated in Conclusions); this might limit its widespread applicability;\n- It poorly exploits the chemical space, i.e. it will most likely generate molecules that are very similar to the input molecule.\n- Even though it is claimed to work with any encoder-decoder architecture, performances are shown considering only a single backbone model (ChemFormer). I would have expected that its cross-applicability would be one of the main focuses of this paper, but unfortunately it is not.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThis work is extremely well written. It was a pleasure to read from top to bottom.\n\n**Quality**\n\nThe quality of this work is high. The choice of experiments is sensible, several ablations and analyses are presented to understand the impact of the modeling choices, all the claims made are substantiated.\n\n**Novelty**\n\nThe paper applies well-known ideas from retrieval-augmented language models to the space of molecules, which does qualify as novel to me. Plus, the nearest-neighbor training objective is a novel idea (to my knowledge). \n\n**Reproducibility**\n\nNot reproducible. The authors state that the code will be released in the future (upon approval, I suspect).",
            "summary_of_the_review": "This appears to me as a strong submission. I am giving a score of 6 for the time being. Will be happy to raise my score when the authors answer the following set of questions/comments: \n\n- In section 2, you acknowledge the existence of weighting coefficients $w_{\\ell}$. However, they don't seem to be present in the rest of the work. What are they (or, are they just construction to explain the problem)?\n- What is the justification for having used ChemFormer instead of any other encoder-decoder architecture as the backbone model? It would be great to see RetMol applied to another backbone, to see if it works across backbones or if it is just a perfect match with ChemFormer.\n- In which order are the constraints removed to relax the feasible set (Sec. 2.1 - Molecule retriever)? It would be interesting to know the impact of using different ordering strategies.\n- In (Sec. 2.1 - Information fusion), I see that the set of retrieved exemplars is a matrix $\\in \\mathbb{R}^{(\\sum_{k=1}^K L_k) \\times D}$, which means that you concatenate all the embeddings of the retrieved molecules. Considering that they might have different dimensions, how do you handle the mismatch? Padding? Also, doesn't this introduce an unnecessary dependence on the order in which the molecules are retrieved (which could have been avoided, e.g. by a permutation invariant aggregation)?\n- I understand the model is very efficient to train. But what about preprocessing (i.e. computing all the embeddings and the pairwise similarities)? What is its impact?\n- This is for my understanding: do you confirm that the iterative refinement is applied only at inference, but not during training?\n- Due to the large standard deviation in Table 1b, I think it's better to also report the mode of the penalized logP values in addition to the mean.\n- How come uniqueness is sometimes not reported in the generation experiments (e.g. Table 2, Table 4-right)? \n\n\n**EDIT**\n\nAfter a successful rebuttal, I am raising my score to 8, since the method is sufficiently new, has good experimental results, and has wide applicability across different molecular generators.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_3hQB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_3hQB"
        ]
    },
    {
        "id": "FirsSLi63qV",
        "original": null,
        "number": 2,
        "cdate": 1666620259043,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620259043,
        "tmdate": 1669812072401,
        "tddate": null,
        "forum": "vDFA1tpuLvk",
        "replyto": "vDFA1tpuLvk",
        "invitation": "ICLR.cc/2023/Conference/Paper1971/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Motivated by the need for sample-efficient molecule generation, this paper introduces a simple retrieval mechanism to retrieve and fuse the exemplar molecules for controllable molecule generation. Evaluated on a variety of synthetic molecule generation tasks, the proposed method outperforms other baselines. ",
            "strength_and_weaknesses": "# Strength\n\n- The experiments are very extensive with lots of details, including both qualitative and quantitative materials.\n- It evaluates the effectiveness of simple retrieval modules for controllable molecule generation. \n\n# Weakness\n\n\n- Inference via iterative refinement introduced in Section 2.3 is quite heuristic, yet the heuristic is not designed carefully. The authors mention that iterative update is common in approaches such as GA methods, and there are many off-the-shelf GA tools. It seems to me that it\u2019s a better choice to use those tools instead of relying on a design with much simpler heuristics.\n\n- On most benchmark tasks, RetMol does not significantly outperform other baselines, and those baselines methods are usually proposed in 2019. The authors should include recent stronger baselines to justify the value of retrieval modules.",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity\nThis paper is well-written and easy to follow\n\n# Novelty\nThe authors fail to provide a comprehensive literature survey on general retrieval-based training methods, especially those in NLP and CV. For example, in \u201cInstance-Conditioned GAN, NeurIPS 2021\u201d, the authors show that a retriever can improve the generation capabilities with very few data points. The authors claim briefly the way the retrieval modules retrieve and integrate the information is slightly different from MSA, but it is not clear to me where are those differences: The retrieval pipeline looks quite standard and the fusion module is just based on the standard attention mechanism. It is true that the authors in this submission focus on applications to bio-related tasks, but the methods used here are not modified accordingly, and thus I think there are very limited technical contributions.\n\n# Reproducibility\nThe authors do not provide the source code in the supplement., and they do not mention in the paper if they will release their code, making it difficult for others to reproduce this work.",
            "summary_of_the_review": "In summary, this paper proposes a retrieval-based method for controllable molecule generation and extensively evaluates its effectiveness on benchmark datasets. The introduction of a retriever for molecule generation is new as far as I know, but it\u2019s not new in other ML communities. However, the design of the retrieval components does not bring in any technical contributions to the community and is mostly based on ungrounded heuristics. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_PZ6g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_PZ6g"
        ]
    },
    {
        "id": "BTIQW-3RkM",
        "original": null,
        "number": 3,
        "cdate": 1667064341038,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667064341038,
        "tmdate": 1669948314213,
        "tddate": null,
        "forum": "vDFA1tpuLvk",
        "replyto": "vDFA1tpuLvk",
        "invitation": "ICLR.cc/2023/Conference/Paper1971/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a retrieval-based method for optimizing molecular properties under similarity constraints. The proposed method leverages a pre-trained encoder-decoder generative model and trains an information fusion module to steer the pre-trained model toward generating more similar molecules to the retrieved ones. During training time, the model is asked to predict the nearest molecule in the retrieved ones. And then, during inference time, an iterative refinement process is employed to perform multi-step optimization. The proposed method performed competitively on several molecular optimization tasks using only a small set of exemplar molecules.",
            "strength_and_weaknesses": "Strength:\n- Data efficiency is a practical issue in the optimization of molecular properties. The proposed method could be used to optimize molecules given a small number of positive examples.\n- To my knowledge, the self-supervised training strategy of predicting the nearest neighbors given the remaining neighbors is novel. The task-agnostic training makes it depend less on the number of task-specific samples.\n\nWeaknesses:\n- The paper did not justify why such self-supervised training strategy would work since the inference time objective is not aligned with the training time objective.\n  - During the training time, the information fusion is trained to predict the nearest molecule given the K-1 remaining nearest neighbors. An information fusion model that adds a small noise to the current molecule would yield a high objective score, which means the information fusion model learns to predict a similar molecule to the current one.\n  - However, during inference time, the model is asked to predict a similar molecule but in the direction of the positive examples. The inference time objective is quite different from the training time objective. This is a mismatch that needs further explanation and/or empirical analysis in the paper.\n- The design of the iterative refinement approach is ad-hoc, and the description in Section 2.3 seems to miss important details about random perturbing.\n  - From my understanding, the model is expected to interpolate between the current molecule and the positive examples in the axis of both structural similarity and property scores. It\u2019s unrealistic to expect the model to extrapolate beyond the database, even if we do iterative refinement. The key mechanism to allow local exploration is random perturbing, mentioned briefly in Section 2.3. However, details are missing here.\n- The abstract and intro section gives the readers the wrong impression that the proposed method only requires a small number of samples for a property optimization task. However, the method still requires a large number of samples (number of calls to the property prediction), even in the SARS-COV-2 experiment where there are only 23 positive examples given. Since this paper focuses on sample efficiency, it would be more convincing if the authors could provide the exact numbers of samples used in the proposed method and all baselines for a full comparison. For example, in the multi-property optimization experiment in Section 3.2, the number of samples required by each methods are (copied from the Appendix): \n  - 296, 000 for the proposed method.\n  - 2, 750, 000 for MARS [1].\n  - 200, 000 for MolEvol [2] (missing in the baselines).\n  - xxx for RationaleRL[3].\n\n[1] Xie, Yutong, et al. \"MARS: Markov Molecular Sampling for Multi-objective Drug Discovery.\" International Conference on Learning Representations. 2021.\n[2] Chen, Binghong, et al. \"Molecule optimization by explainable evolution.\" International Conference on Learning Representation (ICLR). 2021.\n[3] Jin, Wengong, Regina Barzilay, and Tommi Jaakkola. \"Multi-objective molecule generation using interpretable substructures.\" International conference on machine learning. PMLR, 2020.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is mostly clear. The authors did not release the code but promised to release it in the future.",
            "summary_of_the_review": "The paper proposed a retrieval-based method for molecular property optimization. Although the proposed method achieved competitive results, the methodology is less principled and needs more work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_9XRZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_9XRZ"
        ]
    },
    {
        "id": "J9NKpJX0i3",
        "original": null,
        "number": 4,
        "cdate": 1670437635632,
        "mdate": 1670437635632,
        "ddate": null,
        "tcdate": 1670437635632,
        "tmdate": 1670437635632,
        "tddate": null,
        "forum": "vDFA1tpuLvk",
        "replyto": "vDFA1tpuLvk",
        "invitation": "ICLR.cc/2023/Conference/Paper1971/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper studies molecule generation, proposing a new model using a retrieval mechanism, which has recently shown to be successful in NLP.\n\nThe method is evaluated on several established benchmarks and reaches performance comparable to state of the art",
            "strength_and_weaknesses": "strengths\n- comprehensive evaluation\n- new, reasonably motivated model\n\nweaknesses\n- ML novelty somewhat limited\n- docking as oracle is not ideal",
            "clarity,_quality,_novelty_and_reproducibility": "- description is reasonable clear\n- novelty is given but limited\n- quality good enough for ICLR\n- overall, results seems to be reproducible",
            "summary_of_the_review": "good evaluation, decent results, limited novelty",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_UNcN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1971/Reviewer_UNcN"
        ]
    }
]