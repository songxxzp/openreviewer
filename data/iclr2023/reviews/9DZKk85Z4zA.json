[
    {
        "id": "o_zgS8wPW3E",
        "original": null,
        "number": 1,
        "cdate": 1665994199651,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665994199651,
        "tmdate": 1665994199651,
        "tddate": null,
        "forum": "9DZKk85Z4zA",
        "replyto": "9DZKk85Z4zA",
        "invitation": "ICLR.cc/2023/Conference/Paper957/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a gradient-guided importance sampling method for learning binary energy based models. The idea is to combine ratio matching with scalable gradient of the energy function for more efficient computation. The paper is clearly written. Numerical experiments show the advantage of the proposed method over alternative baselines.",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is well written and organized.\n2. The idea of combining gradient information of the energy function and ratio matching is new.\n\nWeaknesses:\n\n1. As the main idea is a combination of ratio matching and gradient information, there seems to be a lack of ablation study on which one is the main factor for the overall improvement. More specifically, there is no comparison to scalable gradient-based samping method for learning discrete EBMs (e.g., GWG, Grathwohl et al., 2021) in section 5.1, and stochastic ratio matching in section 5.2 and 5.3.\n\n2. The number of samples $s$ seems to be a crucial hyper-parameter and there is no ablation study of it throughout the experiments. It would be better to have it to clarify the choice of $s$ in your experiments. The author reported that the simple random sampling failed when $s=10$ which would be easily saved with more samples.\n\n3. The experiment results are not significant on real data tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is clearly written and well presented. Although ratio matching and scalable sampling of discrete energy based models using gradient information have been explored before, it seems to be a new combination for learning binary energy based models.",
            "summary_of_the_review": "The paper present a new method for learning binary energy based model that combines ratio matching and scalable gradient-based importance sampling techniques. Overall, the paper is well written and organized. Although ratio matching and gradient-based information for scalable sampling from discrete energy based models have been proposed before, the combination for learning binary energy based model is new. The lack of novelty and significant empricial evidence of the proposed method is the main reason for my recommendation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper957/Reviewer_wsgm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper957/Reviewer_wsgm"
        ]
    },
    {
        "id": "M4bXgJxXTw",
        "original": null,
        "number": 2,
        "cdate": 1666082754993,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666082754993,
        "tmdate": 1668525494846,
        "tddate": null,
        "forum": "9DZKk85Z4zA",
        "replyto": "9DZKk85Z4zA",
        "invitation": "ICLR.cc/2023/Conference/Paper957/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new method to learn discrete EBMs based on ratio-matching. Specifically, they consider the \u201cdiscrete extension of generalised score matching\u201d. The main disadvantage of this approach is that it is inefficient in time and memory complexity since you need to compute d + 1 energies (d perturbations and x itself), then backprop through it. This paper proposes sampling s << d perturbations instead, and reducing the variance of this estimator via importance sampling. The optimal proposal distribution for importance sampling has a closed form, but is as expensive to compute as the original ratio matching approach. This proposal can be approximated via a first-order Taylor-approximation, following the GWG approach (related work). In practice, the authors dispense with reweighting the ratios by the importance factor (Eq. 11).",
            "strength_and_weaknesses": "The paper is very well-written and clear. There is a very good description of the background materials and the method itself. There are many experiments to back up their claims.\n\nI feel it could be explained more clearly in the main body that the \u201cadvanced version\u201d is the method actually being used. It should be emphasised earlier in the work that the final method does not re-weight the samples according to the importance weights. My understanding is that both \u201cbasic\u201d and \u201cadvanced\u201d are denoted as \u201cRMwGGIS\u201d, which is confusing.\n\nAre there any experiments showing why the variance of the importance-weighted sampler is better?\n\nBesides on toy-data, can you show that the energy functions learned with your approach are better? e.g. can you show that you can do OOD detection with your models? Is it easier to sample from your learned energy functions compared to those where MCMC is used at training time?\n\nDo you stop_grad through the importance weights? If yes, this should be emphasised.\n\nThe top bar notation above equation 9 should be explained in a footnote, and it should be formatted better (e.g. \\overline{x}_i, not \\overline{x_i})\n\nCan you explain in the main body why you remove the importance sampling? How much bias does this induce in the estimator?\n\nIt should be emphasised earlier in the work (e.g. when introducing ratio matching), that this approach doesn\u2019t work well for images.",
            "clarity,_quality,_novelty_and_reproducibility": "This work is overall well-explained and original. I think the method is novel and quite interesting. The experiments are well-done and reproducible.",
            "summary_of_the_review": "The paper is well-written and clear, and the method is novel and interesting. Many of the claims are well-supported by either/both theoretical and empirical justification.\n\nThere are two versions of their method being used, and it\u2019s unclear which they refer to in which experiment.\n\nI have some concerns regarding properties of their method. Specifically, experiments that show the bias/variance of the estimator, and experiments on higher-dimensional data showing that the learned energy functions are better (e.g. are the energy functions as easy to sample from at test-time if sampling is not done during training).\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper957/Reviewer_KMq7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper957/Reviewer_KMq7"
        ]
    },
    {
        "id": "AKgQcTWXCd",
        "original": null,
        "number": 3,
        "cdate": 1666641927345,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666641927345,
        "tmdate": 1666641927345,
        "tddate": null,
        "forum": "9DZKk85Z4zA",
        "replyto": "9DZKk85Z4zA",
        "invitation": "ICLR.cc/2023/Conference/Paper957/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed an importance sampling approach to alleviate the computation and memory complexity of ratio matching for training binary EBM. Specifically, the author first rewrites the ratio-matching objective as an expectation of the energy difference and then showed the form of optimal importance proposal to reduce the variance of the objective. In the end, the author showed that the optimal importance proposal can be approximated by using the Taylor expansion following the ideas from Gibbs-with-gradient (GWG) sampler. \n\nEmpirically, the author evaluates the proposed approach using synthetic data, graph generation, and ising model. In general, it achieves better results in the graph generation task. Although it performs worse than GWG, it is much faster in terms of training.",
            "strength_and_weaknesses": "## Strength\n\nThe paper is clearly written and easy to follow. The author also explains the intuition behind the proposed importance sampling approach in section 3.3, which help the understanding of the paper. Empirically, the author considers three tasks and includes many baselines in graph generation task. I briefly checked the math, which seems to be correct. \n\n## Weakness\nTheoretically, I am curious about why eq.11 has a better performance than eq.6? Eq.11 is not a proper objective anymore, which means it does not correspond to a valid discrepancy. How does this ensure that the model can converge to the correct distribution? In addition, from theorem 1, the importance proposal should be the optimal one (at least approximately). Why the advanced version is better?\n\nEmpirically, I think other than the graph generation task, more baselines should be considered. At the moment, only ratio matching is used for synthetic data and GWG and Gibbs are used for the Ising model. More baselines can further support the claims made by the paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of clarity, I think the paper is clearly written and easy to follow, so I do not have much complaints about the presentation, apart from the reason why the advanced version performs better empirically. In terms of novelty, although the idea is simple, it seems to be a novel contribution to the best of my knowledge. I have briefly checked the math, which seems to be good. For reproducibility, the author provides the settings for the experiments in the appendix. Since the author does not provide the code, I cannot say 100% the experiments are reproducible. ",
            "summary_of_the_review": "The author proposed an improved version of ratio matching for training binary EBM by using importance sampling. In general, the paper is written clearly and does a good job of explaining the intuition of the proposed method. I am also curious why there is a discrepancy between the theory and empirical evaluations such that the advanced version performs better than the \"correct\" version. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper957/Reviewer_D4Cv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper957/Reviewer_D4Cv"
        ]
    },
    {
        "id": "ZKfhY8VEkd",
        "original": null,
        "number": 4,
        "cdate": 1666693805972,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693805972,
        "tmdate": 1670982218676,
        "tddate": null,
        "forum": "9DZKk85Z4zA",
        "replyto": "9DZKk85Z4zA",
        "invitation": "ICLR.cc/2023/Conference/Paper957/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of learning binary energy-based model using ratio matching method. The paper proposes to use importance sampling to improve the time and memory efficiency of the ratio matching method, where the proposal distribution is obtained based on the gradient of the energy function with respect to the binary variables. The effectiveness of the proposed method is demonstrated on synthetic and real datasets. ",
            "strength_and_weaknesses": "Strengths: \n\n(1) The proposed method is novel, simple and useful. \n\n(2) The experiments illustrate the effectiveness of the proposed method. \n\n(3) The paper clearly discusses the limitation with respect to binary images. \n\nWeaknesses: \n\nMethods based on importance sampling may not work well for high dimensional problem. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written and it is a pleasure to read. \n\nThe proposed method is very novel. \n\nThe work is of a high quality. \n\nCan you generalize your method by flipping multiple sites? ",
            "summary_of_the_review": "The paper proposes a simple and effective method for learning binary energy-based model. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper957/Reviewer_pBMS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper957/Reviewer_pBMS"
        ]
    }
]