[
    {
        "id": "c_rARzHtmaQ",
        "original": null,
        "number": 1,
        "cdate": 1666409460672,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666409460672,
        "tmdate": 1666409460672,
        "tddate": null,
        "forum": "TBaS6AqX_F_",
        "replyto": "TBaS6AqX_F_",
        "invitation": "ICLR.cc/2023/Conference/Paper4710/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents s framework to learn manipulation skills with a musculoskeletal hand. Furthermore, this paper demonstrates that a multi-task policy can provide better generalization, e.g., better measure in term of synergies and better generalization to new tasks.",
            "strength_and_weaknesses": "Pro:\n\n1. A simple system that can learn a wide range of manipulation tasks for a musculoskeletal hand. This can serve as baseline for future research in this direction.\n\n2. Demonstration of the advantage of learning multiple tasks at the same time, using metrics like synergies and task generalization.\n\nCon:\n\n1. There are some problems about the comparison in Table I, see comment below.\n\n2. The failure of the student policy to learn effectively from expert policies need more analysis.",
            "clarity,_quality,_novelty_and_reproducibility": "The method seems straightforward and clearly described.\n\nTo truly facilitate reproducibility, it would be best if the authors can release the code, since there are also some complication coming from defining the pregrasp pose and desired trajectories for the objects.  ",
            "summary_of_the_review": "This paper provides a good baseline for learning musculoskeletal hand control. The findings that multitask learning help better generalization is interesting. Some questions to addressed during the rebuttal:\n\n1. The comparison in Table I seems unfair, since MyoDex is initialized with some pretrained policy and the expert is trained from scratch, isn't it expected that MyoDex will win? And it is interesting that in the final two cases of the in distribution task, the expert actually wins. A more fair comparison might be to also taking into account the number of iterations used during MyoDex initial training.\n\n2. It is unclear why the expert fails all the out-of-domain tasks. Is it because these tasks are fundamentally harder? How are the initial set of task to train the expert/MyoDex selected? It will be nice to provide some intuition. Does decreasing/increasing the set of initial tasks affect the performance of the multitask learned policy? i.e., how do we know what tasks to train for initially?\n\n3. Why does the student policies fail to match the performance of the expert policies? Have the authors tried DAGGER? It is unclear to me whether it is due to fundamental challenge to imitate a large number of experts or if it is a purely implementation issue. More evidence is needed to support the claim. e.g., Are the student able to just imitate one expert effectively? What about two? What is the minimum number of experts that will cause the student to fail to learn effectively?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_G4dn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_G4dn"
        ]
    },
    {
        "id": "67QDKzjhQyx",
        "original": null,
        "number": 2,
        "cdate": 1666564261682,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666564261682,
        "tmdate": 1666565563458,
        "tddate": null,
        "forum": "TBaS6AqX_F_",
        "replyto": "TBaS6AqX_F_",
        "invitation": "ICLR.cc/2023/Conference/Paper4710/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents the MyoDex framework, which applies goal conditioned pre-grasping and PPO (introduced in prior work) to grasping and manipulation tasks with a simulated human hand. The paper considers multi-task and transfer-learning scenarios showing the superiority of the method over baselines.",
            "strength_and_weaknesses": "**Strengths**\n\n*S1.* The problem of controlling small, dexterous muscle groups seems understudied and this paper takes a step in understanding how techniques might be applied to address this problem.\n\n*S2.* Experiments are creative and well intentioned. For example, probing for synergies between muscle groups is an interesting idea, with possible implications for transfer-learning on hand models.\n\n*S3.* Extension of the MyoHand simulation to include shoulder movement.\n\n*S4.* Empirical novelty demonstrating the application of Pre-grasp + PPO to the manipulation tasks considered in the evaluated benchmark.\n\n**Weaknesses**\n\n*W1.* The task formulation is not entirely clear (Sec. 3.2). Currently it just presents metrics, which is different than the task itself. Also it is not clear why there are both \"Task Formulation\" and \"Problem Formulation\" (Sec. 4.1) sections.\n\n*W2.* What is $\\phi$ in Sec. 4.1? What is the dimensionality? How does it relate to the hand model? What is meant by a \"joint angle\" in this case?\n\n*W3.* The action space is not clear in the manuscript. What is an example of an action? What does an action represent? Some continuous contractions of muscles? What is an example of a state?\n\n*W4.* The reward function used this this work looks to be the same as that in Dasari et al., 2022. The authors must cite this to make this attribution clear.\n\n*W5.* The method assumes a lot of information about the scene (1) GT state (2) densely annotated ground truth trajectories for their dense reward (3) does not consider complications associated with vision. I consider these to be limitations of the work in its current state, but still feel the exploration is valid.\n\n*W6.* The training dataset details are not clear in the manuscript. For example for each task how many GT training trajectories are sampled? A single trajectory? Multiple trajectories? Given a single task, are the target objects always spawned in the same pose? The manuscript discusses pose variations between different tasks but it is unclear if there is any randomization when training one task.\n\n*W7.* The pre-grasp, introduced in Dasari et al., 2022. seems to greatly simplify the problem and search space. However, I consider pre-grasp as privileged information and wonder if the pre-grasp makes grasping the object trivial. Given the pre-grasp what is the challenge of closing the MyoHand?\n\n*W8.* Only one seed seems to be used in evaluation calling into question the reproducibility and stability of the results.\n\n*W9.* In the explanation of VAF metric (Sec. 5.3) it is not clear on what matrix NNMF is done on. What is the matrix A exactly and what is its dimensions? Is it the output of your network? Perhaps including an example here would add clarity.\n\n*W10.* In Sec. 5.3, the use of cosine similarity to count the number of synergies is not completely convincing to me. My understanding is that H is a matrix of basis vectors and and W of coefficients for the basis vectors for a task. Now consider a permutation of the basis H, which leads to a permutation of W. This may change the cosine similarity when comparing two synergies.\n\n*W11.* It appears that $\\pi^*$ does not have access to the pre-grasp, while MyoDex does. I consider a policy \"$\\pi^*$ + pre-grasp\" to be a more fair point of comparison as it has access to the same amount of privileged information.\n\n*W12.* No network architecture details are presented. It is unclear how big (or small) the networks are. I suggest adding more details about the network to the main paper or appx.\n\n*W13.* It is hard to contextualize what a synergy is in Fig. 6 and what exactly 12 synergies means. Does this map to muscles firing together? Are there interpretable examples of these synergies that can be observed in the resulting behavior? Is it possible to have a human or scripted policy baseline here to contextualize what 12 synergies means?\n\n*W14.* The zero-shot protocol is not clear. MyoDex is conditioned on the goal object. What is the protocol for conditioning on an unseen object? How is the pre-grasp provided? I recommend adding details to make this section more clear.\n\n*W15.* How were multi-task and transfer task splits chosen? Are the tasks taken from the TCDM benchmark introduced in Dasari et al., 2022? If so, I strongly recommend citing the benchmark and making the benchmark setting details more transparent.\n\n*W16.* There are many holes in Tab. 1. Is it the case that these policies did not reach 0.8 success for these tasks? If so, I recommend making this more clear in the caption, so it is clear that these evaluation were actually run. Also I recommend reporting the success rate curves in the appx. so that future work can try to improve on this task subset.\n\n**Minor**\n\n*M1.* Consider not splitting 4.2 and 5.2 into different sections\n\n*M2.* 6.2 is not necessarily about task generalization, but about multi-task experiments. I feel these are different things and the title should be adjusted accordingly.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* The methodological contributions are limited, borrowing heavily from the Desari et al., 2022. However, this could be made more clear.\n* Extension of the MyoHand environment to include the shoulder is a novel contribution\n* The authors claim that 14 of the tasks in the paper were previously unsolved. Hence, the application of the method to these tasks represents empirical novelty and significance. \n* The paper is at time unclear with sections that logically may go together being separate (e.g., 4.2 and 5.2). Additionally several experimental details and protocols are unclear.\n* Only one seed seems to be used in evaluation calling into question the reproducibility and stability of the results.",
            "summary_of_the_review": "The paper explores the application of a method to grasp and manipulate objects with a biologically accurate hand model. The authors provide empirical evidence on the effectiveness of this method and additionally aim to understand the use of the method for multi-task-learning, transfer-learning, and qualitatively probe the resulting behaviors for synergies among muscle groups.\n\nHowever, I currently recommend weak rejection of the manuscript. I am most concerned about the clarity of the manuscript on key methodological and experimental details (*W1-3, 6, 9, 10, 12-15*), the fairness of the multi-task baseline (*W11*), and the lack of attribution to the Dasari et al., 2022 paper on key aspects of the methodological and task (*W4, 7, 15*). Additionally, I am not convinced that the task is non-trivial (*W7*).\n\nI am willing to revisit my evaluation during the rebuttal/discussion period.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_Sq1z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_Sq1z"
        ]
    },
    {
        "id": "T_j1EOAlOz",
        "original": null,
        "number": 3,
        "cdate": 1666613890963,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613890963,
        "tmdate": 1669963845091,
        "tddate": null,
        "forum": "TBaS6AqX_F_",
        "replyto": "TBaS6AqX_F_",
        "invitation": "ICLR.cc/2023/Conference/Paper4710/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a benchmark that touches on an interesting and important topic, musculoskeletal dexterous hand manipulation. The authors further demonstrate that pre-training the policy on 14 manipulation tasks allows for easier fine-tuning in both in-domain and out-of-domain tasks.",
            "strength_and_weaknesses": "\nStrength:\n1.\tThe proposed contact-rich manipulation tasks for the musculoskeletal dexterous agent are novel.\n2.\tMyoDex leverages joint multi-task learning to recover reusable representations (synergies) that allow for easier fine-tuning in both in-domain and out-of-domain tasks (including one/few-shot learning).\n\nWeaknesses\n1.\tAll the tasks in this paper seem based on grasping. The difficulties of these tasks are too homogeneous. Perhaps refer to these projects to design more tasks, such as [1] and [2].\n2.\tThe State Space contains the pose and velocity of the object without any vision-based input, thus resulting in missing geometric features of the object. This may limit the out-of-domain generalization ability. Recently, lots of dexterous hand works contain visual input with a strong generalization ability, such as [3] and [4].\n3.\tThere seem to be no ablation experiments on synergies.\n4.\tThe experiment seems to be done with only one seed, and the authors should consider doing several more seeds in order to better demonstrate the robustness of the method.\n5.\tThe previous work [5], which also presents a dexterous manipulation benchmark with musculoskeletal hands, detracts from the novelty of this work.\n\n[1] https://bi-dexhands.ai/\n[2] https://openreview.net/pdf?id=k2Ml8FGtJZp\n[3] https://openreview.net/pdf?id=k2Ml8FGtJZp\n[4] https://openreview.net/pdf?id=tJE1Yyi8fUX\n[5] https://arxiv.org/pdf/2205.13600.pdf\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and all the illustrations are clear to me.",
            "summary_of_the_review": "Overall, the paper is of good quality. However, the main contribution of this work is to demonstrate the effectiveness of pretraining the musculoskeletal dexterous agent, which I think is not enough for acceptance. I would consider increasing my rating if the authors could address my concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_sdCp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_sdCp"
        ]
    },
    {
        "id": "DVnZY_TSSOz",
        "original": null,
        "number": 4,
        "cdate": 1667073569613,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667073569613,
        "tmdate": 1667073569613,
        "tddate": null,
        "forum": "TBaS6AqX_F_",
        "replyto": "TBaS6AqX_F_",
        "invitation": "ICLR.cc/2023/Conference/Paper4710/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a reinforcement learning problem on MyoHand aiming at learning generalizable representation for manipulating different objects to finish different tasks. The authors designed an RL problem based on the previous MyoSim platform and trained agents to solve 14 tasks together. Grasp pose detection is applied to simplify the RL training. Experiments show that training together outperforms the baseline of first training experts separately and then distilling them into one policy through behavior cloning. Authors show that MyoDex, the agent trained to solve all tasks, has a certain level of zero-shot generalization ability and can be fine-tuned on single tasks. ",
            "strength_and_weaknesses": "Strength:\n\n- the paper constructs an environment for studying dexterous physiological manipulation problems.\n- The paper illustrates the potential of reinforcement learning in multi-task learning.\n\nWeakness:\n\n- Though the paper makes an effective empirical study of RL for dexterous manipulation, I wonder if this is a significant contribution given previous progress in learning dexterous manipulation with RL (Chen et al. (2021)). I do not see significant differences between a MyoHand and a ShadowHand for an RL agent.\n- For the baseline evaluation, simply running the supervised learning is not enough; it is better to use imitation learning, at least DAPG, to have some RL components to fine-tune the student agent.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, but the results are not novel to me.",
            "summary_of_the_review": "The paper presents a  study of training multi-task RL agents on MyoHand. I appreciate the efforts in designing tasks and running RL experiments. Still, the task of grasping and moving objects with a dexterous hand could be more novel, while the authors only use existing RL methods to solve this task without further improvements. Such contributions do not reach the acceptance bar. I suggest authors figure out challenges in dexterous hand manipulation and design or evaluate algorithms, showing the value of studying such problems.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_RfAu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4710/Reviewer_RfAu"
        ]
    }
]