[
    {
        "id": "cgecSdMDrO",
        "original": null,
        "number": 1,
        "cdate": 1666216913201,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666216913201,
        "tmdate": 1666542732062,
        "tddate": null,
        "forum": "vhFu1Acb0xb",
        "replyto": "vhFu1Acb0xb",
        "invitation": "ICLR.cc/2023/Conference/Paper1759/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The submission benchmarks a transformer-based approach to background planning in the Atari 100k benchmark. The submission finds that its approach outperforms existing methods that have benchmarked on Atari 100k, excluding those that use decision-time planning.",
            "strength_and_weaknesses": "### Strengths\n\n- Loosely speaking, existing successful MBRL algorithms are modifications of Dreamer or MuZero. Showing that another framework for MBRL can be successful is a valuable contribution.\n- The submission largely follows the guidelines for benchmarking laid out by the statistical precipice paper.\n\n### Weaknesses\n\n- At least in my opinion, Atari 100k is not particularly well benchmarked. I would say that the only \"good\" algorithm that has been benchmarked by experimenters incentivized to tune the algorithm to maximize performance is EfficientZero. Thus, the extent to which IRIS is good is a bit unclear to me. It would be interesting to see how IRIS performs on the standard Atari benchmark (or, inversely, how something like Dreamer compares to IRIS on Atari 100k).\n- The statistical precipice paper suggests that results on Atari 100k are reliable (under appropriate metrics) with as few as 10 runs; the submission only uses 5 runs. My gut feeling is that the margin of improvement under various metrics seems substantial enough that it would probably continue to hold under a more reliable number of runs, but it would be good to actually show this.\n\n---\n\nAddendum:\nI also concur with reviewer t9Kq: 1) the submission would benefit from additional attention to related work (such as [1],[2],[3]) and 2) additional ablations.\n\n### Comments on decision-time planning:\n\nThe submission argues: \"Moreover, IRIS could be combined with MCTS, both in imagination and in the real environment. Therefore, methods involving lookahead search should not be seen as direct competitors but rather as potential extensions to learning-only methods.\" In principle, this is of course true. However, as a matter of practice, I am not sure it is as clear. I am not aware of any examples of a non-MuZero-like architecture successfully utilizing decision-time planning. It is plausible to me that algorithms like Dreamer and IRIS, which perform well in a background planning regime, may not enjoy much benefit from decision-time MCTS.\n\n### Comments on superhuman performance:\n\n> Most notably, human experts were surpassed by deep RL algorithms in a multitude of arcade (Mnih et al., 2015; Schrittwieser et al., 2020; Hafner et al., 2021), real-time strategy (Vinyals et al., 2019; Berner et al., 2019), board (Silver et al., 2016; 2018; Schrittwieser et al., 2020) and imperfect information (Schmid et al., 2021; Brown et al., 2020a) games.\n\nI find this sentence is misleading. Deep RL algorithms have not surpassed human experts in most Atari games, as is clearly evidenced by the human world record metric. They have also not surpassed human experts in StarCraft (AlphaStar is only grandmaster level) or DOTA (OpenAI5 played a restricted version of the game and was found to be reliably exploitable by humans).",
            "clarity,_quality,_novelty_and_reproducibility": "The submission is clear, of high quality, and novel. The submission includes code.",
            "summary_of_the_review": "The submission shows a qualitatively novel approach to MBRL can, to some extent, be successful. My main gripe is that the submission shows these results in a domain that is, in my opinion, not well benchmarked; thus, IRIS's strength as a MBRL algorithm is a bit unclear to me. Nevertheless, I think the evidence presented in the submission is sufficiently strong to merit acceptance as is.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_fmDi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_fmDi"
        ]
    },
    {
        "id": "M-BcYohum4",
        "original": null,
        "number": 2,
        "cdate": 1666511865132,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666511865132,
        "tmdate": 1669521071930,
        "tddate": null,
        "forum": "vhFu1Acb0xb",
        "replyto": "vhFu1Acb0xb",
        "invitation": "ICLR.cc/2023/Conference/Paper1759/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a miniGPT-like transformer architecture for learning the world model of RL agents in POMDP environments. This World Model's training data is derived from the present policy model's interplay with the real world. The input and output images are then represented in\u00a0the VQGAN-style and utilized to train the global model. Finally, the policy function of the RL Agent is trained using the fictitious world model data. The authors demonstrate the efficacy of this method on the Atari 100k benchmark, which achieves a mean human\nnormalized score of 1.046, and outperforms humans on 10 out of 26 games with two-hours training data.",
            "strength_and_weaknesses": "\n[Pros]\n* The paper is well-writen and clear to read. the effieciecency and effacacy are good on the atari100k benchmark.\n* The code is clear and easy to follow.\n\n[Cons]\n* Noveltiy is insufficient (Some disucussion to [1][2][3] would be appreciated)\n* Increasing the number of ablations and analyses to improve comprehension of the contributions of various designed parts.(e.g. different tokenizer, backbone)\n\n[1] TRANSDREAMER: REINFORCEMENT LEARNING WITH TRANSFORMER WORLD MODELS https://arxiv.org/pdf/2202.09481.pdf \n[2] Reinforcement Learning with Action-Free Pre-Training from Videos, https://arxiv.org/pdf/2203.13880.pdf\n[3] Online Decision Transformer, https://arxiv.org/pdf/2202.05607.pdf\n\n\n*Some typos: sec2.2 blue arrow-> purple? arrow",
            "clarity,_quality,_novelty_and_reproducibility": "The article is very well read and the information given is very clear. My main concern could found above.",
            "summary_of_the_review": "Overall, I think this article is worth reading and being published, as it explores the possibilities of using Transformer to learn World Model. Although I am not a Big Fan of the World model, which breaks down reinforcement learning into learning a simulater for the environment and then learning it, I still endorse the paper's conclusion that Transformer-based architectures (Vit, Swin, etc.) can encode image inputs into a series that can be easily understood and learned tokens.\n\nHowever, I still hope the author can give more in-depth understanding, such as how the encoding of the world-model itself accounts for this task, and whether the pure necessity of the world-model itself is sufficient (e.g., the same backbone structure of the A2C agent can be used, etc.)\n------------------------------------------------------------------------------------------------------\nI have raise my score to 8, while there are still many details I'd like to know about this paper, overall, I'm inclined to think it deserves to be published.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_t9Kq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_t9Kq"
        ]
    },
    {
        "id": "VYn0-yL2MqN",
        "original": null,
        "number": 3,
        "cdate": 1666755060487,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666755060487,
        "tmdate": 1670959822407,
        "tddate": null,
        "forum": "vhFu1Acb0xb",
        "replyto": "vhFu1Acb0xb",
        "invitation": "ICLR.cc/2023/Conference/Paper1759/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes IRIS, which uses a world model to train agents. The world model consists of a discrete autoencoder and an autoregressive Transformer.\n\nThe discrete autoencoder $(E, D)$ consists of an encoder $E$, which converts an input image to tokens, and a decoder, which turns tokens back to an image. Given previous tokens and actions, the autoregressive Transformer then models (1) the transitions to next token; (2) reward; (3) termination of the episode.\n\nThe world model is then used to train an actor-critic method using standard reinforcement learning (RL) objectives.\n\nThe authors conducted experiments on Atari 100k benchmark. After 100k actions (about 2 hours of human gameplay experience), the proposed IRIS method can outperform several other baselines including SimPLe, CURL, and DrQ, and it outperforms human players on 10 out of 26 games.\n\nThe authors also show results of the good prediction ability of Transformer world models in terms of accurately predicting next status of Atari game images, and rewards. Some drawbacks of the world models, such as inability of predicting some games with multiple layers are also discussed.",
            "strength_and_weaknesses": "**Strength**:\n\n1. Using Transformers as world models in model-based RL seems novel.\n2. The results are promising.\n\n**Weaknesses**:\n\n1. Although it is emphasized in the paper that sample efficiency should be a main consideration for model-based RL methods, I think training for a longer time and show that the proposed methods can achieve good results on most games would also be worth considering to verify the proposed models.\n2. The objectives of training the autoencoder and Transformer is missing in the paper and in the appendix (only mentioned by a few sentences). It would be better to also include those settings in the appendix.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, and the models and results are clearly presented. The idea of using Transformer as world models is interesting and novel to me.",
            "summary_of_the_review": "Overall, this work studies an interesting idea of using Transformer as world models in model-based RL, and the promising experimental results support the proposed methods well.\n\n**Update after rebuttal**:\n\nI would like to thank the authors for the feedback, which addressed my main concerns. I increased my score accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_CZra"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_CZra"
        ]
    },
    {
        "id": "6Tcp3D1UJM",
        "original": null,
        "number": 4,
        "cdate": 1666955353169,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666955353169,
        "tmdate": 1666955353169,
        "tddate": null,
        "forum": "vhFu1Acb0xb",
        "replyto": "vhFu1Acb0xb",
        "invitation": "ICLR.cc/2023/Conference/Paper1759/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Authors train very impressive agents for the 100K Atari benchmark. The method consists in representing Atari frames with discrete tokens and training a transformer-based world model and a game agent. The transformer model is trained in a supervised way. The agent is trained entirely using frames from the world model. ",
            "strength_and_weaknesses": "Strengths:\n\n1. Simple and easy-to-understand learning algorithm.\n2. Well-thought-through reuse of standard modeling and algorithmic components.\n3. Outstanding results on Atari 100K benchmark, in particular, bearing in mind the limited compute and expressivity of models.\n\nWeaknesses:\n\n1. Models and agents are trained per game. I am curious what would happen if one tries to train a multi-game world model and agent in the spirit of Gato https://arxiv.org/abs/2205.06175 or Multi-game decision transformers https://arxiv.org/abs/2205.15241. \n2. Nit: the paper may benefit from using more modest language. I mean, in particular, the \u201cdrastically different architecture\u201d claim or not very elegant comparisons to look-ahead algorithms.\n\nA bug that may turn into a feature:\n\nThe method needs \u201cmore tokens\u201d for games that require the detailed representation of images (as authors put it: \u201cAnother kind of games difficult to simulate are mazes with moving enemies, such as MsPacman, BankHeist, and Alien\u201d). This characteristic seems to be a limitation but may lead to an interesting long-context benchmark. Some environments may require more frames and details, leading to a new dataset that can be used to benchmark long-context transformer models.",
            "clarity,_quality,_novelty_and_reproducibility": "Creative repurposing of existing components. The method seems to be easy to use and re-implement.",
            "summary_of_the_review": "Authors train very impressive agents for the 100K Atari benchmark.  Benchmark results are excellent but algorithmic, and modeling novelty is limited.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_Knzj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1759/Reviewer_Knzj"
        ]
    }
]