[
    {
        "id": "QP6bdYST8I",
        "original": null,
        "number": 1,
        "cdate": 1666192134621,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666192134621,
        "tmdate": 1670166079281,
        "tddate": null,
        "forum": "d8tJcOxnzF9",
        "replyto": "d8tJcOxnzF9",
        "invitation": "ICLR.cc/2023/Conference/Paper5248/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors study an inverse online multiobjective problem. In particular, the learner noisily observes a sequence of decisions made by a decision-maker. The learner's goal is to infer the parameters of the multiple objectives used by the decision-maker.\n\nThe authors give an online learning algorithm for this setting that achieves $1/\\sqrt{T}$ regret under some regularity conditions\u2014namely strong convexity of the individual objectives and Lipschitzness in how the decision changes as a function of the parameters. A key issue is efficient computation of the efficient frontier and how approximation affects algorithm performance. Motivated by the theory, the authors introduce an accelerated variant.\n\nIn the experiments, the authors illustrate the estimation error of each algorithm, its computational cost and how well its estimated efficient set matches the true one.",
            "strength_and_weaknesses": "Strengths:\n- The setting and algorithm appear novel.\n- The experiments provide a nice evaluation of the two variants of the algorithm.\n\nWeaknesses:\n- The alignment between the work and motivation seems a bit off. The most natural motivation from my perspective is being able to predict the decision better under unseen settings where we have some salient information, such as new estimated returns and risks in the portfolio optimization setting. As it stands, nothing appears to change between observed decisions except the realized noise\u2014so there doesn't seem to be a strong reason to infer the parameter vector $\\theta$.\n- The authors also gesture towards suboptimality of the observed decisions, which seems like a relevant problem, but their model doesn't really accommodate this because the noise is simply added to the decisions themselves. I was expecting to see noise added farther upstream\u2014either to the objective functions themselves or to the parameters $\\theta$.\n- The sequence of intro to related work is poorly written, in my opinion, starting from about the second paragraph. The end of the intro serves as a mini related work section on its own, but it doesn't make clear what the authors' contributions are in detail or directly clarify what is different from past work.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: there are many sections where the writing could be improved. See also strengths and weaknesses. I found the math reasonably clear (but did not check all details).\n- Use parenthetical citations (\\citep) instead of \\citet\u2014see the instructions in the template\n- The phrase \u201cactually carries the data-driven concept\u201d appears several times and I don\u2019t know what it means\n- Bottom of pg. 3\u2014loss lunction\n- I didn\u2019t follow the last sentence of Remark 2.1\u2014what is strict convexity buying us here?\n- Put the \\ref in parentheses when referring to equations (or write Eq.~\\ref{})\n- Assumption 3.1 \u201crelatively interior\u201d\n- Sec 4 1st para \u201cGurobi Gurobi\u201d\n\nQuality: see strengths and weaknesses. The work solves a problem, but it's more of a potential building block for a larger problem.\n\nNovelty: the work builds on past work, but from a skim of past work, appears sufficiently distinct.\n\nReproducibility: the algorithms are described sufficiently. I do not see details about a code release.",
            "summary_of_the_review": "The work takes a new incremental step that \\emph{may} be in the direction of solving an interesting problem.\n\nPost-response:\nI am somewhat convinced by the authors' response but not fully. (The updated version also fails to fix many of the small presentational issues that the paper has).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_4Sxk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_4Sxk"
        ]
    },
    {
        "id": "Bb8kJIo901",
        "original": null,
        "number": 2,
        "cdate": 1666258490273,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666258490273,
        "tmdate": 1666258490273,
        "tddate": null,
        "forum": "d8tJcOxnzF9",
        "replyto": "d8tJcOxnzF9",
        "invitation": "ICLR.cc/2023/Conference/Paper5248/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of inverse multiobjective optimization via online learning. Under some assumptions, the authors prove that an ideal online implicit update method has the regret bound of $O(\\sqrt{T})$. However, this ideal method cannot be implemented in practice. To address this problem, the authors proposed two approximate variants of this ideal method, which are heuristic.",
            "strength_and_weaknesses": "#Strength\n1) The problem of inverse multiobjective optimization is interesting.\n2) The authors propose an ideal online implicit update method with the $O(\\sqrt{T})$ regret bound, and provide two efficient variants of this ideal method.\n\n#Weaknesses\n1) Dong et al. (2018) have studied inverse optimization via online learning and proposed an online method with $O(\\sqrt{T})$ regret bound. Although this paper further considers the inverse multiobjective optimization, which is more general than Dong et al. (2018), both the ideal online implicit update method and the regret bound are very similar to those in Dong et al. (2018), which limits the novelty of this paper.\n2) Compared with Dong et al. (2018), the additional challenge faced by this paper is caused by the non-existence of the closed form of the efficient set. The authors address this challenge by approximating the efficient set with a sampling approach. However, the authors do not provide theoretical guarantees about the approximation error.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to follow. The theoretical analysis seems to be correct, and enough details of experiments are provided. However, given the existing work of Dong et al. (2018), the novelty of this paper is limited.\n\nMoreover, there are some suggestions.\n1) The caption of Figure 1 has some typos. For example, we cannot find Figure 1(e).\n2) In Figure 1, the authors only compare the running time between the batch setting and online setting. The authors may also compare the error between the batch setting and online setting.\n3) In Figure 1(b), the run time of Alg. 1 and Alg. 2 are stacked, which is not convenient for comparison.",
            "summary_of_the_review": "From the above comments, I think this paper is marginally below the acceptance threshold.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_SLew"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_SLew"
        ]
    },
    {
        "id": "SsZMe9VQ0Ii",
        "original": null,
        "number": 3,
        "cdate": 1666677935399,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666677935399,
        "tmdate": 1671491078051,
        "tddate": null,
        "forum": "d8tJcOxnzF9",
        "replyto": "d8tJcOxnzF9",
        "invitation": "ICLR.cc/2023/Conference/Paper5248/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is very technical and I'll first say I am not familiar with the literature. However, as somewhat an \"outsider\" to this problem, hopefully I can contribute by asking the right questions, which can help the author make this work more accessible.\n\nMy naive understanding of this paper is that it's basically doing reward learning (or inverse reinforcement learning). Given a black box agent with some latent reward function (of a particular form, that of min of bunch of other functions), we can observe the agent's actions to infer what the reward function is. The observations come sequentially, but we do not get to control what observation to make.",
            "strength_and_weaknesses": "strength : It tackles a new problem of multi-objective reward learning, of a particular form: min(f1(x,\\theta) ... fn(x,\\theta)). The paper was able to take this special form, along with some assumptions, to develop a set of update-rules to guess what \\theta can be as online observations come in. Even if the user (like me) does not grasp the full derivation, this algorithm can easily exist in a package to be used as black box.\n\nweakness : for me the paper is easy to follow wherever it is self-contained, but then some thm or corr. was invoked, and this \"jump\" makes the paper hard to follow. however this is unlikely to be an issue with people familiar with the field.\n\nI do have some questions, which would be great to have answered:\n\n1. when we say the agent is minimizing regret, does it mean it is sufficient agent comes up with a hypothesis that explains the data as well as the original \\theta, rather than trying to infer the original \\theta itself?\n\n2. I always find the connection between bandit-like literatures and bayesian inference related, yet the two use very different language. For me, I'd think we just put some prior over the hypothesis P(\\theta), and we do posterior inference of P(\\theta | Data) while assuming some forward data generating process P(Data | \\theta). Or more simply, we can find the maximum-likelihood estimator without the full posterior. There must be a good reason why this kind of language isn't the way to explain your work, but what is it? \n\n3. How would the problem change if you are allowed to take active samples? i.e. present the agent with a scenario as a query, and see how it respond to it in the style of active learning. Can your approach be made to work in this setting? How would you select a query? How would you select a query without making some distributional assumptions of the objective function, other than it is a min of a bunch of functions ? ",
            "clarity,_quality,_novelty_and_reproducibility": "clarity : it appears good -- I can follow everything until 2.2.1\n\nnovelty : the authors claims that nobody has worked on the problem of inferring parameters for the form min(f1(x,theta1)...) before, so this work is novel.\n\nquality : appears to be good",
            "summary_of_the_review": "from a non-expert point of view, this paper can result in an artifact that can exist in scipy as a black-box, which is definitely a contribution. I would defer technical correctness to an expert.\n\nafter discussion with other reviewers, who knows the work better, I'm lowering my score to a 6.\nI still think this work is interesting though.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_QnFE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5248/Reviewer_QnFE"
        ]
    }
]