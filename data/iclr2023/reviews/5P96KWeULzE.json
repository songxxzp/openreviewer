[
    {
        "id": "Ya9TRLkbQzi",
        "original": null,
        "number": 1,
        "cdate": 1666383530956,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666383530956,
        "tmdate": 1666383530956,
        "tddate": null,
        "forum": "5P96KWeULzE",
        "replyto": "5P96KWeULzE",
        "invitation": "ICLR.cc/2023/Conference/Paper1733/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces \u2206-PINNs, a novel form of physics-informed neural networks (PINNs) that leverages the eigenfunctions of the Laplace-Beltrami operator of the manifold to represent the geometry of a 3D solid. This advancement would expand the use of PINNs from simple geometric domains to more complex forms. The paper goes into great detail on how this method is implemented and presents multiple test cases comparing against baselines such as previous PINNs or ground-truth, showcasing that the proposed method outperforms prior PINNs and more closely matches ground-truth observations.",
            "strength_and_weaknesses": "The paper is overall strong; the language is clear, the problem being solved is made obvious, and the effectiveness of the proposed solution is presented in a convincing manner. Though I am not an expert on the mathematics being utilized, I was still able to follow the logical procession of the equations even if I could not grasp the details. The figures and visualizations were not confusing, and the captions served well in clarifying what little doubt the figures may have presented.\n\nHowever, the one potential weakness I see is the mention of the finite element method. I happen to know what that is, and I am sure an audience with a general physics background would know what that is, but given that this is a CS-focused paper, perhaps a paragraph explaining what the finite element method is and how it works would be helpful to offer further understanding for those readers that would not know what it is. Given that understanding the finite element method is important for understanding the methodology of the paper, I believe this would be a worthwhile addition.\n\nIn addition, a concrete example of how physics informed network is used in Section 2.1 will help the readers to understand the contribution better. I happen to work in this domain, so I know the meaning of the three MSEs. However, I doubt if people outside of our domain understand the need of using these three terms.\n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned in the strengths section, the clarity and quality of writing is good but have room for improvement. The method is not necessarily wholly novel, but it is a culmination of prior work that has clearly taken this field of research to the next level. It is clear that the authors have taken steps to ensure their work is reproducible by making mentions of accompanying code and referencing the prior work on which the code is built.",
            "summary_of_the_review": "This paper makes a good contribution towards physics-informed neural net, by leveraging the eigenfunctions of the Laplace-Beltrami operator of the manifold to represent the geometry of a 3D solid. The paper possesses good clarity of expression, a well-explained proposal, and does not stumble in convincing the reader and expanding knowledge. Other than a small suggestion to include an explanation of the finite element method and relevant applicational domain, I believe this paper is worthy of being accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_yokT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_yokT"
        ]
    },
    {
        "id": "c0QgQm_UFs",
        "original": null,
        "number": 2,
        "cdate": 1666622055815,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666622055815,
        "tmdate": 1666622055815,
        "tddate": null,
        "forum": "5P96KWeULzE",
        "replyto": "5P96KWeULzE",
        "invitation": "ICLR.cc/2023/Conference/Paper1733/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a novel positional encoding mechanism to inform PINNs about the topology of the domain, expanding the effectiveness of PINNs to complex geometric domains. The proposed positional encoding mechanism represents the coordinates of the input geometry with the eigenfunctions of the Laplace-Beltrami operator of a manifold, creating an input space for PINNs that represents the input geometry. Extensive numerical experiments (mainly in 2D) were carried out to compare the proposed methodology against traditional PINNs, showing excellent agreement with ground truth for cases where traditional PINNs fail.",
            "strength_and_weaknesses": "Strength: \nThe proposed methodology enables the PINNs to solve problems defined on complex geometric domains with good accuracy.\n\nWeakness:\n1. The differential operators in the PDEs cannot be computed directly from PINNs using AD after applying the positional encoding method. Instead, they are computed numerically on the linear finite elements.\n2. Computing the eigenfunctions of the Laplace-Beltrami operator on large meshes can be very expensive.\n3. The performance of the proposed method strongly depends on the number of eigenfunctions used for positional encoding, while this quantity is a hyper-parameter needs to be tuned case by case.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well written, the description is precise and easy understanding.\n\nThere are some minor problems in the paper: in Figure 3 the result of \u201c\\delta-PINNs not informed by the heat equation\u201d is not included, the caption should be amended as well as the following explanation text; the review of the Laplace-Beltrami eigenfunctions in Section 4 Discussion is suggested to put in Section 1 Introduction.\n\nThe novelty is fair. It is the first time the Laplace-Beltrami eigenfunctions is used in PINNs, while the methodology itself is not novel and has been applied in other neural networks.\n\nThe reproducibility is good.",
            "summary_of_the_review": "The paper proposed a novel positional encoding mechanism to inform PINNs about the topology of the domain, expanding the effectiveness of PINNs to complex geometric domains. While the weakness of the proposed methodology is as distinguishable as its strength, the computation cost and the implementation complexity of the proposed methodology can be higher than the traditional PINNs, making it less promising.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_vdFL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_vdFL"
        ]
    },
    {
        "id": "dxwQbkQrqW",
        "original": null,
        "number": 3,
        "cdate": 1666663817636,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663817636,
        "tmdate": 1666663817636,
        "tddate": null,
        "forum": "5P96KWeULzE",
        "replyto": "5P96KWeULzE",
        "invitation": "ICLR.cc/2023/Conference/Paper1733/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose a PINN-style network where the physical quantities are computed on a manifold. The manifold geometry of the data is represented via a positional encoding based on the eigenfunctions of the Laplace-Beltrami operator of the manifold,  propose to represent the coordinates of the input geometry with a positional encoding. The Laplace-Beltrami operator as well as the eigenfunctions are estimated using a finite element solver.  \n\n",
            "strength_and_weaknesses": "Strengths: \nThe authors\u2019 clearly motivate the need to incorporate geometric/topological information into their method. A nice feature of encoding the NN with eigenfunctions of the Laplace-Beltrami Operator over the domain is being able to hand select the eigenfunctions based on the magnitude of the eigenvalue given prior knowledge about the nature of the problem\n\nWeaknesses:\nHowever, they don't justify their choice of computing eigenfunctions of a continuous Laplace-Beltrami  is their approach. As they say, there is no closed form available, and they could have gone with a graph approach with a graph laplacian. In this setting there are neural networks that directly compute the eigenvectors of graph laplacians, for instance PowerEmbedd from this paper https://arxiv.org/abs/2209.12054.  Thus this whole approach could have been done with a GCN. This is not included as a comparison. In general, numerical experiments aren\u2019t extremely convincing \u2013 need more ablations/comparisons to other types of networks but PINN and non-PINN ones such as GNNs, transformers, etc.  ",
            "clarity,_quality,_novelty_and_reproducibility": "Some aspects of the experimentation are not clear. \n-In Figure 1, which/how many eigenfunctions did you use to get a solution of the Laplace-Beltrami operator on the manifold. Also the figure caption needs to be more descriptive. (e.g. the color bar for geodesic is confusing to have before explaining in section 3 that the solution to the Eikonal equation can be interpreted as a geodesic distance to any point in manifold)\n-How did you select the 50 eigenfunctions for input into the NN? Perhaps there is a principled way to learn which and how many eigenfunctions could be included in the mesh.\n-IN section 2.3 the authors need to elaborate on how they computing the numerical approximation and extracting the gradients \u2013 this seems to be a key part of the method\n-- Bottom of page 5:  these numbers should be listed in a table or with the figure.\n\n\n\n",
            "summary_of_the_review": "At a high level the manuscript is well-principled and the authors explain conceptually how they incorporate geometry into the PINN. The paper does have drawbacks \u2013 one of the major concerns is the lack of comparisons to the other neural networks or geometric-informed PINNs that the authors mentioned. Additionally, the authors could provide more detail on how they numerically approximate the Laplace-Beltrami operator and the finite element scheme/package that was used. Overall, the idea is nice but the impact is not distinguished and its unclear how their method compares to others. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_ebMA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1733/Reviewer_ebMA"
        ]
    }
]