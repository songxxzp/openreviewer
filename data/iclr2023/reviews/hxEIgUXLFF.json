[
    {
        "id": "Yl3NMFTtB2",
        "original": null,
        "number": 1,
        "cdate": 1666602787758,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666602787758,
        "tmdate": 1668777580673,
        "tddate": null,
        "forum": "hxEIgUXLFF",
        "replyto": "hxEIgUXLFF",
        "invitation": "ICLR.cc/2023/Conference/Paper3215/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a specific masking strategy on each client that leads to two outcomes; 1) adhering to the computational constraints of each client and 2) improving the personalised model performance. Instead of prior works that \u201czero out\u201d the masked parameters, this work instead \u201cfreezes\u201d the masked parameters to the values communicated by the server. While strictly speaking this leads to less efficiency gains, the benefit is that each hardware constrained client can maintain the flexibility of the server model, while still being able to contribute in training (a part of) it. To optimise the masking assignment, the authors formalise it as a constraint satisfaction problem that targets to minimise the theoretical convergence bound bias coming from masking. As the latter is an NP-hard problem, the authors propose a specific approximation procedure that seems to empirically work. Finally, the improvement to the personalised model performance comes from also adopting the FedBABU strategy, i.e., splitting the learning of the body and head of the network; the head is frozen and kept local while training the (masked) global body and when the body has converged, the entire network is fine-tuned locally with the available data samples. The authors perform extensive experiments and ablation studies to show the performance of PerFedMask in various settings. ",
            "strength_and_weaknesses": "Strengths\n- Extensive experimental evaluation\n- Theoretical analysis of convergence\n\nWeaknesses:\n- Server side optimization problem for masking does not consider FLOPs directly (which is a better proxy for computational cost, e.g., convolutional layers are more computationally expensive that linear ones, however the latter have more parameters) \n- Incremental; mostly a combination of FedBABU + freezing methods (such as CoCo-FL)\n- No indication of uncertainty / error bars in the results (so unclear whether the gains in some cases are significant) ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear and relatively straightforward to follow. One thing that could be improved in the exposition is Eq. 1; it is not entirely correct for FL, as this objective can be solved without the devices communicating altogether since the optimization problems are independent. FL seeks consensus between the local models, which is what correlates the optimization problems and creates the global model. I would advise the authors to update it. Other than that, I believe that there is reasonable information to be able to reproduce some of the results, although I would have liked some more information on the optimization specifics for the SCA algorithm implementation (e.g., an algorithm, hyperparameters it have, etc). \n\nIn my opinion, the main drawback of this work is novelty. As far as I understand, the personalization component is just an application of FedBABU whereas the freezing part comes from the likes of works such as CoCo-FL. The novelty of this work thus seems to lie on the convergence analysis which leads to the uncovering of the convergence bound bias and the server side algorithm to fix it. Having said that, there is no comparison against the heuristic strategy proposed at CoCo-FL so it is hard to tell its significance compared to prior art. \n\nFinally, some more questions from my side:\n- It is a bit weird that in Table 3, more finetuning steps can be harmful. Is it due to overfitting on the local dataset that this happens? \n- What is the importance of freezing the local heads on each client? How does the method perform without the local head freezing?\n",
            "summary_of_the_review": "Based on all of the above, and primarily due to my novelty concerns, I cannot recommend acceptance. This work could benefit by better positioning in terms of works such as CoCo-FL and by making more clear the improvements that it brings to the table. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_pTHn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_pTHn"
        ]
    },
    {
        "id": "AoDBJ7Cq-CK",
        "original": null,
        "number": 2,
        "cdate": 1666673829483,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673829483,
        "tmdate": 1666673829483,
        "tddate": null,
        "forum": "hxEIgUXLFF",
        "replyto": "hxEIgUXLFF",
        "invitation": "ICLR.cc/2023/Conference/Paper3215/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The author proposes to replace the random mask in FedBABU with a masked optimized for the device heterogeneity. The proposed masking is layer-wise so that all parameters in a layer will be frozen or not, based on the formulation Eq(10). Empirical evaluation shows better performance, less trainable parameters and FLOPS.",
            "strength_and_weaknesses": "Strengths:\n1. The motivation to let devices with more computational resources to do more training makes sense.\n2. There are empirical benefits of the proposed method regarding the accuracy and FLOPS.\n\nWeaknesses/Questions:\n1. How is \\phi_g updated?\n2. Can you show and compare the training curves?\n3. Can you confirm that among those devices with lower computational capacity, a higher computational capacity leads to more trainable parameters?\n4. In Eq (1), the \\theta_n in f_n(\\theta_n) is the concatenation of w and \\phi. However, in section 4 the arguments becomes w, contradicting the previous definition. What are the definitions of F_n and f_n exactly? Why theorem1 is not affected by data heterogeneity?\n5. In remark 1, minimizing upper bounds does not mean it is the best way.\n6. There is a lacking in the empirical validation for the benefits (e.g., time) of the proposed method when applying to heterogeneous devices.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. The novelty is a little bit incremental given the existing work FedBABU.",
            "summary_of_the_review": "The motivation of applying customized mask to FedBABU seems valid, but it is not surprising to see the empirical improvements. There are multiple aspects to further improve the paper as stated in weaknesses.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_nizq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_nizq"
        ]
    },
    {
        "id": "kgnOPbOfia",
        "original": null,
        "number": 3,
        "cdate": 1666701707313,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701707313,
        "tmdate": 1669730813036,
        "tddate": null,
        "forum": "hxEIgUXLFF",
        "replyto": "hxEIgUXLFF",
        "invitation": "ICLR.cc/2023/Conference/Paper3215/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work studied masked federated learning (FL) for device-heterogeneous settings. The theorems on the convergence of masked FL revealed the limitation of existing masking strategies that induced biases to the model convergence. Therefore, the authors propose to optimize the per-client masks on the server. Empirical results demonstrate that the proposed method can improve multiple existing masked federated learning methods.",
            "strength_and_weaknesses": "Strength\n* The method is principled and motivated by the theoretic analysis of convergence. It is novel that the authors show the bias induced by heterogeneous masking. The finding reveals the critical upper bound of empirical studies of masked federated learning so far.\n* Because of the general non-convex and masking-agnostic assumptions, the method can be integrated with different masked federated learning methods, like HeteroFL, Split-Mix FL, etc. \n* The experiments also demonstrate that optimizing masks could improve different baselines. Therefore, the theorems and methods are generalizable and could be impactful in device-heterogeneous settings.\n\nWeakness\n* The method is motivated by the bias on the theoretic convergence bound. But the intuition behind the bias is not well-explained. The authors may elaborate on why the bias occurs. Instead of attributing the bias to the masking, it should be discussed how the bias is related to the heterogeneity. If all clients follow the same mask, how will the bias be? If all clients follow non-overlapped masks, will the bias be maximized? When the mask makes the bias minimized if can all clients afford the same number of parameters?\n* Authors provided two techniques for solving (10a-d). More details about how to choose one of the two techniques should be provided to ease the practice.\n* How does the method work on feature non-iid datasets? Since Split-Mix FL has shown that the HeteroFL would perform poorly on feature non-iid datasets, the Split-Mix FL based evaluation should be conducted on feature non-iid datasets.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: The method has been compared to multiple baselines under two datasets. It would be better if the authors could provide more datasets.\nNovelty: The proposed method is novel, and the insights are also novel through the lens of convergence.\nClarity: The writing could be improved by making the formulations more concise and by elaborating on theoretic results. Some notations should be more meaningful. For example, when *the normalized mask* (k_n)_l is introduced, the meaning of the term should be explained, in addition to its formulation.  Lemma 1 is not explained. Especially how it is used for proving Theorem 1? In Theorem 1, the meaning of each term should be explained more. \n\nMinor issues with the clarity.\n* The heads model should be head models.\n* In the first sentence of the 2nd paragraph of Page 2, \"may lead to a bias in the obtained solution of the learning model,\" is confusing. I suppose the bias should be on the convergence error rather than the model itself.",
            "summary_of_the_review": "The paper provides a novel insight into masked federated learning, which should be valuable for device-heterogeneous federated learning. Some issues on the clarity and experiments should be addressed during the rebuttal.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_Frgf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3215/Reviewer_Frgf"
        ]
    }
]