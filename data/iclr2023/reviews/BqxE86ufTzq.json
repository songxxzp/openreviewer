[
    {
        "id": "d5bo5V7aSz",
        "original": null,
        "number": 1,
        "cdate": 1666618109869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618109869,
        "tmdate": 1668919153112,
        "tddate": null,
        "forum": "BqxE86ufTzq",
        "replyto": "BqxE86ufTzq",
        "invitation": "ICLR.cc/2023/Conference/Paper361/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of domain generalization. The authors propose to reduce the gradient conflict between the gradient biased toward the source domains and the unobservable gradient that could minimize risks in unseen domains. Specifically, the authors leverage the large-scale pre-trained model as a loose approximation of the oracle model for the unseen domains and propose a simple yet effective method called GESTUR. In GESTUR, a fast-update model called task expert (TE) is directly optimized on source domains with calibrated gradient. A slow-update model called generalization expert (GE) is EMA updated by TE and provides the approximated unobservable gradient for calibration. Empirical results on five popular domain generalization benchmarks show that GESTUR outperforms other methods.",
            "strength_and_weaknesses": "### Pros\n1. The proposed method GESTUR is simple and well-motivated.\n\n2. GESTUR is competitive on various domain generalization benchmarks, verified by empirical results.\n\n3. The analysis and ablation are comprehensive, well justifying the proposed method.\n\n### Cons\n1. The hyperparameter $\\lambda$ is very sensitive to domain generalization tasks, as verified by Table 5 and B.2 in the appendix. I am still confused about how to choose $\\lambda$? What does \"while those of the unseen domain are used for hyperparameter search.\" in Section 3.1 mean? DomainBed provides three model/hyperparameter selection protocols, which protocol does this paper adopt, source validation set, oracle test-domain validation set, or leave-one-domain-out cross-validation?\n\n2. In MIRO paper, MIRO can combine with SWAD to further improve the generalization performance, average accuracy of 68.1 for the ResNet-50 model. How about GESTUR in this paper? \n",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity: This paper is well-organized and has a smooth presentation flow.\n2. Quality: The method is well-motivated and the experiments are convincing.\n3. Novelty: The proposed method GESTUR is novel in terms of the gradient calibration by a slow-updated large-scale pre-trained model.\n4. Reproducibility: Codes and implementation details are provided for good reproducibility.",
            "summary_of_the_review": "This paper proposes a simple yet effective method for domain generalization. Extensive experiments well justify the advantage of the proposed method. My main concern is how to select the sensitive hyperparameter $\\lambda$ without accessing unseen target domain data.\n\n***********Post-rebuttal**************\nAfter reading all the discussions and reviews, I share the same concern on the novelty of this submission as Reviewer seAG and Reviewer TqRb. Also, I also agree with Reviewer ENaU that the feasibility and reliability of using large-scale pre-trained models as a loose approximate of unseen domains are not provable, limiting the proposed method. Therefore, I decided to decrease my rating to 5.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper361/Reviewer_e3A6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper361/Reviewer_e3A6"
        ]
    },
    {
        "id": "T61GK5N2GPG",
        "original": null,
        "number": 2,
        "cdate": 1666619716414,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619716414,
        "tmdate": 1666619716414,
        "tddate": null,
        "forum": "BqxE86ufTzq",
        "replyto": "BqxE86ufTzq",
        "invitation": "ICLR.cc/2023/Conference/Paper361/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper explores domain generalization by estimating gradients of unobserved domains using large-scale pretrained models. The method learns task-specific knowledge for the pretrained model while preserving its generalization ability with the estimated gradients by EMA. Results on several benchmarks on DomainBed show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "[+] The paper propose to use EMA to simultaneously learn the task-specific knowledge and preserving the generalization ability of large-scale pretrained model for domain generalization, which is interesting.\n\n[+] The ablation studies and comparisons on several domain generalization datasets  support the effectiveness of the method.\n\n[-] The paper uses pretrained models as the loose approximation of the oracle model of the unseen domains and and estimates the unobserved gradient of unseen domains. But it is not clear why the pretrained models is able to approximate the oracle model. For example, how can an ImageNet-pretrained ResNet can be the oracle model for unseen domains like \u201csketch\u201d? More explanations and discussions are needed for this motivation.\n\n[-] The reviewer is also concerned about the novelty of the proposed method. The estimated gradient in eq. 4 looks more like a regularization that protects the model from changing too much compared with the originally pretrained parameters, which may hurt its generalization ability. Eq. 6 also seems to be doing the same thing. However, this kind of techniques have already been explored in some continue learning methods to deal with catastrophic forgetting.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the presentation is generally clear in most parts of the paper.\n\nQuality: fair.\n\nNovelty: a bit low.\n\nReproducibility: it could be easy to reproduce due to the technical simplicity.",
            "summary_of_the_review": "The paper proposes to fine-tune the large-scale pretrained model for domain generalization by learning task-specific knowledge from source domains while keeping the generalization ability of the pretrained models. But the motivation and justification behind the method are not clear and well supported by experiments. The technical novelty of the method seems weak to me. Therefore, I think it is below the acceptance threshold. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper361/Reviewer_TqRb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper361/Reviewer_TqRb"
        ]
    },
    {
        "id": "X_Sn1avF1UD",
        "original": null,
        "number": 3,
        "cdate": 1666671777923,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671777923,
        "tmdate": 1666671777923,
        "tddate": null,
        "forum": "BqxE86ufTzq",
        "replyto": "BqxE86ufTzq",
        "invitation": "ICLR.cc/2023/Conference/Paper361/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper targets the domain generalization task. Based on the observation that fine-tuning may introduce gradient bias and hurt generalization ability, the paper estimates unobservable gradients that reduce potential risks in unseen domains. The main requirement is that there is a pre-trained model. Experimental results show that the proposed method outperforms baseline methods on DomainBed.\n",
            "strength_and_weaknesses": "This paper proposes to estimate the unobservable gradients from a pre-trained model, which helps the model generalization across various domains. Results on various configurations show the ability of the proposed method. \n\nThere are some concerns with the paper:\n1. The main idea of the paper is to reduce the influence from the source domain gradients and make the model generalize better. However, since we do not know which is the target domain, does it requires some kind of prior knowledge encoded in the pre-trained model? For example, if the target domain is very similar to (or distant from) the source domain, the pre-trained model will produce the same unobservable gradients, but not both of them help the generalization.\n2. Do the experiments in Figure 1 depend on the relationship between the source and target domain? Could the authors show the similarity between the true gradient to the target domain and the gradient estimated by the pre-trained model?\n3. Based on the results in Table 3.6 and supplementary, the value of $\\lambda$ depends on the size of the pre-trained model. Does it relate to the similarity between the source and target domains? Or the diversity of the dataset of the pre-trained model?\n4. Please consider more comparison methods in the experiments. ",
            "clarity,_quality,_novelty_and_reproducibility": "The idea is novel, and using a pre-trained model to help the domain generalization is interesting. The paper is clear.\n",
            "summary_of_the_review": "The overall quality of the paper is good, and the idea is interesting. The two main concerns of the paper are:\n1. Theoretical or empirical analysis should be provided to support the motivation of the paper;\n2. How to design a fair comparison with other methods since a pre-trained model is included.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper361/Reviewer_ENaU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper361/Reviewer_ENaU"
        ]
    },
    {
        "id": "MibCPyDD5f",
        "original": null,
        "number": 4,
        "cdate": 1666825342898,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666825342898,
        "tmdate": 1666825342898,
        "tddate": null,
        "forum": "BqxE86ufTzq",
        "replyto": "BqxE86ufTzq",
        "invitation": "ICLR.cc/2023/Conference/Paper361/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a simple method that leverages the generalization ability of large pre-trained models for domain generalization. The key idea is to use large pre-trained models to estimate the unobserved gradient that minimizes the risks in the target domain, mitigating the gradient biased towards to the source domain during the fine-tuning stage. Experimental results show that the approach is promising despite its simplicity.",
            "strength_and_weaknesses": "Strengths:\n- The proposed method is simple but shows promising results\n- The key idea is well-motivated: large pre-trained models have strong generalization ability and fine-tuning impairs this characteristic; thus, one can do fine-tuning more conservatively to retain the models generalization ability.\n\nWeaknesses:\n- One main concern I have about the paper is that the proposed method is very related to a recent work [1], that proposed to linearly interpolate a fine-tuned model\u2019s weight with the un-tuned model\u2019s weight. The only difference lies in that [1] does the interpolation \u201cafter\u201d the model is fine-tuned, while the proposed method in this paper does the interpolation \u201cduring\u201d fine-tuning (in the optimization steps). [1] is only very briefly mentioned in the related work section. However, I believe properly comparing to [1] in the paper on both the method design as well as experimental results is needed to make the contribution of this work stronger.\n- In the experiments, the evaluation metric only measures the model performance on the unseen domain. However, it\u2019s generally also important to see the model performance on the source domain. It will give a more complete picture on the pros/cons of different methods. For example, maybe the simple ERM can achieve best performance on source domain by trading-off only a bit of its performance on target domain; while methods designed to optimize for target domain may trade-off more performance on source domain.\n- I appreciate that the authors have conducted the analysis in Sec 3.4 to validate the original hypothesis of biased gradient. However, more details on the experimental setup are needed. Specifically, how are the gradients on the unseen domain calculated? Is it by using the actual $(x, y)$ pairs in the unseen domain?\n- Another relevant baseline to consider in the experiments is the zero-shot model baseline. Particularly, with models like CLIP, one can directly do zero-shot predictions on the unseen domain. Will such a model without any fine-tuning achieve even better performance compared to the proposed method?\n- Paper presentation can be improved. There are many repetitive texts in the Introduction section and the Method section. For example, the paragraph on \u201cTask expert and generalization expert\u201d in the Method section is repeated in the Introduction. Authors could use the space to provide more insights to the method design.\n\n[1] Robust fine-tuning of zero-shot models. Wortsman et al. 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is overall clearly written.\n\n- Quality and Novelty: The proposed method is well-motivated and experimental results are promising. However, the method design shares a lot of similarity to a recent work [1], which receives little discussion in the paper. The paper quality can be much improved by carefully discussing its comparisons to related work.\n\n- Reproducibility: The authors provide code to reproduce the experimental results.",
            "summary_of_the_review": "Overall, the motivation and the method design is interesting. However, the paper currently lacks proper comparisons to related work, making the contribution less strong as it stands.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper361/Reviewer_seAG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper361/Reviewer_seAG"
        ]
    }
]