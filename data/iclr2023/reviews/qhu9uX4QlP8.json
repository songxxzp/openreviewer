[
    {
        "id": "ZIO4AR0ZeXm",
        "original": null,
        "number": 1,
        "cdate": 1666621358830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621358830,
        "tmdate": 1666621358830,
        "tddate": null,
        "forum": "qhu9uX4QlP8",
        "replyto": "qhu9uX4QlP8",
        "invitation": "ICLR.cc/2023/Conference/Paper80/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes Meta OT, which can repeatedly solve similar OT problems between different measures by leveraging the knowledge and information present from past problems to rapidly predict and solve new problems.\nThe experiments instantiate that Meta OT can improve the calculation time under various settings.\n",
            "strength_and_weaknesses": "Strengths: Meta OT significantly improves the computational time and number of iterations needed to solve optimal transport between discrete and continuous measures.\n\nWeaknesses: 1.When comparing the time of algorithms, the time of Meta OT should include the training time.\n2. This paper does not explain why meta can help to quickly predict and solve new problems by using knowledge and information from past problems",
            "clarity,_quality,_novelty_and_reproducibility": "The overall structure of this paper is clear. \nThe problem of how to use existing knowledge to compute optimal transport map is novel, but the approach via neural networks lacks novelty.",
            "summary_of_the_review": "This paper proposes Meta OT, which is different from W2GN in that Meta OT takes the cost as the input. \nThe experiments show that it improves the computing time, but it does not explain how to use the existing knowledge",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper80/Reviewer_taDB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper80/Reviewer_taDB"
        ]
    },
    {
        "id": "aH0PMbHzg5",
        "original": null,
        "number": 2,
        "cdate": 1666670896413,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670896413,
        "tmdate": 1669779228210,
        "tddate": null,
        "forum": "qhu9uX4QlP8",
        "replyto": "qhu9uX4QlP8",
        "invitation": "ICLR.cc/2023/Conference/Paper80/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a meta-method to obtain OT loss between two distributions.",
            "strength_and_weaknesses": "In section 2, the authors recall the OT dual formulation in the case of $W_2$ distance and the entropic OT. Based on simpler formulas of computing OT cost for those cases, they proposed  to use neural network to  modeling the cost function. They utilise some structures like Meta ICNN, Resnet for the neural network function. Section 4 includes experiments of discrete OT on MNIST data, transportation on spherical data and colour transfers using Wasserstein-2 distance. The results show that the meta OT needs significant less number of iterations to converge than the Sinkhorn algorithm.  In the last section, the authors claim the contribution and outline limitations of their methods.\n\nOverall, I think the idea is simple and interesting. I am concerned about the novelty of the method as well as its non-applicability in many important situations  as the authors have stated. The authors also do not show the amount of  time  to build up their meta-OT. It is very important issue because if the number of supports of a discrete distribution is extremely large, then  the main questions are how long does it take to train the meta-OT and can we guarantee the accuracy of its solution? \n\nTo improve the paper, the authors might try to include some approximation theory to quantify the solution's  accuracy and show why the Meta-OT initialisation improve the convergence speed of Sinkhorn algorithm. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper was well-written, easy to follow and make clear about its contributions and limitations. ",
            "summary_of_the_review": "Please read the Strength and Weaknesses part.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper80/Reviewer_HF6W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper80/Reviewer_HF6W"
        ]
    },
    {
        "id": "b5TAEnPUm9p",
        "original": null,
        "number": 3,
        "cdate": 1666702476329,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666702476329,
        "tmdate": 1666702476329,
        "tddate": null,
        "forum": "qhu9uX4QlP8",
        "replyto": "qhu9uX4QlP8",
        "invitation": "ICLR.cc/2023/Conference/Paper80/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents Meta OT, a method for initializing optimal transport problems based on prior solutions that applies in contexts in which the problems share structure. Meta OT is described for discrete and continuous problems. Extensive experiments quantify improvements in speed of convergence on problems including MNIST, transportation problems, and color transfer. Results suggest speed ups of several orders of magnitude are possible and, to the eye, they incur little to no loss in accuracy.  ",
            "strength_and_weaknesses": "Strengths: \n- OT and methods for obtaining solutions to OT problems are a timely and important topic. \n- The paper clearly documents the possible improvements in runtime performance. \n- The math is clear and concise. \n- The writing is clear. \n\nWeaknesses:\n- The specific problem, in which one is solving structurally related problems repeatedly, is a bit niche. \n- I would have like to see more systematic analysis of the decay of performance associated with different degrees of out-of-distribution problems, as well as with greater or less coherence within the domain of generalization. \n- Relatedly, I did not see a clear statement of when this can be applied to the advantage to the user. This seems like an important consideration, given that we wouldn't expect the approach to \"work\" generally, necessarily. \n- Similarly, it seems important to document how the performance decays when applied to domains that are less well suited. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well written. The authors state that they will make code available. ",
            "summary_of_the_review": "The paper introduces a nice idea for improving the performance of OT solvers. Given that it only applies to some problems, and an a priori test isn't available to know whether it will help, I would have liked more systematic analysis of the consequences of application to less-well suited domains both in terms of speed and accuracy. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper80/Reviewer_eM4a"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper80/Reviewer_eM4a"
        ]
    },
    {
        "id": "bTJ_HQRHXR",
        "original": null,
        "number": 4,
        "cdate": 1667507263800,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667507263800,
        "tmdate": 1669284134794,
        "tddate": null,
        "forum": "qhu9uX4QlP8",
        "replyto": "qhu9uX4QlP8",
        "invitation": "ICLR.cc/2023/Conference/Paper80/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a meta-learning approach to OT. That is, the authors learn a meta-model on a large train set of OT tasks and then try to predict the solution of the new test OT tasks based on the past experience. Two experimental setups are considered: discrete OT problems for general costs and continuous (small-dimensional) OT problems for the quadratic cost. In both cases, the authors state that the meta-ot predictions notably speed up the OT learning algorithms (meta-prediction is used as the initialization in the OT algorithm). The performance is demonstrated on 2D, 3D optimal transport tasks: interpolation between MNIST digits (considered as 2D distributions), supply-demand transportation and color transfer between RGB images (represented as 3D point clouds).\n",
            "strength_and_weaknesses": "**Strength**\n\n(1) Application of meta-learning to the previously unapproached problem.\n\n(2) Meta-OT allows to predict a good initialization for the OT algorithms which naturally boosts their convergence;\n\n**Weaknesses**\n\n(1) Potential applications of the Meta-OT methodology are questionable;\n\n(2) Meta-OT performance presumably heavily depends on the available meta-distributions (train set of pairs of distributions for OT).\n\n(3) The capabilities of the method are only to predict good initialization for sinkhorn/W2GN, but not the good approximation of the OT plan (not sure here);\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity, quality.** First, from the exposition, it is not clear to which extent meta-OT is actually capable of predicting the reasonably precise solutions of OT problems or it anyway requires fine-tuning. I think this aspect should be discussed in a more detail. \n\n* In the supply-demand example, Figure 5 is an awesome picture, but it explains literally nothing. Is it a good initial (meta-OT) plan? Is its cost already close to the optimal (entropic) one?\n* In most cases, the authors provide some convergence plots of the dual objective and show the marginal error. It would be nice to see the marginal values immediately after Meta-OT prediction (before further fine-tuning) for comparison. Additionally, I would expect to see the transport cost (entropic, a.k.a. The primal objective) of the recovered plan at all these stages. This would help to understand further potential of the method.\n* In section 4.3, the provided examples are images but it unfortunately remains unclear what happens inside their color palettes (where the transport magic actually happens). How good is the recovered transport (both meta-OT prediction and meta+finetune) between the palettes? I think it is useful to add some examples with the color palettes \u2013 otherwise the experiment is not transparent. I am concerned here because such problems can be solved reasonably well by much simpler methods without ANY learning or meta-learning. For example, just by aligning means and stds of RGB channels (like AdaIN used in style transfer) or just by Gaussian (linear OT ot.da.OT_mapping_linear ). This won\u2019t guarantee the correct measure transport, but would in most cases anyway result in good image color transfer qualitatively. Is there any benefit in using (rather complicated) meta-OT here?\n\nSecond, after reading the paper twice, I feel that I do not completely understand what are the scenarios where we need to solve OT repeatedly, so where the proposed methodology is actually applicable. I found only one-two sentences in the text describing this rather important aspect (paragraph 3 in introduction) and only very briefly. I kindly ask the authors to provide a more explicit description of a particular use-cases of their methodology. For example, regarding the supply-demand example, do the trading companies really need to solve the OT problem so frequently that it is required to reduce the computation amount? Shouldn\u2019t they, for example, plan once a month or so? This does not seem to be a scenario requiring meta-OT. I am definitely not expert in logistics/trading, but just trying to understand this (rather important for the current paper) motivational aspect.\n\n**Novelty.** The paper limited scientific novelty \u2013 it is just an application of Meta Learning principles to a field which has not been meta learned before (optimal transport). Regarding the methodological/technical novelty, there are some clever methodological ideas, e.g., predicting the dual variables rather than the OT plan, but I can not say these are very significant as almost any (non-meta) OT algorithm (either discrete or continuous) anyway solves the dual problem rather than the primal.\n\n**Reproducibility:** the code is present \u2013 no questions here.\n\n**Other**\n* Notation overline(psi) for the parameters of the neural network is a little bit weird.\n* Most paper seems to be using the amortized optimization (14). Have you tried the regression-based approach (15)?",
            "summary_of_the_review": "The paper has limited scientific novelty \u2013 it is a application of Meta Learning to OT which is rather straightforward and its significance is not clear. On the one hand, it seems to indeed boost the underlying OT algorithms thanks to the good predicted initialization of dual variables and overall it is interesting to see that OT problems can be (to some extent) meta-learned. On the other hand, the potential applications prospect of Meta-OT are not convincing enough (do we really need to meta-learn OT?) and there are some questions in the experiments. I currently rate this paper as a borderline, and will wait for the authors feedback to make my final decision.\n\n**Post-rebuttal update:** score +1 (see the discussion under the general authors comment)",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "-",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper80/Reviewer_zFaG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper80/Reviewer_zFaG"
        ]
    }
]