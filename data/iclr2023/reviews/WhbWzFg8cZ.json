[
    {
        "id": "Km9bGpcdMD",
        "original": null,
        "number": 1,
        "cdate": 1666619122007,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619122007,
        "tmdate": 1666619122007,
        "tddate": null,
        "forum": "WhbWzFg8cZ",
        "replyto": "WhbWzFg8cZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4081/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The proposed method adopts randomized CNNs ensemble and uses it as descriptor extractors and detects keypoints. Comparing to the state-of-the-art requires training specifically with supervised or self-supervised learning, the method doesn't need any of that and the author claims to have high robustness against illumination and other appearance variations.",
            "strength_and_weaknesses": "The idea is quite interesting. Basically the method seeks matching generalization with an ensemble of purely random parameters. The idea can potentially be used in some data requires matching which contains no training samples.\n\nHowever, the task that authors targeted is specifically for appearance matching which is a well studied domain. The claim of missing matches with depth or nomal are failing (Table.1, Table.2, Figure.5 ...) are simply because those methods (e.g. Superpoint, D2-Net, R2D2) are not trained with those inputs. It's not very hard to swapping those inputs and re-train them.\n\nDespite I know the idea is more like unsupervised vs supervised method, there is simply not much hard work you need to do with supervised method. For example, R2D2 is basically a self-supervised method, the training data can be generated with a set of normal or depth images. The authors need to motivate the idea more than showing the results.\n\nApart from that, the proposed method doesn't really work on any view point changes (Figure 8.) which is essential for image matching. The paper also missed important baseline such as DELF (multi-scale) which is also very robust for illumination changes.",
            "clarity,_quality,_novelty_and_reproducibility": "The idea is simple and clear. Should be fairly easy to reimplement.",
            "summary_of_the_review": "Overall the idea is simple and interesting. However, I believe image matching task has been well studied and there is no difficulty to adapt some state-of-the-art method onto depth or normal image for retraining. Therefore, the authors need to rethink about the task and the relation between the proposed method and the baselines. The question you might want to ask yourself: \"Is there any need for using this unsupervised method in this task?\" Otherwise it's just interesting but without any practical impact.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_cMkJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_cMkJ"
        ]
    },
    {
        "id": "s3mHg5IXwna",
        "original": null,
        "number": 2,
        "cdate": 1666643319107,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643319107,
        "tmdate": 1666643319107,
        "tddate": null,
        "forum": "WhbWzFg8cZ",
        "replyto": "WhbWzFg8cZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4081/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes to apply an ensemble of siamese CNNs to detect and describe keypoints. The parameters of these CNNS are not trained but set randomly. The keypoint descriptors produced by each siamese CNN are matched using a classical nearest neighbor with ratio test followed by a mutual nearest neighbor test. All these match candidates are filtered using a novel consensus mechanism.\n\nThe proposed approach is evaluated on 7-scenes and MegaDepth against RootSIFT, SuperPoint, D2-Net and R2D2 on three different modalities : color images, depth images and normal images.",
            "strength_and_weaknesses": "### Strengths\n\n1. The paper is overall well written and easy to read, except section 3.2 Consensus mechanism which is difficult to understand.\n2. Employing untrained CNNs is an interesting idea\n\n### Weaknesses\n\n1. The consensus mechanism section 3.2 is difficult to understand.\n2. The computational time is probably high compared to other methods as it requires 8 forward passes (8 siameses CNNs are employed in the experiments).\n3. Concerning MegaDepth, thresholds of 10 cm and 50 cm have been defined, but if I am not mistaken, for each MegaDepth scene the 3D point cloud is obtained using SfM up to a scale factor. How did you obtain this scale factor ?\n4. Why did not you run experiments on color images for MegaDepth ? (column \"color\" is missing both in Table 1 and 2)",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written, except section 3.2 that is very difficult to understand. I believe adding some illustrations of the output of the MeanShift algorithm would help. The originality of the paper is somewhat limited to me as recently reviewed several papers investigating the idea of employing Neural Networks with random parameters is the related field of shape matching.",
            "summary_of_the_review": "The paper is not far from the acceptance threshold but the novelty and the performances are not sufficient (to me).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_Miyx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_Miyx"
        ]
    },
    {
        "id": "nIplohqhTQ",
        "original": null,
        "number": 3,
        "cdate": 1666823236912,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666823236912,
        "tmdate": 1666823236912,
        "tddate": null,
        "forum": "WhbWzFg8cZ",
        "replyto": "WhbWzFg8cZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4081/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a surprising new method for keypoint matching across image pairs. The idea is essentially to use randomly-initialized CNNs to generate the features. The random features are first preprocessed slightly to get local peaks, and then the features which do not have mutual neighbors are discarded. Finally matches are found with a consensus mechanism similar to RANSAC, which can be split into a clustering stage (generating hypotheses) followed by a scoring stage (selecting hypotheses). The experiments show that this method is competitive with existing methods.\n",
            "strength_and_weaknesses": "I think this paper presents some surprising findings. I would not have expected that randomly-initialized CNNs could be made to compete so closely with models like SuperPoint and D2 and R2D2. I also appreciate the analysis on the number of CNNs, and the analysis over distance in the HPatches dataset. It's not the best method, but I learned something from reading the paper. \n",
            "clarity,_quality,_novelty_and_reproducibility": "> \"Our observation is that the CNN architecture ... can be regarded as visual descriptors\"\n\nSome typo here I guess. You cannot regard an architecture as \"descriptors\".\n\n\n> for keypoint description, description and matching, \n\n?\n\n> These matches enable us, e.g., \n\nI think this is a bad sentence. It almost sounds like \"us\" is the example. \n\n> \"the aforementioned camera pose estimation is a minimal problem\"\n\nWhat is a \"minimal\" problem?\n\n> \"the feature map F is normalized to a saliency map to filter out homogeneous regions\"\n\nHow does this work? I suppose the normalization here is to make the vector magnitude 1, or maybe asks for some sum to be 1, but why does that turn the vectors into saliency cues, and how does it \"filter out homogeneous regions\"?\n\n\n> \"Consequently, a descriptor can only be used to match the same type of descriptors extracted by the same CNN. Therefore, the process of keypoint extraction and matching of multiple CNNs is independent and can be deployed in parallel\"\n\nI don't really see how these two claims connect. The first claim is obvious (you can only compare features within a CNN), and the second is also obvious (you can run multiple CNNs in parallel), but the first claim does not imply the second.\n\n> \"a local softmax \\alpha in each channel\"\n\nWhat is meant by \"local\" here? Is this redundantly referring to the fact that the softmax is applied per-channel, or is something else meant? The whole description in the neighborhood of this phrase could be improved. In particular, it would be really great to clarify the i,j,k notation or maybe not use it, since I don't think it's very natural for space and channels to be indexed the same way. ",
            "summary_of_the_review": "I like the paper, because it shows a surprising result. I think many people would want to see this. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_m1xk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4081/Reviewer_m1xk"
        ]
    }
]