[
    {
        "id": "IdR48N1uGG",
        "original": null,
        "number": 1,
        "cdate": 1666415306923,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666415306923,
        "tmdate": 1670489440269,
        "tddate": null,
        "forum": "_1gu0EX0mM3",
        "replyto": "_1gu0EX0mM3",
        "invitation": "ICLR.cc/2023/Conference/Paper3627/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The manuscript handles the weakly-supervised domain adaptation in federated learning, in which a set of source clients aiming at boosting the model performance of the target client that has few labelled samples. To achieve the problem, the manuscript proposes to utilize the auxiliary information and gradient projection to help local training and fine-tuning, respectively. The experimental results on three medical image datasets demonstrate the effectiveness of the used techniques.",
            "strength_and_weaknesses": "Pros:\n1) The studied problem weakly-supervised federated domain adaptation is interesting and practical.\n2) The experiments results compared with baselines confirm the effectiveness of the used techniques, i.e., utilizing the auxiliary information and gradient projection to help local training and fine-tuning, respectively.\n3) The manuscript provides sufficient experiments details, along with the codes, which help the reproducibility.\n\nCons:\n1) Although the studied problem weakly-supervised federated domain adaptation is interesting and practical, it is not well illustrated and driven in the manuscript, which can be largely improved.\n2) The proposed method is not well illustrated and driven, and even some parts are confusing. For example, in Eq. (7), the update of model parameter h_T^{(r)} utilizing the scalar P_{GP} is confusing.\n3) The used techniques leveraging auxiliary information during local training and utilizing gradient projection during fine-tuning lacks of novelty, since the former is introduced in [1] while the latter is incorporating the cosine similarity among layers for computing the aggregation weights.\n4) The manuscript can present the visualization of the cumulative gradient projection GP for demonstrating the effectiveness of proposed method.\n\n[1] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. Inn-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness. In International Conference on Learning Representations, 2021.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "a) Clarity: The studied problem and proposed method are not well presented and driven, in which some aspects are confusing, e.g., the update of model parameter h_T^{(r)} utilizing the scalar P_{GP} in Eq. 7.\n\nb) Quality: The utilized technique outperforms the compared baselines.\n\nc) Novelty: Although the studied problem weakly-supervised federated domain adaptation is somewhat novel, the used techniques leveraging auxiliary information during local training and utilizing gradient projection during fine-tuning lacks of novelty, since the former is introduced in [1] while the latter is incorporating the cosine similarity among layers for computing the aggregation weights.\n\nd) Reproducibility: The manuscript provides sufficient experiments details, along with the codes, which boost the reproducibility.\n\n[1] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. Inn-out: Pre-training and self-training using auxiliary information for out-of-distribution robustness. In International Conference on Learning Representations, 2021.\n",
            "summary_of_the_review": "Although the studied problem is interesting and practical, but the manuscript is not well presented and driven, which should be largely improved. I checked the author's rebuttals, some of them are useful and clarifying my concerns. I chose to improve my scorings.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "These are no Ethics Concerns in this manuscript.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_JHRh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_JHRh"
        ]
    },
    {
        "id": "9plrC3dAqs8",
        "original": null,
        "number": 2,
        "cdate": 1666525137388,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666525137388,
        "tmdate": 1670548383001,
        "tddate": null,
        "forum": "_1gu0EX0mM3",
        "replyto": "_1gu0EX0mM3",
        "invitation": "ICLR.cc/2023/Conference/Paper3627/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a weakly-supervised federated domain adaptation (FDA) framework to help the problems of distribution shifts and label deficiency in federated learning systems. It utilizes auxiliary information during local training and gradient projection during fine-tuning respectively to improve performance. Experiments on medical imaging datasets and general datasets show that the proposed framework improves FDA performance.",
            "strength_and_weaknesses": "Strengths:\n\uff081\uff09\tThe proposed framework is reasonable and well-supported by the paper content.\n\uff082\uff09\tExperiments are comprehensive for both the the proposed module and relevant parameters.\n\nWeaknesses:\n(1)\tIt uses auxiliary information in multi-task learning during the local training of each source client. However, such auxiliary information has been proposed before and are widely used, where the effectiveness of such strategy is already verified.\n(2)\tThe experiments include only ablation studies based on the FedAvg. It lacks performance comparison with similar SOTA methods.\n(3)\tMinor\uff1a\n1)\tThe \u201clabelled\u201d is labeled in the following sentence.  \u201cThe human cost of labeling the images is expensive, thus the data are sparsely labelled.\u201d\n2)\tThere are two \u201cthe\u201d in the following sentence. \u201cFurther, in addition to the the medical images.\u201d\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized. Key resources (e.g., code, data) are available, and key details are well-described to reproduce the main results.  The presentation could be further improved if the contribution are more concisely and clearly presented. ",
            "summary_of_the_review": "The paper introduces two modules in weakly-supervised federated domain adaptation (FDA), but the novelty is not so big, and the experiment lacks comparison with methods of full supervision, unsupervised, or other weak supervision.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_sdrU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_sdrU"
        ]
    },
    {
        "id": "f1INVzCW_LP",
        "original": null,
        "number": 3,
        "cdate": 1666584566136,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666584566136,
        "tmdate": 1666584566136,
        "tddate": null,
        "forum": "_1gu0EX0mM3",
        "replyto": "_1gu0EX0mM3",
        "invitation": "ICLR.cc/2023/Conference/Paper3627/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a new method for federated domain adaptation (FDA) with application to medical imaging. to improve target domain performance, authors consider a multi-task learning (MTL) framework over the source domains. Several cheap secondary tasks are considered locally (at each source client). Such local information has been shown to improve generalization for data from the target domain. To furthermore benefit from such local signals, authors propose an aggregation of knowledge collected from source domains and transfer it to the target domain using a gradient projection.  The FDA method is validated on 3 medical datasets and compared to standard fedavg tuned and not-tuned on target domain data, and the proposed method showed good improvement.",
            "strength_and_weaknesses": "Strengths:\n+ The new method allows leveraging inexpensive secondary tasks to improve target domain performance.\n+ Gradient projection aggregation helps improve performance.\n+ The empirical results show the benefit of the method, and some ablation studies are provided.\n+ The supplementary material provides additional implementation details and experimental results that help support the paper.  \n+ The paper includes information that would make it possible to reproduce the methods and experiments (but not with MIDRC data). \n\nWeaknesses:\n - The experimental validation is limited in some respects. There is a lack of comparison with state-of-the-art domain adaptation methods, which makes it difficult to assess the performance of the proposed method, and whether the proposed method provides an improvement. \n- The gradient projection requires that all models must have the same architecture/type.\n- The authors do present average results over several independent replications, using some cross-validation process.  \n- The proposal should be also compared with SOA methods in terms of time and memory complexity.  There should be further analysis of the impact on the performance of growing class imbalance, degree of shift, and diversity among source and target domains.   \n- The tables should show upper-bound results on all datasets.",
            "clarity,_quality,_novelty_and_reproducibility": "+ The paper is clearly written and organized. \n+ The contribution is good. Using MTL and gradient projection in FDA allows leveraging secondary local tasks, and provides a different and more efficient way to aggregate/transfer knowledge from source to target.",
            "summary_of_the_review": "The proposed methods can help to improve the generalization over the target domain. However, there are limited comparisons to state-of-the-art methods.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_v8Kd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_v8Kd"
        ]
    },
    {
        "id": "aHxnqimos_c",
        "original": null,
        "number": 4,
        "cdate": 1667670804133,
        "mdate": 1667670804133,
        "ddate": null,
        "tcdate": 1667670804133,
        "tmdate": 1667670804133,
        "tddate": null,
        "forum": "_1gu0EX0mM3",
        "replyto": "_1gu0EX0mM3",
        "invitation": "ICLR.cc/2023/Conference/Paper3627/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The manuscript focuses on the domain adaptation issue in a federated learning setting, where the target client has limited labeled data, whereas the source data are more available with auxiliary information. The major contribution includes leveraging auxiliary information on source clients and also a gradient projection to aggregate the gradient direction from multiple source clients. The experiments were conducted on three chest X-ray datasets. ",
            "strength_and_weaknesses": "Strength:\n- The manuscript focuses on an important setting and introduces two main methods to solve the problem. The third experiment shows good results in a real-work case. \n\nWeakness:\n\n- The first two experimental settings are less realistic, especially the first one, the domain differences are based on the lung conditions. The second experiment's results are incremental. It is also not clear why the proposed method has a much slower convergence on MIMIC in figure 3. The last experimental setting is more realistic, with locations as different domains. I think the first two experiments are not beneficial to support the conclusion.\n- The related work could be better discussed. How to aggregate local gradient information into a global model is well-studied and should be discussed in more detail. ",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is clear to read. The novelty is marginal. It is not clear if the code will the shared with the public, but it seems it could be reproducible. ",
            "summary_of_the_review": "The contribution of the paper is limited in both novelty and empirical contributions. I recommend revising the paper and resubmitting it to other conferences. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_1NEn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3627/Reviewer_1NEn"
        ]
    }
]