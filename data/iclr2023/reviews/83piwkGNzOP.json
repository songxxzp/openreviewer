[
    {
        "id": "h8ulFHdKOz",
        "original": null,
        "number": 1,
        "cdate": 1665653355951,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665653355951,
        "tmdate": 1665653402284,
        "tddate": null,
        "forum": "83piwkGNzOP",
        "replyto": "83piwkGNzOP",
        "invitation": "ICLR.cc/2023/Conference/Paper1895/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an efficient ANN-SNN conversion mechanism based on the SlipReLU activation function. It replaces the traditional ReLU to improve the accuracy of the converted SNN. The results look promising and competitive compared to the related works.",
            "strength_and_weaknesses": "Strengths:\n1. The tackled problem is relevant to the scope of ICLR.\n2. The contributions look solid.\n3. The results look promising.\n\nWeaknesses:\n1. It would be interesting to have more details about more intuitions about the design decision made when developing the proposed SlipReLU activation function.\n2. The description of the proposed method in Section 4 looks vague and hard to follow. It is recommended to use schemes, and examples to ease the discussion.\n3. Please describe the experimental setup and tool flow used to generate the results shown in Section 6.\n4. It would be useful to provide the source code for reviewers' inspection during the rebuttal.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: 6/10\n\nQuality: 8/10\n\nNovelty: 8/10\n\nReproducibility: 5/10",
            "summary_of_the_review": "Good paper where few concerns should be clarified.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_FPAL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_FPAL"
        ]
    },
    {
        "id": "F78j-c4-8s",
        "original": null,
        "number": 2,
        "cdate": 1665674747076,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665674747076,
        "tmdate": 1669507622509,
        "tddate": null,
        "forum": "83piwkGNzOP",
        "replyto": "83piwkGNzOP",
        "invitation": "ICLR.cc/2023/Conference/Paper1895/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors devise a two-step conversion framework for ANN-SNN conversion. Unlike previous methods which consider the ANN-SNN conversion error, this work considers the error between source ANN and altered ANN as well as altered ANN with SNN. The idea is generally sound and simple to understand. Yet in my view, the two-step conversion naturally has some deficiencies with than one-step conversion (see weakness section for details). \n\n\n",
            "strength_and_weaknesses": "Strength:\n\n+ The structure and presentation of this paper are neat and easy to understand.\n\n+ The perspective of the trade-off between the distance to ANN and the distance to SNN is novel and an interesting activation function is proposed (SlipReLU). \n\nWeakness:\n\n- The major concern in this work is the first term in Eq. 5, which hypothesize that the output between ReLU-based ANN and customized ANN should be considered, is not fully verified in experiments. As far as I interpret Eq. 5, the SlipReLU should have higher ANN accuracy but also higher conversion error than QCFS, because it has less distance to ANN while more distance to SNN compared with QCFS. \nAnd ideal result in SlipReLU is that it shows higher ANN accuracy and despite the higher conversion error, SlipReLU can still achieve higher SNN accuracy than QCFS. However, the results in paper does not verify the tradeoff or did not explicitly discuss the tradeoff in experiments. Ablation studies on the weight of combination, and more analysis on ANN, SNN accuracy tradeoff should be provided. \n\n- Two-step conversion certainly has its pros, but it also has cons. Two step method must train their own ANN models, while one-step models can utilize directly-trained checkpoints in open-sourced projects. Some large-scale datasets and models, are require a lot resource to train the ANN, for example, ImageNet. Thus, ImageNet results are also anticipated. \n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "+ Clarity: This paper is sufficiently clear. \n\n+ Quality: This paper's quality is good. \n\n+ Novelty: An extension from previous work, but it needs more exresults to support its correctness. \n\n+ Reproducibility: Not reproducible at this time. ",
            "summary_of_the_review": "My reasons for the weak rejection are insufficient analysis and the lack of large-scale experiments. Were they addressed by the authors, I can increase my score. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_rSjR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_rSjR"
        ]
    },
    {
        "id": "YiW6ITvT7V",
        "original": null,
        "number": 3,
        "cdate": 1666590001345,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590001345,
        "tmdate": 1669039240416,
        "tddate": null,
        "forum": "83piwkGNzOP",
        "replyto": "83piwkGNzOP",
        "invitation": "ICLR.cc/2023/Conference/Paper1895/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper improves upon the conversion error of two step ANN to SNN conversion based technique to yield sota accuracy.  In particular, it presents an efficient ANN-SNN conversion mechanism based on the SlipReLU and shifted SlipReLU activation function replacing the traditional ReLU to improve the accuracy of the converted SNN. The results look promising and competitive compared to the related works. The theoretical analysis of error strengthens the paper.",
            "strength_and_weaknesses": "### Strengths\n=============\n\nWell written.\n\nWell motivated.\n\nResult is good and inspiring.\n\nAnalysis of the various conversion error is present in details. Some are taken from earlier research though.\n\n### Weakness:\n===============\n\nThe experimental results section is weak. The authors should provide results on larger datasets to show the efficacy.\n\nThe author should do an ablation study with SlipReLU and shifted SlipReLU.\n\nIt would be interesting to see how such ReLU performs under various noisy inputs as discussed in [1-2], particularly, whether they can also maintain some inherent robustness with such non-linear functions, under two-step conversion based framework.\n\nPlease put some light on to the selection of input type (direct, rate etc.) on the performance with  SlipReLU.\n\nlack of reproducibility and missing details of experimental setup.\n\n[1] Inherent adversarial robustness of deep spiking neural networks: Effects of discrete input encoding and non-linear activations, ECCV 2020.\n\n[2] HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training With Crafted Input Noise, ICCV 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "clarity: 9/10\nQuality: 8/10\nNovelty: 8/10\nReproducibility: 8/10",
            "summary_of_the_review": "Overall, this is a well written well motivated paper that requires further experiments to clarify the impact of the proposed non linearity in SNN paradigm.\n\nPost rebuttal: the contributions are new with detailed additional results, major concerns are addressed with results on further complex datasets. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_7AYG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_7AYG"
        ]
    },
    {
        "id": "rssv6lt4Rb",
        "original": null,
        "number": 4,
        "cdate": 1667294332570,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667294332570,
        "tmdate": 1667294332570,
        "tddate": null,
        "forum": "83piwkGNzOP",
        "replyto": "83piwkGNzOP",
        "invitation": "ICLR.cc/2023/Conference/Paper1895/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a conversion algorithm for deploying SNNs.",
            "strength_and_weaknesses": "-Not novel and results are not good. Today, many works are focused on direct training precisely to reduce the overall timestep count in SNNs that can lead to very expensive timestep computations during inference[1]. The authors work still gives best conversion accuracy at T>100. This is not acceptable anymore. I suggest the authors to go over recent conversion works that have strived to created conversion SNNs at T<10 timesteps [2].\n\n[1] Yin, Ruokai, et al. \"SATA: Sparsity-Aware Training Accelerator for Spiking Neural Networks.\" arXiv preprint arXiv:2204.05422 (2022).\n\n[2] Zheng, Hanle, et al. \"Going deeper with directly-trained larger spiking neural networks.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 12. 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "Not novel at all!",
            "summary_of_the_review": "In summary, this paper's attempt is worthy to be credited but it really lacks good motivation and novelty.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_FzYt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1895/Reviewer_FzYt"
        ]
    }
]