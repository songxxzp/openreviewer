[
    {
        "id": "j-DaD3Q0Dd",
        "original": null,
        "number": 1,
        "cdate": 1666647247645,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647247645,
        "tmdate": 1666647247645,
        "tddate": null,
        "forum": "QYiN3R9nVUG",
        "replyto": "QYiN3R9nVUG",
        "invitation": "ICLR.cc/2023/Conference/Paper4369/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new dataset for blood volume pulse (BVP) estimation which addresses some shortcomings of existing datasets. A method to estimate BVP from RGB frames is also introduced. Results on the collected dataset and other publicly available datasets are presented and the proposed approach achieves competitive performance without requiring complex pre-processing.\n\n",
            "strength_and_weaknesses": "Strengths\n\nA new dataset is presented which will be a nice contribution (if it becomes available).\n\nWeaknesses\n\nA major weakness in the paper is that it\u2019s not easy to follow the discussion. There are no references to tables or figures, so the reader is left searching for the corresponding tables/figures.\n\nThe introduction reads more like a review of existing methodologies, it\u2019s hard for the reader to understand what the main contributions are since they are described in different paragraphs. It would be good to have a paragraph which lists the main contributions. For example the end of the last paragraph could be extended to summarise all contributions.  \n\nAn ablation study is missing in the paper. This would reveal the impact of each component.\nFor example, the authors use an image of 8 by 8 in order to alleviate privacy concerns. However, this is a very low resolution and it would be good to test the performance of the proposed approach as a function of the input resolution. Another example is studying the impact of the number of convolutional and spectral layers and the impact of the input sequence length.\n\nOne of the main contributions of this paper is the introduction of a new dataset, however only a brief description of the dataset is given and it is not mentioned if the dataset will become publicly available. The latter Is quite important as if the dataset is not released it diminishes the paper\u2019s contribution. It would also be useful to add more details in the dataset description, e.g., age/gender distribution, did all subjects do all tasks, total number of videos and duration of the entire dataset.\n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned above it is not easy to follow the results discussion. The paper also needs proofreading. There are several typos and sentences which need to be rewritten. A non-exhaustive list from the introduction only is the following (but all sections need proof-reading):\n\n(ICA), In Poh et al. (2010b), -> (ICA). In Poh\nnew color space and separates -> \u2026which separates\nseparate present -> maybe separately present (?)\nfacial image segmentation can limit its deployment on mobile devices because it is currently difficult to achieve on mobile devices effectively. -> this sentence needs to be rewritten\nmovements. the large size -> movements. The large\n\nThe authors provide several details about their method but still the results are not fully reproducible since the training and test sets are generated randomly.\n",
            "summary_of_the_review": "There are several weaknesses as explained above which need to be addressed before the paper can be considered for acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_V5oM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_V5oM"
        ]
    },
    {
        "id": "zJy6RQgOIj_",
        "original": null,
        "number": 2,
        "cdate": 1666657274139,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657274139,
        "tmdate": 1666657658586,
        "tddate": null,
        "forum": "QYiN3R9nVUG",
        "replyto": "QYiN3R9nVUG",
        "invitation": "ICLR.cc/2023/Conference/Paper4369/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a simple method, followed by a dataset for remote PPG/BVP monitoring. The proposed method is a simple neural model with reasonable results, and the dataset has 58 participants.",
            "strength_and_weaknesses": "The main strength of the paper is the dataset component of the work. However, the paper, unfortunately, has a number of weaknesses that needs to be addressed. These weaknesses are as follows:\n\n1- The writing, presentation, and editing are not very polished. \n\n2- The paper is very hard to follow. I find it hard to put my finger on what exactly the contributions of the paper are.\n\n3- The proposed method is very simple and trivial, and does not provide any new \"representation learning\" insights.\n\n4- The paper cites several well-known datasets in the area, including MAHNOB-HCI, VIPL-HR, and others, some of which have more participants and are more diverse. It is therefore not clear why a new dataset was needed.\n\n5- The dataset is not very diverse in terms of participants, and many details are missing, e.g. M/F ratio, age range/SD, etc\n\n6- There is no confirmation that ethics approval has been secure, which is really important.\n\n7- The dataset is not made public (and doesn't seem to be planned to go public). So I am not sure if it can be considered a contribution to the area. ",
            "clarity,_quality,_novelty_and_reproducibility": "The work requires polishing and editing, and perhaps a re-write in a few areas. The contributions are not clear. The methodology is trivial, and many details are missing.",
            "summary_of_the_review": "Please see my review above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "Given that the work includes new human-related data, it is not clearly mentioned if ethics approval has been secured or not.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_j11H"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_j11H"
        ]
    },
    {
        "id": "wvIOZS-BHHz",
        "original": null,
        "number": 3,
        "cdate": 1666668282749,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668282749,
        "tmdate": 1669219400425,
        "tddate": null,
        "forum": "QYiN3R9nVUG",
        "replyto": "QYiN3R9nVUG",
        "invitation": "ICLR.cc/2023/Conference/Paper4369/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an approach for extracting the blood volume pulse signal via photoplethysmography from a video.  This use case of computer vision has several positive applications, that could help make scalable physiological sensing possible.  The authors do a thorough job summarizing the existing literature, including many of the most recent papers.  While the summary could be made a little more readable, I think it is a well synthesized introduction to the paper on whole.  The proposed method uses existing but computationally efficient neural layers to extract a PPG signal from the video.  The results overall appear reasonable and the method performs well compared to the baselines in the comparisons that are given.\n",
            "strength_and_weaknesses": "The authors correctly highlight deficiencies with the existing public datasets which are invariably small and limited in diversity. They present a new dataset that they collected which is arguably larger than the existing data. However, their dataset is also limited in diversity with regard to skin types and age, based on the description. I think their claims that their dataset is particularly large in comparison to existing datasets is not really true - it is comparable in order of magnitude. I think that those claims should be tempered a bit. It was not very clear to me whether the dataset will be made available as a benchmark set?  Please clarify - making the contribution of the dataset a central claim in the paper without releasing it is frustrating to readers as it doesn\u2019t help to advance the communities\u2019 efforts, beyond the insights gained from a single paper.\n\nThe authors state that for some existing methods the \"input batch size is 128 frames, which means it has a latency of over 1s. To get a real-time BVP signal, the latency should be as small as possible.\" However, it is not that clear to me in what application a delay of 1 or even a couple of seconds would be a problem.  In heart rate estimation a period of at least 5 seconds would be need at least any way.  Can the authors clarify why a latency of 1 second is significant here?  I can see the memory or compute constraints with a longer temporal window being more significant which may better support the authors arguments here. \n\nThe approach to solving the problem does appear to be novel.  It is interesting that the authors collapse the input to RGB vectors thereby losing spatial information, which is often useful for segmentation.  I would question how sensitive their method is the any face detection or segmentation step they perform. I would appreciate a comment on this, again with little visibility on the dataset they collected it is hard for a reader to ascertain this.  To add to this point, the paper is short on experimental details and while the supplementary material contains model implementations, it does not actually include end-to-end training code which is disappointing as their are often details in steps prior to, or following, a model that impact performance (e.g., segmentation steps, filtering steps etc.). I would appreciate the authors comments on any additional details that could be provided to help ensure reproducibility.\n\nSection 5:  It is still a bit unclear to me after reviewing the paper why the proposed method cannot be trained on other datasets.  Yes, some datasets do not have very highly synchronized PPG and video, but some do.  In my experience, for example, training models with PURE or SCAMPS is possible.  Can the authors be more precise about why training with those existing datasets isn\u2019t possible? I would appreciate a clearer indication or examples to illustrate this.  \nAnd in Table 4 - why wasn\u2019t EfficientPhys, PulseGAN or DualGAN trained on the collected dataset?  Is that because those models were not implemented and the results taken from prior work?\n\nThe above point applied to training, for testing it would seem that the authors could use any dataset.  Why did the authors only choose to test on UBFC and not any of the other benchmark datasets?  This is a significant weakness of the work as almost all other papers manage to test on at least 2-3 public datasets.  Could the authors produce results on these other datasets? \n\nIn Section 5 the authors write: Unlike the time spent per frame in Liu et al. (2020), we calculated the time spent to process a whole batch, which is more reflective of the latency caused by the computation. However, while this is true about latency, it doesn\u2019t reflect the computational cost which I think is more the point (see the comment above about the difference between latency and computational cost). I don\u2019t think latency is really a bottleneck in this application, but computation is. \n",
            "clarity,_quality,_novelty_and_reproducibility": "I have some concerns and the reproducibility and as a related topic, to the comprehensiveness of the results, as described  in the previous section.",
            "summary_of_the_review": "Overall, I believe this application is very exciting.  I think that the proposed method has some novelty and focusing on fast/computationally light algorithms is good.  The paper has the makings of a good contribution that I\u2019d like to support.  However, I feel like the paper as it is currently falls short in empirical support for their method and theoretical support. If the authors can address all these points above - I would be willing to increase my rating.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "I don't have ethical concens per se.  However, I did question above whether it would be possible for the author to release the data used and this would be a question related to their IRB.  I would like to know the plans, as the authors make the dataset a central part of the story in this paper.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_DUL3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4369/Reviewer_DUL3"
        ]
    }
]