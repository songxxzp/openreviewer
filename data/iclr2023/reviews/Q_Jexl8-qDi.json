[
    {
        "id": "mI9xdCgHahU",
        "original": null,
        "number": 1,
        "cdate": 1666319303382,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666319303382,
        "tmdate": 1668866459064,
        "tddate": null,
        "forum": "Q_Jexl8-qDi",
        "replyto": "Q_Jexl8-qDi",
        "invitation": "ICLR.cc/2023/Conference/Paper384/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is concerned about generation of molecules by connecting motifs extracted from the dataset. The main idea of the proposed method is to mine motifs from the dataset. The algorithm, illustrated in Figure 2, first contracts molecular graphs by contracting the most frequent edge, iteratively. Then, motifs are extracted from the contracted graphs as shown in Figure 2 (b), resulting a vocabulary of motifs. \n\nThe authors propose a generative model using the vocabulary of motifs. At each iteration of the generation process, a connection site $v_t$ from partial graph $\\mathcal{G}_t$ is obtained from the queue, and the other site to be connected is queried by Eq. 1, where the query vector is computed from the partial graph and the input $z$, and the key vector is computed from the other connection site, which may be in the vocabulary or in the partial graph itself. The model is trained in a similar way to VAE, minimizing the loss function in Eq. 3.\n\nThe proposed method is evaluated on GuacaMol benchmarks (distributional and goal-directed benchmarks).\nFor  the distributional learning task, the proposed method achieves relatively higher scores than the baselines. In addition, the authors provide how the scores change as we change the number of merging operations, $K$. The results suggest that as we increase $K$, we get larger motifs, which improves the similarity between the generated molecules and those in the dataset, at the cost of the decreased novelty score, as expected.\n\nFor the goal-directed generation result, the proposed model is combined with off-the-shelf optimization modules to generate optimized molecules. The results show that the proposed method achieves better scores than the baseline methods in GuacaMol benchmark. The authors also analyze the generation trajectory to highlight the benefit of utilizing the motif-based approach.",
            "strength_and_weaknesses": "# Strengths\n- The proposed approach is reasonable and the algorithm is mostly easy to understand (except for the details elaborated in the clarity section of my review).\n- In the empirical studies, the authors not only evaluate and compare the performance, but also highlight the properties of the proposed method (Figs. 4 and 5), which are insightful.\n\n# Weaknesses\nRelationship to the work by Guo et al. (ICLR 2022), which is cited in the paper, is not clear. As far as I understand, the method proposed by them generates a molecule using a grammar, which can be interpreted as connecting (connection-aware) motifs, and they also optimize the grammar (equivalently, the set of motifs) so as to bias the generative model towards the direction users specify, which implies that the resultant graph grammar is not heuristically designed but is optimal in some sense. Thus, I consider the method by Guo et al. satisfies the two desirable properties suggested in the introduction. I would like to see in-depth discussion on the relationship between their method and the method proposed in this paper, and if they have similar capabilities, they should be compared empirically.",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity, Quality\nAlthough the illustration in Figure 2 is intuitive and makes it easy to understand the algorithm, I am confused about the contraction operation (the second iteration in the Merging-operation Learning Phase, i.e., lines 15-17 in Algorithm 1). The algorithm says that for each pair $(\\mathcal{F}_i, \\mathcal{F}_j) \\in \\mathcal{E}_M^{(k)}$ (edges in the $k$-th iteration), if $\\mathcal{F}_i \\oplus \\mathcal{F}_j = \\mathcal{M}^{(k)}$ then merge them in $\\mathcal{G}_M^{(k+1)}$ (the graph at the $(k+1)$-th iteration). What I get confused is that when a pair $(\\mathcal{F}_i, \\mathcal{F}_j)$ is contracted, then another adjacent pair, say $(\\mathcal{F}_j, \\mathcal{F}_k) = \\mathcal{M}^{(k)}$, may not appear in $\\mathcal{G}_M^{(k+1)}$ after the contraction, though it exists still in $\\mathcal{E}_M^{(k)}$. This could happen in Figure 2. The original graph has 12 `c:c`s, which can be contracted as in the second left figure in Fig 2 (a), where `c:c` nodes are connected in a triangular shape, but there could be other contraction where we have a square-shape like `(c:c)1:c:(c:c):c:1`. So, I suspect that the merging-operation learning phase is order-dependent, which seems not to be highlighted in the paper. If this is correct, I would appreciate if the authors could discuss about it and how they resolve it; otherwise, I would appreciate if the authors correct my misunderstandings.\n\n# Novelty\nAs pointed out above, grammar-based methods could be closely related to the proposed method. In order to evaluate the novelty of this work, I would like to hear from the authors the relationship to the grammar-based approaches.\n\n# Reproducibility\nThis work will be reproducible because the authors provide the source code.",
            "summary_of_the_review": "I consider this paper is on borderline, leaning to rejection. While I like the proposed method itself, the relationship between the proposed method and the method by Guo et al. is not clear, which is essential to differentiate the proposed method from the methods in the literature. I would like to re-evaluate the novelty and significance after the authors clarify the relationship.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper384/Reviewer_zHsw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper384/Reviewer_zHsw"
        ]
    },
    {
        "id": "wNHR0jFAYE",
        "original": null,
        "number": 2,
        "cdate": 1666604467962,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604467962,
        "tmdate": 1669253662610,
        "tddate": null,
        "forum": "Q_Jexl8-qDi",
        "replyto": "Q_Jexl8-qDi",
        "invitation": "ICLR.cc/2023/Conference/Paper384/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper develops a novel molecular generation method called MiCaM that simultaneously selects motifs from a motif library and determines how they are connected (or terminate the generation). The key feature of MiCaM is that the motif library (motif vocabulary), the collection of frequent substructural fragments, is built directly from the given set of molecules by iteratively merging subgraphs based on their frequency, also with storing the connection information (this was motivated by byte-pair encoding in MLP). Using this pre-acquired motif library with connection information, MiCaM was trained in a VAE manner to generate novel molecules by selecting motifs and combining them in learned ways. The empirical comparisons to several existing baselines such as JT-VAE, GCPN, and GP-VAE, as well as MoLeR (Maziarz et al., 2021) that generates molecules by extending scaffolds with substructural motifs, demonstrate that it can well resemble the distributions of training sets, keeping high uniqueness and novelty, and it can also perform well on goal-directed benchmarks of the GuacaMol benchmarks.",
            "strength_and_weaknesses": "[Strength]\n\n- The paper presented an interesting method that generates molecules based on \"mined\" and \"connection-aware\" motifs. Due to these considerations, the generator part was effectively designed as a VAE model to just select motifs and determine how they are combined with each other.\n\n- The experiments include two demonstrative tasks of distributional learning results (to produce a set of new molecules that are structurally similar to the given training set) as well as the goal-directed generation tasks (to produce new molecules better than the given training set with respect to the target property) using the GuacaMol benchmarks, which are one of the well-designed benchmarking datasets.\n\n[Weaknesses]\n\n- One significant feature of the proposed method is the way to construct motif vocabulary that is not predefined but is directly mined from the given data, keeping the connection information for further generation uses. But this main claim would sound very incremental when considering a previous work [1]. (Disclaimer: I have no relationship at all with the authors of this paper [1][2][3] below)\n\nThe paper [1] uses a traditional chemoinformatics algorithm BRICS [2] with further refinements to construct a motif tree (motifs at nodes and connection information forms a tree hierarchy on motif vocabulary). The authors could check Figure 2 of [1] to describe the motif vocabulary procedure and would find that this traditional procedure can also be pure data-driven (\"directly mined from the given dataset\") and connection-aware (due to the constructed motif tree), i.e., both \"mined\" and \"connection-aware.\" \n\n[1] Zhang et al. Motif-based Graph Self-Supervised Learning for Molecular Property Prediction. (NeurIPS'21)\n    https://arxiv.org/abs/2110.00987\n\n[2] Degen et al. On the Art of Compiling and Using 'Drug-Like' Chemical Fragment Spaces. (2008)\n    http://doi.org/10.1002/cmdc.200800178\n\nBRICS is a well-known way for molecule fragmentation (and further use of it for molecule library construction), and the original paper [2] was highly cited (it was also cited in the GuacaMol paper, for example). Furthermore, the examples of MiCaM motif vocabulary shown in Appendix C.1 would look like those from typical BRICS (or RECAP) fragmentation.\n\nSo to claim the novelty of the \"mined\" and \"connection-aware\" motifs, it would be highly appreciated to compare the difference and investigate the performance and properties of MiCaM over BRICS motifs (or other motif construction methods). It is already well-established to generate new molecules using BRICS motifs, and it would be informative to check the RDKit document to get a BRICS-based generator.\n\nhttp://www.rdkit.org/docs/GettingStartedInPython.html#brics-implementation\n\nGetting these building blocks is practically quite important and well-investigated (outside the ML community, though) because they can subsequently be used to construct virtual screening libraries for targeted drug discovery. For example, a tool called eMolFrag [3] was published in a chemoinformatics journal, and in this paper, the authors can check the related literature on motif vocabulary construction and their use for generating new molecules.\n\n[3] Liu et al., Break Down in Order To Build Up: Decomposing Small Molecules for Fragment-Based Drug Design with eMolFrag. (2017)\n    https://doi.org/10.1021/acs.jcim.6b00596\n\n- Related to the above point, some ablation study would be needed to confirm that this paper's motif-vocabulary algorithm contributes to the reported good performance by defining the MiCaM generation procedure with existing motif vocabularies other than the proposed one. For example, reporting any concrete examples that can be generated from MiCaM but not likely from MoLeR would be very informative to readers.\n\n- From the reported results of Table 1 (GuacaMol), KL Divergence and FCD were better than MoLeR, but Uniqueness and Novelty were worse than MoLeR. This could also suggest that generated molecules from MiCaM are more like the training set and less valuable in the sense of molecular structure exploration. So it would require a more detailed investigation to systematically understand how this difference is in actual examples. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and provides the codebase as supplementary materials for ensuring reproducibility. \nAs for the novelty, it would be a bit incremental, and would be better to relate this vocabulary construction to the standard fragmentation-based library construction such as BRICS and RECAP in chemoinformatics and that in the previous work [1].",
            "summary_of_the_review": "The paper presented an interesting method that generates molecules by selecting and combining \"mined\" and \"connection-aware\" motifs. But possible alternative methods for this vocabulary building, in particular widely ones such as BRICS (also used in the NeurIPS'21 GNN paper [1]), are not evaluated, and the claim of novelty and significance would be unconvincing, at least in its present form.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper384/Reviewer_5Fqs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper384/Reviewer_5Fqs"
        ]
    },
    {
        "id": "iSWHQ_VVRY",
        "original": null,
        "number": 3,
        "cdate": 1666694422013,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666694422013,
        "tmdate": 1669394454047,
        "tddate": null,
        "forum": "Q_Jexl8-qDi",
        "replyto": "Q_Jexl8-qDi",
        "invitation": "ICLR.cc/2023/Conference/Paper384/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the problem of fragment-based molecular generation. The authors propose MiCaM that includes a data-driven algorithm to mine a connection-aware motif vocabulary from a molecule library, as well as a connection-aware generator for de novo molecular generation. For motif vocabulary, the authors evaluated MiCaM on three different datasets and achieved improvement in some metrics. For fragment-based molecular generation,  MiCaM also obtains improvement on goal directed benchmarks.\n\n",
            "strength_and_weaknesses": "Strength:\n  1) Building fragment vocabulary by data mining rather than pre-defining, which can avoid artificial bias.\n  2) Selecting new connection sites from both motif vocabulary and the intermediate molecule itself, which allows generating larger rings.\n  3) The authors conduct different experiments on various datasets and the problem formulation is clear. \n\nWeaknesses:\n  1) The validity rate of the model without chemical validity check was not provided. Some fragments must combine with each other to form chemical groups (e. g. aromatic systems), therefore only depending on data mining to build motif may neglect this entirety. For example, motif \u2018Cc1ccnn1\u2019 in Figure 11 is chemically invalid, since it violate the H\u00fcckel's rule.\n 2) Results in Table 1 indicate that the proposed model did not outperform other baseline models significantly in terms of uniqueness and novelty. The improvements in some metrics for the primary results are very weak, which makes me wonder if the authors' many choices are well justified. The authors could conduct more downstream tasks on the motif-vocabulary to demonstrate the benefits.\n 3) How does the model control the size of the molecules generated in the goal directed generation task?\n 4) How does the molecule scoring in the Table 2  define?   Can you demonstrate that the improvement comes from the selection of the motif vocabulary? \n 5)  Careless writing, e. g. the \u201cZINC\u201d dataset sometimes is written as \u201cZINK\u201d.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Expression of this paper is not good enough, which makes it hard to read. \nThe method is relatively novel, but the improvement is not significant.\n",
            "summary_of_the_review": "Expression of this paper is not good enough, which makes it hard to read. \nThe insight of the proposed model is reasonable but the implementation may neglect chemical rules.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper384/Reviewer_3hrY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper384/Reviewer_3hrY"
        ]
    },
    {
        "id": "2ciwDZmEXj",
        "original": null,
        "number": 4,
        "cdate": 1666991753328,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666991753328,
        "tmdate": 1666991753328,
        "tddate": null,
        "forum": "Q_Jexl8-qDi",
        "replyto": "Q_Jexl8-qDi",
        "invitation": "ICLR.cc/2023/Conference/Paper384/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presented a novel fragment (motif) based generative model for molecules. The motif vocabulary is mined from the molecule dataset by iterative merging small motifs into larger ones and keeping the most frequent ones from each iteration. Then a generative model is learned to construct the motifs into molecules. In each generation step, the model embeds the motif candidates, the connection site, and the partial molecule into the embedding space and uses a pointer mechanism to select the next motif to connect to the site. The proposed method achieved competitive distributional learning performance on several molecule datasets. It can also be used in goal-directed generation tasks.",
            "strength_and_weaknesses": "Strength:\n- The paper presented a Byte-Pair-Encoding-like motif mining algorithm for molecules and demonstrated its usage together with a VAE-based generative model using the mined motifs as building blocks. To my knowledge, such a subgraph mining method is novel and could be used as a generic graph generative model.\n- The pointer mechanism in Equation (1) allows the model to select from a set of candidates with varying sizes. Compared with using a trainable embedding vector for each motif, using a GNN to embed the motifs allows the model to generalize to less seen motifs. Similarly, such a method allows the sharing of information between different connection sites.\n- Negative sampling (or contrastive learning) is employed to reduce computational costs during training. \n- The distributional learning experiment demonstrated the competitive performance of the proposed method.\n\nWeaknesses:\n- Lack of baseline comparisons in the goal-directed generation experiments.\n- Several motif-based goal-directed molecule generation methods are not included and discussed in the paper. Jin, Wengong, Regina Barzilay, and Tommi Jaakkola. \"Multi-objective molecule generation using interpretable substructures.\" International conference on machine learning. PMLR, 2020. Chen, Binghong, et al. \"Molecule optimization by explainable evolution.\" International Conference on Learning Representation (ICLR). 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is written clearly. The paper provided implementation details and code for reproducibility. Refer to the previous question for Quality and novelty.",
            "summary_of_the_review": "This paper presented a novel fragment-based generative model for molecules. Empirically this method achieved competitive distributional learning performance. Overall the contribution of this paper is solid.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper384/Reviewer_Gyc8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper384/Reviewer_Gyc8"
        ]
    }
]