[
    {
        "id": "R9a97ywzovX",
        "original": null,
        "number": 1,
        "cdate": 1666360889063,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666360889063,
        "tmdate": 1670775875138,
        "tddate": null,
        "forum": "XHiC52N24ox",
        "replyto": "XHiC52N24ox",
        "invitation": "ICLR.cc/2023/Conference/Paper1926/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper investigates the effect of noise injection in the form of additive noise during training and inference of a specific class of neural network models energy based generative models, which are roughly variational encoders whose output is interpreted as energy: smaller energy corresponds to the correct class prediction. Several claims about properties of additive noise are made and multiple experimental results are provided. In particular, it is claimed that additive noise is equivalent to dropout and data augmentation, also that additive noise during inference improves accuracy. Experiments compare multiple different setups of the proposed noisy model on different datasets.",
            "strength_and_weaknesses": "The paper demonstrates results of a very large amount of experiments, performed for different setups and with standard deviation of the run results. Unfortunately, there are no comparisons to any other regularizations and no reports of state-of-the-art results in the field, so it is very hard to judge how beneficial the proposed scheme is.\n\nThe paper is greatly over-claiming the obtained results.\nThe proposed proof of the equivalency of dropout to additive noise is based on the introduced in the paper negate random variable, which is supposed to follow the distribution of activations but being negative of the value. First, I am not sure that constructing such a variable possible in general. Second, this does not prove equivalence to binary dropout, because a mask is sampled anew every time - this will mean that additive noise has to change distribution on every step to correspond to the new mask. Moreover, dropout can be not only binary, but also continuous. \nThe announced in the abstract 200% improvement of the accuracy is seen only in the particular setup considered. It is not specified if the initial model (without noise) has been fine-tuned to perform best on the problem. In such setup adding regularization can obviously lead to very large positive changes, not confirming that particularly additive noise can improve a model twice.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly, easy to follow.\n\nThe novelty of the paper is under the question. For example, [1] already in 1996 considered different types of noise showing that it performs regularization. The claim of equivalence to dropout is not correct and equivalence to data noise does not require a proof. Analogously, the claim that usage of the same noise during inference and training does not require a proof. Moreover, original inference scheme of the dropout is sampling, but since it is computationally expensive the rescaling approach was proposed: thus inference with sampling is not novel as well.\n\nThe supplementary material includes code, so the results are reproducible with high probability.\n\n[1] G.An \"The effects of adding noise during backpropagation training on a generalization performance\"",
            "summary_of_the_review": "The paper investigates an interesting matter of additive noise injection during training and inference. The problem is considered in a particular setup of energy based models. The theoretical claims made in the paper are not significantly novel and some are incorrect. The practical results are presenting an extensive evaluation of the different setups of the model, without any benchmarks or comparisons.\nIn the current state the paper is not ready for publication. \n\n----\nI thank the authors for the reply. Nevertheless, I believe that in its current form the paper has flaws that prevent it from being published. Therefore I stick to my current score.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_BpSj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_BpSj"
        ]
    },
    {
        "id": "_79b-zjwkmD",
        "original": null,
        "number": 2,
        "cdate": 1666682378855,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682378855,
        "tmdate": 1666682378855,
        "tddate": null,
        "forum": "XHiC52N24ox",
        "replyto": "XHiC52N24ox",
        "invitation": "ICLR.cc/2023/Conference/Paper1926/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper generalizes and studies activation noise for both training and inference for the specific case of energy-based models. Core contributions include 1) using activation noise helping at inference time (typically dropout is not used at inference time) and 2) through study of which pairs of distributions of noise works best at training and inference time ",
            "strength_and_weaknesses": "Strengths\n- This paper generalizes dropout to activation noise and studies it thoroughly using controlled set of experiments\n- Using activation noise at inference time seems novel (I have not seen it before) and likely generally useful\n- The paper also presents an interesting negative result that activation noise is not effective for discriminative modeling.\n\nWeakness\n- Caption for Table 1 can be made more descriptive so that the reader can look at it in a self-contained way.\n- While the phenomena is novel, the most impressive results are obtained using 10^4 samples on all the datasets. I'm unsure as a reader if this has practical benefit even on a moderately larger models than the paper considers. I think at least a discussion how the insights can be used would make the paper stronger.",
            "clarity,_quality,_novelty_and_reproducibility": "Barring a few minor issues, the paper is easy to read and the insights look novel. No issues on reproducibility.",
            "summary_of_the_review": "While the paper presents interesting observations using thorough experiments, the practical significance of these results is not apparent.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_Zh4D"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_Zh4D"
        ]
    },
    {
        "id": "hLw8oDPMtg",
        "original": null,
        "number": 3,
        "cdate": 1666682873804,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682873804,
        "tmdate": 1666682873804,
        "tddate": null,
        "forum": "XHiC52N24ox",
        "replyto": "XHiC52N24ox",
        "invitation": "ICLR.cc/2023/Conference/Paper1926/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a method to add noise in EBM in classification tasks. The likelihood and loss functions are derived based on the injected noise $z$. The paper claims adding noise during training includes dropout as a special case, and propose to add the same amount of noise during inference. On image classification tasks, the paper shows increased accuracy when adding the proper amount of noise. ",
            "strength_and_weaknesses": "Strengths:\n\n- The paper has a good overview of literature. \n- Adding noise to EBM seems to be a novel approach.\n- Experiments show huge improvement on classification results. \n\nWeaknesses:\n\n- The title is too big and does not match the paper. Noise is added in both training and inference. Also, since the paper focuses on EBM applied to classification tasks, the title must reflect that. \n- The presentation of methodology is confusing. \n  - It would be nice to have a detailed paragraph on how to mathematically perform classification with EBM (or ten AEs for these classes). I notice that you perform $\\arg\\min_y E(x|y)$ in the paragraph after eq(10). Is it just intuition or derived from Bayes rule applied to $p(y|x)$? \n  - Def 1 and Prop 1 seems straightforward and do not convey much insights. In practice we do not expect the dropout case to happen. What theory do you have for other types of noises? \n  - Eq (5): why use MSE for energy? Why can you decompose $x$ with independent $x_k$? \n  - Thm 1 should be in methodology section rather than experiment section. A theorem concluding empirical findings is much weaker than one that predicts. In addition, this theorem seems straightforward and I do not find anything interesting. \n- The experiments do not show interesting results.\n  - How is the task different from standard classification tasks? If not, why are we interested in this approach, instead of just using standard methods? \n  - What are some interesting applications of the proposed method? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has some clarity and quality concerns based on the comments above. There is some novelty in the sense that adding noise to EBM is a new idea. The paper has code in the supplementary file. ",
            "summary_of_the_review": "I think the paper needs significant improvement on writing and technical results. I do not think this draft can be accepted, but my decision might change based on authors' reply and revised version.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_Ysne"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_Ysne"
        ]
    },
    {
        "id": "QqPb5e8Nw1",
        "original": null,
        "number": 4,
        "cdate": 1666764447680,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666764447680,
        "tmdate": 1666764447680,
        "tddate": null,
        "forum": "XHiC52N24ox",
        "replyto": "XHiC52N24ox",
        "invitation": "ICLR.cc/2023/Conference/Paper1926/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors investigate the effect of activation noise (additive noise applied after the activation function) on an EBM based classification approach.\nThey mathematically describe activation noise during training and inference and come to the conclusion that (i) activation noise can be understood as a generalisation of dropout and (ii) that the loss at inference is minimised when the distribution of noise is used during training and inference.\nIn their experiments, the  authors demonstrate the latter point (ii) empirically and compare the effect of different activation noise distributions on classification accuracy.\nThey find that symmetric noise distributions are to be preferred.\n\n ",
            "strength_and_weaknesses": "**Strengths:**\n* I believe the topic is important and the community can benefit from papers taking a theoretical look at regularisation methods like this.\n* The paper is well written and included some interesting insights.\n* I appreciate the experiments done by the authors, especially that the benefits of noise during inference are investigated.\n\n\n**Weaknesses:**\n* Unfortunately, some of the theory is not completely clear to me and I am not sure I agree. See below.\n* The authors say that that dropout is a special case, but they do not include it in their experiments. This is unfortunate, because dropout is so widely used\n* I think the authors miss a point about the connection between dropout and activation noise.\n\n**Detailed comments:**\nMost importantly, I think the formulation in Eq. 4 might be problematic.\nThe authors give their objective for jointly optimise the network parameters theta and noise distribution q(z) to maximise the conditional log likelihood of their training data drawn form the distribution p_D(x,y). \nHowever, their model p_theta(x|y,z) is conditioned on the noise z instead of integrating over it.\nThis objective essentially tries to make p_theta(x|y,z) approximate p_D(x|y) (which could be derived from p_D(x,y)) for each z sampled form q(z). \nConsidering now that p_D(x|y) does not depend on z, the optimal solution for this objective would be to make q(z) infinitley concentrated on 0, as z cannot contribute to better approximate p_D(x|y), right?\n\nLater in Eq. 9, when the authors discuss inference, they use a different formulation, integrating the energy over the noise and then choosing the class with the lowest integrated energy. Here, the noise becomes part of the model.\nI think this approach is more sensible, but it is in conflict with Eq. 4, where we are integrating the log probabilities.\nThis is different, because of the partition function, right?\n\nRegarding viewing dropout as special case of activation noise, I agree with this perspective.\nHowever, in contrast to the perspective taken by the authors, the activation noise distribution that would result in dropout behaviour, would have to depend on the input x, as it has to (with a certain probability) exactly cancel out the activation of the neuron.\nThe types of activation noise considered in the paper generally don't depend on x.\nDoes the finding that we should use noise during inference hold for dropout?\n\n\n\n\n\n \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.\nThe paper is novel as far as I can tell.\nI believe the paper is reproducible.",
            "summary_of_the_review": "All-in-all, I think this is an interesting paper on an important topic.\nHowever, there are parts of the theory that I cannot follow.\nI believe this has to be clarified to be ready for publication.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_qks6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1926/Reviewer_qks6"
        ]
    }
]