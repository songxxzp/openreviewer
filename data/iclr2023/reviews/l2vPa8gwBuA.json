[
    {
        "id": "ZGZKBnQo6n",
        "original": null,
        "number": 1,
        "cdate": 1665706675444,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665706675444,
        "tmdate": 1670206779643,
        "tddate": null,
        "forum": "l2vPa8gwBuA",
        "replyto": "l2vPa8gwBuA",
        "invitation": "ICLR.cc/2023/Conference/Paper6204/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper considers the problem of unlabeled sparse recovery under\nmultiple linear measurements. Statistical theorems are derived for\nunderstanding the proposed estimator.",
            "strength_and_weaknesses": "*STRENGTH*:\n- The paper derives two solid theorems about permutation recovery:\n  - Theorem 2 states that exact permutation recovery is impossible for\n  fixed $m$ and $p$, as long as $n$ approaches infinity. The condition\n  is very simple and the theorem is very clean.\n  - Theorem 3 states that the ground-truth permutation can be recovered\n  exactly with high probability by solving the linear assignment\n  problem (2), as long as (iv) SNR is larger than some constant,\n  (iii) the number of permuted rows is small enough, (ii) the stable\n  rank of the ground-truth matrix is larger than some logarithm of the number\n  of samples, and (i) we have sufficiently many samples. Once the\n  permutation is correctly recovered, the recovery of the ground-truth\n  matrix ensues, based on the results in compressed sensing.\n\n- Figure 2 presents an interesting phenomenon where\n  the number of samples is actually a double-edged quantity in this\n  problem. As Remark 2 discussed, larger $n$ violates the stable rank\n  condition (ii). Another perspective might be found in Theorem 2 and\n  Theorem 3: With $m$ and $p$ fixed and $n$ approaching infinity, the\n  recovery of the permutation becomes impossible. All these suggest\n  that, in order for exact recovery, the parameters $m,p,n,h$ might\n  have a more sophisticated dependency than the theorems reveal. It\n  would be interesting future work to discover such dependency.\n\n- The proof outline (Sec 4.2) is great as it helps the reader to better\n  appreciate the technical challenge and thus the contribution of the\n  paper.\n\n- I found Table 1 informative. It positions the paper in the\n  literature very well. From it, one can also find that the paper\n  advances our theoretical understanding of the problem.\n\n*WEAKNESS AND QUESTIONS*:\n- In Theorem 2, the supremum is taken over $B_{p,m}$. Why this is\n  required? I thought that, since $n$ approaches infinity, this set\n  would eventually be the entire set of $p\\times m$ matrices.\n  Furthermore, should it be stated in Theorem 2 that the ground-truth\n  matrix is given as in Theorem 1? Or this is actually not needed for\n  the sparse case?\n- Personally, I think that, if possible, it would be greater if an\n  explanation is given regarding the phenomenon discussed in Remark 1\n  and Figure 1. I guess the authors have an answer as to keeping more\n  entries might break down the proof. This discussion is important as\n  the situation is very different from what is commonly known.\n- Sec 4.3 looks a little bit mysterious to me. It seems not very\n  rigorous to claim that the proposed estimator is computationally\n  optimal. For example, despite being incorrect, the estimator that\n  returns an identity permutation and a zero matrix is computationally\n  optimal, as it does not require any computation, let alone matrix\n  multiplication which is needed by the proposed method. The\n  point is, to make such a claim, one needs to prove that (informally\n  speaking) there is no estimator that takes fewer operations\n  (constrained to its correctness).\n- Why is the paper titled *one-step estimator*? The proposed algorithm takes\n  two steps, first recovering the permutation and then the sparse matrix.\n\n*MINOR COMMENTS*:\n- Typos or grammar problems at:\n  - the first line of page 5 (sine -> since)\n  - footnote 4 (extend -> extent)\n  - the line below Equation 5 (accomplish -> accomplished)\n  - the last line of page 7 (is -> are)\n\n- There seems to be some citation issue at the transition of page 4\n  and page 5. Please fix it.\n\n- In the abstract, it is claimed that the case of the sparse unknown\n  matrix in the *insufficient samples regime* is considered for the\n  first time. This might be an overclaim. See for example\n  - [1] Compressed sensing with unknown sensor permutation (ICASSP\n    2014). There, the *insufficient samples regime* is studied\n    computationally (Sec 3).\n  - [2] Sparse recovery with shuffled labels: statistical limits and\n    practical estimators. There, the *insufficient samples regime* is\n    studied theoretically and computationally (as the paper noted).\n  - [3] Homomorphic sensing: sparsity and noise (ICML 2021). There, the\n    *insufficient samples regime* is studied theoretically and\n    computationally (Sec 3).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly, while there are a few typos as mentioned above.\n\nTo the best of my knowledge, the result is novel, despite the fact that it is built upon the analysis framework of several prior works.",
            "summary_of_the_review": "The paper provides some solid theoretical results, and reports and explains some intriguing phenomena for the problem of unlabeled permutation recovery. While I have a few questions and comments, they are somewhat minor and can be easily addressed. In summary, I think this is an interesting paper and I vote for accept. (I did not check the proof in the appendix.)",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_BXq7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_BXq7"
        ]
    },
    {
        "id": "gOnMhxcZA0A",
        "original": null,
        "number": 2,
        "cdate": 1666656188502,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656188502,
        "tmdate": 1666656188502,
        "tddate": null,
        "forum": "l2vPa8gwBuA",
        "replyto": "l2vPa8gwBuA",
        "invitation": "ICLR.cc/2023/Conference/Paper6204/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work considers the problem of reconstructing sparse vectors from an underdetermined system of equations when the measurements are commuted.\nFirst, it gives a lower bound on the required number of measurements given a certain SNR.\nThen, it analyses an estimator which gives corresponding upper bounds (depending on the number of measurements, signal-noise-ratio, sparsity level, ambient dimension, etc.)\nThe paper shows that one can reconstruct the sparse signals, even when the noise level is constant and when the number of measurements is quadratic in the sparsity level.\nNumerical experiments corroborate the theoretical findings.",
            "strength_and_weaknesses": "Strengths:\nTo the best of my knowledge, the novel results go clearly beyond existing work (constant SNR in the undersampled regime) and should be interesting to people working on these topics.\n\nWeaknesses:\n1.The dependence of the number of measurements on the sparsity level is quadratic instead of linear. \n2. Also, I don't really understand Section 4.2. Why does the Theorem follow form inequality (4)? I also don't understand why the inequality on page 8 is true. I am also not sure whether I understand how $()_{\\imax}$ is defined.\n3. In general, the presentation of the material can be improved; see some of the comments below.\n\nFurther comments:\n1. page 3: It might be good to explain how the expression $ \\log \\det \\left( I + \\frac{B^T B}{\\sigma^2}  \\right) $ relates to the SNR!\n2. page 3: \"let $n$ approach infinity\". Consider replacing this statement with something more rigorous. Is this an asymptotic or non-asymptotic statement?\n3. page 4: It seems to me that $\\mathcal{B}_{p,m}$ also depends on $k$. It would be good to make this dependence explicit, for example, by adding $k$ as a subscript.\n4. page 5, Theorem 3 and Corollary: Consider replacing \"Consider the large-system limit...\" by something more rigorous. (It is not clear whether this is an asymptotic or non-asymptotic statement!)\n5. page 5, Corollary 1: \"where $n$ and $p$ are sufficiently large. Consider replacing this by a more rigorous statement.\n6. page 5, Theorem 3: Has $h$ been already properly introduced? If yes, it might be a good idea to recall its definition!\n7. page 7: Why does $ \\Vert B^{\\sharp} \\Vert_F $ affect the reconstruction error? I do not understand this statement.\n8. page 8, Discussion w.r.t. sparsity number $k$: In contrast to your experiments, Theorem 2 does not say that one needs to increase the SNR when one increases the sparsity level $k$. Please add an explanation why this is not a contradiction.\n\nTypos:\n1. page 5 sin(c)e all these works",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned above, the clarity of writing can be improved. The results are novel and are clearly interesting. I was not able to check the proofs in detail.",
            "summary_of_the_review": "The paper has novel and interesting results, but I feel that the presentation can be significantly improved. I would recommend (borderline) acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_7u4U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_7u4U"
        ]
    },
    {
        "id": "6SMNSo-IEo",
        "original": null,
        "number": 3,
        "cdate": 1666667578060,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667578060,
        "tmdate": 1666668033043,
        "tddate": null,
        "forum": "l2vPa8gwBuA",
        "replyto": "l2vPa8gwBuA",
        "invitation": "ICLR.cc/2023/Conference/Paper6204/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the problem of unlabelled sparse recovery under multiple measurements. More formally, Given $(Y, X)$ such that $Y = \\Pi^* X B^*+ W$, where $W \\in \\mathbb R^{n \\times m}$, $W_{i, j} \\sim N(0, \\sigma^2)$, $X \\in \\mathbb R^{n \\times p}$, $X_{i, j} \\sim N(0, 1)$ and each column of $B^* \\in \\mathbb R^{p \\times m}$ is $k$-sparse, the goal is to recover $B^*$ and the unknown permutation matrix $\\Pi^*$. \n\nThey show the following: \n\n1. The sample complexity $n$ should be at least of the order $\\Omega(k \\log p)$ where $k$ is the sparsity of the signal vectors and $p$ is the ambient dimension. Also, the SNR is lower bounded by $\\log det(I + ({B^*}{B^*}^T)/\\sigma^2) \\geq \\log(n) + (m/n) \\log(C(p,k))$.  \n2. By formulating the correspondence recovery as a linear assignment problem (LAP), they show that the correct permutation matrix\ncan be obtained when SNR is above certain positive constant.\n\nTheir results are the first ones s.t. SNR $\\geq \\tilde \\Omega(1)$ is sufficient to obtain the correct permutation matrix with insufficient samples.  ",
            "strength_and_weaknesses": "Strengths: \n1. The paper provides new lower bounds on SNR and sample complexity required for recovery for the problem of unlabelled sparse recovery under multiple measurements. \n2. It demonstrates a simple estimator which requires much lower SNR than prior works, in the regime where the number of samples is much smaller than the ambient dimension. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is clearly written. \nQuality: I think this is a good paper and vote to accept it. \nNovelty: The paper has some technical novelty involved in extending and modifying prior proof techniques to the setting that they consider. \nReproducibility: As far as I could tell, the authors do not provide the code for their experiments. However, there is a detailed description of the method and so they are probably reproducible.  ",
            "summary_of_the_review": "I think this is a good paper and vote to accept it. The paper seems to provide a concrete improvement over the prior work and the estimator is simple. I have not read the proof in the appendix. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_Q6i9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_Q6i9"
        ]
    },
    {
        "id": "evCfc3IycV",
        "original": null,
        "number": 4,
        "cdate": 1666788972579,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666788972579,
        "tmdate": 1666789148615,
        "tddate": null,
        "forum": "l2vPa8gwBuA",
        "replyto": "l2vPa8gwBuA",
        "invitation": "ICLR.cc/2023/Conference/Paper6204/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors provide theoretical guarantees for unlabeled sparse recovery with multiple measurements. They first establish the information-theoretic lower bounds with respect to the number of samples and signal-to-noise ratio (SNR) for the reconstruction of both the permutation and signal matrices. Then, they propose a one-step approach for reconstructing the permutation matrix (and the signal matrix can be easily reconstructed by using the estimated permutation matrix and standard compressed sensing techniques). Some experiments on synthetic data are provided to support the theoretical results. ",
            "strength_and_weaknesses": "Strength:\n\nThe studied problem is at least of sufficient theoretical interest, and the technical results seem to be novel. Besides, the proposed algorithm is sufficiently simple.\n\nWeaknesses:\n\n1. The theoretical results are not clearly interpreted. For example, the authors mentioned, \"For the sample number $n$, the lower bound requires $n$ to be at least of order $O(k \\log p)$; while Corollary 1 requires $n$ to be \u0000$k(\\log n)(\\log^2 m n p)$\u0000\" on page 6. Where does the lower bound come from? I guess it is not derived from Theorem 2 in this paper but from the lower bounds established in standard compressed sensing literature. The authors mentioned on page 2 that the lower bound is established with respect to both the number of samples and SNR. But I cannot see it clearly from the statement of Theorem 2. In addition, it is fairer to compare the lower bound with the upper bound for the number of samples established in Theorem 3 (which has a quadratic dependence on $k$), rather than Corollary 1, which is based on a seemingly restrictive assumption. \n\n2. It is counter-intuitive to see that no matter how large $k$ is, the thresholding operator used in Eq. (2) that only keeps the element with the largest magnitude in each column works well. I hope that the authors can provide more intuitions/explanations for this, instead of only presenting Figure 1. The authors mentioned that \"In the supplementary material, we give a rigorous explanation of this phenomenon\" on page 5. But I cannot find where is a rigorous explanation. Please specify it. \n\n3. The authors claimed in the conclusion that \"we considered the unlabeled sparse recovery with multiple measurements for the first time\". Although the studied problem is interesting in theory. From the current submission, I cannot see how practically meaningful it is. I hope that the authors can provide some numerical experiments on real data to back up the theory. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is generally well-written. But there is a lack of rigorous/intuitive interpretations of the main theoretical results. \n\nThe technical results seem to be novel. \n\nAlthough this paper only involves synthetic experiments, it is better to upload the code for reproducibility.\n\nSome minor problems:\n\n(a) Page 2: provide a reference for the linear assignment problem (LAP).\n\n(b) Eq. (3): provide clear definition of $\\||\\mathbf{B}\\||_1$.  \n\nDoes it mean the sum of entries of $\\mathbf{B}$ (in magnitude), or the operator norm $\\||\\mathbf{B}\\||_{1\\to 1}$?\n\n(c)  Page 4: the definition of $\\mathrm{supp}(\\mathbf{B})$ should be given.",
            "summary_of_the_review": "Overall, I think that although this submission is interesting in theory, it is weak in both interpreting the main theoretical results and presenting the practical motivation. Therefore, I am inclined to rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_KfQu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6204/Reviewer_KfQu"
        ]
    }
]