[
    {
        "id": "1YdpITYoyQT",
        "original": null,
        "number": 1,
        "cdate": 1666597509149,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666597509149,
        "tmdate": 1669015460970,
        "tddate": null,
        "forum": "CW6KmU5wPh",
        "replyto": "CW6KmU5wPh",
        "invitation": "ICLR.cc/2023/Conference/Paper4123/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new unsupervised metric for evaluating the disentanglement of generative models (named PIPE), and a new approach for training disentangled variational autoencoder (named DAVA). PIPE evaluates the distinguishability of the distribution of reconstructed samples and the distribution of generated samples from factored posterior latent distribution. DAVA involves minimizing the distance of the above two distributions. Experiments show that the PIPE correlates well with supervised metrics, and DAVA achieves state-of-the-art disentanglement results on various datasets.",
            "strength_and_weaknesses": "\nStrength:\n\n* The paper is well-written and easy to read.\n\n* The proposed disentanglement metric can be useful for future work.\n\n* The proposed disentanglement approach shows promising results on several datasets.\n\nWeaknesses:\n\n* Important prior work is missing in the discussion and evaluation.\n    - The paper considers UDR as the baseline unsupervised metric for experimental comparison. ModelCentrality (https://arxiv.org/pdf/1906.06034.pdf) is another unsupervised metric and it was shown that ModelCentrality correlates better with the supervised metrics and is better at selecting disentangled generative models (both VAEs and GANs) than UDR. Given that ModelCentrality is proposed more than 2 years ago and performs better than UDR, it is important to discuss and compare with ModelCentrality in the paper.\n\n* Some details are missing in the main text. \n    - For the experiments in Section 4, which generative model is used in the experiment, and how many models are used?\n    - The paper discusses the automatic process for tuning C and mu during training. Does it mean that we still need to tune gamma manually?\n\nBesides the above points, I have the following questions:\n\n* PIPE depends on training a classifier (neural network). Would it be sensitive to the hyper-parameter choices (e.g., architecture, number of training iterations)? It is better to discuss it in the paper.\n\n* The key idea of DAVA is similar to FactorVAE. The difference is that FactorVAE regularizes the distance between the posterior latent distribution and the factored posterior latent distribution in the latent space using a total variation loss, while DAVA regularizes the distance in the image space (after passing the latents through the decoder) using an adversarial loss. Why is the approach in DAVA better than FactorVAE? I understand that in DAVA the hyper-parameters can be automatically tuned based on the accuracy of the introduced discriminator (section 5), but we can also do the same if FactorVAE's total variation loss is used in place of L_{dis} (i.e., tuning C and mu according to the loss value of total variation).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nClarity: The paper is overall well-written.\n\nQuality: The paper is of good quality (except for the above points).\n\nReproducibility: the paper provides both the code and the detailed hyper-parameter settings.\n\nNovelty: The proposed approach is new. However, the key idea shares some similarities to prior work (see above), and more in-depth discussion on the benefit/difference is needed.\n",
            "summary_of_the_review": "\nThe paper is well-written, and the proposed metric and approach could be useful for the community. However, due to the above problems, I cannot give a positive score at this point. I recommend the authors address the questions in the rebuttal, and I will adjust the score accordingly.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_SzgX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_SzgX"
        ]
    },
    {
        "id": "8P-Uaa0dmTX",
        "original": null,
        "number": 2,
        "cdate": 1666633004435,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633004435,
        "tmdate": 1666633004435,
        "tddate": null,
        "forum": "CW6KmU5wPh",
        "replyto": "CW6KmU5wPh",
        "invitation": "ICLR.cc/2023/Conference/Paper4123/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel way to encourage disentangling of representations for VAE-like models.\n\nThey introduce 2 distributions over samples x, D_EP which is the empirical distribution one would usually use with a VAE (where $q(z) = E[q(z | x)]$), and D_FP, which replaces the distribution over z with its forced factorial version $\\bar{q}(z) = \\prod_i q(z_i)$. One can generate samples and images from either distributions, and how much they differ is a signal for disentanglement. \n\nThis can then be used as a metric (which they call PIPE, Posterior Indifference Projection Equivalence), or as an extra loss, by using a Discriminator to penalize a model where these two distributions differ. They also show how one can use the same metric to control the capacity of a model on the fly, which is a good addendum as well. Finally, they show good results on a good set of well accepted simple benchmark datasets.",
            "strength_and_weaknesses": "1. It might be good to mention that this really only allows for unidimensional disentangling? \n   1. You mention this fact with DCI, but it might be the case that more complex datasets require correlated subspaces, which this metric/regularisation would discourage?\n   2. What happened in your case for the DAVA model, say on AbstractDSprites? How was color or angle represented?\n2. You do not comment on how to sample from D_FP vs D_EP, and on the potential difference in computational cost of both in the main text.\n   1. When looking in the Appendix at Algorithm 1, one can see that you obtain \\bar{z} simply by permuting the dimensions of z, but that wasn\u2019t clear from reading the main text. \n   2. It also doesn\u2019t seem to be strictly the same as what the definition of D_FP implies, i.e. I was wondering if/when you would compute the marginal over the whole dataset?\n   3. This should probably be expanded upon, as it is quite critical.\n3. I found Figure 6 interesting, and the overall idea of automatically adapting the capacity of the VAE based on this schedule is a nice addendum.\n   1. It might be worth comparing it to more standard techniques however, like GECO [1] or simpler heuristics like [2]\n4. The abstract and start of the introduction is clear, and I found the related work to be quite thorough as well. However, I found the end of the introduction, which introduces the main idea of the paper, to be slightly hard to follow (despite being quite clear afterwards).\n   1. More precisely, the section from \u201cif a VAE learned a truly disentangled [...]\u201d till \u201cis a necessary condition for disentanglement\u201d is too compressed to be understood on a first read. It now makes sense to me after having read the paper, but I would recommend simplifying/reworking it.\n5. Section 3 is strong and well-derived, I felt like Figure 2 supported the arguments very clearly too. Similarly, Section 4 and 5 are strong and clear and contained all the experiments and clarifications I wanted to see.\n\n\n[1] https://arxiv.org/abs/1810.00597 \n[2] https://arxiv.org/abs/2002.07514 ",
            "clarity,_quality,_novelty_and_reproducibility": "* As explained above, the main text is really clear apart from the few mentioned issues.\n* Quality is high, with a good set of datasets and clearly executed experiments. \n* Even though some ideas were already present in the literature this is novel enough work in my opinion.\n",
            "summary_of_the_review": "I found this work to be clear, well executed, it introduces several good ideas which I think the community can easily build upon, and presents good evidence of its capabilities, hence I would lean towards acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_GT7q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_GT7q"
        ]
    },
    {
        "id": "4V30YxK39Ln",
        "original": null,
        "number": 3,
        "cdate": 1666648239772,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666648239772,
        "tmdate": 1669035479763,
        "tddate": null,
        "forum": "CW6KmU5wPh",
        "replyto": "CW6KmU5wPh",
        "invitation": "ICLR.cc/2023/Conference/Paper4123/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work developed an adversarial variational auto-encoders to learn the disentangled representations of observed data in an unsupervised manner. Specifically, it introduced a new metric that computes the difference of the reconstruction between EP and FP to measure disentanglement. Experimental results on multiple datasets illustrated the effectiveness of the proposed method.",
            "strength_and_weaknesses": "* Strength\n1. The introduced PIPE metric is interesting and somewhat novel.\n2. Conduct extensive experiments on benchmark datasets to verify the effectiveness of the proposed approach \n\n* Limitations\n1. Technical innovation is somewhat limited. The proposed model is quite similar to the adversarial variational auto-encoders in prior work [Han et al. 2020] and [Carbajal et al. 2021] except for the metric PIPE. The defined EP and FP are not new concepts as they are already used in prior work such as FactorVAE and \\beta-TCVAE.\n2. Compared to more recent baselines. This work only compared the proposed approach with the baseline methods before 2020. It would be better to compare the proposed method with some latent baselines, such as ControlVAE [Shao et al 2020] and Recursive Disentanglement Network [Chen et al. 2021], and Jacobian regularization [Wei et al 2021]. For instance, ControlVAE also dynamically tunes the hyperparameters in the VAE objective function based on the output KL-divergence to improve the disentanglement.\n3. Some latest works are missing. The authors only introduced the related work before 2019 while missing some latest work on disentangled representation learning, such as ControlVAE, Recursive Disentanglement Network, and Jacobian regularization as mentioned above. \n4. There is a trade-off between reconstruction error and disentanglement. It would be better to compare the reconstruction error with that of prior work, such as FactorVAE and ControlVAE.\n\nReferences:\n[Chen et al. 2021] Recursive Disentanglement Network. In International Conference on Learning Representations, 2021.\n[Wei et al 2021] Orthogonal jacobian regularization for unsupervised disentanglement in image generation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 6721-6730).\n[Han et al. 2020] Disentangled adversarial autoencoder for subject-invariant physiological feature extraction. IEEE signal processing letters, 27, 1565-1569.\n[Carbajal et al. 2021] Disentanglement Learning for Variational Autoencoders Applied to Audio-Visual Speech Enhancement, https://arxiv.org/abs/2105.08970",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written but the novelty is limited.",
            "summary_of_the_review": "The technical contribution is somewhat limited since the proposed adversarial variational auto-encoders has been developed by the prior work. In addition, this work needs to compare to some latest baselines. The experimental results need to present the reconstruction error.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_pitB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4123/Reviewer_pitB"
        ]
    }
]