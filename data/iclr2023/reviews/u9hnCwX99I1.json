[
    {
        "id": "DwsDN8VjAnr",
        "original": null,
        "number": 1,
        "cdate": 1666591168225,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591168225,
        "tmdate": 1666592268075,
        "tddate": null,
        "forum": "u9hnCwX99I1",
        "replyto": "u9hnCwX99I1",
        "invitation": "ICLR.cc/2023/Conference/Paper2702/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a method for training in MARL setting under hybrid communication setting (decentralized vs fully centralized) by using a autoregressive model for predicting next joint observations. Experiment are provided on some toy domains with 2 decentralized value based baselines.",
            "strength_and_weaknesses": "Strength\n1. The paper is well written in terms of describing the setting used.\n2. The hybrid execution setting is moderately relevant for real applications.\n\nWeakness \n1. The related works is incomplete. The paper lacks discussion about the implications of using the different types of MARL algorithms: decentralized/centralized and policy/value based and their interaction with the hybrid communication setting, which is important (refer to e.g. [1], [2]). Policy based MARL methods like Tesseract [2] and MAPPO [3] can handle this scenario without performance loss in principle. Discussion about the mentioned works should be included for better context and reader understanding.\n\n2. The experimental results are reported only on toy domains, there are more realistic complex domains like Starcraft which can be used. The baselines used are also inadequate, some policy based baselines should be included (for reasons covered in [1, 2]). Even for value based setting, there are stronger baselines available like [4]. \n\n3. The difference with performance of the simple message dropout baseline is not significant, which makes it unclear how effective the proposed approach is.\n\n4. Is the communication matrix C also visible to the agents?\n\n5. In general, the considered setting is significantly easier than decentralized control, so I am unconvinced with the usefulness of the approach.\n\nReferences:\n1. Maven: Multi-agent variational exploration, Mahajan et al, 2019\n2. Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning, Mahajan et al 2021\n3. The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games, Yu et al 2021\n4. Rode: Learning roles to decompose multi-agent tasks, Wang et al, 2021",
            "clarity,_quality,_novelty_and_reproducibility": "1. The clarity of presentation is good. \n2. Novelty wise, setting is not new as it is a very specific restriction of the Dec-POMDP scenario. The methodology proposed of autoregressive prediction is also quite commonly used in MARL (see for e.g. [4] where it is used to learn action embeddings.)\n3. See above for comments about quality. \n4. The code is provided, although I haven't run it.",
            "summary_of_the_review": "Interesting idea, but the results are not strong. The paper also lacks important related works crucial for better understanding the problem. The authors should focus on the points in the weakness section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_CnPR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_CnPR"
        ]
    },
    {
        "id": "M06EhmItpsQ",
        "original": null,
        "number": 2,
        "cdate": 1666638478902,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638478902,
        "tmdate": 1666638478902,
        "tddate": null,
        "forum": "u9hnCwX99I1",
        "replyto": "u9hnCwX99I1",
        "invitation": "ICLR.cc/2023/Conference/Paper2702/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In the context of MARL, this work introduces the paradigm of centralised training with hybrid execution, a setting in which the information availability of the other agent's observation is not guaranteed during execution. A novel training approach is also introduced, MARO, in order to deal with this setting, comprising of a predictive model and a training scheme that includes a random drop of agent observations, to simulate the conditions that might be encountered during execution. ",
            "strength_and_weaknesses": "Strengths:\n- The work formalises the setting of faulty communication of the agent's observations during execution as a hybrid-POMDP (H-POMDP)\n- The work introduces a novel training approach, MARO, that can be combined with many existing MARL methods to improve performance in this faulty communication setting\n\n\nWeaknesses:\n- Lack of motivation for selected benchmarks. In the abstract it is mentioned \"tailored to emphasize the negative impact of partial observability\", but I did not find an explanation for supporting this statement thereafter.\n- Weak comparison against the selected method, can be improved by clarifying more details on the MD approach \n\nQ1. Can you motivate the selection of the benchmark, in contrast for example with the choice of the Kim et al. (2019b) work. Why are they \"tailored to emphasize the negative impact of partial observability\"? \n\nQ2. As far as I can tell, there are never more than three agents in the environment. Have you also tried larger environments? Can you comment on the scalability of the method? Especially in combination with independent learning approaches, I do not see why a larger number of agents might pose an issue. But what about the predictive model?\n\nQ3. Have you tried combining MARO with PG/actor-critic based approaches? It would have been interesting and make for a well-rounded experimental evaluation to also see for example how IPPO behaves.\n\nQ4. Can you clarify if for the adapted MD approach you also used the original training procedures (eg., block-wise/element-wise dropout)? Have you tried also other values for p? \n\nQ5. In 3.2 you mention that the masks enables to measure uncertainty regarding the input. Is this information used anywhere?\n\nQ6. Have you also tested a setting where during execution the p is dynamic?\n\n\nMinor typo:\n- Section 6 'that explicity considers'",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and well-presented. The paper contributes both a novel framework (H-POMDP), as well as a new training scheme for MARL (MARO) and the code is open-sourced.\n",
            "summary_of_the_review": "All in all this, this work addresses a novel setting, that of faulty observations exchange between agents during execution, and proposes a novel framework to capture this setting and a novel training approach for solving it. I would consider it currently slightly below the acceptance threshold, but if authors can clarify my questions, I will raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_eHqC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_eHqC"
        ]
    },
    {
        "id": "cmymrwNYoN",
        "original": null,
        "number": 3,
        "cdate": 1666742598274,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666742598274,
        "tmdate": 1666742598274,
        "tddate": null,
        "forum": "u9hnCwX99I1",
        "replyto": "u9hnCwX99I1",
        "invitation": "ICLR.cc/2023/Conference/Paper2702/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes multi-agent hybrid-POMDPS which uses a centralized training scheme as well as models a communication process between the agents. Experiments are conducted on standard benchmarks to show the superiority of the proposed method. ",
            "strength_and_weaknesses": "strengths:\n-the paper proposes an approach called hybrid-POMDPs\n-it adds the notion of agent communications to dec-POMDPs which is fully decentralized \n-agents can have any level of communication (none to complete)\n\n\nweakness:\n-the contribution may be limited because when the communication matrix is known it can be solved as a Dec-POMDP\n-predicting the unknown observations using an LSTM does not consider all possible contextual information to identify dynamic agent behavior \n-the centralized training scheme needs to be explained in more detail\n-how accurately masking during training reflects agent communication during evaluation needs to be discussed\n-the MD approach used for comparison performs equally better in many scenarios\n",
            "clarity,_quality,_novelty_and_reproducibility": "-the paper is well written\n-the novelty may be limited as it builds on Dec-POMDPs \n-more complex agent behavior, especially dynamic agent interactions needs to be modeled\n-the notion on how uncertainty is captured in the centralized training scheme needs to be explained\n",
            "summary_of_the_review": "The paper introduces hybrid-POMDPs by adding agent communication as an additional parameter to dec-POMDPs. However, the novelty and contribution is limited as the autoregressive prediction model and the masked training procedure does not consider exhaustive multi-agent scenarios. The experiments also show that another baseline performs similar using IQL. The main advantage of the proposed approach over existing works needs to be made clear via experimentation. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_ymGd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_ymGd"
        ]
    },
    {
        "id": "kl-Vw29CCZ",
        "original": null,
        "number": 4,
        "cdate": 1667431347526,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667431347526,
        "tmdate": 1667431347526,
        "tddate": null,
        "forum": "u9hnCwX99I1",
        "replyto": "u9hnCwX99I1",
        "invitation": "ICLR.cc/2023/Conference/Paper2702/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new paradigm for multi-agent reinforcement learning (MARL) whereby the agents are trained in a centralised way but tested in a hybrid fashion. During the hybrid execution, information regarding other agents is hidden during different timesteps, ranging from a fully decentralised mode to a centralized regime. The authors name this problem hybrid-POMDPs and propose a method called MARO to make to most out of the given at times information during execution. The authors provide empirical results that show MARO outperforming other baselines, as well as detailed ablation studies.",
            "strength_and_weaknesses": "## Strengths\n\n- The paper takes on an interesting problem - hybrid execution in MARL. Although the CTDE regime has gained major attention in recent years, no work has previously studied this paradigm which can potentially have real-world use cases. To me the problem itself is novel.\n- The paper includes extensive empirical evaluations and ablation studies that evaluate all aspects of the proposed approach and contrast them with other methods.\n- The paper is clear and easy to follow. The contributions of the work can be easily identified.\n\n## Weaknesses\n\n- The major weakness of this work, in my view, is the environments used for empirical evaluation. The authors only have 2D environments with 2-3 agents. It is very unclear if the proposed method would scale to settings with more agents (e.g. 5, 10, 20) or to more complex domains. I think the SMAC benchmark could be an interesting domain for trying out MARO whilst having a large number of agents alongside complex dynamics\n- While the work is considerably novel (both the problem and the method), the proposed approach is fairly straightforward. It seems obvious that this approach would outperform a fully decentralized case or MD. So what I would want to see here, which is unfortunately missing, is a thorough empirical evaluation of the method for different communication matrices. For example, empirical analysis of the following settings would strengthen the paper - what happens if \n   1. $p{i,j}\\neq p_{j,i}$\n   2. different $p$ value is used for different co-player pairs\n   3. $p$s change throughout the episode\n- (Minor) It would be helpful if the authors include screenshots of the environments in the main text.\n\nNote: My score is not final and can change (in either direction) based on the authors' responses or comments of other reviewers.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: High. The paper is clear and easy to follow. The prior and related work is properly cited.\n\nQuality: Medium. The paper includes extensive experiments and a detailed analysis of prior work as well as new the new method. However, additional testbeds and analysis would strengthen the work.\n\nNovelty: High. The authors proposed a new paradigm for MARL - hybrid PODPS that can have real-world applications in certain settings.\n\nReproducibility: High. The code is included alongside the submission.",
            "summary_of_the_review": "This is an interesting work that proposes a new MARL problem that has not been studied before. The authors compare their method with existing approaches and perform an ablation study of its components. However, using more complex environments with more agents would strengthen the work. In addition, I encourage the agents to perform more experiments studying different hybrid execution paradigms, as described above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_PDRN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2702/Reviewer_PDRN"
        ]
    }
]