[
    {
        "id": "QXq0mgxPzPj",
        "original": null,
        "number": 1,
        "cdate": 1666537474240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537474240,
        "tmdate": 1666537474240,
        "tddate": null,
        "forum": "7Cb7Faxa1OB",
        "replyto": "7Cb7Faxa1OB",
        "invitation": "ICLR.cc/2023/Conference/Paper4528/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the problem of representation learning for bag-of-words count data, trying to understand the usefulness of recent self-supervised learning, including reconstruction objectives (Eq 1) and contrastive objectives (Eq 2). The key question is: why might these approaches be better than previous ones? The paper's goal is to develop theorems and experiments that try to compare/relate the representations produced by these objectives to the per-document posterior representations of probabilistic topic models (like Latent Dirichlet Allocation).\n\nThe main claims see to be that SSL representations are\n\n- as good as the true topic model when the data is generated by a true topic model (backed by theorems in Sec 3/4 and experiments)\n- better than a topic model that is *misspecified* for the data (backed by experiments in Sec 5)\n\nTaken together, the paper suggests that SSL is *robust* to model misspecification, and this may help explain why it is a performant choice for real bag-of-words data.\n\nI'll note the first claim seems somewhat surprising, given that a key part of a topic model is its prior over the document's distribution over topics $$w$$, and the SSL does not know about this prior at all, yet recovers moments of the posterior well.\n\nSec. 5 performs experiments on synthetic data where the true topic model is known (several possible models are considered: pure topic model, LDA, Correlated Topic Model). Here, results in Table 1 assess the distance between the SSL recovered posterior and the \"true\" posterior (fit with NUTS).\n\nSec. 6 provides one brief experiment on real data (AG news, where each doc is one of four categories). Here, representations are assessed in terms of their ability to predict the category of documents in the test set. The authors show how reconstruction-based SSL outperforms other baselines as training set size varies from 100-400 documents.\n\nWhile most theoretical results (Sec. 3) and experiments (Sec. 5-6) focus on reconstruction-based SSL, contrastive SSL is the focus of a theorem in Sec. 4.\n",
            "strength_and_weaknesses": "\n## Strengths\n\n* Paper addresses a timely question (understanding the representational power of self-supervised learning)\n* Theoretical results cover both reconstruction (Sec 3) and contrastive (Sec 4) paradigms of SSL\n* The implications of Theorem 3.1 are reasonably explained to the reader\n* Comparisons to many (4) distinct types of topic models in Sec. 5 help back up claims\n* Real data demonstration in Sec. 5 looks promising\n\n## Weaknesses\n\nHere I list the primary weaknesses as I see them (each is elaborated below under its respective heading of Quality/Clarity/Reproducibility)\n\n* W1: Missing assessment of sensitivity to length of document / assymmetric priors\n* W2: Better to compare predicted distributions over words than topics?\n* W3: Details of NUTS-based posterior sampling missing\n* W4: Clarify how A is handled in experiments\n* W5: Releasing code would significantly help reproducibility\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\n## Novelty\n\nThe paper cites adequate recent work in this space. \nTosh et al. (2021a) is the most closely related study, which shows \"contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models\".\n\nThis previous work focuses on contrastive SSL, while the present paper's focus is primarily on reconstruction SSL. The present paper does look at the contrastive setting (see Sec. 4), and the theorem there nicely removes the anchor words assumption needed by Tosh et al.\n\n\n\n## Quality\n\nOverall, the study and especially the synthetic experiments seem well designed.\n\nHowever, there a couple major issues I'd like to hear more about\n\n### W1: Missing assessment of sensitivity to length of document / assymmetric priors\n\nThe successful recovery of the posterior despite complete lack of knowledge of the prior is somewhat surprising. I wonder if two things could explain this:\n\n* the likelihood is dominating the per-document posterior in most of the experiments considered, and the specific choice of prior is thus less relevant\n* the chosen priors used are fairly default in their assumptions (e.g. LDA uses a symmetric Dir(1/K) prior, so all topics are equally likely to appear in the document) \n\nI'm curious if the results in Sec 5 would hold even if we had an asymmetric prior (e.g. LDA where some topics more common than others) and if test time documents were significantly shorter (e.g. maybe 2-10 words, much smaller than expts in Sec 5 which seem to use Poisson(30) words). \n\nClearly, in the limit where there are *no* observed words in a test document, the posterior must equl the prior, and the SSL doesn't have access to the prior (though I guess it can try to learn it from abundant training data). I'm just hoping to understand the limits of the proposed method for recovering the posteriors of classic probabilistic models. \n\n\n### W2: Better to compare predicted distributions over words than topics?\n\nThe comparisons in Table 1 all assess estimated per-document distributions over topics, denoted w\n\nI'm wondering if there's a chance that if a (misspecified model) gets this distribution wrong, it could still have a good prediction for the missing word. For example, in a given fixed topic-word matrix A, two different topics can put mass on the same word v. As long as the posterior predictive over words (=Aw) is close to the truth, the model would predict well, even if the model uses a different topic than the \"true\" one.\n\nDo the authors have thoughts about this? \nProbably the topics are distinct enough that there is one clearly \"best\" w for each document, but I'd just like to check in on this.\n\n\n## Clarity / Reproducibility\n\nOverall mostly easy to understand, I appreciated that in a paper with theory-heavy contributions the practical implications of the theorems (e.g. Theorem 3.1) were clarified to the reader in the main text.\n\nMajor issues are listed here\n\n### W3: Details of NUTS-based posterior sampling missing\n\nEven though widely used in probabilistic programming packages, I've often found NUTS with default settings may not sample well from some distributions without further tuning. Because NUTS isn't commonly used to do posterior inference for models like LDA (even though of course it seems perfectly suitable), I'm hoping to hear a little more about what diagnostics you've performance to be satisfied your chains are converging to the intended posterior distribution.\n\nFor example, for LDA have you compared your NUTS results to classic Gibbs samplers for LDA? Or to the \"true\" w used to generate a document?\n\nAlso, when you know the \"true\" generative model used to simulate the data (as in Table 1), do you really need to use NUTS at all?\n\n### W4: Clarify how topic-word parameters A are handled in experiments\n\nIn Table 1 and 2, can you clarify whether A is held fixed to the true topic-word parameters used to generate all data? And that each method is only solving the posterior estimation of w given observed x and fixed A? That detail is missing in the paper.\n\nFurthermore, the text says \"Often A will be drawn from ... Dir(\\alpha /K)....\" \n\nAre there cases where you generate A some other way? If so, how?\n\n### W5: Releasing code would significantly help reproducibility\n\nHopefully this is an easy one to address.\nI think the community would benefit from being able to compare to the toy and real datasets studied here under similar settings.\n\n\nMinor issues:\n\n* Would be useful to be clear (in supplement) how exactly you calculate the 95% confidence intervals in various tables.\n",
            "summary_of_the_review": "Overall, I think this study offers some nice new insights about why self-supervised learning might be effective on data from a wide range of possible models. If my concerns are addressed, I think this could be a valuable paper to accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_KUB2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_KUB2"
        ]
    },
    {
        "id": "kL75U4I-MU",
        "original": null,
        "number": 2,
        "cdate": 1666564638760,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666564638760,
        "tmdate": 1666564638760,
        "tddate": null,
        "forum": "7Cb7Faxa1OB",
        "replyto": "7Cb7Faxa1OB",
        "invitation": "ICLR.cc/2023/Conference/Paper4528/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies self-supervised learning (SSL) for general topic models. The main approaches of SSL include reconstruction-based objective and contrastive objective. The paper investigates that feature representations given by SSL provide basis functions of the higher order posterior mean. Also, the robustness analysis provides the error bound of near-optimal solutions in the reconstruction-based SSL. In numerical experiments, the reconstruction-based SSL is examined and compared to the inference with some topic models. The numerical results indicate that the SSL approach is superior to the statistical inference using misspecified models. ",
            "strength_and_weaknesses": "Strength\n- This paper tackles an important problem. Numerous theoretical analysis on SSL has been published in recent years. Most of them focus on the generic effectiveness of the feature representation of the SSL for downstream tasks. This paper restricts the problem to the topic model that includes the main applications of SSL. The robustness analysis in Theorem 3.3 is practically important. \n\nWeaknesses\n- This paper includes a generalized result of [Tosh et al.'21]. However, a detailed comparison with [Tosh, et al.'21] is not presented. More concretely, which condition is relaxed compared to [Tosh et al.'21]? How much is the practical usefulness of such a relaxation?\n- The required dimension of the feature representation is relatively high. Is it possible to show how to reduce the dimension of the functions f and g to obtain similar theoretical results? \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall this paper is clearly written. However, the novelty is not very clearly mentioned. Showing the details of existing work [Tosh et al.] and clarifying the extension would be necessary. ",
            "summary_of_the_review": "This paper tackles an important problem. However, the novelty compared to existing works is not clearly discussed. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_6Fra"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_6Fra"
        ]
    },
    {
        "id": "Hzvxer8JQYU",
        "original": null,
        "number": 3,
        "cdate": 1666606253909,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666606253909,
        "tmdate": 1666606253909,
        "tddate": null,
        "forum": "7Cb7Faxa1OB",
        "replyto": "7Cb7Faxa1OB",
        "invitation": "ICLR.cc/2023/Conference/Paper4528/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper demonstrates the point that Self-supervised learning is immune to the choice of the probabilistic model, therefore shows robustness to model misspecification. In contrast, traditional approach of probabilistic modeling hinges on the specific predefined model. Therefore, the advantage of self-supervised learning is that SSL may outperforms traditional model when inferencing with misspecified model. The evaluation parts measures topic posterior recovery loss as the Total Variation (TV) distance between the recovered topic posterior and the ground truth topic posterior mean, supporting the advantage of the SSL methods. ",
            "strength_and_weaknesses": "Strength:\n\nThe paper demonstrates the ability of self-supervised learning to adapt to different models. Since the prior distribution is not present in the SSL models,  SSL methods therefore avoid the risk mis-specifying the model. This helps the model to better inference the posterior of the topics. In the meanwhile, the paper gives the explicit theoretical guarantees for self-supervised learning with the topic modeling task,  and showed that SSL can provide useful information about the topic posterior without bounded error, even if SSL does not have prior information about the topics. This observation is relatively new and fresh to me. \n\nWeakness:\n\nThe paper is a bit hard to follow in the sense that the proposed theories are very loosely connected to the actual classification error on the downstream task in the form of the polynomials of the w variables. I would appreciate it if the authors might comment on the significance of assuming error bound on the polynomials form of the posterior on w variables.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper lacks a bit of clarity in eventually linking the polynomial form of w with the linear classification error. This helps to verify the significance of the proposed methods. \n\nThe paper is novel in the sense that this is the first paper I came across in attributing the model mis-specification with the actual performance of SSL methods. ",
            "summary_of_the_review": "The paper gives a series of theorems justifying the bounded error of topic classification task, when using the features out of the SSL model.  The paper is well written, and evaluation supports the claims. I have some concerns in linking the theorems to the actual classification error of the topics, I expect to hear from the authors in this regard.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_DvbM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4528/Reviewer_DvbM"
        ]
    }
]