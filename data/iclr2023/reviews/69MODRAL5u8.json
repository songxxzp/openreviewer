[
    {
        "id": "6g96r5LRTFd",
        "original": null,
        "number": 1,
        "cdate": 1666557575027,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557575027,
        "tmdate": 1666558217346,
        "tddate": null,
        "forum": "69MODRAL5u8",
        "replyto": "69MODRAL5u8",
        "invitation": "ICLR.cc/2023/Conference/Paper2934/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to provide a theory to analyze the semantic equivalence of programming languages. This is the classical equivalence problem and in general undecidable. This paper additionally imposes some assumptions and studies when the equivalence can be efficiently decided, defined as tractably embedded in this paper. The authors also conduct an empirical study, aiming to show that BERT-Tiny can learn languages with tractably embedded semantics but not intractably embedded semantics.",
            "strength_and_weaknesses": "**Strength**\n\nAnalyzing the hardness of equivalence decidability can be an interesting perspective to understand the learning capacity of neural network models, especially for programming language tasks.\n\n**Weakness**\n1. The theory is ad hoc:\nThe (semantic) equivalence problem is a classical problem and has been studied for decades for different formal systems, for example, automata, regular expressions, and pushdown systems. They are often at least PSPACE-hard. These are naturally encountered formal systems. In this paper, the authors impose assumptions like the (denotational) semantics is from a finite set, the input space is finite. Those assumptions in general do not hold.\n\n2. The techniques are elementary:\nThe techniques used to develop the theory are elementary. With the finiteness and some efficient procedure assumptions, the proofs are usually direct manipulations of definitions and assumptions. It does not seem that there are useful theoretical or mathematical techniques.\n\n3. The evaluation is rough:\nThe evaluations are on two toy languages defined in this paper, and the input space size is at most 11. It is conceivable that modular addition is easier than bitvector arithmetic to learn because the latter is a direct extension of the former. It is inconclusive to understand model's capacity to learn the semantics just based on this toy evaluation.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nIn the empirical study, the authors present two toy languages. The semantics of bitvector arithmetic is not defined for logical symbols. For example, what is 2 & 3 mod 7? It is fine to omit the semantic specification for modular addition because it has natural mathematical semantics, but bitvector arithmetic needs such specification. \n\n**Quality and Novelty**\n\n In essence, this paper studies the equivalence problem, which is a classical formal language problem. It appears that the authors are unaware of those results, and propose an ad-hoc theory. Therefore, the quality and novelty are insignificant at this time.\n\nI think that understanding the hardness of semantic decidability can be an interesting angle in understanding semantic tasks arising from deep learning models. However, more works need to be done. For example, for existing programming semantic tasks, can the authors classify their hardness using the theory developed in this paper?",
            "summary_of_the_review": "This paper presents a theory to study the semantic equivalence of programming languages. However, the theory is ad hoc and the evaluation is inconclusive. This paper is not ready for acceptance yet.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_Pnio"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_Pnio"
        ]
    },
    {
        "id": "0PGO1XDduu0",
        "original": null,
        "number": 2,
        "cdate": 1666737792781,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666737792781,
        "tmdate": 1666737792781,
        "tddate": null,
        "forum": "69MODRAL5u8",
        "replyto": "69MODRAL5u8",
        "invitation": "ICLR.cc/2023/Conference/Paper2934/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposed a new notion of equivalence-preserving program embedding, proved a simple arithmetic language has an equivalence-preserving embedding, and experimentally demonstrated that having the embedding is crucial to learn an embedding of programs.\n",
            "strength_and_weaknesses": "Strengths:\n\n+ The notion of equivalence-preserving program embedding is new, theoretically formulated, and proven to be satisfied by a simple arithmetic language and unsatisfied by a bit-vector language.\n\n+ The usefulness of equivalence-preserving program embedding is experimentally demonstrated.\n\n+ The documentation is well written and easy to follow.\n\nWeaknesses:\n\n- Little languages have equivalence-preserving program embedding functions. Theoretically, a tractably embeddable language (i.e., one with an equivalence-preserving embedding function) has a means to determine the equivalence of two programs. It means that no Turing-complete language is tractably embeddable. Furthermore, although recognizing the limitation of an approach is crucial in general, even the simple bit-vector language does not have such a function. Therefore, I am concerned about the practicality of the proposed approach in its current status. Considering the strictness of equivalence-preserving program embedding, I am not surprised that a machine learning model can learn an embedding for a tractably embeddable language even when the same model cannot learn an embedding for a language that is not tractably embeddable.\n\n- As a minor point, the theory of the paper seems to assume the input space ($I$) is finite, but, in general, one can consider programs with an infinite input space (like list-processing programs).\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and easy to follow. It is also novel and original in that the paper proposed a new theoretical notion to indicate that a programming language is embeddable.\n",
            "summary_of_the_review": "The paper addresses a critical aim to apply machine learning techniques to programming language tasks. The proposed notion of equivalence-preserving program embedding is novel. However, as described above as a weakness, its practicality is a big concern because of its theoretical strictness. Research given in Section 5.1 would enhance the work much more.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_c7mJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_c7mJ"
        ]
    },
    {
        "id": "154Y8MzPwS0",
        "original": null,
        "number": 3,
        "cdate": 1666810928948,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666810928948,
        "tmdate": 1666810928948,
        "tddate": null,
        "forum": "69MODRAL5u8",
        "replyto": "69MODRAL5u8",
        "invitation": "ICLR.cc/2023/Conference/Paper2934/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a theoretical background on how to incorporate code semantics into code embedding.  They argue that when two programs behave identically on a given input, they are semantically equivalent, and their representation in the embedded space should capture such properties. They demonstrate their theoretical foundation across two tasks.  ",
            "strength_and_weaknesses": "(+) Code semantics is an important program property, and proposing a theoretical framework to incorporate semantics to embedding is important. \n\n(+) The theoretical foundation is good.\n\n(-) The demonstration is shown on small tiny problems. \n\n(-) I am not sure any general-purpose language can be tractably embedded. It is not clear how such a definition can be extended to such languages.\n\n(-) If the intention is to use tractable embedding to domain-specific language, I would encourage the authors to show some convincing scenarios.",
            "clarity,_quality,_novelty_and_reproducibility": "The theoretical foundation presentation is clear. However, the potential of the idea is not thoroughly examined. The results should be reproducible.",
            "summary_of_the_review": "The paper presents some interesting and important ideas. However, there is a large gap between the idea and practicality and generalizability.  It is not clear to me how the proposed idea of tractable embedding can be applied to real-world problems. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_3JjL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_3JjL"
        ]
    },
    {
        "id": "pnPwn-IEoH",
        "original": null,
        "number": 4,
        "cdate": 1667426466468,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667426466468,
        "tmdate": 1667426466468,
        "tddate": null,
        "forum": "69MODRAL5u8",
        "replyto": "69MODRAL5u8",
        "invitation": "ICLR.cc/2023/Conference/Paper2934/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper defines equivalence-preserving program embedding, a constraint that requires the learned program embeddings to be equivalent if the corresponding programs have the same input-output behavior. It provides the conditions specifying when a programming language can be represented into embeddings that preserve the equivalence. It then provides empirical evidence showing that programming languages that satisfy the conditions can be more accurately embedded.",
            "strength_and_weaknesses": "Strength:\n+ Describes an important property of program embeddings: they should remain invariant to semantic-preserving transformations.\n+ First theoretical definition of equivalence-preserving program embedding problem. The paper provides formal conditions under which the programming languages can be tractably embedded.\n\nWeaknesses: \n\n- The empirical study is not convincing by only evaluating BERT-Tiny. Numerous neural architectures have been used to model programs, e.g., large language models, graph neural networks, etc. Can the proposed theory help explain some of the successes of one architecture over others? Can the theory guide how to develop new models to learn program representations? \n\n- The practical implication of this paper is unclear. While the authors describe two applications (Section 2), these applications often deal with common programming languages that are intractable, e.g., code clones across binary code for vulnerability detection. Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others? The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared. \n\n- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs. \n\n- There is no discussion on why larger input space sizes need a smaller number of epochs to converge on the tractable language, which contradicts the observation that losses increase monotonically with input space sizes on the intractable language.\n- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth. \n\n- The paper uses code clone detection and semantic labeling to motivate their theory, but the theory focuses on characterizing language tractability. Can the theory extend to cross-language clone detection, e.g., one language is tractable, but the other language is not?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper describes the core idea clearly. \n\nQuality: the quality of the paper is good.\n\nNovelty: the theory of equivalence-preserving embedding is novel.\n\nReproducibility: the evaluation is easy to reproduce.\n",
            "summary_of_the_review": "My main concern is the practical implication of the proposed theory. Ideally, equivalence-preserving program embedding makes sense if it remains invariant against program transformations. For example, code clone detection requires the model to understand that various classes of transformations on program syntax do not change their input-output behavior. Therefore, it makes more sense to characterize what transformations can be tractably embedded. However, the authors characterize it from the language perspective. Most of the programming languages that existing applications consider are intractable, i.e., assembly code or even undecidable, as pointed out by the authors.\n\nTherefore, it is not unclear how the theory of equivalence-preserving embeddings could help solve existing semantic code modeling tasks. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_M5Qy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2934/Reviewer_M5Qy"
        ]
    }
]