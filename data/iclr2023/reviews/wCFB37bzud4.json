[
    {
        "id": "VNStyQygkso",
        "original": null,
        "number": 1,
        "cdate": 1666492918447,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666492918447,
        "tmdate": 1666492918447,
        "tddate": null,
        "forum": "wCFB37bzud4",
        "replyto": "wCFB37bzud4",
        "invitation": "ICLR.cc/2023/Conference/Paper4464/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors explore the use of bidirectional models, particularly T5-style models, for in-context learning. The pre-training objectives of bidirectional models do not make it directly amenable to prompt-based learning, but representations from bidirectional models might be better. This paper introduces an iterative procedure (Sequential Autoregressive Prompting) to adapt mT5 for incontext learning at inference time. The results show that with this simple procedure, bidirectional models can also perform prompt-based learning. The results are also competitive with larger decoder-only language models. The major downside is the need to run multiple iterations of generations to complete the generation, thus making the process inefficient. The paper also discusses the strategy applied to the tasks of summarization and question answering. ",
            "strength_and_weaknesses": "Strengths: \n\n- The paper shows that bidirectional models can perform prompt-based learning with the right prompting strategy without the need for any model adaptation. This is an interesting fix for models trained for denoising objectives.\n- The paper also proposes an interesting idea for English-centric bootstrapping for unsupervised, though this is somewhat orthogonal to the central contribution of the paper. \n\nWeakness\n\n- The method is applicable to mT5 style models, but the long-term solution is probably to adapt mT5 models with causal LM or prefix LM objectives. This will make the inference more efficient as well. ",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is well-written and understandable.\n- The procedure to adapt se2seq pretrained LMs for prompt-based learning is novel. \n- The methodology for boostrapping prompts for unsupervised MT comes from existing working, but an extension in the form of English-centric bootstrapping method has been proposed. This is shown to be useful in some contexts. \n\nQuestions\n\n- Table 4/5: Why does T5+LM even lag behind vanilla mT5+SAP? Why does it also perform worse compared to vanilla mT5 on summarization? It is trained on a prefixLM kind of objective, so it does have bidirectional context as well as a causal decoder. An analysis of the same would be useful.",
            "summary_of_the_review": "The paper proposes a quick inference-time fix for adapting seq2seq models trained on denoising objectives for prompt-based learning. This just that seq2seq models can perform incontext learning, but the particular methodology proposed in the paper has a lot of inference-time overhead and alternative proposals of LM adaptation of seq2seq models in concurrent work will eventually be adopted.  Hence, the impact of this work might be limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_iGmv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_iGmv"
        ]
    },
    {
        "id": "QPyHj5xWBc",
        "original": null,
        "number": 2,
        "cdate": 1666827398020,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666827398020,
        "tmdate": 1666827398020,
        "tddate": null,
        "forum": "wCFB37bzud4",
        "replyto": "wCFB37bzud4",
        "invitation": "ICLR.cc/2023/Conference/Paper4464/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the effectiveness of bidirectional language models (specifically, mT5 model) on low-resource multilingual generative tasks with the proposed Sequential Autoregressive Prompting(SAP) method. The paper presents a representative case study on the low-resource MT task utilizing the proposed SAP and a self-amplification technique. Further, the generalized ability of the proposed SAP method on bidirectional LMs is also validated on few-shot / zero-shot QA and Summarization task.",
            "strength_and_weaknesses": "**Strength:**\n1. The proposed inference-only SAP approach is an interesting way to use the bidirectional LMs\u2019 low-resource transfer ability on generative tasks such as MT, QA and summarization;\n2. Combines multiple techniques (e.g. filtering , prompt ensembling, and English-centric bootstrapping) and applies them to perform better unsupervised low-resource MT results;\n3. Sufficient experiments and analysis.\n\n**Weakness:**\n1. The technical novelty of the paper is somewhat limited, since the SAP prompt technique is just feeding the generated token back the prompt again so as to get the new representation of the encoder.\n2. The paper only verifies the effectiveness of the proposed SAP method on the mT5 models, however, claims that the performance improvements come from the Bidirectional LMs, which is not reliable. This part of performance improvement may only come from SAP's effect on mT5, or SAP's effect on the encoder-decoder architecture model. Not only that, the underperforming attempt of running SAP on the T5 1.1 proves the unreliability of this conclusion.\n3. Lack of detail analysis on the computational efficiency.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality is relatively good.",
            "summary_of_the_review": "This paper proposes an inference-only SAP prompting technique for mT5 model to achieve remarkable results on low-resource multilingual generative tasks, including MT, QA and Summarization. The proposed method outperforms unidirectional models (GPT-3, XGLM) within fewer parameters and in-context training examples. Even though the paper presents sufficient experiments and analysis, it does not give strong evidence to support the point that the low-resource performance boost comes from bidirectional pre-training objectives. What\u2019s more, the technical novelty of the paper is kind of limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_CyM9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_CyM9"
        ]
    },
    {
        "id": "Ai_-ZqkZV0",
        "original": null,
        "number": 3,
        "cdate": 1666927909985,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666927909985,
        "tmdate": 1666927909985,
        "tddate": null,
        "forum": "wCFB37bzud4",
        "replyto": "wCFB37bzud4",
        "invitation": "ICLR.cc/2023/Conference/Paper4464/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on prompt-based learning applied to bidirectional language models. This class of models doesn't lend itself well to standard prompt-based approaches due to their objectives only training them to fill in short spans of text at most. The approach proposed in this paper is to iteratively prompt such models, feeding back the original prompts concatenated with the first words of previous generations, to enable them to generate much longer sequences in an \"autoregressive\" manner.\n\nThe authors evaluate the method on a translation task, obtaining better performance with mT5 compared to the much larger causal language models GPT-3 and XGLM, and are also not too far off supervised techniques even on low(ish)-resource languages. They further evaluate on QA and summarisation tasks, showing again strong performance against XGLM.",
            "strength_and_weaknesses": "## Strengths\n\n* A clear, well structured paper with a well thought out set of experiments. Most of the questions I could come up with while reading it I found answered in one of the appendices, including an extensive set of ablation studies.\n* Translation/generation performance is impressive compared to traditional prompt-based methods on GPT-like models, in spite of the much smaller model size.\n* The evaluation is generally strong, with 14 languages being chosen for translation, and the model being also compared to supervised approaches.\n\n## Weaknesses\n\n* The main question I have is: why? I don't think this is spelled out clearly enough in the main paper. Do the authors expect SAP-like approaches to eventually overtake supervised approaches? If so, the questions around computational complexity are central and should be discussed in much more detail in the main section of the paper, including perhaps some FLOPS statistics for the proposed approach and the current SOTA.\n* The supervised translation baseline include in Table 2 should perhaps be replaced with a more recent and stronger multilingual model.\n* I would definitely challenge the classification of languages such as `ko`, `ar`, `sw` etc. as being low-resource. These are all languages for which at least 1M training sentences can be found (see e.g. Table 1 in <https://arxiv.org/abs/2207.04672>)\n\nMinor: I believe the meaning of \"Supervised\" in Table 2 is only explained in the Appendix. I would recommend explaining it in the table caption.",
            "clarity,_quality,_novelty_and_reproducibility": "As stated above, I believe this paper to be of high quality, both from a scientific point of view as well as for its clarity. The proposed approach is relatively simple but, I believe, original. The authors give enough detail to reproduce the experiments.",
            "summary_of_the_review": "A strong paper proposing a conceptually simple yet effective prompt-based learning approach for models like mT5. Some questions around computational efficiency I believe should be given a bit more prominence.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_ZTjg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_ZTjg"
        ]
    },
    {
        "id": "QumyN7IQMhn",
        "original": null,
        "number": 4,
        "cdate": 1667247595952,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667247595952,
        "tmdate": 1668794954542,
        "tddate": null,
        "forum": "wCFB37bzud4",
        "replyto": "wCFB37bzud4",
        "invitation": "ICLR.cc/2023/Conference/Paper4464/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper motivates the interest for making bidirectional language models better few-shot/zero-shot reasoners from natural language prompts/instructions. The paper argues that bidirectional models can potentially have richer representations but the unidirectional training in the causal decoder-only models typically happens to be more amenable to few-shot/zero-shot instruction following. The paper resolves the dilemma by introducing a new prompting technique, SAP, to get bidirectional models like mT5 to do few-shot/zero-shot tasks on par with (or better than) other large causal decoder-only models like GPT3.  \n\n\nIn each time step, SAP generates a token using mT5 from a given prompt but then adds the first generated token to the prompt for the next step (in the next time step the whole encoder-decoder is run again with the new prompt). \n\n\nThe paper also adopts several engineering techniques on top of that like bootstrapping with synthetic few-shot samples (sampled and then filtered with unsupervised scorers) and self-amplication (using those synthetic samples as few shots); also prompt ensembling. \n\n\nPaper shows better or on par results of mT5 with unidirectional models on zero-shot and few-shot translation/QA/summarization. ",
            "strength_and_weaknesses": "Strength:\n\n1. The core technique is quite simple and seems effective. \n\n2. The insight that bidirectional models can be utilized effectively for few-shot prompting without weight updates similar to GPT-like models can motivate more research into this direction and towards building of better larger bidirectional models. \n\nWeakness:\n\n1. I am unclear of some of the experimental settings and how much we can conclude from them. Particularly, when is bootstrapping+self-amplification+ensembling are used? Is it used only during translation? \n\nIt also seems odd to use those techniques only for zero-shot and not adapt them (or explore possible adaptions) for 2-shot (given the explanation in 4.4) \n\nMy main concern is, however, that if XGLM is not using bootstrapping+self-amplification etc. in Table 2 I am not sure how fair of a comparison it is. Perhaps with those techniques XGLM would  exceed mT5 by a high margin. \n\n(In appendix G the additional techniques over SAP seems to make a huge difference. Appendix B does show that mT5 performs on par with a much larger GPT3 on translation when both are self-amplified but still would be curious about XGLM given its multilingual emphasis similar to mT5. However, I acknolwedge the effectiveness of SAP compared to other variants of prompts to mT5) \n\n\n2. As the paper acknowledge, SAP requires running the whole encoder-decoder architecture in an autoregressive loop. This can be slow. Particularly critical is that caching isn't anymore possible (wherein caching is generally usable to speed up autoregressive decoding in causal decoders), because the encoder is bidirectional and in the autoregressive loop. \n\n-------------------------------\n\nI am increasing the score to 8. While the weaknesses are not completely resolved: re. 1 there are still enough evidence that mT5 can be made to perform on par with undirectional decoders as the authors have clarified. Regarding 2, authors are upfront about it. \n\nThere are still some limitations. The conclusions rely only on mT5 but authors are clear about their justification and there are not many other models at a similar large enough scale. In terms of impact, I am not entirely sure how meaningful the result will be - given other works on improving Seq2Seq pre-training is already underway independent of this work and SAP, as it is now, may not be as practical for adoption. However,  I think the paper still brings a neat empirical insight, and sets up a bar with SAP that we can attempt to approximate or overcome. It can also open questions and investigation of why this sort of autoregression over the whole seq2seq setup works so well and if there can be some ways to make to computation easier. There is also a decent amount of experiments in the paper. \n\nOverall, given these factors, I decided on raising the score. \n\nSome (optional) discussion topic the paper may (or may not) add:\n\nNot related to prompt tuning but - [1] and [2] also uses a similar strategy of puting the bidirectional encoder within an autoregressive loop and shows better compositional generalization. This could be worth some discussion and encourage future directions in more closely studying what this form of technique is bringing to the table. \n\n[1] Disentangled Sequence to Sequence Learning for Compositional Generalization - Zheng et al ACL 2022\n[2] Recursive Decoding: A Situated Cognition Approach to Compositional Generation in Grounded Language Understanding -Setzler et al. Arxiv 2022",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:** The text, motivation, and methodological descriptions are mostly clear. However, I am unclear on some experimental details as mentioned above. \n\n**Novelty/Originality:** The method is novel to my awareness, but somewhat incrementally novel. However, although in hindsight, the approach is technically just a simple modification over normal prompting,  the method still seems moderately effective and serve an interesting purpose (in bringing bidirectional models on par with unidirectional ones at least for the tasks considered), and this hasn't been done in this form before (to my knowledge). Moreover, \"simplicity\" here can also count as a virtue. So given these factors, the contribution can still be considered significant. \n\n**Reproducibility**: Besides some unclarities, there seems to be enough explication of the resources and methods for it being reproducible although lack of code is not ideal. \n\n",
            "summary_of_the_review": "SAP, a technique to effectively zero-shot/few-shot prompt bidirectional language models, is introduced. Simple method; results look decent. Bidirectional models are shown to have the potential to be on par with or better than unidirectional model on instruction following and in-context learning. However, some experimental comparisons may not be completely fair and inference speed may take a big hit. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_77VL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4464/Reviewer_77VL"
        ]
    }
]