[
    {
        "id": "VBTjCUKRrB",
        "original": null,
        "number": 1,
        "cdate": 1666338847127,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666338847127,
        "tmdate": 1666338847127,
        "tddate": null,
        "forum": "uJzSlJruEjk",
        "replyto": "uJzSlJruEjk",
        "invitation": "ICLR.cc/2023/Conference/Paper1342/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims at a new and interesting setting of novel class discovery (NCD), namely NCD under unreliable sampling (NUSA). In my view it is common NCD plus a special case of label noise. Specifically, this paper is motivated by a sampling view of NCD, and identidies two sampling errors one may face. To conquer the sampling errors, this paper takes inspiration from current label noise literature and proposes a two-stage learning paradigm by first fitting the wrongly sampled data and then discovering the novel classes through a novel mini-batch k-means algorithm. The proposed method is evaluated on several popular NCD benchmarks, which has demonstrated the superiority against the sampling erorrs in NCD.\n",
            "strength_and_weaknesses": "Strength:\n- This work tackles a relatively new potential problem of NCD that has not yet received much attention.\n- This paper is well written and easy to follow.\n- The proposed method is novel and well motivated.\n\nWeaknesses:\n- Some terms and conclusions are not well explained. For instance, what is the residual sampling errors? Why fully fitting the sampled data is necessary to yield clean data representations from hidden layers?",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clearly written and novel, which is of good quality.",
            "summary_of_the_review": "A good submission with an intersesting scope and solid solution.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_6g6E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_6g6E"
        ]
    },
    {
        "id": "CFDhzoe9Rdm",
        "original": null,
        "number": 2,
        "cdate": 1666471718509,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666471718509,
        "tmdate": 1669823244884,
        "tddate": null,
        "forum": "uJzSlJruEjk",
        "replyto": "uJzSlJruEjk",
        "invitation": "ICLR.cc/2023/Conference/Paper1342/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the problem of novel category discover (NCD) in the setting where samples have been mis-labelled. Standard NCD gives a model a labelled set of images from closed-set categories, as well as an unlabelled set of images from disjoint categories. The task becomes to learn a classifier which can both recognise the labelled classes but also cluster new categories in the unseen data. In this paper, the authors consider the setting in which there is noise within closed-set categories (the labelled set), but also when some closed-set examples appear in the unlabelled set and vice-versa. They name this setting 'NUSA'. \n\nThe authors develop a method to solve this problem which involves fitting a standard classifier on all of the data with a (weighted) cross-entropy loss, treating all unlabelled samples as a single class. Clustering of the new classes is performed by running mini-batch K-Means, where centroids are identified on mini-batches and then averaged across them all.\n\nThe authors show results on CIFAR10, CIFAR100 and ImageNet, which are standard NCD benchmarks. The authors create baselines by taking standard NCD methods and running them on top of data which has been algorithmically cleaned with methods from the label-noise literature.",
            "strength_and_weaknesses": "Strengths: \n* The problem the authors tackle is interesting. Label noise is something practical vision systems must deal with and the authors demonstrate that the performance of existing methods deteriorates as noise is introduced. Furthermore, the authors explore two forms of label-noise, within the closed-set classes and between the closed and open-set categories.\n* The authors have made a good effort to create strong baselines by running on the combinatorial space of four NCD baselines and two label-noise cleaning techniques. However, it is not clear if and how hyper-parameters for these methods were tuned. \n* The authors' proposed solution outperforms all the baselines. Furthermore, they validate all design choices in the ablation, with substantial performance drops without each component.\n\nWeaknesses:\n* My main concern is that I am not wholly convinced by the method. Though the authors phrase it in quite a complicated way ('Hidden-prototype-based discovery network'), the method is actually very simple: train a model with cross-entropy loss on all data (treating all unlabelled instances as one class); and then cluster network features with mini-batch K-Means. The language used to phrase the method seems more confusing than explanatory. For instance, despite the discussion of how earlier features may have fit less to label noise, the authors seem to use features before the final linear layer, which is a standard choice for clustering of deep features. This is especially a problem since in some cases, the improvements over baselines are small (e.g CIFAR100 case).\n    * I would strongly suggest the authors re-phrase the method section to highlight the simplicity of the method and its strong relation to prior work (e.g MiniBatchK-Means implemented in sklearn).\n* The authors motivate this study by stating that experts or professionals often confuse similar object categories. However, all results are shown on coarse-grained datasets, where the categories (e.g 'horse' and 'ship' in CIFAR10) are easy to distinguish. Other category discovery papers [1] have evaluated on fine-grained datasets which better reflect the motivating setting.\n* Fig1b shows that the performance of RankStats alone can reach as high as 41%, though the performance in Table 1 is reported at 34%. Is this because performance at the final checkpoint is taken? If so, there should be ways to perform early stopping (like performance on a validation set of closed-set examples). \n\n[1] Generalized Category Discovery, Vaze et al., CVPR22\n",
            "clarity,_quality,_novelty_and_reproducibility": "I think the work is phrased clearly in that I found it easy to follow. However, I believe that the method is phrased in too complicated a fashion, and in such a way that it obfuscates its simplicity and relation to prior work.\n\nI would say the quality of this paper is medium, with a commendable number of baselines implemented and reasonable ablations given.\n\nThe originality of the work is also medium. The setting is an extension of an exisiting problem which has not been studied before, though the method bears strong resemblance to existing work. (I note that this latter point is not a problem in and of itself, though I find it problematic that it is phrased in a complicated manner).",
            "summary_of_the_review": "In its current form, I recommend rejecting the paper. I believe this paper makes promising initial steps towards an interesting problem, but I believe both the methods and evaluations could be expanded before it is accepted as a conference publication.\n\nUPDATE AFTER AUTHOR RESPONSE:\n\nI have now read the other reviews and the authors' corresponding comments. I first acknowledge the authors' positive response to my suggestion for early stopping to improve the performance of the baselines. I am surprised by the authors' finding that early stopping actually reduces the performance of the baseline further (though I would be interested in seeing the training curves for validation accuracy vs overall accuracy to verify this).\n\nOverall, however, my main concerns behind the paper remain. Specifically, though the setting is interesting, the method is essentially to train a supervised representation by treating all unlabelled instances as one class, followed by (mini-batch) k-means. This is described in an unnecessarily complicated way which obfuscates the simplicity of the method, and the authors have not updated the paper to reflect this. The result is that I find it difficult to understand which technical components lead to improvement over the baselines.\n\nFor instance, lengthy discussions on the robustness of the intermediate representations (final paragraph of 4.1) are unnecessary given the authors eventually run the classifier on top of the networks' penultimate layer (Fig 5b). This choice is entirely standard (it is the 'feature vector', or the representation before the FC classifier). I also still fail to see substantial difference between the authors proposed mini-batch k-means and the standard version in sklearn, though perhaps I am missing something.\n\nAs such, though I believe the direction of research is interesting, I maintain my original rating.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_SxkT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_SxkT"
        ]
    },
    {
        "id": "ogimNnJfhh0",
        "original": null,
        "number": 3,
        "cdate": 1666679785829,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679785829,
        "tmdate": 1666679785829,
        "tddate": null,
        "forum": "uJzSlJruEjk",
        "replyto": "uJzSlJruEjk",
        "invitation": "ICLR.cc/2023/Conference/Paper1342/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors describe an approach to solve the unreliability in the novel class discovery problem (NCD), where collectors may misidentify known classes and even confuse known classes with novel classes. They propose a solution which is a combination of a proposed deep network called hidden-prototype-based discovery network (HPDN), and mini batch k-means. The authors evaluate their approach against 3 benchmark datasets and 3 types of models (Existing NCD methods, Combine NCD methods with Co-teaching and Combine NCD methods with DivideMix). ",
            "strength_and_weaknesses": "Strengths:\nThe authors have clearly stated the problem they are addressing and discussed a solution along with experimental results. They have demonstrated the robustness of HPDN under various conditions. \n\nWeakness:\nThe results of the HPDN model are significantly better than the other approaches, which makes one wonder if (a) the baselines chosen are weak, or (b) if the model is indeed better. It is not clear from the paper which is correct. \nLooks like approaches such as UNO (https://arxiv.org/pdf/2108.08536.pdf) and AutoNovel (https://arxiv.org/pdf/2106.15252v1.pdf) seem to have reported different performance metrics than those reported in this paper.\n\nFurther, it is not clear why k-means was chosen instead of other approaches such as cosine similarity, nearest neighbors etc. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is fairly clearly written, barring a few grammatical or typographical errors. \nThe novelty of the paper is hard to appreciate given the lack of justification of the baselines and the choice of performance metrics. \nThe authors have included the details for reproducing the paper. ",
            "summary_of_the_review": "Overall, the paper addresses an important problem of handling novel class discovery problem (NCD). The authors have proposed an approach that learns a HPDN and uses k-means for clustering. The metrics are surprisingly better than baselines, but also are different from those reported in the papers. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_g5Zb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1342/Reviewer_g5Zb"
        ]
    }
]