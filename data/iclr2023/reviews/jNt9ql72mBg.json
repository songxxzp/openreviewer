[
    {
        "id": "xqPSsamaj2",
        "original": null,
        "number": 1,
        "cdate": 1665823991134,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665823991134,
        "tmdate": 1669693614859,
        "tddate": null,
        "forum": "jNt9ql72mBg",
        "replyto": "jNt9ql72mBg",
        "invitation": "ICLR.cc/2023/Conference/Paper3819/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel problem for pseudo-labeling based semi-supervised learning. Especially, the authors proposed Confident Sinkhorn Allocation (CSA), which assigns labels to only examples with high confidence scores and learns the best label allocation via optimal transport.",
            "strength_and_weaknesses": "(+) The paper is generally well-written.\n\n(+) The theoretical analyses of this paper are solid. \n\n(+) The experiments are sufficient.\n\n\n(-) I feel that the proposed method is computational expensive. In each iteration, M models should be trained on labeled data, and an inner loop exists for Sinkhorn\u2019s algorithm. Therefore, I want to see the total running time comparison of the proposed CSA and baseline methods. Besides, how about the scalability of the proposed method?\n\n(-) Also regarding the model assembling, I doubt that the performance improvement of CSA over other comparators in Table 2 is due to this operation. Moreover, I found that the performance improvement on various dataset is quite marginal. Therefore, I want to know whether the comparison is fair, and whether the comparison demonstrates the effectiveness of the proposed way for calculating the uncertainty. Maybe, the authors should conduct statistical significance test to justify the superiority. \n",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned previously, I think the paper is generally well written. The details of the proposed algorithm are clearly stated.",
            "summary_of_the_review": "I like the solid theoretical analyses of this paper, although the experiments are comparatively weak. I would temporarily give a positive mark for this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_hVwg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_hVwg"
        ]
    },
    {
        "id": "o1o_rVOCrW",
        "original": null,
        "number": 2,
        "cdate": 1666471413541,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666471413541,
        "tmdate": 1666487349183,
        "tddate": null,
        "forum": "jNt9ql72mBg",
        "replyto": "jNt9ql72mBg",
        "invitation": "ICLR.cc/2023/Conference/Paper3819/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an improved pseudo-labeling method for semi-supervised learning methods. The paper first proposes a method for filtering out some unlabeled data that has high uncertainty based on  Welch\u2019s T-test and  Total variance.  The paper then extends the methods of SLA [1] to assign labels for unlabeled data.\n\n\n",
            "strength_and_weaknesses": "**Strengths**:\n\n* The paper proposes a method that does not need a predefined threshold to filter the unlabeled data\n\n\n**Weakness**:\n\n* The proposed method has limited novelty. First, considering uncertainty in pseudo-labeling is not new, e.g. [2] considered this scheme. Second, using optimal transport is not new as well. It is proposed in SLA [1].\n\n\n* The proposed method does not need a predefined threshold to filter the unlabeled data, but the method needs additional hyper-parameters, such as fraction of assigned label $\\rho$, which counteract the benefit of the proposed methods.\n\n\n* The proposed methods need additional computation cost due to optimal transport calculation and multiple model training on the labeled data.  \n\n\nReferences:\n\n[1] Sinkhorn label allocation: Semi-supervised classification via annealed self-training. ICML.2021\n\n[2] In defense of pseudo labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning. ICLR 2021",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.\n\nThe novelty is limited.\n\nThe results seem to be reproducible.",
            "summary_of_the_review": "This paper proposes an improved pseudo-labeling method for semi-supervised learning methods, but the novelty of the proposed methods is limited.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_MB4o"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_MB4o"
        ]
    },
    {
        "id": "f7aF9BI6zQ",
        "original": null,
        "number": 3,
        "cdate": 1666672741632,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672741632,
        "tmdate": 1666672741632,
        "tddate": null,
        "forum": "jNt9ql72mBg",
        "replyto": "jNt9ql72mBg",
        "invitation": "ICLR.cc/2023/Conference/Paper3819/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to improve the well-known pseudo-labeling by Confident Sinkhorn Allocation (CSA) which confidently assigns the labels via optimal transport. The authors demonstrated CSA\u2019s performance by comparing it with other SSL strategies.",
            "strength_and_weaknesses": "Strength:\n1. CSA first conducts sample selection by removing low-confidence samples and then focuses on assigning labels. The overall framework is convincing and easy to follow. \n2. The variance of correct assignment, i.e., epistemic uncertainty, is considered for evaluating the uncertainty, which is an interesting idea.\n\nWeaknesses:\n1. The so-called domain-specific and pseudo-labeling has been attributed to two separate components which were thought based on the different designing principles. Please refer to [1].\n2. I understand that authors would like to show correct assignments affect the optimal decision boundary by theorem 1. As it extends Yang&Xu\u2019s theory, I am curious if it gives a better theoretical conclusion, e.g., closer to the decision boundary.\n3. The discussion about the most provable class and second-most probable class is related to the theorem presented in the work [1], because both considered the relative relation between outputs.\n4. T-test for sample selection is based on training M models, which incurs much computation cost. Note that the dropout used in Rizves et al is only involving inference, but CSA is with an ensemble style. An explanation about it should be added.\n5. Another concern is that T-test is used for sample selection, but it has not used epistemic uncertainties, i.e., the variance of I. Notice that total variance is designed for multilabel classification, is it feasible for multiclass semi-supervised classification?\n6. The contribution compared with Tai et al from the label assignment section is not very convincing to me. Does CSA outperform theirs by T-test and some additional constraints over class population size?\n\n[1] Taming Overconfident Prediction on Unlabeled Data from Hindsight, https://arxiv.org/abs/2112.08200\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is overall good and well presented. I personally would not encourage more research efforts on improving pseudo-labeling. The major reason is that studying this specific topic for SSL is narrow because according to the experimental results, such an elaborate design only slightly enhances the SSL performance. It is okay for the method such as FixMatch back to two years ago, but it is not very interesting today. ",
            "summary_of_the_review": "I have listed my concerns about this work above and I am expecting the authors' response.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_AnF4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3819/Reviewer_AnF4"
        ]
    }
]