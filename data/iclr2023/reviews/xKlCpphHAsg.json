[
    {
        "id": "oUS_6hg0Wn",
        "original": null,
        "number": 1,
        "cdate": 1666415336240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666415336240,
        "tmdate": 1666438657488,
        "tddate": null,
        "forum": "xKlCpphHAsg",
        "replyto": "xKlCpphHAsg",
        "invitation": "ICLR.cc/2023/Conference/Paper575/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors introduce an adversarial detection algorithm which tackles the sensitivity of detection scores from the single sample via proposed expected perturbation score. Specifically, the scores are obtained by the diffusion process which takes into consideration multiple levels of noise. The obtained scores are compared through maximum mean discrepancy. The experiments are conducted on different datasets and settings, which involve the evaluation of different attacks. The proposed adversarial detection algorithm show superiority compared to other baselines.",
            "strength_and_weaknesses": "Pros:\n\n++ The paper is well-written and well-motivated. Motivated by the ineffectiveness of the score of one sample, the authors propose to use expected perturbation score via pre-trained diffusion model seems natural.\n\n++ The authors provide theoretical analysis to show that proposed expected perturbation score can better distinguish the distributions between natural examples and adversarial ones.\n\n++ The experiments are extensive. The evaluation is conducted on both CIFAR and ImageNet under various attacks. The authors also consider the adversarial detection of both white-box and black-box settings. The results are promising and convincing, which achieve better performance than other detectors.\n\nCons:\n\n-- One of my concerns lies in the computational cost of proposed adversarial detection. According to Figure 2, both a set of natural images and the target image are fed to the pre-trained diffusion model for perturbation generation and expected perturbation score computation, it seems to have a burden of computation compared to other two-sample test methods.\n\n-- It would be better for the authors to provide evaluation of adversarial detection on up-to-date transferable attacks, such as [1,2]. \n\n[1]. Enhancing the Transferability of Adversarial Attacks through Variance Tuning. CVPR 2021.\n\n[2]. Improving Adversarial Transferability via Neuron Attribution-based Attacks. CVPR 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper introduces a natural and novel adversarial detection algorithm, which could benefit the community of adversarial attack and robustness. The experiments are sufficient. In terms of reproducibility, the description of the experiment setup is clear. More details are included in the appendix.",
            "summary_of_the_review": "Overall, I think this paper is interesting and solid. It would be better if the authors can provide more analysis of the inference efficiency and include more evaluation of up-to-date transferable attacks.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper575/Reviewer_yyTy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper575/Reviewer_yyTy"
        ]
    },
    {
        "id": "MVyC8tDrLmj",
        "original": null,
        "number": 2,
        "cdate": 1666613870097,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666613870097,
        "tmdate": 1666613870097,
        "tddate": null,
        "forum": "xKlCpphHAsg",
        "replyto": "xKlCpphHAsg",
        "invitation": "ICLR.cc/2023/Conference/Paper575/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a new statistic, called Expected Perturbation Score (EPS), for adversarial detection. Based on EPS, the authors develop a Maximum Mean Difference (MMD) metric to measure the difference between test samples and natural samples, and further propose an EPS-based adversarial detection method (EPS-AD). Sufficient theoretical analysis and extensive experiments demonstrate the correctness and effectiveness of the proposed method.",
            "strength_and_weaknesses": "Strength:\n1. This paper is easy to read.\n\n2. The authors propose a new statistical method, called Expected Perturbation Score (EPS), which is able to obtain enough information to identify adversarial examples with only one example after various perturbations.\n\n3. Sufficient theoretical analysis is performed to demonstrate that EPS is able to simulate the difference between the two distributions under mild conditions. Furthermore, extensive experimental results demonstrate the superiority of the proposed EPS-AD.\n\n4. The proposed EPS will be an effective statistic in many applications, such as out-of-distribution detection and anomaly detection.\n\nWeaknesses:\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. Within the perturbation process, why do the authors restrict the value of the time-dependent noise schedule t to be in [0, 1000], but only provide results in [0, 100] in Figure 4(f)? Please explain the reason.\n\n2. Writing issues:\n1) In line 4 of ABSTRACT, \"...gradients...\" should be \"...gradient...\".\n2) The first line of the paragraph under the equation. (2), \"... the the...\" should be \"...the...\".\n3) In the first line of the paragraph preceding Theorem 1, \"...derive a...\" should be \"...derive the...\".\n\n\n3. In the last paragraph on page 7, epsilon in [1/255, 8/255] means all real numbers in this range, why does the authors only consider 8 values?\n",
            "summary_of_the_review": "This paper is easy to read and interesting but still has some minor issues, please refer to weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper575/Reviewer_RHkt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper575/Reviewer_RHkt"
        ]
    },
    {
        "id": "AmUOhiQ4vY",
        "original": null,
        "number": 3,
        "cdate": 1667938966030,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667938966030,
        "tmdate": 1667938966030,
        "tddate": null,
        "forum": "xKlCpphHAsg",
        "replyto": "xKlCpphHAsg",
        "invitation": "ICLR.cc/2023/Conference/Paper575/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new method based on average score function difference to detect adversarial perturbations in a given image. The main result of the paper is empirical, the paper also provides some theoretical justification of the usefulness of the score estimation.",
            "strength_and_weaknesses": "The main strength of the paper is empirical: the proposed method works very well compared to some of the earlier baselines. The method can effectively detect adversarial perturbation in the low perturbation regime. The author did experiments on both CIFAR data and ImageNet data with different architectures to justify the result.\n\n\nThe main weakness of the paper is three folds: First of all, the proposed method is based on the mean discrepancy. It is not very useful in detecting whether a single image is perturbed or not -- While the previously proposed method can do so for a single image. Hence the paper is only compared to other works in its favorable setting. To that extent, the paper should at least study the dependency of the detection accuracy w.r.t the total number of samples used. \n\nSecondly, the paper also emphasizes that their advantage is \"multi-view\", where they average the score estimation over time -- I expected the theory to provide some insights on why such averaging is useful, but I could not interpret it from the current form.\n\nThird, I have significant concerns about Definition 1. Here, the author seems to take x_0 = x to define S(x). However, in the \"Estimation for expected perturbation score\" section, the author claims that they are using s_\\theta(x_t, t) to estimate S(x). Note that  s_\\theta(x_t, t)  is computed not from x_0 = x, but by averaging over all possible x_0 sampled from distribution p_0. I am not sure this is a good approximation of the S(x) as in Definition 1. The definition probably needs some re-work, but I'm afraid that theorem 1 will be completely falsified after that.\n\n\n\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and the method is quite simple to understand and implement. \n\nThe paper simply combines the existing idea of using score estimation for adversarial perturbation with the min-discrepancy loss -- It's not particularly novel.",
            "summary_of_the_review": "The empirical findings of the paper are solid, although not novel. The mathematics in the paper is a bit concerning and probably needs some rework.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper575/Reviewer_d5es"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper575/Reviewer_d5es"
        ]
    }
]