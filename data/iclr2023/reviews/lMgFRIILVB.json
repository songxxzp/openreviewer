[
    {
        "id": "0pZKkCZlMT",
        "original": null,
        "number": 1,
        "cdate": 1666643257306,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643257306,
        "tmdate": 1666643257306,
        "tddate": null,
        "forum": "lMgFRIILVB",
        "replyto": "lMgFRIILVB",
        "invitation": "ICLR.cc/2023/Conference/Paper3188/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes SlenderGNN, a new GNN method that is accurate, robust, and interpretable. Authors report experimental results comparing SlenderGNN's performance with a set of alternative methods. They also conduct an ablated study to assess the importance of individual modules of the proposed method in its performance.",
            "strength_and_weaknesses": "Strength\n- The paper addresses an important topic (i.e. interpretability and robustness of GNN).\n\nWeaknesses\n- Scattered and not well supported claims. The contributions from GNNLin and SlenderGNN are mixed in the paper and empirical results only provide partial evidence about the claims. Maybe it would have been more beneficial if authors had fully focused on SlenderGNN rather than including SlenderGNN related materials as well.\n- Experimental results are not clearly discussed and it is not clear why LR shows comparable to superior results in most data sets vs. more state of the art and GNN-based approaches.\n- Also refer to reviewer's comment on clarity, quality, and novelty in the box below.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity:\nIn general, the way the proposed method works (section 4 of the paper) is not very clear. e.g. The connection between the components of the propagation function and GNNLin (Table 1) is not clear and the choices of 2-step neighbors, neighbors, etc. is not well justified in equation 3 (i.e. propagation function). \n\n- Quality\nInterpretability and robustness are not well explained in the paper and they are not backed by experimental results either. e.g. there are quantification methods for interpretability/explainability in the literature that authors could have reported for their work. For example, one metric is to have a data set with explanation ground truth and measure the overlap between the decisioning factor identified by the proposed method vs. the ground truth explanation. Same point holds about robustness where authors claims are not backed by strong empirical evidence.\n\n- Novelty\nNovelty contributions are marginal.\n\n- Reproducibility\nAlthough authors have provided the source code for their method, due to lack of clarity explained earlier in this box, it's hard to reproduce authors work.",
            "summary_of_the_review": "The paper addresses an important question/concern with GNNs, however there are major limitations in connecting the experimental results with the paper's claims. Also theoretical grounds of the paper are not very clear.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_DLLT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_DLLT"
        ]
    },
    {
        "id": "i2BH8uyPKcw",
        "original": null,
        "number": 2,
        "cdate": 1667068007437,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667068007437,
        "tmdate": 1667068007437,
        "tddate": null,
        "forum": "lMgFRIILVB",
        "replyto": "lMgFRIILVB",
        "invitation": "ICLR.cc/2023/Conference/Paper3188/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors propose the framework that tackles crucial aspects of modeling, which include accuracy, robustness, slenderness, and interpretability. To tackle this, authors propose the generic framework, named GNNLIN, that consists of the propagation layer and the logistic regression layer. Through the generically structured propagation layer, the proposed method can provide the interpretability. Furthermore, authors propose the sanity checking framework that verifies whether a given model algorithms works broadly for various scenarios of graphs and features. Finally, authors use the proposed sanity checks and real-world datasets to show the proposed algorithm outperforming the baseline methods.",
            "strength_and_weaknesses": "* Strengths\n- A simple but generic interpretable model is proposed.\n- The proposed model achieves many aspects all together.\n- Sanity check framework is proposed and it would be great for other researchers to analyze their own models.\n\n* Weaknesses\n- The non-linear component is cleared for simplicity, but it is not clear whether the activation is not necessary or it can play a role to improve the performance more.\n- In particular, the proposed method is just a logistic regression model that uses neighbor information, connectivity information, and node attributes as features. Eventually, the proposed model solves the iid logistic regression regardless of any latent space. Apparently, the proposed model does not seem to be a GNN. Authors need to modify the definition or the explanation of modeling, or regard the proposed model as the linear model using graph features. Robustness and interpretability can be achieved typically through such simple models.\n- Many GNN models rely on sampling methods, while the proposed method is based on more matrix operation. It would be great if the proposed method can work with some sampled data or scale enough.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The manuscript is well-written for authors to follow easily.\n- The model is well-organized, but it is actually a logistic regression with features. In that sense, the proposed model is not novel enough to this literature.\n- Sanity checking framework is great to assess the model performance in various scenarios.",
            "summary_of_the_review": "The proposed framework is very intuitive and passes the sanity checking framework as well as outperforms the baseline methods. However, the model is essentially the logistic regression model using graph and node features, which are already being used commonly by industry. The novelty of the proposed model is limited in that sense.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_y6fQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_y6fQ"
        ]
    },
    {
        "id": "39wpUkNnb0t",
        "original": null,
        "number": 3,
        "cdate": 1667150822955,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667150822955,
        "tmdate": 1667150822955,
        "tddate": null,
        "forum": "lMgFRIILVB",
        "replyto": "lMgFRIILVB",
        "invitation": "ICLR.cc/2023/Conference/Paper3188/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper reviews the desiderata of GNN and proposes SlenderGNN, a simple linear GNN, to meet the needs. The proposed SlenderGNN comes from the linearization framework, which can resemble various GNN designs. Towards these desiderata, the authors present several sanity check, and the proposed SlenderGNN pass all of them. Moreover, SlenderGNN shows superiority over various GNNs on several real-world node-classification tasks.",
            "strength_and_weaknesses": "Strength:\n1. This paper is well written, where all the definitions, declarations, and tables are self-contained.\n2. The discussion of linearizing GNN is comprehensive and valuable for the community, which unifies many SOTA GNN works.\n3. The performance of SlenderGNN is amazing, especially considering that outperforming those SOTA GNNs on such a variety of node classification tasks is very difficulty in nowadays.\n\nWeaknesses:\n1. The SlenderGNN is not a sophisticated instance among the linearization framework, that is to say, it has obvious limitations such as a restricted receptive field. In another word, it is not that novel to me.\n2. As a linear GNN, the transformation $P$ could be interpreted from the perspective of feature engineering. Thus, it might be necessary to include several works in that line as baselines (e.g., graph kernel methods) in the experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: In all, the flow is good to me, where I can easily follow the whole story quickly. However, it seems that there is a lack of the explanation about the linear property of SlenderGNN.\n\nQuality: The definitions are consistent with existing literature. The claims are correct imo, including the concrete linearization of existing GNNs elaborated on in the supplementary materials. The sanity checking is designed to accurately reflect the desired properties of a GNN. The experiments are conducted on a comprehensive collection of node classification tasks with various kinds of SOTA GNNs.\n\nNovelty: The discussions of linearization is novel to me. However, the concrete design of the proposed SlenderGNN is straightforward and sacrifices several advantages of existing SOTA spectral GNNs, which raises my concerns about its novelty.\n\nReproducibility: It is convincing as the authors have provided the repository.",
            "summary_of_the_review": "I appreciate the discussion of what an ideal GNN is supposed to do, which makes the design of SlenderGNN well-motivated. Although the discussed linearization is somewhat straightforward, it well resembles various kinds of GNNs. I think it is helpful for the community to view existing GNNs from such a perspective. However, I have concerns about the novelty of SlenderGNN, which seems to be a trivial linearization. The consistent advantages achieved by SlenderGNN makes me eventually give a relatively positive score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_VYo8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_VYo8"
        ]
    },
    {
        "id": "xHSBSnuovl",
        "original": null,
        "number": 4,
        "cdate": 1667169256915,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667169256915,
        "tmdate": 1667169256915,
        "tddate": null,
        "forum": "lMgFRIILVB",
        "replyto": "lMgFRIILVB",
        "invitation": "ICLR.cc/2023/Conference/Paper3188/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The main objectives of this paper are two-fold. \nFirst, the authors introduced a linearization framework for transforming various GNNs into a linearized form. Removing non-linearities should improve interpretability.\nSecond, the authors applied what they have learned about different GNNs (pain points and factors that distinguish different GNN variants) in designing of their own GNN-variant which is optimized for interpretability, robust to various labeling scenarios in graphs and has fewer parameters.\nThe authors presented their results together with sanity checks where they identified three groups of graph scenarios composed of combination of Edge types, Labels types and Feature types.\n ",
            "strength_and_weaknesses": "This paper follows a strict logical path. The authors first describe their linearization framework. They proceed to describe lessons learned when applying linearization to previous GNN variants. The chief problem they listed have to do with the lack of explainability of GNN models with many layers. \nI was particularly impressed with the sanity checks proposed in this paper for evaluating robustness of the proposed method and for comparing it with previous methods.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper may benefit from a discussion on why replacing nonlinearities with linear activation functions led to the improvement in accuracy. How the loss in model expressiveness due to removing nonlinearities can lead to the improved performance?\nCan the authors mention any improvements upon their presented method that they can address in the future work?\n",
            "summary_of_the_review": "Overall, I found this paper to be well-written and well-motivated. I believe this paper addresses an important problem and provides an innovating solution.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_f9sS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3188/Reviewer_f9sS"
        ]
    }
]