[
    {
        "id": "oBChPYBKLj",
        "original": null,
        "number": 1,
        "cdate": 1666302513108,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666302513108,
        "tmdate": 1666302513108,
        "tddate": null,
        "forum": "NpsVSN6o4ul",
        "replyto": "NpsVSN6o4ul",
        "invitation": "ICLR.cc/2023/Conference/Paper3588/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper finds a \"circuit\" (in this case, a subset of attention heads), C, that is meant to explain how GPT-2 small solves a particular synthetic task named Indirect Object Identification (IOI).\nThis task composes 15 templates of forms like \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\".\nThe goal is to predict the name [A] at the end of the sentence, given all of rest of the sentence as context.\nThe model's behavior on other types of inputs was not evaluated.\n\nThe  claim is supported by experiments which aim to establish that C meets the authors' criteria of being faithful, complete, and minimal.\nSome of their experimental results challenge this interpretation, however (see Sections 3.4 and 4.3).\n\nThe authors also describe how they go about identifying the proposed circuit, describing the techniques of knock-outs (i.e. looking at a subgraph of M), and patching (substituting different activations at some nodes of the computational graph while computing a forward pass).\n\nThe novelty of the proposed criteria and techniques is not clearly stated (except completeness, which they state they introduce).\n",
            "strength_and_weaknesses": "\nStrengths:\n- The notions of faithfulness, completeness, and minimality seem like a promising approach to rigorously evaluating mechanistic interpretability claims.\n- The paper covers a lot of ground; besides (apparently?) introducing these notions, they also propose methods for looking for circuits, and an interpretation of a particular model on a particular task.\n- The interpretability efforts themselves are potentially useful as a case study that could guide or inform future work.\n- The topic is neglected and potentially significant: mechanistic interpretability is worthy goal and not much has been published on it.\n\nWeaknesses:\n- The three claimed contributions are not sufficiently well supported.  \n1) RE \"(1) We identify a large circuit in GPT-2 small that performs indirect-object identification (Figure 2 and Section 3)\":\nThe discovery of the Backup Name Mover Heads suggests that other important bits of circuitry might've been missed, and that the model's behavior on this task might not be very well captured by the circuit.  Perhaps there are also Backup Backup Name Mover Heads, etc.?  Furthermore, as noted, computing the completeness score is intractable, the approximations produce somewhat inconsistent results, and no effort is made to determine which ones are reliable, excepting Section 4.3, where it is indirectly suggested both that the greedy method is both both better at estimating the completeness score, and that the \nThis is methodologically backwards: it assumes the interpretation is correct, and uses this as a basis to challenge the definition of the completeness score.\n2) RE \"(2) Through example, we identify useful techniques for understanding models, as well as surprising pitfalls\":\nThis is a vague contribution and does not make a clear statement of novelty... which techniques are novel?  Or is it their application to \"understanding models\" that is novel?  What are the \"surprising pitfalls\"?\n3) RE \"(3) We present criteria that ensure structural correspondence between the circuit and the model, and check experimentally whether our\ncircuit meets this standard (Section 4)\":\nIt has not been established that these criteria ensures structural correspondence; indeed, the notion of structural correspondence is not defined.  The criteria don't seem quite conceptually correct (see below).\nThe experimental results are not conclusive, and their interpretation remains subjective.  The checks that are performed seem ad-hoc and incomplete.\n- There are a few limitations/concerns that deserve more discussion:\n1) There seems to be an unstated assumption that circuits are they a meaningful way of understanding a model's behavior.  This assumption doesn't seem to be evaluated or supported by this work. \n2) The paper seems optimistic about applying a similar approach to larger models, but doesn't discuss the challenges of scaling this approach (models may have a very high level of inherent complexity, mechanistic interpretability may require a prohibitive amount of human labor needed, even if models are simple enough to be understood mechanistically).  \n3) It seems the interpretation provided in this work can (at most) only tell us about how this model handles this very specific synthetic task.  How does this lead to a meaningful or practical understanding of how a model works more generally?  Or is the idea to study every behavior of interest in isolation? \n- Overall, the writing is not careful in its claims (e.g. Section 3.2 starts with \"Given that the Name Mover Heads are primarily responsible for constructing the output\", but this hasn't been established).\n- The definitions of faithfulness, completeness, and minimality do not seem fine-grained enough to fully capture mechanistic similarity between the circuit and the model.  I would expect the definition of F to measure the average difference in logits instead of the difference in average logits, and measure the difference in the vector of logits or probabilities instead of just the difference between IO and S tokens.  The work does not justify or discuss this chosen definition of F or alternatives.\n- The paper should provide more motivation for this line of research.  What are the pros and cons versus other approaches to interpretability?  What is the value of understanding how the model behaves on this very specific set of inputs?  Can we draw more general conclusions about the model's behavior?  Or what is the end game?  What are the prospects for automating mechanistic interpretability?\n- The definition of the task here is extremely narrow.  The model should be evaluated on OOD examples that similarly require outputting the correct name.  For instance, what if you add distractor text with other names in it to the context?  This work does not address how the model determines whether it should perform this task / engage this circuit.  Is there circuitry for recognizing what the task is?\n\n\nQuestions:\n- Is the goal only to determine how the model solves this one task?  If some of the components of C played a completely different role in different tasks or on OOD examples, how much would that challenge the interpretation?\n- The approach here seems based on finding attention heads that have large individual contributions, but couldn't there be a long-tail of other circuitry contributing to the model's behavior (e.g. in figure 6: what if you include more stuff?  why is .06 / 3% the magic cut-off)?  Section 3.4 suggests this might be the case.  Does this represent a fundamental challenge to the project of finding a circuit?  Consider an analogy with \"typicality\", where most of the probability mass of a distribution (such as a high-dimensional Gaussian) does not come from the most likely samples.\n- For the \"name mover heads\", what does it mean that the OV matrix is a \"name copying matrix\"?  If they \"copy whatever they attend to\" (and not just names), is the claim that they are just approximating the identity matrix?  This could be investigated more.\n- The role of the ABC distribution wasn't clear enough to me; can you clarify why it is used?\n\nMinor comments:\n- The names of the scores are counter-intuitive; e.g. the completeness score measures *in*completeness! \n- The writing sometimes pretty unclear, e.g. \"v can significantly recover F\"; last 2 paragraphs of 3.3.\n- \"serial circuits\" appears undefined.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- The writing was mostly clear, but the organization and style were not.  It lacks rigor in places.\n- The work doesn't clearly outline its methodology and methodological assumptions.  \n- Poor organization: Section 3 doesn't clearly distinguish between experimental proceedures, results, and interpretation. Technical definitions and techniques are presented in a somewhat adhoc fashion throughout the paper. \n\nQuality: \n- Setting aside the issues with the work mentioned elsewhere in the review, the quality of the work is fairly high.  There are many interesting experiments and results.\n- There are, however, insufficient ablation studies / sanity checks, and several of those performed question the validity of the interpretation (Section 3.4) or methods (Section 4.3).\n\nNovelty:\n- The novelty of the proposed criteria and techniques is not clearly stated.\n- The paper lacks sufficient discussion of related work.  It doesn't discuss alternative approaches to interpretability, how their approaches and aims differ from mechanistic interpretability, or the pros/cons of mechanistic interpretability vs. other approaches.  It also doesn't make sufficiently clear claims about the novelty of this work vs. previous work on mechanistic interpretability. \n\n\nReproducibility:\n- It wasn't clear how the model was trained.  Was it pretrained on natural language?  Fine-tuned on this task?  Trained only on this task?\n- Identifying C seems to involve various judgment calls.  This is a fundamental barrier to reproducibility, which should not disqualify the work.  But the authors should be clear in identifying such judgment calls and stating the basis for making them.  How easily could the approach here be generalized to other tasks or models?  Can the authors provide a recipe that a reader could follow?  Or otherwise outline how this work could facilitate future work on mechanistic interpretability?",
            "summary_of_the_review": "\nThe paper doesn't provide sufficient support for its claimed contributions.\nIn particular, I'm not convinced that the proposed circuit is an accurate representation of the model's behavior.\nWhile it makes some meaningful progress in terms of techniques and methodology, more work is needed to justify and solidify these approaches; and the presentation also needs work.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_jy1a"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_jy1a"
        ]
    },
    {
        "id": "vhxFDyYApQY",
        "original": null,
        "number": 2,
        "cdate": 1666479412164,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666479412164,
        "tmdate": 1666621432296,
        "tddate": null,
        "forum": "NpsVSN6o4ul",
        "replyto": "NpsVSN6o4ul",
        "invitation": "ICLR.cc/2023/Conference/Paper3588/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a method for mechanistic interpretation of neural networks, specifically transformer models. The high-level idea is to derive a small subnetwork that can simulate the functionality of the full neural network while satisfying faithfulness, completeness, and minimality criteria. The paper empirically analyze the subnetwork using the GPT-2-small model trained on an indirect object identification (IOI) task. The proposed method is shown to identify several steps needed for the IOI task. ",
            "strength_and_weaknesses": "Strengths: \n1. Mechanistic interpretation is a new direction of interpretability research. \n2. The analyzed model is GPT-2-small, of significant complexity. \n3. The writing is clear and easily understandable. \n\nWeaknesses: \n\nEven though the paper tackles a very new area, for which I am fine with some rough and underdeveloped ideas, the general method suffers from too many flaws for me to \"see the light at the end of the tunnel\". \n\n1. The method requires an _a priori_ known model working mechanism (e.g. the heuristic in Sec. 3), and basically maps different subgraphs (i.e. circuits) to various parts of this mechanism. This seems to be a very strong and possibly unjustified assumption: for all but the very synthetic tasks such as IOI, explicit rule-based classifiers (from the 80s and 90s) perform very poorly, suggesting that human-designed heuristics are most likely not how high-performing models work in general. Second, even if humans have a good grasp on one valid heuristic, it is likely that neural networks can use something totally different, due to accidental spurious correlations in the dataset, a problem known as shortcut learning [1]. \n\n2. The IOI task has three simple heuristic steps, mapping to the three major circuit classes. For more complex tasks, there may be tens or even hundreds of heuristics, especially for multi-class classification with a large number of classes (e.g. ImageNet). Identifying and interpreting them could be very cumbersome. \n\n3. The introduction poses three advantages of mechanistic interpretation, \"better predict out-of-distribution behavior, identify and fix model errors , and understand emergent behavior\". However, none of them is demonstrated in the experiments, and it is not clear to me how they are enabled. \n\n4. The paper assumes that attentions work \"as expected\", in that, e.g. \"Name Mover Heads, by default, attend to previous names in the sentence, but due to the S-Inhibition Heads attend less to the S1 and S2 tokens\". There have been numerous evidences suggesting that attentions may not be faithful interpretations [e.g. 2, 3, 4]. How would they be reconciled with the focus on attention in this paper? \n\n[1] https://arxiv.org/abs/2004.07780\n\n[2] https://arxiv.org/abs/1902.10186\n\n[3] https://arxiv.org/abs/2004.03685\n\n[4] https://arxiv.org/abs/2104.14403",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: the writing is highly clear\n* Novelty: the method is novel, as far as I know. \n* Reproducibility: although code is not included, I believe that this paper and the method should not be hard to reproduce\n* Impact: quite limited, which is my major concern as discussed in the weakness section. ",
            "summary_of_the_review": "Overall, currently I am not convinced that mechanistic interpretation, as demonstrated in this paper, is a promising direction for understanding black-box models. Details are discussed in the weakness section. Therefore, I vote for rejection. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_wPfU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_wPfU"
        ]
    },
    {
        "id": "2mZNmIGkrf",
        "original": null,
        "number": 3,
        "cdate": 1666643486573,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643486573,
        "tmdate": 1667180162945,
        "tddate": null,
        "forum": "NpsVSN6o4ul",
        "replyto": "NpsVSN6o4ul",
        "invitation": "ICLR.cc/2023/Conference/Paper3588/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this work authors discovered specific transformer circuits for a natural language task called the indirect object identification, This task requires the LM to identify the indirect object and needs simple logical reasoning. The significance of this paper is that authors identified a large circuit in GPT-2 small that performs a relatively natural, linguistically meaningful task . Furthermore, the authors present a set of criteria that aim to measure the structural correspondence between the circuit and the model. ",
            "strength_and_weaknesses": "Strength. \nAuthors demonstrated interpretability techniques and criteria through example, making the abstract task of interpretability concrete. \nClarity: the paper is well written and easy to read.\nQuality: The authors have formulated a set of three criteria to measure interpretability and have showed empirical evidence that their circuit have significant improvements compared to a na\u00efve circuit. \nClear limitation: Authors are also being very clear on the limitations of their circuit, showing that their circuit does not do well with the completeness criterion. \n\nWeakness\nFailing the completeness criterion could be seen as a weakness but I tend to agree with the authors that worst-case completeness is too high a bar and could be explored in future works. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Apart from what was discussed in the previous section, I have a question that the authors could perhaps clarify. I\u2019m not too familiar with the literature, is the indirect object identification task an original contribution by the authors or is it from prior works? I didn\u2019t see any reference but it was put under the background section, so I\u2019m a bit confused. This task is a great task to study interpretability as authors rightly argued, as it is linguistically meaningful yet it is very clear what simple interpretable algorithm can perform well on this task. \n\nAnother potential improvement to clarity is adding a summary or overview of all methods used to identify circuit components in the introduction section, or somewhere else, so that reader can have a holistic idea about what is the complete set of techniques used to identify all the circuit components. Maybe expand a bit more on figure 1 in the introduction, I think that could be helpful in terms of readability. Without this overview, readers might need to put together this summary themselves as currently the organization of the circuit discovery is by circuit components rather than techniques used. \n\nNitpick: a typo in the last sentence of 4.3: \u201c\u2026 worst-case completeness criteria\u201d -> \u201c\u2026 worst-case completeness criterion\u201d\n",
            "summary_of_the_review": "I\u2019d recommend acceptance, as I think this paper is a solid contribution to the interpretability of language models in natural tasks that are linguistically meaningful. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_sZ8X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_sZ8X"
        ]
    },
    {
        "id": "YSWhCqBn_l2",
        "original": null,
        "number": 4,
        "cdate": 1666646840861,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646840861,
        "tmdate": 1669719185755,
        "tddate": null,
        "forum": "NpsVSN6o4ul",
        "replyto": "NpsVSN6o4ul",
        "invitation": "ICLR.cc/2023/Conference/Paper3588/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "**Update after rebuttal** After reading the other reviews and the authors' responses I remain in favor of accepting the paper. I think wPfU, jy1a raise some very valid issues, but some of the issues raised concern the viability of the approach/research field of mechanistic interpretability in general, rather than the concrete results presented in the paper - which I think is valid to be discussed but to me is a less relevant criterion to judge one particular paper/analysis. jy1a raises additional relevant criticism specific to this particular paper, and in my opinion the authors have addressed that criticism sufficiently (I'd be keen to hear jy1a's opinion on this).\n\nThe paper is a case study analysis for identifying the mechanism / \u201calgorithm\u201d that GPT-2 small uses for solving a particular language task (Indirect object identification; indirect reference to one of two previously named persons in the same sentence to be precise). Backtracking from attention matrices - the paper essentially identifies groups of attention heads that each have an intuitive functionality, and, when combined, solve the task. To strengthen the identified circuit the paper defines metrics for faithfulness (circuit alone can explain good score on task), completeness (potentially duplicate parts of the circuit have been identified too), and minimality (no superfluous parts, that play no role in functionality and are not duplicates, have been identified) and confirms that the identified circuit fulfills all three notions. To demonstrate that the identified circuit is causally responsible for the functionality Knockouts (rendering parts of the network irrelevant) and Patching (splicing in activations from a different input into parts of the circuit, resembling a more fine-grained intervention than Knockouts) are used.",
            "strength_and_weaknesses": "**Main contributions, Impact**\n1) Well executed case study for identifying a mechanistic understanding of the circuit that solves the analysis task in GPt-2 small. Impact: medium - the techniques introduced to identify the circuit are not entirely novel, but are certainly put to good use; the identified circuit is interesting, but it is unclear whether the identified components will play a significant role in other analyses or a general understanding of strategies used by transformers to solve tasks.\n\n2) Use of interventional analysis to establish causal relevance of identified circuit. This is crucial for any serious attempt at *explaining* network functionality; an explanation must lead to falsifiable (causal) predictions. While Knockouts are a standard technique for crude interventional analysis, the paper also uses more fine-grained Patching, demonstrating its usefulness for analysis of complex circuits. Impact: medium - falsification (or establishing causal relevance) is crucial for hypotheses established via interpretability/explainability techniques. While Knockouts are certainly not novel, and I am not sure whether Patching has been used in this precise context before (but would be somewhat surprised if nothing similar has been reported before), the consistent and effective use of the techniques in the paper serves as a good example for future analysis.\n\n3) Analysis of the identified circuit in terms of faithfulness, completeness, and minimality. I particularly like that the paper aims at making these notions formal and quantitative, and reports quantitative results. For instance, without a check for completeness, the backup heads would likely not have been identified - which is an interesting result, highlighting the potential degrees of (complex) redundancies in neural circuitry. Impact: medium to high - the measures seem sensible, though perhaps not maximally universal, and I think that there is a good chance that they will be picked up by the community.\n\n**Strengths**\n *  Well executed analysis case-study, showing that it is possible to open the \u201cblack box\u201d or neural circuitry\n * Establishing of causal relevance of explanation, as well as quantitative definition and evaluation of faithfulness, completeness, and minimality of explanation\n * Serious attempts at verifying the correctness of the explanation, and \u201cpoking holes\u201d to make sure the results are reliable.\n\n**Weaknesses**\n * The biggest weakness to me is that the results are specific to a particular network (and as the paper suggest do not seem to easily transfer even to GPT-2 medium, a very closely related architecture) and task-instance (which allows for a fairly simple solution strategy as discuss at the beginning of Section 3). There is not much that can be done here - and I actually appreciate focusing on one meticulous analysis rather than analyzing a handful of tasks in a shallow fashion - but the limited generalizability of the results is one weakness of the work - I am more optimistic in terms of generalizing the methodology presented, though not all of it is entirely novel.\n * The second largest weakness to me is that the paper currently does not analyze whether the identified circuit has additional functionality (e.g. is used or even crucial for other tasks). Given the current writing one is inclined to (probably wrongly) infer that the (complete and minimal) sub-circuit found might exclusively serve to solve the particular task presented and that the sub-components also have clear and exclusive functionality (suggested by nomenclature such as \u2018Name Mover heads\u2019). I find it quite plausible that the sub-circuit and individual parts of it serve quite different functionality in different tasks, and are also partly involved in other (maybe even quite unrelated) tasks - e.g. there is no \u2018name moving\u2019 in an arithmetic task even though the same heads might potentially be involved. This exclusivity is not explicitly claimed in the paper, and perhaps not intended by the authors, but it would be great to see this discussed, and perhaps empirically analyzed (see improvements). Essentially, this is a word of caution regarding the recurrence of the well-known \u201cpolysemanticity\u201d problem coined in C. Olah\u2019s earlier work - perhaps the term \u201cpolyfunctionality\u201d is more appropriate for circuits instead of individual neurons.\n\n**Improvements**\n1) Please discuss the possibility that the identified circuit and sub-parts (groups of heads) might be involved in other tasks where they might play a quite different functional role. Ideally (though this might be a stretch for a rebuttal phase) analyze whether knocking out the (minimal) circuit leads to performance losses in other, unrelated tasks. (I do not consider empirical results here necessary for publication).\n\n2) Please discuss limitations of the current work slightly more prominently (the discussion already raises some points, but it would be great to see a strong and critical discussion of the limitations).\n\n3) Please make sure that all details to reproduce the analysis are given in the appendix.\n\n**Minor comments**\n\nA) Though section 4 is fairly well written, it did take me two passes to grasp the quantitative metrics introduced for faithfulness, completeness, and minimality. I am not sure if pseudo-algorithms or graphical intuitions would be more helpful, but readability (or perhaps simply notation) could be improved a bit in Section 4. Not a major issue though.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written, except section 4 which took me a second pass to fully grasp. The quality of the analysis is very high, hypotheses are derived sensibly and verified in multiple ways. As in many analysis case studies, there remains a certain amount of irreducible complexity, but e.g. the beginning of Section 3 is very helpful to set up the right intuitions. To the best of my knowledge the results are completely novel, and while some of the analysis techniques have been used before they have been combined in an exemplary fashion. Given the detailed description I think the analysis should be fairly easily reproducible, but I am not sure if all of the necessary details to do so are currently in the paper - maybe I missed if there is a planned code-release.",
            "summary_of_the_review": "The paper is a strong example of an analysis case study to identify a simple algorithm for solving the indirect object identification task learned by GPT-2. Such case studies are rare, but luckily increasing in number - I personally think it is important to show the community to which degree it is actually possible to understand the internal (mechanistic) function of neural networks. I do not have any major concerns other than expanding the discussion around limitations and specificity of the findings to this particular task (same circuit or parts of it might be involved in other tasks, potentially even with different qualitative functionality). I currently think the work is polished and ready for publication and of interest to a fairly large audience.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_iR9D"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3588/Reviewer_iR9D"
        ]
    }
]