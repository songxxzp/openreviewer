[
    {
        "id": "782hk90GlL5",
        "original": null,
        "number": 1,
        "cdate": 1666494472885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666494472885,
        "tmdate": 1666494472885,
        "tddate": null,
        "forum": "LnQn5-rN-LR",
        "replyto": "LnQn5-rN-LR",
        "invitation": "ICLR.cc/2023/Conference/Paper1584/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposed a multi-scale learnable feature volume encoding for neural implicit surface reconstruction. \nThe main idea of the paper is to train a neural implicit surface function from coarse to fine in 3 stages. In each stage, a learnable volume feature encoding is concatenated to the input of the implicit function. The authors also proposed a volume sparsify procedure to discard the empty voxel for memory efficiency. \nThe proposed strategy can be widely adopted in different coordinate-based neural implicit surface papers.\n\nThe underlying technique of this paper is very simple and easy to understand, yet it significantly improves the surface reconstruction quality of the previous state-of-the-art methods in various public available datasets.",
            "strength_and_weaknesses": "Strength\n\n- The proposed strategy can be widely adopted in different coordinate-based neural implicit surface papers.\n\n- The underlying technique of this paper is very simple and easy to understand, yet it significantly improves the surface reconstruction quality of the previous state-of-the-art methods in various public available datasets.\n\n\n\nWeaknesses\n\nPlease explain more on the claims in the paper : \n- In page 4, Sec 3.3, \"This works well for novel view rendering but has problems in surface reconstruction, because the simple MLP architecture makes learning and optimization inefficient\".\nWhy a simple MLP makes the learning inefficient? Why is it inefficient in geometry learning, but good at RGB learning? \n\n- In page 5, on top: \"This feature volume can naturally encode the knowledge about the 3D space of the object\".\nWhy is a randomly initialized volume encoding can \"naturally\" encode the knowledge about an object? How is this volume encoding looks like when fully trained? More visualization would be helpful here in revealing the use of such encoding.\n\n\nAdditional experiments suggestions:\n\nI am curious to see whether the proposed method can improve the RGB reconstruction or not? It will be good to showcase some novel view synthesis evaluations. And it would be good to explain more on why this encoding can or cannot help RGB reconstruction.\n\nTypos: \nIn page 4, first line, \"with which another implicit\", ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: some of the claims in the paper is not properly addressed of proofed by experiments.\n\nReproducibility: The idea of the paper is clearly state and should be easy for readers to reproduce.",
            "summary_of_the_review": "\nI found the idea of this paper very simple yet very effective.\nThe proposed method can also be easily applied to other works. The paper achieves state-of-the-art performance on surface reconstruction. \nBut some claims in the paper is not properly addressed and nor proofed via experiments. Please see the weakness. \n\nI think the paper at least provides good empirical results on utilizing volume encoding in improving SDF surface reconstruction. On the other hand, it would be good if the authors could also provide more insights on how such encoding assists the geometry reconstruction, and whether such encoding can be applied to broader use (such as novel synthesis).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_ZvSi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_ZvSi"
        ]
    },
    {
        "id": "3ygTS6gyZU6",
        "original": null,
        "number": 2,
        "cdate": 1666638615676,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638615676,
        "tmdate": 1666638615676,
        "tddate": null,
        "forum": "LnQn5-rN-LR",
        "replyto": "LnQn5-rN-LR",
        "invitation": "ICLR.cc/2023/Conference/Paper1584/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper describes a series of experiments in which a hierarchical feature volume is used to encode a latent representation of a scene. The volume defines a continuous feature field through linear interpolation of the features associated with discrete voxel locations. The resultant feature at any point in space can then be passed as input to a neural network or networks to render images of the encoded scene. A variety of rendering methods can make use of this same scene representation, such as NeRF, NeuS, etc. The paper also describes a method of progressively optimizing the feature volumes in a coarse-to-fine order, and a sparsification strategy for the higher-resolution volumes to avoid using too much memory.",
            "strength_and_weaknesses": "The paper identified a valid issue with many neural scene representations, i.e. the inductive bias towards lower-frequency radiance, density, and/or signed distance fields which often results in overly-smooth renderings. The paper also proposes a sensible strategy to mitigate this issue, and show that their technique significantly reduces reconstruction errors when applied to a variety of scene rendering models. The ablation studies provide interesting insights into the value added by the hierarchical volumes and the influence of various hyperparameters.\n\nThe key weakness of the paper is that it lacks technical novelty. However, it is not clear from reading the manuscript this is the case. There are important gaps in the related work cited, and the related work that is cited is given a fairly cursory treatment. Instant Neural Graphics Primitives introduces a very similar approach in which a scene is volumetrically encoded, and it can be used interchangeably with the proposed hierarchical volumes. However, Instant-NGP is only mentioned at the very end of the manuscript. An experiment is performed to compare the performance of Instant-NGP vs. HIVE and the results indicate that HIVE leads to superior performance. However, the experiment is not described in detail and as such it is hard to interpret the results. The manuscript mentions an advantage of HIVE over Instant-NGP, namely that it does not experience hash collisions which can impair performance, but does not mention the corresponding advantage of Instant-NGP over HIVE which is that the memory cost can be kept to O(1) in the scene volume whereas HIVE is O(N) in the scene volume (with some scalar multiplier resulting from sparsification). Was the amount of memory used to represent the scenes balanced between the two approaches for the experiment presented in Table 1? The manuscript also provides no runtime analysis of the proposed approach, so we do not know how it compares to Instant-NGP which is known to enable fast inference of scene representations.\n\nThe manuscript also completely fails to mention a number of highly related works on hierarchical sparse representation of scenes for neural reconstruction, such as Neural Geometric Level of Detail (Takikawa et al. 2021), PlenOctrees (Yu et al. 2021), and ACORN (Martel et al. 2021). NGLoD in particular introduces an extremely similar scene representation. Unfortunately the two approaches are evaluated on different datasets and thus we do not know which performs better or why.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The submitted manuscript is overall of good quality, but lacks clarity on a few specific points. One is the treatment of Instant NGP as described above, which leaves out a lot of detail such that it would be impossible to reproduce the experiment. A few statements that are critical of prior approaches to neural reconstruction are not clear or concrete on what the issues being pinpointed are. For example, in section 3.3 the manuscript states that MLP-based renderings have \u201cproblems in surface reconstruction, because the simple MLP architecture makes learning and optimization inefficient,\u201d but it is not clear what is meant by a \u201csimple\u201d MLP, what is the distinction between \u201clearning\u201d and \u201coptimization,\u201d or what kind of efficiency is lacking. Similarly, in the related work the manuscript states that when using NeRF to represent a scene, \u201cthe surface extracted from the implicit network usually has some defect,\u201d but it is not clear which defects are meant or which surface extraction method is being reference, as NeRF does not represent surfaces and thus does not provide an unambiguous method of surface extraction. ",
            "summary_of_the_review": "The manuscript provides new experiments showing that the addition of a sparse hierarchical volume encoding to a neural scene renderer can improve performance of a variety of existing baseline methods. However, the technical novelty over other previously published sparse hierarchical scene representations is very small, and the manuscript not only fails to make a case for the use of the proposed technique over the highly similar existing approaches.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_wTJb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_wTJb"
        ]
    },
    {
        "id": "SZ9iZixMgI",
        "original": null,
        "number": 3,
        "cdate": 1666689762477,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689762477,
        "tmdate": 1666689762477,
        "tddate": null,
        "forum": "LnQn5-rN-LR",
        "replyto": "LnQn5-rN-LR",
        "invitation": "ICLR.cc/2023/Conference/Paper1584/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents an improved design of spatial encoding for neural surface reconstruction methods, e.g. NeuS and VolSDF. Instead of using frequency positional encoding as in NeRF, the authors propose to explicitly encode the spatial information with multi-scale voxels storing feature vectors. In particular, the encoding consists of dense voxel grids up to the resolution of 256^3, whereas subsequent higher resolutions (512^3 and 1024^3) are derived from sparsified results from the previous levels. Experiments are focused on the DTU benchmark with additional visualizations on BlendedMVS and EPBL, showing improvements over frequency encoding.",
            "strength_and_weaknesses": "Strengths:\n+ This paper presents a simple and effective improvement over frequency encoding used in neural surface reconstruction methods like NeuS and VolSDF. Using explicit (hybrid) representations have recently shown success to accelerate convergence and improve view synthesis results [A,B,C]; this paper applies the same concept to surface reconstruction.\n+ The proposed HIVE adds significant improvement over baseline models (NeuS and VolSDF) in reconstruction quality.\n+ The method description is easy to follow and understand.\n\nWeaknesses:\n- The authors have missed very important references that improves NeRF with explicit (hybrid) encodings, listed as [A,B,C]. In particular, Plenoxels [A] have already proposed explicit encoding with a voxel pruning strategy. In some sense, this paper proposed almost exactly the same concept, but only applied to surface reconstruction. In addition, the authors have ignored a large body of prior works on using octrees to represent 3D scenes with hierarchical voxel grids. A survey can be found in [D].\n- I think it would be good to have discussions on the drawbacks of the proposed HIVE. One limitation I can see is that HIVE is currently limited to the resolution of 1024^3. Although the higher resolutions can be initialized from sparsified voxels (with an additional dilation step), the amortized memory growth will be N^2 (proportional to the surface area) and eventually it will still be memory bounded. So it doesn't seem like HIVE is much more scalable.\n- Another drawback of HIVE is that granular details are not recoverable if certain voxels were pruned at resolution 256^3. So there is a heavy assumption that the coarse shapes should be fully captured at 256^3. This is not a limitation for more na\u00efve frequency encoding from NeRF.\n- The improvement on BlendedMVS scenes seems significant over NeuS and somewhat better than NeuralWarp, but the resolution of the recovered surfaces do not seem to be as high resolution as expected (1024^3?). It would be great if the authors could clarify.\n- The NeuS+hash results seem questionable. From the results of Muller et al., Instant NGP has even more representation capability than the original NeRF, and artifacts shown in Fig 6(c) are not to be expected. It would be good if the authors could clarify; otherwise I would not think this is a fair and faithful comparison.\n- Minor: Fig 6 is hard to understand without sufficient descriptions in the captions. \n- Minor: I don't think equations 7 and 8 are necessary; they are just binary dilation and index lookup operations.\n\n[A] Yu et al. \"Plenoxels: Radiance Fields without Neural Networks.\" CVPR 2022\n[B] Sun et al. \"Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction.\" CVPR 2022\n[C] Chen et al. \"TensoRF: Tensorial Radiance Fields.\" ECCV 2022\n[D] Knoll. \"A survey of octree volume rendering methods.\" 2006",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written and described clearly, and it is easy to follow. The proposed concept is simple so it should be easily reproducible. However, I have doubts on the originality and novelty of this work. It is very similar to Plenoxels but only applied to the application of surface reconstruction. There is also not much additional insights on how the proposed HIVE differ from prior works like Plenoxels.",
            "summary_of_the_review": "I think this is a nice paper that presents surface reconstruction results that have shown observable improvements, but I have major concerns on the novelty of this work. While I understand novelty is not the sole evaluation criterion, I think there are insufficient discussions on (a) how this work differ from the others, (b) deeper insights on the technical parts of the methods, (c) limitations of the proposed method. I am thus leaning towards a reject at this point.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_hdwP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_hdwP"
        ]
    },
    {
        "id": "MENGuPaPs-K",
        "original": null,
        "number": 4,
        "cdate": 1666698479340,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666698479340,
        "tmdate": 1666935153014,
        "tddate": null,
        "forum": "LnQn5-rN-LR",
        "replyto": "LnQn5-rN-LR",
        "invitation": "ICLR.cc/2023/Conference/Paper1584/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The work tackles on reconstructing the implicit surface from images. The main contribution of the work is to propose a hierarchical volume encoding for neural implicit surface reconstruction, which can be easily be plug-and-played on top of other existing works. Although the hierarchical volume encoding scheme has been widely used in computer vision community, experiments on widely used datasets, such as DTU, BlendedMVS show that the work clearly enhances other methods.",
            "strength_and_weaknesses": "**Strength**\n\n- Performance\n\nThe work shows impressive performance both quantitatively and qualitatively. I was impressed by figure1 & 5 reconstructing high frequency details from images.\n\n- Simple and efficient scheme\n\nUsing hierarchical features for implicit reconstruction makes sense and is straightforward. I also enjoyed a simple idea of obtaining sparse high resolution volume by using multi-stage optimization and dilating the low resolution reconstructed implicit function. \n\n\n**Weakness** \n\n- Using hierachical feature volume encoding has been used in the field of computer vision for a long time with various tasks, including surface reconstuction, such as [1]. \n\nThis idea is not brand new, however, I did enjoy the performance increase with respect to the simplicity of the method.\n\n\n- The work can be strengthened by adding more experiments for NeuralWarp + HIVE. \n\nThe authors have reported all scores for both Neus and NeuralWarp with and without HIVE for table 1 & 2. I think adding restuls for NeuralWarp + HIVE in Figure 6 and ablation study can further strengthen the paper, because this paper shows enhancement of the results based on previous works. Because this work is an add on to other methods, I believe these results are necessary to show the performance increase. \n\n- The work can be strengthened by adding more quantitative metric than Chamfer distance. \n\nTable 1, 2 shows the Chamfer distance compared to other methods. While the Chamfer is a good metric to compare the similarity of to points clouds, there has been many questions [2] whether the Chamfer distance could capture the high frequency details or overall ditributional similarity between two point clouds. I would suggest adding normal consistency as in [3] or some other metrics that show that the method can capture the high frequency surfaces.\n\n[1] Chibane et al. Implicit functions in feature space for 3d shape reconstruction and completion. CVPR, 2020.\n\n[2] Wu et al. Density-aware Chamfer Distance as a Comprehensive Metric for Point Cloud Completion. NeurIPS, 2021\n\n[3] Mescheder et al. Occupancy Networks: Learning 3D Reconstruction in Function Space. CVPR 2019\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity & Quality\n\nThe manuscript is overall easy to understand with nice figures. Although some parts of manuscript, such as the third contribution in page 2 should be modified to more concrete and specific sentence. Also, one could add captions on Table 1 & 2 explicitly stating the table is about Chamfer distance. \n\n- Novelty\n\nAs stated in the weakness section, although using hierarchical feature volume encoding is not new, I enjoy the simplicity.\n\n- Reproducibility \n\nThe authors promised to release the code.  \n",
            "summary_of_the_review": "Although the proposed hierarchical volume encoding itself is not novel in the field of surface reconstruction, I believe that the pros of having better performance while being simple is very practical and will be beneficial to community if the additional figures and experiments are done as stated in the weakness section. I would like to hear what other reviewers before making the final decision. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_frLo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1584/Reviewer_frLo"
        ]
    }
]