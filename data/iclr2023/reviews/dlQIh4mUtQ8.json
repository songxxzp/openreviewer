[
    {
        "id": "7XSvr_lw6mM",
        "original": null,
        "number": 1,
        "cdate": 1666550854471,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666550854471,
        "tmdate": 1668629168110,
        "tddate": null,
        "forum": "dlQIh4mUtQ8",
        "replyto": "dlQIh4mUtQ8",
        "invitation": "ICLR.cc/2023/Conference/Paper2768/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper prooses the novel concept of populated region set, and make connection between the proposed PRS ratio and the adversarial robustness of the model. The paper further propose PRS regualrization that can improve adversarial robustness without adversarial training.",
            "strength_and_weaknesses": "## Strength\n1. This paper provides novel concept on PRS and PRS ratio, and make connection between the proposed concept and adversarial robustness\n2. Thorough experiments are conducted to emperically support the claim on the relationship between PRS and robustness\n3. The proposed regualrization indicates the potential benefit PRS can bring to understanding and preventing adversarial attack\n\n## Weakness\nSome technical details of the proposed method are not clearly explained. For example:\n1. How exactly is PRS computed given a DNN model? Is the computation method scalable to a larger/deeper model or a larger dataset?\n2. How is the gradient of the Hamming distance regularization is Eq.(2) computed in the optimization?\n3. As the model is being updated with the proposed regularization, will MRV change in the process? Does MRV need to be recomputed during the training process, and if so what would be the cost of the computation?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper provides novel method and is written in good quality. Some technical details are not clearly explained.",
            "summary_of_the_review": "Generally the paper provides novel and interesting insight on understanding the adversarial robustness of DNN models. However the lack of technical details make it hard to assess the correctness and practicalness of the proposed method, Thus I would recommend a weak rejection for now.\n\n## Post rebuttal\nI believe the response from the author clearifies my doubts. Given the author response and revision I'm increasing my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_o1vx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_o1vx"
        ]
    },
    {
        "id": "yfDv27ABL5Q",
        "original": null,
        "number": 2,
        "cdate": 1666554265111,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666554265111,
        "tmdate": 1666554265111,
        "tddate": null,
        "forum": "dlQIh4mUtQ8",
        "replyto": "dlQIh4mUtQ8",
        "invitation": "ICLR.cc/2023/Conference/Paper2768/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper looks at he notion of _Populated Region Set (PRS)_ which are decision regions with at least one training example in them. The central message of the paper is that networks with lower number of PRS have better robustness.",
            "strength_and_weaknesses": "## Strength\n\n* The concept of PRS is interesting and well motivated.\n* The design of the regulariser is also well motivated. \n* The figures and illustrations are easy to understand and the mathematical formalisations are minimal and kept to the point. Overall, the authors have tried to present a coherent story.\n\n## Weaknesses\n* The message of the paper is not borne by the experimental results. In particular, AA robust accuracy is always zero.\n* It seems that certain networks have not been evaluated under AA and all AA results are relegated to the appendix.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n* The illustration and structure of the paper aid the clarity of the paper.\n* Section 1 contains terms that are not yet defined like PRS ratio, PRS inclusion ratio of test examples etc.\n* However, the writing could be improved. It is not a major drawback but probably something to look at for future versions.\n\n## Quality and Novelty\n*  The authors have made a clear hypothesis and tried to validate with experiments. I find the way the flowchart of the paper quite good. The problem is whether the experiments bear the results and it does not.\n\n## Reproducibility\n* I do not have any major concerns.",
            "summary_of_the_review": "The main drawbacks of the paper  are the following\n\n* The first red flag should have been that for $\\epsilon=0.1$, a CNN network trained via standard training has 80% robust accuracy in Figure 3. This is the main result the authors use to justify that low PRS ratio increases robustness. However, a quick look at Appendix F shows that both Model A and Model B have less than 1% robust accuracy. This shows that it is not that low PRS ratio models are more robust just that, it is harder to find adversarial examples possibly due to ill-conditioning.\n\n*Again Figure 6 shows a similar kind of behaviour as Figure and does not include measurements with AutoAttack.\n\n*Finally table 2 also doesn't contain AA. In fact, even the PGD attack is fairly weak containing only 20 steps. This can also call into question the PRS regularisers are indeed more robust than ST and whether PRS regulariser+AT is more robust than AT.\n\nI did find Appendix G quite interesting, as it does suggest a connection between PRS ratio and robustness but this is the only experiment that is not confounded by the possibility of weak attack.\n\nGiven the above, I am inclined to support rejection unless the authors convince me otherwise.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_wNGM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_wNGM"
        ]
    },
    {
        "id": "7V9Se1CTUb",
        "original": null,
        "number": 3,
        "cdate": 1666635147832,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666635147832,
        "tmdate": 1666635198000,
        "tddate": null,
        "forum": "dlQIh4mUtQ8",
        "replyto": "dlQIh4mUtQ8",
        "invitation": "ICLR.cc/2023/Conference/Paper2768/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors introduced the concept of Populated Region Set (PRS) to characterize the complexity of DNNs and build the correction between low PRS ratio and high robustness of models via several experiments.",
            "strength_and_weaknesses": "Strength: 1. The concept of the Populated Region Set (PRS) is novel and interesting.\n2. The experiments are convincing.  \n\nWeaknesses: 1. Lack of theoretical analysis to verify the claims.\n2. Some definitions are confusing. For example, in Definition 2 (Decision Region (DR)), if the i-th layer has \\textbf{only one neuron}, what are $D_\\ell$ and $|DR_{V_\\ell}|$? From the definition, it seems that $D_\\ell =1$ and $|DR_{V_\\ell}|=2$ in this case, but this seems strange. Please give one small example for each definition to make things clear. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This overall paper is clearly written and well organized. I find it easy to follow. However, some definitions are confusing. \nQuality: This paper is technically sound.\nNovelty: The novelty of this paper is high.",
            "summary_of_the_review": "In summary, the novelty of this paper is high, and the concept of the Populated Region Set (PRS) is novel and interesting. However, my main concern is that doesn't provide theoretical analysis, which makes the contribution limited. Also, some definitions are confusing at this point. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_mBon"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_mBon"
        ]
    },
    {
        "id": "8zogEhhf6j6",
        "original": null,
        "number": 4,
        "cdate": 1666838996766,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666838996766,
        "tmdate": 1670795062060,
        "tddate": null,
        "forum": "dlQIh4mUtQ8",
        "replyto": "dlQIh4mUtQ8",
        "invitation": "ICLR.cc/2023/Conference/Paper2768/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper first studies the relationship of the decision regions induced by the penultimate layer of a deep net to adversarial robustness and then relies on empirical findings to propose strengthening adversarial robustness without adversarial training. ",
            "strength_and_weaknesses": "Strength\n- Some empirical findings are quite interesting.\n- If a model can really defend without adversarial training, it is really great. However, it seems not the case for Cifar100 as in the supplementary material.\n\nWeaknesses\n- The concept of decision boundary and decision region as defined in the paper is confusing and misleading.  Because the decision region is normally relevant one class and represents the date examples classified to this class by a deep net, while the decision boundary represent the boundaries of the decision regions. I believe it should be better if the authors use the terminology like activation patterns. \n- Some behavior experiments lack of details and descriptions, hence hard to follow. For example, cosine similarity matrix of the final layer on Network A/B: cosine similarity of what and what (e.g., representations or weights). Also, Figure 5a is hard to interpret. \n- Mathematical notions used is not solid. For example, the one to define $PRS(X, f, l)$: why do we need $\\forall V_l \\in \\{-1, 1\\}^D$; the one to define $MR_{l,c}$: if $DR \\in PRS(X_c, f, l)$ then $DR \\in X_c$, hence $DR \\cap X_c = DR$.\n- It is great if $L_{ham}$ and $L_{MVR}$ can help to defense for all datasets. But it seems that for Cifar100, it still needs adversarial training. ",
            "clarity,_quality,_novelty_and_reproducibility": "The empirical findings of this paper are pretty interesting to understand more about adversarial examples and robustness. Based on  the empirical findings, the paper proposes a method without adversarial training and adversarial examples to improve the robustness. Unfortunately, this seems not be able to generalize for all datasets. Additionally, the terminologies and mathematical notions used in this paper need to be revised for avoiding misleading.",
            "summary_of_the_review": "The empirical findings of this paper are pretty interesting. However, the proposed approach seems not able to generalize to all datasets because for Cifar100, it still needs adversarial training.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There is no ethics concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_x9iE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2768/Reviewer_x9iE"
        ]
    }
]