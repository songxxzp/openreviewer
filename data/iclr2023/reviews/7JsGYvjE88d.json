[
    {
        "id": "qUy5eJMbfO",
        "original": null,
        "number": 1,
        "cdate": 1666362949313,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666362949313,
        "tmdate": 1666362949313,
        "tddate": null,
        "forum": "7JsGYvjE88d",
        "replyto": "7JsGYvjE88d",
        "invitation": "ICLR.cc/2023/Conference/Paper2716/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents Adaptive Subgoal Search (AdaSubS), an approach to learning-driven search that uses proposed subgoals and a novel \"verifier\" network to make more direct and rapid progress towards the target state. The approach builds upon recent progress in this space, notably the BF-kSubS, by proposing subgoals thought to be reachable a distance \"k\" from the current state towards the goal (for multiple values of k). Combining this multi-distance subgoal generation with a verifier network to prune subgoal not expected to be easily reachable, the approach makes faster progress towards the goal and is more successful at solving state-space search problems than competitive baselines. The authors study a Sokoban and Rubik's Cube domain and \"INT\" a theorem proving domain.",
            "strength_and_weaknesses": "High-level comments\n- [strong] The paper improves upon the state of the art. Search finds the goal in problem challenging problem instances including longer INT problems than are feasible for other approaches in this space. The results are solid and the analysis is comprehensive. This is a central strength of the paper.\n- [strong] The choice of experiments is good and appropriate for the work.\n- [weak] There is no discussion of optimal paths and the quality of the generated paths between the different approaches. For the INT domain, this is perhaps not possible, but for the other two domains, it would be very helpful to understand if the proposed approach improves success at the expense of plan quality, and the extent to which this tradeoff is made. While I do not believe inclusion of this discussion is essential, the paper would be improved by the inclusion of such a discussion.\n- [weak] Sec. 4.5 (analyzing the quality of individual components) seems to omit a key piece of analysis: how well AdaSubS will perform without the verifier or how well the kSubS baseline will perform with the addition of the verifier. The central distinctions between the two strategies are (1) one versus multiple subgoal generators and (2) the inclusion of the verifier network. I do not believe there are any experiments that seek to understand how impactful the verifier. It could therefore be the case that the low level policy network is not particularly capable and that all of the performance improvement comes from the addition of the verifier, which bypasses that process. Some discussion or additional experiments (or a pointer to where these experiments exist) would be incredibly helpful for understanding.\n\nSmaller comments, questions, and typos:\n- Abstract: Though the abstract makes sense after having read the paper, the first couple sentences are not particularly clear on their own. Consider revising those to provide a clearer picture of what the central, unique insight is.\n- Sec. 1: The figure in the introduction, while informative, is perhaps somewhat misleading, since robot motion is not studied in this work. Perhaps it would be more appropriate to use the Sokoban domain instead.\n- Sec. 2: Typo (I believe) \"variable environment variable complexity\".\n- In Sec. 3, the discussion of the thresholds could be clearer; it was not clear to me until later on that there were two thresholds.\n- Algorithm 1: The 'return' statement may not find a path, in which (I believe) the procedure is to keep looping through paths if a feasible path is not found.\n- Algorithm 1: Also, the first 'for' loop that pushes elements into T appears erroneous. There are not yet multiple values of 'k', since the subgoal network has not been queried; should this simply use k=0 and push the starting state into T?\n",
            "clarity,_quality,_novelty_and_reproducibility": "- [Clarity & Quality] the paper is very well written. There are a few gramatical issues (some mentioned below), but otherwise the paper is very easy to follow. The overall approach is well-motivated and clear. Moreover, the appendices are rich with detail and will be no doubt helpful for those who which to implement the approach for themselves.\n- [Novelty] The paper grows the state of the art . The approach is novel, though the amount of novelty is not particularly significant.\n- [Reproducibility] The authors have included all source code and documentation. The paper appears to be fully reproducible.",
            "summary_of_the_review": "This is a solid paper with a somewhat small theoretical contribution bolstered by impressive results in a challenging domain and clear and comprehensive analysis. There are still a few open questions that I believe the paper should address pertaining to the importance of a few of the components and comparison to baselines.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_1BT4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_1BT4"
        ]
    },
    {
        "id": "wZfCTgytRe",
        "original": null,
        "number": 2,
        "cdate": 1666668777791,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668777791,
        "tmdate": 1669072565596,
        "tddate": null,
        "forum": "7JsGYvjE88d",
        "replyto": "7JsGYvjE88d",
        "invitation": "ICLR.cc/2023/Conference/Paper2716/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors proposed an algorithm for planning that uses learned components for generating subgoals (states up to k steps away), generating one low-level action between two states (conditional low-level policy, CLLP), verifying whether CLLP can find an action between two states, and predicting the distance between current state and goal state. The novelty from previous work (kSubS) is that multiple subgoal generators are used to adapt the planning horizon based on states. The modules are trained on offline datasets of puzzles with a large state space. Experiment results show that their algorithm is able to solve the problem of visiting fewer states. ",
            "strength_and_weaknesses": "The idea of learned subgoal generators with adaptive planning horizons is novel. The authors performed large-scale experiments on hard planning problems, comparing their methods both with baselines and also on out-of-distribution problems. That's very good efforts.\n\nBefore authors' rebuttal, the paper lacks important details in the main text for understanding. Though the authors stated the size of their training dataset. It's unclear how many problems were used for the results from Figure 2 and Figure 3. It would be helpful to state that in section 4.1 to make the results more convincing. It's also unclear whether the total wall time in Table 2-4 in the Appendix is from solving one problem or multiple problems, and how they compare to BestFS baseline. Without context, 3-26 hours seems too long for the title of the paper to be called \"fast and precise.\" ",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is sometimes too concise, leaving many implementation and experiment details in the appendix. The method and experiment design are novel. It's great that the authors have provided links to their codebase, which enables researchers to validate their approach and build upon their work.",
            "summary_of_the_review": "Overall it's an exciting paper, tackling hard planning problems with a novel learning-based algorithm. With more details provided about their evaluation, it would make a very strong submission.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_1Tzk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_1Tzk"
        ]
    },
    {
        "id": "kw0WeUmb3q",
        "original": null,
        "number": 3,
        "cdate": 1666743879643,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666743879643,
        "tmdate": 1669682611503,
        "tddate": null,
        "forum": "7JsGYvjE88d",
        "replyto": "7JsGYvjE88d",
        "invitation": "ICLR.cc/2023/Conference/Paper2716/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a new algorithm Adaptive Subgoal Search (AdaSubS), which aims to generate the prospective sub-goals iteratively to generate a good action plan. The system has innovative components of a subgoal generator, Conditional low-level policy (CLLP) to find action steps and a verification algorithm to swiftly prune the faulty sub-goals obtained.\n\nThe authors present comprehensive results to show that adaptive methods work.\n",
            "strength_and_weaknesses": "Strengths:\n\u25cf The paper is well-structured and easy to read.\n\u25cf Introduction of novel search algorithm benefiting from both the planning and\nlearning methods.\n\u25cf The experimental section is very well organized and provides good insights into\nthe complexity of the domains considered.\n\u25cf State-of-the-art results on inequality theorem prover INT.\n\nWeakness:\n- Although the paper shows advancement in learning-based planning, the results are not surprising given that there is a large body of work in search-based planning to show that adaptive action selection / heuristic selection is beneficial in planning. See work like \"Real-Time Adaptive A*\" or historical perspective in a planning book like Ghallab et al. See also recent dissertation titled \"Adaptive Search Techniques in AI Planning and Heuristic Search\" by Maximilian Fickert. \n- A problem with this like of work is that the algos are not complete. They are not guaranteed to  always produce a plan even if such a plan exists. This point should be highlighted. \n* A system architecture diagram depicting the flow of the algorithm would have\nbeen more comprehensible. It is hard to understand if all the chosen sub-goals\nat a given node are being explored.\n\u25cf It is mentioned that the verifier network is a binary classification model, and\nif the network fails to predict the feasibility of the sub-goal, the algorithm\nfalls back on to CLLP to decide whether to keep or discard a given subgoal. But\nit is not clear how CLLP is used for this purpose as it generates an action\nplan between two given states. Does an empty sequence from CLLP mean the\nsub-goal is being rejected?\n\u25cf The authors commented on the out-of-distribution generalizability of the\ninequality theorem prover INT, however, it could have been interesting to see\nthe status of the other domains.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is well-written and clear. The experimental settings are well explored and\nthe comparative analysis of the different algorithms gives a better understanding of\nthe performance on the complex domains. The two main blocks of the algorithm (the\nsub-goal generator and the verifier network) are inspired by the existing works which\nare clearly mentioned in the related work section.\n",
            "summary_of_the_review": "The paper introduces a new algorithm called Adaptive Subgoal Search (AdaSubS). It covers related work and provides extensive experimental results provided which give an overall insight into the performance of the algorithm on the different problems chosen. However, the paper needs to add details justifying the need for multiple blocks for sub-goal verification and contextualize the properties of the planner. The entire flow of the algorithm needs to be summarized in a flow chart format. The memory and time usage details of the algorithm needs to be mentioned.\n\nThe paper should also connect with well known results in search-based planning on adaptive action selection and heuristic selection. Otherwise, it is re-discovering known behaviors in a new setting.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_EUhR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_EUhR"
        ]
    },
    {
        "id": "QsAV8oSPRy7",
        "original": null,
        "number": 4,
        "cdate": 1667544008538,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667544008538,
        "tmdate": 1667544008538,
        "tddate": null,
        "forum": "7JsGYvjE88d",
        "replyto": "7JsGYvjE88d",
        "invitation": "ICLR.cc/2023/Conference/Paper2716/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents an algorithm \u2013AdaSubS\u2013 that can be trained and configured to solve deterministic search problems. The key idea is to consider multiple lookaheads that would be explored with lower-level policy. The ablation study confirms the effectiveness of the idea in challenging domains.\n",
            "strength_and_weaknesses": "# Strengths\n\nI'll be short here. See discussion below on my interpretation of the results.\n\n- The paper is mostly well-organized and well written\n- The ablation study confirms the role of the specific modules. \n\t- I appreciated the detailed algorithms in the appendix\n- The conclusions are very clear, at least for the domains and conditions where it was tested.\n\n# Weaknesses\n\n- Scholarship: I think that Czechowski et al. (2021) should be mentioned as a starting point. The manuscript seems timid about it. I think a stronger paper would make that clear. Here is two key quotes:\n\t- > \"kSubS is the first general learned hierarchical planning algorithm shown to work on complex reasoning domains Czechowski et al. (2021) (called BF-kSubS there), attaining strong results on Sokoban and Rubik\u2019s Cube, and INT. kSubS can be **viewED** as a non-adaptive version of AdaSubS realized by a suitable hyperparameters choice: a single subgoal generator and inactive verifier (t lo = 0,t hi = 1).\"\n\t- > \"Most of the hyperparameters, both for training and evaluation, follow from Czechowski et al. (2021). The most important parameter of AdaSubS is the set of k-generators to use and the number of subgoals each of them generate.\n\t- Czechowski et al. (2021) introduced the idea of a search to achieve the goal in k steps. The paper has multiple references on how they used the same parameter.\n- Scholarship: the paper does not review the state of the art on this problem. If the state of the art is not in the same scope, then related work should be discussed anyway.\n\t- For instance, see Cameron et al, IJCAI 2021, below.\n- BestFS is not explained well enough\n\t- (See before my comment on contrib 2 below)\n\t- Given this is the most important baseline, the paper must make sure that the algorithms was properly tuned.\n\t- It seems it's a simple modification respect to the others, but perhaps there are hyperparameters that would work better for BestFS in comparison with AdaSubS\n- No limitations are discussed (see my first question below as an instance)\n\n# Questions: PLEASE ANSWER THESE ONES\n\n- Does the algorithm keep a list of close nodes?\n\t- Do you cache the result of evaluations in Alg 1 or Alg 2?\n\t- It seems Alg 2 migh run predictions multiple times on the same nodes.\n\t- If a node is visited with k = 8, would it also be visited by GET_PATH with k = 2?\n- How would AdaSubS behave in the following case?\n\t- Suppose a degenerated search space where \n\t\t- There are two action applicable actions in each state, but at least one of them always leads to a dead end.\n\t\t- Suppose further that there is actually only one path to the goal.\n\t\t- For a state in the path to the goal, there are two childs: one to the next state in the plan, the other one child that leads to a dead end by a short binary subtree, all of the deadends.\n\t- Suppose the same list of k used in Sokoban: [8, 4, 2]\n\t- Suppose that all the models are not very good. They choose uniformly over their options. Let's disable the verifier.\n\t- It seems that AdaSubS would expand multiple times the nodes in the subtrees that lead to deadends? Moreover, Alg 2, GET_PATH doesn't seem to have any memory. So, if the models are expensive this could grow quickly.\n\t- (If this example doesn't work, please attempt to provide another example where AdaSubS might deteriorate)\n- Would you comment on the following paper published in IJCAI 2021?\n\t- Efficient Black-Box Planning Using Macro-Actions with Focused Effects. Cameron Allen, Michael Katz, Tim Klinger, George Konidaris, Matthew Riemer, Gerald Tesauro. https://arxiv.org/abs/2004.13242\n\t- Macro-actions are sequences of low-level actions. They create them by attempting to change a few variables in the problem.\n\t- They test in Rubik's cube.\n\t- They tested reusing macros in the same domain.\n- Why does the evaluation support the 2nd main contribution?\n\t- End of sect 1 says: \"We present a comprehensive study of adaptive methods, showing that they typically outperform non-adaptive ones\". But given the lack of comments about other potential algorithms, this might not be true in general. \n\t- I'd accept something like \"they outperform similar algorithms without the adaptation\". It seems that the argument is that given that BestFS and the studied algorithms share common elements, then the value of the contributions is justified.\n- How were the hyperparameters set? \n\t- I see the values in appendix F, but I don't see how they were set. Page 19:\n\t\t- > Based on experimental results, we have chosen generators of 8, 4, and 2 steps for Sokoban, 4, 3, and 2 steps for the Rubik\u2019s Cube, and 4, 3, 2, and 1 step for INT. In the first two domains, the longest generator match the one used for kSubS.\n\t- Explaining that would help readers to understand the effort of using the algorithms in another setting.\n\t- Please clarify the computation cost of arriving at these hyperparameter values? For instance, how expensive is to realize that a set of hyperparameter values are not the most adequate?\n- Are the hyper-parameters of BestFS set in the best possible way?\n- Would you mention the multi-queue algorithms in a revised version of the paper? Where? (See that in my section \"Scholarship on search and planning\")\n\n# Other changes\n\n- Please mention the number of subgoals generators and the values of k early in the paper. \n\t- Table 1 shows that the list k is one of the most important factors for performance.\n\t- The number of goals generated changes fundamentally the search space. \n- In the main body, it should say that BestFS with a trained policy, and how it's implemented. (See my comment on contribution 2)\n\n# Minor questions or comments\n\n- Page 5: > Rubik\u2019s Cube is a celebrated 3D puzzle with over 4.3 \u00d7 10 18possible configurations.\n\t- Please cite Korf's paper\n- Page 9. Verifier: precision and recall\n\t- I\u2019d say the verifier increase accuracy only in a small budget in INT.\n- Page 6: \"Shaded areas indicate 95% confidence intervals.\" How many trials?\n- Page 15, Sect \"Computational budget analysis\" \n\t- says: Tables 3, 2 and 4 present the number of calls to each component per 1000 episodes.\n\t- Is this testing or during training?\n\t- Are those 1000 instances the same for all the algorithms?\n\t- Is that the total number for 1000 episodes? The common practice in deterministic search is to report numbers per episode.\n- page 17:\n\t- > Rubik\u2019s Cube. To construct a single successful trajectory we performed 20 random permutations on an initially solved Rubik\u2019s Cube and took the reverse of this sequence. Using this procedure we collected 10 7trajectories\"\n\t- are there symmetric movements? Are these optimals path? See comment by Clemens et al.\n- Page 18: \n\t- > \"\u03c1 BFSworks in the following way. First, it uses a trained policy network to generate actions to investigate. Specifically, for INT we use beam search to generate high probability actions (it is necessary as for INT we represent actions as sequences, following Czechowski et al. (2021)). Then, it uses these actions to get a state that follows a given action (note that all our environments are deterministic). Finally, we treat returned states as our new subgoals, which are easily found in one step by the low-level policy.\"\n\t - It's not clear what happens in other domains. \n- page 15: please say this in the main body, not just in the appendix:\n\t- > used for sampling predictions from the subgoal generators \u2013 the only component that outputs a set of predictions.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is novel and insightful. The significance can be lower if the algorithm were harder to configure. The interaction of the attempted lookahead with the subgoal generation is interesting. The paper is clear enough, except for what I commented above.\n\nNow I discuss at length some connections with related literature.\n(This aspect is a weak point of the manuscript)\n\n# Scholarship on search and planning\n\nThis is, I think, the 2nd time I see this paper submitted. I'm glad about the changes. I finally have an interpretation of what's going on. The unpacking of the algorithms in the appendix really helps. In general, I'm not very interested in the verifier. The interesting part is the depth.\n\nLet me first discuss multi-queue in comparison with search algorithms used for planning.\n\nFirst, PDDL-based planners are not comparable with the algorithms proposed here because of two reasons:\n- They don't have the chance to train. Instead, they recieve the problem in PDDL, a high-level language for planning. For the planner, it's the first time they see that problem. Rubik's cube and Sokoban could be expressed there.\n- Hyper-parameter tuning is only about the search and heuristics. Moreover, the evaluation tends to focus on finding the parameters that would solve multiple domains. PDDL-based planners intend to be autonomous tools, not human tuning involved.\n- So, PDDL-based planners offer a lower bound on performance.\n\t- I don't think it's necessary to review those numbers here, but I'd expect so in a journal version of the paper.  \n\nSecond, work on heuristic search \u2013like Korf cited in the paper\u2013 it's the opposite of domain-independent. The heuristics are heavily adapted to the domain. So, they are not comparable but they offer an upper bound for learning-based algorithms. \n\nNow, IterativeMixing is similar to alternation queues used in heuristics search algorithms used for PDDL-based planners. \n\nThat was first proposed by LAMA.\n- Richter, Silvia, and Matthias Westphal. \u201cThe LAMA Planner: Guiding Cost-Based Anytime Planning with Landmarks.\u201d Journal of Artificial Intelligence Research 39 (September 21, 2010): 127\u201377. https://doi.org/10.1613/jair.2972.\n\nNowadays, LAMA is usually tested as a configuration of the very flexible Fast Downward.\n- Helmert, M. \u201cThe Fast Downward Planning System.\u201d Journal of Artificial Intelligence Research 26 (July 12, 2006): 191\u2013246. https://doi.org/10.1613/jair.1705. Sect 6.4 Multi-Heuristic Best-First Search\n\t- > \"As an alternative to greedy best-\ufb01rst search, Fast Downward supports an extended algorithm called multi-heuristic best-\ufb01rst search. This algorithm differs from greedy best-\ufb01rst search in its use of **multiple heuristic** estimators, based on our observation that different heuristic estimators have different weaknesses. It may be the case that a given heuristic is suf\ufb01cient for directing the search towards the goal except for one part of the plan, where it gets stuck on a plateau. Another heuristic might have similar characteristics, but get stuck in another part of the search space.\n\t- > \"Various ways of combining heuristics have been proposed in the literature, typically adding together or taking the maximum of the individual heuristic estimates. We believe that it is often bene\ufb01cial not to combine the different heuristic estimates into a single numerical value. **Instead, we propose maintaining a separate open list for each heuristic estimator, which is sorted according to the respective heuristic. The search algorithm alternates between expanding a state from each open list**. Whenever a state is expanded, estimates are calculated according to each heuristic, and the successors are put into each open list.\n\nFast downward is very flexible:\n- https://www.fast-downward.org/PlannerUsage\n- https://www.fast-downward.org/Doc/SearchEngine\n\nOther search engines for planning also incorporate multiple queues.\n- https://lapkt-dev.github.io/docs/modules/\n\nActually, LAPKT has priorities over queues:\n- https://github.com/LAPKT-dev/LAPKT-public/blob/d54b68fcc67d5d75ea40b3921220c29f49c71814/include/aptk/at_bfs_dq_mh.hxx#L353\n\nSome planner \"preferred operators\", choose first a queue that tends to have fewer notes. If that's empty, they use the other one.\n\n**That's similar to what AdaSubS is doing, as it always tries to expand over more steps first.** \n\nOthers algorithms can also be seen from this perspective.\nStrongest-first  behaves more like selecting from the queue, breaking by k. (Can actual V values be the same for two different nodes?)\nLongest-reachable becahse more hierarchical, like options.\n\n## Some references on Sokoban and Rubik's cube\n\n- Sokoban: https://github.com/AI-Planning/pddl-generators/tree/master/sokoban\n- npuzzle, simpler to understand: https://github.com/AI-Planning/pddl-generators/tree/master/npuzzle\n\t- Rubik is a variation of that one. It's a challenging problem for planning\n- A Comparison of Abstraction Heuristics for Rubik's Cube. Clemens B\u00fcchner, Patrick Ferber, Jendrik Seipp, Malte Helmert. https://icaps22.icaps-conference.org/workshops/HSDIP/\n\t- Uses pattern DBs, like use by Korf, but as planning\n\t- > None of the heuristics is able to solve problems where the optimal solution requires more than 13 rotations. Ac- cording to Rokicki et al. (2014), this restriction allows us to solve only 0.0001% out of the 4.3 \u00b7 1019 possible states of Rubik\u2019s Cube. In comparison, Korf (1997) was able to optimally solve tasks at least 18 rotations away from the goal.1 The set of initial states with optimal cost 18 or less makes up approximately 98% of all possible initial states for Rubik\u2019s Cube (Rokicki et al. 2014).\n- B\u00fcchner, Clemens. \u201cAbstraction Heuristics for Rubik\u2019s Cube,\u201d n.d., 44.\n\t- See here is a demo on the 3x3x3 (seems to be an undergrad project)\n\t\t- Muppasani, B., Pallagani, V., Lakkaraju, K., Srivastava, B., & Agostinelli, F. (2022). Solving the Rubik\u2019s Cube with a PDDL Planner.\n\t\t- https://www.researchgate.net/profile/Bharath-Muppasani/publication/362555735_Solving_the_Rubik's_Cube_with_a_PDDL_Planner/links/62f13f8388b83e7320bb63c0/Solving-the-Rubiks-Cube-with-a-PDDL-Planner.pdf\n\t- Rubik's 2x2x2: https://wu-kan.cn/2019/11/21/Planning-and-Uncertainty/\n\nI suggest the authors participate in the Planning and Learning competition that was just announced. https://ipc2023-learning.github.io",
            "summary_of_the_review": "The ideas are novel, the components of the algorithm are well-studied to understand their role, and the benchmarks are appropriate.\n\nI recommend acceptance, but I might lower my scores depending on the answer to my questions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_Kkdv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2716/Reviewer_Kkdv"
        ]
    }
]