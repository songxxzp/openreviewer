[
    {
        "id": "FwnEY1_eB6",
        "original": null,
        "number": 1,
        "cdate": 1666451004815,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666451004815,
        "tmdate": 1666451004815,
        "tddate": null,
        "forum": "BSUoWl5yfv",
        "replyto": "BSUoWl5yfv",
        "invitation": "ICLR.cc/2023/Conference/Paper275/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the incompatibility of two very commonly found components of deep learning, namely the ReLU and Batch Normalization. This incompatibility is manifested e.g., in exploding gradients during the early part of training. The authors hypothesize that the source of the incompatibility is the fact that the variance of the activations and their gradients is affected differently by the combination of ReLU and Batch Normalization. The authors show this analytically, then explore it experimentally. Finally, they propose a solution to alleviate the problem.\n",
            "strength_and_weaknesses": "Strengths (S):\n\n----------------\n\nS: The studied problem of exploding gradients problem is a very important one in deep learning, expecially since it happens with the most typical combination of normalization and activation functions, namely ReLU and BN. \n\nS: The paper proposes a simple extension (LALC) to LARS optimizer that seems to fix at least partially the exploding gradients problem by clipping the learning rate. \n\nS: If LALC is shown to be better than LAMB and the key reference comment (see below) is correct, the paper could be revised to focus on LALC.\n\nWeaknesses (W):\n\n----------------\n\nW: The main weakness of the paper seems to be missing key references. Could the authors discuss how the analytical part of the work is different from this paper Yang, Greg, et al. \"A mean field theory of batch normalization.\" arXiv preprint arXiv:1902.08129 (2019). https://arxiv.org/abs/1902.08129 and this posting: https://kyleluther.github.io/2020/02/18/batchnorm-exploding-gradients.html. \n\nW: Regarding the clipping method (LALC), the paper seems to fail to cite Fong, Jeffrey, Siwei Chen, and Kaiqi Chen. \"Improving Layer-wise Adaptive Rate Methods using Trust Ratio Clipping.\" arXiv preprint arXiv:2011.13584 (2020). https://arxiv.org/abs/2011.13584 , which also contains clipping. Please compare both analytically and experimentally to this method.\n\nW: The experimental part should contain trainings with LAMB, since in many cases it improves over LARS without expensive tuning of LAMB hyperparams.\n\nW: The results with LALC could be compared with the 3 proposed solutions in https://arxiv.org/abs/1902.08129\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Reproducibility, writing clarity and quality is good. There are some questions on novelty (see above).\n",
            "summary_of_the_review": "Decent work but key references missing.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper275/Reviewer_NA9i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper275/Reviewer_NA9i"
        ]
    },
    {
        "id": "gNo1Nh5AIK",
        "original": null,
        "number": 2,
        "cdate": 1666482907823,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666482907823,
        "tmdate": 1666482907823,
        "tddate": null,
        "forum": "BSUoWl5yfv",
        "replyto": "BSUoWl5yfv",
        "invitation": "ICLR.cc/2023/Conference/Paper275/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper shows that mathematically the gradient explosion of Relu + BN network approximately grows in the speed of \\sqrt{\\pi/(\\pi + 1)} w.r.t. to the layers. They also proposed a simple variant of LARS/LAMB that upperbounds the learning rate but not scale it. The authors conducted several experiments to show that the proposed method is effective. ",
            "strength_and_weaknesses": "Strength:\n\n1. This paper contains a certain level of insights: it theoretically analyzes the instability property of BN + RELU, and reveals that the order of speed of gradient explosion (defined by Var(X_l)Var(g_l)/Var(x_{l+1})Var(g_{l+1}). Its mathematical proof looks accurate and rigorous. \n\n2. The proposed method is simple which is a good property for real-world applications, especially in industry level dataset/scenarios. Also given the simpleness, I'm in favor of its good reproducibility. \n\nWeakness:\n\n1. The written of this paper could be non-trivially improved, in particular the \"logic flow\" of it seems vague (detailed comments see below);\n\n2. The mathematical conclusion of this paper (as its main technical contribution) seems narrow in that a) it limits to BN + RELU + no residual connection; b) it seems not closely related with the derived algorithm. Again check below for the details. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nIn general I find this paper could improve a lot to tell a coherent story such that readers can more easily follow. Examples:\n\n1. I cannot tell a clear connection of the theoretical results with the proposed algorithm: it is true that we need some layerwise changes based on the insights of the theory presented, but as also the authors admit, previous works like LARS/LAMB could have addressed that. Therefore it would be much better to state more clearly about, what is connection between the specific change proposed on top of LARS/LAMB (i.e., Algorithm 3) and the main theory in the previous sections. \n\n2. I also find it difficult to understand what is the unique advantage of the proposed change over LARS/LAMB, even if we do not force its connected with the theory. For example section 3 is full of (a little bit) lengthy texts. Could the authors state it in a more structured manner (e.g., bullets, sub-sections with clear titles) to show the \"logic flow\"?\n\n3. Some other obvious flaws like please use the correct format of left quotation mark in Latex, and \"However, Contrary to popular belief\" -> \"contrary\"\n\n\nNovelty:\n\nI'm indeed thinking the novelty of this paper mainly lying in the mathematical proof to reveal the gradient explosion order of BN + RELU under some restricted settings. However as aforementioned, I do not see a clear connection of this with the proposed solution so this does limit the real contrition of it. \n\nInstead figure 1 (a) looks more interesting and I'm not sure whether it can act as the true novelty (despite needs more works though): is there a universal theoretical framework to tell people that under what circumstances (e.g., LN v.s. BN, self-attention v.s. CNN, etc) that the gradient explosion norm would grow in what ways? Note some are increasing while others are decreasing w.r.t. layers.  Furthermore more analysis to demonstrate the \"adaptivity\" of the previous algorithm like LARS/LAMB, for these possible theoretical analysis,  might be more interesting. \n\n",
            "summary_of_the_review": "Despite that this paper provides certain insights in terms of theoretical analysis of the \"gradient explosion\" pattern for RELU + BN, it is not stated clearly, and the novelty seems not being properly \"positioned\", in that 1) no clear reasoning leading to the empirical algorithm; 2) it's limited to a restricted scenario. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper275/Reviewer_eGDm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper275/Reviewer_eGDm"
        ]
    },
    {
        "id": "IuBx3CqGxd",
        "original": null,
        "number": 3,
        "cdate": 1666628969049,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628969049,
        "tmdate": 1666629906118,
        "tddate": null,
        "forum": "BSUoWl5yfv",
        "replyto": "BSUoWl5yfv",
        "invitation": "ICLR.cc/2023/Conference/Paper275/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": " An important research question in neural computing is the interplay between Batch Normalization (BN) and learning. In this vein, this paper studies the influence of BN on gradient norm across the layers. BN causes an exponential growth with depth for the norm of a gradient in the first layer. When studying this phenomenon, the paper establishes theoretical and practical contributions: \n- *Theory.* It is claimed that theorem 1. establishes an exponential growth in the norm of the gradient\n- *Practice.\" Paper proposes a layer-wise stepsize clipping to compensate for the gradient expansion. The proposed method is effective in the classification of CIFAR10 and Imagenet datasets.",
            "strength_and_weaknesses": "**Strength**\n\nThe paper well-motivates the gradient explosion in presence of BN; then, it scientifically studies the cause of the explosion. The extensive references and linking of the results well to the literature are very well done. \n\n**Weakness** \n\nI have two main concerns about the theoretical and practical aspects of the results. \n- *Theoretical.* \n  - I am not sure the expectation in Thm.1 is taken w.r.t which random variables. What is the random variable in Eq. (3)? \n  - I have not checked the proof but suppose that Thm.1. is soundly proven.  I am not sure Thm 1. obtains exponential growth. The  Thm. 1 states $E[a_n/a_{n+1}]>1$ where $a_n$ is a factor of gradient variance in layer $n$. Although it is stated such lower-bound in expectation leads to an exponential growth in $a_n$, I am not sure about this. If there was no expectation, it would be possible to derive exponential growth. However, the expectation makes the recurrence complicated. Would the authors mind if I ask to elaborate on this? \n  - My experiments show the norm of the gradient in early layers (close to input) grows at an exponential rate with depth. While the paper suggests an exponential growth in the norm of the gradient in deep layers (close to outputs). \n- *Practical.* The proposed algorithm is very similar to adaptive gradient clipping proposed by Brock, A., De, S., Smith, S. L., and Simonyan, K. in a paper titled \"High-performance large-scale image\nrecognition without normalization\". \nWhat is the difference between the proposed method and the adaptive gradient clipping?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is well written and their theoretical contribution is novel. The proposed algorithm and experimental settings are well explained. ",
            "summary_of_the_review": "In short, I have some concerns regarding the soundness of theoretical contributions, and also some questions regarding the novelty of the proposed algorithm. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper275/Reviewer_EVtb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper275/Reviewer_EVtb"
        ]
    },
    {
        "id": "txZRc1-Pb0Y",
        "original": null,
        "number": 4,
        "cdate": 1666632193908,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632193908,
        "tmdate": 1666632262365,
        "tddate": null,
        "forum": "BSUoWl5yfv",
        "replyto": "BSUoWl5yfv",
        "invitation": "ICLR.cc/2023/Conference/Paper275/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a new interpretations on why gradient explosion still can exist during the early training of normalized model. Their theoretical results can match the empirical observations to some extents. Based on their method, they propose a new optimization method, LALC, which can obtain good performance in both small batch and large batch training settings.",
            "strength_and_weaknesses": "Strength:\n\n1) The theoretical result is interesting and novel, and match the empirical observations to some extents;\n\n2) Experimental results prove the effectiveness of the proposed method;\n\nWeakness:\n\n1) As far as I concern, there is no apparent connection between the theoretical results (Sec 1-2) and proposed solution (Sec 3-4), which severely damage the integrity of the whole paper. I suggest the author to refer to a missing literature [1], in which another relationship between weights' norm and gradients' norm is derived. I think combining with the theoretical results in [1], the theoretical part can well support the reasonableness of the proposed method.\n\n2) It is wired figure 5 shows SGD+warmup totally failed on imagenet with 8K batch size. In [2], the performance of Resnet50 on imagenet with 8K batch only degrades slightly. Can author explain why?\n\n[1] Wan, Ruosi, et al. \"Spherical Motion Dynamics: Learning Dynamics of Normalized Neural Network using SGD and Weight Decay.\" Neurips (2021): 6380-6391.\n\n[2] Goyal, Priya, et al. \"Accurate, large minibatch sgd: Training imagenet in 1 hour.\" arXiv preprint arXiv:1706.02677 (2017).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is well written, though there's a weak connection between theoretical part and solution part;\n\nNovelty: The theoretical part is novel and interesting; The method is effective according to experimental results;\n\nReproducibility: One of the standard experimental result is not consistent with literature, as I point out in weakness.",
            "summary_of_the_review": "Overall speaking, the result is novel and interesting especially the theoretical part. But the theoretical part and solution part has weak connection. I suggest the author to compensate the gap by combining the theorems in the missing literature. Besides, re-examine the experiment setting.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper275/Reviewer_dvc8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper275/Reviewer_dvc8"
        ]
    }
]