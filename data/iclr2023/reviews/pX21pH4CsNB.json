[
    {
        "id": "gsAg4A8EgG2",
        "original": null,
        "number": 1,
        "cdate": 1665997922213,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665997922213,
        "tmdate": 1668572691372,
        "tddate": null,
        "forum": "pX21pH4CsNB",
        "replyto": "pX21pH4CsNB",
        "invitation": "ICLR.cc/2023/Conference/Paper5673/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper trains tailored diffusion models with differential privacy. Two intuitive motivations for using diffusion models for DP data generation are 1) the loss function is a simple and scalable $L_2$ regression loss; 2) the denoiser network in diffusion models is simpler and smoother because it is not designed to generate data in a one-shot fashion. Several novel modifications on the design choices of diffusion models are proposed to boost the performance. One worth mentioning modification to the objective function of non-private diffusion models is *noise multiplicity*. At each step, the authors sample $K$ noises and take the average of the gradients of $K$ denoising losses. Experiments show the proposed method achieves SOTA performance.",
            "strength_and_weaknesses": "**Strength**\n\n1. This is the first work to use diffusion models for DP data generation. The authors achieve state-of-the-art performance on several image benchmarks. \n\n2. The authors propose several novel modifications to the non-private implementation of diffusion models, which are necessary to achieve good performance.\n\n3. The paper is well written. I enjoy reading it.\n\n**Weaknesses**\n\nI have one concern about the benchmarks used in this paper. They have a common pattern: every image has very visually similar neighbors. For MNIST, all digits from the same class look very similar. For CelebA, there are dozens of images for most of the identities. I understand these two datasets are standard in the literature, but I think they are not representative enough. My suggestion is to include some other datasets that do not have clear clusters in the raw input space, e.g., CIFAR-10 which is also used in some previous works. I don't expect the results to be as good as those in the current version, but it is good for the community to know the results. \n\nAnother small concern about CelebA is that the privacy guarantee is example-wise. Each identity has dozens of examples so the identity-wise privacy guarantee will be loose. Again, I understand this is the benchmark from previous works, but still want to express my concern here.",
            "clarity,_quality,_novelty_and_reproducibility": "Please see Strength And Weaknesses.",
            "summary_of_the_review": "I recommend acceptance because this paper gives a high-quality implementation of DP diffusion models and demonstrates promising results. I hope the authors could reply to my first concern.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_vz3p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_vz3p"
        ]
    },
    {
        "id": "tchRaKcPL5",
        "original": null,
        "number": 2,
        "cdate": 1666610905824,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610905824,
        "tmdate": 1666610959024,
        "tddate": null,
        "forum": "pX21pH4CsNB",
        "replyto": "pX21pH4CsNB",
        "invitation": "ICLR.cc/2023/Conference/Paper5673/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studied the differential privacy preservation for the generative model and proposed incorporating the DP-SGD strategy into Diffusion Model training. ",
            "strength_and_weaknesses": "Strength:\n1. This paper is well-organized and easy to follow.\n2. The experimental results on MNIST, Fashion-MNIST, and CelebA datasets validate the effectiveness of the proposed method, and DPDM achieves state-of-the-art performance.\n\nWeaknesses:\n1. This paper seems simply adopt the well-established DP-SGD into Diffusion Model training. The novelty seems limited.\n2. The motivation of the DPDM is somewhat weak, there exist various generative models, such as GAN, VAE, Diffusion, and so on. Training a GAN is harder than VAE and Diffusion model. However, previous works [G-PATE, PATE-GAN, DPGAN, GS-WGAN] demonstrate the effectiveness of training a DP-GAN-like model. \n3. The datasets adopted have small resolutions. For example, the authors use $28 \\times 28$ resolution for MNIST and Fashion-MNIST, $32 \\times 32$ resolution for CelebA dataset. Training a high-resolution model might be realistic in the application, as the Diffusion Model is well-known for its outstanding performance in high-resolution image synthesis. It might be hard for DP-SGD to train with high resolution while perverse the utility of the outputs.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-structured and clearly written. The definition of the statistical method is easy to follow.\nThe novelty of the paper is somewhat incremental.\nThe reproducibility of the paper seems good as relevant details as listed in the paper.",
            "summary_of_the_review": "The main concern of the reviewer is the novelty of DPDM. It seems that the DPDM is a combination of DP-SGD and DDIM models.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_F4hz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_F4hz"
        ]
    },
    {
        "id": "USSo0D_Mqp",
        "original": null,
        "number": 3,
        "cdate": 1666659852692,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659852692,
        "tmdate": 1666659852692,
        "tddate": null,
        "forum": "pX21pH4CsNB",
        "replyto": "pX21pH4CsNB",
        "invitation": "ICLR.cc/2023/Conference/Paper5673/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces differential private diffusion models (SPDMs) and studies DP-SGD for DPDMs training. This paper proposes a modification of the diffusion model training objective called noise multiplicity to boost performance. The DPDMs experiments show improvement in image generation tasks. ",
            "strength_and_weaknesses": "Strengths:\n\n1. Studying differential privacy for the diffusion model is a good initiation. \n2.The noise multiplicity idea for a less noisy objective function is new and interesting. \n3.This paper also provides positive experiment results using DPDMs. \n\nWeakness\n\n1. The motivation for connecting differential privacy with diffusion models is not well explained.  The arguments in section 3.1 do not fully explain the advantage of diffusion models for differential privacy. The privacy guarantee of DPDMs comes from DP-SGD training which is not new. It would be interesting to show the diffusion model itself benefits privacy.\n2. The advantage of DP-SGD for differential private diffusion models is not well supported. The paper claims that the DP generative model is challenging due to injected noise in training. But DPDMs proposed in this paper also uses DP-SGD for training which also injects noise into training. It will be more convincing if the paper can add theoretical or experimental support that DP-SGD injects less noise for DPDMs than for other generative models \n3. It will be helpful to have a theoretical or empirical explanation that noise multiplicity reduced the noise injected in the training. It also will be interesting if the paper empirically compares the noise variance in the gradient with different levels of K. Also, the paper can clarify if noise multiplicity is unique to diffusion models or if this idea can be generalized to other generative models.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and novelty of this paper are moderate. The experiments could be reproducible with the details provided in this paper.",
            "summary_of_the_review": "I feel the approach proposed in this paper is not well motivated. The significance needs to be improved. Overall, I think this submission is not ready for ICLR. Thus, I recommend rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_d3JQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5673/Reviewer_d3JQ"
        ]
    }
]