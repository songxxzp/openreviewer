[
    {
        "id": "vWb5vNirTA",
        "original": null,
        "number": 1,
        "cdate": 1665955430541,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665955430541,
        "tmdate": 1669232591268,
        "tddate": null,
        "forum": "ATLEl_izD87",
        "replyto": "ATLEl_izD87",
        "invitation": "ICLR.cc/2023/Conference/Paper4345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Neural ODEs are powerful models for learning dynamical systems, however, they cannot be generalized the systems with larger sizes when trained on the smaller systems. In order to solve this problem this paper proposes a graph-based neural ODE (GNODE) which can be inductive and generalize to larger systems with the similar dynamics such as pendulum and springs. Base on success from adding physics-based inductive biases in previous works such as Lagrangian neural networks (LNN) and Hamiltonian neural networks (HNN), this paper also explores the effectiveness of adding various types of physics-based inductive biases to the GNODEs. These inductive biases are (1) Decoupling the dynamics and constraints (CGNODE), (1) Decoupling the internal and body forces (CDGNODE), and (3) Newton\u2019s third law (MCGNODE). They evaluate the models based on three metrics: rollout error, energy violation error, and momentum conservation error. The results show the performance of GNODE model, its different versions with distinct inductive biases, and two competing methods (LGN and HGN). Overall, the performance of MCGNODE is the best among GNODE models in terms of those three evaluation metrics, and it also outperforms the competing methods in the pendulum and spring systems. ",
            "strength_and_weaknesses": "Strength:\n\n- The authors have done a good job in bridging the physics and ML by bringing such inductive biases which really help learn the dynamics in these systems effectively.\n\nWeakness:\n\n- These inductive biases work well in physics-based systems such as pendulum and spring. The authors have not investigated its efficacy in more general dynamical systems such as time-series. \n\n- Related to the previous point, I think the examples in this paper are not diverse and only show the physical systems, pendulum and spring.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and clear. The novelty is sufficient as their way of introducing the physics-based inductive biases to the ODE models are different than previous work.",
            "summary_of_the_review": "I liked the idea of introducing three different types of physics-based inductive biases to the graph-based ODE models. It is always helpful to add known governing rules of the systems to the models in order to guide them to learn the true dynamics. However, I have the following concerns/questions:\n\n- This is related to the usefulness of this method in other dynamical systems. I am convinced that this method should work great in the physical systems where we exactly know some of the underlying rules. However, can it still work so well in other systems such as time-series data? In other words, can bringing such inductive biases still help in the systems that we do not know for sure such assumptions do not hold?\n\n- I think it would really help the reach of paper if it includes time-series data, as right now, the diversity of examples are limited to physical systems. \n\nSome minor comments:\n\n- Typos: \n           an node  --> a node\n           the learn --> to learn\n\n- Should eq (11) have another summation over t?\n- Why the authors use Verlet algorithm to compute the accelerations in eq (12)? Shouldn't the acceleration values be observed in such systems? How to choose \\delta t and how accurate are the estimation of the accelerations using (12)? It would be great if the authors clarify this.\n\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_zGuL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_zGuL"
        ]
    },
    {
        "id": "3TATb8WMsD",
        "original": null,
        "number": 2,
        "cdate": 1666435154840,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666435154840,
        "tmdate": 1669272684754,
        "tddate": null,
        "forum": "ATLEl_izD87",
        "replyto": "ATLEl_izD87",
        "invitation": "ICLR.cc/2023/Conference/Paper4345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper discusses on inductive biases for effective learning of physical dynamics based on a data-driven approach. The proposed method, GNODE, is an extension of neural ODE and can describe physical dynamics using graph structures and can embed some physics-informed inductive biases. In the experiments, the effectiveness of the proposed method is verified by comparing it with NODE and graph-based NN models (LGN and HGN). It is also applied to transductive settings to achieve good performance.",
            "strength_and_weaknesses": "S1. A new graph-based NODE is proposed, which can embed several physics-informed inductive biases.\nS2. In experiments, it is shown that the proposed method can predict trajectories more accurately than NODE while successfully capturing the energy conservation law.\nS3. It is interesting that predictions can be made for unseen systems.\n\nW1. Comparison methods seem to be lacking. For example, in Figure 2, it would be good to have a comparison not only with NODE, but also with models that can use physical knowledge (e.g. Symplectic ODE-Net [R1]).\nW2. The task of predicting unseen systems is very interesting, but I think other approaches (e.g. meta-learning ) are working on similar tasks. I think it would be good to add a discussion of this in the related research section.\nW3. There are several unclear points as follows:\n  - This study is formulated based on the Lagrangian form. What is the reason for choosing the Lagrangian form? Also, are the ideas in this study applicable to Hamiltonian form?\n  - Can you also briefly tell me about the advantages of studying physical systems based on GNN?\n  - The more inductive biases you consider, the more robust you will be against sparsity and noise in your data. If you have any views or experimental results, please let me know.\n\n[R1] Zhong et. al., Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control, ICLR, 2020.\n[R2] Lee et. al., IDENTIFYING PHYSICAL LAW OF HAMILTONIAN SYSTEMS VIA META-LEARNING, ICLR, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "- This manuscript is readable.\n- I think the proposed method contains novelty.\n- There are some concerns about the evaluation. It is necessary to examine whether the comparison method is sufficient.",
            "summary_of_the_review": "Overall, it addresses an interesting problem and the method is novel. However, there are concerns about the choice of comparison methods and some ambiguities in the manuscript.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_okft"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_okft"
        ]
    },
    {
        "id": "E3wUdCfAjC",
        "original": null,
        "number": 3,
        "cdate": 1666675770053,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675770053,
        "tmdate": 1668819392052,
        "tddate": null,
        "forum": "ATLEl_izD87",
        "replyto": "ATLEl_izD87",
        "invitation": "ICLR.cc/2023/Conference/Paper4345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to combine graph neural networks and neural ordinary differential equations (ODEs) to make the learned model generalize to particle systems with arbitrary sizes. It further studies how different inductive biases that could be embedded into the framework affect the performance. On two synthetic datasets, some benefits of the proposed model over two strong baselines are demonstrated.",
            "strength_and_weaknesses": "## Strength\n- The paper is clear and easy to follow.\n\n## Weakness\n- The motivation in the abstract is weak as generalizing to arbitrary-sized particle systems using graph neural networks with ODEs are already done by LGN/HGN as mentioned.\n- The differences between the proposed method and LGN/HGN are not clear. It looks to me that the proposed method slightly generalize LGN/HGN by implementing different inductive biases. If this is the case, the novelty is limited.\n\n## Questions\n- Can you clarity the difference between MCGnode and LGN/HGN (in terms of inductive bias)? \n- In the result section it point that MCGnode outperforms both LGN and HGN (figure 5) without any explanation on potential reasons/conjectures. Why this happens? \n    - In general, the results section should not be a simple number comparison. You should draw some conclusion from the comparison.\n- How are the different inductive biases studied here similar to [1]? Some comparisons could be useful as [1] is also a recent work with similar focus.\n\n[1] Xu, K., Srivastava, A., Gutfreund, D., Sosa, F., Ullman, T., Tenenbaum, J. and Sutton, C., 2021. A Bayesian-symbolic approach to reasoning and learning in intuitive physics. Advances in Neural Information Processing Systems, 34, pp.2478-2490.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is well-written and easy to read.\n- Quality: The method is straightforward and the setup of ablation study of inductive biases is justified.\n- Novelty: The proposed method seems to be very similar to existing ones in the literature.\n- Reproducibility: The details in the appendix seems to be enough for reproducibility.",
            "summary_of_the_review": "It looks to me that the proposed method itself is not novel enough and the main contribution is the specific implementation to achieve several inductive biases and an ablation study on them. If this is not correct, the author could clarify this aspect by answering my questions in earlier section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_gQW5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_gQW5"
        ]
    },
    {
        "id": "OiC7lVIv_XU",
        "original": null,
        "number": 4,
        "cdate": 1667532288974,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667532288974,
        "tmdate": 1668916902378,
        "tddate": null,
        "forum": "ATLEl_izD87",
        "replyto": "ATLEl_izD87",
        "invitation": "ICLR.cc/2023/Conference/Paper4345/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to model the second-order ODE of multi-body dynamical systems by using Graph Neural Networks (GNNs). Different from previous LGN or HGN that directly predicts the Lagrangian/Hamiltonian of the system, this paper explicitly involves the inductive biases of the constraints, internal-external forces, and conservation of Newton\u2019s third law.  Experiments are performed to support the benefit of considering the above biases, and the generalizability to unseen systems of large sizes.",
            "strength_and_weaknesses": "Strengths:\n\n1. Indeed, GNNs have been explored widely for physical modeling. This paper applies GNN to characterize the terms of the second-order ODE in Eq. 5, which has contained sufficient terms that reflect conservative/non-conservative forces, internal/external forces, and constraints. This is novel.\n\n2. The authors develop a series of models that take into account different physics priors. The discussion on the relation with Newton\u2019s third law is interesting.\n\n3. Experiments are conducted compactly but convincingly. It is able to justify the validity of the proposed models, particularly CGNODE, CDGNODE, MCGNODE. \n\n\nQuestions:\n\nBelow, I raise some questions (not necessarily weakness) and hope the authors can provide answers to them.\n\n1. Is there any gap like assumption or relaxation between Eq. (2) and Lagrangian dynamics in Eq. (1). If so, please specify.\n\n2. How to compute the Coriolis-like forces in your models, and how to make M inversible in Eq. (4). \n\n3. How does the derivation of lambda by (4) differ from Eq. (7) in the paper [Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints].\n\n4. N_i = Gamma_i =0 in all your experiments?\n\n5. For your models, CGNODE, CDGNODE, MCGNODE, the inductive biases are added independently, or  enforced upon each other? Why not propose a eventual model that considers all biases?\n\n6. For the baselines LGN and HGN, does it share the same GNN backbone as GNODE?\n\n7. What is the implementation of NODE?\n\n8. From Figure 2, it is hard to verify that GNODE is clearly better than NODE. If so, please modify the presentation in the paragraph of \u201cImpact of topology\u201d.\n\n9. Eq. (3), there is a typo. There is no constraint error to check if the proposed model can really permit the constraint of the systems.\n\nSuggestions:\n\n1. Section 3.1 is not the central contribution. The authors are suggested to introduce more on Section 3.2-3.4 including moving their details and illustrated figures from appendix to the main body. \n\n2. The neural network in Figure 1 is just an MLP and unable to show the case of GNN or message passing.\n\n3. It will be interesting to visualize the constraint errors, the difference between the internal force and external force distribution of the learned model. \n\n4. There are recent papers that focus on enhancing symmetry on physical modeling, leading to the application of equivariant GNNs; examples include EGNN, GMN that also involves constraints, SGNN that considers external force field. I am not asking the authors to conduct experimental comparisons wit them, but rather encourage the authors to add some related discussion with the methods in that domain, since symmetry is actually a central topic in physics. For example, if we enforce the Lagrangian to be invariant w.r.t. space translation/rotation, we will also derive the Newton\u2019s third law just based on Lagrangian dynamics. This point is easily justified, by for example checking the Eq. (5) in GMN, where the force message f_ij on each edge is of the same orientation of the relative position x_ij of each two nodes, indicating f_ij=-f_ji.\n\n\n[EGNN] E(n) Equivariant Graph Neural Networks, ICML 2021.\n[GMN] Equivariant graph mechanics networks with constraints, ICLR 2022.\n[SGNN] Learning Physical Dynamics with Subequivariant Graph Neural Networks, NIPS 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Please see above.",
            "summary_of_the_review": "I generally enjoy reading this paper and accept the ideas. I have some concerns on the writing and the experiments. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_UJsG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4345/Reviewer_UJsG"
        ]
    }
]