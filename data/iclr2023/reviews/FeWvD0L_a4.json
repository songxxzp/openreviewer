[
    {
        "id": "KGEMlgQtpw",
        "original": null,
        "number": 1,
        "cdate": 1666565201307,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565201307,
        "tmdate": 1668826312545,
        "tddate": null,
        "forum": "FeWvD0L_a4",
        "replyto": "FeWvD0L_a4",
        "invitation": "ICLR.cc/2023/Conference/Paper219/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The submission proposes a mechanism that it calls learnable behavioral control (LBC). LBC aggregates the policies of a population into a single policy using a bandit-based meta controller. The submission shows that LBC achieves very strong results on Atari.",
            "strength_and_weaknesses": "# Main Concern\n\nThis situation is unfortunate. **The submission is excellent** (simple approach, great empirical results, nice writing), and the authors clearly spent a large amount of time to make it as good as it is. **But there is existing work that was arxived (https://arxiv.org/abs/2106.06232v1) more than a year ago and recently published in ICML (https://proceedings.mlr.press/v162/fan22c) that proposed essentially the same methodology and achieves similar empirical results.** I will refer to this existing work as GDI.\n\n### Irresponsibility of the omission\n\nGDI was published by a relatively lesser known research group among the reinforcement learning community and has not received as much attention as it deserves, so I can see how the authors may not have known about it. However, even if this omission was unintentional, I feel it was still irresponsible: When making a submission with claims of novelty, the submitters are staking their credibility on the claims of novelty being factual; the submitters appear to have made such claims without having done due diligence.\n\n### Work is not concurrent\n\nI do not think the submission can claim concurrency with GDI since GDI has been on arxiv since June 2021.\n\n### Similarity of LBC and GDI implementations\n\nIn their implemented algorithms, both works use continuous MAB algorithms to optimize the temperatures of softmax functions and mixture parameters over policies. There are many instantiation-level differences, but I feel that the implementation in the submission can meaningfully be described as an instance of GDI (and vice versa). If the authors disagree with this characterization, I ask that they provide detailed evidence for their claims.\n\n### Similarity of empirical results\n\nAcross various metrics, the submission reports results (e.g., 10077.52% mean human normalized score and 24 human world records) that are a bit better than GDI (e.g., 9620.98% mean human normalized score and 22 human world records) after 5 times more samples (1B for LBC vs. 200M for GDI). It is hard to make a precise comparison, but, if anything, I might say that GDI's empirical results are a bit more impressive, given that it achieved almost as good results with 5x fewer samples.\n\n### Value of submission\n\nAlthough I feel that there is not algorithmic novelty and that the empirical results are not substantially better, I think the submission as is offers value in the sense that it is much more clearly written than GDI. Since the idea behind GDI/LBC is, in my view, quite important for modern RL but not currently widely understood by the community, I think it deserves to have a paper where it is explained more clearly than it was in GDI. That said, I do not think it would be fair to the authors of GDI to re-brand the same idea under a different name and merely mention GDI as related work.\n\n## Other thoughts\n\n### Measurement notation\n\nThe submission chooses to break the optimization target into two terms that it calls a diversity-based measurement and a value-based measurement. I am not sure what purpose doing this serves, as the submission never actually comes back to this point when discussing the actual algorithm it implemented. I think the best way to resolve the issue would be to use a single symbol V to refer to a measurement and note in the text that this measurement may be decomposable into some weighted combination of diversity and value. Alternatively, if the authors do not want to do that, I think they should at least describe the algorithm that they implemented in terms of these two measurements at some point in the submission so that readers are able to make the connection.\n\n### \"Goal-directed\" terminology\n\nThe submission repeatedly uses the terminology \"goal-directed\". To me, this feels like unnecessary jargon. The submission suggests that Agent57 uses a goal-directed meta controller, but I could not find any usage of \"goal-directed\" in the Agent57 paper. If the submission does not want to remove this terminology, I think the submission should at least make it clear exactly what it means by \"goal-directed\" and how this usage departs from or is the same as that in existing reinforcement learning literature.\n\n### EfficientZero final performance\n\nThe submission states:\n> From Figs. 3, EfficientZero (Ye et al., 2021) achieves remarkable learning efficiency in smaller data volumes but fails to obtain comparable final performance as other SOTA methods like Agent57 or Muzero.\n\nThis statement may be superficially true, but it is misleading to readers because it is comparing apples to oranges. The numbers reported in the submission for LBC use **four orders of magnitude!** more samples than EfficientZero. It is entirely plausible that the final performance of EfficientZero would be comparable to that of MuZero given the same number of samples. Thus, saying that it does not achieve the same \"final performance\" does not strike me as appropriate.\n\nOn this note, I do not think it is even necessary to include EfficientZero(100k) in these plots. It is not a relevant baseline for the submission due to the drastically different sample usages.\n\n## Closing Thoughts\n\nAs articulated above, I feel that the submission is a great piece of work and, even given existing work, offers value to the community. I hope that, through conversing with the authors, we will be able to agree on appropriate revisions that will make the submission acceptance-worthy. However, I anticipate that these changes may be quite substantial -- i.e., going well beyond simply mentioning GDI as related work. I think they would likely require the submission to be re-written from the perspective of providing additional clarity and empirical confirmation for GDI, rather than that of proposing a novel methodology. To me, it is important that the authors of GDI not be denied credit for having had an important idea simply because they are not well-known RL researchers.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the submission is good.\n\nThe quality of the submission is very high.\n\nThe novelty of the submission is low. (See comments above.)\n\nThe reproducibility of the submission is low. (I think that attempting to exactly reproduce the results without any code would require an unreasonable effort in this case.) **The value of the submission would be substantially increased if code could be released.**",
            "summary_of_the_review": "The main methodological contribution of the submission has already been proposed by existing work, which was first arxived over a year ago and recently published in ICML; furthermore, this existing work achieves similar empirical results to the submission. Because the submission does not acknowledge this existing work, and instead presents its methodology as a novel contribution, I do not think it is acceptable in its current form.\n\n---\n\nAfter discussion with the authors and revisions of the submission, I raised my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper219/Reviewer_PtKB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper219/Reviewer_PtKB"
        ]
    },
    {
        "id": "hCKz6LxJdw-",
        "original": null,
        "number": 2,
        "cdate": 1666637771688,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637771688,
        "tmdate": 1666637771688,
        "tddate": null,
        "forum": "FeWvD0L_a4",
        "replyto": "FeWvD0L_a4",
        "invitation": "ICLR.cc/2023/Conference/Paper219/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work considers the exploration problem in RL. Building upon prior work on population based training, this work aims to increase behavior space without increasing the population size in order to improve sample efficiency. \nThe method is hybrid behavior mapping which learns mapping functions to get sampling behaviors from policies. Experimental results show this method achieves new state-of-the-art performance on the ALE benchmark. \n",
            "strength_and_weaknesses": "- Paper seems well written, key concepts are explained, and claims are supported. \n\n- The results are very good. As many games of the ALE benchmark require exploration, the significantly improved results show that the method is highly effective at exploring. I'm impressed by the effectiveness of this approach. \n\n- The behavior construction and selection method is novel to me although seems too complicated to get it to work well in practice. But the authors provide important hyperparameters and pseudo algorithms. I think this is a good work that demonstrates advances of exploration leads to unprecedented performance on Atari games. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality\n\n- Paper proposes an interesting and novel idea for improving sample efficiency by increasing the behavior diversity without increasing the population size.\n- The experimental results show the effectiveness.\n- It\u2019s unclear what categories of Atari games get the most improvement and which games didn\u2019t not get improvements, can the authors add a discussion on this? You could categorize the games according to their difficulty. \n\nClarity\n- Mostly very clear. Some implementation details are missing. \n- The goal-directed term is used many times throughout the paper without explanation or definition except a reference to Agent57\u2019s paper,  please address this in the next version. \n- It would be great to add a discussion on the difference between this work and MEME. \nPlease consider referring to the per game score that is only available in the supplementary material. \n",
            "summary_of_the_review": "This paper proposes a novel and effective exploration method that achieves good results on Atari games. \nThere are some actionable non-critical issues that I hope could be addressed in the next version. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper219/Reviewer_Spxv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper219/Reviewer_Spxv"
        ]
    },
    {
        "id": "B9tOhQqgQt",
        "original": null,
        "number": 3,
        "cdate": 1666797387735,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666797387735,
        "tmdate": 1666797387735,
        "tddate": null,
        "forum": "FeWvD0L_a4",
        "replyto": "FeWvD0L_a4",
        "invitation": "ICLR.cc/2023/Conference/Paper219/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new technique for enhancing population-based RL (PBRL), and shows state-of-the-art results on the Atari Learning Environment (ALE). The technique expands upon previous work in PBRL, which used a multi-armed bandit (MAB) meta-controller to select the best policy from a population of policies. This paper also uses the MAB approach, but proposes to combine multiple policies from the population by summing their softmax outputs, creating a mixture model. This allows them to achieve the highest number of world records in Atari of any previous algorithm. ",
            "strength_and_weaknesses": "A key strength of the paper is in the significance of the results. Setting a new state-of-the-art in Atari is a significant accomplishment, and will be of interest to the RL community. \n\nA weakness of the paper is in a lack of clarity around key technical details, combined with a lot of redundant and unnecessary explanation characterizing the space of possible techniques. The paper spends 3-4 pages (p. 3-6) on redundant and repetitive explanations of behavior space vs. behavior mapping. Many parts of these pages are repeated (for example, the \"Behavior Formulation\" paragraph on p.4 is fully subsumed in other parts of the section and does not need to be repeated). However, the paper spends relatively little time justifying or giving intuition for why the central contribution of the paper (Eq. 9) is the right approach. Most importantly, the explanation of how the MAB behavior selection interacts with Eq. 9 is left very unclear. It would seem that to apply Eq. 9 the MAB would need to select N policies, but this is not stated in the text, which instead says that Eq. 9 will be applied to a single $\\Phi_k$, which does not make sense. This lack of precision makes the paper hard to replicate. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:**\n- As mentioned above, clarity is the biggest weakness of the paper. I strongly encourage the authors to clarify Section 4.2 to more precisely explain how the MAB approach selects multiple polices to create the mixture model. If the authors could comment on this in the rebuttal that would also be helpful.\n- It is a bit unconventional to put a key results plot in the abstract itself.\n- Explain the acronym NGU\n- Section 2.2 is oddly placed, since it repeatedly mentions behavior control and behavior mapping before those terms are explained. It does not contribute much to the understanding of the paper at this point. \n- Clarify whether the ablation results in Figure 5 apply all of the ablations to each successive item on the x-axis (as in, for \"Random Selection\", are H and $\\Psi$ also ablated for this experiment?)\n\n**Quality:**\n- As mentioned above, the results are potentially highly significant and of interest to the community.\n- Assumption 1 is generally untrue... different random initializations of the network weights, even for the same hyperparameters, can lead to significantly different policies. Why is it necessary to formalize Assumption 1 rather than simply introduce Equation 4 once and use a footnote to mention you leave out $\\theta$ as a notational convenience? \n\n**Novelty:**\n- Many components of the proposed approach have been introduced in prior work, i.e. using PBRL in Agent57 and using a MAB to select from the population in Badia et al. (2020). \n- The mixture policy created in this work and the proposed \"Generalized Policy Selection\" is reminiscent of Generalized Policy Improvement in Successor Features https://arxiv.org/abs/1606.05312 https://www.pnas.org/doi/10.1073/pnas.1907370117. It would be interesting to explore that connection. ",
            "summary_of_the_review": "In summary, the paper should be accepted given that the results are impressive and are of significant interest to the community. However, the organization and technical communication in the paper could be significantly improved to enhance its potential impact and reproducibility. \n\nIf it were not for the issues with technical communication pointed out above, I would increase my score to indicate that the paper should be highlighted at the conference. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper219/Reviewer_qVG5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper219/Reviewer_qVG5"
        ]
    }
]