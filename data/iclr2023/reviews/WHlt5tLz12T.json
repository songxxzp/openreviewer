[
    {
        "id": "PVQ616sWoL",
        "original": null,
        "number": 1,
        "cdate": 1666585995294,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585995294,
        "tmdate": 1666585995294,
        "tddate": null,
        "forum": "WHlt5tLz12T",
        "replyto": "WHlt5tLz12T",
        "invitation": "ICLR.cc/2023/Conference/Paper6237/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Paper proposed a novel architecture for self-learning of human-centric perception problems: 2D/3D human pose estimation, human shape recovery and human parsing. The proposed method is simple and effective -- exceeding SOTA for several benchmarks. The encoder subnetwork uses Contrastive Learning and Lifting network to generate the 3D skeleton of the input; this is then combined with Adversarial loss from Discriminator sub-network to improve the encoder. \n\n",
            "strength_and_weaknesses": "Strengths\n1. Paper's motivations and methods are well presented and supported by experimental results.\n2. Experimental setups are comprehensive and strongly supports the core claim of the paper: self-supervised learning network with contrastive approach to generate 3D representation of human images is superior to other self-supervised approaches.\n3. Ablation studies are thorough and well-done.\n\nWeaknesses\n1. Incremental novelty as proposed method is similar to other approaches for CV tasks, including image classification, object detection, semantic segmentation, etc\n2. Experimental results only compare with other self-supervised methods. ",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity is excellent. Paper is well-written and clearly presented.\n2. Quality is good. All sections are well organized. Figures, Tables etc. are also properly labelled and easy to understand.\n3. Novelty is incremental. See Weaknesses above.\n4. Reproducibility is high as many details are given. However, it's not clear if source code will be shared after acceptance.",
            "summary_of_the_review": "Overall, paper is a good piece of work which should be accepted for ICLR. There are aspects of the work which are incremental, e.g. using of Contrastive Loss, 3D structure representation of human. However, the scientific contributions of it are still sufficiently significant, especially in view of its strong empirical experimental results.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_1MfS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_1MfS"
        ]
    },
    {
        "id": "E20_ZQhQ0f",
        "original": null,
        "number": 2,
        "cdate": 1666619633932,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619633932,
        "tmdate": 1666619633932,
        "tddate": null,
        "forum": "WHlt5tLz12T",
        "replyto": "WHlt5tLz12T",
        "invitation": "ICLR.cc/2023/Conference/Paper6237/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose, Lifting Contrastive Learning (LiftedCL), a feature representation learning approach based on contrastive learning with primary focus on the task of 2D/3D human pose estimation from a single image. Authors further use kinematic chain space (KCS) layer and a discriminator to regularise the skeleton. The key idea is to decompose the information into two, invariant and equivariant features. \n\nAuthors provide key experiments on MSCOCO, MPII and H36m datasets. Ablation study shows that the unsupervised pre-training with invariant and equivariant features improves performance over vanilla supervised training.",
            "strength_and_weaknesses": "Strengths:\n+ Contrastive learning for 3D tasks is quite useful because acquiring annotated 3D data is very hard for for a lot of tasks. Unsupervised feature learning approaches make a lot of sense.\n+ I like the ablation study to motivate the choice of using invariant and equivariant feature learning.\n+ The approach is straightforward and easy to follow.\n\nWeakness:\n- The idea of using equivariance and invariance for feature learning has been proposed in Cheng et al. ICCV'21 (not cited). Eg: They also use contrastive learning on augmented images and use that augmentation of the same image are positive pairs and different images serve as negative pairs. How is the proposed formulation different?\n\n- How is KCS + adversarial learning (Sec 3.3) different than Critic Network in RepNet? Eq. 4,5,6,7 here are same as Eq. 3,4,5,6,7 in RepNet.\n\n- Sec 3.2: To learn equivariant features, since the inverse transformation is known, why do we need to use contrastive learning? We have direct supervision that features of positive pairs should be the same after the inverse transform. Can the authors comment on this?\n\n- Datasets like H36m are a bit saturated for pose estimation as they are a bit synthetic and controlled. 3DPW is more relevant dataset these days. Authors use it for shape recovery but not pose estimation evaluation. Can the authors comment on this?\n \nClarifications and minor suggestions:\n- Sec 3.2: What augmentations are used?\n- Add citation to Wandt et al. ECCVW'18 and RepNet, CVPR'19 in Sec 3.3. Authors mention this in related work but it is better to add the citation here as well, otherwise KCS looks like a contribution of this work.\n- PixPro is just an unsupervised feature representation method. How do the authors use it for 2D pose prediction in Sec 4.2? Can the authors provide more details?\n- Add a bullet list of key contributions. It clearly distinguishes the contributions of this work from the other works. This is quite useful as the final approach often uses components from other works.\n- The ideas of equivariance and invariance are quite well known in the 3D vision community. Authors might be interested in checking some of these works out. eg: ART, Zhou et al. 3DV'22.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and easy to follow. I have concerns about originality as the key contributions of this work seem a bit derivative of existing works, equivariance and invariance  formulation is very similar to Cheng et al. ICCV'21 and lifting to 3D using KCS is similar to RepNet, CVPR'19. Can the author clarify why the current approach is not a combination of these two?",
            "summary_of_the_review": "I'm currently on the fence for this work. The key ideas seem to be coming from other works (see weakness section) and I've seen better numbers on 2D/3D pose estimation task. Although these SOTA works (including the best performing version of SimplePose, whose smaller version authors use as baseline) use much bigger networks than Res50 so they are not directly comparable.\nI don't see a very compelling reason to accept this work. I'm open to changing my mind if authors can clarify the limited technical novelty aspect.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I do not see immediate ethical concerns for this work.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_3nTM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_3nTM"
        ]
    },
    {
        "id": "NyfMRsapxs",
        "original": null,
        "number": 3,
        "cdate": 1666664863372,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664863372,
        "tmdate": 1666664863372,
        "tddate": null,
        "forum": "WHlt5tLz12T",
        "replyto": "WHlt5tLz12T",
        "invitation": "ICLR.cc/2023/Conference/Paper6237/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes the Lifting Contrastive Learning (LiftedCL) workflow to train robust human-centric representations that are useful for downstream 2D and 3D human tasks such as pose estimation, shape prediction, and parsing. There are two core components. The contrastive learning part generates features that are invariant and equivariant (under inverse transforms). The \"lifting\" part generates 3D skeletons from the human-centric representations and is trained with a discriminator along with randomly sampled real 3D skeletons. Experiments show that the proposed training produces more useful features for downstream tasks than competitive alternatives such as MoCo-v2 and PixPro. ",
            "strength_and_weaknesses": "### Strength\n- The intuition of learning a robust representation that encodes 3D human information makes a lot of sense to me.\n\n- The designed pipeline is straightforward. It could inspire further development in this direction.\n\n- The invariance and equivariance training is novel in the context of 3D human feature learning tasks. \n\n- I like the idea of having unpaired randomly sampled 3D skeletons as auxiliary training data.\n\n- Experiments show the solid performance of the proposed method when trained on ImageNet + COCO: downstream tasks have significant improvement. That validates the idea of encoding 3D human structure information is useful for human-centric tasks.\n\n### Weakness\n- I think the paper could use a strong baseline in which all the 3D elements are replaced by 2D counterparts. For example, instead of lifting 2D features to 3D skeletons, the network will output 2D skeletons and a discriminator will compare those with randomly sampled real 2D skeletons. Other parts of the network will be kept as much as possible. If the proposed LiftedCL outperforms this 2D alternative on 2D human tasks such as pose estimation and parsing, then it is clear that 3D is essential to both 2D and 3D human tasks. I agree with the authors that 3D is important but it will be more convincing with such an experiment.\n\n- I might have missed it, but is there an ablation study on the effectiveness of the KCS layer?\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nThe paper is straightforward and easy to follow. \n\n### Quality\nThe quality of the work is good.\n\n### Novelty\nI think the idea of encoding 3D-aware representations in human-centric tasks via lifting-to-3D contrastive learning is novel and it can inspire future studies in this direction.\n\n### Reproducibility\nThere seems to be a sufficient amount of detail in the paper for reproducibility. It will be better if the authors plan to release their code. It is not currently mentioned in the submission.",
            "summary_of_the_review": "Overall, I like this paper because it studies an interesting and important problem of encoding 3D-aware representations in human-centric tasks and provides a viable solution. The design components in this workflow could inspire future research in this direction. The experiment results are solid on multiple human-centric tasks. The paper could be further strengthened by adding the 2D baseline mentioned above, but it is a good contribution to the community in its current form.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_5VTe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6237/Reviewer_5VTe"
        ]
    }
]