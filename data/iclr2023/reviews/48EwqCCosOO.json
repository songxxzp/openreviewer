[
    {
        "id": "Y3OlIOUodn",
        "original": null,
        "number": 1,
        "cdate": 1666673458629,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673458629,
        "tmdate": 1666673458629,
        "tddate": null,
        "forum": "48EwqCCosOO",
        "replyto": "48EwqCCosOO",
        "invitation": "ICLR.cc/2023/Conference/Paper968/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "\tThe paper proposes to add a FPN-like parallel branch to existing vision transformers that fuses multi-scale tokens with consecutive downsampling, upsampling and window attention. Design choices of each part are studies empirically and improvement over Swin-T on ImageNet, COCO, ADE20k are reported. ",
            "strength_and_weaknesses": "Strength: \n\t\tThe idea of adding such multi-scale attention branch in parallel is interesting and design choices of downsampling and upsampling are carefully validated empirically. \n\n\tWeaknesses:\n1.\tThe paper says the method adds minimal complexity. The proposed module actually introduce quite the parameters and flops, 17% #param increase and 14% FLOPs increase when applied to Swin-T, 29% #param increase and 11% FLOPs increase for Swin-S.  And the model performance, compared with RegionViT-S, has only marginal 0.1 improvement, but 10% more #params.\n2.\tCan authors show the performance when applied to large models, e.g. Swin-B?\n3.\tThroughputs and memory? As the method adds parallel branch to existing architectures with consecutive downsamling and upsampling, which is hard for parallelization,  can authors show some throughputs comparison w v.s w/o GrafT. Also, each layer will have much more token maps, can authors compare the memory consumption as well? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has good clarity and the proposed method is novel and validated with ablation studies. Reproducibility is medium as the method involves lots of implementation details. ",
            "summary_of_the_review": "Overall, the paper proposes a novel way to fuse multi-scale information in vision transformers, which is to add a FPN-like parallel branch to each of the attention block. It would make the paper better if some concerns regarding computation, throughputs, memory and applying to large models are resolved. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper968/Reviewer_wB1L"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper968/Reviewer_wB1L"
        ]
    },
    {
        "id": "lM-IJA93Fr",
        "original": null,
        "number": 2,
        "cdate": 1666686527420,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686527420,
        "tmdate": 1666686527420,
        "tddate": null,
        "forum": "48EwqCCosOO",
        "replyto": "48EwqCCosOO",
        "invitation": "ICLR.cc/2023/Conference/Paper968/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents an add-on component (termed GrafT) that considers global dependencies and multi-scale information throughout the transformer network. The proposed method is evaluated on several fundamental visual recognition problems.",
            "strength_and_weaknesses": "Strength:\n\nThe proposed method is evaluated on several fundamental vision tasks, although the evaluation on each task is limited.\n\n\nWeaknesses:\n\nThe performance of ViL (Zhang et al., 2021) is much lower than that in the original paper. Please check the experiments and use ViL as the baseline to evaluate the improvement because ViL is the state-of-the-art method.\n\nThis paper should add the proposed GrafT to models with different model sizes. In the current version, the proposed method is only evaluated for Swin-T for object detection, instance segmentation and semantic segmentation. It is only evaluated for Swin-T, Swin-S and DeiT-T for image classification, which is insufficient to demonstrate the effectiveness of the proposed method.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The experiments are insufficient to demonstrate the effectiveness of the proposed method.",
            "summary_of_the_review": "The insufficient experiments and unfair comparisons are my main concerns. Please see the above comments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper968/Reviewer_EcB8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper968/Reviewer_EcB8"
        ]
    },
    {
        "id": "Cx0uVyHggt6",
        "original": null,
        "number": 3,
        "cdate": 1666711867072,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666711867072,
        "tmdate": 1670172105595,
        "tddate": null,
        "forum": "48EwqCCosOO",
        "replyto": "48EwqCCosOO",
        "invitation": "ICLR.cc/2023/Conference/Paper968/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an efficient and general component GrafT for Transformer-based vision architectures. The GrafT can introduce multi-scale features for early-stage layers, thus achieving better results. The authors demonstrate the effectiveness of the proposed GrafT on several tasks and datasets.\n",
            "strength_and_weaknesses": "Strengths\n* The description of GrafT is clear and the figures are nice, making the paper easy to understand.\n* The authors empirically demonstrate the effectiveness of GrafT on multiple tasks.\n\nWeakness\n* The improvement on ImageNet-1K is marginal. In Table 1, Swin-T+ GrafT outperforms RegionViT-S by only 0.1 but introduces 3.4M more parameters. \n* GrafT should generally introduce more FLOPs and parameters for the backbone model.  However, in Table 2, the FLOPs of DeiT-T+GrafT are even smaller than the original DeiT-T.  Moreover, are the training settings for DeiT+ GrafT and DeiT-T fair?\n* The ablation in Table 6-(a) is not sufficient. What are the results with more scales? Is scale = 3 the best?\n* Generalization performance. The authors only validate the effectiveness of GrafT on Transformer-based architectures. If the multi-scale features are beneficial, I wonder about the performance of GrafT combined with classical CNN models such as VGG and ResNet. ",
            "clarity,_quality,_novelty_and_reproducibility": "There are some details in experiments that should be clarified, as described in the weakness. ",
            "summary_of_the_review": "I have several concerns claimed in the weakness part, thus I choose marginally below the acceptance. \nI may modify the score according to the author's response. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper968/Reviewer_br4Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper968/Reviewer_br4Z"
        ]
    }
]