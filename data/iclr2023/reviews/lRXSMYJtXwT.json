[
    {
        "id": "-nXeRyVLZGu",
        "original": null,
        "number": 1,
        "cdate": 1666371130326,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666371130326,
        "tmdate": 1666371130326,
        "tddate": null,
        "forum": "lRXSMYJtXwT",
        "replyto": "lRXSMYJtXwT",
        "invitation": "ICLR.cc/2023/Conference/Paper3381/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a self-supervised learning (SSL) framework for tabular data, Masked Encoding for Tabular Data (MET). MET employs masked auto-encoding with Transformer architectures. This paper shows that MET outperforms existing SSL methods for tabular data and classical machine learning approaches. In addition, this paper empirically verifies that the learned representations well capture the relationship between features.\n",
            "strength_and_weaknesses": "Strengths\n- The proposed method, MET, outperforms recent SSL methods (VIME, DACL, SubTab) and classical ML approaches (RF, GBDT, RF-G) by a large margin.\n- This paper empirically verifies that the learned positional embeddings well capture the relationship between features; in other words, MET is highly interpretable.\n\nWeaknesses\n- I feel the lack of methodological novelty in this paper. I think this paper is a simple application of the existing MAE approach into the tabular domain with no modification.\n- Most multi-classification benchmarks are vision datasets, not tabular: FMNIST, CIFAR10, and MNIST. Other tabular benchmarks should be tested rather than vision datasets.\n- How to select the hyperparameters in Table 7? Which split (train, validation, test) is used for the selection?\n- How to handle categorical features? This should be described in the main manuscript.\n  - I found that this paper uses categorical features as integers instead of one-hot vectors for CovType. Why use this approach?\n- The transformer architecture is necessary? Since the number of input features is constant, one can use MLPs (or other architectures) as VIME did. I cannot find why the transformer architecture is important.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The detailed comments are described in the previous section. In summary,\n- Clarity :: This paper is well-written, and it is easy to follow.\n- Quality :: The empirical results are strong.\n- Novelty :: I cannot find methodological novelty in this paper.\n- Reproducibility :: All the hyperparameters are well-described.\n",
            "summary_of_the_review": "Although the proposed method is not new, the empirical results are strong. Since the tabular domain is yet under-explored, I think this paper's contribution is somewhat meaningful in this field. Hence, I vote for weak accept.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_twHD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_twHD"
        ]
    },
    {
        "id": "GN1BwV6kVfk",
        "original": null,
        "number": 2,
        "cdate": 1666692286319,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692286319,
        "tmdate": 1666692286319,
        "tddate": null,
        "forum": "lRXSMYJtXwT",
        "replyto": "lRXSMYJtXwT",
        "invitation": "ICLR.cc/2023/Conference/Paper3381/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This submission contributes a masking based reconstruction approach with a transformer architecture for self-supervised learning based on quadratic reconstruction error with adverserial perturbation of the input.\n\nThe method is benchmarked on a set of classic datasets where it is shown to predict better than standard methods including gradient boosted trees.",
            "strength_and_weaknesses": "Transformers are clearly powerful architectures and it is interesting to mix them with masked loss for tabular data.\n\nThe datasets benchmarked in table 1 are not tabular data (4 out of 5 are image data). Grinsztajn et al \"Why do tree-based models still outperform deep learning on typical tabular data?\" give a clear definition of properties of tabular data and a list of openly-available data to use.\n\nWhat is the train-test-validation strategy used? Reading the code submitted withthe manuscript seems to reveal that the left-out data set where the performance of the algorithm is evaluated was also used to set the hyper-parameters.\n\nHow are categorical columns dealt with in the reconstruction loss?\n\nHow are categorical inputs dealt with in the perturbation of the input in eq 6?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is reasonably clear to read. I had no difficulties reading it.\n\nI do not believe that I have already seen the specific combination of adversarial masked loss and transformers.\n\nThe accompanying code will help in terms of reproducibility. However, it is not sufficient, as I wasn't able to understand the whole hyper-parameter selection / training routines.",
            "summary_of_the_review": "This manuscript contributes an interesting idea, but it is not clear that the empirical evidence is entirely robust.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_wvLH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_wvLH"
        ]
    },
    {
        "id": "ccMbm3kXNw",
        "original": null,
        "number": 3,
        "cdate": 1668545336949,
        "mdate": 1668545336949,
        "ddate": null,
        "tcdate": 1668545336949,
        "tmdate": 1668545336949,
        "tddate": null,
        "forum": "lRXSMYJtXwT",
        "replyto": "lRXSMYJtXwT",
        "invitation": "ICLR.cc/2023/Conference/Paper3381/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new model for self-supervised learning on tabular data which is based on transformers and auto-encoding via masked reconstruction. To encode feature types, the model uses learnable \"positional\" embeddings which can also capture relations between features. The method is evaluated on a variety of tabular and non-tabular datasets where it shows promising results.",
            "strength_and_weaknesses": "The paper addresses an interesting problem, i.e., how to extend the success of self-supervised representation learning to tabular data. The proposed approach is reasonable and seems to provide promising experimental gains. The experimental evaluation is performed on a wide range of datasets what surpasses prior work in this area. Due to the use of learnable positional embeddings, the methods gains also some form of interpretability (i.e., similarity relations between features) what is a nice additional benefit of the approach.\n\nHowever, in its current form, the paper has some shortcomings that would require further attention, most importantly with regard to clarity, novelty, and reproducibility. I will detail these aspects further in the next section.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is overall good to follow. However, the authors emphasize the connection to graphical models quite frequently and this aspect is unclear to me: GMs provide a convenient way to encode joint probability distributions (e.g., their conditional independence structures). Similarity of positional encodings seems a relatively weak analogy in this context. If the connection to GMs is to be used as a motivation for this approach (as it is currently in the paper), it would like to see a stronger theoretical justification and/or empirical evaluation.\n- Reproducibility: The large improvements of MET over even supervised baselines on some datasets seem surprising. For instance, on Arrythmia, GBDTs achieve ~70% accuracy and all other baselines, including SSL methods for tabular data are (well) below these results. Yet, MET seems to achieve 81+% accuracy. Can the authors provide more context on why this is the case? The very low results of 50% acc for baselines MLPs and RF-G on Thyroid (e.g., random results on binary classes) would also benefit from more context.\n- Reproducibility: The paper overlaps only on a few datasets with prior work (e.g., VIME, Subtab). However, on these datasets, the results do not seem to match those reported in prior work. For instance, for VIME on Income, the original paper reports ~88% accuracy, what would surpass the results of MET. Is this due to different evaluation setups? If yes, what is the motivation for using a different setup?\n- Reproducibility: Related to my question above: while the authors report hyperparameter ranges (which is great) the exact training setup (e.g., splits, hyperparameter selection, stopping criteria) is unclear\n- Novelty: Methodologically, the approach is relatively straightforward (random masking + concatenation of positional embeddings). In terms of technical contributions, I found novelty therefore to be somewhat limited. However, if my questions with regard to clarity and reproducibility above would be addressed, this would be less of a concern as the method shows promising results.\n- Minor: Evaluation on image datasets is somewhat confusing. As the authors note themselves, images have very different properties than tabular data (e.g., non-exchangeability).",
            "summary_of_the_review": "The paper explores interesting ideas for SSL on tabular data and shows promising results. However, short-comings in terms of clarity, reproducibility would require attention prior to publication.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_F52Q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3381/Reviewer_F52Q"
        ]
    }
]