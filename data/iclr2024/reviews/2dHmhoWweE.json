[
    {
        "id": "Ije9M9sRfX",
        "forum": "2dHmhoWweE",
        "replyto": "2dHmhoWweE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_1aPq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_1aPq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new version of multi-step SAM using a linear interpolation technique. They discuss convergence properties of the algorithm and present numerical experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed method seems to outperform SAM in the settings studied."
            },
            "weaknesses": {
                "value": "- The idea of multi-step SAM is not new and has been explored before. Although the interpolation step makes this work different from the previous work, I think that is a marginal contribution.\n\n- The numerical experiments are rather limited. As far as I could tell, they only consider CIFAR and a down-sized version of ImageNet, only using ResNets. I think the complete ImageNet should be in the numerical studies, and some transformer-based models need to be added (such as ViTs or BERT)."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Reviewer_1aPq"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1831/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698388674193,
        "cdate": 1698388674193,
        "tmdate": 1699636112805,
        "mdate": 1699636112805,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JlWJr8f1MT",
        "forum": "2dHmhoWweE",
        "replyto": "2dHmhoWweE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_aoaQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_aoaQ"
        ],
        "content": {
            "summary": {
                "value": "The authors focuses on contributing to the Sharpness-Aware Minimization (SAM) algorithm, more specifically the multiple-ascent SAM, where they proposed Lookbehind SAM. Lookbehind SAM average the history gradient solved during multiple ascent steps for each batch training. e authors empirically show the effectiveness of their method via experiments on CIFAR, ImageNet and as well as lifelong learning settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is clearly written and easy to follow. But some of the presentations need to be improved.\n2. The proposed method seems interesting.\n3. I notice that the authors present valuable extra results, i.e. lifelong learning, in addition to the image classification that is typically used in SAM."
            },
            "weaknesses": {
                "value": "1. My first concern may be the title this paper, \"Lookbehind Optimizer: k steps back, 1 step forward\". The title obviously mimics the paper \"Lookahead Optimizer: k steps forward, 1 step back\". This somehow directly implies that the method of the presented paper is opposite to that in Lookahead paper. But they are very different. The proposed Lookbehind could not be used without SAM, and focusing on different gradients. Considering the proposed method contributes specifically to SAM, so at least, the paper ought to mention SAM algorithm in their title to give a clear view, such as Lookbehind SAM Optimizer or Lookbehind SAM. Not mentioning SAM in the title is unacceptable.\n\n2. The motivation is not quite clear for me. The authors claim that the proposed method could reduce the variance derived from the multiple ascent steps. Why we need to reduce such variance is not clearly demonstrated. \n\n3. Although the proposed method seems interesting, yet its drawback is quite obvious. A single parameter update requires performing multiple backwards propagation to calculate the ascent gradient. In other words, the utility efficiency of training samples is quite low. Multiple backwards propagations are required on the same sample batch. Given that the improvement of the proposed method is marginal, the side effect of such a method can potentially be substantial. So, in my opinion, the proposed method may not be better than the vanilla SAM.\n\n4. Based on my tuning experience, the authors have not trained the models to achieve comparable results when using vanilla SAM in their baseline on Cifar dataset. The authors should at least trained models to achieve comparable results with those reported in the original SAM paper. For example, in the original SAM paper, WRN-28-10 can achieve an error rate of 16.5 with SAM, while in the given paper, it achieves an error rate of 19.5 with SAM, almost 3 percentage gap. Therefore, the reported results can not fully persuade me that their method is more effective. Also, many advanced SAM variants have not mentioned in their experiments. It is highly recommended that the authors make comparisons with these SOTA methods.\n\n5. For Figure 2, it is recommended that the authors draw some marks with respect to the gradient vector.\n\n6. For Algm 1, it is recommended that the authors use $\\theta$ to substitute fast weights $\\phi$, as that used in the Lookahead paper."
            },
            "questions": {
                "value": "See Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I have not found any discussions about the limitations and potential negative societal impact. But in my opinion, this may not be a problem, since the work only focuses on the learning method in machine learning. Still, it is highly encouraged to add corresponding discussions."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Reviewer_aoaQ"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1831/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735763229,
        "cdate": 1698735763229,
        "tmdate": 1699636112719,
        "mdate": 1699636112719,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "46kWuRU6B9",
        "forum": "2dHmhoWweE",
        "replyto": "2dHmhoWweE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_tnTm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_tnTm"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a new approach for the multiple ascent steps Sharpness-aware minimization training, which has been proven to enhance the generalization ability of neural networks. In particular, the authors introduce a variance reduction technique to better leverage the information along the trajectory instead of using the last updated model parameter only. Extensive experiment results on both single-task and continual learning show the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- While previous studies have shown that multi-step ascent SAM does not improve over single-step SAM, the paper proposes to utilize multiple gradients along the ascent trajectory for a better maximization step. Motivated by the Lookahead optimizer, the proposed method stabilizes the training, thus improving the performance of the model.\n- The paper is well-written and easy to follow.\n- The authors conduct experiments on many datasets and backbones and empirically verify the benefit of Lookbehind SAM over SAM. The ablation studies showcase how their method is better than naive Multistep-SAM and Lookahead SAM.\n- Lookbehind is readily applicable to different SAM-based training methods (e.g. ASAM). Moreover, it is robust to the hyperparameter tuning.  \n- The proposed adaptive $alpha$ utilizes the similarity in the updating directions between the first and last gradients can eliminate the need to tune this parameter while maintaining superior performance."
            },
            "weaknesses": {
                "value": "- The authors claim that \"a drawback of any multiple ascent step SAM method is the computational overhead which increases training time by a factor k\". However, while Lookbehind calculates k ascent steps (line 6 in Algorithm 1) and k descent steps (line 8), Multistep-SAM performs k ascent steps and only a single descent step, requiring almost half the complexity.\n\n- Can the authors compare Lookbehind against averaging the ascent gradients baseline, which has been proven to be able to improve SAM [1] (and also performs k ascent steps and a single descent step only)?\n\n- More detailed descriptions are needed for Figure 2 and Figure 11. The decay term can be omitted for simplification.\n\n[1] Kim, Hoki, et al. \"Exploring the effect of multi-step ascent in sharpness-aware minimization.\" arXiv preprint arXiv:2302.10181 (2023)."
            },
            "questions": {
                "value": "- While leveraging multiple ascent steps can improve over the original SAM/ASAM, a prior study [2] shows that the inner gradient ascent can be calculated periodically while maintaining similar performance to the conventional SAM (i.e. it is redundant to compute the ascent gradient at every step). Can the author elaborate more on this?\n\n- Since the computational complexity is multiplied by k, can the authors compare Lookbehind against SAM/ASAM at different training budgets?\n\n[2] Liu, Yong, et al. \"Towards efficient and scalable sharpness-aware minimization.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Reviewer_tnTm"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1831/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811933318,
        "cdate": 1698811933318,
        "tmdate": 1699636112639,
        "mdate": 1699636112639,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QRoeXp7WDq",
        "forum": "2dHmhoWweE",
        "replyto": "2dHmhoWweE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_sgRK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1831/Reviewer_sgRK"
        ],
        "content": {
            "summary": {
                "value": "The\u00a0authors\u00a0propose a novel optimization method, called Lookbehind,\u00a0that leverages the benefits of multiple ascent steps and linear interpolation to improve the efficiency of the maximization and minimization parts of sharpness-aware minimization (SAM). The experiments show that Lookbehind improves the generalization performance across various models and datasets, increases model robustness, and promotes the ability to continuously learn in lifelong learning settings."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1. The work is well motivated. Finding a simple but effective method to improve SAM is both interesting and important. \n\nS2. The paper is well written and easy to follow. The illustration in Fig.\u00a01 and Fig.\u00a02\u00a0are\u00a0helpful to understand the main results.\n\nS3. The authors conduct numerous experiments to showcase the benefits of achieving a better sharpness-loss trade-off in SAM methods. These experiments are comprehensive and convincing. Additionally, the paper includes several ablation studies."
            },
            "weaknesses": {
                "value": "W1. As mentioned by the authors, one inherent drawback of Lookbehind is the computational overhead, which leads to an increase in training time by a factor of $k$.\n\nW2. No convergence analysis for Lookbehind is provided."
            },
            "questions": {
                "value": "Q1. Drawing inspiration from the Lookahead optimizer, can the fast weights (updated in line 8 of Algorithm 1) be approximately updated using any standard optimization algorithm like SGD or Adam?\n\nQ2. Why not conduct an analysis of the sensitivity of Lookbehind to the step size $\\eta$ for the fast weights?\n\nQ3. Anderson acceleration has a similar flavor to Lookbehind, and it has been employed in solving minimax optimization problems.What is the relation between Lookbehind and Anderson acceleration?\n\nMinor Comments:\n\n(1) On page 3, in line 4 from below, should \"slow weights\" be replaced with \"fast weights\"?\n\n(2) On page 8, in line 13 from below, should \"$\\rho$\u201d be repaced with \"$\\alpha$\u201d?\n\n(3) On page 8, in line 4 from below, \"$0\\geq \\alpha^*<1$\u201d should be \"$0\\leq \\alpha^*<1$\u201d."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1831/Reviewer_sgRK"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1831/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699177871889,
        "cdate": 1699177871889,
        "tmdate": 1699636112554,
        "mdate": 1699636112554,
        "license": "CC BY 4.0",
        "version": 2
    }
]