[
    {
        "id": "H9y9tJuIgR",
        "forum": "L0b0vryZRX",
        "replyto": "L0b0vryZRX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission209/Reviewer_YeKP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission209/Reviewer_YeKP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes two novel theorems (Theorems 4.1 & 4.2) to disentangle the representations of instrumental variables, confounders, and adjustable variables from pre-treatment variables and bypass MI estimation between high-dimensional representations from the perspective of information theory."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper considers an important problem in causal inference and proposes two novel theorems to disentangle the representations of instrumental variables, confounders, and adjustable variables from pre-treatment variables. The results demonstrate the effectiveness of the proposed algorithm.\n\n- This paper provides a comprehensive review of the literature on counterfactual prediction and disentangled representation learning. The paper is well-organized."
            },
            "weaknesses": {
                "value": "Incorrect Definiton about $I(A; B \\mid C)$, which should not denote conditional mutual information. If $I(Z ; Y\\mid T)$ represents conditional mutual information, then in Eqs. (2,3,4), it is evident that the conditional mutual information $I(Z ; Y \\mid T) \u2260 0$, as the open of the collider structure $Z \u2192 T \u2190 \\\\{C, U\\\\}$ will make $Z$ dependent on $\\\\{C, U\\\\}$ when $T$ is fixed as a condition, which consequently results in the dependence of Z and $Y$ through $\\\\{C, U\\\\}$. Then the authors use the conditional mutual information in the chain rule of mutual information again. The authors should clarify this point and differentiate the definition $I(Z ; Y \\mid T)$ in Eqs. (2,3,4) from the definition of conditional mutual information. The relevant content may need to be restated."
            },
            "questions": {
                "value": "- Is it necessary to use a shallow network for $Q^z_T$ and $Q^c_T$? Why not use a network of the same size as the reference network?\n\n- The optimization directions of the losses $L\\left(Q_T^z, T\\right) + L\\left(Q_T^c, T\\right)$ and $L\\left(Q_T^c, Q_T^z\\right)$ may be different or conflicting because the former aims to maximize the predictive abilities of $z$ and $c$ on $T$ (the predictive abilities of $c$ and $z$ on $T$ are different), while the latter actually implies forcing a better-performing model to reduce its predictive abilities. This can be achieved by modifying either the predictive network or the representation network. In essence, it is a non-zero-sum game problem. Only when all three are equal to 0 does it mean that $D[\\mathcal{P}_T^{R_z} \\| \\mathcal{P}_T^{R_c}]=0$. \nOtherwise, minimizing the loss of self-distilled disentanglement does not necessarily mean minimizing $D[\\mathcal{P}_T^{R_z} \\| \\mathcal{P}_T^{R_c}]$. I am not sure if I have missed any important parts, but it clearly requires further clarification. Additionally, the Teacher network only aims at enhancing information prediction abilities and does not seem to be the focus of this paper? I will adjust my scores based on the author's response."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698486809227,
        "cdate": 1698486809227,
        "tmdate": 1699635946399,
        "mdate": 1699635946399,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3UpXIQtJHl",
        "forum": "L0b0vryZRX",
        "replyto": "L0b0vryZRX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission209/Reviewer_wJ78"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission209/Reviewer_wJ78"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the task of disentangling the underlying factors of observational datasets in causal inference. The paper proposes a novel disentanglement method that is capable of dissecting instrumental variables and confounders. The authors provide theoretical guarantees for their solution. They also evaluate their proposed method by conducting extensive experiments and show empirically that it outperforms SOTA."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The ideas in the paper are presented clearly; it\u2019s an easy paper to read and follow.\n- The paper provides a good coverage of the related literature and clearly points out its contribution to the research area.\n- Great use of probabilistic graphical models to clearly motivate the proposed solution.\n- The idea of using mutual information to address disentanglement, as well as handling its challenges is interesting.\n- The experiments are extensive and cover a wide range of scenarios."
            },
            "weaknesses": {
                "value": "- Some captions are not descriptive enough of the contents of the figures. E.g., Fig. 1(b) and (c).\n- Use of inline equations should be avoided if possible.\n- It\u2019s best to state each finding in a separate bullet-point.\n- When referring to the appendix, it\u2019s best to also indicate its section number, to make it easier to find."
            },
            "questions": {
                "value": "- I\u2019m not quite sure about the method\u2019s name, specifically, what is being \u201cdistilled\u201d here? Is this referring to dissected factors from X?\n- What is being measured in the radar charts in Figure 3(b)? The caption states it shows \u201cthe contribution of actual and other variables to the decomposed representations\u201d; how is this measured?\n- It is stated in the paper that \u201cthe IV-based methods perform worse than the non-IV-based ones under the continuous scenario\u201d but no reference or discussion is included. Please elaborate why."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698639334011,
        "cdate": 1698639334011,
        "tmdate": 1699635946328,
        "mdate": 1699635946328,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0ZlHyvdxjF",
        "forum": "L0b0vryZRX",
        "replyto": "L0b0vryZRX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission209/Reviewer_pgv6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission209/Reviewer_pgv6"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for representation learning for causal inference building on an existing disentanglement-based approach, by giving a method for optimizing the mutual information between two components of the representation without engaging in an intractible high-dimensional mutual information estimation problem. The authors discuss how to do this optimization by MI estimation with distillation problems and prove equivalencies in optimization problems. Empirically, they demonstrate that their method is better able to estimate ATEs, and through ablations show that their disentanglement is successful and that there is an advantage to avoiding the MI estimation step with their method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- nice empirical results, showing a good win for their more flexible method as well as disentanglement results in controlled settings\n- seems like some clever methods for avoiding problematic MI estimation\n- draws good connections between deep learning approaches and causal formulations"
            },
            "weaknesses": {
                "value": "My main issue with this paper is around clarity - I don't quite follow the novel/interesting parts, specifically through Sec 4. I think a lot of extra care could be taken rewriting here and could result in a nice paper. Specifically:\n- Eq 3: both parts confuse me. On the left: it seems like the constraint I(Z; Y | T) = 0 contradicts the statement from the bottom of p3 about this inducing dependence through a collider. on the right: I'm not sure where this inequality constraint comes from, or why it's necessary\n- Eq 4: this notation is confusing to me: I'm not clear on what variable is being minimized here. I think this could benefit from extra clarity spelling this out. Additionally, isn't I(Z, Y | T) a constant? should this be R_z? what precisely is the difference?\n- What does it precisely mean to say that \"the mutual information between R_a and R_c is all related to Y during the training phase\"? And how would this be ensured by setting up prediction models that go out of R?\n- Corollary 4.3: I don't understand this notation (10a-c, 11a-c)- does this mean minimizing all 3? minimizing the smallest? Again, I think clearer notation could be used around statements around optimization\n- Sec 4.2: I don't follow a lot of these architectural choices: I think the \"retain network\" and \"teacher networks\" could have their roles explained more, as well as the relationship between the deep and shallow networks.\n- Eq 12: a lot of this notation seems a little messy and leaves me uncertain: is W defined anywhere? the sampling weights w, and hyperparameters \\alpha and \\beta all look like global scalars in L_SD2, but I know that w should be w_i (example-wise weights), and so I'm not sure about \\alpha and \\beta - again these aren't defined anywhere\n- what is the metric in 3b representing \"contribution of actual variables?\"\n\n\nSmaller notes:\n- top of p5: you say A is independent of C and Z - do you mean here that C is independent of A and Z? that seems to align more closely with the topic of the paragraph.\n- I find the notation mk, mz, etc. to be confusing - these look like products to me rather than single variables. Maybe consider using m_k etc.\n- it would be good to see more information on the contrast between your method and DRCFR"
            },
            "questions": {
                "value": "- is there an implicit assumption in this method that T, Y are causally downstream of X? what other assumptions are required for this method to work well?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698785391387,
        "cdate": 1698785391387,
        "tmdate": 1699635946257,
        "mdate": 1699635946257,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DApAO7ncx7",
        "forum": "L0b0vryZRX",
        "replyto": "L0b0vryZRX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission209/Reviewer_FUp5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission209/Reviewer_FUp5"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to develop an estimator that estimates causal effects in the presence of unobserved confounding while avoid the need to explicitly assume knowledge of an instrumental variable. Instead, they aim to disentangle instruments from confounders and then estimate the effects. They derive an information theoretic approach to separating instruments from confounders and find that it give strong performance on the benchmarks that they tested."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* I really like the idea of finding ways to go beyond assuming access to IVs to address unobserved confounding.\n * The method offers strong performance on benchmark datasets.\n * The method makes no distributional assumptions, so if correct, this would make it far more general than anything that has come before it... unfortunately I don't think that it is correct (see counter examples below)"
            },
            "weaknesses": {
                "value": "The method works by minimizing the conditional mutual information between instruments and response given the treatment, $I(Z;Y | T)$, under the claim that the *exclusion* assumption implies that $I(Z;Y | T) = 0$. Unfortunately, this claim is incorrect, because it ignores that conditioning on $T$ opens a collider between $Z$ and $Y$ via $U$ (also via $C$, but the authors are aware of this). Here is an explicit counter example showing that the mutual information is not zero in general:\n\n$ U \\sim Bern(0.5 )$\n\n$ Z \\sim Bern(0.5 )$\n\n$T = XOR(Z, U)$\n\n$Y = XOR(T,U)$\n\nwhere $XOR$ is the exclusive or function that evaluates to 1 if either argument is 1 but not both. Notice, that $H(Y | T)$ is just 1, since all the randomness in $Y$ comes from $U$ which has entropy $1$ by construction. More importantly, if you work through all the possible outcomes of the above system, you will see that, conditional on $T$, $Z$ is always equal to $Y$ (i.e. $H(Y | T, Z) = 0$), but that they are conditionally independent when you condition on both $T$ and $U$. For example, if $T = 1$, then when $z=0$ we know $U=1$ (since otherwise $T$ would not be 1), and hence $Y = XOR(1, 1) = 0 = z$. \n\nThis is an extreme example, but it highlights that the claim is surely not true in general. Also - the authors make no assumptions on the functional form of the structural equation that determines $Y$, and we know from the LATE (local average treatment effects) framework and Pearl's work on bounding treatment effects, that it is impossible to non parametrically identify the treatment effect with access to an instrument. So there are surely more necessary assumptions for the method to work in general.\n\nThe simulation results are very strong, so I don't know whether there is just a missing assumption and the method works under additional assumptions, or if there are mistakes in the simulations too."
            },
            "questions": {
                "value": "Can you give sufficient conditions under which this method identifies the treatment effect?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699160733850,
        "cdate": 1699160733850,
        "tmdate": 1699635946174,
        "mdate": 1699635946174,
        "license": "CC BY 4.0",
        "version": 2
    }
]