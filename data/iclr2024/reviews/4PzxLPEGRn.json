[
    {
        "id": "iomsTsCiqV",
        "forum": "4PzxLPEGRn",
        "replyto": "4PzxLPEGRn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_7uXz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_7uXz"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new benchmark, OCAtari, based on the ATARI 2600 RL environments. Instead of providing raw pixel observations to an RL agent, this benchmark allows the use of object-centric representations as input for an RL algorithm. The authors propose two methods to extract objects: one is a vision-based method that extracts bounding boxes by searching for a particular set of pixels per game, and the second is a method extracting the object coordinates from the game emulator RAM. In addition, the authors also generated a dataset of frames together with their detections, which can be used to evaluate the accuracy of an object-detection method on ATARI. Finally, OCAtari also allows to adjust the RAM state in order to generate particular or novel game situations, which could be used to generate new variants of existing Atari games."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Standardised benchmarks are a cornerstone to advance research, as it allows to evaluate and compare different approaches on a level playing field. Being built on top of the well-known Atari benchmark further enables to compare against a wealth of related work on pixel-based RL."
            },
            "weaknesses": {
                "value": "- I think one of the main outstanding challenges in object-centric RL is how an agent can learn which are the particular objects in a game, and more importantly which are the relevant objects in a game. By introducing a predefined object extraction pipeline you basically fix an important part of an object-centric RL algorithm, and it's not said that the proposed object representation (i.e. coordinates and bounding box) is actually the best representation for an RL algorithm. So whereas this might be an interesting tool for developing and debugging object-centric methods, I'm in doubt of the value of this as a benchmark per se.\n\n- In Figure 5, the pixel-based Deep PPO agents actually seem to outperform the object-centric ones in sample efficiency on some of the games (i.e. Asterix, Boxing and Freeway). This makes me wonder whether the current object-centric representation is actually fit for purpose. Of course the current policy that ingests the object-centric representation is pretty naive so that could be the point of the benchmark to further improve this."
            },
            "questions": {
                "value": "- For some games the object detection method seems to be far from perfect (i.e. DemonAttack, ChopperC.), or have a low IoU (i.e. IceHockey). It might be interesting to see what's going on in these environments in the qualitative results and/or appendix.\n\n- If the environment gives you a list of objects, how does it handle \"object permanence\" over different frames? For instance, is the object at index i at time t the same object at index i at time t+1, or are the objects just put in random order in a list each timestep. Also, is the list of fixed size for a particular game, or does the list grow/shrink with the number of visible objects in a frame?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1860/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1860/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1860/Reviewer_7uXz"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1860/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698388159079,
        "cdate": 1698388159079,
        "tmdate": 1699636116137,
        "mdate": 1699636116137,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dt0wm82lLU",
        "forum": "4PzxLPEGRn",
        "replyto": "4PzxLPEGRn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_BhyG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_BhyG"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a new experimental platform based on the Atari 2600 to investigate object-centric representation in reinforcement learning. To extract object-centric representation, the authors implement two methods. One is the Vision Extraction Method (VEM) using computer vision techniques, and the other is the RAM Extraction Method (REM) based on AtariARI (Anand et al., 2019). Currently, VEM and REM cover 32 and 25 games, respectively. The authors also claim that OCAtari can change game elements or behavior by manipulating the RAM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Creating the object-centric Atari Learning Environment greatly impacts the community that develops the object-centric RL algorithms. \n2. The source code is available."
            },
            "weaknesses": {
                "value": "1. Although the introduction is well-written, it is still unclear why the ALE was selected. Please see my first question below."
            },
            "questions": {
                "value": "1. I agree that learning object-centric representation is one of the important research directions, but I am unsure whether the ALE is a good testbed because of its simplicity. In addition, there are several simulators that consider object-centric representation, such as VirtualHome (Puig et al., 2018), iGibson (Li et al., 2021), and AI2-THOR (Kolve et al., 2022). Would you explain why the ALE is selected in detail? \n- Puig et al. (2018). VirtualHome: Simulating Household Activities via Programs. Proc. of CVPR. \n- Li et al. (2021). iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. Proc. of CoRL. \n- E. Kolve et al. (2022). AI2-THOR: An Interactive 3D Environment for Visual AI. arXiv. \n2. Recently, Aitchison et al. (2023) proposed a principled way to pick up a small subset of games. Their method makes it possible to reduce the computational cost because the algorithms are not evaluated on all the games. For example, they found that five games are enough. Is it possible to incorporate their method into OCAtari? \n- M. Aitchison et al. (2023). Atari-5: Distilling the Arcade Learning Environment down to Five Games. Proc. of ICML. \n3. What does the red circle in Figure 4 represent? In addition, the bounding boxes near the enemy are empty in MsPacman. It suggests that OCAtari does not treat tiny rectangles (foods) as objects. Is my understanding correct? \n4. Figure 5 seems interesting. I would like to know why the pixel-based PPO agent learns slightly faster than the object-centric PPO agent. Specifically, I expected the OC-PPO agent to learn faster because it has good state representation, but the result is the opposite. Would you discuss this point in detail?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1860/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698673899582,
        "cdate": 1698673899582,
        "tmdate": 1699636116046,
        "mdate": 1699636116046,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MvTHVYgwNx",
        "forum": "4PzxLPEGRn",
        "replyto": "4PzxLPEGRn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_wGg4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_wGg4"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a modification of the Atari-game Arcade Learning Environment (ALE) that augments the traditional pixel observations with information about objects and their bounding boxes. The new library, OCAtari, uses two different object extraction methods, one vision based, the other RAM-based. The paper describes the relative strengths and weaknesses of these two approaches, and demonstrates that the object-centric representations can be used for reinforcement learning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The library can serve as a best-case result for comparing against approaches that do Atari object detection without access to the RAM state. It also allows research to proceed on designing agents that exploit object-centric representations without first waiting for object-detection methods. The paper also argues that when visual features are not needed, this library can dramatically speed up the training process by eliminating much of the rendering pipeline."
            },
            "weaknesses": {
                "value": "1. I am somewhat skeptical that this library will be broadly useful to the field. The paper presents a publication-count-based argument that there is a need for object-centric Atari environments. I don't draw the same conclusion from the presented evidence. The authors may be surprised to learn that one of the earliest Atari + reinforcement learning papers (from 2008!) dealt with this exact question: Diuk, Cohen & Littman's paper on Object-Oriented MDPs. The fact that Atari did not become a popular testing ground for reinforcement learning until later, with the advent of the ALE, suggests that the lack of well-defined object-centric representations was not what was holding back adoption, but rather the availability of a wide range of domains featuring a common interface.\n\n2. I am also skeptical of the authors' prediction that they will \"complete what we have started\" and add the remaining ALE games. What would it mean to \"complete\" this project? It seems like there are substantial hurdles left to overcome in the remaining games, particularly since without Atari ARI as a guide, they will require much more reverse engineering to extract objects from the RAM.\n\n3. The paper claims that the library allows new modifications of existing games. They present \"hard-fire Pong\" as an example, but this seems to already be possible under the existing ALE. I suspect many of the proposed variations are already possible as well, since the ALE already provides `set_ram` functionality.\n\n4. I am unconvinced by the argument that the REM object detection will amount to a training-time speedup. For example, in Ms. Pacman, the object detection does not work for walls, so visual observations are necessary even when objects are available. (Incidentally, the paper claims that the walls in Ms. Pacman are static, but this is incorrect; they change after a certain number of completed levels.)"
            },
            "questions": {
                "value": "My main question for the authors is: if objects are indeed so important, why not build an environment (or improve an existing one) that supports objects natively, rather than reverse-engineering one from the ALE? What's so special about Atari?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1860/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800280435,
        "cdate": 1698800280435,
        "tmdate": 1699636115970,
        "mdate": 1699636115970,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JnYSEU5KGb",
        "forum": "4PzxLPEGRn",
        "replyto": "4PzxLPEGRn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_Lfyp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1860/Reviewer_Lfyp"
        ],
        "content": {
            "summary": {
                "value": "The authors consider an interesting gap in the RL benchmarks i.e. the evaluation and training of object centric approaches. To this end, this paper introduces Object-Centric Atari, a set of environments that provides object-centric representations of ALE.  They show that OCAtari can be used to train or evaluate any part of an object-centric RL agent-- including object detection methods that extract objects and  extract categories from the extracted embeddings or be used in supervised learning directly. They build on top of AtariARI."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This work provides a concrete benchmark/dataset to train and evaluate object centric properties of RL approaches. Key strengths of the paper include: \n*    The benchmark can serve a nice tool to test the abstraction ability of our methods today as humans seamlessly can detect objects and reason in the space of object oriented.\n*    It can inform the quality of representations learned in ALE domains and further if the methods have abilities such as compositional generalization, etc.\n*    The work is valuable to provide the open-source implementation of the benchmark.\n*    Finally, the authors also provide documentation to customize these environments etc."
            },
            "weaknesses": {
                "value": "The paper offers interesting contribution, however I believe the paper is not up to the mark for the ICLR conference venue. I find the following issues major limiting factor in recommending acceptance:\n*   The topic and contribution is relevant, however it is unclear to me immediately what this buys us for methods not focused at object central. For e.g. a method might be able to achieve very good performance but not do well on object centric evaluation.\n*    What is missing and would be nice to see baselines of representation learning methods to showcase the benchmark's utility further?\n*    The contributions on top of AtariARI seem not substantially different, for e.g. can we not access VEM provided information."
            },
            "questions": {
                "value": "I would be happy to reconsider my score and engage during discussion period with the following questions:\n\n*    What is the contribution here from the learning perspective? May be I am missing something here, but is it correct to understand that the primary contribution lies in a wrapper around the ALE benchmark to be able to provide an object centric evaluation for RL agents in a way that combines REM (from prior work) with previously established vision modules to annotate objects? \n*    Next, the paper shows that the current methods do not necessarily have a great understanding of objects? Is that strictly necessary to solve the tasks? While I value object centric research, I am unsure if the agents would strictly needs that to solve tasks and should be evaluated on this ability more strictly for methods who do not bake such an inductive bias in the approaches?\n*   \"To extract objects, OCAtari uses either a Vision Extraction Method (VEM) or a RAM Extraction Method (REM), that are depicted in Figure 2.\" What were the specific techniques used to perform vision. I was unable to find this information in the manuscript.\n*    The authors mention that RL methods are hard to evaluate due to the non-determinism of the approaches -- how does OCAtari overcome this problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1860/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699379995868,
        "cdate": 1699379995868,
        "tmdate": 1699636115915,
        "mdate": 1699636115915,
        "license": "CC BY 4.0",
        "version": 2
    }
]