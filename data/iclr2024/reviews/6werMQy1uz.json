[
    {
        "id": "925iEjXVZh",
        "forum": "6werMQy1uz",
        "replyto": "6werMQy1uz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
        ],
        "content": {
            "summary": {
                "value": "This paper considers a model of information markets with LLM based agents to resolve the buyer's inspection paradox. Specifically, the buyer wants to assess the information to determine its value, while the seller wants to limit the access to prevent information leak."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- It appears to me that the information market will become an increasingly important problem in the future, but this problem is not well studied beyond abstract theoretical models. This paper proposes an interesting initiative to solve the problem of inspection paradox in information markets through LLM based agents, as those agents are innate to understand the text in context without the capacity to memorize the information.\n\n- This paper designed a simulated information market to generate text contents for sales and evaluate the potential performance of the proposed method. Several interesting experiments with a good amount of efforts are conducted to evaluate the economic rationality of LLM based agent.\n\n- The findings about debate prompting is interesting by itself --- but should the paper cite the source of this technique if it is not an original invention? At a high level, this observation seems to suggest that decision making, especially those require strategic thinking should involve counterfactual reasoning (obtained from debating or self-questioning); this insight might be useful to improve the strategic reasoning skill of LLMs."
            },
            "weaknesses": {
                "value": "- The paper only compares the performance between agents powered by different LLMs. Though the \"Evaluating the Evaluator'' experiment made some comparison between GPT4 and humans as evaluators, what about baselines based on algorithmic approaches, e.g., a buyer agent that designs quoting strategy based on keyword-matching? The ability to forget the information from rejected quotes can also be artificially planted in these algorithms. Hence, without these algorithmic or heuristic baselines, it is unclear to me how it is necessary to use LLM based agents in this task.\n\n- The paper focuses on the inspection paradox, but the procedure of inspection, especially in the context of information market, is oversimplified --- it is basically whether to allow the agent to read all the text content. However, there is a rich line of econ/cs/ml literature (see e.g., [1, 2, 3]) on the information market that concerns the power of information design for buyer inspection. \nFor example, the seller could only give out a summary of the content, or only answer certain query questions from the buyer agent --- because it is unclear whether it is reasonable or enforceable to trust the buyer to forget all the information from rejected quotes in reality. \n\n[1] Bergemann, Dirk, Alessandro Bonatti, and Alex Smolin. \"The design and price of information.\" American economic review 108.1 (2018): 1-48.\n\n[2] Ghorbani, Amirata, and James Zou. \"Data shapley: Equitable valuation of data for machine learning.\" International conference on machine learning. PMLR, 2019.\n\n[3] Chen, Junjie, Minming Li, and Haifeng Xu. \"Selling data to a machine learner: Pricing via costly signaling.\" International Conference on Machine Learning. PMLR, 2022.\n\n- To my knowledge, there is no clear evidence so far that an LLM based agent has any reasonable rationality or strategic reasoning skill  --- GPT4 cannot play tic-tac-toe, or even reliably compare two numbers. This is also verified in the paper's experiment. Hence, I am not sure whether it is meaningful for the paper to give LLM based agents the ability to make economic decisions --- these decisions could be left for the human or some simple algorithmic procedures while only asking the LLM to provide its reasoning or evaluation scores on the value of the text."
            },
            "questions": {
                "value": "Please see my comments above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698783811196,
        "cdate": 1698783811196,
        "tmdate": 1699636976062,
        "mdate": 1699636976062,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ugGapcBAGX",
        "forum": "6werMQy1uz",
        "replyto": "6werMQy1uz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
        ],
        "content": {
            "summary": {
                "value": "The authors propose text-based digital information market environment is proposed. In such an environment, buyer agents try to obtain the necessary information by transactions with vendor agents without overspending the budgets. Vendor agents need to sell the information for market credits. As the evaluation and access process is implemented by LLMs, the information is not directed accessed by the buyers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Abundant experiments about whether LLM can be used to evaluate information and make economic decisions. It also examines the performance of different LLMs in different aspects.\n2. Give detailed introductions about how LLM can become a useful agent in Information Bazaar, including the prompts, interaction frameworks, and dataset analysis.\n3. An open-source simulator has been established, which is helpful for future work."
            },
            "weaknesses": {
                "value": "1. The idea of protecting the information lies in the belief in LLM. However, LLM may face data leakage risks. The authors need to clarify whether it is secure for LLMs to access the information, even if only metadata is accessed.\n2. This paper primarily focuses on explaining how to transform LLM into an agent capable of performing rational actions in an information bazaar, but it lacks detailed explanations regarding using LLM. In other words, replacing LLM with any intelligent agent possessing information evaluation capabilities and trading intelligence would still be able to effectively address the problem of determining the value of information."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7945/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7945/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698932758773,
        "cdate": 1698932758773,
        "tmdate": 1699636975951,
        "mdate": 1699636975951,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wQJFeYhgy4",
        "forum": "6werMQy1uz",
        "replyto": "6werMQy1uz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_ovK6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_ovK6"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an interesting automated market run by LLMs that avoids the information asymmetry characteristic of information markets.  The market is run entirely by agents implemented as LLMs that both evaluate text offerings then forget what they've read. This avoids the need for the human agent--the principals-- to view content offered in the market to be able to evaluate it,  creating a  problem for the vendor who would prefer to not reveal the content prior to sale. By use of automated agents for both buyer and vendor, a selection is made without human intervention, so not revealing any content used for evaluation. \n\nThe paper works out a full simulation of multiple agents together with a pricing scheme to demonstrate the feasibility of LLMs performing these tasks. Various LLM implementations are used --"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The intricacy and just pure inventiveness of the marketplace proposed is impressive. To create system with LLMs playing multiple competing roles is novel. SImilarly the insight that such automation can address a longstanding question in information economics. One can imagine that this work could inspire a flock of similar LLM-driven markets to resolve similar inefficiencies in actual markets. \n\nThe simulation presented shows favorable qualities of better performance with more capable LLMs, rational price behavior in both micro- and macroeconomic scenarios, and improved performance as information content improves."
            },
            "weaknesses": {
                "value": "There is a  fundamental evaluation question, concerning is definition and creation of a evaluation baseline. The paper takes as a premise that an LLM-based method is by nature superior to a conventional automated method. Granted, evaluating LLM performance is an area open to many approaches, and no conventional method exists such as cross validation serves for supervised learning.  Specifically in this paper, one could create a surrogate for non-LLM buyer and vendor agents (the vendor could be a trivial version that just presents metadata), to serve as a point of comparison for the LLM models presented. This would be the analog of the statistician's null hypothesis. For example, if just metadata were used - e.g. the $\\script{F}(M(I))$ by an algorithm based on conventional similarity measures of relevance, how would it perform? Hence the research question posed, \"Does this marketplace enable buyers to more reliably identify and value information?\" begs the question, \"more reliably than what?\"\n\nIn the Section \"Evaluating the Evaluator\" a comparison is made between GPT4's result and a human label, showing reasonable human-level performance. This is interpreted to mean that the method has a subjective component.  This does not answer the fundamental evaluation question. \n\nIncidentally Figure 6 is missing the caption \"Figure 6\"  Figure 6a could be more succinctly presented since the\noff-diagonal elements are simply 1 minus the other. The choice of visualization method is different than for 6b - one is a comparative percentage, the other a correlation, which is confusing."
            },
            "questions": {
                "value": "One could argue that judging a paper on a task that it does not propose to do is to force a requirement on the paper outside of the scope of work.  One conceivably could always come up with such arguments - \"what about X or Y -- why were they not included in the work?\" and hence such criticisms might appear in general unfair.    The argument as to the weakness described could be considered as such.  However this is a stronger argument, that claims about a contribution must be substantiated against a conventional norm.   I am open to reconsideration of this point should the current contribution based purely on novelty be considered adequate."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698967644619,
        "cdate": 1698967644619,
        "tmdate": 1699636975824,
        "mdate": 1699636975824,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zzRvVnle9A",
        "forum": "6werMQy1uz",
        "replyto": "6werMQy1uz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_mENG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7945/Reviewer_mENG"
        ],
        "content": {
            "summary": {
                "value": "This paper studies how the use of agents based on large language models (LLMs) could potentially affect information markets. To this end, the paper introduces a suitable environment simulating an information market, and it experimentally evaluates various LLM-based agents within it."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I believe that the challenges addressed in the paper are relevant for better understanding how large language models behave in application scenarios in which strategic aspects are concerned. The paper makes a very good job at presenting the studied setting and derived results."
            },
            "weaknesses": {
                "value": "The first concern that I have is about the exposition of the results in the paper. While the obtained results are very-well explained at least intuitively, I think that the paper misses some formalism that is needed to really fully understand the presented results. In the end, the actual framework that has been developed to model agents' strategic interactions is never introduced in the paper. Perhaps this is not so important from an experimental perspective, but it could be of great value for those that are more interested in the theoretical implications that the obtained results have.\n\nThe second concern that I have is more from a deployment perspective. I found interesting the idea of equipping agents with the ability of forgetting information if this is not acquired by them. However, I have some doubts on how this behavior can be enforced in practice."
            },
            "questions": {
                "value": "See the second concern in the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699433151257,
        "cdate": 1699433151257,
        "tmdate": 1699636975716,
        "mdate": 1699636975716,
        "license": "CC BY 4.0",
        "version": 2
    }
]