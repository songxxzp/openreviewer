[
    {
        "id": "OBDLTSb76w",
        "forum": "x4fm4T2tjM",
        "replyto": "x4fm4T2tjM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_ygbc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_ygbc"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes RoboGPT, an LLM-based approach that fine-tunes the RoboGPT planner (LLaMA 7B) for sub-goal planning, \nuses RoboSkill to perform each navigation and manipulation sub-goal, and modifies the initial plan if the agent cannot find a target object.\nTo fine-tune the LLM, the authors follow Wang et al. to generate instructions, resulting in the dataset combined with a small amount of the generalization data.\nFor better segmentation mask prediction, they adopt the backbone of Fast SAM.\nThey outperform previous state-of-the-art methods in most metrics with noticeable margins."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper tackles an important problem of ungrounded issues when utilizing LLMs in embodied agents.\n- Each component of the proposed approach plays an important role as observed in the ablation study with noticeable margins.\n- Exploiting commonsense knowledge encoded in LLMs for planning sounds reasonable.\n- The proposed method achieves strong performance in a challenging embodied instruction following benchmark."
            },
            "weaknesses": {
                "value": "1. The proposed approach lacks novelty.\n- For the RoboGPT planner, using LLMs for planning has been already explored in the same domain (Song et al., 2023) and different domains (Brohan et al., 2023a; Huang et al., 2022), as mentioned in the paper. The differences from the prior work are 1) the output format (i.e., introducing \"Find, <obj>\") and 2) generating more trajectories for fine-tuning but they look like engineering efforts.\n- RoboSkill is quite similar to (Min et al., 2022), except for training a better segmentation module with the Fast SAM backbone, which is also an engineering effort.\n- Re-plan measures the similarity between an object to be replaced with all observed objects. Though it is simple, it looks like specifically designed for the downstream task (a plan for the task is a sequence of actions and corresponding target objects). Can this approach be applied to other tasks?\n\n2. Some comparisons are unfair or unreliable.\n- The validation unseen split consists of only 50 episodes that are matched to the ground truth, which is much fewer than the original one (i.e., 821). While agreeing with the imperfections of language annotations, I do not see such a large number of imperfect annotations (i.e., more than 700 episodes). How do the authors exactly select the reduced episodes?\n- While LLM-Planner uses approximately 0.5% of the original ALFRED dataset, the proposed method uses a substantial amount of datasets, about three times more than the original one. As it uses more training data, the performance gain is expected.\n\n3. Some descriptions are not clear.\n- The authors use commonsense encoded in LLMs but it is a bit counter-intuitive to augment more training data for fine-tuning, because LLMs already have much knowledge and therefore they are expected to easily adapt to downstream tasks. If we generate more data examples for planning, why not just use some vanilla planning modules (e.g., LSTM-based models)?\n- For \"ALFRED's data,\" the authors deduce 5 new tasks and construct planning templates. What are the 5 new tasks?\n- What is the mapping module \"S_n = Map(P_n)\" here? How is it implemented?"
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6784/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6784/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6784/Reviewer_ygbc"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697545128366,
        "cdate": 1697545128366,
        "tmdate": 1699636783487,
        "mdate": 1699636783487,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qurpLNnVmJ",
        "forum": "x4fm4T2tjM",
        "replyto": "x4fm4T2tjM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_SCK4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_SCK4"
        ],
        "content": {
            "summary": {
                "value": "This paper presents RoboGPT, an agent system for solving daily instruction tasks with long-term decisions. An LLM-based planner finetuned on the proposed new robotic dataset is proposed to break a task instruction into sub-goals, and a re-plan module is designed to generate more feasible plans based on the environment feedbacks. Experiments show an improved feasibility."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis paper proposes a new robotic dataset including 67k robot commands. The quality and variety of the proposed dataset is good, and experiments show reasonable improvements for models trained from it.\n2.\tThis paper proposes a semantic map based re-plan module to solve practical issues brought by nomenclature diversity.\n3.\tExtensive experiments and discussions."
            },
            "weaknesses": {
                "value": "1.\tThe technical contribution is not clear. The improved feasibility mainly comes from 1) a self-collected and self-labelled dataset and 2) semantic map extracted by an existing work, which seems straightforward. The technical challenges and underlying designs need to be pointed out more clearly.\n2.\tThe significance of the feasibility considered by this paper is not clear. For example, this paper proposes a re-plan module with real-time semantic recognition on failure so that the agent can know \u201cTable\u201d and \u201cDesk\u201d are the same. How about simpler solutions like a mapping between common concepts?\n3.\tSome works like Saycan and RT2 also consider the match of the environment and the agent ability. Key differences between the proposed method and those existing works need to be more carefully discussed.\n4.\tSome failure cases like \u201cput the apple from microwave into the garbage\u201d actually can be correctly planned by ChatGPT with proper prompts."
            },
            "questions": {
                "value": "1.\tThe technical contribution is not clear. The improved feasibility mainly comes from 1) a self-collected and self-labelled dataset and 2) semantic map extracted by an existing work, which seems straightforward. The technical challenges and underlying designs need to be pointed out more clearly.\n2.\tThe significance of the feasibility considered by this paper is not clear. For example, this paper proposes a re-plan module with real-time semantic recognition on failure so that the agent can know \u201cTable\u201d and \u201cDesk\u201d are the same. How about simpler solutions like a mapping between common concepts?\n3.\tSome works like Saycan and RT2 also consider the match of the environment and the agent ability. Key differences between the proposed method and those existing works need to be more carefully discussed.\n4.\tSome failure cases like \u201cput the apple from microwave into the garbage\u201d actually can be correctly planned by ChatGPT with proper prompts."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698458523414,
        "cdate": 1698458523414,
        "tmdate": 1699636783373,
        "mdate": 1699636783373,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MVdIB9eeLK",
        "forum": "x4fm4T2tjM",
        "replyto": "x4fm4T2tjM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_A6GH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_A6GH"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed RoboGPT, a large-language-model driven approach to long-horizon task planning that demonstrates state-of-the-art performance on the challenging ALFRED instruction following benchmark. RoboGPT consists of three main parts: the core RoboGPT planner (a fine-tuned Llama LLM that takes a language instruction and produces a multi-sub-goal plan), the RoboSkill skill execution module (a perception+mapping+planning module that builds a semantic map and executes plan sub-goals), and a Re-Planning module (which uses the semantic map to determine when sub-goals cannot be executed and proposed alternatives). The authors also describe the process by which they generate a 60k-instruction corpus of additional data generated in the ALFRED environment and via human effort with which they fine-tune the Llama LLM. They demonstrate state of the art performance on ALFRED and compare the performance of their approach against competitive LLM-driven baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes an interesting application of large language models to long-horizon task planning and demonstrates state of the art performance on the challenging ALFRED instruction following benchmark. Despite a reliance on significant hand-curated data and subsequent fine-tuning, there is potential for the proposed system to serve as a building block towards more reliable long-horizon planners for open-set household tasks specified in natural language."
            },
            "weaknesses": {
                "value": "**Language and Typos** It is rare that I comment specifically about language or typos in the main body of my review, yet the poor language throughout the paper makes it difficult to understand what is being proposed and how it is being evaluated. For instance, the contributions reference \"the new robotic dataset\", yet it is not clear if this is a dataset provided by the authors. Later on, the nature of this generated dataset and also the ablation studies are ambiguous. The abstract alone contains many typos (\"palnner\", \"low computational\", \"LLMs-based\") and hard-to-understand language constructions (\"RoboSkill individually designed for sub-goals to learn better [...]\"). The planner itself is misspelled in multiple locations: \"RoboGPT agnet\" and \"RobOGPT\". Please proofread before submitting another revision of the manuscript, as the typos and language issues made the paper difficult to follow.\n\n**Clarifying technical contribution and differences between the proposed approach and the state of the art.** There are a few issues in the comparison with the most competitive baseline \"Prompter\"; the biggest potential selling point of the proposed approach over the most competitive baseline \"Prompter\" and so comparison to this method should not be taken lightly.\n\nFirst, it is difficult to establish a clear point of comparison between the two, since they have different perception modules. The Prompter paper includes in its ablation study a version of the planner provided perfect perception, which raises performance by ~15 absolute percentage points (though it is important to note that it is only for the version of the planner that is provided low level language). The ablation study in this paper does not include a variant similar to this one in which the perception is idealized (that may be incorrect; see my questions below). Thus it is somewhat difficult to tell how much the system's performance is hampered by poor perception. Including additional results that address this omission would be incredibly helpful.\n\nSecond, one of the main claimed advantages of the proposed approach is in its ability to generalize to new prompt or task types, yet this is something that does not seem to be demonstrated. It appears that the system is trained on data the includes the new tasks, which makes it somewhat unsurprising that it is able to perform just as well on those as on the tasks from the original ALFRED dataset. By contrast, the Prompter approach cannot succeed on these, likely because its templates do not include the ability to succeed at them, yet this comparison seems unfair. How well would the RoboGPT system have done if not provided \"enriched\" data that includes the five additional tasks introduced by the authors? This is a key point to understand whether or not the system achieves its stated advantages.\n\nRelatedly, it is mentioned that one of the limitations of the Prompter approach is that it is limited to a fixed number of templates and classes. However, the re-planning module in RoboGPT is also only capable of proposing terms that fall within the categories the object detection is trained to detect with the minor addition of a BERT-based similarity score to map open-set outputs to the closed-set entities on which the perception system is trained.\n\nFinally, it seems that the performance of the proposed approach, which is fine tuned on considerable domain-specific data, is fairly similar to that of Prompter, raising questions about when one might use RoboGPT. The authors will need to justify why the proposed approach justifies the additional complexity and training needed to achieve state of the art performance.\n\n*Deeper description of other baselines* The primary point of comparison for the proposed approach is against the LLM-Planner and the Prompter approaches. Though some discussion of these baselines is included in the Appendix, some additional discussion of how they are different, and thus why the proposed RoboGPT method should be able to succeed where they do not, would be a welcome addition to the main body of the paper.\n\nSmaller comments and suggestions for improvement:\n- The Abstract lacks any concrete metrics for success, whose addition would help clarify what the central advance of the paper is. When referencing \"the proposed RoboGPT agent outperforms SOTA methods\", it would be helpful to reiterate that, for example, success rate is a key metric being evaluated.\n- The Appendix compares the performance of the fine-tuned perception model against what seems to be an off-the-shelf Mask RCNN. It is unsurprising that the performance of the system trained specifically in this environment would outperform one that is not and so the language in the text (In Effectiveness of RoboSkill: \"the segmentation and detection of RoboSkill greatly outperform those of others\") is misleading and should be removed."
            },
            "questions": {
                "value": "- The central issue that I would like the authors to clear up is the comparison to the Prompter baseline. I have detailed a couple points above that should be addressed [I will not reproduce that discussion here.]\n- [reproduced from above] It seems that the performance of the proposed approach, which is fine tuned on considerable domain-specific data, is fairly similar to that of Prompter, raising questions about when one might use RoboGPT. The authors will need to justify why the proposed approach justifies the additional complexity and training needed to achieve state of the art performance.\n- What is meant by the Ablation \"without RobotSkill\". As that module is needed to execute sub-goals, how can an ablation be performed in which this module is not provided?\n- Relatedly, how well would the propose RoboGPT system perform if given access to \"perfect\" (ground truth) perception?\n- Can the authors comment on what are the additional five task types that they added to their dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700927973,
        "cdate": 1698700927973,
        "tmdate": 1699636783225,
        "mdate": 1699636783225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "p9iF1dRXYz",
        "forum": "x4fm4T2tjM",
        "replyto": "x4fm4T2tjM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_16gg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6784/Reviewer_16gg"
        ],
        "content": {
            "summary": {
                "value": "This work has three main contributions: 1) a synthetic robot planning dataset with generated instructions and sub-goal samples that are augmented from the ALFRED starting dataset, 2) RoboGPT, a LLM-based high level planner that finetunes on the synthetic dataset in 1) and produces subgoal text instruction plans given a high level text instruction; RoboGPT is claimed to surpass ChatGPT and other methods, and 3) claimed SOTA performance of 2) on the ALFRED benchmark. The synthetic dataset starts with 360 sampled ALFRED plans and uses them as few-shot prompts for an LLM to generate new instruction-plan pairs; in total, there are 7,724 samples generated with this method. The RobotGPT planning agent trains on the 7k synthetic samples in addition to 60k samples from ALFRED. To utilize RoboGPT in the ALFRED benchmark, this work introduces two modules: a RoboSkill module that utilizes perception modules to generate voxel and segmentation masks for querying robot actions, and a Re-Plan module that utilizes VLM object detections to update low-level robot primitives to re-map object names. They demonstrate this combined system on the ALFRED benchmark, and compare against other prompting and planning works."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The method achieves strong performance on ALFRED\n- The new instruction dataset combining ALFRED data with synthetic data is a good contribution for robot planning methods that need to produce language primitive subgoals given a high-level text instruction"
            },
            "weaknesses": {
                "value": "- The core motivating limitations of current zero-shot LLMs at robot planning are not justified. The paper claims that RoboGPT is the first model to understand prefixes, object dependencies, and object quantities; however, simple tests of SOTA LLMs (which are not finetuned on robot data) are able to easily solve these tasks.  I tried to ask ChatGPT as well as Bard to respond to the examples provided in the paper and it works on the very first prompt I use: `You are a robot given an open-ended instruction from a human, please break down the following task into individual steps that you can achieve. Instruction: \"There is a stove and no microwave, how to heat an apple\". Skills you know are \"find\", \"pick\", \"interact with\", \"open\", \"close\", \"place\"`. Similar prompts work for the other cases mentioned. I did no prompt engineering for this. This is highly worrying, and goes against the claim \"RoboGPT with strong generalization ... surpass[es] ChatGPT and other planning methods\". Therefore, this results in two serious issues: 1) the main motivating claim of why RoboGPT is needed is not supported, 2) if anyone today can verify independently that zero-shot LLMs can perform well on the exact examples included in the paper, then the results in Table 1 and Table 2 seem quite dubious.\n- The large performance gains in ALFRED may be attributed to the domain-specific Map() module in Section 3.1 or the visually grounded feedback in Section 3.2; however, from the main contributions, a core claim is the RoboGPT model is better than baselines on high-level instruction to low-level subgoal instruciton prediction. However, it seems that Re-Plan is actually providing the bulk of the gains. In fact, the ablation in Table 1 of \"RoboGPT without Re-Plan\" performs worse than the baselines on some benchmarks, despite \"RoboGPT without Re-Plan\" containing supposedly superior subgoal instruction prediction.\n- The presentation is extremely poor, with a high volume of grammatical and spelling errors. See below for some examples. In addition, the paper is convoluted and quite difficult to follow, with RoboSkill and Re-Plan modules seemingly very separate from the finetuned LLM in RoboGPT, and yet being quite domain-specific modules themselves, yet with few details. In general, the level of polish in the manuscript is extremely far from the level expected in an ICLR publication.\n- There is no explanation of the text to low-level action execution in RoboSkill.\n- The core claim is not clear. Is RoboGPT the finetuned LLM model (based on Introduction)? Or does RoboGPT also include RoboSkill and Map and Re-Plan (based on Table 1)? If RoboGPT includes RoboSkill and Re-Plan, then it needs to be compared/discussed against works that also re-plan (see below).\n- There is no comparison against works that re-plan in robotics, including those that take visual scene information leveraging perception modules. For example, Inner Monologue [1] incorporates re-planning in the form of text-based VLM observations.\n- Minor writing issues (an automated spellchecker may catch additional issues):\n    - Abstract: \"with re-plan\" => \"with re-planning\", \"palnner\" => \"planner\" x2\n    - Introduction: \"detialed\" => \"detailed\", \"object name match\" => \"object name matching\", \"as far as we known\" => \"as far as we know\"\n    - 3.3 RoboSkill: \"and interaction module)\" => \"and interaction module\"\n    - 4 Experiments: \"LLM-Planer\" => \"LLM-Planner\"\n    - 4.2 Ablations: \"RoboGOPT\" => \"RoboGPT\"\n\n\n[1] \"Inner Monologue: Embodied Reasoning through Planning with Language Models\", Huang et al. 2022"
            },
            "questions": {
                "value": "- Clarifications to my questions above will be appreciated and help me better understand the work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698862779321,
        "cdate": 1698862779321,
        "tmdate": 1699636783107,
        "mdate": 1699636783107,
        "license": "CC BY 4.0",
        "version": 2
    }
]