[
    {
        "id": "xPasCHb2nE",
        "forum": "cKIwtXHg4D",
        "replyto": "cKIwtXHg4D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_WwVi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_WwVi"
        ],
        "content": {
            "summary": {
                "value": "The authors describe an optimization algorithm for continuous functions $f:\\mathbb{R^d}\\to \\mathbb{R}$ that draws random samples from the search space using a Latent slice sampler and the probability density from which the samples are drawn is the product of a prior $\\pi(x)$ and the exponentiated objective functions $\\exp(-k\\cdot f(x))$, i.e. an energy based model.\n\nThe authors prove basic properties of the distribution and perform experiments against a range of comparable methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- well written, clear and easy to follow\n- the idea of using the objective function as energy in an energy based model together with an MCMC algorithm and varying temperature is is well justified (and unfortunately has been done extensively before)"
            },
            "weaknesses": {
                "value": "- using the objective as energy in an energy boltzmann distribution (also known as energy based models) for MCMC sampling is an old well established family of methods known as simulated annealing. This paper does not acknowledge simulated annealing nor cite any simulated annealing work (the prior work of Luo 2018 cites one paper for simulated annealing when discussing differential evolution). I feel the proposed framework is not novel. In the simulated annealing literature, $1/k$ is referred to as temperature $T$ and increasing $k$ or reducing $T$ over time is the \u201ccooling schedule\u201d, and as the algorithm \"cools down\", the sampler converges closer and closer to the minima (exactly as described by Theorem 1).\n\n- it is not clear if the methods are using the same number of objective function evaluations. If I understand Algorithm 1 correctly, the objective function is evaluated in line 5, in the condition of the while loop, hence the while loops and thus the number of objective function calls is not deterministic for each iteration of the algorithm. Comparing algorithms by number of iterations when algorithms call the objective a different number of times each is not a fair comparison.\n\n- the proofs are standard results, rewriting the minima distribution in exponential family form $m_k(x) = exp([-k, 1] \\cdot [f(x), \\log(pi(x))]) / Z$, Theorem 2 is a standard result for all exponential family distribution, the gradients with respect to the natural parameters yield moments of the distribution.\n\n- as the temperature of an energy based model is reduced, the distribution tends to delta function around the maximum is well known. In many generative models, increasing the \u201ctemperature\u201d in sampling is synonymous with increasing variety in generated outputs, and decreasing temperature leads to deterministically generating maximum likelihood outputs.\n\n- in my view the framework of ProGO is not new. The use of this particular MCMC Latent Slice Sampler within an simulated annealing algorithm may be new. If so, Standard Metropolis Hasting with a Gaussian proposal and other MCMC methods should be baselines. Even so, a change of MCMC sampler is not sufficient for publication.\n\nI enjoyed the paper and the writing, however, unfortunately I cannot recommend for acceptance."
            },
            "questions": {
                "value": "- do all algorithms evaluate $f(x)$ exactly the same number of times per iteration? the results should plot total numebr of function $f(x)$ calls on the x axis."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4630/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698614325171,
        "cdate": 1698614325171,
        "tmdate": 1699636442349,
        "mdate": 1699636442349,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FxBfiNzxtT",
        "forum": "cKIwtXHg4D",
        "replyto": "cKIwtXHg4D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_jr1B"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_jr1B"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of finding global minimums of non-convex functions. It proposed a new algorithm that does not require the computation of gradients, but rather it depends on sampling from a sequence of distributions $m_k(x)$ that is induced by the objective function $f$. The authors showed that the maximizer of each distribution $x_k^* = \\mathrm{argmax} (m_k(x))$ converges asymptotically to a global minimum, under some separation conditions. In addition, $f(x_k)$ converges to $f^*$ even when the separation condition does not hold. The authors also performed experiments on some non-convex functions and showed that the proposed algorithm converges much faster than other algorithms, like gradient descent etc."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is thoeretically interesting, in that it proposed a new type of optimization algorithms and constructs its (asymptotic) convergence theory. This algorithm provably converges to the global minimum of the objective. Interestingly, they showed that $\\int f(x)m_k(x) dx \\downarrow f^*$, where $m_k(x)$ is a probability measure constructed using $f$. Further, when $x_k^* = \\mathrm{argmax} (m_k(x))$, it holds that $x^*_k \\to x^*$ in $\\ell_2$ distance. \n2. This paper is written clearly and provides useful explanation and intuition."
            },
            "weaknesses": {
                "value": "1. The authors only provides convergence property when the iteration $k$ goes to infinity. It seems promising that the new method out-performs classic algorithms on some functions, but what about the worst-case upper bound? It would be more interesting (and practical) if we have some non-asymptotic results like how many iterations we need to approximate an global minimizer within error $\\epsilon$. If, in the worst case, the algorithm needs $(1/\\epsilon)^d$ calls of function value oracle to find a global min of a (say, lipschitz) function, then it is no better than a brute force search."
            },
            "questions": {
                "value": "1. How many samples does the LSS-ProGo algorithm need to approximate the distribution $m_k(x)$? Especially, in high-dimension scenerios? How accurate this approximation needs to be?\n2. I am wondering what would happen if we use Gaussian as $\\pi(x)$ instead of uniform distribution. Will that bring us better results?\n3. In addition, when the set $\\Omega$ is unbounded, like $R^d$, how to construct a uniform distribution on this set $\\Omega$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4630/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727868425,
        "cdate": 1698727868425,
        "tmdate": 1699636442259,
        "mdate": 1699636442259,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XWHxcYOl8J",
        "forum": "cKIwtXHg4D",
        "replyto": "cKIwtXHg4D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_dC7R"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_dC7R"
        ],
        "content": {
            "summary": {
                "value": "The authors present a new probabilistic global optimization algorithm called ProGO, which relies on the theory of nascent minima distribution by Luo (2018) and the latent slice sampler. This method departs from traditional gradient-based approaches by ensuring reliable convergence to global optima without the need for gradient information, while still maintaining computational efficiency. They extend Lou\u2019s framework to accommodate noncompact sets and demonstrate its global convergence. The ProGO algorithm is then developed based on this extended framework, and it incorporates a latent slice sampler to improve computational efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1)\tPropose a novel derivative-free optimization algorithm for global optimization with convergence guarantee. \n\n2)\tExtend the framework proposed in Luo (2018) to non-compact constraint sets and analyze its global convergence.\n\n3)\tProvide some promising experimental results."
            },
            "weaknesses": {
                "value": "1)\tIn order to apply the proposed algorithm, the optimal function value $f^*$ is supposed to be known. The assumption is not true for many practical applications.\n\n2)\tThe algorithm is only tested on two test instances, which can be efficiently solved by a number of existing derivative-free optimization algorithms. More experiments are expected to convince the performance benefit of the algorithm, for example, see \u201cN. Hansen, A. Auger, R. Ros, O. Mersmann, T. Tu\u0161ar, D. Brockhoff. COCO: A Platform for Comparing Continuous Optimizers in a Black-Box Setting, Optimization Methods and Software, 36(1), pp. 114-144, 2021\u201d \n\n3)\tThe performance of the algorithm heavily depends on the efficiency of the latent slice sampler  applied to the nascent minima distribution $m_k$."
            },
            "questions": {
                "value": "1)\tHow to calculate the denominator of Equations (2) and (3) for a general black-box $f(x)$?\n\n2)\tIn Algorithm 2, why we don\u2019t use only a single large value for $k$? In Line 3, is $x^{(0)}$ that same for every t-th iteration? I don\u2019t see any interaction between iterations; that is, the information of $x^{(1)}, \u2026, x^{(N)}$  is not reused in next steps. \n\n3)\tIn Line 7 of Algorithm 2, $x$ is a vector, $x_j$ is a scalar, what does it mean by $x < x_j$? \n\n4)\tWhat is the impact of selecting $k$ in Eq. (3) on the solution quality? What should the appropriate value for $k$?\n\n5)\tIn Algorithm 2, why we need to fix $T = 200$?\n\n6)\tWhat are stopping criteria for ProGO and other baseline methods used in Section 4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4630/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698779934951,
        "cdate": 1698779934951,
        "tmdate": 1699636442177,
        "mdate": 1699636442177,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oRSGByc3Pl",
        "forum": "cKIwtXHg4D",
        "replyto": "cKIwtXHg4D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_vc8T"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4630/Reviewer_vc8T"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a gradient-free numerical algorithm to solve the global optimization problem. The algorithm is probabilistic, designed to sample from a sequence of probability distributions that converge to a distribution supported on the global minima set. The sequence of distributions $m_k(x)$ is constructed by weighing a uniform probability distribution by exponential of the objective function $\\exp(-kf(x)$ for increasing $k$. The proposed algorithm is illustrated and compared on several numerical examples, demonstrating its efficiency and accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is nicely written with clear presentation and explanations of the contributions. \n- The proposed algorithm is supported by theoretical asymptotic convergence results. \n- The numerical experiments report strong support for the efficiency and accuracy of the algorithm in comparison with several approaches."
            },
            "weaknesses": {
                "value": "- Although the algorithm is based on the convergence of m_k, the rationale behind the proposed sampling procedure for m_k is not clear. \n -There is no non-asymptotic analysis that relates the number of function evaluations with the optimality gap. \n- Although theoretical result is nice, it does not explain why this algorithm performs better than alternative approaches. As a result, two numerical experiments might not be sufficient to support the paper's claim. \n- The paper misses discussing model-based optimization algorithms as in [1]. Similar theoretical convergence results exists in this and other papers. For example, see Thm. 3 in [2]. The convergence holds under weaker assumptions for the objective function: lower-semicontinuous instead of continuous; and the strong separable condition seems to hold (see the discussion in Appendix C of [2]). \n\n[1] Hu, Jiaqiao, et al. \"A survey of some model-based methods for global optimization.\" Optimization, Control, and Applications of Stochastic Systems (2012): 157-179.\n\n[2] Zhang, Chi, Amirhossein Taghvaei, and Prashant G. Mehta. \"A mean-field optimal control formulation for global optimization.\" IEEE Transactions on Automatic Control 64.1 (2018): 282-289."
            },
            "questions": {
                "value": "Please see my comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4630/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791329891,
        "cdate": 1698791329891,
        "tmdate": 1699636442094,
        "mdate": 1699636442094,
        "license": "CC BY 4.0",
        "version": 2
    }
]