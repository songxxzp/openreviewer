[
    {
        "id": "zIiCqDRTLG",
        "forum": "9Z0yB8rmQ2",
        "replyto": "9Z0yB8rmQ2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
        ],
        "content": {
            "summary": {
                "value": "This paper presents Lyra, an automated system integrating large language models for autoformalisation and symbolic tools such as sledgehammer in proof assistants. The two core components, Tool Correction and Conjecture Correction, are critical for its achieving SoTA performance on the miniF2F benchmark."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed mechanism makes good intuitive sense. The performance improvement is impressive on the miniF2F benchmark. The ablation studies are well-presented and convincing."
            },
            "weaknesses": {
                "value": "There needs to be more contextualisation of the prior works. For the two major correction mechanisms, there have been direct prior works doing very similar or even identical things.\n- Tool correction: in the DSP work [1], the authors already used sledgehammer + heuristics to close conjectures made. The understanding is that the Lyra method first tries a LLM-generated tactic to close conjectures, and if it doesn't work, try sledgehammer. This is largely similar and should be noted.\n- In the Baldur work [2] from April 2023, the authors have proposed to use the proof assistant error message to repair the proofs. This is very similar to the conjecture correction with error messages and should be noted.\n\n[1] Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothee Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, and Yuhuai Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, 2023.\n\n[2] First, Emily, Markus N. Rabe, Talia Ringer, and Yuriy Brun. \"Baldur: whole-proof generation and repair with large language models.\" arXiv preprint arXiv:2303.04910 (2023)."
            },
            "questions": {
                "value": "None."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697905258318,
        "cdate": 1697905258318,
        "tmdate": 1699636036040,
        "mdate": 1699636036040,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YEOpjgUdxZ",
        "forum": "9Z0yB8rmQ2",
        "replyto": "9Z0yB8rmQ2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a couple of approaches, namely Tool Correction (TC) and Conjecture Correction (CC), for improving the performance of LLM-guided autoformalization techniques based on the Draft-Sketch-Proof (DSP) paradigm. TC is a post-processing technique---once the LLM generates a formal proof sketch, the proof is fed to an Interactive Theorem Prover (ITP) and if the ITP returns an error, then TC uses simple heuristics to replace the tactics in the incorrect formal proof sketch one-by-one. CC, on the other hand, incorporates the error message from the ITP and generates a new prompt that includes the previous proof attempt and the error message. This interaction between the LLM and ITP is conductive up to 5 times. The proposed extensions to DSP are evaluated on the miniF2F benchmark and lead to improved proof success rates."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The techniques lead to an improvement over the state-of-the-art.\n2. I find it a little surprising that models like GPT-4 and Codex are able to understand and act based on the error messages from Isabelle. Unfortunately, the paper does not explore this surprising observation in depth.\n\n-----------------------------\nRating updated to 5 after discussion. Overall, I remain unconvinced by the technical contribution of TC but I find the empirical phenomenon of LLMs being able to interpret ITP error messages interesting\n\n-----------------------------\nRating further updated after much discussion about the general applicability of TC to 6. In particular, the authors presented evidence that TC helps improve performance on another dataset, namely, LISA."
            },
            "weaknesses": {
                "value": "1. I am not an expert in the area so it is possible that the empirical results might be surprising to experts in a way that I am unable to appreciate. However, I find that the techniques used to achieve the state-of-the-art results do not involve any significant technical or empirical insights.\n\n2. The heuristics used in TC seem too specific to the task and dataset. Are the heuristics used for TC transferable to other theorem proving tools and datasets? How do we know that these heuristics are not overfit to the miniF2f dataset? Do these heuristics represent some general insight into how mathematical theorems ought to be proved?\n\n3. CC simply incorporates the ITP error message into the prompt. On a technical level, this is an obvious idea that has been tried before for proof generation [1] and code generation [2,3]. Some of these approaches require fine-tuning the model, so the scientific question to be evaluated here is does incorporating error feedback without any fine-tuning help **in general** for autoformalization. Since models such as Codex and GPT-4 are not explicitly trained on the error messages from ITPs, one would not expect simply providing the error messages in the prompts to be generally helpful. While the empirical results here suggest that error messages help when the ITP is Isabelle, it remains to be evaluated if it is helpful with other ITPs. It would also be useful to analyze the nature of the error messages generated by Isabelle. Do the improvements depend on the quality of the error messages? One would expect so but this would be another useful aspect to empirically evaluate.\n\n[1] First, E., Rabe, M. N., Ringer, T., & Brun, Y. (2023). Baldur: whole-proof generation and repair with large language models. arXiv preprint arXiv:2303.04910.\n\n[2] Le, H., Wang, Y., Gotmare, A. D., Savarese, S., & Hoi, S. C. H. (2022). Coderl: Mastering code generation through pretrained models and deep reinforcement learning. Advances in Neural Information Processing Systems, 35, 21314-21328.\n\n[3] Wu, X., Cheriere, N., Zhang, C., & Narayanan, D. (2023). RustGen: An Augmentation Approach for Generating Compilable Rust Code with Large Language Models."
            },
            "questions": {
                "value": "1. Are the presented techniques overfit to miniF2F dataset and Isabelle? In particular, I am afraid this might be the case for TC.\n\n2. Would CC work with the error messages from a different ITP? How much does the availability of formal proofs and error messages for a particular ITP affect the effectiveness of CC?  How much does the quality of the error message affect CC?\n\n3. There are number of spelling errors in Algorithm 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1096/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1096/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772919304,
        "cdate": 1698772919304,
        "tmdate": 1700553518263,
        "mdate": 1700553518263,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "R3jZBvFWYw",
        "forum": "9Z0yB8rmQ2",
        "replyto": "9Z0yB8rmQ2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an LLM-augmented automated theorem proving framework called Lyra in a formal theorem proving environment. The distinguishing features of Lyra include Tool Correction (TC) and Conjecture Correction (CC), which respectively post-edit formal proofs emitted from LLMs given feedback from the proving environment. Good performance has been shown over the miniF2F dataset with 3 IMO problems being solved."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written with a clear illustration of its two contributions TC and CC. I especially appreciate the ablation study where Lyra downgrades to DSP without TC and CC. The performance gain also looks good."
            },
            "weaknesses": {
                "value": "Although I very much like the idea of CC, the innovation of TC appears slightly limited. At least to me, it does not involve much interaction with LLMs -- it is more like an exhaustive attempt on a set of heuristically chosen proof methods other than Sledgehammer."
            },
            "questions": {
                "value": "- page 1, 'However, they have not been able to post-process LLM generation or gradually refine previous generations.': The Baldur paper (https://arxiv.org/abs/2303.04910) has explored post-processing LLM-generated proofs. I would love to see a comparison between Baldur and Lyra if possible.\n- This paper is mostly based on the previous DSP paper, where LLMs are used to produce proof skeletons (i.e., unproved conjectures). In the tool correction part, it appears that LLMs are prompted to produce a full mechanised proof including the tactic 'by (simp add: div mult mod eq)', which is considered as LLM hallucination by the authors. Is that the case? If so, it might be a good idea to make the distinction clear as this may affect the ablation study. \n- Figure 3, the informal proof and the formal sketch are actually quite different. For example, the formal one does not cover continuity nor limit, which have been mentioned several times in the informal proofs. I was wondering if the authors could elaborate a bit on the discrepancy between the informal proof and the formal one.\n\nminor\n- page 3, 'conducted on LLLMs' -> 'conducted on LLMs'\n- page 5, 'As all formal proof begins with proof -': strictly speaking this is not quite true, as some Isabelle proofs start with 'proof (...)' or 'apply (...)', where ... can be some Isabelle tactics."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791868112,
        "cdate": 1698791868112,
        "tmdate": 1699636035896,
        "mdate": 1699636035896,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AwfBTIhIrF",
        "forum": "9Z0yB8rmQ2",
        "replyto": "9Z0yB8rmQ2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_Wc5t"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1096/Reviewer_Wc5t"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes two methods for postprocessing and fixing the errors in the proof steps generated by LLM for theorem proving. The first method is Tool Correction, which tries a list of automation tactic such as sledgehammer, auto and arith on the fails steps. The second method is Conjecture Correction, which asks LLM to regenerate the proof step based on the error message or simply regenerate this step to start a new iteration. Experiments show that TC and CC could improve the performance significantly on the miniF2F valid (50.4%->55.3%) and test set( 42.6%->51.2%), and achieves the new state-of-the-art results."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Both Tool Correction and Conjecture Correction are technically sound. Tool Correction implies the insights that LLM is better at generating the next conjecture to prove than closing the conjecture. Extensive search is helpful to close the conjecture."
            },
            "weaknesses": {
                "value": "The paper doesn't have much novelty in terms of the approach. It seems that the set of 11 tactics in TC have been proposed in DSP. The method of appending error message for self-debugging and generating multiple candidates have been commonly used for code generation."
            },
            "questions": {
                "value": "1 I think one good baseline would be replace Minerva and Codex in DSP with GPT4. So we still have GPT4 to generate the proof sketch (the intermediate conjectures) but use 11 tactics + sledgehammer to close the open goals. \n2 Could you calculate the number of wrong proof steps fixed by each tactic in TC?\n3 The proposed method adds a lot more computation. How much time would be token by calling GPT4, TC and CC? If we set a time limit for each question like 10 or 30 minutes, what would be the performance of TC/CC compared with the GPT4 baseline and DSP+GPT4 baseline?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concern."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699046111527,
        "cdate": 1699046111527,
        "tmdate": 1699636035812,
        "mdate": 1699636035812,
        "license": "CC BY 4.0",
        "version": 2
    }
]