[
    {
        "id": "1muP84b6NR",
        "forum": "qi5Xa2cOZg",
        "replyto": "qi5Xa2cOZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_4L8o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_4L8o"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an LLM-based approach to mask out task-irrelevant objects in visual observations to improve imitation learning. The resulting \u201cabstract states\u201d - observations with only task-relevant features, enables training behavior cloning policies with better data efficiency and generalization. The method is straightforward: taking a task specification and the observed object information as input, a pretrained LLM is leveraged to remove irrelevant objects. Optionally, the authors recruited human subjects to refine the LLM output or identify irrelevant objects from scratch as ablations.\nThe authors evaluate the proposed approach on the VIMA[1] benchmark, comparing it with behavior cloning policies trained with various forms of state abstractions. The results indicate that the proposed method: 1) enhances data efficiency and success rate while requiring less human efforts; and 2) can generalize to unseen object textures, distractor objects, and task specifications.\n\n[1] Jiang, Yunfan, et al. \"Vima: General robot manipulation with multimodal prompts.\" ICML 2023."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea to leverage the semantic reasoning ability of LLMs to identify task-relevant features is interesting and innovative. The approach of masking out irrelevant objects does prevent learning robot policies harmed by spurious correlations.\n2. The paper is written clearly and easy to follow.\n3. The paper includes comprehensive experiments to demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. The primary weakness of the paper lies in the absence of a lack of substantial technical contribution. While the proposed strategy mitigates the issue of spurious correlations, it appears more as a choice of system design to generate heuristics rather than a fundamental method to identify useful state features. Notably, the importance of state features not only depends on task semantics, but also the low-level geometric constraints imposed by the environment and robot embodiment. For example, some objects not mentioned in the task specification may be important for robot collision avoidance. Consequently, the learning of important state features and motion policies are coupled and should ideally be learned together, such as in VIOLA [2].\n2. Another drawback is that the imitation learning setup is overly simplified . The use of VIMA [1] benchmark, which employs high-level primitive actions like \u201cpick\u201d and \u201cplace\u201d with continuous goal poses, significantly simplifies the training of a behavior cloning policy. Given that the major objective is to assess the proposed state abstraction in imitation learning, it would be advisable for the authors to consider a more rigorous robot manipulation benchmark with continuous actions, such as RoboSuite [3].\n3. State abstraction is a fundamental problem in decision making. I think it would be helpful for the readers to understand the context better if the authors refer and discuss the related literature (such as [4,5]).\n\n\n[2] Zhu, Yifeng, et al. \"Viola: Imitation learning for vision-based manipulation with object proposal priors.\" CoRL 2022.\n[3] https://robosuite.ai/\n[4] Li, Lihong, Thomas J. Walsh, and Michael L. Littman. \"Towards a unified theory of state abstraction for MDPs.\" AI&M 2006.\n[5] Tomar, Manan, et al. \"Model-invariant state abstractions for model-based reinforcement learning.\" ICLR 2022."
            },
            "questions": {
                "value": "Regarding the observation input to behavior cloning in LGA, do you use the binary mask directly (as visualized in Figure 1) or the masked image? If you use the former one, I wonder how the latter one works."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Reviewer_4L8o",
                    "ICLR.cc/2024/Conference/Submission4142/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698221616596,
        "cdate": 1698221616596,
        "tmdate": 1700619811016,
        "mdate": 1700619811016,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bhp6zfd8cP",
        "forum": "qi5Xa2cOZg",
        "replyto": "qi5Xa2cOZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_PEPS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_PEPS"
        ],
        "content": {
            "summary": {
                "value": "This work presents a method LGA that leverages language models to compose abstract states for few-shot imitation learning. Visual RGB observations are first segmented and textualized into features that a language model is then tasked to filter conditioning on the language instruction. The policy is then trained with such abstract visual state.\n\nExperiments in a simulated benchmark shows the proposed method outperforms naive baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This work presents an intuitive and simple idea that is shown to be powerful for few-shot imitation learning of policies that are specifically designed to generalize across variations of color and texture.\n\nThe proposed method leverages the commonsense reasoning capabilities of large language models for reducing the task complexity for imitation learning, which is an exciting application of pretrained language models in robotics."
            },
            "weaknesses": {
                "value": "Conceptually, the idea of using visual masks as attention or part of state representation isn\u2019t novel and has been explored in various prior works including recent ones such as robotmoo[1] and VIOLA[2].\n\nFeature abstraction of LGA takes a filtering approach that relies on segmentation and textualization operates at the desired abstraction level and is complete. For example, language instruction can be about a group of objects, the object as a whole or only part of an object and it is unclear how to segment or group segmentations before we know the task. \nAn alternative approach to filtering would be leveraging open-vocabulary object detectors or VLMs for identifying the target objects like in recent works using LLMs for planning, which the paper didn\u2019t ablate. \n\nUsing binary masks as state representation seems to be limiting and can hurt in tasks where the texture or details of the object matters, maybe the language model should decide if the binary mask or original state should be used or not based on the context. On a similar note, it seems from the results LGA-S performs better anyway?\n\nAt the same time the background might be important landmarks for the robot to understand relative size. For example if the robot is learning to visually navigate to certain objects, this proposed method would fail if the model removes all the background necessary for the robot to localize itself. \n\nThe authors should explicitly discuss assumptions and limitations of the method to specific types of tasks/settings.\n\n[1] https://robot-moo.github.io/ \n[2] https://ut-austin-rpl.github.io/VIOLA/\n\n\n\n---Edit----\n\nThe rebuttal addressed some of my initial concerns and I appreciate the response and explanation from the authors. I do think demonstrating the failure modes of LGA and discussing the limitations is as important as showing the positive results. \n\nI am happy to raise my evaluation but won't argue strongly for acceptance."
            },
            "questions": {
                "value": "It seems LGA relies heavily on the segmentation and captioning module. How well does these systems work? What are some common failure modes? Can the robot arm be successfully segmented?\n\nDoes LGA or the instantiation assume full observability? or does it run segmentation and feature extraction on each and every frame? this seems expensive given the size of SAM \n\nHow good is the language model at guessing relevant objects if they are not explicitly mentioned in the language instruction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Reviewer_PEPS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698697743672,
        "cdate": 1698697743672,
        "tmdate": 1700436439590,
        "mdate": 1700436439590,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8V5E0BQrE6",
        "forum": "qi5Xa2cOZg",
        "replyto": "qi5Xa2cOZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_rEzX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4142/Reviewer_rEzX"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the Language-Guided Abstraction (LGA) framework, which utilizes natural language to construct state abstraction for imitation learning. The method comprises three key steps: First, in the textualization phase, it transforms raw perceptual input into a text-based feature set. Second, during the state abstraction step, a pre-trained language model is employed to filter out irrelevant features from the feature set, creating task-specific state abstractions. Finally, in the instantiation stage, the reduced abstracted feature set is converted into a format understandable by the policy, such as an observation displaying only the pertinent objects."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "LGA avoids spurious correlations by highlighting goal information in semantic maps, not raw pixels. LGA converts language and observations into unambiguous states to enhance policy adaptability. This is especially important when only limited training data is available. The integration with Language Models enables contextually appropriate task-relevant feature selection, boosting the overall policy generalization and performance at test time.\n\nThe experiment results demonstrate that LGA reduces the time needed for feature specification compared to manual methods, yet outperforms non-abstraction-based baselines in terms of sample efficiency. Policies trained using LGA's state abstractions exhibit resilience to observational shifts and language variations. In multi-task scenarios, LGA effectively resolves task ambiguities and adapts to new language specifications in observations."
            },
            "weaknesses": {
                "value": "There appears to be a gap in the evaluation regarding task failures\u2014whether they stem from policy quality or incorrect state abstraction remains unclear. The experiment results do not specify how frequently the language model predicts insufficient or redundant state abstraction, and whether refining its choices with feedback from policy execution is a feasible solution remains unexplored.\n\nThe paper appears to overlook extensive research on learning state abstraction for reinforcement learning, including notable works such as \"Approximate State Abstraction\" (ICML 2016), \"State Abstraction In Lifelong RL\" (ICML 2018), and \"State Abstraction As Compression\" (AAAI 2019)."
            },
            "questions": {
                "value": "Can you categorize task failures into two groups: those caused by policy quality and those resulting from incorrect state abstraction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4142/Reviewer_rEzX"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698894828822,
        "cdate": 1698894828822,
        "tmdate": 1699636379464,
        "mdate": 1699636379464,
        "license": "CC BY 4.0",
        "version": 2
    }
]