[
    {
        "id": "ajAk6UmiWt",
        "forum": "xle26hcxHh",
        "replyto": "xle26hcxHh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_n97E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_n97E"
        ],
        "content": {
            "summary": {
                "value": "Aiming to solve the domain generalization problem in the case of inaccessible source domains, the authors propose AudoFormer which dynamically evaluates consistent labels and consistent neighbors through ADM blocks. and realizes sample alignment using CMK- MMD"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Uses VIT instead of CNN as backbone, fewer previous studies have used VIT for this purpose.\nScore the samples by multiple consistency strategies to further categorize them into simple and difficult samples.\nUse CM K- MMD to align difficult samples with simple samples."
            },
            "weaknesses": {
                "value": "Not innovative enough, it's all stuff that's already been proposed before, and only one alignment module is self-proposed.\nLack of ablation experiments to analyze the effect of the three modules proposed by ourselves"
            },
            "questions": {
                "value": "Is it possible to add a proof-of-validity analysis of the three modules in the ablation experiment"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6780/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697950248376,
        "cdate": 1697950248376,
        "tmdate": 1699636782675,
        "mdate": 1699636782675,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LAbCuEwMQ6",
        "forum": "xle26hcxHh",
        "replyto": "xle26hcxHh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_2ckR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_2ckR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for source-free domain adaptation. They utilize the Transformer model as the backbone for the training. In addition, the intermediate layer features are aggregated and considered as auxiliary domain representations. They then align the source-like with the target-specific samples by conditional guided multi-kernel max mean discrepancy (CMK-MMD), which guides the hard samples to align the corresponding easy samples.  Some experimental evaluation validates the good results of the method in source-free domain adaptation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper's writing is generally sound, with clear expressions.\n2. The proposed methods are interesting, which consider the intermediate layers as a kind of representation of the auxiliary domain, and try to align them to the target domain.\n3. The pseudo-label processing technique is novel, which plays a critical role in alignment of different domains."
            },
            "weaknesses": {
                "value": "1. The paper's organization confuses me sometimes, for example, 2.3.2 and 2.2.3 should be in the same section, perhaps.\n2.  There is a critical weakness of this paper, I have not found the ablation studies for each component/strategy of the proposed method, which makes it difficult to evaluate how strong these methods are. \n3. I guess, the alignment with pseudo-labels is strong enough, is it possible to say that MMD alignment is not necessary?"
            },
            "questions": {
                "value": "1. I suggest the paper add a thorough analysis of each component, and ablation studies should be included. \n2. Qualitative evaluation is needed.\n3. Which one is stronger? MMD alignment or pseudo-label-based alignment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Reviewer_2ckR"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6780/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698542022685,
        "cdate": 1698542022685,
        "tmdate": 1699636782545,
        "mdate": 1699636782545,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nhNOSRy8vQ",
        "forum": "xle26hcxHh",
        "replyto": "xle26hcxHh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_QH22"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_QH22"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a model called AudoFormer to address the issue of obtaining invariant feature representations by domain consistency in SFDA. In the pre-training phase, the model employs a Visual Transformer (ViT) as the backbone and trains an Auxiliary Domain Module (ADM) based on the global attention features from the intermediate layers of the feature extractor to generate diverse representations. During the domain adaptation phase, this paper utilizes a consistency strategy to categorize target samples into \"source-like\" easy samples and \"target-specific\" hard samples, based on both the auxiliary domain and the target domain. It then optimizes their pseudo-labels to reduce the impact of noise. Finally, it aligns the hard samples with their corresponding easy samples using CMK-MMD. Experiments are conducted on three datasets, i.e., Office-31, Office-Home, and VISDA-C, to show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "#Originality\nThis paper introduces an Auxiliary Domain Module (ADM) block for the ViT backbone, addressing the inherent limitations of inductive bias and enabling the generation of diverse representations from global attention. These diverse representations are used to construct an auxiliary domain. Subsequently, the approach treats features mapped by consistent labels as invariant features, effectively tackling one of the most challenging issues in SFDA. Additionally, the paper leverages a dynamic strategy to calculate the initial centroid of each category, thereby mitigating the interference caused by noise. Furthermore, the self-supervised loss is applied to align samples with the same label in different spaces, enhancing the consistency discrimination from multiple dimensions. To achieve even better domain adaptation, this paper introduces CMK-MMD. This variant enhances the hard feature representation.\n\n#Quality \nThis paper conducts experiments on benchmarks of varying sizes. In all three sets of experiments, the proposed method in this paper outperforms other experiments listed. Furthermore, the supplementary documentation includes an ablation study on the ADM module and the consistency strategy, demonstrating their effectiveness in improving performance. The paper also provides visual insights by employing attention maps and t-SNE to visualize various methods, substantiating the efficacy of the proposed approach.\n\n#Clarity\nThe clarity of this paper is relatively high.\n\n#Significance\nThis paper introduces a novel approach that applies Transformer-based methods to the challenging problem of Source-Free Domain Adaptation (SFDA). By leveraging an Auxiliary Domain Module, it effectively mitigates the impact of inductive bias, overcomes limitations imposed by the convolutional neural network's receptive field, and preserves both global and local features. This, in turn, enhances the model's ability to extract semantic information. Furthermore, the paper presents a methodology rooted in the consistency principle between the auxiliary domain and the target domain, enabling the extraction of invariant features."
            },
            "weaknesses": {
                "value": "Experiment: It would be beneficial to include comparisons with more recent models. As of 2023, recent papers have demonstrated an average accuracy of around 90.0 on the VisDA-C dataset. However, most of the methods compared in this paper are from 2021 or earlier, with only a few from 2022. This leaves the paper lagging behind in terms of benchmarking against the most up-to-date approaches. Additionally, it would be worthwhile to provide a more comprehensive exploration of the effectiveness of the improvements made to MMD and the centroid evaluation calculation methods. Demonstrating the impact of these enhancements on the experimental results would further strengthen the paper.\nAn experiment on Domain-Net, one of the largest DA datasets, is required but missing.\n\nInnovation: The optimization methods for pseudo-labels and the techniques for reducing distribution loss are fairly standard and well-established. While there are some modifications introduced in the paper, their effectiveness hasn't been convincingly demonstrated.\n\nDetails: There are several issues with the visual representation in the paper. On the third page, the color for \"category centroid\" and \"category dynamic centroid\" in the overall workflow diagram of AudoFormer is not very intuitive. Additionally, the arrows between the \"consistency strategies\" module and the \"align the target-specific to source-like\" module seem to depict data flow direction, but the legend indicates that the left arrows represent the \"back loss.\" On the second page, there is a typographical error in the third-to-last line, where \"source-like\" is misspelled. In section 3.2.2 on the eighth page, there is a spelling error in the term \"AudoFormer.\" Furthermore, on the thirteenth page, the title of Table 4 contains a spelling error for \"ADM.\"\n\nContent: One notable aspect that could improve the paper is the inclusion of a more comprehensive introduction to the related work. By providing a thorough survey of existing research and methodologies in the same domain, the paper could offer readers a clearer understanding of where the proposed approach fits within the broader context of the field. This would not only enhance the paper's background but also help readers appreciate the novelty and significance of the presented work."
            },
            "questions": {
                "value": "Besides the weaknesses above, what are the advantages of using an auxiliary domain and consistency-based methods to distinguish between \"source-like\" and \"target-specific\" samples, compared to the traditional approach that relies solely on entropy levels for differentiation?\n\n\n\n----------after rebuttal-----------\n\nThank the authors for providing the rebuttal. This paper received four \"marginally below the acceptance threshold\". The reviews have various concerns, such as motivation, novelty, and ablation study. I think the paper might not be suitable to be accepted in its current format."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6780/Reviewer_QH22"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6780/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698555980375,
        "cdate": 1698555980375,
        "tmdate": 1700721625782,
        "mdate": 1700721625782,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HrNE2xe1GA",
        "forum": "xle26hcxHh",
        "replyto": "xle26hcxHh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_JA6w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6780/Reviewer_JA6w"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces AudoFormer, an efficient transformer-based model for SFDA, which leverages an auxiliary domain module to obtain diverse representations and employs consistency strategies to distinguish invariable features, ultimately achieving superior performance on benchmark datasets compared to existing methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper first solves SFDA problem from a new perspective by domain consistency.\n- This paper aligns the source-like with target-specific samples by CMK-MMD to improve the alignment effect of the domain adaptation.\n- Extensive experiments are conducted on three benchmark datasets to show its SOTA performance."
            },
            "weaknesses": {
                "value": "- Motivation is not clear. The last two sentences of the first paragraph on page 2 (\"Intuitively, if ...... layer features.\") do not have a direct cause-and-effect relationship. Why should we turn to intermediate layer features for emulating the invariant features? And the \"Intuitively\" also lacks clear explanations.\n- Lack of novelty. For instance, dividing target samples into easy and hard parts is proposed by [1], and consistency between neighborhoods is proposed by [2].\n- The use of CMK-MMD is not clarified. There are lots of methods for constructing invariant feature representations across different domains, but no one is compared to used CMK-MMD.\n- More experiments and results are needed. While ViT is a stronger backbone to ResNet, and SFDA-DE and TransDA can be equipped with ViT, why don't conduct experiments on it? Besides, recent commonly used DomainNet should be included, and more ablation studies are needed.\n\n[1] Divide and Contrast: Source-free Domain Adaptation via Adaptive Contrastive Learning\n[2] Exploring Domain-Invariant Parameters for Source-Free Domain Adaptation"
            },
            "questions": {
                "value": "See the weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6780/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699217959848,
        "cdate": 1699217959848,
        "tmdate": 1699636782241,
        "mdate": 1699636782241,
        "license": "CC BY 4.0",
        "version": 2
    }
]