[
    {
        "id": "BQlIld5cGw",
        "forum": "QqdloE1QH2",
        "replyto": "QqdloE1QH2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_rYoT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_rYoT"
        ],
        "content": {
            "summary": {
                "value": "This work translates formal problem descriptions into informal descriptions in natural language with GPT-4, and demonstrates on two standard benchmarks that the collected data is helpful to improve autoformalization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Significant improvement of the performance on autoformalization."
            },
            "weaknesses": {
                "value": "The scope and novelty is limited.\nThis paper can be viewed as a back-translation version of Fu et al. (ICML 2023; see below for reference details).\nThe proposed method is generic, but only evaluated on the narrow domain of autoformalization.\n\n### Missing References\nThree lines of related work are almost completely missing.\nRepresentative work in each line is listed below.\nPlease conduct a literature search using the papers below as starting points and cite relevant papers in their references.\n1. **Model distillation** \\\n    Fu et al. Specializing Smaller Language Models towards Multi-Step Reasoning. ICML 2023\n\n2. **Mathematical and logical reasoning with LLMs, and related work that involves multiple (natural) languages** \\\n    Cobbe et al. Training verifiers to solve math word problems. 2021 arXiv preprint: 2110.14168 \\\n    Lewkowycz et al. Solving Quantitative Reasoning Problems with Language Models. NeurIPS 2022 \\\n    Shi et al. Language Models Are Multilingual Chain-of-Thought Reasoners. ICLR 2023\n\n3. **Executable program as formalisms of natural language** \\\n    In addition to OpenAI's Codex, the following work is also worth checking:\\\n    Yu et al. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task. EMNLP 2018 \\\n    Austin et al. Program synthesis with large language models. 2021 arXiv preprint: 2108.07732 \\\n    Fried et al. InCoder: A Generative Model for Code Infilling and Synthesis. ICLR 2023\n\n### Minor Comments and Typos\nTerm consistency needs double check: for example, both *formalisation* and *formalization* appear in the paper."
            },
            "questions": {
                "value": "- Have you also checked potential data contamination issues? For example, would it be possible that GPT-4 has seen the test data in the evaluation benchmarks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2851/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698708132923,
        "cdate": 1698708132923,
        "tmdate": 1699636228860,
        "mdate": 1699636228860,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5uuhB6jJEc",
        "forum": "QqdloE1QH2",
        "replyto": "QqdloE1QH2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_1cNi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_1cNi"
        ],
        "content": {
            "summary": {
                "value": "This paper describes the creation of a parallel dataset for informal natural-language mathematical statements and their formal counterparts in two proof-assistant languages. The dataset, the largest of its kind, is creating using the technique of back-translation. The paper then uses this dataset to fine-tune a LLM on the task of formalizing natural-language statements, which improves its performance a lot (compared to 0%)."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is an important problem, and the dataset will be helpful for many others working in this area. The dataset is the largest of its kind by far.\n\nIn the introduction, the fact that the dataset covers multiple formal languages does not necessarily sound like a selling point to me, until you point out that training a model on multiple formal languages helps. I think this is a strong point that could be emphasized more (if I understand it correctly, see below under Questions)."
            },
            "weaknesses": {
                "value": "I feel that the word \"Multilingual\" is confusing because it sounds like it works on multiple natural languages. However, I admit that \"multi-formal-language\" is awkward.\n\nThe data is automatically generated by back-translation (\"informalization\"). This is good because informalization appears to be an easier task than formalization and because it's more important for the target (formal language) side of the data to be high quality. However, it also does mean that the source (natural language) side of the data might not be correct or might not be as realistic as it could be. As the authors note, \"the resulting MMA dataset is not perfect: Rather than the ground truth, informalisations in MMA should be treated as noisy approximations of it.\""
            },
            "questions": {
                "value": "It's possible that I misunderstood the claim that training on mixed-language data helps. I did not understand the sentence \"We emphasise that the jointly fine-tuned model has seen 3/4 Isabelle and 1/4 Lean4 tokens of the monolingual models, and conclude that fine-tuning with multiple formal languages is much more data-efficient than with single-formal-language autoformalization data\" (p.6). The jointly fine-tuned model has a greater total amount of data, right? How many steps are in an epoch? By 40000 steps, has the jointly fine-tuned model seen more examples than the Lean4-only and Isabelle-only models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2851/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797728180,
        "cdate": 1698797728180,
        "tmdate": 1699636228795,
        "mdate": 1699636228795,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5nfO8XiGGu",
        "forum": "QqdloE1QH2",
        "replyto": "QqdloE1QH2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_Gtv6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_Gtv6"
        ],
        "content": {
            "summary": {
                "value": "The work introduces an automated dataset for mathematical formalization, composed of informal-formal pairings. This dataset was generated using a reverse translation approach on two formal corpora, utilizing the large language model (LLM). Experimental results from two benchmark tests (100 examples) supports the enhancements achieved through fine-tuning on this synthesized dataset. A notable discovery from the study is that fine-tuning on a multilingual (formal language) dataset can also yield benefits for a monolingual (formal language) benchmark."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "* This work is the first effort in distilling mathematical formalization from the LLM, a contribution given the notable scarcity of parallel datasets of mathematical formalization.\n\n* Both the generated dataset and the fine-tuned model will be made publicly available for further research and development."
            },
            "weaknesses": {
                "value": "* The evaluation could benefit from further enhancement. Currently, a sample size of only 50 examples from the benchmark is used, which may not provide sufficiently convincing results due to potential statistical limitations.\n\n* As the author also mentioned, the synthesized datasets could be noisy. It would be beneficial to also include GPT4 in your comparative analysis for formalization quality. This would offer deeper insights into the noise levels within the generated datasets, i.e., how noisy it could be.\n\n* The term \u2018language\u2019 or \u2018lingual\u2019 as used throughout the paper, especially in the section of introduction, could potentially lead to confusion, although it is understandable with careful reading."
            },
            "questions": {
                "value": "* Considering that the total number of examples required for complete testing is approximately **eight times** the number of the sampled 50 examples used in the evaluation, I would appreciate more information about the overall effort required to execute the complete testing process."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2851/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698849204621,
        "cdate": 1698849204621,
        "tmdate": 1699636228730,
        "mdate": 1699636228730,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EK8e2f7HhY",
        "forum": "QqdloE1QH2",
        "replyto": "QqdloE1QH2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_d1G8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2851/Reviewer_d1G8"
        ],
        "content": {
            "summary": {
                "value": "Summary\nThis study centers on the autoformalization of natural language into machine-verifiable formalizations, employing a back-translation approach with GPT-4 to convert formal mathematical statements into their informal counterparts. Utilizing this newly constructed dataset, the authors further fine-tune various language models, achieving an acceptable output\u2014with minimal adjustments needed\u2014on 16-18% of statements when benchmarked against miniF2F and ProofNet."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths\n\nThe Multilingual Mathematical Autoformalization (MMA) dataset was ingeniously synthesized using GPT-4, resulting in a substantial collection of 332,000 informal-formal pairings across multiple formal languages.\nWith its multilingual and multidomain composition, the dataset notably exceeds the size of the largest existing datasets in the field.\nThe research showcases improved outcomes when compared against established baselines."
            },
            "weaknesses": {
                "value": "Weaknesses\n\nThe integrity of the MMA dataset warrants further examination, as it was entirely auto-generated via GPT-4, potentially leading to mismatched cases. The paper would benefit from an expanded discussion on the discrepancies and the inclusion of findings from human evaluation.\nThe paper's innovative contribution seems incremental, largely relying on the automated capabilities of GPT-4 for dataset generation, which suggests a limited technical advancement."
            },
            "questions": {
                "value": "How do the authors check the quality of the dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2851/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698942726272,
        "cdate": 1698942726272,
        "tmdate": 1699636228654,
        "mdate": 1699636228654,
        "license": "CC BY 4.0",
        "version": 2
    }
]