[
    {
        "id": "UW71otmdxv",
        "forum": "Uavy4DLrXR",
        "replyto": "Uavy4DLrXR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_dU7f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_dU7f"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a recurrent mechanism with LSTM to acquire layer-wise sparse masks, considering both the sparse masks from previous layers and visual prompts.\n\nThe paper has achieved commendable performance on CIFAR and Tiny ImageNet datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The presentation of this paper is excellent, with professional handling of formulas, images, and expressions.\n\n2. The paper has achieved commendable performance on CIFAR and Tiny ImageNet datasets."
            },
            "weaknesses": {
                "value": "1. The novelty of this paper is relatively limited. Several methods have already been proposed to address the intricate dependencies arising from channel elimination across layers with sequence network, such as the RNN-based SkipNet[1]. To enhance the novelty, the author is encouraged to explore a broader range of dynamic neural network literature, as numerous ideas and methods have been introduced in this domain over the years. \n\nIt is necessary to compare these methods and elucidate their differences.\n\nThe reviewer possesses a deep understanding of dynamic networks with sequence modeling. Any potential misconceptions in the reviewer's understanding can be clarified during the rebuttal phase.\n\n2. Visual prompts are typically designed for fine-tuning with limited data and domain transfer scenarios (e.g., transform the ImageNet model to CIFAR), but the author claims that the visual prompt plays a key role in pruning. However, the experiments in this work seem challenging to support this argument, as all the gains from visual prompts appear to be very marginal, less than or equal to 1%. Such experimental results are hard to be convincing. \n\nAdditionally, prompt learning relies on a strong foundation of pre-trained models. To demonstrate its effectiveness in network pruning, favorable experiments and analyses are essential.\n\n In cases where pruning a model without fine-tuning, the visual prompt is unnecessary, in such a scenario, it seems that the paper may not work.\n\n3. The experiments conducted on small datasets, such as CIFAR and Tiny-ImageNet, with very low resolution and data scale are not entirely convincing. The reviewer suggests including experiments on at least ImageNet-1k or ImageNet. In the era of big data, ImageNet is considered a relatively small dataset.\n\n[1] Wang, Xin, Fisher Yu, Zi-Yi Dou, Trevor Darrell, and Joseph E. Gonzalez. \"Skipnet: Learning dynamic routing in convolutional networks.\" In Proceedings of the European Conference on Computer Vision (ECCV), pp. 409-424. 2018.\n\n\n----------------------\n\nAfter reading the rebuttal, the reviewer raised the score to 5."
            },
            "questions": {
                "value": "1. Could the author explain that why the visual prompts improve channel pruning? Since the visual prompts are static across a task or a dataset, why the author state their pruning method as \u201cfrom a data-centric perspective\u201d while it is not even input dependent?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6393/Reviewer_dU7f",
                    "ICLR.cc/2024/Conference/Submission6393/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697956664896,
        "cdate": 1697956664896,
        "tmdate": 1700550757126,
        "mdate": 1700550757126,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7SJWMMpUVV",
        "forum": "Uavy4DLrXR",
        "replyto": "Uavy4DLrXR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_dN4F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_dN4F"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors study how to use visual prompts for channel pruning. The authors argue that the layer-wise mask should consider the sequential dependency between adjacency layers, network weights and visual prompts. Motivated by this argument, the authors propose PASS to learn sparse mask using a recurrent LSTM network. The authors conduct experiments on six target datasets with four different backbones."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed method achieves better performance over the baselines on most of the proposed settings.\n2. The authors provide the code in the appendix."
            },
            "weaknesses": {
                "value": "1. Model Complexity: While the channel pruning reduces size, the added LSTM network introduces new parameters. An analysis of its impact on model parameters considering the LSTM and training/testing time would be beneficial.\n2. Backbone Networks: this paper uses ResNet and VGG as the backbone networks. I recommend the authors also explore more contemporary and potentially powerful architectures, such as ResNeXT and ViT used in DepGraph.\n3. Benchmarks: The paper's benchmarks are limited in size. Testing on larger datasets like ImageNet, as used in GrowReg, DepGraph, and other baselines, is recommended."
            },
            "questions": {
                "value": "1. Please correct the typos in the title, \"sparsity\" and \"recurrent\".\n2. It's preferable to place figures and tables at the top of a page.\n3. The authors may consider switching the sequence of Figure 4 and Figure 5 to align with their respective mentions in the text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698630114636,
        "cdate": 1698630114636,
        "tmdate": 1699636708307,
        "mdate": 1699636708307,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mh1J4mfVQq",
        "forum": "Uavy4DLrXR",
        "replyto": "Uavy4DLrXR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_NTwF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_NTwF"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to solve the problem of estimating the channel significance in structural pruning task. It leverages the visual prompts in in-context learning to capture the channel significance and derive high-quality structural sparsity. A novel network which takes visual prompts and weight statistics as input will output layer-wise channel sparsity recurrently. Experiments have demonstrated effectiveness of proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. It is novel to take the visual prompts into the channel pruning problem.\n2. The theoretical analysis is solid and convincing for me.\n3. Experimental results are sufficient to demonstrate the effectiveness of proposed method."
            },
            "weaknesses": {
                "value": "No obvious weakness for me."
            },
            "questions": {
                "value": "Is the proposed method effective to vision transformer based models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6393/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6393/Reviewer_NTwF"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772376854,
        "cdate": 1698772376854,
        "tmdate": 1699636708141,
        "mdate": 1699636708141,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AA2bBQT5cL",
        "forum": "Uavy4DLrXR",
        "replyto": "Uavy4DLrXR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_F4Cf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6393/Reviewer_F4Cf"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the inefficiency of large-scale neural networks by proposing a pruning method named PASS, which stands for Prune to Achieve Sparse Structures.PASS utilizes visual prompts as an innovative means to identify crucial channels for pruning, seeking to enhance model efficiency without sacrificing performance. This framework adopts a recurrent hypernetwork to generate sparse channel masks in an auto-regressive manner, leveraging both visual prompts and weight statistics of the network. The authors provide extensive experimental evidence showing that PASS achieves better accuracy with fewer computational resources across multiple datasets and network architectures. They also highlight that the hypernetwork and sparse channel masks generated by PASS have superior transferability for subsequent tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. PASS introduces a novel use of visual prompts to determine channel importance.\n2. Using recurrent hyper networks allows efficient learning of sparse masks, considering the inter-layer dependencies.\n3. Experiment results show the advantage of the proposed method over baselines on convolution baseline over small benchmarks."
            },
            "weaknesses": {
                "value": "1. The recurrent hyper network approach might introduce complexity, especially in the LSTM network. Does the FLOPs computation involve the hyper-network? This requires more clear explanation in the paper. \n2. This paper only experiments with the convolution-based method. While the transformer-based approach, such as vision transformers and swin-transformers, has no investigations. To validate the generalization of the proposed approach, the authors need to provide more experiments on transformer-based networks. \n3. The experiments performed in small-scale datasets, such as cifar10, cifar100. It is worth reporting results on large datasets such as imagenet."
            },
            "questions": {
                "value": "Please refer to the questions in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concern on Ethics."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821404690,
        "cdate": 1698821404690,
        "tmdate": 1699636707960,
        "mdate": 1699636707960,
        "license": "CC BY 4.0",
        "version": 2
    }
]