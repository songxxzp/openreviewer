[
    {
        "id": "cVa3icDBM1",
        "forum": "S62iZf0cba",
        "replyto": "S62iZf0cba",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_Ngzz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_Ngzz"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a multi-objective optimization algorithm designed for molecular structure design. The algorithm introduces an approach by encoding discrete molecular structures into a continuous latent space, subsequently optimizing the latent Pareto set through a combination of global optimization and local search techniques. Experimental results demonstrate that MLPS achieves state-of-the-art performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The integration of local search and global search is interesting.\n2. The proposed algorithm achieves the state-of-the-art performance."
            },
            "weaknesses": {
                "value": "1. The ablation study is not enough to demonstrate the effectiveness of each component in the proposed algorithm. It is unclear what is meant by \"without local models.\" Was a single surrogate model built for performance prediction? Additionally, the number of evaluations in Figure 2 is 2000, while in Table 1 is 5000. However, the HV value in Figure 2 is larger than the HV value in Table 1, which is very confusing. \n\n2. The idea of optimizing in a continuous latent representation has been extensively explored in the field of neural architecture search (NAS). Many algorithms exist that optimize discrete graphs by encoding them into continuous space and employing surrogate models for performance prediction (e.g., [1][2][3][4]). Since molecular optimization and NAS are very similar, it is important to mention and compare these existing works.\n\n3. This paper aims to learn the latent Pareto set; however, the experiments only showcase a limited number of solutions. It would be beneficial to sample a large number of $\\lambda$ to provide an accurate approximation of the Pareto front.\n\n[1] Neural Architecture Optimization with Graph VAE, NeurIPS 2018\n\n[2] NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural Architecture Search, ECCV 2020\n\n[3] Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS, NeurIPS 2020\n\n[4] BRP-NAS: Prediction-based NAS using GCNs, NeurIPS 2020"
            },
            "questions": {
                "value": "1. Why do you use multiple local surrogates? We can use a single global surrogate to perform local search, which is much cheaper and more straightforward.\n2. Why do you choose Tchebycheff scalarization instead of linear scalarization?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1043/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1043/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1043/Reviewer_Ngzz"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1043/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698771305645,
        "cdate": 1698771305645,
        "tmdate": 1699636030561,
        "mdate": 1699636030561,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1rF4eiCS6D",
        "forum": "S62iZf0cba",
        "replyto": "S62iZf0cba",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_U6hC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_U6hC"
        ],
        "content": {
            "summary": {
                "value": "Through this paper, the authors aim to establish a method that can efficiently handle multi-objective molecular design scenarios by learning the comprehensive Pareto set in a latent space. To accomplish this, the authors propose to utilize an encoder-decoder model to transform the chemical space into a continuous latent space."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The writing is easy to follow. The concept figure also aids the understanding."
            },
            "weaknesses": {
                "value": "I will combine the *Weaknesses* section and the *Questions* section. My concerns and questions are as follows:\n- The authors did not provide the codebase to reproduce the results.\n- The main weakness of the paper is that the experiment results are weak and insufficient.\n   - The effectiveness of the proposed model is verified on a single kind of tasks introduced in [1]. I highly recommend reporting results with more benchmarks such as the multi-property objective (MPO) tasks of the PMO benchmark [2].\n   - The proposed model is a generative model, but there is no visualization showing the molecules generated.\n   - There are other models that used the same benchmark, such as MolEvol [3] and RetMol [4]. I recommend to include those methods to the baselines and report the performance (Table 1) and visualize the solution space (Figure 6).\n- The authors claimed the existing Pareto set learning models like P-MOCO and PSL have limitations in Related Work, but they were not selected as baselines in the experiments. All the baselines in Table 1 do not utilize Pareto optimization. I highly recommend to include those methods to the baselines and rigorously show the specific advantage of the proposed method compared to existing Pareto set learning methods.\n\nFor now, I\u2019m leaning toward reject, but I\u2019ll be glad to raise the score when all my concerns are fully resolved.\n\n---\n\n**References:**\n\n[1] Xie et al., Mars: Markov molecular sampling for multi-objective drug discovery, ICLR 2021.\n\n[2] Gao et al., Sample efficiency matters: a benchmark for practical molecular optimization, NeurIPS 2022.\n\n[3] Chen et al., Molecule optimization by explainable evolution, ICLR 2021.\n\n[4] Wang et al., Retrieval-based controllable molecule generation, ICLR 2023."
            },
            "questions": {
                "value": "Please see the *Weaknesses* part for my main questions.\n\n---\n\n**Miscellaneous:**\n- Section 4.2, the first paragraph and in Table 1, *RationalRL* -> *RationaleRL*\n- Figure 2, title, *JNK* -> *JNK3*"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1043/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839989901,
        "cdate": 1698839989901,
        "tmdate": 1699636030494,
        "mdate": 1699636030494,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gb3r8c637d",
        "forum": "S62iZf0cba",
        "replyto": "S62iZf0cba",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_bnCR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1043/Reviewer_bnCR"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose MLPS, a new approach for learning the latent Pareto set targeting multi-objective molecular design.\nThe proposed scheme utilizes widely used encoder-decoder model that casts discrete and high-dimensional chemical space to a continuous and low-dimensional latent space.\nMLPS tries to train a \"global\" Pareto set learning model that can map preference vectors to optimal points in the Pareto set.\nUnder several multi-objective molecular design scenarios (ranging from the optimization of two objectives to the optimization of up to four objectives), the proposed MLPS is shown to have advantages over other popular molecular design schemes based on the hypervolume of the generated molecules."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, the manuscript is written well in a clear and easy-to-understand manner.\nThe proposed MLPS is well-motivated and the proposed approach is reasonable.\nAn effective global Pareto set learning model, as proposed in this current work, that can efficiently map preference vectors to the corresponding Pareto optimal solutions would enable fast exploration of the Pareto optimal molecular set to identify optimized molecules that meet the multi-objective design criteria and balance the trade-offs between multiple properties as desired."
            },
            "weaknesses": {
                "value": "While the proposed MLPS scheme is well-motivated, interesting, and reasonable, there are several major & minor concerns regarding the current manuscript.\nThese are elaborated below.\n\n1. Throughout the manuscript, the authors make strong claims that may be misleading or unsubstantiated.\n\nFor example, it is claimed that \"the work is the first endeavor towards learning the Pareto set for multi-objective molecular design\", which is clearly not true unless they substantially narrow down the definition of \"learning the Pareto set\" and specify what type of \"learning problem\" they are focusing on.\n\nIt is claimed, MLPS is a general framework that is compatible with \"any plug-in encoder-decoder with continuous latent representations. \nAlthough the reviewer agrees that this is reasonable speculation, the authors do not show whether the proposed MLPS scheme can indeed be easily applied to different generative molecule design models with such architecture and latent molecular representation.\nFurthermore, there are experimental results showing whether the incorporation of MLPS would indeed lead to enhanced molecular design for different types of models.\n\n2. At the core of training effective local surrogate models lie two central issues: how to set the center for each local trust region and how to reinitialize.\nThe proposed strategy appears to be reasonable, but in-depth discussion and empirical analysis are missing.\nFor example, it is not discussed how frequently different trust regions may intersect or collapse with one another (effectively reducing the number of distinct trust regions) and how often trust regions need to be reinitialized in practice (e.g., for the multi-objective scenarios considered in the results section).\n\n3. The paper compares MLPS to several other existing methods (GA+D, JT-VAE, GCPN, RaionaleRL, MARS, and MolSearch) but it is unclear how these baselines were used for \"multi-objective\" molecular optimization since they are not necessarily inherently designed for multi-property optimization.\nWas each baseline used to randomly sample novel molecules?\nWas scalarization based on a specific (or randomly sampled) preference vector used to turn MOO into SOO?\nOr was multi-objective BO used for optimization in the latent space?\nThis choice will have a tremendous impact on the performance of each baseline (both in terms of the property of the optimized molecules as well as the sample efficiency), hence needs to be clearly described.\n\n4. As the performance metric, only the HV (hypervolume) of the optimized molecules was used.\nHowever, in addition to such \"aggregated\" performance metric, it would be meaningful to compare the individual properties as well (e.g., average property score, average property of top molecules, scatter plot - at least for the two-objective scenario, etc.)\n\n5. There is no discussion on the impact of various hyper parameters.\nFor example, what is the impact of varying the number of trust regions n_tr, minimum edge length L_min, or number of iterations Tg for training?\nThis needs to be clearly discussed and empirically tested.\n\n6. There is currently no discussion on the computational cost of MLPS and its scalability with respect to the number of objectives.\nAt least a high-level discussion and some empirical results need to be provided."
            },
            "questions": {
                "value": "Please see the comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1043/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698883611906,
        "cdate": 1698883611906,
        "tmdate": 1699636030417,
        "mdate": 1699636030417,
        "license": "CC BY 4.0",
        "version": 2
    }
]