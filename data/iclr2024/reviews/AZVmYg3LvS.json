[
    {
        "id": "VDRp6Fpk4Z",
        "forum": "AZVmYg3LvS",
        "replyto": "AZVmYg3LvS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_QnS6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_QnS6"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new function space variational inference for classification problem. The existing informative function prior may lead to high entropy to both in and out distribution data points. The idea is to assign lower entropy to in-distribution data and higher entropy to out-of-distribution data. The authors have designed a specific function prior and variational posterior to control the entropies. The experiments show somewhat promising results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well presented with good visualization to motivate the targeted problem. The designed prior and variational distribution are interesting and reasonable."
            },
            "weaknesses": {
                "value": "1.\tWhy was the last layer set as BNN layer? Why not set the whole network as BNN? \n2.\tThe experimental results are only marginal, which is my main concern. Is that because the only last layer is BNN? Why not try more BNN layers that can demonstrate more difference between new prior with previous informative prior? \n3.\tSince the prior is changing during the training, how to ensure the convergence of the procedure? \n4.\tSince the method is specially designed for the classification task, I suggest the author to revise the title and introduction accordingly to highlight the classification task. \n5.\tWhat is the role of (12)? \n6.\tSome symbols are not defined, like N^q"
            },
            "questions": {
                "value": "Please see the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6987/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698559097703,
        "cdate": 1698559097703,
        "tmdate": 1699636817541,
        "mdate": 1699636817541,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M0R9KAUSqx",
        "forum": "AZVmYg3LvS",
        "replyto": "AZVmYg3LvS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_hyeW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_hyeW"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the problem of inferring posteriors of Bayesian neural nets with function-space priors more effectively than the existing variational inference approach that uses the first-order Taylor approximation."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The studied transfer learning setup with Vision Transformers is interesting and fits well to the purpose of doing Bayesian inference.\n\n * The paper presents results from a comprehensive set of experiments."
            },
            "weaknesses": {
                "value": "* The problem setup does not make much sense to me. The introduction says:   **\u201cWe build an informative function space prior by using the empirical Bayes approach along with the parameters of hidden values and the last layer weight parameters which are obtained iterations during early stages of training\u201d**. I wonder how the approach is then different from having an uninformative prior after all. If the information comes from the data, it is technically not a prior. It appears that the paper makes its main point by differentiating from cases where the priors are just so strong that they unnecessarily restrict the model capacity.\n\n * The paper significantly lacks clarity. Apart from having extremely many typographical errors, it has statements without sharp enough meanings. Among the many, one example is: **\u201cDenote auxiliary inputs, which are far from training points and are placed closely with the training sets, respectively\u201d**. I have no idea what it means for a training point to be close to a training set. Likewise: **\u201ch(.) from the q-th component empirical parameters of hidden feature \u2026\u201d** What is an empirical parameter? I also have no clue about what is going on in pages 5 and 6 after spending considerable time trying to read them. Even the purpose of all these complications such as introducing adversarial hidden features do not look to me justified.\n\n * It is a clear weakness that after motivating Bayesian inference with lots of effort, the paper ends up using it only on the penultimate layer. Those layers are typically linear, where even closed-form Bayesian linear regression would work and the learned model weights would give a degree of interpretability. Why should one use function-space Bayesian inference if the prior will come from the weights learned in another data set and only the penultimate layer will be Bayesianized?\n\n * I do not think the reported results demonstrate the benefit of the proposed approach clearly enough. All models in all experiments perform very closely to each other. The results reported in Figure 2 are mixed: (a) and \u00a9 are favorable for the central message of the paper while (b) and (d) are just the opposite.\n\n* The take-home message given in the last sentence of Section 5.1 is obvious and comes from the nature of using an arbitrary regularizer. I wonder why one needs even an experiment for that.\n\n--- POST REBUTTAL ---\n\nThe author response does not give any concrete answer to any of the issues I raised above. I keep my score unchanged."
            },
            "questions": {
                "value": "Only T-FVI or all the three baselines? If first, why not others?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Reviewer_hyeW"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6987/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698664384493,
        "cdate": 1698664384493,
        "tmdate": 1700757367120,
        "mdate": 1700757367120,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8SBY2kVHe1",
        "forum": "AZVmYg3LvS",
        "replyto": "AZVmYg3LvS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_3j4p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_3j4p"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates a new approach to specify informative priors for improve variational inference in function space on classification tasks. In particular, the paper relies on the functional variational inference (f-VI) framework proposed by Rudner et al. (2022) but replaces the uniform (uninformative) functional prior with an informative functional prior. To this end, the authors reconsider the role of functional prior in the perspective of Bayesian Model Averaging (BMA), and then propose a new functional prior relying on the empirical Bayes approach (using the training data to specify the prior). This prior is aimed at avoiding common pathology of the uniform functional prior, which encourages the model to be uncertain on both the training and out-of-training data. In addition, the authors propose a new functional variational distribution that is aligned with this new functional prior.  The proposed method is validated on toy data and popular benchmarks."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper aims at tackling an important problem for Bayesian deep learning which is designing a good prior for Bayesian neural networks.\n- The code is anonymously provided. However, there are no instructions to use the code. Thus, it is difficult to verify the provided code.\n- The idea is interesting and well-motivated which is to design a new prior promoting high uncertainty for out-of-distribution data but low uncertainty for in-distribution data."
            },
            "weaknesses": {
                "value": "- The writing should be improved. There are many grammar typos such as the use of \u201ca\u201d and \u201can\u201d. Some parts of the paper are difficult to read, especially Section 4. There are some confusions of notations. Please refer these to in the box of Questions.\n- In Section 4, although the authors motivated the paper from the view of Bayesian Model Averaging, and claimed that *\u201cwe may design a function space prior that does not explicitly encourage generating high-entropy predictions for each predictive probability but the average prediction (via BMA) would still have high-entropy when encountered with an OOD input\u201d*, it is not clear how the proposed prior can achieve this.\n- The proposed method is somehow ad-hoc without well-elaborations. For example, in Eq (9), why do the empirical mean and covariance are averaged from those obtained from all pre-training iterations? How did the authors come up with the equation (13), the parameter $\\hat{p}(\\cdot)$ for the variational distribution?\n- The authors ignored a very related work from Izmailov et al. (2021). The narrative of this work also relies on Bayesian model averaging. This work also considers designing a novel prior that is robust to out-of-distribution data by using the empirical Bayes approach. The authors should cite, discuss, and compare experimentally with this work.\n- Experimental results on image benchmarks (Sec 5.2) show that the performance gain from the proposed prior (R-FVI) is very marginal compared to the uniform prior (T-FVI). To show clearly the effect of the prior, the authors should ablate different training sizes and temperature values for the posterior on these benchmarks.\n\nReferences:\n\nIzmailov et al. Dangers of Bayesian Model Averaging under Covariate Shift. NeurIPS 2021."
            },
            "questions": {
                "value": "- In Equation (8), what is $N^q$ how to define it? Do we have to compute the means and shared covariance over the dataset?\n- In Equation (9): what is $T$? It should be consistent with the sentence before the Equation (8).\n- From Figures 3c and 3f, it seems that the proposed method always induces a much higher disagreement ratio on both in- and out-of-distribution data compared to the uniform prior. Is this good? On in-distribution data, the entropy should be low.\n- In the paragraph \"Context inputs from adversarial hidden features\". How do we define $r$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6987/Reviewer_3j4p"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6987/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698695666402,
        "cdate": 1698695666402,
        "tmdate": 1699636817295,
        "mdate": 1699636817295,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nxMcKnXsAG",
        "forum": "AZVmYg3LvS",
        "replyto": "AZVmYg3LvS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_1KC1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6987/Reviewer_1KC1"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on improving function-space Bayesian Neural Networks (BNNs) by addressing some of the key challenges they face in terms of dealing with significative prior distributions. Applied in a classification setting, the authors propose an informative function space prior that encourages sample functions to have a certain predictive probability and varying degrees of disagreements based on input status. They also tackle the issue of computing KL divergences in function space by using an adversarial hidden feature and refining the variational function space distribution. Experimental results show that their approach outperforms other inference methods on the CIFAR 100 dataset, demonstrating its effectiveness for large-scale models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The topic is quite interesting from the point of view of enlarging the contributions to the function-space approach to modern probabilistic machine learning. The topic of using function-space BNNs is relevant and promising, and further research such as this is very welcome.\n* The proposal for function-space variational distribution introduces a categorical latent variable that represents the uncertainty in using a specific feature based on its empirical distribution. This allows for better understanding and interpretation of the model's behavior.\n* The authors use multi-dimensional probit approximation (MPA) to obtain an approximate marginalization over a Gaussian distribution for obtaining $\\hat{p}(\\cdot)$. This technique helps to efficiently compute and approximate complex distributions, making it feasible to implement this approach."
            },
            "weaknesses": {
                "value": "* The article writing does not contribute to the overall appreciation of the work being done and should be thoroughly revised. I strongly encourage the authors to do an integral check on the text for improvements. This is quite noticeable, even the abstract should be revised to correct typos and improve the overall text flow and comprehension. A lot more care and effort have to be put in this regard.\n* The proposed method relies on a last-layer approximation, which is not thoroughly discussed enough. While this approach can be employed with the right arguments, the authors do not make the efforts necessary to justify this choice or the consequences it may entail in the proposed technique.\n* While the paper presents an improved function-space variational inference method, it does not provide extensive evaluation results or comparisons against other existing methods on benchmark datasets or real-world applications to demonstrate its superiority over alternative approaches. I think stronger experimental work is needed to further motivate the usage of the proposed approach. The contribution is itself interesting, but further experimental results would bolster the proposal (e.g. regression experiments, applying this method to specify the prior in other function-space inference methods to check the potential improvements, etc.).\n* The proposal made in the article is strictly limited to BNNs, while other methods such as the one in [1] or Rodr\u00edguez-Santana et al. (2022) can be seen as \"generalist approaches\" where the function-space formulation can be done for many other models (not just BNNs, which are only particular cases).\n\n*Note:* I condition my review score on the fact that some of these issues get fixed in the final draft version. Otherwise, I may be inclined to lower the score. \n\n\n(see \"**Questions**\" for the references)"
            },
            "questions": {
                "value": "* In the initial paragraph of the introduction, when mentioning function-space BNNs I would include the reference [1].\n* Why would you argue that the main goal of function-space BNNs is \"directly assigning prior distributions to the outputs of neural networks\"? I would argue this can be done without function-space formulation, and that the main interest lies directly on the properties of the function space itself. I would even argue that the approach does not necessarily become more \"user-friendly\" due to the difficulties intrinsic to function space. I would appreciate more insight on these points.\n* Given the BMA approach and the nature of the contribution in Rodr\u00edguez-Santana et al. (2022), how do these relate to each other? I think further discussion here could improve to make a more comprehensive overall picture.\n* Does the last-layer approximation play a role in the final performance metrics? What results are achieved if this restriction is not applied and instead a full Bayesian NN is used?\n\n---\n### **Notes:**\n\n* As the authors mention: \"(Flam-Shepherd et al., 2017; Karaletsos & Bui, 2020; Tran et al., 2022), it has been less clear to specify the interpretable function space prior for the classification task\" I would expect this contribution to try to either expand on this formulation or present a general contribution for classification problems (although one also could say that works such as Tran et al. 2022 could serve to that purpose). The formulation of the article up to Section 3 makes the reader think the authors are presenting a general approach both for regression and classification, while in reality they only do the latter. Thus, I would encourage the authors to be clear with these intentions from the beginning. Moreover, since the conversion to regression does not seem too far off from the method present, I strongly \n* Results for the presented method in table 2 are highlighted, while there are other methods in ECE and AUROC that are competitive (with equal performance). This should be corrected.\n\n### **Minor corrections:**\n\n* Please correct typos. Just in the abstract there are some of them, such as the capitalized \"Recent\", the \"the this function space\" sentence, \"thought the uniform function space...\" should be revised. Further examples can be found all through the text, such as \"lineariztion\" or \"Jacobin matrix\".\n* Maintain consistency, e.g. if you are using \"function-space\" on the title I would expect to keep the \"-\" throughout the text. On the same line, remove the red-colored subindex in page 3 (unless you use justify its usage further). Also, there are some inconsistencies also in singular and plural expressions, such as \"since the posterior distribution of the weight parameters p(\u0398|D) are not tractable in general\". Please, correct the text carefully.\n* Reference for Rodr\u00edguez-Santana et al. (2022) is missing the \\' in \"\u00ed\" \n\n### **References:**\n[1] Ma, C., Li, Y., and Hern\u00e1ndez-Lobato, J. M. (2019). \u201cVariational implicit processes\u201d. In: International Conference on Machine Learning, pp. 4222\u20134233."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6987/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699461116831,
        "cdate": 1699461116831,
        "tmdate": 1699636817172,
        "mdate": 1699636817172,
        "license": "CC BY 4.0",
        "version": 2
    }
]