[
    {
        "id": "N9SCfZ4qCJ",
        "forum": "93LoCyww8o",
        "replyto": "93LoCyww8o",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_9L23"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_9L23"
        ],
        "content": {
            "summary": {
                "value": "This work proposees Hybrid Internal Model which uses minimal sensor input for legged locomotion aiming to address the limitation of existing learning-based locomotion control methods. The Hybrid Internal Model learns the latent representation of velocity and implicit dynamics of the environment via contrastive learning. The method is evaluated in simulation and deployed in the real world."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The work provides a simple one-stage method for training blind locomotion controllers, with minimal sensory information.\n2. This work provides impressive real-world performance in the supplementary video.\n3. The t-SNE visualization shows that the proposed hybrid internal model learned to distinguish different terrain type in latent space."
            },
            "weaknesses": {
                "value": "1. The overall delivery of the work is not satisfactory in the following aspect:\n* Many technical details are poorly described or totally missing: what\u2019s the exact task legged robot need to solve (follow forward velocity or follow angular velocity or anything else), what command is included in the user-command, what\u2019s the linear velocity and angular velocity range for the input. \n* Some parts are quite confusing, for instance: the user command and trainable prototypes are using the same notation: c_{i}. There are many typos in the paper, for example: \u201cpolice network\u201d in section 3.\n\n2. The evaluation of the method is poor:\n* There is no quantitative comparison with any baseline in the paper (no result in simulation and no result in real world). \n* The only comparison result (The training curve in Figure 6) provides limited information, since there is no specific description of the task. It\u2019s hard to see the actual performance gap of different methods in terms of the \u201ctask target\u201d like velocity tracking and angular.0\n* There is no actual baseline compared in the experiment section, since the method use only proprioception observation of the robot, at least RMA, MoB should be compared, quantitatively, and provide corresponding training curve. Since this work claim the proposed method provide better performance and sample efficiency against two-stage methods, at least comparison is needed.\n* There is no performance analysis the method or baselines across different terrains, or across different command range or different command types, or across different command target.\n* This work claims contrastive learning is better than purely regression, but there is no experiment to support the claim.\n\n\nReference: \n[1] Kumar, et al. RMA: Rapid Motor Adaptation for Legged Robots"
            },
            "questions": {
                "value": "Though this work provides a reasonable real-world demo, this work need to be improved in multiple ways to meet the standard of ICLR. \n1. Many technical details (including but not limited to the items mentioned in the weakness section) need to be cleared.\n2. More baseline needs to be compared.\n3. More ablation study need to be performed, for example regression or contrastive learning\n4. More specific performance analysis is required: performance across terrain or different physical properties."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Reviewer_9L23"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698539488721,
        "cdate": 1698539488721,
        "tmdate": 1700630136317,
        "mdate": 1700630136317,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ah15ZXhhJp",
        "forum": "93LoCyww8o",
        "replyto": "93LoCyww8o",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_Yqja"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_Yqja"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use a learned model to improve learning policies for a quadrupedal robot. In particular, the learned model is trained via contrastive learning instead of the typical regressive learning in existing literature."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Using contrastive learning for learning the dynamics model seems interesting.\n\n2. Real robot experiments."
            },
            "weaknesses": {
                "value": "1. The paper seems to be written in a rush with lots of typos and incorrect references. \n\n2. The need of the velocity model is a little bit unsatisfying as one would expect a perfect internal model should be able to replace it.\n\n3. Need clarification for some questions that I will list below."
            },
            "questions": {
                "value": "1. Seems to me the proposed model is more of a state estimation model (or a state compression model) instead of a dynamics model. For example, one would expect a dynamics model to be used to do rollouts instead of using a simulator during training. It will be nice to have some comments about it.\n\n2. A key missing ablations is to compare the proposed contrastive learning with a regression model. \n\n3. It would be nice to have more analysis of the learned latent model as this is the key contribution. For example, examining the effect of the number of prototypes,"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5999/Reviewer_Yqja"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698556598141,
        "cdate": 1698556598141,
        "tmdate": 1700463952487,
        "mdate": 1700463952487,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1pdSrn2eG1",
        "forum": "93LoCyww8o",
        "replyto": "93LoCyww8o",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_FQfg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_FQfg"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a new legged locomotion method called HIM (Hybrid Internal Model). The method uses only joint encoders and IMU observations (no cameras or range sensors). HIM has 2 modules, the \"information extractor \" which learns the environment dynamics, and the \"policy network\" which learns the policy. The HIM model is trained in a simulator (IsaacGym) and successfully deployed in the real world (Unitree Go1 robot)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The main strength of the paper is the proposal of the HIM (Hybrid Internal Model), which is able to address the legged locomotion problem using only joint encoders and IMU observations (no cameras or range sensors). This is achieved using two components, the \"information extractor \" which learns the environment dynamics, and the \"policy network\" which learns the policy. This is a very interesting approach and from my point of view is related to the \"world models\" concept.\n\nThe method worked successfully in different simulated and real environments. In the real world, experiments were conducted on various environments, showing agile and robust locomotion."
            },
            "weaknesses": {
                "value": "From my point of view \"world models\" also learn the dynamics of the environment, in simulation or without using simulators, and it is required that authors compares its proposal with world models. For instance, Wu et al. \"Daydreamer: World models for physical robot learning\" applies word models online and address legged locomotion. \n\nThis is important in order to better assess the originality and contributions of the paper."
            },
            "questions": {
                "value": "How your work is related with \"world models\" that also learn the dynamics of the environment? For instance, [1] applies word models online and also addresses the legged locomotion problem. I know that in your work less sensor data is used, but in addition to this, how your approach is compared with world models? Can your approach be considered a world model?\n\n[1] Wu et al. \"Daydreamer: World models for physical robot learning\" applies word models online and address legged locomotion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethical concerns."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698926246912,
        "cdate": 1698926246912,
        "tmdate": 1699636642657,
        "mdate": 1699636642657,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1WRSKOqaTp",
        "forum": "93LoCyww8o",
        "replyto": "93LoCyww8o",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_SBNA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5999/Reviewer_SBNA"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed a new auxiliary module, i.e. the hybrid internal model to help blind locomotion policy training. The hybrid internal model consumes past propiorceptive observation histories and produces a latent dynamic vector and estimated base body speed. Instead of using the regular regression loss, the latent dynamic vector is trained with a contrastive loss. The authors zero-shot sim2real transfer their policy to a Unitree robot and show that  their policy can outperform other blind baselines on a few difficult tasks including walking up/down large stairs and on soft terrains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper shows great sim2real results. The learned gait looks very smooth, and more importantly, can solve difficult multi-terrains without using perception\n2) Some novelties in introducing a contrastively learned environment/internal dynamics model."
            },
            "weaknesses": {
                "value": "1) There isn't a big delta from previous works, i.e. the ETH 2020 science paper also demonstrates similar capabilities. \n2) While it is applaud to see good results on blind locomotion walking, without perception the policy is still fundamentally limited on difficult terrains. For example, the policy has to hit the vertical edges to sense the terrain before the hybrid internal model can \"sense\" the change in the environment. And there are already good perceptive locomotion works there. \n3) The experiment result section of the paper is thin. For example, there is no quantitative results on success rate etc. \n4) In the ablation study, the oracle policy seems learning slower than the proposed method, which is surprising. \n5) Consider publishing the code with the paper. Right now there is a supplementary pdf which is a duplication of the main paper."
            },
            "questions": {
                "value": "Is the hybrid internal model co-trained with the policy or separately?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699227539957,
        "cdate": 1699227539957,
        "tmdate": 1699636642555,
        "mdate": 1699636642555,
        "license": "CC BY 4.0",
        "version": 2
    }
]