[
    {
        "id": "w1bRSTXEJa",
        "forum": "P1ANzoGg3W",
        "replyto": "P1ANzoGg3W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_ZNfu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_ZNfu"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes follow-up method to the SDF-based NeRF-like methods for indoor reconstruction, with a focus to improve geometry on objects in the second phase of optimization. The main novelty is the introduction of the auxiliary representation of Object Surface Field (OSF), which is activated on object surfaces. OSF can learned with 2D supervision of instance segmentation, as well as a loss in 3D which jointly constrain the SDF field and OSF field, bringing about zeros of SDF around object surfaces, leading to improved reconstruction on detailed high-frequency object parts. The method is evaluated against baseline SDF-based NeRF-like methods, on scenes including ScanNet and Replica."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "[1] The proposal of using instance segmentation as additional input to the pipeline, as well as designing effective supervision signals with input segmentation. \n\nDespite it is not new to use additional signals to the task (e.g. monocular normal and depth supervision for 2D-3D consistency, sparse points to supervise local SDF values, and using semantics and planar assumptions improve geometry of layouts), the paper is one of the first to demonstrate the usage of instance segmentation to improve fine geometry. More importantly, the paper does so in a non-trivial way, by introducing OSF to explicitly evolve object surfaces using a 2D loss between the input segmentation and OSF as well as a 3D loss between OSF and SDF.\n\n[2] Illustration of the relationship of OSF and SDF (and the gradients), and the use of the OSF to drive SDF.\n\nThe paper provides informative illustration in Fig. 4 and related text on the relationship of OSF and SDF and how does the optimization of OSF loss drive SDF towards zero point around surfaces. The illustration using examples and 1D figures is clear and supports the motivation of the design of OSF.\n\n[3] Extensive evaluation of the proposed method against baseline methods, and on more than one datasets."
            },
            "weaknesses": {
                "value": "[1] Clarification on OSF. Despite the good illustration of OSF as mentioned above, extra clarification is urgently needed to explain the motivation of the mathematical form of the 3D OSF loss (Equ. 2), and details in Fig. 4.\n\nSpecifically, despite Fig. 4 explains how the gradients of the 3 loss drives SDF to form a zero points around surfaces, and paper does not provide intuitive explanation on (a) why the various terms of the loss in Equ. 2 are designed as they are, (b) how \\gamma controls the steepness of the function, how it matters and how $\\gamma$ is picked (better with illustrations similar to Fig. 4). Additionally, it is not clear that, between Fig. 4 (a) and (c), why different d(x) lead to identical $\\sigma_\\gamma(x)$. Without clarifying the issues it is difficult to understand why OSF and the losses are designed the way they are, despite being proven effective.\n\n[2] Demonstration of applying the proposed OSF and losses general SDF-like NeRF-based methods. The proposed OSF and losses should theoretically be applicable to all of the baselines methods as simple drop-in, but somehow the paper decides to compare against its own vanilla baseline. Is it possible to apply to other existing methods to better showcase the general nature of the proposed method, and how effective will it be?\n\n[3] Limited scenes to evaluate. The main evaluation is done on ScanNet, with limited qualitative results on Replica. However ScanNet is known to have image quality issues. Why is the method not evaluated and compared on alternative datasets including Replica, Tanks & Temples, etc, as is done in other papers like MonoSDF? Without the additional evaluation, it is difficult to decide the generalization of the method across various indoor scenes.\n\n[4] Additional comparison. One less important thing to add is, potential comparison with I^2-SDF. Despite I^2-SDF is based on additional geometry supervision signals, the goal is aligned with the proposed method, and it showcases similar improvement in fine detailed objects. It would be beneficial to add comparison to I^2-SDF to inspire the discussion on optimal strategy to improve reconstruction of high frequency signals in indoor geometry."
            },
            "questions": {
                "value": "Please see the Weakness section for questions to address."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698714989729,
        "cdate": 1698714989729,
        "tmdate": 1699636408113,
        "mdate": 1699636408113,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qr13yOjDv6",
        "forum": "P1ANzoGg3W",
        "replyto": "P1ANzoGg3W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_rsDk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_rsDk"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a neural 3D indoor reconstruction framework to reconstruct 3D mesh of indoor scenes with a volume rendering framework. The key motivation of this paper is to decouple the learning of the layout and object with two stages. In the first stage, the layout of the scene is trained with an uncertainty-aware rendering loss function on both color and normal prediction. In the second stage, a new term named Object surface field (OSF) is introduced to measure the object occupancy of a 3D point, and authors demonstrate how SDF will facilitate SDF with the presented mutual induction. Extensive experiments on ScanNet have showcased the effectiveness of the proposed framework over different state-of-the-art (SOTA) methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) The motivation to decouple the learning of layout and object into two stage is straightforward and clear. The layout contains planar areas and the objects may have more high-frequency signals, thus may have different pace of convergence.\n\n(2) The introduction of OSF is novel, and how the OSF can be transformed back to SDF and assist its representation is technically sound.\n\n(3) Experiments on ScanNet have shown the advantages of proposed components of the method."
            },
            "weaknesses": {
                "value": "(1) The major concern for me is that of the technical impact of this work is limited by introducing a normal estimation network [1] which is also trained on ScanNet, to provide pseudo groundtruth normal and uncertainty during training. This cannot ensure fairness among baseline comparison and highly constraints the generalizability of the proposed method onto different benchmarks. A fair setting would be replace this network with another model or method which is pretrained on other datasets, or alternatively, test this method onto other indoor datasets such as 7-Scenes. This will significantly improve the fairness and technical impact of this work.\n\n(2) In the supplementary material, authors present that they apply the OSF-based Filtering during reconstruction. I am curious about where does the major improvement of OSF comes from, either the proposed osf loss or the filtering. Authors are expected to conduct ablation study about this to make the contribution more convincing.\n\n(3) Minor: The presentation can be further improved, and there exists noticeable typos in the submission such as Table 2."
            },
            "questions": {
                "value": "I appreciate the motivation of the design of this paper, however the use of a model seen on the same dataset limits the value of the proposed method. I would consider to improve my rating if my concerns listed in the weaknesses part can be well addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816938506,
        "cdate": 1698816938506,
        "tmdate": 1699636408011,
        "mdate": 1699636408011,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0bgFJ3cWE7",
        "forum": "P1ANzoGg3W",
        "replyto": "P1ANzoGg3W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_ypMg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_ypMg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a two-phase learning approach named H2O-SDF that combines both holistic surface learning and object surface learning, for 3D reconstruction in indoor environments. \n\nThe main contributions are: 1) a two-phase learning framework that balances between the reconstruction of global room geometry and local object details. 2) Introduction of Object Surface Field (OSF), a new concept designed to address the vanishing gradient problem suffered by SDF, which hinders the reconstruction of high-frequency details. The authors also introduce an OSF-guided sampling strategy to prioritize object surfaces in the sampling process."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper tackle an important issue in the field of 3D indoor scene reconstruction \u2014 the difficulty of preserving the overall geometry while capturing intricate object details. It introduces a two-phase learning approach, which has not been explored before. \n2. The OSF concept is new and shows promising results in handling the inherent vanishing gradient issue in the learning process.\n3. It is an interesting idea to use normal uncertainty as a guidance to re-weight normal and color loss, to adaptively moderate normal and color losses in both low-texture and texture-rich regions.\n4. The submission appears to be well-organized with its ideas clearly articulated.\n5. Experimental evaluations, together with ablation studies, confirm the effectiveness of H2O-SDF. The results show that the proposed solution outperforms existing state-of-the-art methods."
            },
            "weaknesses": {
                "value": "1. The explanation and exposition of some key, novel concepts, such as OSF, L2D_OSF, L3D_OSF, could be more thorough. There is insufficient mathematical detail on the OSF guided sampling strategy (although there is graphical illustration in the appendix A2, the explanation seems to be mostly a repetition of the main body). Strengths of the proposed formulation could be better appreciated by providing more detailed explanations and mathematical insights. \n\n2. Running time: The paper does not provide specific details about the computational complexity or running time of the approach, for both training and inference.  It only states that all experiments were conducted on a single NVIDIA RTX 3090Ti GPU.\n\n3. Comparison with more diverse data (this is more of a suggestion): While the paper compares favorably to state-of-the-art methods on the ScanNet dataset, it would strengthen the paper to include a broader range of data under different conditions, such as different indoor layout complexities, object variations etc."
            },
            "questions": {
                "value": "1. It would be interesting to find out to what extent this method relies on pre-trained models and priors, which might limit its application in environments where such models are not easily available.\n\n2. Running time/computational complexity of the proposed method. Please refer to point 2 under Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4361/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4361/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4361/Reviewer_ypMg"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826774823,
        "cdate": 1698826774823,
        "tmdate": 1699636407907,
        "mdate": 1699636407907,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mfpayFMCeT",
        "forum": "P1ANzoGg3W",
        "replyto": "P1ANzoGg3W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_93pm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4361/Reviewer_93pm"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a two-phase framework (H2O-SDF) for 3D indoor scene reconstruction. In particular, the proposed method adopts a two-stage method, which consists of one-stage reconstruction for the scene layout followed by a second-stage reconstruction of the objects using NERF. The key contribution is to introduce the concept of the object surface field. The 2D and 3D object surface losses are introduced to estimate the SDF for fine object surface details. The experiments are conducted on ScanNet and show superior results compared with existing methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The method reconstruct the layout and the object separately and achieves very good reconstruction on the details of the objects.\n+ The introduced OSF captures the occupancy of the surface of the 3D object.\n+ The introduced two losses let the SDF captured more surface details."
            },
            "weaknesses": {
                "value": "-\t2D object surface loss. Could it be explained as the loss between the rendered object masks and the ground truth masks? It would be great to make it clear that the proposed method actually requires object annotations.\n-\tIt would be great to explain OSF with more details. Based on the description in the paper, it is quite similar to the absolute gradient field of the occupancy values. In particular, Eq. 3 actually enforces the OSF to have large values on the object defined by the 3D points.  In addition, 3D points provide strong prior on the details of the shapes. It would be great to provide the ablations study of using the point cloud with MVS images or not.\n-\tExperiments on ablations studies. It is not clear to the reviewer what model A, B, C are. It would be great to provide detailed explanations about those models.\n-\tFor the second stage, it would be great to ablate whether all the losses have contributed to the final results. The proposed method adopts more accurate point cloud obtained from MVS images compared with monocular depth estimated from a single image. Those factors should be ablated to demonstrate the performance benefits from OSF and the sampling strategy not from the prior data"
            },
            "questions": {
                "value": "- It would be great to elaborate more on the insight of OSF and also compared with existing density functions parameterised with the SDF values. \n- The ablations studies are missing. Please demonstrate all the losses introduced in stage two all contributes to the improvement of the reconstruction. In addition the proposed method leverages the point cloud obtained from MVS. It would be great to show how these priors can influence the final performance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699629225851,
        "cdate": 1699629225851,
        "tmdate": 1699636407830,
        "mdate": 1699636407830,
        "license": "CC BY 4.0",
        "version": 2
    }
]