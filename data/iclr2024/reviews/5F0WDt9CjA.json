[
    {
        "id": "qKJT06lQUG",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_iYeg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_iYeg"
        ],
        "content": {
            "summary": {
                "value": "- This paper presents a dataset of piano performances aiming to aid research focusing on he task of piano performance evaluation\n- The authors state a few parameters that are important for performance evaluations: 1.) multiple performances of the same piece, 2.) perceptual features which capture both performer\u2019s and listener\u2019s interpretations, 3.) multi-level features which contain low-level details such as pitch/duration of notes and high-level musical concepts, and 4.) expert annotations critiquing the performed music. They note that no existing dataset satisfies these 4 conditions.\n- The authors collect a dataset called PercePiano, which includes various performances of the same piece, expert annotations for 19 perceptual features, as well as expert assessments for the performances.\n- The authors also present a new model for heirarchical modeling of the performance after aligning it with the score of the piece being performed. The model operates at 4 levels of heirarchy: note, voice, beat, and measure. The proposed model outperforms pre-trained models such as MusicBERT."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The authors have carefully come up with a taxonomy of low-to-high level musical features that encapsulate the quality of a musical performance with annotations collected from experts.\n- The presented model seems to be well designed for music performances. Similar ideas have been explored in the past with models like MuseFormer[1], or MeasureVAE[2], but they typically are either constrained to model note-level and measure-level, or have some musical rules baked in, such as attending to specific measures in the past.\n\n[1] Yu, Botao, et al. \"Museformer: Transformer with fine-and coarse-grained attention for music generation.\"\u00a0Advances in Neural Information Processing Systems\u00a035 (2022): 1376-1388.\n\n[2] Pati, Ashis, Alexander Lerch, and Ga\u00ebtan Hadjeres. \"Learning to traverse latent spaces for musical score inpainting.\"\u00a0arXiv preprint arXiv:1907.01164\u00a0(2019)."
            },
            "weaknesses": {
                "value": "- The topic is not too relevant to the audience at ICLR. The hierarchical model may be of some interest but in the current state the paper is not a great fit. A dataset contribution is highly appreciated, however, the ICLR community at large might not benefit too much as compared to a more specialized venue like ISMIR or music perception venues like ICMPC. Conversely, the authors might not gain too much since it will be difficult to foster conversations at a general venue like ICLR where the audience does not have a background in music or music perception.\n- The results are not very convincing for the proposed baseline. Since the authors do perform cross-validation, I would be interested in seeing some error-bars for the results. Some of the results look very close and I\u2019m not sure if they are significantly better. I understand that the baseline is not necessarily supposed to be very performant, but given the authors\u2019 justifications for the design it would be expected to perform much better than existing naive transformers.\n- Section 4.1 needs a lot more detail. In general I appreciate that the authors spend a lot of time explaining and motivating their design choices and pointing out issues in existing literature. However, this particular section needs specifics about what features are used. The authors simply add a few words in parentheses: (e.g. onset deviation, articulation) and (pitch, velocity, start and end time) for the features used. The paper needs details or at least definitions and a reference about how these are calculated."
            },
            "questions": {
                "value": "See weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698776528747,
        "cdate": 1698776528747,
        "tmdate": 1699636535379,
        "mdate": 1699636535379,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ms7LBoqyDv",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_vNEe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_vNEe"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel dataset named PercePiano, designed to provide a comprehensive collection of features and labels for 1202 musical segments. The authors present their motivations for creating this dataset, emphasizing its utility in facilitating a thorough assessment of piano performance. They also provide detailed insights into the data collection process. Moreover, the paper harnesses the Percept-HAN architecture and introduces a set of metrics to assess the effectiveness and practicality of PercePiano."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The primary contribution of this paper lies in the introduction of a pivotal dataset, PercePiano, poised to significantly benefit the broader music AI community across various downstream applications, including music transcription, music performance assessment, and music emotion recognition. The authors exhibit a profound foresight regarding the evolving landscape of music AI research, exemplified by their meticulous curation of labels for this dataset. Anticipations are high for the dataset's exceptional quality, promising to set a new standard in the field."
            },
            "weaknesses": {
                "value": "While the paper makes a commendable contribution in the form of the PercePiano dataset, there are notable concerns regarding its technical novelty and experimental validation. It would be a great contribution if the submission is dataset-target only. However, the proposed metrics, such as MSE, R^2, and RA, lack direct ties to specific downstream tasks, which could limit their effectiveness in assessing the dataset's utility. Furthermore, the model employed in this study has been previously introduced in other works, diminishing its novelty.\n\nIt would be better to use several downstream tasks to verify the proposed PercePiano dataset. By establishing several SoTA models and training them with PercePiano can demonstrate its high quality and comprehensive labels and features. For example, there are some tasks can be highly recommended to conduct:\n\n1. The music transcription task. Previously, there exists the GiantMidi dataset with a pianoNet to achieve high performance. Does PercePiano provide more useful labels that can enhance this performance, or extend this transcription task to more dimensions?\n\n2. The music emotion recognition task. Previously, EMOPIA and EMO-Music are main resources for this task. Will the introduction of PercePiano provide better quality?\n\nAdditionally, as a dataset paper, it would be great to provide some demos or examples inside PercePiano to fully assess the dataset.\n\nAt present, the paper is primarily credited for its dataset contribution, but to make a more substantial impact, it should address these concerns and expand its focus on practical applications and validation."
            },
            "questions": {
                "value": "The questions are provided in the weakness section above. There is one error in the EMOPIA dataset: it also provides the reference audio tracks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Reviewer_vNEe"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814637761,
        "cdate": 1698814637761,
        "tmdate": 1699636535258,
        "mdate": 1699636535258,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n0n0NWqI2h",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_ZEzP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_ZEzP"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses a gap in the literature regarding performance reception when listening to piano performances. The authors collate a new dataset containing perceptual features collated from expert listeners."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Principled approach to the design of perceptual features to include - this is a well referenced contribution and shouldn\u2019t be overlooked"
            },
            "weaknesses": {
                "value": "* given the dataset is only 3 different songs (though there are a dozen or so performances of each) the claims regarding the model may not be the most robust. Without having to collect more data, perhaps an ablation could be done by cleverly splitting test and train sets of evaluation?"
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698949896421,
        "cdate": 1698949896421,
        "tmdate": 1699636535146,
        "mdate": 1699636535146,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F3FyS1cSXL",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_Pd1L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_Pd1L"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a newly collected dataset for piano performance evaluation, which focuses on perceptual features. A new model structure is proposed along with a new metric for evaluating perceptual features."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper presents a new dataset for piano performance evaluation. The strength of the dataset is: 1) it is labelled with a wide range of perceptual features; 2) the annotations are provided by experts."
            },
            "weaknesses": {
                "value": "1. The dataset exclusively comprises romantic classical piano music, which implies a rather narrow focus and may not be suitable for general piano performance evaluation. This can lead to generalization issue for the models trained on this dataset. In addition, the dataset only contain ~1200 segments, raising questions about the robustness of a model trained on such limited data.\n\n2. In Section 4.1, the authors state that \"Such a transformer structure does not work well when it comes to evaluating perceptual features in piano performance\". The argument lacks validation. It seems that the problem is associated with the ways of processing input MIDI data rather than the transformer structure. The issue is about the operation of grouping notes and voices into beats and then into bars. And the main novelty of the proposed Percept-HAN is how to leverage hierarchal structure from the input MIDI data. In the proposed structure, Bi-LSTM is used in each hierarchical unit to encodes each piece of information. I'm wondering whether replace the Bi-LSTM with transformer will degrade the performance (if the problem is indeed the transformer structure).\n\n3. The test set is randomly chosen and it's not clear whether the test set contains variations that are not included in the training set. I'm concerned about the generalization ability of the model. \n\n4. All the systems are only evaluated on the PercePiano dataset. It's not clear whether the proposed structure also works with other piano evaluation datasets, especially with a border range of piano music.\n\n5. In Section 4.1, the authors claim that the sophisticated structure is important for evaluating performances. I'm wondering whether 4 bars are enough for the evaluation of such structure. I'm also interested in whether the length of segments affect piano evaluation.\n\n6. Not sure whether ICLR  has the appropriate audience of such dataset and task. Conferences that primarily focus on audio, speech, music may be more suitable for this work."
            },
            "questions": {
                "value": "1. Table 1 - comparison of dataset should also include the size of dataset (i.e. number of segments, total duration, etc.)\n\n2. The annotation process is not clear to me. In the first paragraph of Section 3.2, it says that the performance is evaluated by experts. In the last paragraph of the section, it says that the scores are collected from MuseScore, a crowdsourced platform, which is confusing.\n\n3. Btw, the opening quotation marks on the third to last line of the first paragraph of section 3.3 are incorrectly written."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Reviewer_Pd1L"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699073656678,
        "cdate": 1699073656678,
        "tmdate": 1699636535042,
        "mdate": 1699636535042,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pr7zLUxrzd",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_sviL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_sviL"
        ],
        "content": {
            "summary": {
                "value": "Detailed Review to be added in a few hours"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Detailed Review to be added in a few hours"
            },
            "weaknesses": {
                "value": "Detailed Review to be added in a few hours"
            },
            "questions": {
                "value": "Detailed Review to be added in a few hours"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699203690124,
        "cdate": 1699203690124,
        "tmdate": 1699636534948,
        "mdate": 1699636534948,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mI8dmL2ZtQ",
        "forum": "5F0WDt9CjA",
        "replyto": "5F0WDt9CjA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_zHsN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5327/Reviewer_zHsN"
        ],
        "content": {
            "summary": {
                "value": "This paper presents PercePiano, a new dataset comprised of a sizable body of expert annotations of musical performance quality from the open-source MAESTRO dataset. The authors discuss in depth the dataset curation process. The authors then propose a regression-based performance quality task, wherein a Hierarchical attention-based model is used, beating out transformer-based pretrained baselines on the task."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The overall contribution of the dataset itself is highly valuable. To my knowledge, no widely available datasets exists for music performance assessment that has such fine-grained features, which is of clear interest to the wider MIR community.\n- Discussion on dataset creation and cleaning is incredibly thorough and clear."
            },
            "weaknesses": {
                "value": "I have a few concerns about both the dataset portion and the modeling portion of the work.\n\n**Dataset**\n- The authors make the claim that extracted features are chosen with the criteria of \"The features are not readily extractable from performance data using automated machine methods, indicating their perceptive nature,\" but do not go in depth with regards to any evidence of this phenomenon. If there is some more in depth reasoning to support this or related work, it would be important to cite here.\n- Constructing all of the features in the binary-sense that is done in the paper feels rather odd and atypical for general description-style features. Namely, it is not clear why the authors did not choose something more established in the literature such as phrasing features as a multi-label tagging problem within each category, as the implied dichotomy between subjective features that the authors used seems arbitrary.\n- While resource constraints for annotations are understandable, the fact that the data only comes from a few number of distinct musical pieces limits its usefulness\n\n**Modeling**\n- Overall, I have serious concerns about the high level message that transformer-based models *cannot* encode hierarchical information.\n    - The authors acknowledge that hierarchical information can be learnt by transformers in the text domain but that \"the\ntransformer in the music field fails to capture the semantics.\" This comment is made without citation, and seems in direct conflict with the growing progress in the generative music domain (which often uses transformer-based architectures)\n    - The claim that MusicBERT does not use hierarchical information seems like a strong overstatement. Namely, just because it does not *explicitly* encode hierarchical information does not mean it doesn't use it *implicility* (the way text-based models do), and would need significantly more experimentation to prove this fact.\n    - It is hard to tell whether MusicBERT-small's performance difference described in Table 3 is due to the transformer architecture itself, or rather that Percept-HAN uses \"grounded performance features\" that MusicBERT never sees in its Octuple encoding. It would be a useful exercise to see whether augmenting MusicBERT with the grounded performance features would perform better or not.\n    - Additionally, the note that MusicBERT-base seems to beat the proposed model in all but 1 metric (which should be reported in Table 3) seems to directly contradict the claim that \"transformers do not encode hierarchical information,\" and thus the messaging could be changed to reflect that any claims of transformers lack of hierarchical reasoning are constrained to small models. \n- I am concerned there may be severe data leakage issues in the entire experimental set-up. Namely, it is not clear whether training and validation data are split according to song or not. If not, it is hard to trust any of the evaluation metrics, as there may be considerably high correlation between features from one part of a piece to another. If possible, the authors should rerun experiments making sure to minimize the conceptual overlap between training and validation sets (such as restricting one song to only occur in the validation set)."
            },
            "questions": {
                "value": "- The explanation of Percept-HAN is a bit hard to follow. Could you describe more in depth specifically how the model encodes features from multiple hierarchical levels?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5327/Reviewer_zHsN"
                ]
            }
        },
        "number": 6,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699324954905,
        "cdate": 1699324954905,
        "tmdate": 1699636534858,
        "mdate": 1699636534858,
        "license": "CC BY 4.0",
        "version": 2
    }
]