[
    {
        "id": "y0kysomv1q",
        "forum": "AHgc5SMdtd",
        "replyto": "AHgc5SMdtd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission19/Reviewer_H5pV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission19/Reviewer_H5pV"
        ],
        "content": {
            "summary": {
                "value": "This paper targets industrial zero-shot anomaly detection. Leveraging mutual scoring on unlabeled data, the proposed method achieves SOTA performance on several well-known industrial anomaly detection benchmarks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe paper is well written, with clear architecture.\n2.\tThe motivation is insightful, with clear ablation studies to show its effectiveness. The motivation and the proposed method are well-matched."
            },
            "weaknesses": {
                "value": "1.\tThis paper employs a methodology that utilizes unlabeled test images to collectively measure anomaly scores, differing somewhat from the traditional zero-shot recognition setting. In the conventional approach, each image is independently evaluated, such as WinCLIP. This difference in evaluation methodologies can result in a somewhat unfair comparison.\n2.\tThe underlying concept is reminiscent of [a], which presumes homogeneous input texture and identifies image regions that disrupt this homogeneity as anomalies. In other words, if a patch significantly differs from its neighboring areas, it's deemed an anomaly.\n3.\tThe approach of jointly measuring anomaly scores across entire datasets aligns closely with [b]. While not mandatory, it would be beneficial for the authors to discuss or draw comparisons with [b].\n\n[a] Aota et al. \"Zero-shot versus Many-shot: Unsupervised Texture Anomaly Detection.\" In WACV 2023.\n\n[b] Li et al. \"Zero-Shot Batch-Level Anomaly Detection.\" arXiv, February 2023."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission19/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698648612162,
        "cdate": 1698648612162,
        "tmdate": 1699635925396,
        "mdate": 1699635925396,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Uk9PdZmZYz",
        "forum": "AHgc5SMdtd",
        "replyto": "AHgc5SMdtd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission19/Reviewer_dCfU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission19/Reviewer_dCfU"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses zero-shot anomaly classification (AC) and segmentation (AS) with following contributions:\n1) Using unlabeled test images for AC/AS.\n2) A new mutual scoring mechanism for identification of abnormal patches.\n3) SOTA performance, significantly outperforming existing zero-shot methods"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The claimed contributions summarized above."
            },
            "weaknesses": {
                "value": "1) This paper makes the assumption that access to the entire test dataset is available. This allows for a direct application of the proposed mutual scoring mechanism. However, for zero-shot settings, such an assumption is too restrictive.  Access to test data is mostly very limited in real-world scenarios, especially for zero-shot.\n\n2) The method heavily relies on many heuristic design choices. It consists of a three-step pipeline which depends on many hyperparameters for feature representation, mutual scoring estimation, and classification rescoring. The paper poorly presents sensitivity of performance to optimizing all these parameters.\n\n3) Overall technical novelty seems incremental, since the method incorporates well-established multiscale features (Sec 3.1), norm-2 distance (Sec 3.2), and clustering (Sec 3.3). \n\n4) Since the method lacks a training phase and directly generates results based on estimating the test-set statistics, inference is likely to be much slower than in previous approaches. I was not able to find a report/comparison of the inference times."
            },
            "questions": {
                "value": "1) Could your approach handle a setting when a test dataset lacks ground truth? What is performance when a test dataset lacks ground truth for optimizing the proposed heuristic procedure? \n\n2) One of the claimed contributions, the mutual scoring mechanism, appears to depend significantly on the relative positions of feature patches. This limits the application of this approach in real settings where orientations and scales are not consistent. What is performance when test images exhibit inconsistent orientations or scales?\n\n3) Could your method be extended to (or readily address) the few-shot setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission19/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698680197799,
        "cdate": 1698680197799,
        "tmdate": 1699635925316,
        "mdate": 1699635925316,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nd4rOlaFoy",
        "forum": "AHgc5SMdtd",
        "replyto": "AHgc5SMdtd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission19/Reviewer_idjR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission19/Reviewer_idjR"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces MuSc, a novel zero-shot framework for industrial anomaly classification and segmentation. It utilizes cues from unlabeled test images and combines local patch tokens with a mutual scoring mechanism. The method notably outperforms existing zero-shot approaches and rivals many few-shot and full-shot methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The MuSc framework introduces a novel approach to zero-shot anomaly classification and segmentation, particularly in the industrial domain. The method of leveraging implicit cues from unlabeled test images for anomaly detection is an innovative concept.\n\n2. The empirical results demonstrate a substantial improvement over existing zero-shot approaches and competitiveness with few-shot and full-shot methods.\n\n3. The approach holds significant potential for industrial applications, where anomaly detection is crucial but training data is often scarce or expensive to obtain."
            },
            "weaknesses": {
                "value": "In Table 3, the ablation study of LNAMD with different aggregation degrees \\(r\\) raises a question regarding the effectiveness of combining aggregation degrees. Specifically, it's unclear why the combination of \\({3, 5}\\) performs worse in the anomaly classification (AC) task than using \\({3}\\) alone. This observation seems to contradict the paper's claim that using all aggregated patch tokens with different degrees is beneficial for detecting anomalies of various sizes. Based on this claim, one would expect the combination of \\({3, 5}\\) to outperform either \\({3}\\) or \\({5}\\) individually. This inconsistency warrants further clarification or investigation to reconcile the results with the stated claims."
            },
            "questions": {
                "value": "See the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission19/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805736672,
        "cdate": 1698805736672,
        "tmdate": 1699635925241,
        "mdate": 1699635925241,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yinO0jnVvj",
        "forum": "AHgc5SMdtd",
        "replyto": "AHgc5SMdtd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission19/Reviewer_52S5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission19/Reviewer_52S5"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an anomaly detection and segmentation method utilizing unlabeled images from a test set. It is assumed that a set of images with some form of anomaly is available for inference and it is claimed to be zero shot. \nThe method starts with computing a representation for every image patch through aggregating (pooling) token features generated by ViT at different layers. An anomaly score for each patch is then computed by comparing the aggregated patch token with that from each image in the *test* set. Further heuristic tricks are applied to refine this score and the final pixel level anomaly score is given by the max of the refined score. \nThe method then produces an image level classification by defining a weighted graph over *test* set images where weights are defined by the class token generated by ViT. The image level classification score is the determined by by some graph operations that were not explained well. The method was tested on public datasets and compared with solid baselines."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "I am afraid I was not able to find a notable strength of this paper."
            },
            "weaknesses": {
                "value": "1. Technical soundness: The method relies heavily on availability of a set of images in order to compute the anomaly scores. I dont think this emulates the practical scenario of anomaly detection in industry. The more realistic scenario is a method is required to classify and segment the anomaly given one image. Using test set images to produce the output on the same set of images also does not conform with the scientific procedure. I dont think this is the definition of a zero shot method either. The setting sounds completely unreasonable to me.\n\n2. Contribution: The algorithm appears to be a set of heuristic tricks applied in a sequence. There is not a solid technique that is novel, elegant, theoretically justified and of broad interest.\n\n3. Clarity: None of the techniques were adequately explained as to why they are being performed and why it makes sense (intuitively or conceptually) to apply them. Just stating the process does not qualify as a good scientific exposition."
            },
            "questions": {
                "value": "..."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission19/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809673236,
        "cdate": 1698809673236,
        "tmdate": 1699635925147,
        "mdate": 1699635925147,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "p5amrLZXIi",
        "forum": "AHgc5SMdtd",
        "replyto": "AHgc5SMdtd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission19/Reviewer_NLA8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission19/Reviewer_NLA8"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a MuSc model for zero-shot AC/AS. The method exploits the normal and abnormal information implicit in unlabeled test images without any training or prompts, A Mutual Scoring Mechanism (MSM) is proposed to assign abnormal scores to each other using unlabeled test images, and an optimization method based on constrained image-level neighborhoods (RsCIN) for image-level anomaly classification. The method shows better performance on MVTec AD and VisA datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea that normal image patches can be found in a relatively large number of similar patches in other unlabeled images, while abnormal image patches have only a small number of similar patches, is novel. The authors were able to accomplish this task simply by using a test dataset and utilizing the test images to score each other without any training or prompting.\n\n2. The authors considered the size of the anomalies in different datasets and used patch tokens with multiple aggregation degrees to obtain high-quality anomaly scores even when using a simple distance measure.\n\n3. The authors found that the image-level features satisfy the conditions of high-dimensional manifolds, and designed RsCIN based on manifold learning to optimize the pixel-level anomaly classification results, and experimentally verified the effectiveness of the module, proving that the proposed RsCIN module can further improve the performance of the existing methods."
            },
            "weaknesses": {
                "value": "Even without training or prompts, the method requires long inference times and high memory costs. While the authors provide a solution to increase speed and reduce memory by dividing the test set into subsets, this also reduces performance by a small margin. Are there any other approaches that could have been considered to solve the problem?\n\nThe authors should provide more detailed theories for MSM and RsCIN."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission19/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698901355281,
        "cdate": 1698901355281,
        "tmdate": 1699635925074,
        "mdate": 1699635925074,
        "license": "CC BY 4.0",
        "version": 2
    }
]