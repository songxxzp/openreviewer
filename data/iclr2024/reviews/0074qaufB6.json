[
    {
        "id": "46J8mL6uMo",
        "forum": "0074qaufB6",
        "replyto": "0074qaufB6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_fMm6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_fMm6"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a network architecture to try to recover time-series data for multi-stream tasks such as multi-microphone audio processing. The authors give some theoretical insights on the reasons behind suggesting the proposed architecture which resembles a data interpolation scheme conditioned on the per-sample information entropy. The proposed method shows that the usage of the extra modules that estimate the information entropy and the one that tries to perform interpolation between data streams performs better than a model without those modules for the tasks which are considered (e.g. multi-microphone estimation of arrival and multi-microphone sound event detection)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "I like the principled way that the authors tried to introduce their model by using a module that specifically tries to estimate the uncertainty of one value and another module that can use the previous results to generate the missing data (data streams with high uncertainty) using conditional interpolation."
            },
            "weaknesses": {
                "value": "- First of all, the early attention framework which performs the explicit estimation of the uncertainty of the data-streams was not compared to other alternative modules that could perform implicit uncertainty estimation of the data [A] and feature recovery (e.g. any GAN, VAE, diffusion generative model or even a simple discriminatively trained model using simple regression on the missing data-streams).\n\n- The authors completely omit to compare with even a single decent benchmark model in the tasks of degree of arrival estimation. There are hundreds of models that the authors could use to just show how their models compare against them, I will just cite some [B, C, D, E]. There is no way of knowing that this whole implicit uncertainty estimation and conditional interpolation would yield a higher performance over a simple baseline. The authors should explicitly describe how they applied the baseline models of the literature to this task and use widely known benchmark datasets to compare against.\n\n- The paper becomes almost unreadable with the extreme overuse of acronyms throughout the manuscript. The pages are more than enough to present everything without reducing the readability of the paper.\n\nI would be more than happy to increase my score if all the above weaknesses are addressed by the authors. \n\n[A] Ma, C., Li, Y. and Hern\u00e1ndez-Lobato, J.M., 2019, May. Variational implicit processes. In International Conference on Machine Learning (pp. 4222-4233). PMLR.\n\n[B] Sharath Adavanne, Archontis Politis and Tuomas Virtanen, 'Direction of arrival estimation for multiple sound sources using convolutional recurrent neural network' at European Signal Processing Conference (EUSIPCO 2018)\n\n[C] Sharath Adavanne, Archontis Politis and Tuomas Virtanen, 'Multichannel sound event detection using 3D convolutional neural networks for learning inter-channel features' at International Joint Conference on Neural Networks (IJCNN 2018)\n\n[D] Serizel, R., Turpault, N., Shah, A. and Salamon, J., 2020, May. Sound event detection in synthetic domestic environments. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 86-90). IEEE.\n\n[E] Papageorgiou, G.K., Sellathurai, M. and Eldar, Y.C., 2021. Deep networks for direction-of-arrival estimation in low SNR. IEEE Transactions on Signal Processing, 69, pp.3714-3729."
            },
            "questions": {
                "value": "1. What is the purpose of Figure 11? The authors mention that: \"From the figure, it is evident that how InfoNet\nsuccessfully recovers the missing information achieves better performance.\u201d How did the authors arrive at this conclusion? Better performance compared to some other model or some other method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5962/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698618130371,
        "cdate": 1698618130371,
        "tmdate": 1699636636496,
        "mdate": 1699636636496,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sPW0MSCdWh",
        "forum": "0074qaufB6",
        "replyto": "0074qaufB6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_tZQw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_tZQw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes InfoNet, a generalized algorithm that retrieves the information from a corrupted feature set to recover the inference performance loss due to corrupted input data streams. InfoNet estimates the information entropy at every element of the input feature to the network and retrieves the missing information in the input feature matrix. InfoNet is tested for two downstream applications, including sound source localization and wireless signal-based source localization, and has shown superior performance over baselines in corrupted data schemes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Missing or corrupted information under multi-stream sensors is a common setting in real life and has not been studied in sound source localization. The proposed method, based on estimation of information entropy is intuitive and has outperformed several baselines under this setting. The paper also conducts a thorough analysis of the proposed model."
            },
            "weaknesses": {
                "value": "1. Lack of stronger baselines. The proposed method is compared only to two simple baselines - retraining with missing streams and a basic time-domain recovery method. More recent approaches, such as those in [1] and [2], are not included in the comparison.\n2. The model is only tested under limited data setting (<100 hours).  It's unclear how the model performs in larger datasets, even though practical use cases often involve much more data (e.g., Audioset contains ~5k hours of multimodal signals)\n3. The downstream model for sound event localization is quite basic. Its performance with more recent sound event localizers (e.g., [3][4]) is unclear.\n\n\n[1]. Ma et al., SMIL: Multimodal Learning with Severely Missing Modality, in AAAI 2021\n\n[2]. Wang et al., Multi-modal Learning with Missing Modality via Shared-Specific Feature Modelling, in CVPR 2023\n\n[3]. Shimada,  et al., ACCDOA: Activity-coupled cartesian direction of arrival representation for sound event localization and detection, in ICASSP 2021\n\n[4]. Cao et al., An improved event-independent network for polyphonic sound event localization and detection, in ICASSP 2021"
            },
            "questions": {
                "value": "1. How does the model compare to other methods, such as those in [1] and [2], in sound event localization or other multimodal tasks like Audiovision-MNIST?\n2. How does the model perform in a larger data setting (e.g., audio-visual event classification)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5962/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807944071,
        "cdate": 1698807944071,
        "tmdate": 1699636636378,
        "mdate": 1699636636378,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Jf7a5eTpHO",
        "forum": "0074qaufB6",
        "replyto": "0074qaufB6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_9qjF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5962/Reviewer_9qjF"
        ],
        "content": {
            "summary": {
                "value": "* This paper presents an innovative algorithm, InfoNet, which addresses the challenge of corrupted sensor data in Deep Neural Networks (DNNs). InfoNet's novelty lies in its components: Early Attention (EA) for pinpointing problematic data, Deep Conditional Interpolator (DCI) for reconstructing missing information, and Guided Replacement (GR) for restoring data integrity. These innovations enable InfoNet to estimate information entropy and effectively retrieve missing data, thereby aiding in the recovery of DNN performance. \n* The algorithm's effectiveness is validated through sound localization tests, with its potential applicability to other sensing tasks, such as wireless localization, also being explored. \n* The paper details these novel components, the experimental setup, and discusses the broader implications for advanced techniques in managing incomplete or corrupted data inputs for DNN applications."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-\tNovel Components: InfoNet's innovative approach is underscored by its unique components\u2014Early Attention (EA) for targeted data analysis, Deep Conditional Interpolator (DCI) for accurate data reconstruction, and Guided Replacement (GR) for precise data input restoration. These improvements collectively enhance the algorithm's capability to estimate information entropy and retrieve missing information in multi-stream sensing systems, potentially addressing the challenges of corrupted data inputs in deep learning.\n-\tGeneralizability: The algorithm's utility extends beyond audio streams, as demonstrated by its potential for application in other sensing modalities, such as wireless signal-based source localization.\n-\tDetailed Evaluation: Extensive experimental evaluations provide a comprehensive comparison of the InfoNet algorithm against baseline methods. The results, highlighting significant performance improvements specifically in reducing localization errors, attest to the algorithm's effectiveness.\n-\tWell Written: The paper is well-structured with a clear writing style. \n-\tSoundness: The theoretical approach of the paper seems sound, and the method is well-grounded in information theory, specifically leveraging the concept of entropy to address missing information in multi-stream sensing systems."
            },
            "weaknesses": {
                "value": "-\tThe paper's experimental section adequately covers comparisons with baseline methods, but primarily takes SELDNet[1] from 2018 for its most recent comparison. This raises a question about whether the paper might have missed evaluating InfoNet against the latest developments in sound event localization and detection, which would provide a clearer picture of its relative performance to latest methodologies.\n-\tThe current approach, which combines concepts from information theory and feature extraction methods similar to U-Net, may not sufficiently demonstrate originality due to its simplicity. Incorporating more unique or novel elements into the proposed method could help enhance its originality and distinguish it from existing approaches.\n-\tWhile the experiments performed within the paper align with its scope, the absence of experiments involving other commonly encountered modalities such as images, videos, and text restricts the demonstration of the method's general applicability. If experiments in these additional modalities could be included, the authors can showcase the versatility and effectiveness of their approach across a broader range of data types.\n\n[1] Adavanne, Sharath, et al. \"Sound event localization and detection of overlapping sources using convolutional recurrent neural networks.\" IEEE Journal of Selected Topics in Signal Processing 13.1 (2018): 34-48."
            },
            "questions": {
                "value": "* The method appears to be a straightforward application of entropy concepts from information theory, combined with a U-Net-like feature extraction process. There's a concern about the overall originality and innovation of the approach.\n* Limited Experimentation and Potential Overstatement in Title: Experiments are primarily focused on sound localization with corrupted audio streams or wireless signal-based source localization. The absence of experiments in other modalities (like images, videos, and text) limits the understanding of the method's applicability and effectiveness across different domains.\n* The paper doesn't clearly specify what aspects are \u201chighlighted\u201d in Figure 1. This lack of clarity makes it difficult to understand the specific innovative elements or key features being presented.\n* Baseline's model structure is also quite simple; I question if it is because there is no up to date research in this direction.\n* Is there anything important about the \u201cstream\u201d in the title? It doesn't seem to require a lot of real-time?\n* What is the computational cost of InfoNet, especially when dealing with real-time data streams? Is the increase in performance justified by the computational overhead?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5962/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698910414535,
        "cdate": 1698910414535,
        "tmdate": 1699636636278,
        "mdate": 1699636636278,
        "license": "CC BY 4.0",
        "version": 2
    }
]