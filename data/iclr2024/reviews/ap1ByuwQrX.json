[
    {
        "id": "B6zlOS3B3c",
        "forum": "ap1ByuwQrX",
        "replyto": "ap1ByuwQrX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
        ],
        "content": {
            "summary": {
                "value": "Existing saliency methods have problems that are inconsistent with LLM generation goals or rely heavily on linear assumptions. To address this, this paper proposes token distribution dynamics (TDD) to unveil and manipulate the role of prompts in generating LLM outputs. TDD leverages the interpreting capabilities of the language model head to assess input saliency. It projects input tokens into the embedding space and then estimates their significance based on distribution dynamics over the vocabulary. Experiments reveal that the TDD surpasses baselines in elucidating the causal relationships between prompts and LLM outputs and achieves good results on two prompt manipulation tasks for control text generation tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The motivation of this paper is clear, and the method is simple and effective. The proposed token distribution dynamics (TDD) can unveil and manipulate the role of prompts in generating LLM outputs and it simply depends on the dynamic of token distribution.\n2. The method proposed in this paper works well and has achieved improved results on 11 datasets.\n3. In addition to achieving great improvement in elucidating the causal relationship between prompts and LLM output, the method in this paper also demonstrates its potential application value in controllable text generation tasks."
            },
            "weaknesses": {
                "value": "1. The TDD method is based on multiple assumptions listed at the bottom of page 4. Some assumptions are strong without any theoretical and experimental proof, especially the first and second assumptions.\n2. For controllable text generation, this paper uses simple meaningless space tokens as alternative tokens in toxic language mitigation. In sentiment direction, this paper uses simple key tokens \u201cpositive\u201d or \u201cnegative\u201d as alternative tokens. Although this can prove that the method in this paper has potential application value in controllable text generation tasks, this method is too simple for practical applications. And whether such a way will impact the reasonableness of the evaluation of the results.\n3. In controllable text generation tasks, only automatic evaluation is used, manual evaluation is lacking, and the indicators used in automatic evaluation are relatively simple. It is difficult to fully reflect the quality of the generated text, especially when there is no ground truth for the task of this paper.\n4. LLMs can already complete controllable text generation tasks well, such as by giving LLMs toxic prefixes and designed prompts, making LLMs generate non-toxic text. This paper lacks a comparison with them, which may reduce the application value of this work.\n5. The attribution of the prompt for the next token prediction is a simple problem that has been explored in many text classification tasks. The SOTA method such as integrated gradients (IG) should be also considered as a baseline. Furthermore, I think the attribution of the prompt for the sequence of generated text is a more practical task than the current one."
            },
            "questions": {
                "value": "The major concerns are listed in the Weaknesses. \n\nSome other questions are listed below.\n\n1. If it is in controllable text generation under multi-attribute control, what is the scalability and performance of this method?\n2. In the task of controllable text generation, the data used in this paper does not have ground truth, and the existing evaluation results cannot fully reflect the quality of the generated text. How does the method in this paper perform under manual evaluation?\n3. The highlighted number in Table 3 column 5 is wrong."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698481514797,
        "cdate": 1698481514797,
        "tmdate": 1700646444153,
        "mdate": 1700646444153,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lEKkIANTpv",
        "forum": "ap1ByuwQrX",
        "replyto": "ap1ByuwQrX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the roles of individual tokens in prompts in guiding the responses of LLMs. To analyze the dynamics of token distributions, this paper proposes three methods (TDD-forward, TDD-backward, TDD-bidirectional), each offering insights into token relevance. \n\nTDD-forward computes $r_i - r_{i-1}$, where each $r_i$ is the difference between the probability of token i (computed from a contextualized LM) and the probability of the alternative token. TDD-backward computes the probabilities at the last token, and uses $r_{i-1} - r_i$. TDD-bidirectional is the sum of the TDD-forward and TDD-backward.\n\nOn 11 out of the 67 datasets on BLiMP, this paper shows that TDD-based methods in general have better AOPC and Sufficiency results than multiple baseline methods. Additionally, in some case studies (toxic language suppression and controllable text generation), the TDD method works better than some baseline methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The method is simple and efficient.\n- The analysis towards understanding causal mechanisms of token probability distributions is a timely and important research topic."
            },
            "weaknesses": {
                "value": "- The TDD methods heavily depend on the alternative word $w_a$. The datasets chosen in this paper (those BLiMP datasets) provide sentence pairs with exactly one-word differences. Other datasets may not have such well-defined alternative words. This greatly limits the potential applicability of the proposed TDD methods.\n    - A related point: it is unclear to me how the w_a in the Section 5 experiments are identified.\n- The analyses presented in this paper are not really causal analyses, despite claims that the LM head \u201celucidate causal relationships between prompts and LLM outputs\u201d (page 4). No controlled variable is specified, and no treatment effect is measured. This paper could be much stronger if some sort of causal scores are computed, for example, how large is the treatment effect of changing w to w_a causes the toxicity of the generated texts. Currently, the numbers shown in Tables 3 and 4 look similar to the treatment effects, but without more descriptions about how the variables are controlled, we can\u2019t really say the numbers are treatment effects.  \n- A minor point about writing styles: Excessive adverbs (e.g., those in the sentence \u201celegantly simple yet remarkably effective\u201d) can make the paper read less rigorous, rendering the text resemble more of a social media post than a scientific paper."
            },
            "questions": {
                "value": "In section 5, which variant of TDD is used? Are TDD-forward used there?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698608903582,
        "cdate": 1698608903582,
        "tmdate": 1700629625370,
        "mdate": 1700629625370,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KdfxyTBbvU",
        "forum": "ap1ByuwQrX",
        "replyto": "ap1ByuwQrX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel method for constrastive XAI for autoregressive LMs. Instead of using gradients or attention maps, the introduced TDD approach is based on token distributions. TDD aims to explain token influence in the input prompt. To this end, three variants are presented: forward, backward, and bidirectional, as the authors describe, each offering unique insights into token relevance.\nThe introduced approach is evaluated based on the explanations' faithfulness and the capability to steer the model\u2019s outcome.\nSteering is done by replacing the most influential tokens and replacing them, e.g., with white space tokens."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed method is a simple and efficient method\n- In general, the paper is well-written, with a clear introduction method and description of experiments\n- Evaluation of multiple autoregressive models\n- The authors seem to provide all the necessary details for reproducible experiments\n- Additional showcasing on interesting and important use cases"
            },
            "weaknesses": {
                "value": "- The difference between the TDD variants is not well discussed. While the applications are very interesting, the authors could have used the space to elaborate on the differences between the introduced variants. \n- Captions Table 1 and Table 3 are too sparse.\n- While not being a contrastive XAI method, important related work on explainability for autoregressive LMs missing: \nATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation. Bj\u00f6rn Deiseroth, Mayukh Deb, Samuel Weinbach, Manuel Brack, Patrick Schramowski, Kristian Kersting. In Proceedings of NeurIPS 2023"
            },
            "questions": {
                "value": "- Can you elaborate on the difference between TDD and AtMan [Deiseroth et al., 2023] (see weaknesses) beyond contrastive explanations? It seems to be more similar to TDD than Rollout while at the same time relying on attention layers.\n- In the steering demonstration, multiple alternative tokens are used at the same time. As far as I understood, in Sec. 4, only one alternative token is selected. How robust is TDD when multiple alternative tokens are used?\n- Beyond the benchmark experiments, how would one select an alternative token to explain the LMs decision? \n- Which TDD variant is applied in the steering experiments? You mentioned that each TDD variant offers unique insights into token relevance. Can you further elaborate on this regard? Unfortunately, I could not find a discussion in the paper. Are there scenarios where one variant is beneficial? \u0010"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761974998,
        "cdate": 1698761974998,
        "tmdate": 1699636294417,
        "mdate": 1699636294417,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "x0vs3sffW2",
        "forum": "ap1ByuwQrX",
        "replyto": "ap1ByuwQrX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new method via using Token Distribution Dynamics (called TDD) to both interpret and control LLMs' generations. \n\nThe authors compared the proposed method with a few baselines (attention rollout, contrastive gradient) and show TDD obtains a more precise explanation with lower sufficiency. The authors also put TDD into real use for toxic language suppression and sentiment steering, and show TDD can effectively control LLMs' outputs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The idea of analyzing the token distributions throughout the progression of prediction is quite interesting. The idea is simple but seems to be quite useful in unveiling the importance of input tokens when providing contrastive explanations.\n\n- The authors did experiments over a fairly comprehensive set of language models including GPT-2/J, BLOOM, and LLaMA.\n\n- The applications on toxic language suppression and sentiment steering further demonstrate the usefulness of the proposed TDD method."
            },
            "weaknesses": {
                "value": "- One simple way to control LLMs' generations is via prompting for style transfer, e.g., ask the model to transform the outputs into \"less toxic\" content, or \"positive/negative\" sentiment. How would this baseline compare to the proposed TDD?\n\n- The models used in experiments are relatively smaller models (maximum size 7B), how would the proposed approach work on larger models (e.g., llama-2 13B, 70B)? What is the computation cost (efficiency, memory) for running TDD over larger models?\n\n- The proposed TDD provides contrastive explanations on the token level, it would be interesting to see if this method can be extended to higher-level concepts, e.g., why sometimes a model chooses to generate an unfaithful output."
            },
            "questions": {
                "value": "- Could the authors add a simple baseline by prompting the LLMs for style transfer on the outputs?\n\n- What is the computation cost (efficiency, memory) for running TDD over larger models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767244837,
        "cdate": 1698767244837,
        "tmdate": 1699636294342,
        "mdate": 1699636294342,
        "license": "CC BY 4.0",
        "version": 2
    }
]