[
    {
        "id": "4ISQhGuxBn",
        "forum": "zIrpuifCJW",
        "replyto": "zIrpuifCJW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission517/Reviewer_FieS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission517/Reviewer_FieS"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to explore the influence of the information entropy change, and specifically analyzes the impact of various types of noise, i.e., Gaussian noise, linear transform noise, and salt-and-pepper noise, on the performance of deep learning models for image classification and domain adaptation tasks. The authors verify their method on different network architectures, i.e., CNNs and ViTs, and show that the positive noise injection can improve the accuracy of image classification."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The proposed method of using noise injection to improve the performance of CNNs and ViTs, which has not been extensively explored before.\n\n2. The article is well-written and easy to understand, with clear explanations of the proposed method and the experimental results."
            },
            "weaknesses": {
                "value": "1.Limited analysis between data augmentation and the proposed noise injection. It seems more like a feature augmentation method for different layers. The article claims that the positive noise is benefit of the classification network, but it is hard to measure the noise level for the positive/negative influence. It is encouraged to compare the difference between the data augmentation with noise and the proposed method.\n\n2.Noise definition confusion. Unlike Gaussian noise and salt-and-pepper noise with the specific probability distribution, the linear transform is not a kind of noise, but a simple operation. \n\n3.Limited analysis of the tasks. The authors leverage the proposed method in image classification tasks, including domain adaptation. It is encouraged to conduct the noise injection in image object detection/segmentation tasks, or some NLP tasks, to verify the effectiveness of the proposed method."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751052146,
        "cdate": 1698751052146,
        "tmdate": 1699635978753,
        "mdate": 1699635978753,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zqc6YOGIhj",
        "forum": "zIrpuifCJW",
        "replyto": "zIrpuifCJW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission517/Reviewer_eupP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission517/Reviewer_eupP"
        ],
        "content": {
            "summary": {
                "value": "This paper examines the impact of task entropy change in deep neural networks by introducing noise at different levels in a network, and demonstrates that certain kinds of noise can actually help with learning by reducing the task entropy. The paper differentiates between \"positive noise\" (PN) that can enhance system performance by reducing task complexity and \"harmful noise\" (HN) that deteriorates it. The concept of \"positive noise\" is introduced in [1] which this work cites. By using information entropy as a measure of task complexity, the research shows that intentionally adding positive noise can substantially improve performance. The empirical findings challenge traditional views on noise in deep learning, suggesting that positive noise can be beneficial. Results are demonstrated using networks from the ResNet and ViT family for classification on ImageNet and using ViT-B for unsupervised domain adaptation on Office-Home and Visda2017 datasets.\n\n[1] Xuelong Li. Positive-incentive noise. IEEE Transactions on Neural Networks and Learning Systems,\n2022."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written. The supplementary section provides further details on the derivations, which is very helpful.\n\nThe technique is well motivated and the empirical results are quite impressive.\n\nThis work provides an interesting new perspective on positive noise injection which can help training."
            },
            "weaknesses": {
                "value": "No error bars in any tables - did the authors run multiple seeds for their experiments? Even though the improvements are generally large, it is nice to see these in the tables/figures.\n\nThe technique is only evaluated on classification using ImageNet and domain adaptation. It would be good to see results on other tasks like object detection perhaps, and specially domains like Natural Language Processing, which differ from vision based tasks."
            },
            "questions": {
                "value": "Given that the improvement is so large on ResNet-18, do the authors have an explanation for why ViT-T does not improve similarly?\n\nCan the authors elaborate on this statement? \"Besides, when the models are corrupted under brute force attack, the positive noise also can not work.\" Why is this the case?\n\nThis point also requires more detailed explanation - \"Second, injection to shallow layers obtain less entropy change gain because of trendy replacing Equation 8 with Equation 7.\" The explanation for why shallower layers don't provide as high accuracy gains as deeper layers can be improved. \n\nHave the authors tried combinations of later layers for noise injection?\n\nGiven that this is a new perspective and the results are strong, will code be released for reproducibility?\n\nCan the authors give other examples of positive noise that they considered?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission517/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission517/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission517/Reviewer_eupP"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817771846,
        "cdate": 1698817771846,
        "tmdate": 1699635978684,
        "mdate": 1699635978684,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kt29EuvCAy",
        "forum": "zIrpuifCJW",
        "replyto": "zIrpuifCJW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission517/Reviewer_H7oc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission517/Reviewer_H7oc"
        ],
        "content": {
            "summary": {
                "value": "This research investigates the impact of noise-induced entropy changes in deep learning systems, focusing on computer vision tasks. While noise is traditionally seen as detrimental, this study demonstrates that specific noise, termed positive noise (PN), can enhance deep learning model performance by reducing task complexity defined by information entropy. The study introduces a distinction between positive noise (beneficial) and harmful noise (detrimental) and shows that proactive injection of positive noise significantly improves accuracy, achieving over 95% on ImageNet. Besides, this paper explores three types of noises. But the difference of positive noises on different kinds of noise types lacks discussion."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths:\n- This paper challenges the notion that noise always hampers deep learning models, showcasing its potential as a positive influence.\n- It offers theoretical insights, distinguishing noise impact at different levels, aiding in optimizing task complexity.\n- Experiments on both CNNs and Vision Transformers are conducted."
            },
            "weaknesses": {
                "value": "- The range of tasks tackled remains relatively limited, lacking diversity and complexity in comparison to broader applications. To be specific, this paper only conducts experiments on classification tasks. More results on other tasks (e.g., regression tasks like Object Detection or generative tasks like language understanding)  are lacking to validate its generalization ability."
            },
            "questions": {
                "value": "For each type of noise, there will exist positive noises. What are their difference and influences?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835383757,
        "cdate": 1698835383757,
        "tmdate": 1699635978616,
        "mdate": 1699635978616,
        "license": "CC BY 4.0",
        "version": 2
    }
]