[
    {
        "id": "MKC1v6qMun",
        "forum": "0d1gQI114C",
        "replyto": "0d1gQI114C",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_fLuR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_fLuR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a post-training quantization method for LiDAR-based 3D object detection. It uses min-max quantization and proposes task-guided global positive loss.\nThe experiments are conducted in the Waymo Open Dataset with CenterPoint detector, achieving competitive performance among other quantization methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper achieves competitive results compared with other quantization methods.\n- The writing is clear and easy to follow.\n- Although the proposed method is quite simple, it is fast and pratical."
            },
            "weaknesses": {
                "value": "### This paper lacks novelty and originality. \n- Although the authors propose the so-called sparsity-based calibration and conduct the spatial sparsity analysis, the implementation simply adopts the max-min calibration without any unique designs.\n- The proposed TGPL is also a trivial technique, which basically selects some high-confidence prediction for supervision and this is widely-adopted in many fields such as distillation. \n### Some claims are inaccurate or wrong.\n\"Point cloud coordinates have explicitly encoded the shapes and geometrics of objects, so the larger arithmetic range of input point\ncloud preserves essential geometric information.\"  By this sentence, the authors indicate the large range of point cloud coordinates makes the detectors sensitive to quantization range. However, in fact, LiDAR-based object detectors do not take the absolute point cloud coordinates as input. Voxel encoders usually calculate the relative coordinates within each voxel as input.\n### The application is a little bit narrow.\nThere are emerging methods of \"fully sparse detectors[1][2][3]\", which show impressive efficacy and efficiency and do not lead to zero feature maps. Thus the proposed method (sparsity-based calibration) has no advantages in these methods.\n\n[1] Fully Sparse 3D Object Detection, NeurIPS 2022. \\\n[2] Super Sparse 3D Object Detection, TPAMI 2023. \\\n[3] VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking, CVPR 2023."
            },
            "questions": {
                "value": "No more additional questions. Looking forward to the authors' response to my concerns in the weaknesses box."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2446/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2446/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2446/Reviewer_fLuR"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2446/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698479545405,
        "cdate": 1698479545405,
        "tmdate": 1700457001039,
        "mdate": 1700457001039,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fl9ZFh9MQS",
        "forum": "0d1gQI114C",
        "replyto": "0d1gQI114C",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_3wrT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_3wrT"
        ],
        "content": {
            "summary": {
                "value": "Running neural nets for object detection on an edge device requires quantization of the network so that it can fit on the limited memory of the device and perform inference at an adequate (real-time) speed.\nTraditionally, post-training quantization (PTQ) for vision tasks utilizes a small set of unlabeled samples as a calibration set. These samples are used to quantize the weights and activations of the network using max-min and information theory to minimize KL-divergence between the quantized and non-quantized tensor. The information-theory based method which performs well for 2D object detection does quite poorly on 3D LIDAR object detection because of sparsity in the point cloud. This paper describes a LIDAR-PTQ method that quantizes existing LIDAR object detectors like the Centre-point-pillar. It uses a sparsity based calibrator, a Task-Guided Loss (which calibrates the quantization parameters using performance on the final object detection task) and an adaptive rounding-to-nearest loss which determines whether the weight in a particular neuron should be rounded up or down.\n\nExperiments demonstrate similar performance to the floating point model on the NuScenes and Waymo datasets, but with a 3x inference speedup on a Jetson AGX Orin edge device."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is on the whole well written and does a good job of introducing the reader to the subject of neural network quantization. It describes an algorithm for the important task of adapting large neural nets for operation on the edge, while preserving model accuracy. Since there is relatively little work on LIDAR network quantization, the paper is timely and important."
            },
            "weaknesses": {
                "value": "There is not enough detail about the optimization steps: particularly which parameters are optimized when and what percentage of training data is required for this post-training quantization. The task-guided loss minimizes the distance between the output of the quantized network vs the non-quantized network and so presumably requires the labelled training data. This seems to deviate from the requirements of PTQ, which only seems to need a small number of unlabeled samples as the calibration set.\nEven though the combined system with max-min quantization + grid search + TGPL + Adaptive Rounding together approach the mAP of the FP model, the contribution in narrowing the gap between max-min and the final model seems to be mainly by the grid search. The TGPL and Adaptive Rounding contribute relatively small gains to the mAP. This could be a quirk of the dataset / optimization parameters / training regime and I would ideally like to see more experiments to be convinced of the efficacy of TGPL and Adaptive Rounding, even though from a conceptual point of view, they make sense.\nI would like the code to be released so that independent validation of the authors\u2019 experiments can be performed."
            },
            "questions": {
                "value": "-What is LEVEL_2 mAPH in Table 1? Please clarify this closer to the table\n-Page 5: Huge \u2018sparisity\u2019 lead to inappropriate quantization range. \n\u2018Sparisity\u2019 should be sparsity\n-Page 7: \u2018\u2026 are the soft-quantized weights follows Eq 11\u2019. \nI think you mean equation 10?\n-Page 7: \u2018NuSecens\u2019 should be NuScenes"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2446/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698978681634,
        "cdate": 1698978681634,
        "tmdate": 1699636180427,
        "mdate": 1699636180427,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7Gl8jbTgUk",
        "forum": "0d1gQI114C",
        "replyto": "0d1gQI114C",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_Dy1B"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_Dy1B"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a Post-Training Quantization (PTQ) compression approach, LiDAR-PTQ, for the real applications of 3D LiDAR point cloud detection that are deployed on edge GPU systems. The key ideas include density-aware calibration, task-guided global positive loss and layerwise-reconstruction-based adaptive rounding.  The proposed method is evaluated on the Waymo dataset to validate the low performance-drop with INT8 compared with FP32."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is  easy to understand.  The analysis of why 2D-PTQ can\u2019t be directly applied to 3D is reasonable and the corresponding solution is practical. \n-  The proposed LiDAR-PTQ achieves competitive  detection performance as INT8 quantization for bothe CP-Pillar and Voxel."
            },
            "weaknesses": {
                "value": "- The method is only evalutated on the PointCenter model, how about the effect for other types of detectors (Transform-based, etc.).\n- It is said that the method is evaluated on various datasets (Waymo and NuScenes). However, results on  NuScenes seem not available."
            },
            "questions": {
                "value": "- Comparisons of inference acceleration performance with other baselines are not available in Tab.3.  Accuracy together with speed performance can better demonstrate the advantages of the proposed method.\n- How is \u03b3 set for TGPL?\n- It is wrotten that \u201cthere is no extra access to labeled training data\u201d. Dose this work like the knowledge distillaatio  from the full FP32 model  for an INT8 quantizated model?\n- For results on Waymo, can authors give some explaination about why  select LEVEL2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2446/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699339046031,
        "cdate": 1699339046031,
        "tmdate": 1699636180329,
        "mdate": 1699636180329,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kGG0bSazcg",
        "forum": "0d1gQI114C",
        "replyto": "0d1gQI114C",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_szHU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2446/Reviewer_szHU"
        ],
        "content": {
            "summary": {
                "value": "This paper describes an approach for model compression for applications using 3D Lidar data, namely 3D object detection.  The approach is based on post-training quantization.  The paper shows that direct application of post-training quantization methods used with 2D images leads to a decrease in performance. The method proposed in the paper is based on a sparsity-based calibration followed by the application of a task -guided global positive loss and finally by the application of an adaptive rounding-to-nearest operation. Experimental results show that the proposed approach achieves state-of-the-art performance, namely that the accuracy of the model with PTQ INT8 is at the level of the accuracy of the model using FP32. The inference speed is increased 3 times."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper shows that the simple and direct application of approaches commonly used for model compression in applications with 2D images leads to a decrease in performance (when applied to object detection with 3D lidar data) and proposes a new method for model compression (for 3D Lidar data and for object detection). This new model achieves similar accuracy to a full precision model and achieves an increase in inference speed (3x). The authors also analyze and discuss the reasons that may be the cause of such behavior. Such analysis is qualitative---no experimental validation. The proposed approach is clear and contributes a solution to a well-defined problem."
            },
            "weaknesses": {
                "value": "The main weakness of the paper results from the experimental results (and validation) having been obtained for a single application: CenterPoint (in both versions, Pillar and Voxel).  This is too specific, and it is not clear that similar results could be obtained with other applications using 3D Lidar data, e.g., segmentation."
            },
            "questions": {
                "value": "Two main questions:\n--Would  similar results be obtained with other object detectors based on Lidar data?\n--Would similar results be obtained with other applications using Lidar data, e.g., segmentation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2446/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699528262973,
        "cdate": 1699528262973,
        "tmdate": 1699636180264,
        "mdate": 1699636180264,
        "license": "CC BY 4.0",
        "version": 2
    }
]