[
    {
        "id": "TKmlz4MjpI",
        "forum": "L7jtdGhWzT",
        "replyto": "L7jtdGhWzT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_8Ctj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_8Ctj"
        ],
        "content": {
            "summary": {
                "value": "This paper targets interpretable and faithful explanations for specific neural inferences. Currently, feature attribution is a commonly used technique for interpretability and input perturbation is used to objectively quantify the faithfulness of an attribution to the model by masking out salient or monotonous features. These approaches overlook the faithfulness of attribution to the hidden-layer encodings. Thus, this paper tries to measure the faithfulness of hidden layer representations, leading to an optimization method for attribution."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Pros:\n- This work focuses on an overlooked problem: faithfulness to hidden layer representations, which is worth exploring.\n- The ensemble method can remove the need for hyper-parameters and is effective as well.\n- Gradient clipping is able to maintain internal faithfulness as shown with visualization results."
            },
            "weaknesses": {
                "value": "Cons:\n- Lack of in-depth discussion of the visualization result. It seems that EP can also obtain good visualization and locate the Submarine better than FEI. It would be better to discuss the impact of 'hot' and 'cold' areas in heat map."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Reviewer_8Ctj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3961/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761596371,
        "cdate": 1698761596371,
        "tmdate": 1699636357201,
        "mdate": 1699636357201,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MVO0wRoHZ3",
        "forum": "L7jtdGhWzT",
        "replyto": "L7jtdGhWzT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_tHJd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_tHJd"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel neural network explanation method driven by faithfulness in both model decisions and internal model functioning. It combines ensemble approximation with gradient clipping. Additionally, it proposes a new qualitative metric that implicitly assesses internal faithfulness. Reasonable qualitative and quantitative results are reported."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method makes sense to me.\n2. The paper is generally well-written.\n3. The qualitative results are reasonable."
            },
            "weaknesses": {
                "value": "I am not familiar with interpretable deep learning, so I am not sure if the quantitative results are sufficient and significant. The baselines are outdated - Extremal Perturbation(EP) Fong et al. (2019), RISE Petsiuk et al. (2018), FGVis Wagner et al. (2019), GradCam Selvaraju et al. (2017) and Integrated Gradient Sundararajan et al. (2017), so I do not take them as competitors powerful enough. Though the qualitative results with several images make sense to me, I cannot be fully convinced by such an insufficient quantitative comparison."
            },
            "questions": {
                "value": "I would suggest the authors include quantitative results with recently proposed competitors.\n\nI will lower my rating if the other reviewers' comments on the quality of the quantitative analysis agree with mine.\n\nIf the AC and other reviewers are familiar with this research area and believe that the presented results are sufficient enough, please let me know and I will be happy to raise my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3961/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810503995,
        "cdate": 1698810503995,
        "tmdate": 1699636357102,
        "mdate": 1699636357102,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KM4I6H1ssY",
        "forum": "L7jtdGhWzT",
        "replyto": "L7jtdGhWzT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_xnf4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3961/Reviewer_xnf4"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new framework for faithfulness based attribution. They use a differentiable approximation of fractiles to allow them to optimize an otherwise non-differentiable objective. They then optimize this and average over different fractiles and use the resulting attribution map to evaluate several metrics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper improves the Q_P metric over the selected baselines."
            },
            "weaknesses": {
                "value": "- Section 3 is difficult to understand, at least partially due to notation. For example, the LHS of (2) seems to be a scalar based on notation (dot products on the RHS), but from context it seems that the authors are using the \\cdot to mean element-wise multiplication (Hadamard product).  There are other things that are confusing like having $\\alpha_f(p)$ and then $\\alpha_p$, where $p$ presumably means different things in each context - it's an argument, but then it's also used as the fractile. Another example; in (3), $\\tilde x$ and $l_{faith}$ should be notated to depend on $f$. \n\n- The relation between faithfulness metrics and faithfulness optimization is unclear\n\n- The results seem mixed at best; there is improvement in Q_P, but overall Q_D is not improved and their defense mechanisms seem to be worse than baseline (this section was difficult to interpret, but based on the text it seems that lower is better)."
            },
            "questions": {
                "value": "1. In 3.2, you define a consistency constraint $\\alpha_1 \\le \\alpha_2$ and then state that optimizing under these constraints is challenging. Have you considered parameterizing $\\alpha$ as a cumulative sum? e.g. $\\alpha_i = \\sum_{j\\le i} \\delta_j$ In this case, the constraints becomes $\\delta_j > 0$ and $\\alpha_N=1$, which is easier to handle in an SGD framework.\n\n2. Since there are two faithfulness metrics Q_P and Q_D, how does l_faith relate to them? Is it only optimizing perturbation (a hunch based on table 1 results)?\n\n3. What is $\\bar x$ in (5)? Is it the same as $\\tilde x$?\n\n4. Are the gradients clipped at every single layer? if not, how do you define the decomposition of the network?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3961/Reviewer_xnf4"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3961/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698941435597,
        "cdate": 1698941435597,
        "tmdate": 1699636357033,
        "mdate": 1699636357033,
        "license": "CC BY 4.0",
        "version": 2
    }
]