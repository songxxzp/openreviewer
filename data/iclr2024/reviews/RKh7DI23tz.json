[
    {
        "id": "yyYyHmdVNW",
        "forum": "RKh7DI23tz",
        "replyto": "RKh7DI23tz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_aeLC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_aeLC"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the user of weight decay (WD) in deep learning. There are three main contributions of the paper:\n\n1. The authors state that WD results in implicit regularization by controlling the learning rate. They provide two conjectures which build on empirical observations they have made. \n2. The authors replicate findings from (Hoffman el al. 2022), showing that WD leads to lower final loss in the final stages of training LLMs. The authors argue that WD will modulate the effective LR.\n3. The authors observe that for a small GPT style model, WD allows better stability when training in bf16. The authors hypothesize that WD alleviates precision issues for bf16."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "WD is very common, so demonstrating something novel about it would be very impactful. \nThe paper is rather well written."
            },
            "weaknesses": {
                "value": "1. The arguments in finding (1) are very handwavy, and they are rather similar to observations done in earlier papers. It would be better if the authors could show proofs and theorems instead of conjectures.\n2. Finding (2) from the paper is not novel. The observation that WD will increase the effective LR has been made in (Van Laarhoven, 2017). Furthermore, as stated in the text, the observations on WD for LLMs have been made by (Hoffman el al. 2022)\n3. Finding (3) the paper is interesting, but the authors do not really explain why WD allows for better stability in bf16 training. The paper states that \u201cWe suspect this precision limitation is the primary challenge in bfloat16 runs without weight decay\u201d. This must be true per definition if fp32 works but bf16 does not, so it\u2019s not a very insightful statement."
            },
            "questions": {
                "value": "Can you verify your hypothesis for bf16 training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8408/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697493563199,
        "cdate": 1697493563199,
        "tmdate": 1699637047072,
        "mdate": 1699637047072,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oa4ep5lGPR",
        "forum": "RKh7DI23tz",
        "replyto": "RKh7DI23tz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_8iM1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_8iM1"
        ],
        "content": {
            "summary": {
                "value": "This paper studies why we need weight decay in modern neural networks. The paper claims that, different from the regularization role in conventional machine learning, weight decay has novel roles and various roles for over-parameterized neural networks and under-parameterized neural networks. For over-parameterized neural networks (CNNs), weight decay modifies the optimization dynamics and enhancing the ever-present implicit regularization of the SGD noise. For under-parameterized neural networks (LLMs trained with nearly one-pass SGD), weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss. Preventing sudden loss divergences for mixed-precision training of LLMs is also reported for weight decay."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "-\tThis work focuses on an important topic: the role of weight decay in modern neural networks. Novel insights and observations about weight decay are presented.\n-\tThe empirical results ranging from CNNs to Large Language Models are appreciated. Particularly, the empirical analysis of weight decay on Large Language Models have rarely touched by previous studies. \n-\tThe theoretical results are helpful for understanding the empirical results."
            },
            "weaknesses": {
                "value": "-\tThis work divided modern neural networks into two classes: over-parameterized neural networks (using ResNet and VGG) and under-parameterized neural networks (using Large Language Models trained with nearly one-pass SGD). The classification of modern neural networks is very confusing and may be the most significant weakness in this work. I agree that weight decay may have different roles in the two classes of neural networks according to the empirical results. But does over-parameterization and under-parameterization matter here? What is exactly over-parameterization and under-parameterization in this paper. Could it be because ResNet and VGG are CNNs, while Large Language Models are Transformers? Could it be because we train CNNs for many epochs, while we train LLM for only one epoch? Could it because the ratio of the training data size to the number of model parameters?\n-\tCan weight decay prevent sudden loss divergences for training of neural networks beyond mixed-precision training of LLMs? I believe this does not only happen to mixed-precision training or LLMs. I once observed similar phenomenon for CNNs. As this is a main contribution of this work, it is necessary to further explore this topic. \n-\tThe contributions and conclusions in this work are not informative and quantitative enough. The qualitative conclusions are helpful but not as significant as quantitative ones. For example, what is the quantitative difference between the so-call over-parameterized neural networks and under-parameterized neural networks? The theoretical contributions are also weak due to lack of quantitative analysis and conclusions. \n-\tA small point. While I think this work did a relatively complete literature review to my knowledge, a recent relevant work on weight decay (https://arxiv.org/abs/2011.11152) is missing in Sec. 2."
            },
            "questions": {
                "value": "Please see the questions associated to the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8408/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8408/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8408/Reviewer_8iM1"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8408/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698233342137,
        "cdate": 1698233342137,
        "tmdate": 1699637046965,
        "mdate": 1699637046965,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zIwpKU1XHy",
        "forum": "RKh7DI23tz",
        "replyto": "RKh7DI23tz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_Crhm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_Crhm"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the effect of weight decay in modern deep learning tasks, ranging from computer vision to language modeling."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The literature review seems complete."
            },
            "weaknesses": {
                "value": "- Global impression: I think this paper gathers a lot of information and concludes many different things in a succession of paragraphs. It is quite hard to follow the reasoning of the authors as the paper is too dense (or at least should be reorganized).\n- As a consequence of the previous point, it is difficult, after reading the paper a few times, to have a clear idea of what are the conclusions of the paper.\n- I think vision experiments are a bit too light to conclude, for all modern deep learning, from them. I think a vision transformer, or more complicated dataset (mini Imagenet?) would have strengthened this part of the paper. \n- In the end, it is hard to grasp what influences experimental results: architecture, optimizer, dataset? It is not very clear to me after reading the paper.\n- It is not very clear to me where the two conjectures come from? I think it is from observations, but is it enough to observe that the loss and the trace of the hessian decrease together (fig 3) to conjecture equation 4 and 5? Did the authors try to observe other important quantities to decorrelate their influence with the trace of the Hessian?\n- I don't think the authors give a reason on why weight decay may stabilize the training in bf16? Can they give an intuition?\n- I don't think the assumptions of Proposition 3 are reasonable: bounded weights and gradients are strong assumptions. Did the authors try to relax them to let's say, subgaussian? Also, m and M should depend on the dimension of the gradient of h, they are not constant? \n- I was surprised by the result on page 8: the loss scaling as $O(\\eta)$? This is a very loose bound?"
            },
            "questions": {
                "value": "- I think $\\sigma_\\eta$ was nowhere defined? (I may have missed it).\n- What does \"mixing in the function space\" mean? When first reading this paragraph, I had the feeling that it was written there just to impress the reviewer/reader with mathematical terms, that are not well defined in the paper.\n- I understand the authors may be on a reduced compute budget, but why setting the context length of the GPT2 model to 256? Why not set it to the standard 1024 and reduce the batch size? Due to stability reasons?\n- Do the authors clip gradient values in the GPT2 experiments as it seems to be standardly done?\n- Page 8: what does \"homogeneity of the training loss\" mean?\n- Page 9: I think there is a typo \"with only 7 bits for the fraction instead of 23\" ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8408/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698339454474,
        "cdate": 1698339454474,
        "tmdate": 1699637046831,
        "mdate": 1699637046831,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ThmgT2Fgps",
        "forum": "RKh7DI23tz",
        "replyto": "RKh7DI23tz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_hANA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_hANA"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the effect of weight decay in modern deep learning, such as overparameterized models and large language models. The main finding is that, on over-parameterized models, weight decay regularizes the trace of Hessian implicitly, while on LLMs, weight decay mainly benefits the optimization dynamics instead of regularizing the model. Finally, the paper finds the reason for why LLM training has loss spikes from the perspective of the low precision of bfloat16."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well-written and quite interesting to read. It proposes to investigate the important question on the effect of weight decay.\n\nThe idea that weight decay helps regularize the trace of Hessian is novel as far as I know.\n\nThe section about bfloat16 training of LLMs looks quite interesting."
            },
            "weaknesses": {
                "value": "Some conclusions in this paper are not quite rigorous, listed as follows.\n\n1. Section 3.3 presents one of the major findings of the paper using just three learning rate values, so it is hard to say whether the conclusion is generalizable to different learning rate settings with a larger range.\n\n2. Section 4 draws a conclusion that weight decay in LLMs is not regularization based on the qualitative result in Fig. 4. This does not look quite rigours, as it is not clear what is the meaning of not regularization and how to tell weight decay is regularization or not based on a quantitative measurement.\n\n3. It is not clear to me how the bfloat16 issue is directly related to weight decay. In other words, how weight decay helps to address the precision issue is not quite well explained. \n\nOverall, I think the paper is quite promising but some important issues should be fixed. I am happy to increase my scores if my concerns and questions can be addressed."
            },
            "questions": {
                "value": "1. The projected SGD in scale-invariant neural networks is investigated in existing research [1,2,3]. Could the authors provide a discussion on these related research?\n\n2. Third line of Fig. 2's caption should be Fig 2b instead of Fig 2d.\n\n3. I don't quite get the meaning *The model with the largest LR exhibits the smallest $Tr(\\Delta)$*, which is contradictory to the result of Fig. 3.\n\n4. I understand that the trace of the Hessian is hard to optimize for large models, is it possible to show the regularization effect for smaller models like two-layer MLPs?\n\n[1] Huang, Lei, et al. \"Projection based weight normalization: Efficient method for optimization on oblique manifold in DNNs.\" Pattern Recognition 105 (2020): 107317.\n[2] Liu, Ziquan, et al. \"Weight Rescaling: Effective and Robust Regularization for Deep Neural Networks with Batch Normalization.\" arXiv preprint arXiv:2102.03497 (2021).\n[3] Wan, Ruosi, et al. \"Spherical motion dynamics: Learning dynamics of normalized neural network using sgd and weight decay.\" Advances in Neural Information Processing Systems 34 (2021): 6380-6391."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8408/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698939319273,
        "cdate": 1698939319273,
        "tmdate": 1699637046681,
        "mdate": 1699637046681,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5neNEq9Ym9",
        "forum": "RKh7DI23tz",
        "replyto": "RKh7DI23tz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_i8U2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8408/Reviewer_i8U2"
        ],
        "content": {
            "summary": {
                "value": "The study explores the necessity of weight decay in deep learning, specifically addressing its relevance and effects. Key contributions of the research include:\n1. Weight decay is shown to enhance the implicit regularization of SGD noise in overparameterized networks by maintaining the learning trajectory close to that of a process with a regularized Hessian trace.\n2. In LLMs trained with nearly one-pass SGD, weight decay does not act as a significant regularizer but adjusts the effective learning rate and improves the bias-variance tradeoff, reducing training loss.\n3. Weight decay also serves to prevent abrupt loss divergences during bfloat16 mixed-precision training, critical for training LLMs at scale."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A great deal of research has been done on weight decay.\nThe authors analyze the role of weight decay in models such as overparameterization and LLM in the context of a large number of existing studies."
            },
            "weaknesses": {
                "value": "The novelty of this paper is very difficult to understand.\nThe reason for this is that so many other papers are cited in the analysis section of this paper that it is difficult to tell the difference between them.  \nThe discussion of whether the results are similar or different in existing studies is mixed, so it is not clear whether what is shown in this paper is really something novel.\n\nAlso, the third analysis regarding bfloat16 seems to be not so novel. \nThe paper states the following,\n\n>We suspect that LLM practitioners may be aware of this phenomenon\n>qualitatively, but we could not find any systematic reference addressing it. \n\nwhich does not seem to reveal anything new beyond simply a question of bfloat precision.\n It seems to me that the effect of the weight decay in suppressing large values is simply to suppress overflow.\nIs there something more to it than that. \nWhat more is there to say?"
            },
            "questions": {
                "value": "A better way to claim novelty from other papers would be to make a table showing how what is shown in this paper differs from the papers cited in the analysis part.\nWould it be possible to make such a table that shows at a glance the differences from existing studies?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8408/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699065902028,
        "cdate": 1699065902028,
        "tmdate": 1699637046541,
        "mdate": 1699637046541,
        "license": "CC BY 4.0",
        "version": 2
    }
]