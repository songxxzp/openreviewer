[
    {
        "id": "sspd3Z0Ozk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_FS1c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_FS1c"
        ],
        "forum": "nr0w6CH7v4",
        "replyto": "nr0w6CH7v4",
        "content": {
            "summary": {
                "value": "Inspired by the success of RLHF to align large language models, the paper introduces Quality Diversity through Human Feedback (QDHF).\nThe main motivation is to learn a diversity model instead of using adhoc diversity metrics, by analogy with reward modeling in place of hand-engineered rewards in RLHF.\nThis paper demonstrates empirically that using those diversity models (trained by contrastive learning) improves the results obtained with standard diversity metricsfor automated diversity discovery. Furthermore, when used in image generation tasks, QDHF can generate diverse images for a given caption (\"a photo of an astronaut riding a horse on mars\")."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Novelty: Using diversity modeling from feedback is innovative, and presents a fresh way to look at diversity.\n- Results: The study supports empirical evidence indicating that QDHF works.\n- Applications: This method can be applied in diverse domains like image generation."
            },
            "weaknesses": {
                "value": "- The only large scale experiment, on image generation, is actually restricted to a singular prompt with 16 generated images. More experiments are required.\n- The papers include \"human feedback\" in its title, but actually all the experiments are with automatic feedback.\n- The paper could benefit from a clearer exposition of implementation choices. The absence of supplementary materials exacerbates this opacity.\n- Minors\n    * I find the paper quite complex to follow for the readers not well-versed with Quality-diversity.\n    * An ablation study highlighting the impact of various design choices would have added depth to the research."
            },
            "questions": {
                "value": "- Regarding the image generation experiment, I'm unclear about the source of randomness. Is the randomness exclusively attributed to the diffusion process? Or is there also an element of prompt modification? Additionally, could you elucidate how the cells are defined in image generation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Reviewer_FS1c"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6896/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697206127792,
        "cdate": 1697206127792,
        "tmdate": 1699636802306,
        "mdate": 1699636802306,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Wm5tolyH6G",
        "forum": "nr0w6CH7v4",
        "replyto": "nr0w6CH7v4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_5CR4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_5CR4"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates how to learn diversity metrics from human feedback, which is beneficial as typically diversity metrics must be manually specified. They propose a new algorithm, QDHF which uses human feedback to infer diversity metrics. QDHF can outperform the AURORA algorithm for diversity discovery."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strength 1: Brings up interesting problem of how to learn diversity metrics from human feedback.\n\nStrength 2: The proposed QDHF algorithm seems to be novel."
            },
            "weaknesses": {
                "value": "Weakness 1: The writing is not very clear. There are numerous typos and the importance / use cases of diversity metrics is not made clear in the introduction.\n\nWeakness 2: This paper only uses one baseline algorithm (although several variants are considered) and this algorithm is unsupervised. The authors then claim that their algorithm can \"outperform current QD\" methods, but this is not at all a fair comparison. I think this difference in settings should be addressed more clearly.\n\nWeakness 4: The qualitative evaluation of the LSI seems not very rigorous. In particular, I think that selecting images with the highest clip score in the left hand column may be incorrect, as selecting based on clip score alone could diminish the diversity. In addition, I think the authors should try to do a large scale/quantitative evaluation. Otherwise it is hard to tell if this scenario is cherry-picked. Moreover, I think that the authors should compare with some simple heuristics for increasing generation diversity, such as using different generation hyperparameters.\n\nWeakness 3: This paper claims that they are expanding RLHF to consider the diversity of the generated responses/solutions, but the experiments do not show such results in typical RLHF environments and the paper does not compare their algorithm with standard RLHF."
            },
            "questions": {
                "value": "See weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Reviewer_5CR4"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6896/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698634122806,
        "cdate": 1698634122806,
        "tmdate": 1699636802158,
        "mdate": 1699636802158,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dzRhSuftMF",
        "forum": "nr0w6CH7v4",
        "replyto": "nr0w6CH7v4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_XG8W"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_XG8W"
        ],
        "content": {
            "summary": {
                "value": "This paper introduced QDHF, a Quality Diversity (QD) algorithm to learn diversity metrics from human feedback, instead of relying on manually defined metrics as in conventional QD algorithms. Contrastive learning and human judgement employed to align the learned metrics with human preference. Two training strategies are devised. Experiments are done on various AI tasks, such as Robotics, Reinforcement Learning (RL), and Computer Vision (CV)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The notion of integrating quality diversity and human feedback is both innovative and reasonable, and has been demonstrated to be efficacious.\n2. The experiment was conducted in three disparate fields, which further substantiated QDHF is a ubiquitous approach for quality diversity.\n3. In the context of latent space illumination, the author employs stable diffusion in conjunction with CLIP, instead of StyleGAN, which is a more sophisticated and functional approach.\u201d"
            },
            "weaknesses": {
                "value": "1. The authors mentioned several quality diversity (QD) method in Section 2.1, but the sole method of comparison is AURORA and the extension. It seems that the comparison is insufficient for evaluation and comparison. \n2. Examples for latent space illumination (LSI) are somewhat partial. Some of the images contain unreasonable facts (such as a big brown helmet above the astronaut). More analysis is required.\n3. Quality diversity is an important topic in dialog generation and image captioning. Yet the balance between diversity and rationality/accuracy is required. It seems that if the diversity is added, the rationality of generated results would be hampered. Therefore it would be better to evaluate both diversity and rationality at the same time.\n4. Adding user study would be better for human-related tasks."
            },
            "questions": {
                "value": "Please check the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6896/Reviewer_XG8W"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6896/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698770111750,
        "cdate": 1698770111750,
        "tmdate": 1699636802039,
        "mdate": 1699636802039,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SnXiruJplr",
        "forum": "nr0w6CH7v4",
        "replyto": "nr0w6CH7v4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_2snW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6896/Reviewer_2snW"
        ],
        "content": {
            "summary": {
                "value": "Summary of the paper's contribution: This paper introduces Quality Diversity through Human Feedback (QDHF), a novel approach that combines human feedback with quality diversity (QD) algorithms to infer diversity metrics. QDHF aims to overcome limitations of reinforcement learning from human feedback (RLHF) and QD algorithms by leveraging human feedback for learning diversity metrics. The paper presents empirical results showing that QDHF outperforms existing QD methods in automatic diversity discovery and matches the search capabilities of QD with human-constructed metrics. In a latent space illumination task, QDHF significantly improves the diversity of images generated by a Diffusion model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. QDHF leverages human feedback to learn diversity metrics, expanding the applicability of QD algorithms. The proposed approach has the potential to improve exploration, personalization, and fairness in optimization for complex, open-ended tasks.\n2. Empirical results demonstrate the effectiveness of QDHF in comparison to existing QD methods and its ability to enhance diversity in image generation tasks. \n3. The paper is easy to understand."
            },
            "weaknesses": {
                "value": "1. The paper could provide more details on the scalability of QDHF, especially in the context of more challenging RL and open-ended learning tasks.\n2. The evaluation metrics used in the paper are primarily quantitative, without fully leveraging the advantages of human feedback. For a method that relies on human feedback, more intuitive and persuasive evaluation criteria should include qualitative indicators such as user satisfaction and user experience.\n3. The collection and processing of human feedback may be subject to subjective biases and inconsistencies. How to address these issues to improve the robustness and reliability of the method\uff1f\n4. The method may be limited by the amount of human feedback data available. For large-scale and complex tasks, collecting sufficient feedback may be difficult and time-consuming."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6896/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835412916,
        "cdate": 1698835412916,
        "tmdate": 1699636801934,
        "mdate": 1699636801934,
        "license": "CC BY 4.0",
        "version": 2
    }
]