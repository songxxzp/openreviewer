[
    {
        "id": "fxVSTysL6x",
        "forum": "nJsfYo3HDy",
        "replyto": "nJsfYo3HDy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_SxfR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_SxfR"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to elucidate why GANs perform poorly as density models for outlier detection and generative classification tasks with recent GAN models like BigGAN and StyleGAN. The authors use latent optimization as a tool in the investigation. They observed that GANs tend to assign higher likelihood to out-of-distribution images (e.g., flat images) compared to images from the training set. Additionally, the authors found that the quality of image reconstruction has a significant dominant over the KL divergence in likelihood assignment to input images. The experiments were limited to subsets of CIFAR-10, SVHN, and ImageNet due to the computational expense of the proposed method.\n\nOverall, the paper is easy to read. However, there is a need for additional details, as indicated in the comments below. While likelihood assignment represents the primary valid contribution of the paper, there are still gaps that require clarification and more supporting details to bolster the claims made in the paper. Based on my current understanding, I would recommend rejecting the paper in this state."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The conclusion that GANs fail to learn the underlying distribution of training data is not new. Nevertheless, the paper does introduce some seemingly novel insights, particularly regarding likelihood assignment to input images."
            },
            "weaknesses": {
                "value": "However, the limitation to only a subset of the datasets raises concerns about the representativeness of their findings in the broader distribution. Furthermore, there is a missing piece of values of optimized z that the authors may have overlooked, which requires verification (as outlined in the questions below). Without addressing these issues, the validity of the contribution is in question.\n\n\n\n1. The explanation of the z-reconstruction error is not entirely clear to me. Based on my intuition, it seems that the latent is optimized to maximize the likelihood of reconstructing the image, which is equivalent to minimizing the sample's reconstruction error. If my understanding is correct, there appear to be some concerns related to experimental design and the claims made when using the z-reconstruction method as a proxy for validating the model's density, particularly when working with limited data.  For more details. In Figure 1, the authors demonstrate that the GAN can reconstruct the generated images better than the training images. The results are predictable because the GAN was optimized during training to generate these specific images, making them more amenable to reconstruction and resulting in lower error. To explain further, if we consider the bad GAN model which collapses a specific mode of data distribution only, this GAN excels at reconstructing these samples but may struggle with reconstructing images outside of this distribution mode. However, when the authors use only a limited dataset, it's possible that the examples representing the mode the GAN learned are not included.  My point is that a comprehensive investigation requires access to the full dataset to ensure robust support for the findings. Could the authors provide a plot of the full dataset? This request also relates to Figure 2, as there might be training examples that the GAN could collapse into. If these examples are not utilized, the complete picture of the training distribution may not be accurately represented.\n\n\n2. The reconstructions of SVHN and flat images in Figure 1 are equally poor when compared to the training examples to me. It is clear that GANs manage to capture the global color appearance and shape, but they struggle with preserving the finer details of the images. Even in the case of flat images where we can still discern patterns (indicating they are not entirely flat) from the training distributions. Only the reconstructions of the generated images from the model appear to be well, largely consistent to the reasons I mentioned earlier. Therefore, it might not be sufficient to assert that the model \"can copy images completely outside the original training distribution,\" as it appears that the reconstruction behavior remains consistent across most images, and this claim should be approached with caution.\n\n\n3. One crucial aspect that I couldn't find in the author's discussion in the paper is the value of the optimized z. GANs are optimized with a specific latent distribution, such as a Gaussian within a defined range, and they may behave differently when confronted with latent variables that fall outside of this distribution. It would be beneficial if the author could provide more information about the latent distribution used for generating images in the investigated GAN models. Also, comparing the optimized z values for SVHN and flat images to those optimized for the generated samples and training images?. This comparison is only valid when the optimized z values fall within the latent distribution that the GAN was originally trained with. The choice of optimized z values could significantly impact all other results in the paper. If it turns out that the optimized z values are far outside the actual latent distribution required, this could raise questions about the validity of the findings. A similar concern could be applied to Figure 5. If the optimized z values are indeed found to be outside the latent distribution, it may result in KL divergence values that remain relatively constant, dominated by the reconstruction term, which tends to be better optimized."
            },
            "questions": {
                "value": "**More comment and questions**\n\n* In Figure 1, could the authors include the results of other GAN models on the same images to strengthen their claim? \n\n* Could the authors clarify the distinction between density and likelihood as defined in the paper? Furthermore, it's not clear why the density is greater than 1 in Figure 4? \n\n* The rationale behind dividing likelihood by the dimension in many plots in the paper could also be elaborated upon? \n\n* Can authors explain how to sample and generate of \u201cflat images\u201d in Figure 4, Figure 7?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3389/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698449921370,
        "cdate": 1698449921370,
        "tmdate": 1699636289961,
        "mdate": 1699636289961,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KEtP1hARmQ",
        "forum": "nJsfYo3HDy",
        "replyto": "nJsfYo3HDy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_kwJr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_kwJr"
        ],
        "content": {
            "summary": {
                "value": "The authors present a methodology to answer the question of how well modern GANs estimate the density of the ground truth distribution. Since GANs do not have a tractable density, the authors propose a relaxed likelihood framework by adding noise to the push forward of the generator with a latent vector defining the density everywhere on the manifold. Predicated on this augmentation, the likelihood of this density can be solved numerically with annealed importance sampling. Furthermore, the authors empirically test the quality of density estimation given by the Generator by evaluating its performance on two tasks, outlier detection and generative classification, as well as provide analysis to understand why GANS is not performing well on these tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1). The authors provided sufficient empirical evidence that modern GANs perform poorly on outlier detection and generative classification tasks.\n\n2). The plots are well done and easy to read.\n\n3). Parts of the paper are well written."
            },
            "weaknesses": {
                "value": "1). Some of the assumptions and motivational arguments could benefit from more explanation.\n* The sentiment of GANs should be good density estimators because they are capable of generating a realistic sample. A justification is required because GANs are not trained with a well-defined density, so is it reasonable to assume they can be good at estimating something they were not trained to do?\n* \"The GAN is able to generate realistic samples but is unable to reconstruct\ntraining images when only z is optimized.\" There should be some justification here explaining why this is possible even though the optimization problem defined in eq. (7) is np-hard [Inverting Deep Generative Models].\nOne layer at a time](https://proceedings.neurips.cc/paper_files/paper/2019/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf).\n\n2). Analysis of the z-reconstruction error term\n* This error will exist because a k-dimensional vector cannot represent all of $R^ {n}$, this has been extensively studied in the field of GANprior [Compressed Sensing using Generative Models](http://proceedings.mlr.press/v70/bora17a/bora17a.pdf). The density truly lies only in the range of $G(z)$, but since noise was added to the manifold to have a well-defined density over $R^{n}$, it is unclear if the poor recon error and likelihood are dominated by the noise added to the manifold or the n-k dimensions of the manifold z cannot represent. A noise-to-signal ratio metric would mitigate this issue.\n\n3). Problem formulation of the proposed method\n* AIS-logliklihood calculation is unprincipled because GANS do not have tractable density, so noise must be added to the system to define a density.\n\n4). At times, the paper read as if it were attempting to answer too many questions.\n* The papers consistently switch between the question of how well Gans estimate density and how poor they estimate density. The paper would be easier to follow if it were read as first demonstrating evidence for question 1, then moving onto the next question."
            },
            "questions": {
                "value": "1). Could the authors provide metrics for noise to signal ratios of the observed model $x=G_{\\theta}(z) + \\eta $ for training and test sets?\n\n2). Could the authors please justify why this is a reasonable assumption? \"The GAN is able to generate realistic samples but is unable to reconstruct training images when only z is optimized,\" even though the defined optimization problem is np-hard.\n\n3). Could the authors provide a justification on why we should expect GANs to be good at estimating density when they are not trained specifically for such a task?\n\n4). Could the authors please describe the procedure for how the flat images are created? As well, what is the definition of flat? Is this a reference to the manifold of the image?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3389/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3389/Reviewer_kwJr",
                    "ICLR.cc/2024/Conference/Submission3389/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3389/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698712352503,
        "cdate": 1698712352503,
        "tmdate": 1700539799503,
        "mdate": 1700539799503,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Q3QK7XiVuy",
        "forum": "nJsfYo3HDy",
        "replyto": "nJsfYo3HDy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_PGsS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_PGsS"
        ],
        "content": {
            "summary": {
                "value": "This work investigates GANs as a density estimator and reveals that state-of-the-art GANs are very poor on density-related tasks. Hence, GANs do not truly learn the underlying distribution. To understand this phenomenon, the authors show that if using model inversion, the likelihood is dominated by the so-called \"z-reconstruction error\", which GANs often perform better for out-of-distribution data than the training data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem being investigated is interesting and potentially important for practitioners. The writing is clear and most of the arguments are supported by experiments. \n\nThe authors investigated GANs in both classification and OOD detection tasks. The link between the performance and the z-reconstruction error is interesting and novel to me."
            },
            "weaknesses": {
                "value": "## The motivation is relatively weak:\nAs the authors stated in Section 5, this phenomenon is already known for various generative models. Hence, it's not unexpected that GANs are also not good. I am not entirely convinced that this is important for GANs nowadays as nobody actually uses them for inference tasks. \n\nOn the theoretical side, GANs as density estimators have been studied extensively in the literature. They have been shown to be minimax optimal density estimators with certain assumptions. But this line of work is not sufficiently discussed in this submission.  \n\n\n## The message is mixed\nGANs are implicit generative models that do not have a direct way to access the likelihood information. In this work, the authors considered \nboth optimizing the latent z and the noisy $p_\\lambda$.  \nThe former can be unstable due to the optimization difficulty.\nFollowing Figure 1, the authors stated that \"GAN is unable to reconstruct training images when only z is optimized.\" Is this due to poor optimization and stuck as local minima?\nThe latter is computationally prohibitive to well-approximate. Motivated by the experiments, the authors identified that the reconstruction term is dominant and have since considered the negative z-reconstruction error. \nHowever, the link between the z-reconstruction error and whether a GAN model captures the density information is not that strong. \nFor instance, the L2 reconstruction argument is only coming from the added Gaussian noise, which is not inherent to the GAN methodology.  \n\n\n\n## Analysis is weak\nThis work is mainly empirical. Although the experiments are interesting, no rigorous argument has been made. \nMost of the findings are left on the surface, without digging into the underlying reason. The impact of this work can be greatly improved if the authors can gain a deeper understanding of the training of GAN and propose modifications to it to improve GANs in inference tasks.  \n\n\n\nReference:\n[1] Liang, Tengyuan. \"How well generative adversarial networks learn distributions.\" The Journal of Machine Learning Research 22.1 (2021): 10366-10406.\n\n[2] Uppal, Ananya, Shashank Singh, and Barnab\u00e1s P\u00f3czos. \"Nonparametric density estimation & convergence rates for gans under besov ipm losses.\" Advances in neural information processing systems 32 (2019)."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3389/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699234583535,
        "cdate": 1699234583535,
        "tmdate": 1699636289801,
        "mdate": 1699636289801,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qEItRUCgmx",
        "forum": "nJsfYo3HDy",
        "replyto": "nJsfYo3HDy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_pQQy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_pQQy"
        ],
        "content": {
            "summary": {
                "value": "The paper seeks to provide an explanation for why GANs remain poor density models despite having impressive sampling capabilities. The authors use Annealed Importance Sampling (AIS) to estimate log likelihoods for GANs. In their experiments on pretrained models such as StyleGAN and BigGAN, they find that these models assign high likelihood scores to seemingly out of distributions samples, implying that outlier detection via GANs might be hard. Additionally, they also show that images reconstructed by searching through z-space to be similar to training examples are given low likelihood scores, implying that GANs seem to not learn the underlying distribution of the training data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The main idea is pretty straightforward and the paper is nicely written with clear explanations. (Some concerns discussed below)\n2. Significance: understanding failure of distribution learning in GANs is a significant problem especially in more modern architectures."
            },
            "weaknesses": {
                "value": "1.  My main concern regarding this paper lies with novelty. That GANs don\u2019t learn the underlying distribution has been known for some time (see Arora et al. [2]) so while it is nice to have confirmation of this fact, it does not add to our understanding of GANs. What would be interesting is a new explanation for WHY these models behave the way they do. The authors do attempt to provide an explanation via log likelihood estimation but I have some concerns about the methodology and results. (See next point)\n2. The authors report that the GANs should be, based on their results, bad at outlier detection and that they do not memorize training samples. However, prior works on GANs have reported the exact opposite results in both these cases. There is large body of literature on GANs being used for anomaly detection [3] and there is work demonstrating both theoretically [4] and empirically [5] that GANs tend to memorize training samples. I am thinking this might be because the estimated log likelihood used by the authors is not actually a good estimate of underlying log likelihood of the model itself. I am willing to believe that the authors might have found something that previous works have missed and am open to be corrected on this.\n3. Writing wise, while I think most of the paper is clear about the mechanics of the experiments, I would encourage the authors to summarize their contributions clearly at the start of the paper (preferably at the end of the introduction). At several points during reading the paper, I was confused about the exact contributions of the current paper vs contributions from prior work. \n4. Related to the writing point above, the paper is titled \u2018Why are Modern GANs poor density models?\u2019 but I\u2019m still not sure about the exact reason the authors are proposing to be the cause for this phenomenon (poor density modelling). I would encourage the authors to clearly state the reason. The closest I found was in the abstract: \u201c To try and understand the source of this poor performance, we show that the likelihood that a GAN assigns to an input image is dominated by the quality of the GAN reconstruction when only the latent variable is optimized \u201d. This is then again touched on in Section 4 briefly. I would have liked some more analysis about this proposed reason. One such question for example is, do all training samples have similarly bad likelihood? Which modes are represented? (Mode collapse) \n5. Dataset size is limited. The authors report log likelihood on on 200 samples from only 10 classes on ImageNet (along with results on small samples from other datasets). Classes used are mentioned din the appendix, however, it is unclear if the results in the paper are merely an artifact of the selection of classes made since there is no justification given for why these classes were chosen. I understand that not everyone has access to large compute resources but the concern remains if there is no ablation/justification.\n\n[1] Wu et al. On the quantitative analysis of decoder-based generative models\n\n[2] Arora et al. Do GANs learn the distribution? Some Theory and Empirics\n\n[3] Mattia et al. A Survey on GANs for Anomaly Detection\n\n[4] Nagarajan et al. Theoretical Insights into Memorization in GANs \n\n[5] Bai et al. Reducing Training Sample Memorization in GANs by Training with Memorization Rejection"
            },
            "questions": {
                "value": "I am intrigued (and a little confused) by the finding that GANs used by the authors don\u2019t seem to memorize training examples seemingly in contradiction of prior work. What do the authors think the reason might be?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3389/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699241700227,
        "cdate": 1699241700227,
        "tmdate": 1699636289743,
        "mdate": 1699636289743,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "o41QKIjrhX",
        "forum": "nJsfYo3HDy",
        "replyto": "nJsfYo3HDy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_GHc8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3389/Reviewer_GHc8"
        ],
        "content": {
            "summary": {
                "value": "The authors present a computational study that evaluates GANs as density models. They first introduce a \"relaxed\" likelihood which they propose to use for likelihood estimation using annealed importance sampling (AIS). They then use the AIS likelihood estimates to compute, among other things, GAN classification accuracy or out-of-distribution detection performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is an interesting study on the capability of GANs as density models.\n- The paper is well written and generally easy to follow.\n- The paper fits well in line with the recent literature on \"out-of-distribution detection\" of neural density models and should be a valuable contribution to the field."
            },
            "weaknesses": {
                "value": "Overall, the paper has several limitations which are discussed below:\n\n-  The paper seems to be of only limited originality and novelty. It builds on the work by Wu et al. [1] to use AIS to compute likelihood estimates for generative models, and uses it to evaluate the capability of GANs as density estimators in several experiments.\n\n- Conceptually, some aspects of the manuscript are unclear to the reviewer: what is the motivation to frame GANs as density models, since vanilla GANs are not trained with, e.g., maximum (marginal) likelihood objectives. Why would the adversarial loss of GANs lead to good density models and what did the authors expect to find with this study? Can the poor performance of GANs for density estimation tasks be remedied? How does the authors' work fit in the context of related recent literature, such as [2-4].\n\n- As an empirical computational study, the evaluations are a bit limited, and the paper is sometimes difficult to follow and/or lacks technical details and clarity. For instance:\n    - The influence of the stochastic relaxation $p(x) = \\int p(z) p(x | G(z))dz$ on the density estimation is not sufficiently discussed. Could the introduction of the noise lead to lower (or vice versa higher) likelihoods and not the model itself? How is the noise variance chosen?\n  - In Section 2.2, the authors write \"[i]n generative classification, it is assumed that different parametric distributions\nwere learned for each class\" and define a conditional likelihood $p_\\theta(x|c)$. How does this likelihood look like? Do the authors mean something like $p_{\\theta_c}(x)$ where for each class a density model is learned, or how is the conditioning done? \n  - Figure 4 shows that the style GAN estimates higher likelihoods to flat and SVHN data than to training data. It is not clear if this result is just an artifact, because the intrinsic dimension of flat/SVHN data is significantly lower than the intrinsic dimension of the training/testing data (CIFAR10). What happens when applied to a data set with higher intrinsic dimension like ImageNet? \n  - Equation 6 introduces a conditional density $p(z|x)$.  It is not clear how this distribution is computed. Also, the equality does apparently not hold. As far as I can tell, the right-hand-side is the evidence lower bound, and hence it is an inequality.\n\n- Given that the paper is entirely empirical, the code base is not of sufficient quality: which libraries are used and which versions do they have, how can the results be reproduced, etc.\n\n[1] https://arxiv.org/abs/1611.04273\n[2] https://proceedings.neurips.cc/paper_files/paper/2018/hash/4996dcc43b5be197b5887a4e60817b1c-Abstract.html\n[3] https://proceedings.neurips.cc/paper/2019/hash/959ab9a0695c467e7caf75431a872e5c-Abstract.html\n[4] https://openaccess.thecvf.com/content_CVPR_2019/html/Abbasnejad_A_Generative_Adversarial_Density_Estimator_CVPR_2019_paper.html"
            },
            "questions": {
                "value": "Questions:\n\n- How is the variance of $\\eta$ in Equation 1 chosen? This seems to be a critical hyperparameter.\n- How did you select the classes in ImageNet10 and CIFAR10?\n- How are the baselines fitted? Have KDEs/diagonal Gaussians been fitted for each class or have they been fitted on the pooled data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3389/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699306382408,
        "cdate": 1699306382408,
        "tmdate": 1699636289659,
        "mdate": 1699636289659,
        "license": "CC BY 4.0",
        "version": 2
    }
]