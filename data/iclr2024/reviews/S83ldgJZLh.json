[
    {
        "id": "pYjTO2Zixc",
        "forum": "S83ldgJZLh",
        "replyto": "S83ldgJZLh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_hcWa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_hcWa"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a pruning approach for model based deep learning. They present structured pruning algorithm based on DepGraph and also considers three approaches to fine tune the model after the pruning to restore lost accuracy due to the pruning. They demonstrate the effectiveness of their approach by applying it to MRI and SuperResolution databases."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Motivation and experiments are well presented well. Experiments gives support to their their approach."
            },
            "weaknesses": {
                "value": "The explanation of the methods could be more clear. As I am not familiar with MBDL methods they discuss in the paper or DepGraph, I cannot really follow that how this pruning works. For example, \"$f_{\\theta,i}$ has dependency on $f_{\\theta,j}$\" is very briefly explained but it seems to be some what a key ingredient of the proposed pruning approach. And also how the layers are actually removed?   Probable not just taking a layer out of the network, as it would need some additional assumptions about compatibility of the input and output dimensions of the layer, plus not sure if network give any meaningful output after such removal. Authors could improve the presentation. For example, they could one MBDL method and describe in details that how their approach is applied to it. (e.g. Table 2 and Figure 4 can be removed or moved to a supplementary material if more space is needed) \n\nAlso, probable due to limited understanding, I fail to see that how this approach is for MBDL instead of being more general pruning method. Is there something in the pruning approach which required the model to be MBDL instead of, say, a typical classification CNN or ResNet?  I can only see that the model A is used in self-supervised fine tuning approach (Eq (10)), but its value seems quite low due to worst performance in the results. Also it could be clarified that what is their contribution or novelty with respect to DepGraph."
            },
            "questions": {
                "value": "Speed up seems quite low compared to pruning ratio. For example, 10% pruning only seems to give 0-3% speedup and E2EVar (Table1) has only 24% speedup with 65% pruning ratio. Does pruning remove lower-complexity layers, does times include possible compilation times (XLA, jit, etc), or how this can be explained?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Reviewer_hcWa"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6153/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698142331832,
        "cdate": 1698142331832,
        "tmdate": 1700555552878,
        "mdate": 1700555552878,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oFAAFH3YBK",
        "forum": "S83ldgJZLh",
        "replyto": "S83ldgJZLh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_NVrb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_NVrb"
        ],
        "content": {
            "summary": {
                "value": "The authors present structured pruning algorithm for model-based deep learning (SPADE)  as a solution to reduce the computational complexity of CNNs used within Model Based Deep Learning (MBDL) framework. SPADE has two components: \n1. Network Pruning: The authors adopt DepGraph to construct the dependency group for each layer in the network and use group `1-norm as the criteria to rank the importance of the filters. The non-essential weights are pruned, resulting in a reduced network structure while preserving the model's accuracy. \n2. Network Fine-Tuning: Authors propose to fine-tune the pruned network to minimize performance gap. They propose three fine-tuning strategies, each with a unique benefit that depends on the presence of a pre-trained model and a high-quality ground truth. \n\nFurther, authors validate SPADE compressed sensing MRI and image super-resolution, with results showing that they can achieve substantial speed up in testing time while maintaining performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Inverse problems are theoretically interesting, and practically very relevant. Reducing inference computational complexity has help bring deep learning based solutions to the main stream for inverse problems, and potentially unlock more applications and widespread usage. \n\n+ Authors use DepGraph (Fang et al., 2023) to perform to pruning, and show with experiments that just the pruned network has significant performance degradations. To combat this, authors propose to fine-tune the pruned network.\n\n+ Authors propose three fine-tuning strategies for the network, which can comprehensive to cover different cases:\n1. Supervised: where ground truth data is used to fine-tune. \n2. School: when labels are not available, pre-trained network is used to score the test data, and in fine-tuning the discrepancy between the pruned network and original network is reduced. \n3. Self-supervised: when pre-trained network and labelled data points are not available, self-supervised objective functions are used to fine-tune the pruned network. \n\n+ Authors also perform extensive numerical experiments and evaluate SPADE on compressed sensing and super resolution, showing competitive performance while improving the computational speed."
            },
            "weaknesses": {
                "value": "+ While I appreciate the authors effort in improving the computation efficiency of deep learning methods for inverse problems, I wonder if ICLR is the correct venue for this paper. I personally think that the contributions maybe more of relevance to a compressed sensing, and super resolution community, as the pure technical contribution in this paper maybe limited. At the heart, the paper applies existing pruning method, and existing fine-tuning/training methods. \n\n+ While the paper specialize in Model Based Deep Learning, and the introduction focuses on methods like RED, I fail to see how the proposed method SPADE is relevant to such methods, or how any specialized knowledge from this domain is used. It occurs to me that this can be applied to any CNN, not just the ones used within MBDL framework. Can authors confirm? \n\n+ Why was compressed sensing and super resolution selected as the tasks of choice? Showing more inverse problems, and including more networks can help establishing a stronger case for the paper."
            },
            "questions": {
                "value": "Please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6153/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698695483292,
        "cdate": 1698695483292,
        "tmdate": 1699636667085,
        "mdate": 1699636667085,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IsDoIdkns1",
        "forum": "S83ldgJZLh",
        "replyto": "S83ldgJZLh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_vSdx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_vSdx"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a pruning algorithm using DepGraph and group L1 norm as well as three fine-tuning methods. The proposed method was evaluated in multiple experiments such as MRI and super resolution."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The proposed method showed good performance in speed up for CS-MRI (see Fig. 2) and super resolution (see Table 4)."
            },
            "weaknesses": {
                "value": "It is questionable that the proposed method is indeed for MBDL only. It could be seen as a mere combination of DepGraph and group sparsity based pruning.\nThree fine-tuning methods do not look novel - they are simply three usual losses that were used for inverse problems.\nExperiments may not be as comprehensive as it should be: it is unclear if the sampling pattern in CS-MRI is fixed for all / super resolution was not evaluated on diverse test datasets, which were frequently used for super resolution literature."
            },
            "questions": {
                "value": "Q1. it is unclear if the proposed pruning method is novel over other prior pruning works using group sparsity. See the following works:\n- W Wen et al., Learning Structured Sparsity in Deep Neural Networks, NeurIPS 2016\n- J Yoon & S J Hwang, Combined Group and Exclusive Sparsity for Deep Neural Networks, ICML 2017\n- Y Li et al., Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression, CVPR 2020\n- A Kumar et al., Pruning filters with L1-norm and capped L1-norm for CNN compression, Appl Intell 51, 2021\n- K Mitsuno & T Kurita, Filter Pruning using Hierarchical Group Sparse Regularization for Deep Convolutional Neural Networks, ICPR 2021\n- Z Huang et al., Rethinking the Pruning Criteria for Convolutional Neural Network, NeurIPS 2021\nIt is hard not to see this manuscript as a work for network pruning using group sparsity, so properly discussing and comparing the above works seems essential. I can not agree with the claim \"We propose the first network pruning algorithm specifically designed for MBDL models\" - to me, the proposed method can be used for any task considering DepGraph and group sparsity based pruning.\n\nQ2. It is unclear why the proposed three fine-tuning methods are novel : they are simply three popular losses that were used for full networks and there is no special treatment for pruned networks. Please clarify.\n\nQ3. It may be true that \"its potential has remained unexplored in the realm of imaging inverse problems,\" but I am not sure if exploring this potential is important considering that there are a number of drawbacks. For example, it is unclear if this work simulated diverse sampling patterns for CS-MRI, which is much more practical than using a single pattern. If different sampling patterns require a new pruning, then it may not be as convenient as using a full network. Moreover, it is unclear if 51-81% speed up is beneficial by sacrificing the performance by 0.77dB in CS-MRI, which may be critical for missing clinical information. More convincing arguments for the necessity on network pruning for inverse problems along with practical experiments should follow. For super resolution, 0.68dB is a huge gap and most prior works evaluated their methods in more diverse datasets."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6153/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698840575956,
        "cdate": 1698840575956,
        "tmdate": 1699636666983,
        "mdate": 1699636666983,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vdtNxQ5vhn",
        "forum": "S83ldgJZLh",
        "replyto": "S83ldgJZLh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_ifBm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6153/Reviewer_ifBm"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a structured pruning method for model-based deep learning in inverse problems. The proposed method, SPADE, reduces the computational complexity of model-based networks at test-time by pruning its non-essential weights. In addition, three different fine-tuning methods are introduced for the pruned networks to reduce performance loss. SPADE is evaluated on compressed sensing MRI and image super-resolution, and is shown to speed up inference with minimal performance degradation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:\n- The application of structured pruning to model-based networks in inverse problems is new and promising, especially due to high computational costs in large-scale imaging settings.\n- The proposed method results in faster inference speed and is applied to multiple frameworks, namely deep equilibrium models (DEQ) and deep unrolling (DU)."
            },
            "weaknesses": {
                "value": "Weaknesses:\n- The contributions of the paper are mostly comprised of a combination of existing techniques such as the pruning algorithm and the fine-tuning techniques.\n- The method is not compared with other methods for improving inference speed, such as [1] or [2] mentioned in the paper. The lack of this comparison makes it difficult to quantify the significance of the results. As an example, there is a 0.77 dB PSNR drop with a 51% speed up at test-time (Table 1) for compressed sensing MRI which seems to be a large performance reduction, and it is unclear how this compares to existing methods.\n\n[1] J. Liu, Y. Sun, W. Gan, X. Xu, B. Wohlberg, and U. S. Kamilov. SGD-Net: Efficient Model-Based\nDeep Learning With Theoretical Guarantees. IEEE Trans. Computational Imag., 7:598\u2013610,\n2021.\n\n[2] J. Tang and M. Davies. A fast stochastic plug-and-play ADMM for imaging inverse problems. arXiv\npreprint arXiv:2006.11630, 2020."
            },
            "questions": {
                "value": "- How much does the training time increase for SPADE, compared with the baseline unpruned model-based network?\n- Is it possible to combine fine-tuning losses, rather than view them as independent techniques, and could that help preserve performance?\n- How does the memory complexity change at test-time? Memory complexity is also a quite important consideration for which discussion has not been included.\n\nSuggestions:\n\n- The introduction, and the \"DL and MBDL.\" subsection in the background are repetitive. For instance, the equation for PnP/RED does not seem to contribute to the story of the paper. The background can be shortened to include more experiments in the main paper, such as the visual results (Figure 6-8) in the supplemental, which are crucial for compressed sensing MRI. \n- Typographical errors should be fixed via proofreading."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6153/Reviewer_ifBm"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6153/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699082659962,
        "cdate": 1699082659962,
        "tmdate": 1699636666878,
        "mdate": 1699636666878,
        "license": "CC BY 4.0",
        "version": 2
    }
]