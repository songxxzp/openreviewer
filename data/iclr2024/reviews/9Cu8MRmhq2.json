[
    {
        "id": "fXXYESyduO",
        "forum": "9Cu8MRmhq2",
        "replyto": "9Cu8MRmhq2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission39/Reviewer_83JB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission39/Reviewer_83JB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel method for learning long-term temporal correspondence from noisy instructional videos. The main idea is to use optimal transport (OT) to measure the sequence similarity between video clips and captions, and address the multi-granularity noisy correspondence (MNC) problem at both coarse and fine levels. The paper also introduces several techniques to enhance the OT framework, such as a soft-maximum operator, an alignable prompt bucket, and a faulty negative exploitation strategy. The paper evaluates the proposed method on various downstream tasks, such as video-paragraph retrieval, videoQA, and action segmentation, and shows that it outperforms existing state-of-the-art methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "(1) The paper tackles an important and challenging MNC problem of learning long-term temporal dependency from noisy video-text data, which has many potential applications in video understanding. Although temporal misalignment has been explored in TAN [1], they only consider the noisy correspondence from a course grained sentence level. While this paper proposes a novel and efficient method based on optimal transport, which can handle the multi-granularity noisy correspondence problem in a unified framework and outperform previous work TAN. The paper also provides empirical evidence to support the proposed method. \n(2) The paper introduces several innovative components to enhance the optimal transport framework, such as the soft-maximum operator for fine-grained alignment, the alignable prompt bucket for filtering out irrelevant clips or captions, and the faulty negative exploitation for improving clip representation. \n(3) The paper conducts extensive experiments on diverse downstream tasks and datasets and demonstrates that the proposed method achieves remarkable improvements over existing state-of-the-art methods. The paper also performs ablation studies to analyze the impact of different design choices."
            },
            "weaknesses": {
                "value": "(1) The explanation of why using optimal transport effectively learns video-paragraph similarity in the paper could be more explicit. Specifically, when the similarity calculated by the S matrix might not be accurate in the early stages of model training, it is important to understand how the training objective, which aims to maximize the similarity of \u27e8Q,S\u27e9, prevents misleading the model. Additional clarification on this point would be beneficial.\n(2) The paper does not compare the proposed method with other methods that use optimal transport for sequence alignment, such as Su & Hua (2017) [2]. It would be interesting to see how the proposed method differs from these methods in terms of performance and efficiency."
            },
            "questions": {
                "value": "(1) How do you choose the value of p of clip-caption pairs for the alignable prompt bucket? Is it fixed per epoch or adaptive to different batches? How sensitive is the performance to different values of p? \n(2) How do you deal with clips or captions that have different lengths as you choose a random window size for clip and caption sampling? Do you perform any preprocessing or padding on the clips or captions? How does this affect the optimal transport computation?\n[1] Tengda Han, Weidi Xie, and Andrew Zisserman. Temporal alignment network for long-term video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022.\n[2 ] Bing Su and Gang Hua. Order-preserving wasserstein distance for sequence matching. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1049\u20131057, 2017."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission39/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission39/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission39/Reviewer_83JB"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission39/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698589729068,
        "cdate": 1698589729068,
        "tmdate": 1699635928150,
        "mdate": 1699635928150,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tHlhMgjMW5",
        "forum": "9Cu8MRmhq2",
        "replyto": "9Cu8MRmhq2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission39/Reviewer_pP85"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission39/Reviewer_pP85"
        ],
        "content": {
            "summary": {
                "value": "This paper delves into the long-term video-text learning task and reveals a new problem named multi-granularity noisy correspondence (MNC), referring to both course-grained clip-caption misalignment and fine-grained frame-word misalignment. Clearly, such a problem would hinder temporal learning and video understanding. To address the MNC problem, the authors propose NOise Robust Temporal Optimal traNsport (Norton), which formulates the solutions to both course- and fine-grained NC into a unified optimal transport (OT) framework. On the one hand, Norton filters the irrelevant clips and captions using an alignable prompt bucket and realigns the asynchronous clip-caption pairs based on transport distance, contributing to robustness against course-grained NC. On the other hand, a soft-maximum operator is used to identify crucial words and keyframes so that the negative impact of fine-grained NC can be alleviated. The effectiveness of Norton is validated through extensive experiments on commonly used video-text tasks, including video retrieval, video QA, and action segmentation."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "**Revealing a new problem**. This paper studies a new and practical challenge in the context of long-term video-text representation learning, namely, multi-granularity noisy correspondence (MNC). MNC encompasses both coarse-grained clip-caption misalignment and fine-grained frame-word misalignment, both of which hinder temporal learning and video comprehension. While some studies have been concentrated on addressing the coarse-grained clip-caption misalignment, as far as I know, there are no formal studies on the fine-grained NC for video-text learning. From this perspective, I think this paper would bring some new insights to the community.\n\n**Novel approach**. To handle MNC and achieve robust long-term video-text learning, this paper proposes Norton, which formulates the solutions to both course- and fine-grained NC into a unified optimal transport (OT) framework. Norton first incorporates a token-wise soft-maximum operator to identify crucial words and keyframes within each clip-caption pair, so that the fine-grained NC could be eliminated. After that, Norton filters the irrelevant clips and captions using an alignable prompt bucket, and realigns the asynchronous clip-caption pairs based on transport distance, leading to robustness against course-grained NC. \n\n**Good shape**. This paper is well-written and structured. Besides, the experiment designs are interesting and sufficient. Extensive experimental results validated the effectiveness of the proposed methods and the necessity of solving MNC problems."
            },
            "weaknesses": {
                "value": "- While the authors effectively illustrate the motivation in Fig. 1, the advantages of the proposed OT method over DTW require more elaboration. It is advisable to include further discussions to expound upon and clarify the claims made regarding the superiority of OT over DTW.\n- The use of the stop-gradient operation in transport assignment Q is highlighted by the authors as a means to enhance the efficiency of their video-paragraph contrastive loss. However, the rationale behind this operation's efficacy is not entirely clear. To remedy this, additional discussions should be included to provide a more comprehensive explanation of why this operation is meaningful and how it improves efficiency.\n- To enhance clarity, it is suggested that the authors highlight the second-best results alongside the primary results in each table. This practice can provide a useful point of reference for readers and facilitate a more comprehensive understanding of the findings.\n- The results of DTW should be included as a baseline for comparison. This can help demonstrate the advancements made in the proposed methodology and provide a clearer context for the contributions of this work."
            },
            "questions": {
                "value": "The major concern is the lack of some claims, as highlighted in the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission39/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636165645,
        "cdate": 1698636165645,
        "tmdate": 1699635927984,
        "mdate": 1699635927984,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qe4eJIxX7b",
        "forum": "9Cu8MRmhq2",
        "replyto": "9Cu8MRmhq2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission39/Reviewer_TtfV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission39/Reviewer_TtfV"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an innovative approach Norton for video-language pre-training that learns long-term temporal dependencies between short video clips and captions. The paper addresses two challenges: 1) the high computational cost of modeling long videos and 2) the noisy correspondence between clips and captions due to asynchronous and irrelevant pairs. The paper uses a modified optimal transport framework to measure the sequence similarity between clips and captions, and to filter out the noisy pairs. The paper also exploits the faulty negative samples in contrastive learning to improve clip representation. The paper evaluates the method on video-paragraph retrieval, text-to-video retrieval, videoQA, and action segmentation tasks, and shows that it outperforms existing methods on various metrics. The paper also conducts ablation studies to analyze the impact of different components."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1.This paper is well-written, well-organized, and easy to follow.\n2.The problem tackled by the authors is an interesting one - noisy correspondence, almost all video harvested from the web would include such cases and hinders the performance of large-scale multi-modal video learning. This challenge is inherent in the data and has received little attention in the literature. The paper explores this novel and important problem in depth.\n3.The paper presents a unified OT framework that can efficiently and effectively solve the MNC problem at different levels of granularity. I commend the authors for providing a time cost table in the appendix which shows the efficiency of their method with various settings and verifies their claims.\nThis method's unique strength lies in using existing pre-training model and works in a self-bootstrapping capability. Note that directly pretraining a large multi-modal model is unpractical for the researchers not in company. This paper significantly improves the temporal ability of VideoCLIP without the need for additional models like DecemBert or TAN. This self-sufficiency significantly contributes to its enhanced scalability."
            },
            "weaknesses": {
                "value": "1.This paper does not provide specific numerical results on how well the proposed method handles noisy correspondence. It would be beneficial if the authors could provide more detailed numerical results or analysis on this aspect in their rebuttal or future work. For example, they could conduct experiments on synthetic noisy datasets to show the performance of their method. They could also compare their method with other methods that are designed to handle noisy correspondence and show how their method performs in comparison. This would provide more concrete evidence on the effectiveness of their method in handling noisy correspondence.\n2.In certain scenarios, such as video-paragraph retrieval on YouCookII (as shown in Table 1) and in the context of ablation experiments (as indicated in Table 7), we observe encouraging indications of potential improvements. While in other experiments (as depicted in Table 2), there are mixed results across various metrics. Can you shed light on the reasons behind this disparity?\n3.How does the proposed method compare with other OT-based methods like action sequence matching? What are the benefits or drawbacks of using OT for video-text learning? Please provide some comparisons and discussions."
            },
            "questions": {
                "value": "The primary queries for the rebuttal are predominantly derived from the \"weaknesses\" section outlined earlier. For instance, it would be highly appreciated if the authors could augment their experiments regarding noisy correspondence and offer more clarification on how their approach differs from other OT-based methods. Resolving these raised concerns will make the submission stronger and I vote for accepting this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission39/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698749708192,
        "cdate": 1698749708192,
        "tmdate": 1699635927899,
        "mdate": 1699635927899,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1zhQ5aqWdm",
        "forum": "9Cu8MRmhq2",
        "replyto": "9Cu8MRmhq2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission39/Reviewer_UrFs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission39/Reviewer_UrFs"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces NOise Robust Temporal Optimal traNsport (Norton), a method designed to address multi-granularity noisy correspondence (MNC) in video-language studies, particularly focusing on long-term temporal dependencies in long videos. Norton utilizes optimal transport (OT) to handle both coarse-grained clip-caption misalignment and fine-grained frame-word misalignment, hindering temporal learning and video understanding. The method incorporates video-paragraph and clip-caption contrastive losses, an alignable prompt bucket for filtering irrelevant clips and captions, and a soft-maximum operator for identifying crucial words and keyframes. Additionally, Norton rectifies alignment targets in clip-caption contrastive learning to ensure precise temporal modeling. The effectiveness of Norton is demonstrated through extensive experiments on video retrieval, video QA, and action segmentation tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper introduces a novel method, NOise Robust Temporal Optimal traNsport (Norton), which addresses the multi-granularity noisy correspondence (MNC) problem in video-language studies. This method is unique in its approach to handling both coarse-grained and fine-grained misalignments using optimal transport.\n2. Norton incorporates innovative components such as an alignable prompt bucket and a soft-maximum operator to address specific challenges in video-language representation learning.\n3. The method is rigorously evaluated across various tasks, including video retrieval, videoQA, and action segmentation, demonstrating its effectiveness and robustness.\n4. The paper provides extensive experimental results, comparisons with existing methods, and visualizations to validate the proposed approach.\n5. The paper effectively communicates the core ideas, methodologies, and results, making it accessible to readers with a background in the field.\n6. Norton addresses a significant challenge in video-language studies, particularly the handling of long-term temporal dependencies in extended videos.\n7. The method\u2019s ability to improve temporal learning and video understanding has potential implications for various applications in computer vision and natural language processing."
            },
            "weaknesses": {
                "value": "1. The paper could benefit from providing more context and justification for the chosen methodologies and design decisions. For instance, the rationale behind the specific components of the Norton method, such as the alignable prompt bucket and the soft-maximum operator, could be elaborated upon to give readers a deeper understanding of their significance and contribution to the overall approach.\n\n2. The paper could be improved by including a more thorough discussion of the limitations of the proposed method. Acknowledging and addressing potential shortcomings or challenges in the approach would provide a more balanced view and help to set realistic expectations for the method\u2019s applicability and performance.\n\n3. Providing more detailed implementation details, including hyperparameter settings, training procedures, and computational resources, would enhance the reproducibility of the results and allow other researchers to more easily build upon the work."
            },
            "questions": {
                "value": "1. Could you provide more details on the design choices behind the Norton method, specifically the alignable prompt bucket and the soft-maximum operator? Understanding the rationale behind these components could offer deeper insights into their roles and contributions to the overall approach.\n\n2. The paper presents a comparison with existing methods, but could you elaborate on specific scenarios or cases where Norton particularly excels or struggles? This information would help in understanding the practical implications and limitations of the method.\n\n3. Could you discuss any potential limitations or challenges associated with the Norton method? Acknowledging these aspects would provide a more balanced view of the method and help set realistic expectations for its performance.\n\n4. Could you provide more detailed implementation details, including hyperparameter settings, training procedures, and computational resources? This information would enhance the reproducibility of the results and facilitate future research building upon this work.\n\n5. Could you elaborate on the potential implications and applications of the Norton method in real-world scenarios? Understanding the practical impact of the method could offer additional motivation for the work and highlight its significance in the field."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission39/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission39/Reviewer_UrFs",
                    "ICLR.cc/2024/Conference/Submission39/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission39/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820096864,
        "cdate": 1698820096864,
        "tmdate": 1700457201297,
        "mdate": 1700457201297,
        "license": "CC BY 4.0",
        "version": 2
    }
]