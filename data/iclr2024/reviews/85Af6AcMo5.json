[
    {
        "id": "Kx4boPosz0",
        "forum": "85Af6AcMo5",
        "replyto": "85Af6AcMo5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_zqdo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_zqdo"
        ],
        "content": {
            "summary": {
                "value": "The work investigates accelerating diffusion model sampling. Compared with existing works, the authors propose a new gradient estimation method,  named recursive difference, and show improvement compared with existing works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The experiments are very comprehensive for image experiments in terms of FID. \n2. Based on experiments in the main paper and appendix, the proposed new method shows improvements."
            },
            "weaknesses": {
                "value": "1. After reading the main paper, I have difficulties in understanding why the proposed recursive difference works better. The authors claim \" This method recursively extracts the hidden lower-order derivative information of the higher-order derivative terms in the Taylor\nexpansion of the score-integrand at the required point, as illustrated in Figure 2.\" The recursive difference trick is key contribution of the work, authors should consider rewriting the above high-density sentence into an easy-to-understand paragraph and highlight why it works, presenting more analysis.\n\n2. Can the author show some comparison in terms of numerical accuracy (MSE against ground truth solution) besides FID? How fast of various methods converge to ground truth solution? \n\n3. After reading the main paper and appendix, it is unclear to me why the chosen coefficient C6 is better than C5. Besides the empirical experiments, do authors have more principled math analysis for them? \n\n4. Similar to Q2, can authors present evidence that the proposed method can better estimate score gradients?\n\n5. A recent work investigates a similar problem and shares a similar algorithm. Can authors comment on the connection and difference[1]? \n\n[1] Zhang et al. Improved order analysis and design of exponential integrator for diffusion models sampling"
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698646059189,
        "cdate": 1698646059189,
        "tmdate": 1699636394452,
        "mdate": 1699636394452,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "svCHRAlOJs",
        "forum": "85Af6AcMo5",
        "replyto": "85Af6AcMo5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_MTm2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_MTm2"
        ],
        "content": {
            "summary": {
                "value": "This work introduces a new method, the recursive difference method, to improve the speed of Diffusion models by efficiently calculating score function derivatives. Their SciRESolver technique significantly accelerates DM sampling, achieving state-of-the-art FID scores with fewer NFEs. The method demonstrates remarkable performance on tasks like text-to-image generation, requiring few NFEs for high-quality samples."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "In diffusion models, the NFE required for sampling has always been the main computational overhead, and reducing NFEs is very important for efficiency."
            },
            "weaknesses": {
                "value": "The improvement is not consistent, which makes the interpretation a little challenging."
            },
            "questions": {
                "value": "Given the current literature, as the distillation of score-based models can reduce NFE significantly. How can your algorithm be combined with distillation?\n\nHow can you explain the behavior of SciRE-V1-2 and SciRE-V1-3 from a theoretical perspective?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698789888945,
        "cdate": 1698789888945,
        "tmdate": 1699636394346,
        "mdate": 1699636394346,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aKXZeZUBKL",
        "forum": "85Af6AcMo5",
        "replyto": "85Af6AcMo5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_eocv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_eocv"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new training-free sampling algorithm for diffusion models, called SciRE-solver. SciRE-solver is based on Taylor expansion and uses the proposed Recursive Difference (RD) method to estimate the derivative of the score model. The authors conduct extensive experiments on various datasets such as CIFAR10, CelebA, ImageNet, LSUN, showing that the proposed SciRE-solver consistently outperforms existing numerical samplers."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-written with sufficient details and comprehensive ablation studies. \n2. The paper clearly explains its relationship to and differences from the related work to be well-placed in the literature. \n3. SOTA performance compared to existing numerical sampling algorithms on various datasets and diffusion models."
            },
            "weaknesses": {
                "value": "1. The paragraph above Figure 2 needs revision for clarity. The score approximation error is inevitable. How can the proposed sampling method mitigate this issue? The third sentence is also vague without explaining what the \"additional variables\" means. It is not clear how these considerations lead to the hypothesis either. \n2. While the authors demonstrate generated samples of pre-trained DMs on high-resolution datasets such as ImageNet, LSUN-bedroom, and stable diffusion model, there is lack of quantitative results on these datasets except for ImageNet128. Can you also add quantitative results on ImageNet256 and LSUN-bedroom? \n3. In Table 1, SciRE-solver uses pre-trained model from EDM. But the results of the original EDM sampler is missing from the comparison. \n4. Minor: in the abstract, \"Experiments demonstrate also that demonstrate that\" -> \"Experiments also demonstrate that\"."
            },
            "questions": {
                "value": "1. While SciRE-solver outperforms its counterpart DPM-solver in the experimental results, can you elaborate more on why it is better than DPM-solver numerically? Does SciRE-solver provide more accurate higher-order derivative estimation than DPM-solver theoretically?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4270/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4270/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4270/Reviewer_eocv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698798071087,
        "cdate": 1698798071087,
        "tmdate": 1699636394255,
        "mdate": 1699636394255,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D4MY8uBvoi",
        "forum": "85Af6AcMo5",
        "replyto": "85Af6AcMo5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_gjHa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4270/Reviewer_gjHa"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the Recursive Difference (RD) method to calculate the derivative of the score function network. Based on the RD method and the truncated Taylor expansion of score-integrand, the authors propose SciRE-Solver to accelerate diffusion model sampling. \nThe core of their algorithm relies on evaluating higher-order derivatives of the score functions, which cannot be done by conventional finite difference methods, as errors can propagate easily. The RD method is proposed to tackle this problem. They provide extensive experiments on variant benchmark datasets to demonstrate the effectiveness of their approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors propose a fast sampling algorithm for diffusion models based on using an RD approach to evaluate higher-order derivatives of the score function. They clearly introduce the intuiotion and the background story. Extensive experiments on various datasets are conducted to support the use of their proposed algorithm. Compared to existing algorithms, the proposed SciRE-based algorithm in many cases achieve lower FID score with a fewer number of NFEs."
            },
            "weaknesses": {
                "value": "I have two major concerns:\n\n1. Their main result, the RD procedure is not presented clearly enough. This algorithm is only described in words, and Figure 2 is hard to parse. From Equation (3.7) I see that to evaluate first order derivative at $s$, we need both the first and the second order derivatives at $t$. Then why the authors say in the caption of Figure 2 that we can evaluate the first order derivative at $s$ with only zero order derivative at $t$? I would suggest present the most general form algorithm in a pseudo-code format like Algorithm 1 and 2. \n\n2. This paper might contain some critical typos that affect the entire proposal (see my second question). \n\nI would love to increase my score if these issues are well-addressed."
            },
            "questions": {
                "value": "1. Is there any acceleration algorithm for diffusion SDE as well? If yes, I would love to see the authors providing a discussion. If no, could the authors elaborate a bit on why training-free acceleration is mostly for diffusion ODE? \n2. I thought $\\alpha_t = \\prod_{i = 1}^t \\beta_i$ is piecewise constant?  Then how do you define $f(t)$ as the derivative of $\\log \\alpha_t$ with respect to $t$? It is unclear whether the authors use $t$ as a index for discrete time step or continuous time. \n3. In Eq (3.1), $h(r)$ should be $h_1(r)$. \n4. I understand that $NSR$ is monotone, but why is it strictly monotone? Namely, how to guaratee the existence of its inverse function. \n5. Why the authors say in Figure 1 that the proposed algorithm outperforms DDIM and DPM solver? \n6. Where is $t_i$ defined? \n7. Maybe this is a dumb question. Why can we assume the neural network is differentiable? I would imagine this is not the case when the activation function is ReLU. \n8. This sentence is hard to parse. \"This method recursively extracts the hidden lower-order derivative information of the higher-order derivative terms in the Taylor expansion of the score-integrand at the required point, as illustrated in Figure 2\". I would suggest the authors present their most general form algorithm in the format of Algorithm 1 and 2. \n9. Could the authors elaborate on what Figure 2 is trying to illustrate? In particular, why some blocks are colored in red and the others in blue? Why do you call the first row Taylor series and the second row Weighted sum? \n10. In Theorem 3.2, $m$ has to be larger than 2 or 3? \n11. The legend in Figure 3 is a bit misleading. I assume the first four ones are for dashed lines, but it is not apparent at first glance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4270/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4270/Reviewer_gjHa",
                    "ICLR.cc/2024/Conference/Submission4270/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699133187417,
        "cdate": 1699133187417,
        "tmdate": 1700668585636,
        "mdate": 1700668585636,
        "license": "CC BY 4.0",
        "version": 2
    }
]