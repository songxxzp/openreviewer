[
    {
        "id": "z9CJeVnjUa",
        "forum": "gHaokdQkoi",
        "replyto": "gHaokdQkoi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_pwWA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_pwWA"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a neural network model combined with the explicit Runge-Kutta time integration scheme to solve some 1D/2D ODE and PDE problems. For PDE problems, the network model essentially fits the (discretized) spatial gradient operators in the PDE."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "At a high level, I appreciate the combination of classical numerical methods with neural network models. I think this is a right move that deserves more attention in the community.\n\nI also like that the paper puts thoughts on network generalization and explicitly discusses multiple scenarios: different initial conditions, spatial discretizations, PDE coefficients, etc."
            },
            "weaknesses": {
                "value": "I struggle to see a motivation for using a neural network model to replace the evaluation of f in Eqn. (1) in the RK framework. The RK scheme described by Eqn. (3) is a standard explicit time integration scheme, and a numerical method (finite difference, finite elements, etc.) for evaluating f in Eqn. (1) can be highly efficient using trivial parallelization on GPUs. Numerical methods also have great generalizability as they can easily handle different initial conditions, physical parameters, spatial discretization, etc. in a principled way. After reading the paper, it remains unclear to me what the advantages of the proposed method over numerical simulation are.\n\nI also have a number of concerns regarding the experiments:\n- Following my comment above, I feel the method should be compared with a high-quality numerical simulator (finite difference/element/volume, etc.) and report their runtime difference. I skimmed over the Burges equation part in the code, and it looks like the training data were generated using finite differences implemented in numpy. Was it faster or slower than the network inference time in the proposed method?\n- I feel the comparison with other neural network baselines is not well-balanced in that it exaggerates their weaknesses but ignores their strengths in other aspects. Taking PINN as an example, PINN has been tested against much more complicated PDEs in fluid and solid mechanics (e.g., Navier-Stokes) which explicit time integrations like RK4 struggle to solve, and I don\u2019t see an easy way for extending the proposed method to these PDEs given that it is coupled with RK time integration. Another thing is that PINN can be trained with partial observations of the spatiotemporal states sampled irregularly in time and space, so it seems to impose fewer requirements on the training data than the proposed method. Of course, it is unnecessary to beat all baselines in all aspects before publishing a research paper, but I think a more balanced view and experiment design would make it more convincing."
            },
            "questions": {
                "value": "I actually don\u2019t have any technical questions to ask for now. The paper is well-written, and the main method is quite straightforward to follow. Maybe I will ask some technical questions after reading the rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Reviewer_pwWA"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698677681039,
        "cdate": 1698677681039,
        "tmdate": 1700639970143,
        "mdate": 1700639970143,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DRSmywBWN8",
        "forum": "gHaokdQkoi",
        "replyto": "gHaokdQkoi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_r1o4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_r1o4"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel model, Graph Neural Runge-Kutta (GNRK), which combines classical numerical solvers with graph neural networks. GNRK leverages Runge-Kutta to address time-dependent partial differential equations (PDEs) and is designed to be generally applicable under varying conditions, including changes in initial conditions, PDE coefficients, and modifications in time and space discretization.\n\n# After rebuttal!\nThank you for addressing my inquiries about the paper. I appreciate your thoughtful responses, and I hope that my questions and suggestions have been beneficial for the paper. Additionally, there are aspects I'd like to see included in the future, such as experiments related to question 8, specifically showcasing experiments involving nu. Furthermore, it would be valuable to have comparisons with other baselines that you mentioned haven't been conducted yet due to time constraints. I believe that addressing these aspects would significantly enhance the paper. Currently, it feels a bit incomplete without these additions, and I hope to maintain the score I have given, expecting improvements in the future. Thank you."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Research that combines deep learning techniques like graph neural networks and message passing with well-established numerical analysis methods is of significant importance. This integration of mathematical principles and deep learning technologies has the potential to create more robust and effective models."
            },
            "weaknesses": {
                "value": "Firstly, the title of the paper includes \"PDE,\" but the experimental results mainly focus on 2D Burgers' equations as PDE, while all other experiments seem to center on coupled ODE systems. Also, the phrase in the abstract, \"often confined to specific PDEs under certain constraints,\" seems somewhat unclear in its meaning. There are different numerical schemes (e.g., FDM, FEM, or more specialized variations) for applying numerical analysis methods to different types of equations. It appears that neural network models have various methods for different types of PDEs. More detailed explanations in the paper title and abstract might be needed to better represent this research.\n\nSecondly, the paper lacks a clear explanation of how the novelty of the GNRK model differs from existing models. It is essential to clarify where GNRK offers advantages over previous models concerning the combination of numerical analysis and graph neural networks. The novelty mentioned on page 2 and the four categories discussed in Section 3 require a precise comparison with prior research. For instance, the advantage related to the initial condition might not be unique to GNRK but rather a common benefit shared with all models utilizing graph neural networks. Additionally, the statement that learning with changing PDE coefficients is not efficient, as mentioned in Section 3, should be supported by evidence. In light of this, focusing on the advantages of GNRK over other neural network models, considering multiple aspects of operator learning models and models that learn solutions varying over time, and creating a table that clearly illustrates what each model can and cannot do would be beneficial. This table could emphasize where GNRK excels in comparison.\n\nFurthermore, there appears to be a lack of mention and references to several recent papers that use graph neural networks for simulating physical phenomena. In fact, papers [1], [2], [3], [4], for instance, utilize GNNs to predict changes between the previous and subsequent time steps and consider time-dependent predictions. It would be helpful to discuss the commonalities and differences between these papers and GNRK, particularly [1] and [2], which deal with time-dependent PDEs, and explain how they relate to the work in this paper. Additionally, considering additional types of data in this paper could further highlight the advantages of GNRK.\n\n*[1] Brandstetter, J., Worrall, D., & Welling, M. (2022). Message passing neural PDE solvers. arXiv preprint arXiv:2202.03376.*\n\n*[2] Boussif, O., Bengio, Y., Benabbou, L., & Assouline, D. (2022). MAgnet: Mesh agnostic neural PDE solver. Advances in Neural Information Processing Systems, 35, 31972-31985.*\n\n*[3] Pfaff, T., Fortunato, M., Sanchez-Gonzalez, A., & Battaglia, P. W. (2020). Learning mesh-based simulation with graph networks. arXiv preprint arXiv:2010.03409.*\n\n*[4] Lienen, M., & G\u00fcnnemann, S. (2022). Learning the dynamics of physical systems from sparse observations with finite element networks. arXiv preprint arXiv:2203.08852.*"
            },
            "questions": {
                "value": "* More detailed explanation is needed for the phrase 'less dependent on the form of PDEs or conditions.' at page1. What does it mean? \n\n* In Section 2.1, it would be helpful to clarify how GNRK can handle non-uniform discretization. For example, if there are data points at 1 second, 2 seconds, and 5 seconds, how can GNRK capture the information that the intervals between 1 and 2 seconds and between 2 and 5 seconds are different?\n\n* In the middle of page 3, there is an assumption about \"same degree.\" Is this assumption absolutely necessary, or can GNRK be applied without it? You've clarified that GNRK is applicable in cases like the left graph in Figure 1, but what about scenarios like the right graph in Figure 1? Can GNRK be used there as well?\n\n* Regarding Figure 2, when determining the order of Runge-Kutta and constructing the model, can GNRK be applied to predict solutions only at that order?\n\n* In the Burgers experiments in Section 4.1, it would be interesting to know how the model in Figure 2 adapts and learns GNRK as nu changes. This is one of the novelties mentioned in Section 3 but is not detailed in the main text.\n\n* Section 4.2 discusses experiments related to coupled ODEs without comparative benchmarks. Could you explain why there are no benchmarks for coupled ODEs? Is it possible to apply the benchmarks in Table 1 to coupled ODEs, or are there other neural network models suitable for coupled ODEs that are worth mentioning?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Reviewer_r1o4",
                    "ICLR.cc/2024/Conference/Submission3170/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839988319,
        "cdate": 1698839988319,
        "tmdate": 1700887439565,
        "mdate": 1700887439565,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LKfQ9TRH99",
        "forum": "gHaokdQkoi",
        "replyto": "gHaokdQkoi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_yG9N"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_yG9N"
        ],
        "content": {
            "summary": {
                "value": "# Initial review summary\nIn this paper, the authors propose Graph Neural Runge-Kutta method, which utilizes graph networks to capture the spatial structure, and the Runge-Kutta method for the temporal integration. It is claimed that the proposed model can better handle general PDE problems. Experiments in Burgers' equation have been performed, in comparison with baseline methods such as FNO, GNO, GraphPDE, etc.\n\n# Update after rebuttal\n\nThanks very much for your detailed response. Some of my questions are definitely clarified. It is also very inspiring to go through other reviewers' questions and replies.\n\n- I am still concerned if it is necessary or beneficial to choose $a$ and $b$ strictly from the Butcher's table, while $f$ itself has lost its rigorousness.\n- Without the capability of remeshing, I think there will be a gap between the proposed method and practical usage, since it will face time-dependent PDE problems where fixed mesh has limits. Also, I don't think it is trivial to integrate remeshing into the proposed method.\n- Other reviewers' concerns about the experimental settings, evaluation metrics, comparison baselines, etc., are also very solid questions.\n\nWith all the factors considered, I tend to remain my original score for now."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Finding the sweet point to combine data-driven models and numerical methods is an important and interesting topic in AI4PDE.\n- Benefit from the design, the proposed method can estimate the solution at any position or time."
            },
            "weaknesses": {
                "value": "- There are a few popular works solving spatial-temporal PDEs with graph neural networks that are not mentioned or compared in the paper, such as meshgraphnet, MP-PDE, etc. There are also a few works in Neural ODEs that are relevant, such as hypersolver, deep Euler method, etc.\n- Traditionally, the Runge-Kutta method comes with strict guarantees in accuracy, convergence, stability, etc. But with a GNN as the estimator in a timeslot, such theoretical properties are lost. So I wonder if it is still necessary or beneficial to utilize the Runge-Kutta scheme with GNN when handling a practical PDE problem.\n- In the conclusion section, it is claimed that \"it is invariant to spatial and temporal discretization\". But I don't see how the proposed method can guarantee such invariance capability."
            },
            "questions": {
                "value": "- I am wondering which numerical method suits the situation better, the Runge-Kutta method or the multi-step method. And I would like to know if the authors have some comments on this.\n- I don't see how remeshing is handled in the proposed method? Remeshing is a vital part of time-dependent PDEs, especially for fluid problems, hence I think remeshing should be a necessary part in the solution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3170/Reviewer_yG9N",
                    "ICLR.cc/2024/Conference/Submission3170/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699231503644,
        "cdate": 1699231503644,
        "tmdate": 1700746703524,
        "mdate": 1700746703524,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "b3LRoIJOTb",
        "forum": "gHaokdQkoi",
        "replyto": "gHaokdQkoi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_Sxmd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_Sxmd"
        ],
        "content": {
            "summary": {
                "value": "A novel surrogate model based on graph neural networks (GNNs) to solve partial differential equations (PDEs) is introduced. The proposed model is endowed with a recurrent structure to mimic numeral solvers. It is achieved by integrating Runge-Kutta scheme. This model can handle different PDE conditions."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1/ Originality and significance:\n\nWhile GNNs become the standard models to approximate the functional space of PDEs, integrating Runge-Kutta scheme to GNNs is a key contribution. As a consequence, GNN based on Runge-kutta scheme enables tackling PDE problems under different conditions and can enjoy good generalization capabilities where existing GNN based PDEs fail.\n\n2/ Quality:\n\nThe proposed work is interesting for the community, it opens new perspective at the crossroad of numerical solvers and neural networks. The motivation to  generalize to different PDE conditions is well structured, the claims are well supported in the experiments. \nThe claims on the ability to cope with different initial conditions, PDE coefficients and spatio-temporal discretization are important for engineers in real-world applications\n\n3/Clarity:\n\nThe paper is well structured and easy to follow.\nDiscussion of related works is sufficient.\nResults are reproducible and the code is easy to follow."
            },
            "weaknesses": {
                "value": "One of the weaknesses of this work is in its experimental protocol. It has not been validates on large scale datasets and problems with challenging geometries and high reynolds(10^6).  \nThe value of the paper will be important if it is validated on challenging problem, proving that the following claims still hold at large scale:\n\u2022 Initial conditions\n\u2022 PDE coefficients\n\u2022 Spatial discretization\n\u2022 Temporal discretization and the order of RK"
            },
            "questions": {
                "value": "1/ It is mentioned in the paper \"It can even generate solutions with higher precision than the training data through the RK order adjustment\":\nCan you explain more how it is possible ? is it just inference or fine-tuning at test time\n\n2/ It would be very important to validate the proposed work on challenging datasets. For instance:\nA- EAGLE: Large scale learning of turbulent fluid dynamics with mesh transformers.  About 1 million 2D meshed with 600 different scenes\nB- AirfRANS: High Fidelity Computational Fluid Dynamics Dataset for Approximating Reynolds-Averaged Navier\u2013Stokes Solutions. Complex geometries, high Reynold numbers and challenging to obtain accurate results at the boundary layer.\nC- PDEBench: An Extensive Benchmark for Scientific Machine Learning. For instance considering the following datasets: 3D_cfd, 2D_cfd, darcy_flow.\n\nI would be happy to increase my score if the suggested new experiments validate the claims of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699522974163,
        "cdate": 1699522974163,
        "tmdate": 1699636264518,
        "mdate": 1699636264518,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fdec6Fo5iW",
        "forum": "gHaokdQkoi",
        "replyto": "gHaokdQkoi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_MKmy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3170/Reviewer_MKmy"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the GNRK as a PDE solver by using graph neural networks as the message passing mechanism, which simulates the multi-step Runge-Kutta method with a recurrent structure. The proposed method can handle nonuniform spatial grids and temporal intervals by learning graph representations from node and edge, and global information. GNRK can be trained with a small amount of data, and outperforms the classical neural operators and PINNs in 2D Burgers' Equation. Moreover, experiments in three datasets of the heat equation, Kuramoto equation, and coupled Rossler equation proved that the fourth-order solver model outperforms the first-order solver model, and the network can handle three types of graph topologies well."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The design in GNRK is reasonable. Directly modeling observation time with Runge-Kutta method enables the model to deal with nonuniform observation time intervals. Incorporating graph neural network enables models to cope with irregular meshes.\n\n- GNRK beats other baselines in the 2D Burgers' Equation dataset with less parameters."
            },
            "weaknesses": {
                "value": "1. There exists serious mismatches between the authors' claim and their experiments.\n\nThe authors claim that GNRK can be generalized to different initial conditions, PDE coefficients, spatial discretization and temporal discretizaition without retraining in Section 3. However, **no experiments are provided to prove the generalization without retraining**. They just change the Runge-Kutta order between train and test datasets in each experiment. For me, to demonstrate the model generality, they should train the model in Dataset I and test in Dataset 2.\n\n2. About the experiment settings.\n\nThe experimental datasets are too simple to provide converncing results.\n\n- In Appendix B, the initialized state of the 2D Burgers' equation is determined by a quite simple periodic function, which only changes the phase and the center point. Reference to FNO[3], the 2D Burgers' Equation dataset can be initialized using a normal distribution.\n- Besides, for three datasets mentioned in section 4.2, they only experiment GNRK and do not provide any comparisons to other baselines. Thus, it is hard to judge the model performance in irregular meshes.\n\n3. About the model efficiency.\n\nHigher order of Runge-Kutta leads to higher computational cost, the comparisions between GNRK and other baselines in running time, GPU memory are expected.\n\n4. About the baselines and ablations.\n\nFNO, GNO, GraphPDE, PINN are both not the SOTA baselines. Recently, many advanced neural operators have been proposed, such as LSM [1] and geo-FNO [2]. They can also handle the irregular input meshes. How about directing comparing with them or replacing the GNN parts with them?\n\n\n```\n[1] Solving High-Dimensional PDEs with Latent Spectral Models, ICML 2023\n[2] Fourier Neural Operator with Learned Deformations for PDEs on General Geometries, arXiv 2022\n```\n\n5. About the showcases. \n\nThe authors only provide the showcases for their own model. More showcase comparisons are expected to intuitively demonstrate the effectiveness of GNRK."
            },
            "questions": {
                "value": "The design of the network seems reasonable. But the experiments can not verify the performance of the proposed model. All the details can be found in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699586413238,
        "cdate": 1699586413238,
        "tmdate": 1699636264438,
        "mdate": 1699636264438,
        "license": "CC BY 4.0",
        "version": 2
    }
]