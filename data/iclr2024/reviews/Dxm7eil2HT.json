[
    {
        "id": "W8TqNiojOr",
        "forum": "Dxm7eil2HT",
        "replyto": "Dxm7eil2HT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_aduf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_aduf"
        ],
        "content": {
            "summary": {
                "value": "This paper considers a bivariate causal discovery problem where the observed labels are noisy. Observing that in the causal direction $P(X)$ does not contain information about the mechanism $P(Y|X)$, authors show that $P(\\tilde Y|X)$ is a good surrogate in this setting and then propose a noise injection based method to discover the causal direction. Some theoretical results are given and experimental results validate the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The method of noise injection for causal discovery is novel and interesting. \n- Theoretical guarantees are given. \n- Illustration of the proposed method is good."
            },
            "weaknesses": {
                "value": "- Problem setting is not very rigorous\n- No explicit identification result and no assumptions/conditions under which the proposed method can identifiy the true direction.\n- Lacking some details regarding the experiment part."
            },
            "questions": {
                "value": "I reviewed this work in a previous venue where authors have addressed many of my concerns. For this version, I only have the following questions/suggestions:\n\n- Compared with traditional biavariate causal discovery methods, this work and the proposed method are novel in two aspects: 1) noisy labels, and 2) high-dim features $X$ and scalar label $Y$. Thus, I think the paper should be made more clear regarding the problem setting and assumptions in Section 3.1:\n  - \"This mechanism, being correlated with P(Y|X), provides insights into the true class posterior.\"---how do you define \"correlated\"? and in what sense?\n  - \"It\u2019s noteworthy that P\u03b8(Y\u02dc |X)  generally maintain a dependence with P\u03b8(Y |X).\" Similarly, how do you define \"dependence\"  in a more accurate way (e.g., using math formulas) and in what sense?\n  - \"It is usually highly correlated with and informative about P(Y |X). Moreover, under a causal setting, P(X) cannot inform P(Y\u02dc |X), since Y\u02dc and Y are effects of X, and P(X) and P(Y\u02dc |X) follows causal factorization and are disentangled according to independent mechanisms (Peters et al., 2017b). Thus, P\u03b8(Y\u02dc |X) is an proper surrogate.\" -----From the causal graph in Fig. 2, I can see an edge $X->\\tilde Y$  for both causal and anticausal settings, so the factorization should work for both directions. Or three should be a more accurate causal graph regarding the proposed setting?\n\n- There seems no identification conditions  discussed in the main text? Please make identification explicit in the main text and discuss also the assumptions. This would help readers have a better understanding of the proposed method.\n- Experiments: please do consider to have more details in the main text (e.g., in the camera-ready version where more pages are allowed or move some content to the appendix) For example, Table 1 seems not mentioned at all in the main text.\n- A minor question: GES and some other methods work for scalar variables. How do you apply these methods to image data? I do no find such details and cannot say if the comparison with these methods are proper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8394/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698577648189,
        "cdate": 1698577648189,
        "tmdate": 1699637045243,
        "mdate": 1699637045243,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "67oQBTY6KY",
        "forum": "Dxm7eil2HT",
        "replyto": "Dxm7eil2HT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_g7sE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_g7sE"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces RoCA, a method of determining whether the causal direction between features $X$ and label $Y$ is causal or anticausal. The observed labels $\\tilde{Y}$ are a noisy proxy for the true labels $Y$. The approach assigns a pseudo-label $Y\u2019$ to each datapoint based on a clustering of the feature space and then decides that the dataset is causal if $Y\u2019$ cannot be predicted from the features $X$ and observed label $\\tilde{Y}$ (implying that $Y\u2019$ contains no information about $P(\\tilde{Y} \\mid X)$). This decision is done tractably by selectively adding noise to the observed labels $\\tilde{Y}$ depending on the features $X$, then observing the disagreement between the pseudo-labels $Y\u2019$ and the noisy labels at different levels of noise. The argument for this approach is that if $Y\u2019$ is not informative of $P(\\tilde{Y} \\mid X)$, then adding noise would not change anything. However, if it is informative, then adding noise would make $\\tilde{Y}$ increasingly unpredictable. Experimental results show that the approach is more accurate than competing approaches."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The theoretical analysis on the noise injection levels is quite interesting and insightful.\n\n2. The hypothesis testing makes the end decision more quantifiable and systematic.\n\n3. The experimental results are quite impressive."
            },
            "weaknesses": {
                "value": "1. The way that the concept of independent mechanisms is presented in this paper seems misleading.\nFirst, the paper quotes at the bottom of page 3 that \u201cthe mechanism generating the effect from its cause does not contain any information about the mechanism generating the cause\u201d and then concludes that \u201cthe conditional distributions of each variable, given all causal parents, are independent entities that do not share any information\u201d. This conclusion only holds under the Markovianity assumption (i.e. no unobserved confounders). Under the presence of unobserved confounding, it is possible that the causal mechanisms can be independent, but a variable can still be dependent on some other variable given its parents. It seems that this assumption is actually key to the effectiveness of the proposed approach. However, this assumption is not stated anywhere in the paper.\nSecond, mathematically speaking, $P(X, Y)$ can be factorized as either Eq. 2 or Eq. 3 regardless of causal orientation. It is not clear what is the causal consequence of choosing one over the other.\nThird, it is not formally explained what it means for a distribution to \u201cinform\u201d another, yet this seems to be key to understanding the proposed approach. Is the paper claiming to somehow infer the data-generating mechanisms from the distributions?\n\n2. I am concerned about the soundness of the approach. The approach seems to rely on the property that within causal datasets, observed labels are evenly distributed among the clusters of $P(X)$, while they are not in anticausal datasets. This property does not seem to be related to any causal properties.\n\n3. Assumptions are quite unclear. In addition to the assumption of Markovianity, it seems there are many more made that are not explicitly stated. In Sec. 3.1, it is discussed that $P_{\\theta}(\\tilde{Y} \\mid X)$ can act as a surrogate for $P(Y \\mid X)$, but there is no formal explanation on what this means. There is also little justification on the implications of the clustering algorithm. The results of this approach heavily depend on the outputs of the clustering algorithm, so there must be some implicit assumption that the clustering algorithm outputs something relevant to the causal structure of the dataset, which should be explicitly stated.\n\nGiven these concerns, I cannot recommend the paper for acceptance in its current form. I am open to hearing author responses in case I misunderstood something.\n\nEDIT: Following rebuttal, I am raising my score from 3 to 6."
            },
            "questions": {
                "value": "1. In the introduction, it is mentioned that the causal graphs are assumed to be acyclic. However, there seems to be a cycle in Fig. 1b from $X_2 \\rightarrow X_d \\rightarrow Y \\rightarrow X_2$. This seems to be a contradiction, could the authors clarify on this point?\n\n2. In Sec. 3.1, it is mentioned that $P(\\tilde{Y} = \\tilde{y} \\mid Y\u2019 = y\u2019, X = x)$ should equal $1 / C$ for each $x$. Does this only hold if the distribution of labels is uniform?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8394/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8394/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8394/Reviewer_g7sE"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8394/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698785111960,
        "cdate": 1698785111960,
        "tmdate": 1700684544852,
        "mdate": 1700684544852,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PH7qMKStxu",
        "forum": "Dxm7eil2HT",
        "replyto": "Dxm7eil2HT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_32x9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8394/Reviewer_32x9"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to discern if a data generation process leans towards being causal or anti-causal. Introducing the Robust Causal and Anticausal (RoCA) Estimator, the authors attempt to differentiate the two by investigating if the instance distribution, $P(X)$, offers pertinent details about the prediction task, $P(Y|X)$. They opted for the noisy class-posterior distribution, $P(\\tilde{Y}|X)$, to act as a stand-in for $P(Y|X)$, and devised clusters using unsupervised or self-supervised techniques. Their findings suggest that in a causal scenario, there's no correlation between mismatch and noise levels, while in an anti-causal context, a correlation exists. The paper furnishes empirical evidence to support these claims."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem of interest is an important topic in casual discovery.\n\n2. The method proposed overall sounds interesting and new.\n\n3. The paper is well written."
            },
            "weaknesses": {
                "value": "1. The core premise of the paper, notably the logic of employing \\(p(x)\\) predictiveness to discern between causal and anti-causal directions for \\(p(y | x)\\), lacks solid substantiation. A deeper justification, supported by empirical data, would strengthen this assumption.\n\n2. The paper does not present clear identifiability results. The claim that it's unnecessary to identify all potential causal relationships among single-dimensional variables is made without sufficient exploration. Additionally, concerns arise in an anti-causal context with a potential cyclic graph, questioning whether \\(P(X)\\) indeed offers valuable insight for the prediction task \\(P(Y|X)\\).\n   \n3. There seems to be a discrepancy in the paper's foundational assumptions on causal inference. While the authors state they align with the definitions in Sch\u00a8olkopf et al. (2012), their handling of the Anticausal definition, especially regarding confounded cases, suggests otherwise. The paper needs to clarify its stance on unmeasured confounders.\n\n4. The methodology for determining the noisy distribution and constructing \\(P(\\tilde{Y}|X)\\) appears to lack a clear rationale. Offering detailed reasons for the \"Noise Injection\" approach and possibly introducing sensitivity analysis would bolster this section.\n\n5. The method's practical relevance raises concerns. While the novel concept of integrating the causal direction into (semi-)supervised problems is compelling, its adoption in real-world applications remains questionable.\n\n6. The paper seems to omit a comprehensive review of the related literature. Engaging more deeply with existing academic contributions would provide readers with valuable context, facilitating a better understanding of the paper's novelty and its positioning in the wider domain.\n\n7. The overall organization and clarity of the paper need improvement. The section discussing experiments is notably intricate, making navigation challenging. A clearer structure and presentation would significantly improve the paper's readability."
            },
            "questions": {
                "value": "Please consider addressing the weakness I mentioned above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8394/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817875277,
        "cdate": 1698817875277,
        "tmdate": 1699637044959,
        "mdate": 1699637044959,
        "license": "CC BY 4.0",
        "version": 2
    }
]