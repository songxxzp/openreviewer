[
    {
        "id": "cTrPmbyHUA",
        "forum": "NLPzL6HWNl",
        "replyto": "NLPzL6HWNl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_8DEX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_8DEX"
        ],
        "content": {
            "summary": {
                "value": "The Federated Generative Learning (FGL) framework offers a novel approach to federated learning, leveraging foundational generative models like Stable Diffusion to generate training data from prompts shared by clients. Clients contribute class-level or instance-level prompts, encapsulating key features of their local data. The server, in turn, amalgamates these prompts and synthesizes corresponding training data for global model training. This approach trims down communication costs since only concise prompts, and not bulky gradients or models, are transferred. This system also boasts robustness to data diversity and has demonstrated superior performance \u2013 with just one communication round, it outdid FedAvg's 200 rounds in accuracy. When trialed on skewed ImageNet100 distributions, FGL exceeded FedAvg's performance by 30% in just five communication rounds. Apart from being efficient, FGL also enhances privacy, as prompts reveal lesser private data than traditional methods. Evaluations confirmed no private data memorization in the synthetic images and an enhanced resilience against membership inference attacks. However, challenges persist with non-IID data, intricate domains, and the potential risks associated with prompts."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tClearly identifies limitations of vanilla LoRA in federated learning settings and provides theoretical analysis on the causes.\n2.\tProvides extensive experiments that demonstrate consistent improvements of FFA-LoRA over LoRA on multiple models, datasets, and conditions.\n3.\tReduces communication costs and removes reliance on scaling hyperparameters compared to LoRA."
            },
            "weaknesses": {
                "value": "1.\tUnclear how the approach performs under other challenges like adversarial attacks, concept drift, and personalization. \n2.\tThe paper only evaluates NLP tasks with text data. Unclear if the benefits of FFA-LoRA generalize to other data types like image, speech, etc.\n3.\tThe theoretical analysis and intuitions provided are informal. No formal convergence or privacy proofs given."
            },
            "questions": {
                "value": "please refer to the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6253/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698544084613,
        "cdate": 1698544084613,
        "tmdate": 1699636684229,
        "mdate": 1699636684229,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0LzInab5vI",
        "forum": "NLPzL6HWNl",
        "replyto": "NLPzL6HWNl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_E2bX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_E2bX"
        ],
        "content": {
            "summary": {
                "value": "This paper presented an approach called Federated Freeze A LoRA (FFA-LoRA) to address the limitations of the low-rank adaptation method in federated learning setting. The limitations of the vanila low-rank adaptation include: 1) data heterogeneity, 2) amplication of difficiential privacy noise and 3) sensitivity to hyper-parameters. Authors provide empirical results, showing that the FFA-LoRA outperforms vanilla LoRA in federated learning settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The study on federated LoRA is timely.\n2. The proposed approach is simple to implement.\n3. The authors provide case studies to highlight the limitations of the vanilla LoRA and motivate their approach."
            },
            "weaknesses": {
                "value": "1. The benefit of FFA-LoRA on differential privacy (DP) is not very well backed by empirical evaluation. The performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets $\\epsilon$, including $\\epsilon = 0$. Such an empirical result suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA.\n\n2. I do not see why the proposed FFA-LoRA is free from tuning the hyper-parameter $\\alpha$. In Section 4, the authors claim that \"FFA-LoRA does not rely on $\\alpha$, and is equivalent to LoRA with $\\alpha = \\infty$\". Such a claim, in fact, suggests that the $\\alpha$ is fixed in FFA-LoRA. Then, in Theorem 1, the theoretical result suggests that tuning $\\alpha$ is equivalent to tuning the learning rate $\\eta$. I'm not able to fully follow the discussion here."
            },
            "questions": {
                "value": "1. Is the FFA-LoRA approach more sensitive to random initialization? Suppose a bad initialization sets $\\mathbf{A} = \\mathbf{0}$; is the model still trainable?\n\n2. What's the variance in the experiment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6253/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698788765005,
        "cdate": 1698788765005,
        "tmdate": 1699636684104,
        "mdate": 1699636684104,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aFjyb8a3wJ",
        "forum": "NLPzL6HWNl",
        "replyto": "NLPzL6HWNl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_WAsF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_WAsF"
        ],
        "content": {
            "summary": {
                "value": "The author proposes FFA-LoRA, a LoRA variant in FL by freezing one of the LoRA weight and training only the other LoRA weight so that it's easy to do model averaging in FL. Empirical results show that FFA-LoRA achieves comparable performance compared with LoRA under different differential privacy guarantees."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The motivation is sound and the paper writing is easy to follow.\n+ Empirical results show competitive performance under different differential privacy and parameter budget.\n+ Empirical results are comprehensive, considering multiple tasks and ablation study."
            },
            "weaknesses": {
                "value": "+ The motivation is straightforward and intuitive, without theoretical insights."
            },
            "questions": {
                "value": "+ Why rank 16 for MNLI is worse than rank 8 in Table 2?\n+ Another intuitive variant is to alternative optimize the two LoRA weights. How would this perform compare with the proposed method?\n+ Why non-iid performance is similar to iid performance in Table 3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6253/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814654022,
        "cdate": 1698814654022,
        "tmdate": 1699636683968,
        "mdate": 1699636683968,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QGaOujVM9q",
        "forum": "NLPzL6HWNl",
        "replyto": "NLPzL6HWNl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_1Jzn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6253/Reviewer_1Jzn"
        ],
        "content": {
            "summary": {
                "value": "This paper discuss the potential discordances of applying LoRA in differentially private federated learning: (1) decompose `\\DeltaW` to `BA` moves LoRA into a nonlinear regime that potentially cause trouble for aggregation/averaging in model updates (2) the nonlinearity of `BA` cause trouble for DP noise (3) LoRA introduce an extra parameter \\alpha. A new algorithm FFA-LoRA is proposed, where instead of updating both `B` and `A` matrices in LoRA, FFA-LoRA only updates the matrix B and keeps A fixed at random initialization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I like the motivation of the FFA-LoRA algorithm, and appreciate the attempt to provide some analysis on the caveats of LoRA. The experiments on two models (RoBERTa and LLaMA) fine-tuning on a subset of GLUE tasks and a GSM-8K language generation task in both non-DP and DP settings show good empirical performance of FFA-LoRA."
            },
            "weaknesses": {
                "value": "I thank the authors for providing details of the experimental setup. However, the federated learning setting in experiments seems a bit unconventional with a very small number of clients (only 3 clients). This might be categorized as a cross-silo setting, but it would be good to clearly discuss the targeted application (https://arxiv.org/abs/1912.04977 table 1, https://arxiv.org/abs/2107.06917 section 3.1). \n\nWhile I appreciate the motivation of analyzing LoRA in section 3, none of the explanations seems to be particularly convincing. The discussion of Discordance (1) and (2) heavily focus on the nonlinear nature of LoRA, but deep neural networks suffer from more severe nonlinearity, it is a bit unclear for me why LoRA `BA` suffers more than multi-layer network `W_1 W_2`. For example, for (1), I believe it not only applies to averaging models from clients, but also to averaging gradients from examples. \n\nI also fail to understand why \\alpha becomes an issue for LoRA in  Discordance (3) as it is only a scalar and might potentially be absorbed in learning rate. As shown in table  5, tuning the learning rate helps. \n\nMinor:\nThe empirical results on local DP seem to be very good with very little accuracy drop compared to non-DP results. It is possible that DP fine-tuning is not a particularly hard task compared to training from scratch, but could the authors share more details about the privacy accounting and important privacy parameters? \n\nFedBert seems to mainly focus on pre-training instead of fine-tuning. \n\nPlease cite \u201cCommunication-Efficient Learning of Deep Networks from Decentralized Data\u201d for federated learning and the FedAvg algorithm."
            },
            "questions": {
                "value": "See weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6253/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698899166842,
        "cdate": 1698899166842,
        "tmdate": 1699636683842,
        "mdate": 1699636683842,
        "license": "CC BY 4.0",
        "version": 2
    }
]