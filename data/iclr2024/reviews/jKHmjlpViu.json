[
    {
        "id": "SXqlalFtHf",
        "forum": "jKHmjlpViu",
        "replyto": "jKHmjlpViu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_aKVX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_aKVX"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the author introduces OpenWebMath, a new large-scale dataset for language model mathematical problem-solving. A comprehensive illustration of the dataset construction pipeline is provided and some further analysis of the dataset is conducted."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper provides an opensource large-scale mathematical web text dataset which can benefit the following research.\n2. The detailed dataset construction pipeline is provided."
            },
            "weaknesses": {
                "value": "1. The advance of OpenWebMath compared with existing datasets such as Proof-Pile is not provided.\n2. My main concern here is that the paper is a dataset construction paper without novel technique contribution provided. I\u2019m not very sure if this kind of paper is suitable for ICLR."
            },
            "questions": {
                "value": "What is the advance of OpenWebMath compared with existing datasets such as Proof-Pile?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5983/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698074828992,
        "cdate": 1698074828992,
        "tmdate": 1699636639983,
        "mdate": 1699636639983,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NLQnyjDdZh",
        "forum": "jKHmjlpViu",
        "replyto": "jKHmjlpViu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_2Z7u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_2Z7u"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes OpenWebMath, an open dataset of 14.7B high-quality mathematical documents from web text. The authors highlight the importance of pretraining on mathematical content to improve the reasoning abilities of large language models. They mention the success of the Minerva model, which was trained on a curated dataset of mathematical documents. However, existing open-source web datasets do not preserve mathematical notation accurately, limiting their usefulness. OpenWebMath aims to address this gap by providing a dataset of 14.7 billion tokens of mathematical web pages extracted from Common Crawl. The authors describe their method for extracting and filtering web pages for high-quality English mathematical documents. They also conduct experiments showing that models trained on OpenWebMath outperform models trained on larger general language datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper proposes an open high-quality mathematical dataset, which can let models get a good reasoning ability in a lower computation.\n2. This paper proposes a new method for extracting and filtering mathematical text from web pages. This method is worth deeper research."
            },
            "weaknesses": {
                "value": "1. The authors should provide an example of a dataset in the paper.\n2. The order in which the table appears is inconsistent with the logic of the text.\n3. There are invisible Unicode characters and some text in other languages in the data."
            },
            "questions": {
                "value": "Why there are some invisible Unicode characters and other language text in sample_dataset.jsonl? For instance the\u00a0 40th and 43th lines of sample_dataset.jsonl."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5983/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5983/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5983/Reviewer_2Z7u"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5983/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698718351122,
        "cdate": 1698718351122,
        "tmdate": 1699636639884,
        "mdate": 1699636639884,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BFOvOabszN",
        "forum": "jKHmjlpViu",
        "replyto": "jKHmjlpViu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_oFxt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5983/Reviewer_oFxt"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a large scale dataset of mathematical text (14.7B tokens, 6.3M documents) filtered from the Common Crawl dataset: OpenWebMath. The paper primarily describes the extensive pre-processing applied to obtain this dataset. To indicate the value of the dataset the paper trains a 1.4B Pythia model on the gathered data and reports perplexity on GSM8k and MATH datasets and task accuracy on MATH and LILA-multiarch. The results indicate that a model trained on OpenWebMath sees improved perplexity and better task accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper presents a well documented dataset.\n- The dataset seems to be useful for training LLMs of small-medium scale."
            },
            "weaknesses": {
                "value": "- The paper presents no special insight on the dataset or the effect of the processing steps applied - it only describes the pre-processing pipeline. A key aspect that would strengthen this paper is a description of the overlap (computed in some apt way: eg overlap of urls, text overlap, others) between OpenWebMath and the benchmark datasets it evaluates on - computing overlap other popular reasoning benchmarks would also be a welcome addition."
            },
            "questions": {
                "value": "- It seems like the MATH dataset was gathered from aops.com/community/c3158_usa_contests. Is this a part of Common Crawl? What is the overlap between OpenWebMath and MATH? This is important given concerns of dataset contamination with web scale datasets: https://arxiv.org/abs/2310.10628\n- How does OpenWebMath differ from ProofPile? Are there obvious reasons why using OpenWebMath results in significantly better performance than ProofPile?\n\t- The citation for ProofPile (\"Proofnet: Autoformalizing and formally proving undergraduate-level mathematics.\") seems incorrect. Please consider adding a note of what the dataset is and its source.\n- What exactly is LILA-multiarith? It seems the LILA benchmark contains multiple different datasets, why did the evaluation here only use this one dataset in the benchmark? \n\t- In similar vein to the above comments, does the data here overlap with OpenWebMath?\n\t- Please consider citing the original source of the multiarith dataset in addition to the benchmark, its not clear what the original data is. The citation chain to the original dataset seems to be: https://arxiv.org/pdf/2210.17517.pdf (LILA) -> https://arxiv.org/pdf/1608.01413.pdf (methodological paper using the data?) -> https://aclanthology.org/Q15-1001.pdf (original data) - please verify this.\n- Please consider describing the tasks of Table 2 in more detail.\n- Please place a table or figure closer to the texts discussing it."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5983/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5983/Reviewer_oFxt",
                    "ICLR.cc/2024/Conference/Submission5983/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5983/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698786496780,
        "cdate": 1698786496780,
        "tmdate": 1700690919218,
        "mdate": 1700690919218,
        "license": "CC BY 4.0",
        "version": 2
    }
]