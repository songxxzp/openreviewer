[
    {
        "id": "GDvLvjwTtC",
        "forum": "TKqMmKlmA7",
        "replyto": "TKqMmKlmA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_UjJ7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_UjJ7"
        ],
        "content": {
            "summary": {
                "value": "- The authors propose a framework referred to as Spectral Transformation (ST) to modulate the spectrum of embedding and to seek functions beyond whitening that can avoid dimensional collapse.\n- Additionally, The authors introduce a novel ST instance named IterNorm with trace loss (INTL) to prevent collapse and modulate the spectrum of embedding toward equal eigenvalues during optimization.\n- The extensive experiments on ImageNet classification and COCO object detection demonstrate the effectiveness of INTL in learning superior representations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- (+) The authors show the novel points of the proposed methods, INTL, while comparing them with previous methods such as hard and soft whitening.\n- (+) The authors show the empirical observations of IterNorm, which map all non-zero eigenvalues to approach one, with large enough iterations (T)."
            },
            "weaknesses": {
                "value": "- (-) The authors seem to have a missing baseline [1] in SSL. The baseline looks similar to INTL from the viewpoint of spectral adjusting.\n    - [1] Exploring the Gap between Collapsed & Whitened Features in SSL-ICML2022"
            },
            "questions": {
                "value": "- Could the authors compare the INTL method with the baseline [1] if possible?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4214/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698563857578,
        "cdate": 1698563857578,
        "tmdate": 1699636388625,
        "mdate": 1699636388625,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "82PviRYSda",
        "forum": "TKqMmKlmA7",
        "replyto": "TKqMmKlmA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_AFis"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_AFis"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a new self-supervised learning framework called spectral transformation (ST) to modulate the spectrum of embedding to avoid dimensional collapse. To be specific, they introduced a novel ST instance named IterNorm with trace loss (INTL). Theoretically, this paper proved that INTL can modulate the spectrum of embeddings toward equal eigenvalues and prevent dimensional collapse. Empirically, the authors showed that INTL can obtain state-of-the-art performance for SSL on real-world datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The dimensional collapse is an important problem in contrastive learning and the analysis in this paper is insightful.\n2. The theoretical analysis and empirical results cooperate well. The improvements on real-world datasets are significant, especially in transfer learning tasks."
            },
            "weaknesses": {
                "value": "1. As analyzed in this paper, both whitening methods and INTL are instances of spectral transformations. However, it seems that INTL outperforms whitening in every task. So what are the disadvantages of whitening methods? It would be better to provide more theoretical and empirical comparisons between them.\n2. The motivation behind the trace loss is a little confusing. Is it possible to provide a more detailed discussion?\n3. It seems that INTL shows superior performance in 5-nn accuracy than linear probing accuracy. Are there any intuitive explanations for that?\n4. There are some typos. For example, in p.4, \u2018Eqn. 13 can be viewed as an optimization problem over \u2026\u2019 should be replaced with \u2018Eqn.6 \u2026\u2019."
            },
            "questions": {
                "value": "see my comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4214/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698647049308,
        "cdate": 1698647049308,
        "tmdate": 1699636388526,
        "mdate": 1699636388526,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zj6T8KNTVp",
        "forum": "TKqMmKlmA7",
        "replyto": "TKqMmKlmA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_YNa9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4214/Reviewer_YNa9"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new approach, Spectral Transformation (ST), for self-supervised learning, and proposes a new training algorithm named IterNorm with trace loss (INTL). The basic idea of the paper is to balance the spectrum of the covariance matrices for the learned features which is often ill-posed. Theoretical and empirical results are provided as well for demonstrating the performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Clear writing with many experimental results."
            },
            "weaknesses": {
                "value": "To me, I do not see any obvious weakness of the proposed approach. Motivated by the whitening, the paper presents a nice and logical development of the approach. However, I do not see a very strong point neither that can make this paper stand out compared with the literature. I suggested the authors to further emphasize the key contributions: What really makes your approach better than others such as MoCo and SimCLR? How about computational speed (this seems not to be discussed in both paper and appendix)? \n\nI\u2019d like to increase my rate if the authors can convince me at this point."
            },
            "questions": {
                "value": "see my comment"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4214/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698941593871,
        "cdate": 1698941593871,
        "tmdate": 1699636388440,
        "mdate": 1699636388440,
        "license": "CC BY 4.0",
        "version": 2
    }
]