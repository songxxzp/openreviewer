[
    {
        "id": "GZCdOonYY2",
        "forum": "xWrAAsdKoX",
        "replyto": "xWrAAsdKoX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_nR3E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_nR3E"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the challenge of locating texts in a large document collection based on abstract descriptions of their content. The authors argue that current text embeddings and semantic search solutions are inadequate for this task, as they lack a well-defined notion of similarity. They propose a new model that significantly improves retrieval by utilizing a consistent and well-defined similarity based on abstract descriptions. The model is trained using positive and negative pairs sourced through prompting a LLM. The authors highlight the limitations of existing search techniques, including keyword-based retrieval, dense similarity retrieval, QA-trained dense retrieval, and query-trained dense retrieval. They emphasize the need for a specific type of similarity, referred to as description-based similarity, which captures the relation between abstract descriptions and concrete instances within documents. They demonstrate the effectiveness of their proposed model in retrieving relevant texts based on abstract descriptions and suggest that their approach can enhance knowledge discovery in various data-intensive domains, including legal, medical, and scientific research. Overall, the paper emphasizes the importance of a well-defined similarity measure for effective semantic search and presents a novel approach that leverages the strengths of LLMs to achieve a retrieval task that is not feasible using traditional text generation capabilities."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "They evaluate the effectiveness of their proposed \"Abstract-sim\" model in sentence retrieval based on abstract descriptions, comparing it with several baseline models. The evaluation includes both human and automatic evaluations. For the human evaluation, the researchers conducted a crowd-sourced evaluation of retrieval performance for 201 random descriptions, comparing their model with several strong sentence encoder models. The results of the human evaluation indicate that the \"Abstract-sim\" model outperforms the baselines significantly, with an average of close to 4 out of 5 sentences deemed relevant for the query, while the baseline models had significantly lower performance, ranging between 1.61 to 2.2 sentences. The automatic evaluation was carried out to assess the model's robustness to misleading results. The authors generated a dataset of valid and invalid descriptions, and their model demonstrated superior performance in terms of precision at various retrieval points, with the largest disparity observed at precision@1. Their modell achieved a precision@1 score of 85%, compared to 7~3% for the strongest baseline model. The paper emphasizes the potential of leveraging large language models for generating tailored training datasets, despite their limitations in direct retrieval tasks. Their results indicate that the proposed model, trained on a dataset specifically tailored to the task, performs significantly better than standard sentence-similarity models."
            },
            "weaknesses": {
                "value": "lack of comparisons with state of the art retrieval models and neural rankings. \n\nGuo, Jiafeng, et al. \"A deep look into neural ranking models for information retrieval.\" Information Processing & Management 57.6 (2020): 102067.\n\nMitra, Bhaskar, and Nick Craswell. \"Neural models for information retrieval.\" arXiv preprint arXiv:1705.01509 (2017)."
            },
            "questions": {
                "value": "I think the baselines for their algorithms are pretty simple"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698611862783,
        "cdate": 1698611862783,
        "tmdate": 1699637157127,
        "mdate": 1699637157127,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F83ZYRnoM7",
        "forum": "xWrAAsdKoX",
        "replyto": "xWrAAsdKoX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_Uira"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_Uira"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel retrieval task designed to fine sentences that exemplify the ``instance-of'' property related to a given query. To achieve this, the paper constructs a dataset using a large language model and utilizes this dataset to develop a dense retrieval model. Experimental results from a manually constructed dataset demonstrate that the proposed dense retriever outperforms baseline models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper effectively delineates the problem at hand by highlighting its distinction from existing research. This clear exposition aids readers in comprehending the subject matter. Furthermore, the employment of crowd-workers to curate a new retrieval dataset is commendable, as it promises to significantly benefit future search research."
            },
            "weaknesses": {
                "value": "The main concerns regarding this paper are:\n\n- While the paper emphasizes that the retrieval based on description-based similarity is different from the existing retrieval, the description-based similarity also belongs to the similarity between texts. Existing methods measure this text similarity through learning from query-document (sentence) pairs, while the proposed method learns from query (description)-sentence pairs. Thus, from this viewpoint, the proposed approach seems to address a specific instance of text-to-text similarity rather than introducing a fundamentally new form of similarity-based search.\n\n- The retrieval in this paper appears specialized in a specific domain and not universally applicable. It would be better to explain in detail the actual application that requires this proposed retrieval.\n\n- While the paper innovates by introducing a new dataset, the retriever itself lacks novelty. Essentially, it is the same as the existing methods that train encoders, previously used in dense retrieval, and subsequently use nearest-neighbor search techniques.\n\n- Recent dense retrieval research has seen the emergence of diverse encoders and similarity techniques, such as Colbert and PLAID. It's necessary for this paper to evaluate the efficacy of its proposed method by incorporating a variety of encoders and similarity metrics in the experiments."
            },
            "questions": {
                "value": "Q1: Generating data with GPT often leads to the issue of hallucination. How was this tackled in this study?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698815945778,
        "cdate": 1698815945778,
        "tmdate": 1699637157018,
        "mdate": 1699637157018,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Z8dzmu65nB",
        "forum": "xWrAAsdKoX",
        "replyto": "xWrAAsdKoX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_s5K1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_s5K1"
        ],
        "content": {
            "summary": {
                "value": "This paper posits that the similarity reflected in embeddings is often ill-defined and inconsistent, which can be suboptimal for various practical use cases. To address this issue, the paper adopts a novel approach. It leverages off-the-shelf large language models to generate multiple descriptions for a given document. Subsequently, it conducts sentence retrieval tasks based on these descriptions to enhance the retrieval task's ability to capture abstract semantic information. As no suitable public dataset is available for the new retrieval settings, the authors introduce a new dataset for training and evaluating their model. The results on this proposed dataset indicate that the trained model outperforms the baselines in both human evaluations and automatic assessments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper offers a fresh perspective on the traditional retrieval task, highlighting the limitations of term-based and vector-based matching approaches. It introduces a novel description-based matching approach and enumerates its advantages over these traditional methods.\n\n2. To validate the effectiveness of the proposed method, the authors construct a new dataset based on descriptions using Wiki data. They employ off-the-shelf large language models for extensive data collection and annotation, underscoring the rigor and comprehensiveness of their approach.\n\n3. The paper is exceptionally well-written, ensuring that it is easily accessible and comprehensible for readers, making it a valuable contribution to the field."
            },
            "weaknesses": {
                "value": "1. I totally agree that the term-based and vector-based retrieval frameworks are not perfect and may lead to some problem in practice. However, I wonder that is it really a new of the proposed description-based framework, because as mentioned in the paper, author just modify the dataset and change the meaning of relevance. Moreover, the model used in the paper is also vector-based method.\n\n\n2. Using large language model to generate training dataset is risky in two folds. Firstly, it may not cover all the aspects of a given document form the generated descriptions, so that it may missing some information of the document. Second, it may also contain duplicate aspects of one document so that after model training, some aspects will be strength or biased by the data.\n\n3. It may not a fair comparison between proposed method and baselines. As mentioned in Weakness 1, the meaning of relevance is changed. The proposed method train and evaluate on the same data distribution is evidently better than the model test on OOD distribution."
            },
            "questions": {
                "value": "1. It is an interesting paper that expand the view of relevance. However, the major concern is that the formulation of description-based framework is also weak and lack some theoretical support, which is the same as the vector-based one. I think how to formulate the description-based relevance is the vital problem in the next version.\n2. How to make sure abstract description is what we actually need in practical search? Some statistic study may be involved as former evidence.\n3. The comparison of proposed method and other baselines should be fairer. Furthermore, some strong dense retrieval baselines should also be involved in the experiments.\n - ANCE: Approximate nearest neighbor negative contrastive learning for dense text retrieval\n - BERM: BERM: Training the Balanced and Extractable Representation for Matching to Improve Generalization Ability of Dense Retrieval\n - TAS-B: Efficiently teaching an effective dense retriever with balanced topic aware sampling.\n - Contriever: Unsupervised dense information retrieval with contrastive learning."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698885608834,
        "cdate": 1698885608834,
        "tmdate": 1699637156908,
        "mdate": 1699637156908,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2AdR9WqGS9",
        "forum": "xWrAAsdKoX",
        "replyto": "xWrAAsdKoX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_34Co"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_34Co"
        ],
        "content": {
            "summary": {
                "value": "The authors in this paper propose a different search approach by retrieving sentences based on abstract descriptions of their content.  The authors demonstrate the shortcomings of the current methods of text embeddings and propose a metho to improve them. The authors created a dataset using LLMs to capture the notion for similarity and use the same to train an encoder whose representations are better than the state-of-the-art. Specifically, the authors used GPT-3 to generate positive and misleading descriptions for sentences from the English Wikipedia dataset. The authors utilize a pretrained sentence embedding model and fine-tune it with contrastive learning to train their model for the task of aligning sentences with their descriptions. They use two encoders \u2013 one as a sentence encoder and the other as a description encoder. Limitations of the approach were not discussed in the paper."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors propose a novel approach to generate abstracts instead of the regular search methods. \n2. The authors have used both human evaluation and automatic evaluation to evaluate the proposed model."
            },
            "weaknesses": {
                "value": "1. In the abstract, did you mean \u201cinconsistent\u201d instead of \u201cnon-consistent\u201d? In the Introduction, \"This make the\u201d --> \u201cThis makes the\u201d, \"well defined\u201d --> \u201cwell-defined\u201d. There are several such grammatical errors, and it would benefit the authors to run the text through any of the free grammar tools available. Also, the authors can recheck the camel cases of sentences and sub-headers (full stop or no full stop?).\n2. What are the different use cases of the proposed description-based search in documents? The authors can discuss some different case studies or use cases to convince readers."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699290513681,
        "cdate": 1699290513681,
        "tmdate": 1699637156778,
        "mdate": 1699637156778,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L70NimZKKO",
        "forum": "xWrAAsdKoX",
        "replyto": "xWrAAsdKoX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_SM29"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9195/Reviewer_SM29"
        ],
        "content": {
            "summary": {
                "value": "The paper defines a new task that retrieves text based on abstract descriptions. The specific kind of similarity between text and abstract description are defined and hand curated examples were used in the instructions to LLM to generate training data. The proposed method works better than other sentence/text retrievers trained with the general definition of sentence similarity on the test data designed for this task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The text and abstract description similarity is a very interesting type of similarity and would value the information retrieval field. I think the strength of the paper is to design the prompts to gather the text/description pairs that satisfy the definition."
            },
            "weaknesses": {
                "value": "The paper proposed an interesting new task. I'm confident it will be useful for some application or existing retrieval applications. However, the paper didn't explore what will benefit from this new task as much.\n\nAlso, I would think it is pretty straight forward to see that the proposed method would outperform a general purpose retrieval or sentence similarity model. Those method are not trained or finetuned using the same training data, which defines the relationship of sentence and its abstraction."
            },
            "questions": {
                "value": "Questions:\nHow is precision @k decreases when k is increasing, especially for the proposed method?\n\nSuggestions:\nI think this is a interesting task with value, but I think it is worth to explore what end task would be benefit from this new task, or how this task post challenges to existing retrieval models, if any.\n\nMinor typos:\n  - page 8. Settings. \"invalid-recall@k\" is missing the @ sign."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699510801624,
        "cdate": 1699510801624,
        "tmdate": 1699637156662,
        "mdate": 1699637156662,
        "license": "CC BY 4.0",
        "version": 2
    }
]