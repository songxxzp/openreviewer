[
    {
        "id": "2t1cMFz7Zl",
        "forum": "kIDbvowuce",
        "replyto": "kIDbvowuce",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_gra1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_gra1"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework named Federated Ephemeral Neural Networks (FENNs) to tackle the resource-constrained issues of edge devices in federated learning. The proposed framework can automatically adjust the model during training and inference according to the available computational resources on edge devices."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper focuses on a practical issue in federated learning where devices have heterogeneous computational resources. The proposed framework FENNs can adaptively adjust the local model for each device according to the available resources. The authors honestly show the experimental results that FENNs can attain better resource-adaptability in extreme cases where all devices are low-power."
            },
            "weaknesses": {
                "value": "Despite the novel framework, this paper lacks clarity and solid evidence to support the main claim that FENNs can effectively address the systematic heterogeneity in federated learning. More specifically, the following issues of this paper need to be addressed to attain the acceptance bar of an AI conference:\n\n1.\tSome important parts of the methodology are not elaborated in the main body of the paper. For example, the calculation methods of $R_t, C_t$ and RAI are not included in the paper. The details of architecture adaptation are not included. For example, how to increase or decrease the weights in FNNs is ambiguous.\n\n2.\tExperiments are insufficient. Only the RAI is included in the experimental results, while the performance of different neural network frameworks is not included, which should be an essential part of the empirical evaluation of the new method. \n\n3.\tThe limitations of the proposed method are fatal. Although the authors honestly state the limitations, the poor effectiveness and extra resource consumption significantly weaken the contribution of this paper. FENNs cannot attain better results compared to LSTM in most cases. And FENNs require extra resources on the edge device to finish the knowledge distillation, which is prohibited in resource-constrained settings. Therefore, the proposed method seems to be impractical."
            },
            "questions": {
                "value": "What are the contributions and prospects of the proposed framework given all the limitations stated in this paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Reviewer_gra1"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2829/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698178769432,
        "cdate": 1698178769432,
        "tmdate": 1699636226602,
        "mdate": 1699636226602,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Vy86I7wpJG",
        "forum": "kIDbvowuce",
        "replyto": "kIDbvowuce",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_AX8d"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_AX8d"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Federated Ephemeral Neural Networks (FENNs), a novel framework for decentralized learning that combines the flexibility of ephemeral neural networks with the privacy-preserving features of federated learning. FENNs are designed to address the challenges of resource-intensive deep neural network computing and data privacy concerns in edge computing environments. The authors propose a new metric, the Resource Adaptability Index (RAI), to evaluate the adaptability of FENNs to varying resource conditions. They also describe a multi-step process for creating a synthetic dataset that mimics real-world sensor data commonly encountered in edge devices. The paper presents experimental results that demonstrate the effectiveness of FENNs in resource-constrained environments, such as mobile devices and Internet of Things (IoT) devices. The authors conclude that FENNs have the potential to enable efficient and privacy-preserving decentralized learning in a wide range of applications, including healthcare, finance, and transportation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- A good motivation to apply ENN in FL. In FL, the datasets and environments of participants are usually heterogeneous. Adjusting the local training process and model structures of participants according to the total resource is beneficial for the fairness and convergence of the global model.\n\n- Sufficient metrics for resource measurement. The different resource metrics in RAI cover the general network\u2019s capacities to adapt to different resource constraints, which improves the capacity of FENN to allocate total resources in training accurately."
            },
            "weaknesses": {
                "value": "- Redundant and unconcise descriptions. The pseudo-algorithms of FENN use many verbal descriptions. The denotation of arguments and metrics should be expressed clearly. The process of strategy selection should be interpreted by the branch statement better.\n\n- The paper is hard to follow since there are many unclear definitions. First, the statistical principle of resource metrics in the calculation of RAI is short of quantitative discussion. Thus, the experiment result in the Table is unreliable. Second, the classification of resource environment needs to be more specific. The detailed indicators of all kinds of resources should be demonstrated. Otherwise, the practical viability in real-world environments is in doubt. Thirdly, the whole process of FL should be explicated, including the details of aggregation, privacy-preserving, and local updates.\n\n- Lack of sufficient experimental results. The aggregative indicator RAI is not convincing enough for the performance evaluation compared with related work. The weights of all kinds of resource metrics need to be quantitatively analyzed. The impact of different metrics should be evaluated and discussed in more detail.\n\n- Insufficient superiority to related works. This paper does not make any comparison with related works in the experiment section."
            },
            "questions": {
                "value": "- Please describe the aggregation and local update in more detail. It is confusing how the participant updates LM from GM in each epoch. If the LM updates via shadow model, how does the knowledge transfer in the teacher-student framework reversely? If the LM updates without a shadow model, how do the GM parameters update the LM in unaligned features and networks?\n\n- Please describe the strategy selection clearly. Basically, how can the resource threshold be calculated dynamically according to resource variation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Reviewer_AX8d"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2829/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698638861922,
        "cdate": 1698638861922,
        "tmdate": 1699636226510,
        "mdate": 1699636226510,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6Y03Flitxx",
        "forum": "kIDbvowuce",
        "replyto": "kIDbvowuce",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_JR2g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_JR2g"
        ],
        "content": {
            "summary": {
                "value": "The paper claims to introduce a new radical concept called \"Ephemeral Neural Networks\" (ENNs) and proposes to learn these networks in a federated fashion. It also claims to propose a new metric called \"Resource-Adaptability Index\" (RAI) to evaluate the suitability of neural network architecture for given resource constraints."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The proposes concept would be ideal for both centralized and federated settings and would revolutionize the field of machine learning if there is any practical feasibility of implementation."
            },
            "weaknesses": {
                "value": "1) The proposed concept is utopian to the extreme and is woefully short of any detail. How can a neural network (participant model) dynamically adapt its architecture (like adding new layers or removing neurons arbitrarily) without substantial retraining/fine-tuning effort, that too in every communication round? Just doing it effectively once (say at the beginning or end of training) would be an herculean task. Honestly, the complexity of neural architecture search is orders of magnitude more computationally expensive than training and is beyond the capabilities of most edge devices. \n\n2) Again, how will the server transfer knowledge from the participant model to the shadow model with a substantial amount of auxiliary data?\n\n3) The proposed RAI metric is also unrealistic and there is no detailed description of how it can be implemented. Simply stating that it will be a weighted combination of available memory, cpu, etc. is not enough.\n\n4) Only scant details about the so-called \"experiments\" are available in the paper."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Is this even a real paper written by human authors? Probably this is what a modern LLM/ChatGPT would generate when presented with the requirements of an ideal federated learning system."
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Reviewer_JR2g"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2829/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699081033854,
        "cdate": 1699081033854,
        "tmdate": 1699636226431,
        "mdate": 1699636226431,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TPtsEBqPcW",
        "forum": "kIDbvowuce",
        "replyto": "kIDbvowuce",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_8qfQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2829/Reviewer_8qfQ"
        ],
        "content": {
            "summary": {
                "value": "This work proposed Federated Ephemeral Neural Networks (FENNs),  a pioneering architecture that ingeniously addresses both resource-intensive computing and data privacy concerns. FENNs rely on the concept of ephemeral neural networks (ENNs), a novel paradigm where neural networks exhibit dynamic adaptability in their architecture based on available computing resources. They also introduce a novel metric for evaluating the efficacy of resource-constrained learning and/or machine learning in resource-constrained environments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The area and overall idea are interesting. \n- The proposed scheme is interesting.\n- Provide a detailed simulation study and provide a detailed benchmarking."
            },
            "weaknesses": {
                "value": "- The authors use the word \u201cprivacy-preserving\u201d in their paper title, but there is no discussion on anything about how the proposed scheme is satisfying privacy-preserving property.\n- Lack of theoretical support for the security guarantees of the proposed scheme. There are no security proofs (or any proof sketch) and privacy guarantees discussion of their proposed framework."
            },
            "questions": {
                "value": "- Could you describe how the proposed scheme satisfies the \"privacy-preserving\" nature?\n- The described algorithm (in the Appendix) should move to the main paper (because Algorithm 1 and Algorithm 2 are the main contributions of this paper)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2829/Reviewer_8qfQ"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2829/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699369866515,
        "cdate": 1699369866515,
        "tmdate": 1699636226357,
        "mdate": 1699636226357,
        "license": "CC BY 4.0",
        "version": 2
    }
]