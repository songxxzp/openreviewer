[
    {
        "id": "4qFMUN40st",
        "forum": "3cE6NKYy8x",
        "replyto": "3cE6NKYy8x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_rPbE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_rPbE"
        ],
        "content": {
            "summary": {
                "value": "This work tackles the novel fair graph anomaly detection problem. The authors present two graph datasets constructed from Reddit and Twitter. They investigate the performance-fairness trade-off in nine existing GAD and non-graph anomaly detection methods on these datasets with extensive experiments. The results are impressive and demonstrate the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper is well-written, structured and easy to follow. The authors provide sufficient implementation and experimental details in the Appendix. The authors provide a clear motivation for the problem. \n2. The graph datasets constructed from Reddit and Twitter are contribution to the field. \n3. The experiments are extensive and the results are presented in a clear and concise manner. The discussion of future directions is a plus."
            },
            "weaknesses": {
                "value": "1. The paper could benefit from a more detailed and faithful discussion of the limitations of the proposed approach. The authors only mention that the approaches they examined leverage unsupervised learning but not semi-supervised methods, which is not deemed as a \u201climitation.\u201d  \n2. Additionally, the paper could benefit from a more detailed discussion of the implications of the results for real-world applications.\n3. It would be great if you provide more details in the captions of Figure 1-3. For example, in Figure 1 and 2, \u201cincreasing $\\lambda$ leads to a decrease in EOO. \u201d Then what is its implication? You should give more intuitive information about what these plots suggest.\n4. What are the implications of the results for real-world applications of anomaly detection in social networks?\n5. The datasets proposed are indeed a plus. What is the plan for releasing the dataset? How do you ensure the long-term accessibility of the dataset to a wide range of users? \n\nMinor point: It is a nice practice to also use **bold** subtitles in the first section for better clarity. You did this for the other sections, but can also do it for the introduction."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6733/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6733/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6733/Reviewer_rPbE"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698381350556,
        "cdate": 1698381350556,
        "tmdate": 1699636774774,
        "mdate": 1699636774774,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rL2jZ6z4qA",
        "forum": "3cE6NKYy8x",
        "replyto": "3cE6NKYy8x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_jyni"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_jyni"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the fairness of unsupervised graph anomaly detection (GAD). The background is that fairness in GAD is vital yet under-explored in research, but there is a lack of real-world datasets containing graph structures, anomaly labels, and sensitive attributes for the research. To handle the issue, this paper builds two graph datasets for fair GAD. Besides, it also conducts empirical evaluation: (1) investigating the effectiveness of the nine GAD methods w.r.t accuracy and fairness, and (2) exploring the performance of some fairness methods on the GAD methods. The codes and datasets are publicly available."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The contribution of this paper is significant. It customized two real-world GAD datasets for fairness concerns. I believe the datasets would inspire future work. \n\nThis work conducted extensive experiments to analyze the datasets and GAD methods. Specifically, it presents detection effectiveness and comprehensive analysis of fairness, e.g., the analysis of accuracy-fairness trade-off.\n\nThe whole paper is generally of great readability and well-organized."
            },
            "weaknesses": {
                "value": "1. I suggest the authors use case studies to introduce more about the datasets, illustrate the practical meanings of graph anomalies on the two datasets, and show why it is important to care about fairness. \n\n2. This paper is about GAD on attributed graphs, but it only considers the fairness of unsupervised GAD methods, ignoring the semi-supervised ones. Hence, it shows limited impacts.\n\n3. The adopted GAD methods are unsuitable. First, it does not involve the recently proposed GAD methods that were proposed in 2023 [1, 2]. Hence, it is unsuitable to claim that SOTA GAD methods are exploited. Second, the adopted three GAD methods are not diverse, i.e., both DOMINAT and CONAD are reconstruction-based methods and quite similar. Please add more GAD methods with diverse working mechanisms, e.g., community-analysis methods [3-5]. It is also suggested to add non-deep learning GAD methods, e.g., Radar [6]. \n\n4. The results in Table 2 seem weird. Why does the EDITS significantly boost the detection performance of CONAD and DOMINAT while showing trivial impacts on CoLA? Specifically, the results on CONAD and DOMINAT may indicate that the sensitive attributes (political leaning, gender, and age) are closely related to the \u201canomalies\u201d. Intuitively, the performance of CoLA (Table 2) and other GAD methods, e.g., VAE and ECOD (Table III), should also be boosted since EDITS changes the characteristics of the graphs. \n\n5. Although Table 1 partly summarizes the related works, I suggest the authors add a related work section and briefly summarize the mainstream methods about fairness in GNNs.\n\n6. Please check the correctness of the reference information. For example, the paper of the GAD method CoLA was published in 2021 rather than 2022. The paper \"Contrastive Attributed Network Anomaly Detection with Data Augmentation\" has been cited twice.\n\nReferences:\n[1] Huang Y, Wang L, Zhang F, et al. Unsupervised graph outlier detection: Problem revisit, new insight, and superior method, 2023 IEEE 39th International Conference on Data Engineering (ICDE). IEEE, 2023: 2565-2578. \n[2] Duan, Jingcan, et al. \"Graph anomaly detection via multi-scale contrastive learning networks with augmented view.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 6. 2023.\n[3] Duan, Jingcan, et al. \"ARISE: Graph Anomaly Detection on Attributed Networks via Substructure Awareness.\" IEEE Transactions on Neural Networks and Learning Systems (2023).\n[4] Zhou S, Tan Q, Xu Z, et al. Subtractive aggregation for attributed network anomaly detection, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 2021: 3672-3676.\n[5] Guti\u00e9rrez-G\u00f3mez L, Bovet A, Delvenne J C. Multi-scale anomaly detection on attributed networks, Proceedings of the AAAI conference on artificial intelligence. 2020, 34(01): 678-685.\n[6] Li J, Dani H, Hu X, et al. Radar: Residual analysis for anomaly detection in attributed networks, IJCAI. 2017, 17: 2152-2158."
            },
            "questions": {
                "value": "I wonder whether the fairness concern can be eliminated by directly removing the sensitive attributes (political leaning, gender, and age) while using the remaining attributes for GAD model learning. Because the \u201canomaly\u201d on the two datasets represents whether a user is a real-news or misinformation spreader, which is purely determined by the \u201ccorrectness of the news\u2019 content\u201d. Removing the sensitive attributes may not affect detecting \u201canomaly\u201d, e.g., fake-news spreader."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698676213110,
        "cdate": 1698676213110,
        "tmdate": 1699636774634,
        "mdate": 1699636774634,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UAxzYr4Z7N",
        "forum": "3cE6NKYy8x",
        "replyto": "3cE6NKYy8x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_9VrT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_9VrT"
        ],
        "content": {
            "summary": {
                "value": "The paper presents two new datasets to foster fairness research in graph-based anomaly/outlier detection tasks. The first consists of Reddit data (approx. 10k nodes, average degree 122.5) created by connecting users who posted to the same subreddit within a 24-hour window, from a set of 110 politics-related subreddits. The second consists of Twitter data (approx. 48k nodes, average degree 9.8) created from \"follower\" relationships of a list of users who posted COVID-19 related misinformation (Verma et al., 2022). In the dataset curation, several node features were incorporated, including demographic attributes and political leaning. Labels were defined based on whether the user posted misinformation. These and other datasets lacking one of \"graph\", \"anomaly detection\" and \"fairness\" aspects are characterized. The authors formalize the FairGAD problem -- fair graph anomaly detection -- and propose performance (AUC and AUPR) and fairness metrics (SP, EOO) for evaluation. Using the new datasets, they evaluate three GAD methods (CoLA, CONAD, DOMINANT) in combination with a graph debiaser (FairWalk or EDITS) or with a fairness regularizer (FairOD, HIN or Correlation)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. Work includes a great data collection and dataset curation effort (including) data from two major social networks and may help to address the lack of datasets for studying fairness in graph anomaly detection.\n\nS2. The methodology is relatively thorough w.r.t. the choice of GAD and debiasing techniques. \n\nS3. Proper documentation of the dataset using a Datasheet (Appendix A).\n\nS4. The paper is well-written, the reading flows well and the appendices provide extensive results and details."
            },
            "weaknesses": {
                "value": "W1. Imbalanced classification with sensitive attributes could also be used for evaluating FairGAD methods by discarding labels. The paper below includes an NBA network of basketball players:\n- Enyan Dai and Suhang Wang. Say no to the discrimination: Learning fair graph neural networks with limited sensitive attribute information. In WSDM \u201921. URL https://doi.org/10.1145/3437963.3441752.\n\nW2. Defining edges in Reddit based on users who posted to the same subreddit within a time window weakens the argument that this is a real graph. This choice bears some resemblance with \"synthetic\" graphs connecting all nodes that have some common property. Moreover, it creates extremely dense subgraphs which prevented the authors from running the EDITS fairness regularizer. The relatively low performance (AUCROC ~0.61) suggests that the edges may not be encoding useful information.\n\nW3. Although demographic attributes of the users are inferred through M3, they were not considered in the experiments as alternative choices of sensitive attributes (which would seem very natural).  Note that this is part of the motivation in Section 2.\n\nW4. Some parts of the text require clarification/revision."
            },
            "questions": {
                "value": "Q1. Is there a fundamental issue preventing the use of graph datasets introduced for classification tasks which have both imbalanced labels and sensitive attributes for FairGAD, assuming the labels are not used, or only partially used?\n\nQ2. Have you considered more organic ways of defining edges in the Reddit network? For instance, users who replied to each other?\n\nQ3. Have you considered setting age, gender or race as sensitive attributes? If not, why? If so, do you have preliminary results to comment on?\n\nQ4.  Clarification questions:\n- In the intro, \"Jin et al., 2023a\" does not seem related to cybersecurity.\n- In the intro, which reference supports the use of GAD methods in loan applications?\n- By \"posted to the same subreddit\", does that include comments or only submissions? Are you referring to the \"same subreddit thread/submission\"?\n- Is the Reddit network weighted? If not, wouldn't that be important?\n- What does Y=0 indicate? Unlabeled or normal?\n- Using \"Statistical Parity Difference\" and \"Equal Opportunity Difference\" would be preferable since the current metrics (Eqs. 1-2) are \"unfairness\" metrics.\n- In Section 4.2, the authors conjecture that the limited performance may be due to reliance on graph homophily. Can you provide a metric as evidence to back up this hypothesis? Alternatively, is it possible that the edge definition in the Reddit network is not capturing useful information?\n- Review: \"However, we believe that the gain *of improvement* is not substantial\" -> in performance?\n- In \"none of the existing GAD methods fail to achieve the desired outcomes\", isn't the desired outcome low EOO and high AUC?\n- In Appendix C, it is not clear whether $A_{norm}$ refers to the symmetric normalized or the random walk graph Laplacian."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The authors stated that the collection of publicly available datasets was deemed review exempt by the IRB."
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6733/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6733/Reviewer_9VrT",
                    "ICLR.cc/2024/Conference/Submission6733/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722604814,
        "cdate": 1698722604814,
        "tmdate": 1700574458900,
        "mdate": 1700574458900,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eUbcvNFVzv",
        "forum": "3cE6NKYy8x",
        "replyto": "3cE6NKYy8x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_QKDb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6733/Reviewer_QKDb"
        ],
        "content": {
            "summary": {
                "value": "This paper presents FairGrad, two datasets with political leanings as sensitive attributes and misinformation spreaders as anomaly labels investigate the fair graph anomaly detection problem. Their performance analysis suggests a performance-fairness trade-off in nine existing anomaly detection methods on five fairness methods and identify limitations in addressing the fair graph anomaly detection problem.\n\nOverall, this is a nice paper that investigates the performance-fairness tradeoff with new benchmark datasets, existing fairness and GAD methods, and performance and fairness metrics. However, the given two datasets may not be representative enough to study the fair graph anomaly detection problem to make strong conclusions. I propose authors to extend the benchmark data collection to more diverse real world datasets, and introduce different synthetic graph families (e.g., dK random, synthetic attribute graph generation) to study more on the impact of structural and attribute bias in the given problem domain."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Important problem domain to evaluate biased and unfair anomaly detection outcomes\n* Experiment with existing fairness and GAD methods."
            },
            "weaknesses": {
                "value": "* Why not taking the distribution of nodes across sensitive classes in calculating the fairness metrics? For example, we need to be aware that predictions on the minority classes are highly represented and vise-versa.\n* Data Coverage: Twitter datasets were collected from a set of authors, who posted COVID-19 related tweets that contain misinformation. Political leaning of users is defined as the sensitive attribute. Two users relate to a directed edge if users follow. Apart from the graph characteristics, how representative the given data sample to study the fair graph anomaly detection problem since the dataset focus on specific event such as COVID-19?\n* Not sure whether calculating the structural bias from 2-hop neighborhood information is being the most optimal in this problem scenario. For example, Twitter and Reddit datasets are very different from the network structure but yet the structural bias remains comparable.\n> structural bias (Dong et al., 2022) uses the Wasserstein-1 distance (Villani, 2021) while comparing adjacency matrices based on a two-hop neighborhood between them\n* Given the definition of structural bias taken into account, it is hard to conclude that the limited performance of GAD methods due to only graph homophily or attribute bias.\n> Given that our datasets manifest a lower degree of a structural bias when compared to existing synthetic datasets, the limited performance of GAD methods may be due to their prevalent reliance on graph homophily.\n> Considering that the attribute bias of Reddit is significantly larger than that of Twitter while their structural biases are similar (see Table 1), we attribute the results of high SP and EOO on Reddit to its substantial attribute bias."
            },
            "questions": {
                "value": "* Apart from the common practices, are there any reasons not to consider graph anomaly detection problem as a (semi) supervised task?\n> It is worth noting that since GAD is regarded as an unsupervised problem in most literature (Kim et al., 2022; Ma et al., 2021), the labels should only be used in the test step, not in the training step\n* Does the sensitive attribute need to be predefined?\n> FairGAD methods aim to accurately detect anomalous nodes while avoiding discriminatory predictions against individuals from any specific sensitive group."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns",
                    "Yes, Responsible research practice (e.g., human subjects, data release)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This study presents several social media datasets with sensitive attributes."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767723847,
        "cdate": 1698767723847,
        "tmdate": 1699636774232,
        "mdate": 1699636774232,
        "license": "CC BY 4.0",
        "version": 2
    }
]