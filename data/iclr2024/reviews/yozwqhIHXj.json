[
    {
        "id": "CHCGrPrhla",
        "forum": "yozwqhIHXj",
        "replyto": "yozwqhIHXj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission759/Reviewer_EyuE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission759/Reviewer_EyuE"
        ],
        "content": {
            "summary": {
                "value": "The paper presents the Diffusion Visual Programmer (DVP), a new neuro-symbolic framework for image translation that combines a diffusion model with the GPT architecture, coordinating a sequence of visual programs for image editing tasks like RoI identification, style transfer, and positioning. DVP stands out due to its ability to use instance normalization for condition-flexible translation, focusing on textual prompts for quality content creation, and its capability to convert complex concepts in feature spaces into simpler symbolic representations, ensuring localized editing that retains image coherence. Additionally, DVP provides clear symbolic representations at every stage, enhancing user control and understanding, marking progress in aligning artificial image processes with human cognitive intelligence."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The Diffusion Visual Programmer (DVP) method, rooted in a neuro-symbolic perspective, integrates a condition-flexible diffusion model with the GPT framework, guiding a series of pre-existing computer vision models to produce the desired results. DVP's strength lies in its ability to accurately position translated objects and allow for various context-free manipulations. The advantages of this work include:\n1. Precision in Targeting: By prioritizing the identification of the Region of Interest (RoI), the system ensures accurate and relevant image translations.\n2. High-fidelity Translations: After identifying the target region, the system maintains high-quality translations into the desired domain.\n3. Spatial Awareness: DVP's capability to position translated objects based on spatial data enhances the translation's realism and context.\n4. Enhanced User Control: The system's step-by-step approach allows users to have better control over the translation process, ensuring results align closely with their intentions."
            },
            "weaknesses": {
                "value": "1. Dependency on Modules: DVP's systematic design implies that if one module falters, the entire system could be compromised. The robustness of such an interconnected system becomes a pertinent question. If one cog in the machine is faulty, can the system still deliver optimal results, or will it be critically hampered?\n2. Comparison with Other Techniques: Some results showcased by DVP can be achieved using established perception techniques like Segment Anything (SAM) or conditional control generation methods like ControlNet's point-to-point mode. A comparative discussion on the advantages of DVP over these techniques would provide clarity on DVP's unique value proposition.\n3. Textual Argument Handling: Even though DVP marries a condition-flexible diffusion model with the GPT architecture, its prowess in handling complex textual arguments requiring intricate reasoning remains questionable. The paper does not offer substantial experimental evidence to vouch for the enhanced capabilities of integrating GPT, leaving room for skepticism.\n4. Handling Complex Scenarios: DVP's recurrent challenge is its inability to adeptly manage intricate situations. As highlighted in the failure case study, the system falters in the face of occlusions, inadequate lighting conditions, and densely populated scenes. This limitation raises concerns about the system's applicability in real-world, diverse scenarios."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "There is no discussion on the bias, e.g., instructions like \"changing a man to a woman\". What is the possible bias it may cause?"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission759/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698105678911,
        "cdate": 1698105678911,
        "tmdate": 1699636003373,
        "mdate": 1699636003373,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IfVpWRCCs7",
        "forum": "yozwqhIHXj",
        "replyto": "yozwqhIHXj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission759/Reviewer_DvDX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission759/Reviewer_DvDX"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new method, named Diffusion Visual Programmer (DVP), for image translation. DVP is a neuro-symbolic framework that incorporates condition-flexible translation into an LLM planner. Specifically, the authors propose instance normalization to avoid manual guidance to achieve higher-quality content editing. The authors also prompt LLM to generate a sequence of programs with operations, which can be executed to plan the procedure, segment the object of interest, give the caption for the image, inpaint the masked image, and manipulate the sizes and positions of objects. DVP makes the process of image translation controllable and interpretable. The qualitative and quantitative results demonstrate a good performance of DVP."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper integrates the condition-flexible diffusion model into a visual programming framework to improve image translation.\n- The paper proposes an efficient instance normalization to improve the quality of image editing.\n- GPT planner provides controllability and explainability for the image translation process.\n- The generated results are good with quantitative and qualitative evaluation.\n- The paper is well-written and easy to read."
            },
            "weaknesses": {
                "value": "- It seems the conditional-flexible diffusion model is the prompt-to-prompt method with proposed instance normalization. However, the authors only compare the results of using instance normalization and different guidance scales. It is also important to ablate the instance normalization in DVP to demonstrate instance normalization significantly outperforms a fixed scale when incorporating in-context visual programming.\n- The proposed method is an aggregation of different models planned by an LLM. However, how the components (e.g., mask2former, Repaint, BLIP, position manipulator) are aggregated is not clearly clarified. The authors may explain various translation procedures by providing more step-wise illustrations like Fig. 7. Besides, the authors may provide the prompt they use for the GPT planner.\n- Some important details are missing. For example, how the conv layer in instance normalization is parameterized? Is there any other difference between the conditional-flexible diffusion model and the prompt-to-prompt model, except for instance normalization? How to decide the order of operation sequences, automatically by GPT or manually by humans?"
            },
            "questions": {
                "value": "- The authors use a conv layer in instance normalization (Eq. 5). But there is no evidence of how the conv layer is trained or parameterized. Can authors give more details?\n- In Figure 7, We can see different plans derive different translated results. How do authors obtain different orders of operation sequences? How do authors decide which plan is the best for the final result?\n- In Fig. 8, are reconstructed results with automatic labels and human labels generated by null-text inversion? To my knowledge, null-text inversion produces quite similar reconstructed images to the original ones regardless of the input prompt. Can authors explain why using GPT-generated prompts derive better reconstructed results than human annotations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission759/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698400843969,
        "cdate": 1698400843969,
        "tmdate": 1699636003292,
        "mdate": 1699636003292,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "orOdJDGPTX",
        "forum": "yozwqhIHXj",
        "replyto": "yozwqhIHXj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission759/Reviewer_TXue"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission759/Reviewer_TXue"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce the Diffusion Visual Programmer (DVP), a neuro-symbolic image translation framework that seamlessly combines a diffusion model with the GPT architecture. DVP enables transparent and controllable image translation processes, covering tasks like RoI identification, style transfer, and position manipulation. Extensive experiments showcase DVP's remarkable performance, surpassing existing methods. The success of DVP can be attributed to its condition-flexible translation, in-context reasoning, and systemic controllability. This research represents a significant advancement in harmonizing image translation with cognitive intelligence, with promising applications in various domains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. **Innovative Framework**: DVP introduces a novel neuro-symbolic image translation framework, seamlessly combining a diffusion model with the GPT architecture for various image processing tasks.\n\n2. **Remarkable Performance**: DVP outperforms existing methods, demonstrating high-quality image translation through extensive experiments.\n\n3. **Condition-Flexible Translation**: DVP achieves condition-flexible translation via instance normalization, enhancing content generation while reducing manual guidance sensitivity."
            },
            "weaknesses": {
                "value": "1. **Novelty**: The paper should address concerns about its novelty, as it resembles existing visual programming pipelines with the primary distinction being the choice of image editing tools. Clarification on how DVP significantly sets itself apart from previous work is crucial.\n\n2. **Lack of Comparative Analysis**: The paper's strength in performance could be further substantiated by a more thorough comparative analysis. A comparison with alternative approaches like instructive tuning-based diffusion models, such as instruct2pix, would provide a clearer perspective on its relative merits.\n\n3. **Limited Experimentation on Instance Normalization**: The paper introduces instance normalization as a valuable element of the DVP framework, which can have broader applications. However, there is a need for more extensive experimentation to validate the advantages of instance normalization in the context of general diffusion-based image generation."
            },
            "questions": {
                "value": "While the paper showcases DVP's impressive performance, there is a need for further exploration of its adaptability to a range of image translation tasks. These tasks might include object replacement, color/texture/material editing, and style transfer. Currently, the paper's experiments encompass a holistic approach without distinct analysis of how DVP caters to varying task requirements.\n\nAdditionally, the paper's reliance on a relatively small self-collected dataset comprising 100 image-text pairs may present limitations in terms of the breadth and diversity of data for evaluation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission759/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698486003321,
        "cdate": 1698486003321,
        "tmdate": 1699636003215,
        "mdate": 1699636003215,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6QokFmdT9c",
        "forum": "yozwqhIHXj",
        "replyto": "yozwqhIHXj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission759/Reviewer_fWRk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission759/Reviewer_fWRk"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a new framework called Diffusion Visual Programmer (DVP) for image translation tasks. It follows the diagram that first identifies the instructed target region and then translates it into the targeted domain. In particular, the authors use instance normalization for context-flexible translation, avoiding adjusting guidance manually. Besides, the authors decouple the concepts in feature space into simple symbols and then deal with the symbols with visual programming. Qualitative and qualitative results show that DVP outperforms other state-of-the-art methods, providing more reliable, controllable, and interpretable image translation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Overall, the paper is well-organized and easy to follow. The figures and tables are informative.\n\n- The performance of the proposed method is promising. Figures 4, 6 clearly demonstrate the superiority of DVP.\n\n- The ablation study and system analysis are clear and informative, making it easy to see the effectiveness of different parts, such as instance normalization, and prompter."
            },
            "weaknesses": {
                "value": "- The proposed method is a systematic approach for image translation tasks incorporating different components. A potential drawback is its inference speed. It would be beneficial if the authors could compare inference speed with other image translation tasks.\n- The comparison with methods like SDEdit, Prompt2Prompt, and InstructPix2Pix is somehow unfair since they do not require an additional segmentation network.\n- The quantitative evaluation is only the proposed dataset, which contains fine-grained edit instructions. The effectiveness of DVP could be further proved by evaluating simple or even ambiguous instructions."
            },
            "questions": {
                "value": "- I have questions about the learning process of the 1\u00d71 conv layer in equation (5). How is it exactly trained? And is it sensitive to the training sample size?\n- Will instance normalization also work in text-to-image tasks? It will be interesting to see if it could generate higher fidelity images with semantic meaning more aligned with the provided text prompts."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission759/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission759/Reviewer_fWRk",
                    "ICLR.cc/2024/Conference/Submission759/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission759/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698808366018,
        "cdate": 1698808366018,
        "tmdate": 1700570787749,
        "mdate": 1700570787749,
        "license": "CC BY 4.0",
        "version": 2
    }
]