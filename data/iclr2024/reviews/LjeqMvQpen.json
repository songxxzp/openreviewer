[
    {
        "id": "Vh0r2LAvbD",
        "forum": "LjeqMvQpen",
        "replyto": "LjeqMvQpen",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_hByk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_hByk"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for fusing multiple independently trained transformer architectures using optimal transport to align their respective architectural components. To this end, authors analyse predominant Transformer architectures based on their components, and provide OTFusion methods for each. The proposed approach allows for fusing transformers of different sizes. \nExperiments are conducted on a range of image classification datasets; CIFAR10, CIFAR100, TinyImagenet and ImageNet-1k. Authors show results for models obtained through both zero-shot (without fine tuning) and with fine tuning. In zero-shot fusion, the proposed approach outperforms Vanilla Fusion methods. With fine tuning, the proposed approach is able to beat either parent model. Authors conclude with a number of limitations of their approach and suggestions for future research."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper is very well-written, authors give clear and concise descriptions of their approach and illustrate its complex aspects through figures and examples. This makes the manuscript easy to read and the ideas it expands upon easy to understand despite their complexity. The method seems to work well, drastically outperforming Vanilla Fusion (naive model averaging). The authors show a range of valuable ablations, and motivate most of their design choices well."
            },
            "weaknesses": {
                "value": "My main concern is to do with the clarity of the contribution of this work. The authors refer to [1] a lot in their paper, where the concept of OTFusion is introduced. It seems like a lot of the techniques used in this work were actually introduced there. Although I understand the need for reintroducing these concepts in the manuscript for contextual clarity, I think it would be good to give a clearer picture of the actual contributions made in this work and the methods proposed in previous works. From the description under 4.3 it seems [1] uses hard alignment where you find soft alignments to outperform. Are these contributions of your work? What about the TM combination approaches (Averaging/Weighted Scalar/ Weighted Matrix)? Or heterogeneous fusion?\n\nI hope the authors are able to address this in their rebuttal, in which case I see this work as an interesting and strong submission.\n\n[1] Sidak Pal Singh and Martin Jaggi. Model fusion via optimal transport. Advances in Neural Information\nProcessing Systems, 33:22045\u201322055, 2020."
            },
            "questions": {
                "value": "-What do you mean by \u201cThis diversity offers a challenging fusion problem requiring a non-trivial alignment strategy, and thus effectively recreates a plethora of other scenarios\u201d (under 5 - Model Training). Can you explain e.g. how varying random seed equates to model training on different subsets?\n-How does your work relate to [2]? You indicate that [2] is very similar to OTFusion, but looking at zero-shot performance of your method (and your VF baseline) on CIFAR10 classification it seems performance is drastically different (~93% vs ~60%). If essentially identical, why does [2] yield zero-barrier LMC where your approach does not?\n-Could you give an intuition for soft-alignment, what resulting network is actually being constructed  in this case and why could it be beneficial compared to hard alignment approaches?\n-Do you have an intuition for why your method performs better with soft-alignment, where [1] shows better results with hard alignment?\n\n[2] Samuel K Ainsworth, Jonathan Hayase, and Siddhartha Srinivasa. Git re-basin: Merging models\nmodulo permutation symmetries. arXiv preprint arXiv:2209.04836, 2022.\n\n---\n\nUpdate after rebuttal: I thank the authors for their thorough rebuttal. I'm pleased to say my concerns are adequately addressed. Also considering the largely positive reviews by the other reviewers, I'd like to update my recommendation to an accept."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Reviewer_hByk"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4949/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698774850423,
        "cdate": 1698774850423,
        "tmdate": 1700923426225,
        "mdate": 1700923426225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JbEmqNhn18",
        "forum": "LjeqMvQpen",
        "replyto": "LjeqMvQpen",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_KSPk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_KSPk"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a systematic fusion technique for transformer-based networks by leveraging Optimal Transport to align architectural components. It offers a flexible approach applicable to various architectures, including key Transformer components. Heterogeneous fusion enables efficient compression, with superior performance compared to vanilla fusion and individual parent models, as demonstrated in image classification (Vision Transformer) and natural language tasks (BERT). Our analysis underscores the significance of soft alignment in the context of Transformers, highlighting the potential for combining multiple Transformers to enhance their capabilities in the emerging field of model fusion and recombination."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors examined various strategies (weight vs activation, hard vs soft etc) for applying optimal transport (OT) methods\n2. The authors conducted experiments employing both Vision Transformer (ViT) and BERT architectures across multiple datasets.\n3. The OT method demonstrates particular efficacy in one-shot scenarios.\n4. OT methods exhibit versatility, as they can be effectively applied to models of varying widths, presenting a viable alternative to distillation."
            },
            "weaknesses": {
                "value": "1. The OT method yields comparatively lower performance when contrasted with ensemble methods.\n2. The suitability of the OT method for achieving solid results on larger datasets, such as ImageNet-1K, in one-shot scenarios remains uncertain."
            },
            "questions": {
                "value": "Please refer to the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4949/Reviewer_KSPk"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4949/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811300859,
        "cdate": 1698811300859,
        "tmdate": 1699636481508,
        "mdate": 1699636481508,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9tniV8L56p",
        "forum": "LjeqMvQpen",
        "replyto": "LjeqMvQpen",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_5GYY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_5GYY"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a systematic approach for fusing two or more pretrained transformers by studying the flow of transportation maps in each specific component of Transformer. The authors empirically showed that when working with Transformers, hard alignment underperforms soft alignment in one-shot fusion, which is in contrast to the cases of fully connected and convolutional neural networks. Finally, they showcased the efficiency of the proposal in fusing and finetuning ViT and BERT."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper is well-structured.\n- To the best of my knowledge, this is the first work that aims to fuse transformer architectures by aligning their weights.\n- The proposed method is successfully backed by theoretical results."
            },
            "weaknesses": {
                "value": "- The methodology part is not well-written and lacks some details."
            },
            "questions": {
                "value": "- Section 2: The model fusion literature has some papers that are slightly off: Tatro et al., 2020; Juneja et al., 2022; Kandpal et al., 2023.\n- Eq. 2: What is $f$? What is its output?\n- Section 4.2.1: How to calculate weighted matrix?\n- The authors should remind the formulation for Attention operation in either Section 3 or Section 4.2.2.\n- Section 4.2.2:\n  - Where do the authors remove the constraints in Section 4.2.2?\n  - It is unclear how to calculate $T_Q$ and $T_K$. Did the authors check the assumption $T_Q = T_K$ in the experiments?\n  - What are $W_i^Q, W_i^K$, and $W_i^V$? Does $i$ indicate the head index?\n  - Additional visualizations may help to demonstrate the method here.\n- Section 4.2.3: What is this sentence for? \u201cFor the concatenation, we notice that the class token is only a small fraction of the full sequence, in other words, for the integrity of the sequence, it is far more important to propagate the TM of the patch embeddings than the one for the class token.\u201d In addition, the class token is more important because it gathers the information from the patch.\n\n\n**Minors**: \n- Eq. 3 should be moved up a paragraph."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4949/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818893650,
        "cdate": 1698818893650,
        "tmdate": 1699636481407,
        "mdate": 1699636481407,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vLVevtPSbU",
        "forum": "LjeqMvQpen",
        "replyto": "LjeqMvQpen",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_GM8g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4949/Reviewer_GM8g"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport technique. The proposed method can generalize to arbitrary architectures for CNNs and Transformers. Extensive experiments involving the fusion and finetuning of Vision Transformers (ViTs) across multiple datasets demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper is well written.\n- The proposed method shows good generalization across different architectures.\n- The proposed method show strong performance for several benchmark."
            },
            "weaknesses": {
                "value": "- Most experiments are conducted to compare with Vanilla Fusion. More comparisons with state-of-the-art methods should be included.\n- Most experiments are conducted on CIFAR dataset which is relatively small."
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4949/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698842398605,
        "cdate": 1698842398605,
        "tmdate": 1699636481303,
        "mdate": 1699636481303,
        "license": "CC BY 4.0",
        "version": 2
    }
]