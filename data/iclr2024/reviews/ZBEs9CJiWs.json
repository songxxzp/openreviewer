[
    {
        "id": "mYDiGvCjC5",
        "forum": "ZBEs9CJiWs",
        "replyto": "ZBEs9CJiWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_hVxs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_hVxs"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to improve inter-personal communication (general communication to achieve goals) by means of the proposed Explore-Generate-Simulate framework leveraging LLMs.\nThe framework 1) generates diverse pieces of advice that apply to a given scenario; 2) generates candidate responses based on each piece of advice; and 3) simulates how candidates will be received by possible audiences.\nThe authors compare their framework against other strategies like chain-of-thought across eight scenarios ranging from PR, marketing statements, and interpersonal domestic conflict."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The framework steps are intuitive and well grounded / explained. This can be seen as an interesting application of multi-agent conversations for LLMs grounded in theory about goal-oriented conversation. The paper could benefit from better defining e.g. advice and breaking down what constitutes good advice or any possible distinctions between how LLMs seem to generate responses conditioned on advice vs. how humans may take the advice. But overall the framework seems to make sense and is well explained.\n\n2. The human study has good N (652) and evaluation of inter-rater reliability, which gives us confidence in the results. The experimental procedure could be better summarized in the main paper body - the detail in A.4 is in stark contrast to the brief explanation on page 6 of the paper itself.\n\n3. The results in comparing EGS against zero-shot prompting and the version of Chain of Thought used here are encouraging, on both the human evaluation and simulated SHP evaluation."
            },
            "weaknesses": {
                "value": "1. My main concern here is that LLMs are highly sensitive to prompt engineering, wording, and order. This paper would benefit from a deeper discussion of how the prompts were developed (human-written, LLM-aided, etc.), any success or antipatterns noticed, and stability of results WRT prompts. As it stands the results are positive but \n\n2. One specific concern is the quality of LLM reasoning over numeric values (e.g. in A.3 prompts weighting different stakeholders by asking the LLM to infer numeric ratings/weight for each stakeholder wrt the goal). When asking for multiple quantities in a prompt, it's unclear how effective each particular portion is, and the paper would benefit from an ablation or breakdown of generation quality in each stage.\n\n3. The pilot study results (e.g. for number of pieces of advice) should be delineated in the main paper body to more strongly justify the design choices. Similarly, choices like \"generat[ing] three candidates...to overcome any noise in generation\" seems like empirical design and should at least be explained further. The framing of \"You remember a piece of advice...\" can also be better justified.\n\n4. The demos are interesting but do bring up a concern about hallucinating information: for 4.2 for example, the friend names are hallucinated and things like the particular events (pool, break-up) also seem to be hallucinated. While this may seem like incidental information it's important to see an analysis of what hallucinations are typically generated under this framework for the LLM(s) chosen and whether they are material to the goal/conversation."
            },
            "questions": {
                "value": "See weaknesses - I would like to see some discussion of those points."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697990664226,
        "cdate": 1697990664226,
        "tmdate": 1699637088603,
        "mdate": 1699637088603,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0IkFL9m1vc",
        "forum": "ZBEs9CJiWs",
        "replyto": "ZBEs9CJiWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_Dz3q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_Dz3q"
        ],
        "content": {
            "summary": {
                "value": "Human interpersonal communication can be difficult due to limited experience and time to make careful decisions. This paper studies the potential of using a language model to help humans communicate better. The paper proposes a EGS framework with exploration, generation, and simulation. The language model first explores by providing advice, including unorthodox advice. Next, the language model generates candidate messages that the human agent can use. Finally, the language model is used to simulate human behavior by evaluating the candidate messages. When simulating human behavior, an audience called stakeholders are generated, along with their importance weights. Finally, the stakeholders can evaluate the candidate messages and this can be used to derive an aggregate based on their answers and weights. The paper further proposes 8 scenarios that cover the ten fundamental processes of social interaction, such as social influence, social support, privacy management, and uncertainty management. By comparing with GPT-4 zero-shot and Chain of Thought, and by using human judgements as evaluation, the proposed EGS framework performed the best on 5 out of 8 scenarios. Finally, the paper discuss how the simulate step is well aligned with real-world web users, by using the Stanford Human Preferences dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Enhancing interpersonal communication may become one of the popular applications of language models, and it seems to be a potentially important research direction.\n- The 8 scenarios cover diverse situations, and the paper discuss how they span the 10 fundamental processes of interpersonal communication.\n- The proposed EGS framework is relatively simple and easy to understand.\n- The paper introduces some unique ideas such as simulating stakeholders.\n- The code and data is provided in the supplementary link."
            },
            "weaknesses": {
                "value": "- It would have been better to have some discussions about some of the recent advances in prompt engineering (post CoT), perhaps in Section 2. When I first read the manuscript, it wasn't clear to me why only the zero-shot and chain-of-thought baselines were used. My current understanding about the reason for not including other baselines is that other prompting methods such as Wang et al. (ICLR 2023) that also try to sample many candidates and then choose the best one does not work with the interpersonal communication tasks due to the lack of a fixed answer. Similar methods for open-ended generations (such as Jain et al. 2023) seem to also rely on the assumption that there is an underlying fixed answer and tries to look for semantically closer ones. The contributions of the paper will become more significant if we have this kind of discussion. I think it will also strengthen the motivation to study/focus on the interpersonal communication application, rather than focusing on general prompting methods.\n- The stakeholder idea is interesting. It demonstrates how focusing on the interpersonal communication task is meaningful. However, it makes me wonder if it is meaningful to consider stakeholders for the scenarios after the first two. For the first two (plane crash, product launch), it seems to be a nice idea to have stakeholders. Figure 1 shows an example of generated stakeholders (sales, customer, media), but it would be better to have the generated stakeholders and their generated weights for all scenarios, perhaps in the appendix.\n- Other variations of the EGS formulation: I wonder if we can improve the framework by simulating the stakeholders before the generate step. If we condition on each stakeholder and then generate candidates, will it generate better candidates compared to the case without conditioning on the stakeholders?\n- Related to the \"white lie\" scenario, I feel the \"negative use\" paragraph in Section 7 can be discussed in more detail. For example, the language model can generate messages that may include more serious lies that superficially improve the communication but with more societal/ethical harm.\n\nWang et al. (ICLR 2023): Self-consistency improves chain of thought reasoning in language models\n\nJain et al. (2023): Self-consistency for open-ended generations"
            },
            "questions": {
                "value": "Minor comments and questions:\n- Park et al. (2023a) and Park et al. (2023b) seem to be the same paper.\n- Ref error in Section A.4: (Appendix ??)\n- It would be helpful to have a table with 10 fundamental processes on the columns and 8 scenarios on the rows, and where each cells indicate if the scenario includes the fundamental process or not with a check mark.\n- Is it more precise if we say \"zero-shot Chain of Thought\" instead of \"Chain of Thought\"? The prompt example shown in Table 5 seems like it is the zero-shot version of CoT."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698726621233,
        "cdate": 1698726621233,
        "tmdate": 1699637088471,
        "mdate": 1699637088471,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HRtL9nJqYy",
        "forum": "ZBEs9CJiWs",
        "replyto": "ZBEs9CJiWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_GN7N"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_GN7N"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new framework for communicative message generation under different scenarios. It adopts a three-step pipeline: explore (explore key advice for each scenario) \u2192 generate (generate initial messages based on different advice combinations) \u2192 simulate (simulate audiences with different perspectives to select the final best message). The authors evaluate this framework in eight scenarios. They collect human selections of candidates and ratings over messages generated by EGS and other baselines. The experimental results show that EGS agrees with human selection and gets ratings higher than other baselines. This framework is further applied to a real Internet user simulation, which validates its generality to real-world scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Leveraging multiple LLMs to serve different roles to complete a given task is a promising research direction. \n2. The authors validate this framework through a comprehensive design of experiments, which encompasses comparisons with human selection, various baseline models, and practical applications in real-world scenarios.\n3. The EGS framework prompts LLMs to generate advice and audiences corresponding to the current task, which enables it to be easily generalized to different scenarios."
            },
            "weaknesses": {
                "value": "1. Scenario design: it is not clear to me how these eight scenarios are chosen based on the 10 fundamental processes of interpersonal communication, and why it is representative of all possible social tasks. \n2. The initial generation results bottleneck the final generation. As the example shown in Section 4.3, both candidates may demonstrate some advantages. It would be interesting if it could aggregate the valid points in both candidates and then decide the final generation."
            },
            "questions": {
                "value": "1. In step 2, when saying \u201citerates over subsets of advice\u201d, how these subsets are formed?\n2. How the prompts are designed for the CoT baseline? \n3. Experimental results demonstration: \n\n    a. For Table 2, the authors choose \u201c>0.6\u201d as a high agreement. However, it would be better if a baseline is included to clarify how a \u201chigh agreement\u201d is decided. \n\n    b. Similarly in Table 3, it would be better to mark the significance between comparisons. \n\n    c. In Table 5, what do the results represent? I think it is the accuracy of selecting the correct upvote, but it is not stated in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8685/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8685/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8685/Reviewer_GN7N"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699208699069,
        "cdate": 1699208699069,
        "tmdate": 1699637088366,
        "mdate": 1699637088366,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zuU20xKcct",
        "forum": "ZBEs9CJiWs",
        "replyto": "ZBEs9CJiWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_V2zC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8685/Reviewer_V2zC"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the idea of incorporating LLM to communicate better in various scenarios when the user has a specific goal in mind and wants to communicate by employing a strategy (advice) such that the predefined goal would be achieved. Authors show that LLMs are used in generating different advices or strategies, subsequently different outputs and they are capable of simulating the outcome of each generation from the perspective of various audiences."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of incorporating LLMs to communicate better and use them not only for generation but also for simulating the outcome of each generation on different audiences seems promising, as the nature of communications sometimes can be very complicated and indeed finding the best strategy would be much more challenging. With the good performance of LLMs in many domains authors claim that they can be reliable for easing the communications. This paper tries to address such kind of problem by merely focusing on the ability of LLMs."
            },
            "weaknesses": {
                "value": "Even though the idea seems to be promising my main concern is regarding the shortage of evidence in proving and showing the framework's performance. The approach is tested on a limited set of scenarios which does not provide a strong proof of the model's performance in different domains (and its generalizability). One possible benchmark could be the negotiation conversations to check what percentage of the time the proposed approach will be able to win the negotiation. However in section 6 the stimulate step is assessed on SHP dataset, it would be nice to have more fine-grained study on the type of the domain/user preferences and personalities and their connection with the framework's performance."
            },
            "questions": {
                "value": "How much the proposed framework for improving the interpersonal communication is affected by the underlying LLM's social norms. Since the proposed method relies on off-the-shelf LLMs, it is important to investigate the outcome of their generations in different cultures or on people with different personalities. In other word, relying directly on LLMs that have been trained on data with specific social norms in the background should have different outcomes which urges a comprehensive study in various cultures/domains.\n\nIn table 2, how do we assure that the outcome of EGS is significantly better than the other baselines? have you done any significance testing?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699585658354,
        "cdate": 1699585658354,
        "tmdate": 1699637088255,
        "mdate": 1699637088255,
        "license": "CC BY 4.0",
        "version": 2
    }
]