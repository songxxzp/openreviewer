[
    {
        "id": "5YXcmXJ6fT",
        "forum": "ONhwvkaIe6",
        "replyto": "ONhwvkaIe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_4BDw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_4BDw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework to evaluate the hypernymy understanding of text-to-image models using the WordNet hierarchy and ImageNet classifiers. The paper introduces two metrics, In-Subtree Probability (ISP) and Subtree Coverage Score (SCS), that measure the generation precision and coverage of the WordNet tree. The paper also compares several popular text-to-image models, such as GLIDE, Latent Diffusion, and Stable Diffusion, using the proposed metrics and analyzes their language understanding capabilities and limitations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper introduces a novel framework for evaluating text-to-image models using the WordNet hierarchy and ImageNet classifiers, which is a unique approach in the field. The work is of high quality, with rigorous methodology and comprehensive evaluation of several popular models. The research is significant as it provides valuable insights into the language understanding capabilities of text-to-image models, which can guide future research in this area."
            },
            "weaknesses": {
                "value": "The paper could include more diverse models for comparison to provide a more comprehensive evaluation. Meanwhile, the proposed metrics (ISP and SCS) are innovative, but their interpretation and implications could be explained more clearly."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8163/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698138663663,
        "cdate": 1698138663663,
        "tmdate": 1699637011323,
        "mdate": 1699637011323,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VhNFg2E4pv",
        "forum": "ONhwvkaIe6",
        "replyto": "ONhwvkaIe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_pgJu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_pgJu"
        ],
        "content": {
            "summary": {
                "value": "This paper presents metrics, In-Subtree Probability (ISP) and Subtree Coverage Score (SCS), based on WordNet and ImageNet, for evaluating the hypernymy comprehension capabilities of popular text-to-image models. The proposed method also can be used to provide insights into text-to-image models' limitations for downstream applications. The authors evaluate publicly available models and analyze the hypernymy understanding of existing text-to-image models, validating the effectiveness of their proposed method in this work."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This study investigates the problem of assessing the hypernymy understanding of text-to-image models. The authors propose an effective approach that combines the hypernymy knowledge from WordNet with the classification capabilities of established image classifiers. This integration demonstrates a successful application in evaluating the hypernymy understanding of the models.\n\n2. The paper was, in general, easy to follow. In particular, I feel condent that, based on the description, I can reimplement the model and reproduce the results. \n\n3. The proposed evaluation framework and its motivation are reasonable (but see the weakness)."
            },
            "weaknesses": {
                "value": "1. The efficacy of the proposed method presented in this study is heavily dependent on the performance of the image classifier. Both the In-Subtree Probability (ISP) and Subtree Coverage Score (SCS) metrics rely on the probabilities generated by the classifier. To achieve reliable results, it is crucial to obtain a highly accurate classifier capable of effectively covering a wide range of real-world object classes. The metrics' effectiveness is contingent on the classifier's performance, meaning that if the classifier demonstrates low prediction accuracy, the reliability of the ISP and SCS metrics may be compromised.\n\n2. Pretrained generic large language models (e.g., T5, Llama2), trained on text-only corpora, demonstrate proficiency in text encoding for image synthesis. These models inherently possess semantic understanding and effectively acquire knowledge of hypernymy. More experiments of applying the proposed metrics into text-to-image models equipped with LLMs need to be conducted."
            },
            "questions": {
                "value": "1. Please consider extending the experiments with more LLMs-equiped text-to-image models, e.g. Imagen (Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding) (but not limited to.)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8163/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698677476781,
        "cdate": 1698677476781,
        "tmdate": 1699637011195,
        "mdate": 1699637011195,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CxpRcjxrf6",
        "forum": "ONhwvkaIe6",
        "replyto": "ONhwvkaIe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_npm8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8163/Reviewer_npm8"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework to evaluate the hypernymy understanding abilities of text-to-image models, including two distinct and complementary metrics. The evaluation process is fully automated. The authors also show some merits of the evaluation framework such as finding unknown concepts and conducting granular comparison of models. Overall, this paper presents a focused analysis on a specific aspect of text-to-image generation (i.e., hypernymy understanding)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This experiments presented in this paper are comprehensive and elaborate.\n- The evaluation metrics are automated and could be useful for future research."
            },
            "weaknesses": {
                "value": "- This paper focuses on a very specific aspect of text-to-image generation.\n- The proposed evaluation framework relies on a well-trained image classifier. It performance depends on the accuracy and coverage of the image classifier. Particularly, its usefulness may be limited by the coverage of existing image classifiers.\n- The results of some experiments  (e.g., the influence of the classifier-free guidance scale, the number of diffusion steps, and the number of generated samples) seem to be self-evident and provide little new insights."
            },
            "questions": {
                "value": "- For Subtree Coverage Score, why not use simpler formula such as the entropy of the average distribution.\n- Do you anticipate any more applications of the proposed evaluation framework?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8163/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8163/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8163/Reviewer_npm8"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8163/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698922645524,
        "cdate": 1698922645524,
        "tmdate": 1700623601567,
        "mdate": 1700623601567,
        "license": "CC BY 4.0",
        "version": 2
    }
]