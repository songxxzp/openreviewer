[
    {
        "id": "aWzZaLbNIT",
        "forum": "viNQSOadLg",
        "replyto": "viNQSOadLg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_Arqn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_Arqn"
        ],
        "content": {
            "summary": {
                "value": "This submission isn concerned with the application of GFNs to sequence modifications. I\u2019m not up to date with the relatively large number of works on similar approaches. The related work section appears in the supplementary material and does not attempt to discuss the differences between this paper and the papers listed there. This is a key issue that most be resolved. Also there is no comparison with earlier GFN methods: is there any for these problems? These concerns have made me give a lower score than what I otherwise would have given. I have minor comments and questions below, but I really enjoined reading this submission. It provides a description of the method at hand as well as the general GFN approach on very well chosen level. It is mostly well written. Moreover, the approach make sense and the results are good. I would like to accept it, but the above issue should be resolved."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Well written, technically strong, good resuls."
            },
            "weaknesses": {
                "value": "Poorly described relation to previous research and unclear if compared with the right methods."
            },
            "questions": {
                "value": "* that can provide consistency condition, Bengio et al. (2021) formulates ow- matching loss function as follows: LFM(s; \u03b8) = log P\u2200s\u2032:s\u2032\u2192s F\u03b8(s\u2032 \u2192 s) P\u2032\u2032\u2032\u2032 F\u03b8(s \u2192 s\u2032\u2032) . (4) Moreover, as an alternative objective function \u2028Page 3 \u2028Sure but which do you use? \u2028\n* 2 \u00a0R(x)\u2028Page 3 \u2028Not defined here. \u2028\n* GFlowNet\u2019s ow function F\u03b8(\u00b7) to identify sub-optimal positions of x, and subsequently replace the sub-optimal parts with newly sampled edits based on the stochastic policy \u03c0(\u00b7). pretrained ow function F\u03b8(\u00b7) Page 4 \u2028At this point its implementation is not clear or why it can be pre trained \u2028\n* For instance for the DNA sequence x = \u2018ATGTCCGC\u2019, appending token a = \u2018C\u2019 to x:2, we get x:2 + a = \u2018ATC\u2019. \u2028Page 4 \u2028I would guess that this is an insert operation on x, but it is not clear from the description, which actually suggests that the suffix from position t+1 is removed from x.\u2028New guess: you are stepwise building a sequence and you either use the character from the given sequence or another. You should make this more clear. \u2028\n* 5 \u00a0can\u2028Page 4 \u2028Would \u2028\n* 6 \u00a0Pa\u2032\u2208A Page 4 \u2028It should be made clear that the given character x_t always belongs to the available actions. \u2028\n* 7 \u00a0chosen by the algorithm Page 4 \u2028Point out how or, alternatively, where you describe it. \u2028\n* 8 \u00a0regularization parameter \u03bb allows tuning Page 5 \u2028Point out how it is set or where you describe it. \u2028\n* 9 \u00a0RF,T represents the reward of a sequence with length T generated using the ow function F\u03b8(\u00b7) \u2028Page 5 \u2028It IS the reward. Formulate it as a rv with the distribution induced by the flow function, with reference to the correct equation. \u2028\n* 10 \u00a0Levenshtein  Page 6 \u2028Spelling. \n\n* Higher binding activity is preferable Page 6 \u2028In what sense? It may not be so in a biological system. \u2028\n* 12 \u00a0diversity Page 7 \u2028You need a better measure that also takes the improvement into account. \u2028\n* 13 \u00a014.34 Page 7 \u2028This should be in bold, right?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Reviewer_Arqn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7903/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698491082389,
        "cdate": 1698491082389,
        "tmdate": 1700667814695,
        "mdate": 1700667814695,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GmAJ4Hec1C",
        "forum": "viNQSOadLg",
        "replyto": "viNQSOadLg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_aGg2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_aGg2"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an innovative algorithm called GFNSeqEditor, which is specifically crafted to enhance sequences by optimizing their desired properties. GFNSeqEditor harnesses the power of pretrained flow functions and devises a set of destructive operations, whether tokens are modified or not. It then reconstructs the altered tokens using these pretrained flow functions. The process of destruction and subsequent reconstruction is governed by three crucial hyperparameters: $\\lambda$, $\\alpha$, and $\\delta$. These hyperparameters play a pivotal role in achieving a balance between exploration and exploitation, while also managing the trade-offs and risks associated with expected improvements.\n\nThe authors provide a comprehensive analysis of these proposed hyperparameters, which intuitively guide the algorithm's behavior. To evaluate its effectiveness, GFNSeqEditor is benchmarked against classical editing methods across three distinct sequential generation tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper excels in storytelling, skillfully introducing a promising generative model for sequence editing. The approach itself is novel and the underlying concept is commendable. The subsequent algorithm, while simple, remains straightforward, and the mathematical analysis of the newly introduced hyperparameters is intuitively presented. Overall, this paper is highly accessible and a pleasure to read."
            },
            "weaknesses": {
                "value": "The primary weakness of this paper lies in its experimental validation. In my opinion, the experiments conducted here fall short of adequately substantiating the proposed idea. There are several issues that need addressing:\n\n**Pretraining Discrepancy**: One notable concern is the difference in the starting points for experimentation. While this work leverages pretrained GFN models, other baselines begin from scratch. This discrepancy could potentially lead to an unfair comparison.\n\n**Baseline Variety**: The baseline comparisons should extend beyond the scope of other generative models and optimization techniques in biological sequence design. It would be beneficial to incorporate baseline methods such as offline model-based optimization [1], which are tailored to extrapolate sequences from offline datasets, thereby yielding \"improved sequences.\"\n\n**Evolutionary Algorithms**: To provide a more comprehensive perspective on the proposed approach, the paper could benefit from the inclusion of promising evolutionary algorithms specifically designed for biological sequence design [2].\n\n**Comparison with GFN Baselines**: Additionally, conducting a thorough comparison with GFN baselines would be valuable in demonstrating the relative strengths and weaknesses of the proposed method when contrasted with models of similar architecture.\n\nAddressing these concerns would significantly enhance the rigor and completeness of the experimental evaluation in the paper.\n\n[1] Trabucco, Brandon, et al. \"Design-bench: Benchmarks for data-driven offline model-based optimization.\" International Conference on Machine Learning. PMLR, 2022.\n\n[2] Sinai, Sam, et al. \"AdaLead: A simple and robust adaptive greedy search algorithm for sequence design.\" arXiv preprint arXiv:2010.02141 (2020)."
            },
            "questions": {
                "value": "1. Could you please elaborate on the process you used for pre-training GFN?\n\n2. Have you conducted a comparison with baseline models (e.g., Seq-to-Seq) using the pretrained GFN as a component?\n\n3. Does this algorithm demonstrate improvements in scalability?\n\n4. Is this algorithm more beneficial than naive search algorithms based on pretrained policies, such as beam-search or MCTS?\n\n5. Have you performed experiments related to Theorem 1 and 2? Inclusion of such experiments would likely enhance the overall quality of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Reviewer_aGg2",
                    "ICLR.cc/2024/Conference/Submission7903/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7903/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698634868012,
        "cdate": 1698634868012,
        "tmdate": 1700631542638,
        "mdate": 1700631542638,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fv1g12C8PT",
        "forum": "viNQSOadLg",
        "replyto": "viNQSOadLg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_1B72"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7903/Reviewer_1B72"
        ],
        "content": {
            "summary": {
                "value": "* In this paper, the authors present a novel sequence editing method that leverages GFlowNet. This method relies on a pre-trained flow function to evaluate the potential for substantial property improvement within a given sequence. Furthermore, it generates a variety of edits using a stochastic policy. \n* The properties of the edited sequences are analyzed by assessing the lower and upper bounds of the reward function. \n* To evaluate the effectiveness of this approach, the authors conducted real data experiments and compared their method to three baseline approaches. They assessed performance using various metrics, including property enhancement, edit percentage, and diversity in TF binding."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The experimental results demonstrate the superiority of the proposed method across various DNA and protein sequence editing tasks. It consistently outperforms other baselines by generating sequences with fewer edits, enhanced properties, and greater diversity"
            },
            "weaknesses": {
                "value": "* Lack of Training Details: The paper lacks sufficient information regarding the training process of the policy. It should provide more details on the training data used, the methodology for updating parameters, and the specific hyperparameters employed in the process.\n* Unclear Literature Review: The literature review in the paper needs improvement. It is not adequately clear what the main contribution of the proposed method is, and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The paper should provide a more explicit and comparative analysis of related work.\n* Ambiguity in Key Innovation: The claim that GFNSeqEditor can produce novel sequences with improved properties lacks clarity regarding the key innovation driving these contributions. The paper should better articulate what novel techniques or insights lead to the claimed improvements, thereby enhancing the reader's understanding of the method's unique value."
            },
            "questions": {
                "value": "See the comments in Weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7903/Reviewer_1B72",
                    "ICLR.cc/2024/Conference/Submission7903/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7903/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811062364,
        "cdate": 1698811062364,
        "tmdate": 1700578460816,
        "mdate": 1700578460816,
        "license": "CC BY 4.0",
        "version": 2
    }
]