[
    {
        "id": "iICQgJlRge",
        "forum": "KZSEgJGPxu",
        "replyto": "KZSEgJGPxu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_8R9V"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_8R9V"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces SNIP, a multimodal pre-training method whose aim is to combine the symbolic and numeric properties of functions into a structured and meaningful latent space.\nThe authors show that the resulting embeddings can be used for a variety of downstream prediction tasks such as predicting the degree of convexity or upwardness of a function. They also combine their model with a decoder and a latent space optimiser to produce a powerful symbolic regression method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall this a very enjoyable and valuable paper. I particularly appreciated:\n- Novelty: although the paper builds on top of existing approaches, the CLIP-like training is a clever contribution which gives a lot of value to the paper.\n- Impact: I believe this approach has a real potential to impact the way we perform symbolic tasks.\n- Clarity: the paper is extremely pleasant to read. Although some parts lack details (see weaknesses), the paper is very well-written, easy to follow, and the figures are excellent.\n- Content: I really enjoyed the experiments the authors present. The embeddings plot of Fig. 2 and interpolability plot of Fig. 5 give a lot of intuition, and the applications to cross-modal property prediction\n- Experimental soundness: the authors put a lot of effort into evaluation. They rigorously benchmarked their model using SRBench (which many SR papers avoid still today), and have an extensive set of additional results in the appendix.\n- Code availability: the authors provide an anonymous link towards their code."
            },
            "weaknesses": {
                "value": "In some parts, the authors are too hasty in their presentation of the technical details, missing out some important informations (see the questions below for details, and some other minor issues). Apart from this, I do not have many concerns about this paper."
            },
            "questions": {
                "value": "- There is a lack of details in some parts of the paper:\n    - Finetuning (section 4): (i) It isn\u2019t clear to me whether the properties (NCR and upwardness) are predicted based on the symbolic or numeric data. (ii) What is the dimension ? I don\u2019t see how one can define upwardness for multi-dimensional functions so I assume D=1?\n    - Interpolability plot (figure 5):  are these graphs qualitative plots, or are they actual functions in the latent space ? I would like the authors to comment on this.\n- I\u2019m not sure the fine-tuning task with 100 examples can be called few-shot. Few-shot usually refers to only a handful of examples. I would instead call this the \u201clow data regime\". \n- In Fig 3, it looks like supervised model is going to catch up with SNIP\u2026 This is a bit problematic, ideally we would need to see results with more training examples to make sure SNIP remains better asymptotically. Authors the authors may argue that SNIP is much better in the low data regime, I don\u2019t think this is the most important asset of SNIP, as we typically have infinite data in these kind of tasks anyway.\n- I find it a bit weird to use a mapping network to convert the latent vector to a sequence. I understand that the authors want to mimic the cross-attention of the decode as in Kamienny et al, but intuitively, I would have instead tried using the latent vector as a \u201cBOS\u201d token, then use cross-attention with the output embeddings of the encoder (before they are pooled). This could be worth trying in the future.\n- I don\u2019t find the results section of sec 5.4.2 particularly well presented, especially in paragraphs \u201cstrogatz\u201d, \u201cblack box\u201d and \u201cFeynman\u201d where many numbers are presented which can directly be read from the graph \u2014 since the orderings of the models are similar on all three datasets, it would be better to have a more qualitative description extracting the key takeaways"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4179/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697635612636,
        "cdate": 1697635612636,
        "tmdate": 1699636384030,
        "mdate": 1699636384030,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IQqF8UjzE2",
        "forum": "KZSEgJGPxu",
        "replyto": "KZSEgJGPxu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_PqVT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_PqVT"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes SNIP, a joint encoder for numeric and symbolic mathematical data, -- i.e. functions and their values. SNIP consists of two transformer-based encoders, one for numeric sequences, and one for symbolic functions (including numeric pre-factors: e.g. 6.21cos(2.1x+3.25)). At the output of each encoder, an attention pooling mechanism converts the encoded sequence into a fixed-dimension embedding. \n\nThe numeric encoder architecture is very similar to Kamienny (2022). Floating point numbers are discretized into three tokens (following Charton 2022), D-dimensional vectors (represented as 3D tokens) are reduced to a single embedding using a feed-forward network (as in Kamienny), and sequences of N embeddings are fed, without positional encoding, into a 8 layer transformer with 16 heads and 512 dimensions. \n\nThe SNIP architecture is pre-trained on generated pairs of functions and their values, similar to the generated training sets used for end-to-end symbolic regression (Biggo, d'Ascoli, Kamienny). The authors use a symmetric contrastive loss, and show that the trained embeddings account for qualitative properties of the encoded functions, such as their growth and convexity (Figure 2, and appendix C ans D).\n\nThe model is then tested on two tasks: \n* predicting qualitative properties of functions, by training a one layer classifier on top of a pre-trained model (either frozen or trainable)\n* symbolic regression, by adding an autoregressive 16-layer transformer decoder at the output of the  pre-trained numeric encoder, and performing pre-factor fine-tuning of the predicted solution (i.e. tuning the constants in the functional expression) by minimizing mean square error over perturbed input data (noisy and/or subsampled).\n\nFor property prediction, the pre-trained model achieves high accuracy after fine-tuning on a small sample of functions (1000, to 10000). \nFor symbolic regression, the pre-trained model achieves state-of-the-art performance on the SRBench evaluation dataset. It outperforms better previous end-to-end approaches (Kamienny) and is comparable to the best evolutionary methods (Operon, SBP-GP)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Joint training on functions and their values is a promising idea, and the paper proposes a working architecture. The results on symbolic regression achieve a new state of the art for end-to-end transformer-based methods, on par with the best evolutionary tools. \n\nThe paper is clearly written, and the method is sufficiently described. Experiments are convincing."
            },
            "weaknesses": {
                "value": "* The architecture is complex and no ablation studies are provided. In particular, the model is larger than previous works on symbolic regression with transformers. SNIP has 8 and 16 layers in the encoder and decoder vs 6 and 6 in Biggio, and 4 and 8 in Kamienny. Without an ablation study, it is difficult to know if the improved performance is due to the new architecture, or is just an effect of scaling. \n\n* Most evaluations focus on symbolic regression, which is also the pre-training task. Therefore, the claim that SNIP can be used on many mathematical tasks is not well-supported. To prove that the model can be applied to other tasks, evaluations on symbolic to numeric tasks, like function evaluation, or on pure symbolic or numerical computations (eg symbolic integration, linear algebra) would be needed.\n\n* The test sets for symbolic regression are small, and somewhat limited. Feynman has 119 functions, many of them redundant, most of them very simple (first order approximations of physical laws). Strogatz has 14, all in low dimension. Evaluating from a larger test set of generated functions (held-out from the training set) would greatly improve the paper. \n\n* There are no ablations on results. How does model performance scale with problem dimension, function complexity, the number of inputs, desired precision?\n\n* Evaluation on function properties (section 4) is weak. The metrics used are redundant ($R^2=1-NMSE$), and not appropriate (what is the point of $R^2$ when only one number is predicted?). Additional metrics are needed, such as the number of correct predictions (e.g. model prediction within 1% of correct values). \n\n* The comparison with unsupervised training (section 4) is inconclusive. The pre-trained models used 60 million examples, comparing them with an unsupervised model trained on 10,000 is unfair. In fact, the 87% accuracy achieved by the unsupervised model after only one million examples is quite surprising."
            },
            "questions": {
                "value": "**Section 3 - encodings**\n* Alternative encodings for real numbers been proposed in previous works. Biggio feeds the floating point representations into the embedding, Becker et al. propose the two-bit encoding (https://arxiv.org/abs/2307.12617). Recently (after the submission deadline), Golkar et al. introduced XVAL (https://arxiv.org/abs/2310.02989), an improvement over the three token embedding. These alternatives should be referenced in the paper (either in section 3 or in the related works). A discussion of their relative merits would be useful.\n* In several previous works,, symbolic functions are encoded as \"skeletons\", where pre-factors are replaced by constant tokens, e.g. CST cos(CST x + CST) instead of  6.21 cos (2.01 x + 3.25). Could they be used in SNIP, instead of encoding prefactors (as 3 token sequences)?\n* Can you provide dataset sizes, notably the number of pre-training examples, in the main? \n* Section 3.1 p.3: the base 10 floating point encoding, using three tokens per numbers, was introduced in Charton (2022) \n* Section 3.2 p.4: the prefix enumeration of trees was introduced in Lample (2020)\n\n**Section 4 - predicted properties**\n* $R^2$ makes little sense when measuring scalar quantities. Also, $R^2=1-MSE$, so the columns in table 1 are redundant. Could you add scalar accuracy metrics, such as the percentage of test examples predicted within a certain tolerance of their actual values? \n* Add the chance level for the indicators in table 1.\n* The comparison between pre-trained and unsupervised model (figure 3) is unsatisfactory: it overlooks the fact that the pre-trained model already saw 60 million examples. The analysis is interesting but needs to be improved.\n* Several properties were measured in this evaluation, but only average results are presented. Can detailed results for each property be provided? (maybe in the appendix)\n\n**Section 5 - Symbolic regression**\n* The decoder is significantly larger that what was used in previous works (16 layers, vs 8 in Kamienny and 6 in Biggio), why is this so? Can you provide ablation results for different architecture choices (layers, but also dimensions and heads)?\n* Figure 11.a, in Appendix E, strongly suggests that SNIP is learning different (independent?) models for different dimensions D. Is there a benefit in training SNIP on many dimensions at the same time? Or should different models be trained on different dimensions? \n* Please provide results on a held-out dataset of generated functions, and scaling results for different problem dimensions (D), function complexity (e.g. family of operators used), number of input (N), precision achieved (in the MSE sense).\n* The late space optimisation experiments would benefit from a more detailed description in the main (perhaps at the expense of the introduction, which is a bit repetitive). In particular, the impact of LSO on model performance should be presented and discussed.\n* A gradient-free library like Nevergrad (https://facebookresearch.github.io/nevergrad/) could be used to provide better perpective on the potential impact of LSO. At present, only one algorithm is used, with little justification."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4179/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698411081880,
        "cdate": 1698411081880,
        "tmdate": 1699636383938,
        "mdate": 1699636383938,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5yVNtLDI1W",
        "forum": "KZSEgJGPxu",
        "replyto": "KZSEgJGPxu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_RHHe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_RHHe"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces SNIP, a Symbolic Numeric Integrated Pre-training approach, meant to unify numeric and symbolic domains via contrastive learning. The proposed method follows the rich literature on multi-modal pre-trained models whose main goal is to combine different modalities such that their representations are appropriately linked and correlated in the latent space. \nSNIP is based on two encoders, one for numerical data and one for symbolic expressions. Contrastive learning is used to unify the resulting representations. Once this pre-training phase is completed, the numerical encoder can be extracted and combined with a symbolic decoder responsible for predicting the symbolic expression associated with the input numerical values, a.k.a. performing end-to-end symbolic regression. Thanks to the rich structure acquired by the numerical encoder during pre-training, latent space optimisation can be performed to enhance the results of symbolic regression. The results show that SNIP's encoders contain cross-domain information about symbolic and numerical inputs and that symbolic regression benefits from the pre-training phase."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "In terms of clarity the paper is generally well written and easy to follow.\n\nIn the context of end-to-end symbolic regression performed by Transformer models, the problem of unifying numerical and symbolic representations is very relevant. As such, I believe SNIP represents an interesting step in this direction.\n\nThe experiments in Section 4 and Appendix C effectively demonstrate that the single encoders' representations contain cross-domain information, e.g. the symbolic encoder's latent space is informative about numerical properties associated with the evaluations of the input expression. In addition, the example in Fig. 5 seems to suggest that the latent space possesses a continuous structure, in the sense that nearby points can be decoded into expressions that have a similar numerical evaluations.\n\nThe results in Section 5 show that the proposed approached outperforms E2E, which is the closest baseline deep learning model for symbolic regression. The model performs comparably with state-of-the art genetic-programming-based symbolic regression methods."
            },
            "weaknesses": {
                "value": "- Some parts could be better explained and more details should be provided. For example, in Section 4 it is not clear how the task is performed. Looking at the Appendix, it looks like the prediction of the NCR and Function Upwardness is made by extracting the embedding from the symbolic encoder only as the goal would be to assess whether the symbolic representations contain numerical information as well. If my interpretation is correct, I believe this should be explained more clearly in the main body.\nAnother source of confusion is the way symbolic regression is performed. In particular, it is not clear to me if the decoder is trained or not. Are the authors keeping it frozen and training only the mapping network? \n\n- The experiments performed in Section 4 are conducted on 1-d symbolic expressions. Although this setting is already insightful, I would be curious to see whether similar tests can be conducted on higher-dimensional expressions.\n\n- While Transformer-based approaches to symbolic regression provide advantages in terms of inference time compared to genetic programming approaches, they may suffer from some of the limitations characterizing standard language models. One such limitation could be that they may hallucinate and output a symbolic expression that does not fit the numerical data at all. I would have liked to see some investigations on this aspect, for example an analysis on the extent to which output symbolic expressions are numerically aligned with the input dataset."
            },
            "questions": {
                "value": "See weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4179/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698583367425,
        "cdate": 1698583367425,
        "tmdate": 1699636383846,
        "mdate": 1699636383846,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "k86wK05aTG",
        "forum": "KZSEgJGPxu",
        "replyto": "KZSEgJGPxu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_7mJN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4179/Reviewer_7mJN"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new model for pre-training an embedding space for mathematical expressions. The obtained embeddings aim at encoding both symbolic and numerical properties of the corresponding expressions. \u2028The paper introduces a dual encoder-scheme to learn such joint embeddings, inspired by similar schemes in multi-modal representation learning.\u2028\u2028\nThe paper focuses on two tasks: property prediction and symbolic regression.\u2028\u2028\u2028\n\nFor property prediction, a simple extension of the embedding architecture is proposed, where an additional head is exploited to predict numeric and symbolic properties of the input equations. The results show that pretrained embeddings (possibly, fintuned) provide a much better prediction in terms or R^2 and NMSE. \u2028\u2028\n\nFor symbolic regression, a much more elaborate scheme is proposed. The existing encoding architecture is mapped with a pretrained-decoder using a technique similar to ClipClap. Second, an inference latent space optimization process is exploited to exploit the interpolability of the pertained latent space. The results show that SNIP is in the Pareto front for all the three investigated datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written and easy to follow.\u2028\u2028\n\nThe method is simple, sound and elegant.\n\nGenerating a large number of expressions automatically is easy: these settings are the ones that may benefit more from a pretraining strategy."
            },
            "weaknesses": {
                "value": "From the current shape of the paper, it is a little bit hard to investigate the novelty. The majority of techniques are inspired by similar techniques in multi-modal representation learning, and it is not clear whether there has been similar endeavors in the context of mathematical expressions representation learning or closer domains."
            },
            "questions": {
                "value": "1) It is unclear whether there are other methods that exploit pretraining for mathematical expressions, or other semi-supervised approaches. In both the comparison, it is clear that some of the methods have been exposed to a very different amount of (unsupervised) data. So one may wonder whether there are other methods of exploiting such data than the one proposed by the authors.\u2028\u2028\n\n2) In order to apply the proposed method to symbolic regression, a LSO process is added on top of the standard training. It is unclear what is the impact of such step on the quality of the generation and whether competitors employ similar strategies and to which extent. Do the authors have performed an ablation study or have intuitions about the impact of the LSO?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4179/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4179/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4179/Reviewer_7mJN"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4179/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698654550378,
        "cdate": 1698654550378,
        "tmdate": 1699636383773,
        "mdate": 1699636383773,
        "license": "CC BY 4.0",
        "version": 2
    }
]