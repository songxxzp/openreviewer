[
    {
        "id": "ca8vgBo3AU",
        "forum": "Lu5gGqhFTw",
        "replyto": "Lu5gGqhFTw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission523/Reviewer_SHZg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission523/Reviewer_SHZg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the matrix cross-entropy (MCE) loss for semi-supervised learning (SSL). In addition to matching the output of the strong augmentation with the pseudo-label of the weak augmentation, they also match the pairwise product of the output of the strong augmentation with that of the weak augmentation. Extensive theoretical analysis on the MCE loss reveals the nice theoretical property of the proposed approach. Experiments on benchmark datasets validate the effectiveness of the proposal."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The proposed MCE loss is novel and interesting. As far as I know, this is the first time it has been applied to the SSL literature. \n- The theoretical analysis is very comprehensive and sound. The nice theoretical property can promote further investigation of MCE in the community.\n- The empirical performance is very strong since the compared methods are very recent and strong methods in SSL."
            },
            "weaknesses": {
                "value": "My small comment concerns the details of the writing, especially the notations. There may be some typos or unclear statements. \n\n- In section 2.1, it should read $\\log q_1$ instead of $\\log q_i$. \n- In section 2.1, what's Eq.(2.1)?\n- In Eq. 4, is $\\tilde{Y}_s$ the model output of weak augmentations? In a line above it is written as $\\tilde{Y}$. If they mean the same thing, the notation should be the same. \n- In Definition 4.2, it should be $n=0$ instead of $i=0$. \n\nThe author should check the notation carefully."
            },
            "questions": {
                "value": "Since MCE can be simplified with a $l_2$-normalized matrix, what is the loss function used in the experiments? Is it still equation (1) with a non-normalized matrix?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698211735764,
        "cdate": 1698211735764,
        "tmdate": 1699635979579,
        "mdate": 1699635979579,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dig0Ls9oU1",
        "forum": "Lu5gGqhFTw",
        "replyto": "Lu5gGqhFTw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission523/Reviewer_Hi55"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission523/Reviewer_Hi55"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the challenges in semi-supervised learning. The authors highlight that prior research has often overlooked the interconnections between data points in a batch. To address this gap, they introduce RelationMatch, an approach designed to harness the consistency of relationships within a batch of unlabeled data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The paper is well written and easy to understand. \n2. The authors present the derivation of the proposed MCE Loss through the lenses of matrix analysis and information geometry, showcasing its advantageous characteristics such as convexity, boundedness from below, and optimizable properties."
            },
            "weaknesses": {
                "value": "1. My primary concern pertains to the paper's novelty. SimMatch[1] has previously addressed the relationship between data points by applying consistency regularization at both the semantic and instance levels, promoting identical class predictions and maintaining similarity relations with other instances for different augmentations of the same instance. A detailed discussion and comparison between SimMatch and RelationMatch are essential to elucidate the distinct contributions of the latter.\n\n2. The benchmark comparison appears outdated. The most recent method evaluated in the paper is from 2021, and although the authors mention some methods from 2022 and 2023, such as FreeMatch, MaxMatch, and NP-Match, these have not been included in the experimental comparisons. When compared with the latest methods, RelationMatch does not seem to meet the state-of-the-art standard.\n\n3. The experimental scope of the paper is limited to toy datasets. To bolster the findings, it is recommended to extend the experiments to more complex, real-world datasets, such as ImageNet.\n\n\n[1] Zheng, Mingkai, et al. \"Simmatch: Semi-supervised learning with similarity matching.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission523/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission523/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission523/Reviewer_Hi55"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698737119916,
        "cdate": 1698737119916,
        "tmdate": 1699635979512,
        "mdate": 1699635979512,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Erm35bTMGa",
        "forum": "Lu5gGqhFTw",
        "replyto": "Lu5gGqhFTw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission523/Reviewer_8nMg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission523/Reviewer_8nMg"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces the consistency between each pair of weak and strong augmentation within a batch in semi-supervised learning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. the paper proposes a novel idea, which consider in-batch relationship in SSL.\n2. The paper proposes matrix cross-entropy, which has a theoretical foundation and interpretations.\n3. Good writing, easy to follow, I appreciate the warm-up example, which is helpful for understanding."
            },
            "weaknesses": {
                "value": "1. Figure 1 can be improved. There are too many lines, which are confusing.\n2. Large dataset experiments are missing, e.g., ImageNet \n3. Ablation studies on $\\mu$ and $\\gamma$ are missing.\n4. Formulations and notations are not clear. What's the definition of $Y_s$ and $X_s$ in eq(4)? \n5. How MCE connect with Relation in the introduction?"
            },
            "questions": {
                "value": "1. Would you consider a relation (strongeaug dog, strongaug cat) > relation(weakaug dog, weakaug cat)? Intuitively, this relation more close to nature's rule.\n2. Is there an intuitive explanation of matrix cross-extropy? \n3. MCE(P, Q) = tr(\u2212P log Q + Q). For matrix cross-entropy, why +Q?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698756767875,
        "cdate": 1698756767875,
        "tmdate": 1699635979450,
        "mdate": 1699635979450,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "I9ogKylpqE",
        "forum": "Lu5gGqhFTw",
        "replyto": "Lu5gGqhFTw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission523/Reviewer_BTXg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission523/Reviewer_BTXg"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of semi-supervised learning, which is a common and interesting area. The author proposes RelationMatch, an innovative semi-supervised learning framework that capitalizes on these relationships through a novel Matrix Cross-Entropy (MCE) loss function. Extensive empirical evaluations, including a 15.21% accuracy improvement over FlexMatch on the STL-10 dataset, have demonstrated that RelationMatch consistently outperforms existing state-of-the-art methods.corruptions."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is well-written, well-organized, and easy to follow.\n2. The paper addresses a novel and important problem, i.e., the relationships among data points within a batch, which has not been well-studied in the literature. \n3. This method can be easily incorporated with other works"
            },
            "weaknesses": {
                "value": "1. The experiment appears somewhat insufficient, as only two experiments were conducted in the main text, and they were tested on just two to three datasets. Additionally, I am curious as to why the STL-10 dataset was omitted from Table 1.\n2. Based on the results presented in Table 1, the displayed accuracy results show limited differentiation. The matrix cross-entropy outperformed by a margin of less than 0.3%. This could potentially be attributed to randomization and perturbations.\n3. Potential failure modes or limitations not discussed."
            },
            "questions": {
                "value": "The primary questions for the rebuttal primarily arise from the \"weaknesses\" section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699014656988,
        "cdate": 1699014656988,
        "tmdate": 1699635979375,
        "mdate": 1699635979375,
        "license": "CC BY 4.0",
        "version": 2
    }
]