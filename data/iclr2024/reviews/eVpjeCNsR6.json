[
    {
        "id": "CJ7sk8cXeW",
        "forum": "eVpjeCNsR6",
        "replyto": "eVpjeCNsR6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_oTvb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_oTvb"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an unlearning algorithm for diffusion models in order to mitigate the concerns about data memorization. With the goal of scrubbing the information for certain classes, this paper proposes to maximize the variational bound on the sub-dataset under those classes while also minimizing the objective function on the remaining data.  To solve the constrained optimization, the author proposed to view it as a bi-level optimization and perform maximization and minimization alternatively to erase the information while maintaining the model quality. The proposed method is simple and effective, as demonstrated by numerical experiments. My major concern is that the practical performance fails to outperform in both forgetting and remaining classes. The author may claim their method achieves a better tradeoff, which is not fully supported by the experiments and could be subjective. It would be better to demonstrate some kind of \u201coptimality\u201d either theoretically or empirically to back up this simple idea."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea is simple and effective. The effectiveness is shown via numerical experiments, where the proposed method achieves an arguably better tradeoff between forgetting some certain classes and remaining to perform well in other classes."
            },
            "weaknesses": {
                "value": "Is there a theoretical guarantee to do the optimization alternatively? It seems not necessary in this setting, as we may do it completely in a separate way, i.e., do the maximization first to completely scrub the forgetting classes and then fine-tune to make up the performance on the remaining dataset. Which way would be better, and why?\n\nWe also see a drop in the quality of generated figures from Table 2, and the proposed model is worse than finetune from Table 3."
            },
            "questions": {
                "value": "Minor typo: page 3, \u201cthe variational bond\u201d above equation (1)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Reviewer_oTvb"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7041/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698522373841,
        "cdate": 1698522373841,
        "tmdate": 1699636827380,
        "mdate": 1699636827380,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XiY1W8uNGb",
        "forum": "eVpjeCNsR6",
        "replyto": "eVpjeCNsR6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_LbvE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_LbvE"
        ],
        "content": {
            "summary": {
                "value": "The paper propose the first(up to their knowledge) unlearning algorithm for diffusion models in order to let the models learn to erase the learning effects by some specific training data and still remember the distribution of other training data, without retraining the models from scratch. Such algorithm help protect privacy, prevent misuse, mitigate or erase bad impact by some undesirable training data but preserve model utility with respect to remaining training data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This paper proposes a new strategy to finetune diffusion model to eliminate effects of some training data.\n2. This includes experiments comparing the effectiveness of their model on both label-conditional and unconditional diffusion models, showing that by the algorithm provided, a pretrained model can actually forget designated data and preserve the rest. \n3. Problem addressing, motivation, method(learning objective design and finetune pipeline), experiments are clear.\n4. This paper demonstrate efficacy and efficiency to scrub diffusion model and such contribution can be significant if more and more privacy concerns are addressed on those generative models."
            },
            "weaknesses": {
                "value": "The evaluation is based too much on image label, which might only be a small subset of the potential problem cases. \nFor class conditional diffusion model, it makes sense to run the finetune algorithm to forget all training images for specific class, it is like a reverse-process of few-shot learning. \nFor unconditional diffusion model, the training data still provide image class(but diffusion model is not able to access label during training or testing). Then, by erasing some all data from a specific class, the diffusion model does not actually \"forget well\" about those data. Such case is severe especially for alike classes, and for human face dataset like CelebA.\nMost importantly, if the elements in forgetting subset do NOT share enough common property(for example, a photographer want you to erase all photos she took, but those photos are of huge variety with many semantics, despite \"her special style\" can be labeled, this is often not a label available in original model training), in that case, it is hard to evaluate how good the model forgets such subset."
            },
            "questions": {
                "value": "Suggestions:\n1. Design more experiment(and have more discussion) on random(or not so well-labeled) subset, demonstrate model efficacy.\n2. Evaluating unconditional diffusion model utility with respect to specific sub-dataset can be hardly well-defined, so try to narrow-down and specify the problem you want to tackle in a more guided way(such as to only some specific conditional diffusion model).\n3. Try more types of condition(or context)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Reviewer_LbvE"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7041/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698704537204,
        "cdate": 1698704537204,
        "tmdate": 1699636827269,
        "mdate": 1699636827269,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yrIE94I44N",
        "forum": "eVpjeCNsR6",
        "replyto": "eVpjeCNsR6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_JxPy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_JxPy"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the development of an algorithm called EraseDiff, which aims to address the privacy risks and data protection regulations associated with diffusion models. These models, known for their high-quality output and ease of use, pose concerns related to privacy, memorization of training data, generation of inappropriate content, and potential violation of data ownership and copyright laws. The proposed algorithm formulates unlearning as a bi-level optimization problem, with the goal of scrubbing the information associated with forgetting data from diffusion models without the need for retraining the entire system. The algorithm is evaluated in various scenarios, including the removal of classes, attributes, and races from different datasets, and it demonstrates improved performance compared to baseline methods."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. This paper focuses on a crucial question: the issue of privacy within the diffusion model."
            },
            "weaknesses": {
                "value": "1. The formulation of the diffusion model unlearning problem in this work seems unconventional. Both the inner and outer objectives aim to optimize the model parameters. As such, it can be naturally defined as a multitask problem. One task seeks to preserve the utility of the diffusion model for the remaining data, while the other aims to eliminate the information related to the data slated for removal.\n\n2. The inner objective of this work strives to make the diffusion model incapable of generating meaningful images corresponding to C_f. The rationale behind defining sample unlearning in this manner is unclear. A more intuitive approach would be to ensure that the model, when trained with both the remaining and the forgetting data, has parameters equivalent to those obtained when trained solely on the remaining data after the unlearning process."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Reviewer_JxPy"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7041/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698754044410,
        "cdate": 1698754044410,
        "tmdate": 1700636582507,
        "mdate": 1700636582507,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "s0pNtLdQl7",
        "forum": "eVpjeCNsR6",
        "replyto": "eVpjeCNsR6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_Sr9v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_Sr9v"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a bi-level optimization approach for the unlearning of diffusion models. Specifically, the inner objective focuses on data sanitization, while the outer objective seeks to retain the utility of the diffusion model with respect to the retained data. Moreover, the proposed technique is versatile, accommodating both conditional and unconditional image generation. Its effectiveness has been demonstrated across several datasets, including UTKFace, CelebA, CelebAHQ, and CIFAR10."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Assess the performance of the unlearned model using a diverse set of metrics to capture multiple perspectives. These metrics include the Fr\u00e9chet Inception Distance (FID), accuracy (Acc), Membership Inference Attack (MIA), Kullback-Leibler (KL) distance, and weight distance.\n2. Examine the effectiveness of the proposed approach across several datasets: UTKFace, CelebA, CelebAHQ, and CIFAR10."
            },
            "weaknesses": {
                "value": "The proposed method primarily focuses on class-wise unlearning and may have limitations when applied outside this specific context (e.g., nudity removal, artistic style removal)."
            },
            "questions": {
                "value": "How effective is the unlearning process when subjected to adversarial attacks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7041/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698785657978,
        "cdate": 1698785657978,
        "tmdate": 1699636827011,
        "mdate": 1699636827011,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nnjTmOJVEg",
        "forum": "eVpjeCNsR6",
        "replyto": "eVpjeCNsR6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_KgRz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7041/Reviewer_KgRz"
        ],
        "content": {
            "summary": {
                "value": "**POST REBUTTAL NOTE FOR AUTHORS:**\n\nI would like to thank the authors for patiently answering my questions and acknowledge that I have read their responses. \n\n--------------------------------------------------\n\n**PRE REBUTTAL REVIEW:**\n\nThis paper tackles the privacy issue with respect to the generations of diffusion models. Diffusion models, pose significant privacy risks as they can memorize and regenerate individual images from their training datasets and this paper aims to propose an unlearning algorithm. The setup considers access to a pretrained diffusion model as well as the \"forgetting data\"(data to be forgotten) and the \"remaining data\" (data which needs to be modeled correctly in the diffusion model). \n\nEraseDiff casts this problem to a bi-level optimization problem that fine-tunes the model with the remaining data while deviating the generative process to erase the influence of the forgetting data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- EraseDiff introduces a new approach to data unlearning in diffusion models.\n- The method is more efficient than retraining the entire model, but requires more comparison in terms of other recent baselines in the literature.\n- The paper provides extensive empirical evaluations, comparing with existing unlearning algorithms for neural networks.\n- The technique can be applied to both conditional and unconditional image generation tasks.\n- The paper grounds its methodology in a solid theoretical framework"
            },
            "weaknesses": {
                "value": "- I understand the assumptions made in the paper are that we do have access to $\\mathcal{D}_r$. However, is this a reasonable assumption for large scale diffusion models? Often times, we have access to a pre-trained diffusion model and also to the forgetting data ($\\mathcal{D}_f$) but assuming access to $\\mathcal{D}_r$ which may be very large might not be reasonable. Have the authors thought about the case where we do not have access to the remaining data? How does the algorithm change? Is there significant impact on the results?\n\n- The impact of unlearning seems to have affected the samples quality significantly. \n- The assumption in the methodology that they access to $\\mathcal{D}_r$, hinders the use of the algorithm for large scale diffusion models such as Stable Diffusion. \n\nSee my questions below."
            },
            "questions": {
                "value": "- There is no definition of the hyper-parameter $\\lambda$. Does it control the balance between retaining and forgetting data?\n\n- Authors have missed important citations: [2] and [3].\n\n- Can the authors clarify on the connections and similarity of their work compared to [1], [2] and [3]? From my understanding, [1] also fine-tunes the score network to minimize the generation probability of samples that can be labeled as a specific class. Also in [2] and [3] authors propose similar approaches for removing concepts. I believe the claim made in the introduction about this work being the first to study unlearning in diffusion models is incorrect. \n\n- A believe it would be nice to be able to compare your method against Selective Amnesia [2]. In Table 1 of [2] there is results on CIFAR10  and the FID on the remaining classes seems to be much lower (9.08) than what you have reported in Table 2 (seems to be on average above 20). I would appreciate it if the authors provide more comparisons or clarifications with respect to [2]. \n\n- The texts on Figure 3 are not easily readable. What is the y axis (frequency)? How do we interpret this plot?\n\nI am willing to modify my score once the results and comparisons with existing baselines in the literature are clarified.  \n\n\n[1] Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, and David Bau. Erasing concepts from diffusion models. arXiv preprint arXiv:2303.07345, 2023.\n\n[2] Heng, Alvin, and Harold Soh. \"Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models.\" arXiv preprint arXiv:2305.10120 (2023).\n\n[3] Gandikota, R., Orgad, H., Belinkov, Y., Materzy\u0144ska, J., & Bau, D. (2023). Unified concept editing in diffusion models. arXiv preprint arXiv:2308.14761."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7041/Reviewer_KgRz"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7041/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699482026115,
        "cdate": 1699482026115,
        "tmdate": 1700776172660,
        "mdate": 1700776172660,
        "license": "CC BY 4.0",
        "version": 2
    }
]