[
    {
        "id": "tE1mdCrUjm",
        "forum": "9JQtrumvg8",
        "replyto": "9JQtrumvg8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_Jsxu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_Jsxu"
        ],
        "content": {
            "summary": {
                "value": "The paper introduced 1) a web-agent model that manipulates the web objects by human natural language instructions 2) a newly pretrained HTML-T5 model as a component in web-agent. \n\nThe experimental results show that 1) the web-agent, compared to solely using it's component Flan-U-Plam, is significantly better in a benchmark; and 2) the newly introduced HTML-T5 itself is outperforming existing HTML LLMs on web understanding tasks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall the reviewer found the experiments are well designed in supporting their claims of 1) the overall methods is much better than using a single LLM and 2) the HTML-T5 is an advance by itself. The most recent models are included in the experiments, and the evaluation datasets (mind2web and miniwob++) are used in training of both the proposed HTML-T5 and the baseline model long-T5. Therefore, the reviewer has no concerns of unfair comparisons."
            },
            "weaknesses": {
                "value": "The presentation can be improved. Please consider revise the writing to avoid the questions below."
            },
            "questions": {
                "value": "1. How are \"open ended actions\" (Figure 1), \"canonical sub-instructions\"(abstract), and \"pre-defined action space\" defined? Does the author promote the open-ended action space or pre-defined action space?\n\n2. In section 3.3, does \"given a few canonical examples for program generation\" describe the step of \"few-shot prompt' in Figure 3? Where do these examples come from?\n\n3. Could the author elaborate on the difference between two tasks in 4.1 and 4.2, except that they have different baseline models and datasets. What's the difference between input/output, etc. \n\n4. What's the definition of \"planning\" in Section 3.2. Is summarization referring to \"localizing\" the relavant snippet of the current sub-instruction?\n\n5. Could the author summarize the WebAgent workflow end-to-end. i.e. describe Figure 3 and explain the user input, system's knowledge/DB if exists, and the HTML-T5 to Flan-U-Plam is one-time action or interactive process. \n\n6. Could the author summarize the newly curated dataset that is used to pretrain/finetune part or entire WebAgent? E.g. template, sub-instruction, action examples\n\n7. In Table1, for example, the real-estate case, does the WebAgent see the same searching page but different instructions in the 20 tests?\n\n8. Is it correct that HTML-T5 is trained only for summarization, while the other models compared in Table 4 are multi-tasking.\n\n\nGlad to raise the score if the clarity will be significantly improved."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1265/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697679540214,
        "cdate": 1697679540214,
        "tmdate": 1699636053387,
        "mdate": 1699636053387,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tBq0fKvsxm",
        "forum": "9JQtrumvg8",
        "replyto": "9JQtrumvg8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_eCh6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_eCh6"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a Web Agent that (1) decomposes natural language instructions into sub-instructions plan, (2) summarizes long HTML pages into task-relevant snippets (based on sub-instructions), and (3) acts on web pages by writing and executing Python programs with the Selenium WebDriver.\n\nWebAgent is based on two neural networks: HTML-T5 (introduced in this work) and Flan-U-PaLM.\nHTML-T5 is an encoder-decoder transformer trained on HTML documents from CommonCrawl with various long-range denoising objectives. The model is then fine-tuned on specific downstream tasks to predict a sub-instruction and a summary of the HTML page (data-ref HTML attributes?) given the natural language instruction, previous sub-instructions, and the raw HTML page.\n\nGiven the predicted sub-instruction and HTML snippet from HTML-T5, Flan-U-PaLM is then prompted to predict executable Python code that will perform the sub-instruction on a given web page.\n\nHTML-T5 is evaluated on MiniWoB++ and Mind2Web. Results show better performance than previous baselines.\nWebAgent is evaluated on WebSRC and instructions following on real websites based on task attributes successfully covered. Experiments show that the modular approach of WebAgent is beneficial compared to using only 1 language model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This work is making a significant contribution to the field by providing two models: one encoder-decoder that reads, understand and summarizes HTML pages: HTML-T5; and one WebAgent that combines the previous model with a code generation model (Flan-U-PaLM) to act and follow instructions on synthetic and real websites. \n\nSome notable strengths of the proposed architecture are:\n- To capture long-range dependencies in long documents, HTML-T5 uses both local and transient global attention similar to Long-T5. In addition it is pre-trained on various long-range denoising objectives.\n- To be able to execute actions on real websites, WebAgent produces executable Python code instead of discrete and non-generalizable HTML actions. This allows the agent to handle any action space present in real HTML pages instead of being limited to a set of fixed actions.\n\nExperimental results show that WebAgent is able to solve tasks in real websites."
            },
            "weaknesses": {
                "value": "Overall, this is a strong paper, however, one weakness of this work is the lack of baselines to compare results against in real-world tasks. Table 1 provides good ablation study insights into the proposed WebAgent but there are no other Agents to compare to. Similarly in Table 3, HTML-T5 is only compared against MindAct on Mind2Web. Are there any other agents that could be used on this benchmark? \n\n---\n\nAnother weakness of this work is its clarity and ease of comprehension. Some aspects of the paper were not entirely clear, in particular how was HTML-T5 trained to predict sub-instruction plans and HTML summaries? What data supervision was used for that?\n\nSimilarly, it is not entirely clear what HTML-T5 produces: Figure-3 indicates \"HTML-snippets\", but the paper mentions multiple times that it \"summarizes\" HTML pages (so it should produce a summary?), and in Section 3.2 the paper states that it predicts ``_the corresponding data-ref attributes_''. If the model outputs only data reference IDs (like suggested also with Figure 6) then this is not summarization but more like information retrieval and the paper should reflect this. In addition, if object references are what is really being predicted, then it is not clear how Flan-U-PaLM make use of that information without having access to the raw HTML containing these objects.\n\nAnother confusion is the window size of HTML-T5: in Section 3.1 it is mentioned that the input sequence length of HTML-T5 is 4096, but in section 4.2 it uses 16k tokens for the context window. Which one is it? 16k tokens seems more likely overall since the model is supposed to take as input instruction, previous sub-instructions, and raw HTML. Just the raw HTML would overflow the 4096 context size as mentioned in the paper and illustrated by Figure 2. After reading 4096 in Sections 3.1, it was hard to understand how all inputs of HTML-T5 would fit in such a small window (especially after seeing Figure 2).\n\n---\n\nEventually, one important thing that the paper should discuss is the difference between train and test settings. It seems like WebAgent was trained on all domains individually. What precautions were made to ensure that the testing tasks do not overlap with the ones used during training?\n\n---\n\nMinor: some syntactic mistakes make the paper hard to read sometimes."
            },
            "questions": {
                "value": "Mostly clarification questions related to weaknesses above:\n\n- What data was used to train HTML-T5 to predict sub-instruction plans and HTML summaries?\n\n- What is defined as a \"HTML summary\" and how is it used by Flan-U-PaLM?\n\n- How did the HTML-T5 inputs (instruction, previous sub-instructions, and raw HTML) fit into a window size of only 4098? The raw HTML would take up all the space.\n\n- How was the train/test split done to ensure no task (or even sub-task) overlap?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1265/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698287261951,
        "cdate": 1698287261951,
        "tmdate": 1699636053321,
        "mdate": 1699636053321,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hzzmAausZD",
        "forum": "9JQtrumvg8",
        "replyto": "9JQtrumvg8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_ASiH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_ASiH"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a new LLM-based agent for web-based tasks which achieves state of the art on Mind2Web.\nThe proposed method combines two LLMs into one agent, HTML-T5 which is a new pretrained model and is further finetuned for planning and summarization, and Flan-U-PaLM which is a frozen model and generates programs to allow the model to interact with web environments."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The model's usage of HTML-T5 for planning and summarization is effective and novel, and the overall performance is good. Especially on Mind2Web, it significantly pushes the upper bound of performance."
            },
            "weaknesses": {
                "value": "Because the model relies on Flan-U-PaLM with 540B parameters, it's difficult to judge how reliant the method is on the ability of this particular model to generate executable code.\n\nThe organization of the paper could be improved, including more details about how feedback was acquired and finetuning was done to enable planning and summarization (i.e. Fig 6 in appendix)"
            },
            "questions": {
                "value": "- There are some missing recent baselines for miniwob++ [1]. These methods report that the task performance is near human (93%). Could you provide more information about the performance of the proposed method (which is a bit lower) in this context?\n\n- Is it possible to report results using models other than Flan-U-PaLM with 540B parameters?\n\n- Will HTML-T5 be released?\n\n[1] SYNAPSE: Trajectory-as-Exemplar Prompting with Memory for Computer Control. Zheng et al., arxiv 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1265/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1265/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1265/Reviewer_ASiH"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1265/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698868587174,
        "cdate": 1698868587174,
        "tmdate": 1700645155477,
        "mdate": 1700645155477,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MujrL4V6CP",
        "forum": "9JQtrumvg8",
        "replyto": "9JQtrumvg8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_Gbpj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1265/Reviewer_Gbpj"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces \"WebAgent,\" an autonomous agent driven by large language models (LLMs) that completes navigation tasks on real websites by following user instructions and combining canonical web actions in a program space. WebAgent's capabilities are outlined as follows:\n\n---\n\nPlanning Sub-Instructions Per Step: It decomposes natural language instructions into sub-instructions, planning out the steps needed to complete a task.\n\nSummarizing Long HTML Pages: It can summarize lengthy HTML pages into snippets that are relevant to the task at hand, based on the sub-instructions derived from the user's commands.\n\nActing via Programming: It grounds sub-instructions and HTML snippets into executable Python codes, allowing it to interact with real websites programmatically.\n\n\n---\nTo form WebAgent, two LLMs are combined:\n\nFlan-U-PaLM: Used for grounded code generation. This model provides the agent with the ability to generate code snippets that can interact with web pages.\n\n\nHTML-T5: Used for task planning and conditional HTML summarization. This model has an encoder-decoder architecture and is specialized in capturing the structure, syntax, and semantics of long HTML pages. It  incorporates local and possibly global attention mechanisms to better process the structure of HTML documents.\n\n---"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The paper has several strengths:\n\n----\n1. Unlike prior works, there is a focus on real world application. Demonstrating success in real-world web navigation tasks provides a strong case for the practical application of this research. This has implications for the usability and deployment of AI systems in everyday tasks.\n\n----\n\n\n2. The collaborative approach, where different models work together to complete tasks, showcases a novel use of ensemble techniques in a practical setting, which encourages more research in model collaboration. There is also additional benefits of such a modular approach, in that scalability and error analysis becomes easier. The use of an ensemble of specialized models to address specific aspects of the problem space, is a departure from the trend of using a single generalist model for all tasks.This specialization can lead to performance improvements and more efficient computation."
            },
            "weaknesses": {
                "value": "1. Especially for this kind of work, the broader impacts section should be in the main text and should be fully fleshed out. This is a significant weakness in this work.\n\n-----\n\n2. It would be good to have a baseline comparison comparing what performance looks like with model scale. Flan-U-PaLM is a 540B parameter model which puts it at a scale inaccessible to many researchers.. it would be good to benchmark how this approach scales from small accessible open source models, to the large ones used in this work.\n\n----"
            },
            "questions": {
                "value": "Does Webagent replan after failures? How does it handle failures?\n\nRelated to a mentioned weakness, how does this approach scale? would it just perform better with more data, parameters and compute?\n\nAre all the components of web-agent available open-source and will web-agent be open-sourced?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Potentially harmful insights, methodologies and applications"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This work builds automated bots to interact on the web. This is important work but it should have a fully fleshed out broader impacts section."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1265/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699034230973,
        "cdate": 1699034230973,
        "tmdate": 1699636053149,
        "mdate": 1699636053149,
        "license": "CC BY 4.0",
        "version": 2
    }
]