[
    {
        "id": "Bc8bb41sKr",
        "forum": "LojXXo2xaf",
        "replyto": "LojXXo2xaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_NYtC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_NYtC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes MathGLM, a transformer-based language model specifically designed and trained to excel at mathematical reasoning and arithmetic tasks. \n\n1. MathGLM is trained on a large dataset of arithmetic expressions and sequences, ranging from simple to complex multi-step calculations. This allows it to learn the underlying rules and patterns of arithmetic operations.\n\n2. A step-by-step strategy is used during training, where MathGLM is tasked with generating each intermediate step leading to the final result. This mimics human calculation and helps MathGLM deeply comprehend the calculations.\n\n3. Curriculum learning is used, starting with simpler arithmetic tasks and progressively increasing complexity. This improves efficiency and allows handling of large digit numbers.\n\n4. MathGLM demonstrates significantly higher accuracy on arithmetic tasks compared to GPT-4, ChatGPT and other LLMs. It also achieves comparable performance to GPT-4 on a Chinese math word problem dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The core idea of specializing a language model for mathematical reasoning is novel and well-motivated. Math is an important domain where current LLMs struggle.\n\n2. The step-by-step training strategy is creative and helps MathGLM learn the intricacies of arithmetic operations. Generating intermediate steps is akin to human math solving.\n\n3. The arithmetic dataset construction process covers various types of math operations and data formats in a principled manner. This diversity is key for strong training.\n\n4. Extensive experiments demonstrate clear performance gains over GPT-4 and other models, validating MathGLM's capabilities. The scaling experiments also provide useful insights.\n\n5. The work is technically sound, clearly presented and easy to follow. The motivation and proposed techniques are intuitive."
            },
            "weaknesses": {
                "value": "1. While specializing for arithmetic is beneficial, it could compromise more general capabilities. Testing on broader math/reasoning tasks could help characterize tradeoffs.\n\n2. More analysis and examples demonstrating the step-by-step generation process could be useful to understand MathGLM's learned skills.\n\n3. The reasoning behind curriculum learning's benefits is not fully fleshed out. Is it mainly about efficiency gains?\n\n4. How well do the findings transfer to non-Chinese languages? Cross-lingual experiments could help strengthen claims of language-agnostic reasoning."
            },
            "questions": {
                "value": "Are there any analysis and examples of the errors made by MathGLM? Understanding the remaining limitations could guide future improvements.\n\nFor real-world usage, how does MathGLM handle novel word problems outside its training distribution? Experiments on out-of-distribution generalization could be insightful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9208/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698373448183,
        "cdate": 1698373448183,
        "tmdate": 1699637159126,
        "mdate": 1699637159126,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1pVboCiSsh",
        "forum": "LojXXo2xaf",
        "replyto": "LojXXo2xaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_mwYm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_mwYm"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce two new datasets that can be used to improve pre-training and fine-tuning of large language models or, more generally, large-scale Transformer models. One dataset contains a large set of arithmetic problems, while the other represents a refined version of Ape210K, which has been augmented with step-by-step solution procedures to solve math word problems involving natural language. The authors exploit these datasets to train a series of Transformer-based language models and show that they indeed achieve more accurate performance in arithmetic and word problem tasks compared to GPT models or other LLMs."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-\tThe article is generally clear and well-written. The research questions are well-motivated.\n-\tInvestigating the arithmetic and mathematical abilities of Transformer-based architectures and LLMs is an important and timely research area.\n-\tReconstructing the Ape210K dataset by adding step-by-step solutions constitutes an interesting extension to the available training corpora (which would become even more useful if the dataset would be made publicly available).\n-\tThe authors also analyze the impact of problem difficulty (e.g., grade levels) and the error distribution."
            },
            "weaknesses": {
                "value": "-\tThe training/testing setup used in the present work differ from those used in similar work, making it challenging to compare the current results with previous contributions. Overall, it seems that the advantage in the reported benchmarks mostly (only?) stems from the use of an extended training set containing math problems, rather than from architectural innovations. This would still constitute an interesting finding, but it should be demonstrated using out-of-distribution test instances (see next point).\n-\tThe authors claim that MathGLM has a \u201cprofound understanding of the complex calculation process\u201d and \u201ceffectively learns the underlying rules and principles of arithmetic operations\u201d, however I do not think that its generalization abilities have been properly evaluated.\n-\tThere are a few methodological details than require clarification (see questions below).\n-\tThe paper does not include any Reproducibility Statement or any pointer to source code repositories, which makes it difficult to replicate the simulations and the experimental setup."
            },
            "questions": {
                "value": "-\tThe authors say that MathGLM learns to solve arithmetic tasks \u201cby integrating a step-by-step strategy into its architecture\u201d. However, it is not clear how the model architecture actually implements step-by-step reasoning process (from the description, it seems that such feature is just a property of the solution format, rather than of the architecture design). This point should be clarified.\n-\tIn order to properly test for generalization the authors should demonstrate that the model can solve problems outside the training distribution (e.g., involving much longer numbers, and much more operands, see for example https://arxiv.org/abs/2207.02536). At present, an alternative (and more parsimonious) explanation is simply that the larger-scale of the training data allows to the model to memorize a more consistent amount of arithmetic knowledge.\n-\tThe authors say that \u201cTo assess the generalization ability of MathGLM beyond the 5-digit range, a set of 50,000 training records involving numbers within the 12-digit range are introduced into the training dataset\u201d. This does not guarantee that generalization is properly assessed; it rather shows that by adding more training samples from the testing range the performance increases, which is expected (also see https://arxiv.org/abs/2306.15400).\n-\tIt is not clear whether the curriculum learning strategy is beneficial since there is no comparison with a non-curriculum counterpart.\n-\tIt is not clear how the Ape210K dataset was reconstructed. Were the step-by-step solutions generated in an automatic way? If so, how was their quality verified?\n-\tWhat is the rationale of using different models for the Arithmetic task and the Math Word Problems? Shouldn\u2019t the same MathGLM model be able to solve both types of problems? The authors say that \u201cour goal is to simultaneously advance both mathematical reasoning and arithmetical calculation capabilities of LLMs, addressing both aspects at the same time\u201d, but from my understanding they trained separate models for the Arithmetic and MWP datasets (the \u201cTraining Strategy\u201d section at pg. 5 should be expanded and described in a much clearer way).\n-\tThe authors should more carefully explain how GPT models were tested. Which prompting methods were used to probe these models? How did performance change when using more advanced (e.g., Chain-of-though) prompting strategies?\n-\tThe title is misleading, since it suggests that models from the GPT family (e.g., ChatGPT, GPT-4) achieve the best accuracy, while in fact the authors are tuning a model from the GLM family. A better option could be to just use \u201cLLMs\u201d as a more general term?\n-\t\u201cGLM\u201d has not been properly defined in the introduction (I suggest including both the acronym description and the reference paper).\n-\tThe manuscript content is often redundant; I suggest removing duplicate (or similar) sentences."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9208/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698395910852,
        "cdate": 1698395910852,
        "tmdate": 1699637158998,
        "mdate": 1699637158998,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iqlxt1J8HA",
        "forum": "LojXXo2xaf",
        "replyto": "LojXXo2xaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_Bh6z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_Bh6z"
        ],
        "content": {
            "summary": {
                "value": "The paper has a full study of LLM on math problems, with the focus of multi-digit complex operations and math problems in regular text. The dataset are created, and the LLM of different sizes are fine tuned. The MathGLM has been evaluated on many setup and ablation. The new model has proven better performance than the GPT-4 on the two goals."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The math accuracy belongs to one of the core challenge of LLM. The paper has very good CoT dataset and gets enhanced performance compared to the GPT-4 model. The paper appears rather useful among many scholars from relevant area."
            },
            "weaknesses": {
                "value": "Could we extend the evaluation of the new model and see the performance on non-math tasks? The math focus finetune may have reduced the performance on other tasks, and it is good to know how good / bad that would be."
            },
            "questions": {
                "value": "Maybe a followup work would seem how to train model for middle-school level math problems, how the size of dataset / model would scale for that"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9208/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830095033,
        "cdate": 1698830095033,
        "tmdate": 1699637158862,
        "mdate": 1699637158862,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BX3JZ8QQ4h",
        "forum": "LojXXo2xaf",
        "replyto": "LojXXo2xaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_GLqj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9208/Reviewer_GLqj"
        ],
        "content": {
            "summary": {
                "value": "The authors propose using LLMs to perform complex mathematical computations. To prove this theory, they trained a model called MathGLM on a dataset with multi-step arithmetic operations and math problems described in text. They verify their results on the APE test set, as well as a K6 dataset they proposed, which consists of elementary-school math word problems. They demonstrate that on a constructed dataset of complex mathematical computations, their model outperforms GPT-4."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Interesting perspective on using LLMs to conduct complex mathematical computations without the use of tools.\n2. The paper states its theory and results clearly."
            },
            "weaknesses": {
                "value": "1. The claim regarding motivation is not robust. While MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, these calculations can be done with 100% accuracy using other tools.\n2. The computation is limited to addition, subtraction, multiplication, division, and exponentiation. The method probably wouldn't generalize well to more intricate computations such as log, sin, etc. Moreover, mathematics should aim for complete accuracy, so utilizing LLMs for these calculations isn't a suitable strategy, especially considering the costly pretraining involved for computations that other tools can resolve more efficiently. Instead, LLMs should concentrate on providing more insight and higher-level strategies for solving math problems.\n3. The primary math word problem datasets are APE and K12, both of which are in Chinese. There were no experiments conducted on popular math datasets like MATH and GSM8K. Since GPT-4 is primarily trained in English, and MathGLM is fine-tuned for Chinese math word problems, such a comparison might not be valid. The advantage of MathGLM could be due to the language, rather than its proficiency in resolving math problems."
            },
            "questions": {
                "value": "See Weaknesses and,\n\nThis paper uses LLMs to conduct complex mathematical computations. This is a novel approach, but the motivation is weak because using LLMs for complex mathematical computations lacks accuracy and generalizability. Additionally, there is a lack of experimentation on MATH and GSM8K, as the primary comparisons are made using Chinese mathematical datasets.\n\nCorrectness: 3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\nTechnical Novelty And Significance: 2: The contributions are only marginally significant or novel.\n\nEmpirical Novelty And Significance: 2: The contributions are only marginally significant or novel."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9208/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9208/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9208/Reviewer_GLqj"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9208/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698844263573,
        "cdate": 1698844263573,
        "tmdate": 1699637158754,
        "mdate": 1699637158754,
        "license": "CC BY 4.0",
        "version": 2
    }
]