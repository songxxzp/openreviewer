[
    {
        "id": "TcMmnunCqA",
        "forum": "oTWhkg5Ed4",
        "replyto": "oTWhkg5Ed4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_4Bqj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_4Bqj"
        ],
        "content": {
            "summary": {
                "value": "This paper is a follow-up work to (Tang et al., 2023) and (Zhang et al., 2023), which uses stable diffusion model's feature maps for semantic matching, due the fact that stable diffusion could provide very well semantic meaningful features. In this work, three prompting options are designed for stable diffusion on semantic matching, which are single, class, and conditional prompting. The results show the effectiveness of the simple prompting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper is easy to understand\n\n2) The constructed prompting strategies is easy and effective.\n\n3) The stable diffusion's feature is good for semantic matching."
            },
            "weaknesses": {
                "value": "1)  Even though one can design lots of different detailed schemes regarding conditional prompting, the idea is already appeared in CoCoOp [1] and it does not show very big difference. The reviewer expects some novel things in addition to some plain designs.\n\n    [1] Conditional prompt learning for vision-language models @ CVPR'22\n\n2) Why skip VAE and directly refer to UNet's input as image I?\n\n3) All the credits went to stable diffusion and the discovery of its features that is good for semantic matching (Tang et al., 2023) and (Zhang et al., 2023). The reviewer deeply felt that there is no much advance in this work, either comparing to (Tang et al., 2023) and (Zhang et al., 2023) or prompt tuning method CoCoOp [1]\n\nBased on the above concerns, the review suggests rejecting the paper."
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1340/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772460180,
        "cdate": 1698772460180,
        "tmdate": 1699636061436,
        "mdate": 1699636061436,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "46v0kwJPFv",
        "forum": "oTWhkg5Ed4",
        "replyto": "oTWhkg5Ed4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_Q84M"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_Q84M"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a prompt tuning method for Stable Diffusion (SD) feature extraction to solve the semantic matching problem. Recently, semantic correspondence has achieved significant performance improvements by extracting discriminative local features from the U-Net structure of SD. In this paper, the authors propose a conditional prompting module (CPM) using local patch embedding in addition to global descriptors using object categories to construct prompts. Prompt using the CPM module in the proposed SD features significantly improves performance for some cases of SPair-71k, but this performance is not significantly different from SD features using class label prompt."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Good motivation: using the features of U-Net within SD for semantic matching is a good approach. The additional use of langauge information (or prompt embedding) for robust feature extraction is a novel direction.\n\nProper citation: The citation of existing research on semantic matching in section 2 related work is appropriate and well categorized. In addition, the recent developments in diffusion models and prompt tuning and the related research synthesis are helpful for understanding the research history.\n\nHigh performance: Even though the study uses weak-supervision (class labels) at inference time for strong-supervised training, PCK@10=75.5 on SPair-71k is quite high performance.  \nHowever, the excessive increase in image resolution needs a fair comparison. (See Weakness for details) \n\nAblation study: Fig. 3(a) shows the effect of the proposed CPM module under various conditions."
            },
            "weaknesses": {
                "value": "Results of geometric matching: The results on the three standard benchmarks for semantic matching are impressive. However, for a definitive proof of SD's ability to extract discriminative features, it should also perform on general geometric matching. \nFor example, HPatches [1] has a name for each sequence, possible to evaluate the proposed method in this benchmark.\n\nResults on other benchmarks in Table 1: It is impressive to see the performance improvement on SPair-71k by only changing the empty string to object category, can you show this result on PF-PASCAL as well?\n\nMissing reference: this paper is missing a citation to a paper that proposes a method [2] to extract discriminative local features for semantic matching. Please cite this paper.\n\nSection 3.3 N_{dino} subscript should not be italic. Italic is for enumerate, please use roman. \n\nSection 4.1. \"we set the timestep t = 50 as empirical tests suggest it provides optimal results, even though our method was trained at t = 261. \"\nHow did you decide on this t=50? Did you get the results from your test set? Figure 3 (b) looks to evaluate  the performance on the test set. I am worried to tune the model on test set and list the highest one.  It would be fair to find the optimal model by searching on the validation set.\n\nSection 4.1. \"Images are resized to 768 \u00d7 768 for both the training and testing phases. \"\nWas this image resize done the same for all the other methods in Table 2? I doubt if the performance improvement is from the prompt tuning you propose or from the image resize. \nPlease provide information on image resolution, computational cost (GFlops), and performance on PF/SPair.\n\nConcern of the performance gain 1: Table 2. The proposed CPM is not significantly different from the class prompt (a photo of [category]). Does this mean that simply giving a class prompt will give the same result? TThis requires a detailed analysis and explanation.\n\nConcern of the performance gain 2: Table 3. The zero-shot generalization of CPM is actually worse than empty string (single) baseline. \n\nFigure 5. Visualization effectively decomposes semantic meaning in different category objects. Can this be evaluated across multiple instances of the same class? [3] I don't need quantitative results, I'm just wondering whether the possibility of prompt tuning using SD can discriminate instances of a category.\n\n\n[1] HPatches: A benchmark and evaluation of handcrafted and learned local descriptors (Balntas et al., CVPR 2017)\n[2] Learning to Distill Convolutional Features into Compact Local Descriptors (Lee et al., WACV 2021)\n[3] MISC210K: A Large-Scale Dataset for Multi-Instance Semantic Correspondence (Sun et el., CVPR 2023)"
            },
            "questions": {
                "value": "Please refer to the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1340/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1340/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1340/Reviewer_Q84M"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1340/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823350468,
        "cdate": 1698823350468,
        "tmdate": 1699636061343,
        "mdate": 1699636061343,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NabsOhLZzW",
        "forum": "oTWhkg5Ed4",
        "replyto": "oTWhkg5Ed4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_jb5q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1340/Reviewer_jb5q"
        ],
        "content": {
            "summary": {
                "value": "The paper employs prompt tuning to the previous UNet + stable diffusion solutions for semantic matching. It also introduces a new conditional prompting module to condition the prompt on the local details. These two elements contribute to the proposed method SD4Match to achieve higher accuracy than existing methods on three benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Applying prompt tuning for SD based semantic matching methods is new.\n\nThe proposed conditional prompting module is reasonable for the semantic matching task.\n\nThe superior results than previous works on the standard benchmarks."
            },
            "weaknesses": {
                "value": "The paper lacks comparison to typical semantic matching methods based on deep graph matching, such as \n[1] Joint graph learning and matching for semantic feature correspondence, PR, 2023\nFrom the results in [1], the paper can not beat many existing works. Further explanations and validation are required.\n\nAs the paper lacks comparisons to some highly related works, the paper also misses to discuss a majority works on semantic correspondence, for instance,\n[1] Deep graph matching via blackbox differentiation of combinatorial solvers, ECCV 2020.\n[2] Deep Graph Matching under Quadratic Constraint, CVPR, 2021.\n[3] GLMNet: Graph learning-matching convolutional networks for feature matching, PR, 2022."
            },
            "questions": {
                "value": "There is query feature extraction for the I^A, how about put this on the I^B side? Does this will affect the final results?\n\nThe complexity analysis about the training and run time can be included in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1340/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826754847,
        "cdate": 1698826754847,
        "tmdate": 1699636061267,
        "mdate": 1699636061267,
        "license": "CC BY 4.0",
        "version": 2
    }
]