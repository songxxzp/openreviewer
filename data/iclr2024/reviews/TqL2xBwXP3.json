[
    {
        "id": "aLr8uJtKCN",
        "forum": "TqL2xBwXP3",
        "replyto": "TqL2xBwXP3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission776/Reviewer_92yi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission776/Reviewer_92yi"
        ],
        "content": {
            "summary": {
                "value": "This paper explores possible ways to extract and tease out the geospatial information embedded inside the knowledge bases like LLMs. Specifically, they fine-tune LLMs such as chatGPT and Llama-2 with training data curated using OpenMaps with labels derived from various sources for geospatial tasks. On a variety of tasks, they show that fine-tuning LLMs on such data can effectively outperform several baselines. They further establish the geographical consistency of their results as well as ablation on suitable prompts."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper reveals an innovative way to use LLMs towards a expert tasks such as computing geospatial metrics without access to various kinds of data. \n\n- The access to various covariates, as mentioned, might not always be available - so the motivation of this work is sound and valid.\n\n- The experiments cover a wide variety of tasks and settings, indicating the power of the proposed approach.\n\n- The experiments involve comparison between multiple LMs like RoBERTa, GPT3.5 and LLama-2, with several useful observations pertaining to performance as well as the data efficiency of each of those."
            },
            "weaknesses": {
                "value": "- There are no experiments which really delineate where the performance improvements of the final model are coming from. The chosen baselines are not that strong. To delineate the knowledge offered by the LLMs compared to that of the training data, can the authors also conduct an experiment where they fine-tune a normal neural network (not LLM) on the created training data? For example, we can first pass the prompt to a sentence encoder, and then train an MLP/Neural Network which uses this embedding to predict the output as a regression or classification task  (using the same training data used during fine-tuning). This would separate the contributions offered by the LLM compared to the training data which was used in fine-tuning. \n\n-  Adding to the above, can the authors also provide results with using zeroshot capabilities of the LLMs? This would help to separate the importance of fine-tuning on custom prompts. \n\n- Assuming the covariates are indeed available, does the current method offer complimentary benefits to further improve the performance?\n\n- The authors, if possible, should also make comparisons with fine-tuning several other geo-spatial LLM type models, like K2 (Deng et. al. 2023) through fine-tuning on the same set of data."
            },
            "questions": {
                "value": "Overall, I have several requests to further delineate the performance improvements due to various aspects, while also using stronger baselines as detailed above. I am ready to raise my rating upon satisfactory rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697854081317,
        "cdate": 1697854081317,
        "tmdate": 1699636005182,
        "mdate": 1699636005182,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WXyNXhlg5X",
        "forum": "TqL2xBwXP3",
        "replyto": "TqL2xBwXP3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission776/Reviewer_Gcfb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission776/Reviewer_Gcfb"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new method called GEOLLM, which can effectively extract spatial knowledge from large language models and fine tune it by using auxiliary map data from OpenStreetMap. Experiments on various tasks of several large-scale real-world sets show that the method is practical and effective. In the experiment, the author found that the pre-training language model has rich geospatial knowledge, and their method can unlock this knowledge. In addition, the author also discusses how to construct appropriate hints to extract geospatial knowledge, and how to find a balance between knowledge extraction and sample efficiency.\nThe contributions of the paper include demonstrating the quantity, quality, and scalable nature of geospatial knowledge contained in LLMs and presenting a simple and efficient method for extracting this knowledge."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1: This paper delves into the internal structure of large-scale language models in extracting geographical knowledge. Utilizing auxiliary map data from OpenStreetMap to extract geospatial knowledge from large language models represents a new approach that has been sparingly explored in previous research. By fine-tuning basic models of different structures and scales and employing prompt templates containing addresses and nearby places, geographical knowledge within pre-trained models is effectively extracted. \nS2: In terms of significance, this paper addresses a challenge in natural language processing by exploring how to extract geospatial knowledge from large-scale language models. The paper proposes a new approach to knowledge extraction based on fine-tuning and prompt strategies, establishing a new concept of \"geospatial covariates.\""
            },
            "weaknesses": {
                "value": "W1: Lack of clear prompt templates and answer pairs design. The paper mentions the use of multiple data sources and various tasks; however, there are significant deficiencies in the theoretical approach. Specifically, the paper does not clearly specify whether the prompt formats are the same for each task and lacks detailed descriptions of how prompt templates and answer pairs were designed for different tasks. This lack of clarity makes it challenging for readers to understand the experimental design and poses obstacles for replication and further research.\nW2: Lack of clear experimental design details. Furthermore, in terms of experimental design, there are shortcomings in this paper. It does not provide a clear overview of the experimental training process, including the selection of data, preprocessing steps, and hyperparameter tuning. This omission makes it difficult to evaluate the detailed experimental procedure, hindering the reproducibility of the experiments.\nW3: Absence of comparison with ground-truth. Additionally, the paper does not thoroughly explore the comparison between experimental results and real-world geospatial data (Ground Truth). Accuracy of geospatial knowledge is crucial in practical applications; however, the paper lacks comparative analysis with actual geographical data."
            },
            "questions": {
                "value": "Besides what is mentioned in weaknesses, what does \u201cthe prompts\u2019 mean in \u201cThis suggests that the model is less prone to overfitting on the prediction tasks compared to the prompts\u201d on page 4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Reviewer_Gcfb"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698635351028,
        "cdate": 1698635351028,
        "tmdate": 1699636005086,
        "mdate": 1699636005086,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sbi9HCKfrX",
        "forum": "TqL2xBwXP3",
        "replyto": "TqL2xBwXP3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission776/Reviewer_tFFk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission776/Reviewer_tFFk"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes GeoLLM, a prompt method that enriches geographic coordinates with auxiliary map data for geospatial prediction task (e.g., population density, economic livelihoods). This prompt approach outperforms some baseline methods in several tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.  This paper is well structured and good at the clarity of presentation.\n\n2.  The significance of the problem is high, potentially impacting a wide range of geospatial applications and offering a new way to view large language model capabilities.\n\n3. The paper provides a detailed discussion of how large language models can be linked to geospatial applications. This can potentially bring new research opportunities to the field of spatial data mining."
            },
            "weaknesses": {
                "value": "1.  The method presented seems to build incrementally on existing methodologies to generate auxiliary texts for prompt engineering, which may not represent a significance in technical novelty.\n\n2.  The scope of experiments could be further expanded to support the conclusion. Please consider the Questions below for details."
            },
            "questions": {
                "value": "1.  While Peason's r^2 is used for comparisons with previous literature, can I see more comparisons with baselines on other evaluation metrics like MAE or MSE?\n    \n2.  Could the paper present the label distribution to evaluate performance variations between urban and rural areas, or densely versus sparsely populated regions?\n    \n3.  It would be beneficial to include a wider range of baselines, particularly \"weaker\" text embedding models like Doc2Vec, ELMo, and BERT, paired with basic predictors, for a holistic performance comparison.\n    \n4.  I tried to use GPT 4.0 for the example in Figure 1, and it looks like it can solve this question pretty well with only coordinates:  \n    \"\"\"User: Coordinates:  \n    (40.76208, -73.98042)  \n    Population Density (On a Scale from 0.0 to 9.9):\n    \n    ChatGPT:  \n    Given the coordinates (40.76208, -73.98042), this location is in New York City, specifically in Manhattan. Manhattan has one of the highest population densities of any area in the United States.  \n    On a scale from 0.0 to 9.9, where 9.9 would represent the most densely populated, Manhattan would be close to the top of that scale. While I can't provide an exact number without more specific criteria for each point on the scale, it would be reasonable to rate Manhattan, particularly Midtown which is where these coordinates roughly point to, above 9.0 on a density scale capped at 9.9, considering its population density surpasses 10,000 people per square kilometer.\n    \n    User:  \n    Just return a number\n    \n    ChatGPT:  \n    9.5  \n    \"\"\"  \n    The paper could enhance its soundness by examining the performance with more powerful LLMs. Performance insights using LLama 13b and 70b, as well as the latest GPT-4 model, would be valuable.\n\n\n\n\n5.  Can I see the performance on LLMs without finetuning? It would be necessary to see the impact of fine-tuning in geospatial predictions.\n    \n6.  Few-shot learning capabilities are an intriguing aspect of LLMs. An analysis of the model\u2019s few-shot performance, both pre and post fine-tuning, could significantly add to our understanding of the method's efficiency and flexibility.\n    \n7.  The current ablation study does not fully clarify the independent contribution of coordinates to the model's performance. Results from experiments that exclude coordinates from prompts would help demonstrate that the enhanced performance is not solely attributable to the auxiliary map data."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636574936,
        "cdate": 1698636574936,
        "tmdate": 1699636005028,
        "mdate": 1699636005028,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Hqj5SHk7RV",
        "forum": "TqL2xBwXP3",
        "replyto": "TqL2xBwXP3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission776/Reviewer_5MUc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission776/Reviewer_5MUc"
        ],
        "content": {
            "summary": {
                "value": "This study explores leveraging large language models (LLMs) for geospatial prediction tasks, addressing limitations of traditional covariates like satellite imagery. The authors introduce GeoLLM, an approach that effectively extracts geospatial knowledge from LLMs with auxiliary map data. The proposed method demonstrates a 70% improvement in performance compared to baselines, rivaling satellite-based benchmarks. GPT-3.5 outperforms other models, highlighting the scalability of the proposed approach. This research underscores LLMs' efficiency, global robustness, and potential to enhance geospatial analysis."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It proposed a novel method for efficiently extracting geospatial knowledge from large language models.\n2. The paper outlined experiments to evaluate extracting geospatial knowledge from large language models, which included constructing a comprehensive benchmark, developing a robust set of baselines, and presenting results and an ablation study.\n3. The paper revealed that GeoLLMs are sample-efficient, rich in geospatial information, and robust across the globe."
            },
            "weaknesses": {
                "value": "1. The paper does not provide a detailed analysis of the potential biases of LLMs and their training corpora. \n2. It would be better to compare the GeoLLM\u2019s performance with the results from satellite images."
            },
            "questions": {
                "value": "Have you tried the zero-shot or few-shot performance of various LLMs on the presented tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission776/Reviewer_5MUc"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727384428,
        "cdate": 1698727384428,
        "tmdate": 1699636004954,
        "mdate": 1699636004954,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2m1HJE2dOK",
        "forum": "TqL2xBwXP3",
        "replyto": "TqL2xBwXP3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission776/Reviewer_xypS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission776/Reviewer_xypS"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a method to extract prior geospatial knowledge from pretrained LLM. \nThe queried knowledge includes spatial demographics data, census data, and survey data. \nThe findings in the paper are interesting, however seem very preliminary. And the experiments are limited."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is well presented, and the experiments cover several different geospatial datasets and tasks in relation to census and demographic data."
            },
            "weaknesses": {
                "value": "\u2022\tIt seems that the proposed GeoLLM can only perform one specific task. After fine-tuning, is the fine-tuned LLMs (e.g., GPT-3.5) able to retain the ability to answer general questions that is not related to the specific task? Including some discussions about the generalization part could be useful.\n\n\u2022\tThe proposed model can only handle static/tabular geo information. It does not handle other types of spatial data, or spatiotemporal data and tasks.\n\n\u2022\tBaselines are too simple. Considering some more recent deep-learning-based or Transformer-based baselines could be more convincing.\n\n\u2022\tThe experiments are limited."
            },
            "questions": {
                "value": "\u2022\tIs there any specific tokenization process introduced for GPS coordinates? Normally, the direct tokenizers with LLMs could split the GPS point into several different tokens, which might undermine the ability to understand GPS coordinates correctly.\n\n\u2022\tWhy using classification setting? The current loss functions that LLMs are using is a kind of binary, where only predictions that exactly match the masked word are considered correct and rewarded, while all other predictions are considered incorrect and penalized. So, there is no has no awareness and no sense of being close to or far away the correct answer. Normally, for the task described in this paper, this kind of sense should be valuable in getting better performance.\n\n\u2022\tWhat about the deployment cost of the proposed GeoLLM? For example, compared to the baselines, what are the fine-tuning costs and inference costs of using GPT-3.5 or other LLMs. From my experience, fine-tuning GPT-3.5 can be very expensive."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698756039090,
        "cdate": 1698756039090,
        "tmdate": 1699636004862,
        "mdate": 1699636004862,
        "license": "CC BY 4.0",
        "version": 2
    }
]