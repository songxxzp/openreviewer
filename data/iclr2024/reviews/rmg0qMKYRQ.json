[
    {
        "id": "s6PwTgj3M1",
        "forum": "rmg0qMKYRQ",
        "replyto": "rmg0qMKYRQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_QCiG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_QCiG"
        ],
        "content": {
            "summary": {
                "value": "The tradeoff between generative and discriminative classifiers is a long-running issue in ML research (the earliest that I can recall is Andrew Ng's paper in the early 2000s).  It's generally been understood that generative classifiers can be more robust and more sample efficient but suffer if the generative model is mis-specified or under-powered.  Due to progress in the quality of generative models, it is worthwhile to revisit this tradeoffs, and it seems that generative classifiers now have realized these substantial advantages in robustness.  This paper is a useful contribution to this ongoing research trend by performing more detailed analysis on the inductive biases of generative classifiers.  \n\nnotes: \n  -Discriminative vs. generative classifier analysis.  \n  -Analysis is that generative classifiers have much higher shape bias, good OOD accuracy, alignment with human errors, and understand some perceptual illusions.  \n  -Generative classifier adds noise and reconstructs with the class label as the prompt, and then the reconstruction error is used to classify."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-The findings of this paper are interesting, and shows the power of generative classifiers in OOD accuracy as well as consistency with human classification.  \n  -The discussion is generally interesting, and I liked the idea that deficiencies of generative models could be probed through this approach (for example the inability to recognize rotated images as well as humans).  \n  -The study on the duck-rabbit and old woman - young woman illusions are nice."
            },
            "weaknesses": {
                "value": "-This is an analytical study of an existing approach with existing methods.  The general direction of the findings is also not terribly surprising, although the exact degree of the results and the precision of this study is still useful I think."
            },
            "questions": {
                "value": "-Do you think it would be possible to distill the generative classifier into a much stronger discriminative classifier, so that the computational benefits could be achieved while improving robustness and other properties like shape bias?   \n\n-Have you thought about probing to find places where discriminative classifiers have an advantage over generative classifiers?  Conceptually, I might try to think about types of images or classes which generative models are currently unable to generate well."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Reviewer_QCiG"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698769592480,
        "cdate": 1698769592480,
        "tmdate": 1699636214069,
        "mdate": 1699636214069,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C5RDIWTc8p",
        "forum": "rmg0qMKYRQ",
        "replyto": "rmg0qMKYRQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_tjak"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_tjak"
        ],
        "content": {
            "summary": {
                "value": "This submission compares recently proposed generative image classifiers to human perceptual decisions. It builds on a previous work (Clark & Jaini, 2023) which suggested employing image generation models as \"analysis-by-synthesis\" classifiers: Each test image is classified by attempting to reconstruct a noised version of it, conditioned on different classes. The class that best supports the reconstruction is chosen as the classifier's prediction. This approach is similar to that proposed by Schott, Rauber, Bethge & Brendel (ICLR 2019), but it leverages state-of-the-art generative AI to form generative classifiers, instead of relying on the non-scalable solution of class-specific variational autoencoders.\n\nIn the current work, three such generative classifiers (based on Stable Diffusion, Imagen, and Parti) are compared to human decisions through evaluation on out-of-distribution challenges published by Geirhos, et al., NeurIPS 2021. In addition, the ability of the classifiers to comprehend bi-stable stimuli is assessed. The experiments find high human-alignment of the proposed generative classifiers, rivaling almost all previously tested models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The task of comparing contemporary generative classifiers with discriminative classifiers in terms of human alignment is both important and timely. Generative modeling might be key to emulating human perceptual behavior.\n2. Overall, the evaluation is well-executed and includes a wide array of benchmarks.\n3. Including three different generative classifiers enhances the generality of the results.\n4. The new experiments using ambiguous stimuli are both creative and compelling.\n5. The control analysis, in which a ResNet is trained with additive image noise, sheds light on confounding factors in play."
            },
            "weaknesses": {
                "value": "1. My primary concern is whether the alignment between the generative models and human behavior should be attributed to the models' generative nature or their rich semantic representations. In this context, a particularly relevant comparison is between CLIP and Stable Diffusion. Both models employ the same semantic representation, while CLIP is discriminative and Stable Diffusion is generative. However, CLIP demonstrates better OOD accuracy and error consistency than Stable Diffusion. Stable Diffusion outperforms CLIP as a human perception model only in the shape-bias benchmark. However, as suggested by the control experiment, this effect might be attributed to the high-frequency content of the additive noise.  \nFor Imagen, there is no corresponding discriminative counterpart; such a counterpart would require training a network to map images to T5-XXL encodings. Given the absence of such a control, Imagen's alignment with human perception does not provide strong evidence in favor of generative models over discriminative models.  \nIn summary, the reported results do not conclusively indicate whether human alignment necessitates generative modeling or merely rich semantic representation. The authors could strengthen the submission by addressing this issue, either through new experiments or by revising the conclusions and abstract to reflect the existing uncertainty.\n\n2. The clustering analysis is misleading, since CLIP has better error consistency than most of the generative classifiers. I would omit this analysis completely.\n\n3. The lack of an open code repository undermines the transparency and potential impact of the submission."
            },
            "questions": {
                "value": "- The loss guiding the classification score (Eq. 2) averages the error over the entire diffusion process. How does the model behavior compare if only the final, resulting image is considered? \n- The authors may wish to cite Golan, Raju & Kriegeskorte (2020, PNAS), which showed evidence of greater human alignment of generative classifiers over discriminative classifiers in simpler image domains."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2718/Reviewer_tjak"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698860753215,
        "cdate": 1698860753215,
        "tmdate": 1701008546592,
        "mdate": 1701008546592,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BI5i4ekMUK",
        "forum": "rmg0qMKYRQ",
        "replyto": "rmg0qMKYRQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_e2eW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2718/Reviewer_e2eW"
        ],
        "content": {
            "summary": {
                "value": "The paper revisit the idea of generative classifiers, which performs classification based on comparing class-conditional likelihood of a generative model, particularly focusing on the recent state-of-the-art generative models such as Imagen, Stable Diffusion, and Parti. The paper conducts a set of extensive comparison between discriminative vs. generative modeling paradigm, including comparisons in terms of shape bias, out-of-distribution accuracies, and error consistency, largely adopting the setups from Geirhos et al., 2021. The experimental results highlight that generative classifiers with state-of-the-art models are now capable, unlike previous attempts, to achieve human-like shape bias and OOD-accuracy, also advancing the error consistency with respect to humans."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, the presentation is very clear, and the manuscript is well-written. The introduction section nicely summarizes the historical and related literature on generative classifiers, which can help the readers. I think the significance of empirical results are the key novelty of the paper. As an additional point, the method considered in this paper is simple and easy-to-implement."
            },
            "weaknesses": {
                "value": "I do not see major weaknesses from the paper. Although I do not much concern about it, some readers may do regarding the lack of technical novelties, considering the previous methods on generative classifiers. As a minor point, I think a more discussion with \"ViT-22B-384 trained on 4B images\", given that this discriminative model is still fairly possible to be considered as a competitive state-of-the-art compared to the generative modeling results that the paper highlights."
            },
            "questions": {
                "value": "- Technically, it seems the paper applies different resizing resolutions for different generative models considered - e.g., 64x64 for Imagen and 512x512 for Stable Diffusion. I would like to see a discussion on the more reasons for this and its effect to the final performance. \n- If possible, it would be helpful for the readers if there could be any discussion on practical considerations and design choices on the proposed method. It seems the current version ended up with computing pixel-wise mean-squared errors to measure conditional likelihoods, but wonder if there was other considerations in attempts to improve the performance of generative classifier. Such an ablation study would help for the future research on developing generative classifiers."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698884526144,
        "cdate": 1698884526144,
        "tmdate": 1699636213918,
        "mdate": 1699636213918,
        "license": "CC BY 4.0",
        "version": 2
    }
]