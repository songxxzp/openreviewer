[
    {
        "id": "ylCnEYtXMQ",
        "forum": "JAfGlmRBTU",
        "replyto": "JAfGlmRBTU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission297/Reviewer_iE1G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission297/Reviewer_iE1G"
        ],
        "content": {
            "summary": {
                "value": "In this manuscript the authors present their COMPOSER scheme how object hierarchies might be represented in biological neural networks by synchrony of neural responses. The synchrony is created by using a denoising autoencoder on the network representation whose output drives neurons one period of the oscillation later. By linking the representations at two levels of a hierarchy the authors can additionally create a rough synchronisation of the parts and the whole representations that are represented at the two depths."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Synchrony of responses is still discussed as a possibility for binding in neuroscience and this manuscript implements a model that creates such synchrony for neurons encoding the same object or part. By running a similar process at different levels of the hierarchy a object and part hierarchy can be represented in a fixed neural architecture. And Composer is a spiking neural network with full temporal dynamics."
            },
            "weaknesses": {
                "value": "I do not think this is a convincing model of processing in visual cortex or a good starting point for machine learning and computer vision models. \n\nFrom the perspective of artificial systems synchrony based approaches are not really of interest from the start as similarity for inferring objects and parts can be implemented much more efficiently by simply computing the information that is encoded in the phase explicitly.\nThe scheme proposed here is only evaluated on extremely simple tasks, without any comparisons to other techniques, which is not convincing that the authors\u2019 technique works particularly well, even for these simple tasks.\n\nAdditionally, COMPOSER is implemented only for simple displays and simple shallow architectures. As the authors admit it additionally has a bad scaling behaviour because a different phase is required for each part of every object in the scene. For natural scenes this approach is not expected to work. And we have working segmentation algorithms that can do segmentation at any level of the object hierarchy. These approaches appear clearly better suited for computer vision than the one proposed here.\n\nI also think the less relevant aspect of a model of biological vision is not really fulfilled by this model, because of the scaling issues and because this model implies parallel processing of objects everywhere. Clearly humans can deal with natural levels of complexity and it is well documented that object parsing takes time and proceeds sequentially, i.e. humans cannot do segmentation for all objects in a scene at once as this model would suggest. Also, the levels of synchrony observed in the networks here go far beyond anything I have ever seen in a visual cortex."
            },
            "questions": {
                "value": "The manuscript seemed fairly clear to me and I don\u2019t have questions for the authors.\nIn general options to improve my impression of this work would be any push towards realistic levels of complexity and/or demonstrations of overall segmentation behaviour that aligns with our knowledge about human vision. \n- For example, making this work on natural stimuli, or at least something with a background or more objects and parts than fit into different phases. \n- Or inclusion of a spatial propagation of the recruitment or an attention like mechanism that can choose which object to extract.\n- Or just comparisons to any other algorithms performing the same tasks.\n- Or comparisons to the alternative ideas how object segmentation might be represented in visual cortex like attentional facilitation spreading, an explicit representation of local similarity, or the hierarchy assignment.\n- Etc. \n\nThese would be substantial revisions of the manuscript that I do not expect to see in the revision period though and thus expect to keep my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698788877207,
        "cdate": 1698788877207,
        "tmdate": 1699635956147,
        "mdate": 1699635956147,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tleXmJeXPO",
        "forum": "JAfGlmRBTU",
        "replyto": "JAfGlmRBTU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission297/Reviewer_JZAs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission297/Reviewer_JZAs"
        ],
        "content": {
            "summary": {
                "value": "This work presents a dynamical network-based solution to the problem of representing part-whole hierarchy in artificial neural networks. They propose a model, Composer, which consists of two-layers of neurons that mimic lower and higher visual areas, which form assemblies to represent parts and whole, respectively. The model uses a denoising autoencoder to encourage finding metastable attractors in the spike coding population, which consists of (largely) rate-based neurons that emit spikes with refractory periods. Furthermore, the authors create a set of toy tasks and a metric that evaluates the performance of the proposed model, and compares it to a SOTA model for visual part-whole parsing."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The introduction of the paper (and Fig.1) explains the part-whole hierarchy representation problem quite clearly, with behavioral and neuroscientific evidence as motivation. The intuition behind the proposed model (e.g., Figure 2) is also nicely illustrated. The creation of several benchmark toy tasks as well as a metric is commendable, so is the comparison to a SOTA model, and ultimately, demonstrates that the proposed model works. Overall, it\u2019s an interesting paper which tackles a very high-level problem with a novel brain-inspired model."
            },
            "weaknesses": {
                "value": "1. it\u2019s unclear how the model actually works, even though the explanation of the architecture is clear. I\u2019m not sure if I understood correctly the important mechanisms, but it feels a bit magical that it \u201cjust worked\u201d, and that assemblies naturally emerged. Was there parameter learning or network training, either beforehand or during a single stimulus? Or is it really the case that a stimulus is simply presented and both whole and part assemblies simply arise over time? If the latter case, how sensitive are the results to specific values of the parameters. While the ablation study is nice, setting the various values to zero is somewhat dramatic and uninformative, and I\u2019m rather wondering how precise the parameter values must be, e.g., tau_r, for the network to work. It\u2019s also a bit unclear to me what exactly the DAE is doing, though Figure 10a suggests that they are trained a priori?\n\n2. the proposed model, given the stated motivation of the paper, was somewhat underwhelming for me. If I understood correctly, the \u201cspike coding space\u201d layers simply receive input, one neuron per pixel, and while they do emit spike, there is no recurrent interaction within the SCS (as a standard spiking NN would), nor is it really \u201cspiking\u201d, since the rates are the governing variables and multiplicatively gated across layers, but the spikes are simply emitted with a given\u2014and precisely set\u2014refractory time. If this is correct, it\u2019s difficult to judge how robust the setup is (i.e., parameter sensitivity), as well as how generalizable this mechanism is. The connections to neural circuits are quite loose, and I think calling it a \u201cbio-plausible\u201d framework is an overstatement. \n\nTaken together, my limited reading of the work is that it\u2019s a very \u201chandcrafted\u201d model / toy solution to an important and general problem, but ultimately falls short of making a convincing contribution."
            },
            "questions": {
                "value": "- Some clarification or intuition on how the model works would be informative, i.e., are there just naturally emerging assemblies after letting it run for long enough? What does the DAE do and how is it trained (if it is)?\n- Is there no parameter tuning? how does the \u201cwhole\u201d-level population naturally fire with longer periods (e.g., Fig7b?)? Or is it very sensitive to specific parameter values (e.g., delay and refractory timescales), and if so, are the findings of the study generalizable to either learning something about the brain or improving practical ML algorithms?\n- axis scaling between different tasks for Fig 8, esp panel d, is misleading\n- What is the downstream decoder? Since the entire image is represented partially through time, how is the parsing score computed? Is it aggregated / smoothed over some time window? If so, how does one choose this window and is it realistic for a decoder in the brain to perform this?\n- The study does not really acknowledge any limitations, in particular how much the proposed model deviates from its stated goal of \u201cbio-realistic\u201d implementation. The most obvious example is that the spiking is quite artificial (as explained above).\n- Similarly, the lack of recurrent activity between neurons within a SCS layer seems very implausible, compared to cortical assemblies in the real brain. In this work, the assemblies arise due to the DAE forcing them into metastable attractors (I think?), whereas cortical assemblies are typically formed via connectivity, especially to and from inhibitory neurons.\n- The introduction raises several points that existing models fail at, e.g., \u201cthe parse tree could switch among multiple reasonable forms even given a single scene\u201d, i.e., \u201ccorrect\u201d parsing is context-dependent. While this is true, the proposed model also does not deal with this (or does it?)\n- The proposed relationships to the canonical cortical microcircuit, e.g., Figure 2g, doesn\u2019t really add much value, in my opinion\n- Does the model even need the timescale hierarchy? At it\u2019s core, each layer simply has assemblies that represent some specific part of the image, and it seems like persistent firing with the different assemblies that temporally coincide is sufficient for solving this task\n- in-line citations are not bracketed, which is very distracting\n- figure text is way too small, e.g., Fig 5c & 8a legend box is illegible; similarly, very hard to tell different colors of spikes in 7c\n- Some citation on the formation of, and computing via neuronal assemblies may be appropriate (e.g., L. Mazzocato, J Gjorgjieva, etc.)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Reviewer_JZAs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698847199177,
        "cdate": 1698847199177,
        "tmdate": 1699635956047,
        "mdate": 1699635956047,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BQBlOVqJvR",
        "forum": "JAfGlmRBTU",
        "replyto": "JAfGlmRBTU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission297/Reviewer_FiYe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission297/Reviewer_FiYe"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a spiking neural network to parse images into parts and wholes. A denoising auto-encoder is trained on single-object images. This auto-encoder is integrated into a hierarchical network with both bottom-up and top-down connections. Running the network forward eventually leads it to converge to oscillatory dynamics which are indicative of the whole-parts relationship in the image."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This work addresses an important question in the literature, for which much ink has been spilled: how does binding work? From the Gestalt psychologists to Singer and Buszaki to Hinton and his capsule networks, this question has been identified as both interesting and very hard to pin down. The authors do a good job of framing the problem (Figures 1 and 2). They assemble some reasonable toy datasets and show that it works on those. The evaluation using Victor-Purpura spike train metrics is interesting."
            },
            "weaknesses": {
                "value": "I found this paper really hard to read past the introduction, and I cannot identify its main technical contribution. They detail the training method in the 30+ page appendix (unacceptably long) and I cannot figure out why it should do any useful work given that it's so simple. I cannot convince myself that the network does something useful; the benchmarks are very easy, and I don't understand why their baseline gets a score of 0.\n\nThe citations are badly formatted and there are many awkward phrasings. It needs proofreading\u2013automated tools like Grammarly or ChatGPT would suffice."
            },
            "questions": {
                "value": "How is the network trained? It seems like a DAE is trained in isolation and that network is assembled out of the pieces of that network. I don't understand why the network weights don't need to be adjusted once embedded in a spiking recurrent neural network. This info needs to be in the main text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission297/Reviewer_FiYe"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698876491160,
        "cdate": 1698876491160,
        "tmdate": 1699635955779,
        "mdate": 1699635955779,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1k45ahEHq8",
        "forum": "JAfGlmRBTU",
        "replyto": "JAfGlmRBTU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission297/Reviewer_denz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission297/Reviewer_denz"
        ],
        "content": {
            "summary": {
                "value": "The authors propose COMPOSER, a new framework for modeling part-whole hierarchical object representations in neural networks. Composer is an architecture obtained by combining aspects of deep learning (denoising autoencoders trained in a self-supervised manner) and computational neuroscience (spike timing, synchrony, layered-organization in the neocortex, etc) trained it in a self-supervised manner. The authors propose a suite of benchmarks to evaluate the ability of models to parse a visual scene into part-whole hierarchies of objects present in the scene, and propose metrics corresponding to this evaluation. The authors show evaluations on the proposed datasets both qualitatively and quantitatively showing that neurons in Composer show emergent part-whole grouping, with lower-level neurons encode part- features and higher-level neurons encode whole- features."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Representing part-whole hierarchy in neural representations is a challenging open problem that both machine learning and cognitive science researchers find interesting. The paper proposes a complete package to model and evaluate part-whole parsing in neural networks.\n- The proposed datasets and corresponding metrics are a useful contribution to further research in this domain. That being said, the proposed metrics are suitable only for evaluating spiking neural network models of scene parsing (authors, please correct me if I'm wrong in my understanding here with more elaboration on how to evaluate non spiking networks too)\n- I appreciate that authors share the code to reproduce the results presented here."
            },
            "weaknesses": {
                "value": "- Lack of ablations: Composer is quite a complicated architecture and has many moving parts to it. The authors haven't justified how they arrived at this architecture, and if all its components are useful for the downstream task. They need to ablate individual components and report the value of each of them to justify such a complicated architecture.\n- Metrics used aren't explained very clearly: The authors could further explain part-score and whole-score more clearly, maybe with visualizations of part- and whole- segmentation with low and high part- / whole- scores to make the readers understand the used metrics. Without a clear understanding of what these metrics are doing, many figures and visualizations aren't accessible. \n- Writing: It feels like the authors have tried to compress a lot of important information into the main text (and appendix) as a result of which clarity of the writing has dropped. There is some inspiration from neuroscience in the spiking and synchrony modeled in Composer, however I felt the description of composer to be unnecessarily heavy on neuroscience-oriented jargon. \nE.g. 1) superficial spike-coding space, what does 'superficial' stand for here? 2) what does 'abstract' refractory period mean? did you mean to say absolute refractory period? 3) I didn't find it necessary to mention that neurons in the architecture are pyramidal neurons unless there is some anatomical/computational inspiration of pyramidal neurons in composer.\n- (nit) Formatting issues: I believe many citations are in the wrong format, quotes are wrongly formatted (two close quotes used in place of open and close quotes), multiple spelling errors (Cotical -> cortical in the first mention of Composer's full form) need to be corrected."
            },
            "questions": {
                "value": "Please refer to my main review's weaknesses section for questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698978136672,
        "cdate": 1698978136672,
        "tmdate": 1699635955600,
        "mdate": 1699635955600,
        "license": "CC BY 4.0",
        "version": 2
    }
]