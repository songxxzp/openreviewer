[
    {
        "id": "C1sQzhiFiy",
        "forum": "X5u72wkdH3",
        "replyto": "X5u72wkdH3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_QJht"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_QJht"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the unsupervised crowd counting task, a critical yet challenging task. To achieve this goal, the authors use latent diffusion models to create two types of synthetic data and then utilize the ranking image pairs for pre-training and fit a linear layer to the noisy synthetic images using these crowd quantity features. Experiments conducted on five datasets demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(a) Using stable diffusion to generate the crowd dataset is a good idea, providing a new perspective for this area. \n(b) This paper is written well and easy to follow"
            },
            "weaknesses": {
                "value": "1. For the fully supervised part, the authors only discuss the density-based crowd counting methods. In other words, many localization-based methods should be discussed, making the related work more comprehensive.\n\n2. The authors have pointed out that the prompt count is not reliable but using it as the GT count directly during the training phase. It makes me confused. I think it would be better to rank the generated 60 images using the pre-trained backbone first. Secondly, fine-tune the GT count according to the ranking results. Specifically, image A and image B are generated using the same prompt count 20. However, ranking results present that image A contains fewer persons than image B, so the GT count of image A could be fine-tuned to be smaller than the GT count of image B.\n\n3. I understand that the input of the generation process is complete images without cropping, but the inference process uses image patches as input. There may be resolution gaps. How about cropping the original images into patches in the generation process instead?\n\n4. There is a lack of quantitative analysis about the reliability of the generation process. Specifically, the authors can sample n source images for generation and statistics on the percentage of images where the objects were successfully removed.\n\n5. The authors think the ranking information is reliable, and the prompt count is relatively unreliable. Thus, the authors pre-train the backbone using the ranking information and freeze the backbone during the training phase to resist the prompt count noise. I agree that the ranking information is more reliable. However, I am not sure it is necessary to fix the backbone as only fine-tuning the linear layer may limit the learning potential on the prompt count, which is considered ground truth. There could be an ablation study on fine-tuning the backbone during the training phase.\n\n6. Since the current method is still significantly lower than CrowdCLIP, the authors think the early stop used in CrowdCLIP might be unfair. So I would like to know the performance under early stop.\n\n7. The motivation to synthesize the ranking crowd image is still unclear since one can utilize the existing datasets to generate the ranking image pairs, like CrowdCLIP."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698571355081,
        "cdate": 1698571355081,
        "tmdate": 1699636384891,
        "mdate": 1699636384891,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tzaPPFH5CY",
        "forum": "X5u72wkdH3",
        "replyto": "X5u72wkdH3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_rbvA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_rbvA"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an unsupervised counting method that utilizes latent diffusion models to create synthetic data. The approach involves two unsupervised techniques: first, removing pedestrians from actual images, resulting in ranked image pairs that provide a ranking loss of object quantity. Second, generating synthetic images with a predetermined number of objects, which gives a noisy but related counting label."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of utilizing a stable model to generate synthetic images seems feasible.\n- The paper introduces two strategies: a weak but reliable object quantity signal and a strong but noisy counting signal. This approach seems quite reasonable, as it can potentially complement and enhance the model's performance."
            },
            "weaknesses": {
                "value": "- What is the rationale behind the setting of N, which is the crowd count to generate synthetic images? What is the quality of the generated images? Is it possible to provide a measure of variance to assess the feasibility of this method? \n- There are only six categories for N. Why not train the model by a classification task? In situations where the labels are not stable, the classification task seems to be able to maintain a relatively high level of accuracy.\n- The synthetic images do not include images with 0 crowd count. Does this method have the capability to handle datasets that consist of a large portion of (background) images with no people, such as NWPU?\n- How does the computational cost of generating synthetic images using the diffusion model compare to that of other unsupervised counting models?\n- There are some repetitions in the references."
            },
            "questions": {
                "value": "-  Figure 6 illustrates that the features exhibit an underlying crowd-count-based ordering. However, it would be more convincing if features from supervised counting models could be provided for comparison.\n- In Table 3, the methods proposed in the paper actually include ImageNet pretraining. What is the performance when combining ImageNet pretraining with intra-image ranking?\n- Does the ranking loss merely train the model to distinguish between real and synthetic images?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793825814,
        "cdate": 1698793825814,
        "tmdate": 1699636384816,
        "mdate": 1699636384816,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AI7IvW0KS3",
        "forum": "X5u72wkdH3",
        "replyto": "X5u72wkdH3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_98cL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4186/Reviewer_98cL"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an unsupervised crowd counting approach based on synthetic data. Specifically, it generates synthetic data through stable diffusion with a selected prompt and then employs the rank loss and a count loss for prediction. The excellent experimental results demonstrate the advantages of the proposed unsupervised method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea is novel and the experimental results demonstrate the advantages of the proposed unsupervised method."
            },
            "weaknesses": {
                "value": "A deep analysis of the experimental results is not provided."
            },
            "questions": {
                "value": "1. Could the author provide a more comprehensive explanation for Figure 6? Both small and large counts are distributed throughout the entire space in the QNRF dataset. It is difficult to interpret the UMAP results without any explanation.\n2. What is the advantage of generating synthetic data via stable diffusion, especially when compared with the large synthetic dataset GCC[1]? Both approaches are label-free, but GCC contains more detailed count and localization information. Additionally, [1] achieves better counting performance than the proposed method when there are no human-labeled annotations. It would be helpful to clarify the specific advantages of this paper.\n3. Although this is an unsupervised method, it would be valuable to understand whether the pre-training phase performs as expected. The authors could randomly select pairs of images from SHA/SHB/QNRF to determine accuracy or probability and analyze cases in which it failed. Furthermore, the accuracy should be compared with a similar method presented in Liu et al[2].\n4. The impact of patch size is only presented in the table. Could the authors provide a deeper analysis and discussion on the reasons for the observation that different patch sizes lead to different performance?\"\n\n[1] Wang, Qi, et al. \"Learning from synthetic data for crowd counting in the wild,\" CVPR, 2019.\n[2] Liu, Xialei, et al. \"Leveraging unlabeled data for crowd counting by learning to rank,\" CVPR, 2018"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4186/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4186/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4186/Reviewer_98cL"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698819466004,
        "cdate": 1698819466004,
        "tmdate": 1699636384742,
        "mdate": 1699636384742,
        "license": "CC BY 4.0",
        "version": 2
    }
]