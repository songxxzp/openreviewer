[
    {
        "id": "HORYvcoFXM",
        "forum": "OcaKeyGb0K",
        "replyto": "OcaKeyGb0K",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission551/Reviewer_4wri"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission551/Reviewer_4wri"
        ],
        "content": {
            "summary": {
                "value": "The paper attempts to present an approach to scene and object representation learning. Objects are decomposed into attributes and transformations between objects are learned using a neural network to satisfy algebraic independence between the attributes. A similar strategy is used to decompose scenes into objects and learn a transformation between scenes in the latent space. The authors claim the neural network used to learn these transformations accomplishes a form of representation learning."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Difficult to identify any contributions."
            },
            "weaknesses": {
                "value": "- The entire work seems like a trivial addendum to the cited work of Ohmura et. al. (2023) (which itself is a non peer reviewed paper on arXiv). Unfortunately, I was not able to identify significant extensions and significantly new experiments relative to Ohmura et. al. (2023).\n- The paper is poorly written:\n    - Vague explanations of technical concepts.\n    - Sentences are repeated verbatim in multiple places. E.G. abstract and introduction are word-for-word almost the same.\n    - Paragraph 3, line 2 seems to be copied from Ohmura et. al. (2023) page 6, line 1.\n    - The authors refer to other relevant work, but contributions relative to these references are poorly motivated and poorly explained. I was not able to find explanations how and why the other works relate to the proposed work.\n- I had difficulties in understanding the experiments, due to confusing setups and evaluation metrics.\n- Figs 1 and 2 do not explain the setup adequately; details missing."
            },
            "questions": {
                "value": "- Motivation and utility of this approach are poorly presented. How can we use the proposed neural networks for downstream tasks?\n- How would this approach handle real world images that contain complex scenes with overlapping and occluded objects?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission551/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700306195,
        "cdate": 1698700306195,
        "tmdate": 1699635982412,
        "mdate": 1699635982412,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IkZXTNDztH",
        "forum": "OcaKeyGb0K",
        "replyto": "OcaKeyGb0K",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission551/Reviewer_cTci"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission551/Reviewer_cTci"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a unified theory to explain both scene representation learning and object representation learning based on algebraic independence and validated the theory in Multi-dSprites dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The algebraic independence between object representation learning and scene representation learning that this paper focuses on is worth investigating."
            },
            "weaknesses": {
                "value": "The novelty of this work seems incremental, compared to Ohmura et al. (2023), it seems that the ALGEBRAIC INDEPENDENCE is straightforwardly implemented to scene and object representations. The novelty of this paper seems not that strong.\n\nThe writing needs to be enhanced. There are some repetition in the ABSTRACT and INTRODUCTION sections, and the main contribution of the INTRODUCTION section of the paper is not very clear and concise. For example, the authors emphasized that they proposed a unified framework to explain scene and object representation learning, however, it seems difficult to follow that how  scene and object representation learning be explained.\n\nRegarding the UNIFIED THEORY section, the Object Representation Learning Description is a quotation from existing work[1] and lacks novelty. Overall, the idea of the proposed unified explanation framework is relatively simple and straightforward.\n[1] Yoshiyuki Ohmura, Wataru Shimaya, and Yasuo Kuniyoshi. An algebraic theory to discriminate qualia in the brain. arXiv preprint arXiv:2306.00239, 2023."
            },
            "questions": {
                "value": "In addition to the above weakness, I also have concerns about the experimental results.\nThis paper consider the segmentation as the evaluation task, and uses a very traditional measurement adjusted Rand index (ARI) in evaluation. However, the widely used segmentation measurement of accuracy, mIoU are not considered. And there is no comparison to the related works in experiments, making it difficult to evaluate the advances of this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission551/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763435521,
        "cdate": 1698763435521,
        "tmdate": 1699635982298,
        "mdate": 1699635982298,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PXNpr1EAUm",
        "forum": "OcaKeyGb0K",
        "replyto": "OcaKeyGb0K",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission551/Reviewer_wsoP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission551/Reviewer_wsoP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a unified theory approach for learning object and scene representations. The authors draw inspiration from Ohmura et al. and propose an algebraic approach to object-scene representation learning. The authors claim to have unified the learning of both object and scene representations, particularly for scenes, which had not been achieved previously. They perform a quantitative analysis on multi-colored dsprites using the ARI score to evaluate scene representation."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The authors present a unified approach to learning both object and scene representations through algebraic methods.\n\n2. The authors achieve high ARI scores of 0.99 and 0.98 on two different experiments, with the number of objects varying, indicating a strong performance in scene representation."
            },
            "weaknesses": {
                "value": "1. The paper lacks novelty, as most of the work is derived from Ohmura et al.'s work.\n\n2. The theory section is largely based on the inspired work, with limited original content.\n\n3. Equation 4, the loss function, is also a derivative of prior work.\n\n4. The experimental section is limited, with only two settings (two objects and different number of objects) and no comparison to other baselines.\n\n1. The authors do not provide an evaluation of object representation.\n\n2. The caption for Figure 2 is unclear and does not effectively convey the author's intentions.\n\n3. There is no other ablation provided on the independence of the approach.\n\n4. The authors do not explain the O transformation in the two experiments.\n\n5. It is difficult to understand the approach's benefits since there is no direct comparison with the SOTA methods. Further, the authors modified the multi-dsprites dataset (so no occlusions are present), making an even harder comparison with previous approaches. We suggest the authors train SOTA scene/object representation methods for the same setup.\n\n6. Another problem with evaluation is that the tested method was tested on only a simplified version of the multi-dsprites dataset. We encourage the authors to perform additional experiments on other datasets like CLEVR (a more challenging dataset than multi-sprites), and Tetrominoes.\n\n7. If the proposed method cannot handle cases where objects are partially occluded, the authors should clearly mention this in their paper as a limitation of their approach.\n\n8. The paper used segmentation accuracy as the quantitative metric. However, as the representations are derived from segmentation masks, segmentation accuracy cannot be used as a proper metric for evaluating representations. (Disentanglement metrics and other downstream tasks are needed)\n\n9. There are multiple attributes in the dataset while the paper only involves 2 sets of latent vectors and 2 transformations, which means the proposed method is limited in generalizing to real scenario.\n\n10. How to determine the correspondence between objects among the two scenes (how to determine the object pairs for transformation) is not clear."
            },
            "questions": {
                "value": "View the section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission551/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698783182228,
        "cdate": 1698783182228,
        "tmdate": 1699635982220,
        "mdate": 1699635982220,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3Iq3Jx2IC8",
        "forum": "OcaKeyGb0K",
        "replyto": "OcaKeyGb0K",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission551/Reviewer_rWCq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission551/Reviewer_rWCq"
        ],
        "content": {
            "summary": {
                "value": "A recently proposed theory for object representation learning is used to develop a unifies theory of object and scene representation learning.\nExperimental results using two simple datasets are presented."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Extension of a recent \":theory \"of object representation learning to integrate scene representation learning and object representation learning."
            },
            "weaknesses": {
                "value": "The proposed theory should be validated using more challenging datasets. The proposed theory does not account for background. The modeled transformations are too simplistic. How will this work when one object is occluded by another or when 3D translational and rotational transformations are considered?"
            },
            "questions": {
                "value": "Generalize the proposed theory to more challenging datasets and transformations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission551/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797882958,
        "cdate": 1698797882958,
        "tmdate": 1699635982127,
        "mdate": 1699635982127,
        "license": "CC BY 4.0",
        "version": 2
    }
]