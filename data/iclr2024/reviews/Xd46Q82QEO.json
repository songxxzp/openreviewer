[
    {
        "id": "YamWWfiKNn",
        "forum": "Xd46Q82QEO",
        "replyto": "Xd46Q82QEO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_vKT7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_vKT7"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes new similarity measure between two representation spaces. The main idea of the new measure lies in assessing similarity locally, i.e., by comparing neighbourhoods of points between representation spaces."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The development of reliable similarity measures between representations is important and ongoing direction in the modern deep learning. Authors suggest studying similarity from the perspective of neighbourhoods of points and examine the proposed measure in various experiments."
            },
            "weaknesses": {
                "value": "My main concern is that authors propose a new metric which is build on CKA and CKA is known to have pitfalls (i.e. [1]). Thus, the very important part of suggesting a new metric is studying the pitfalls of the new measure and understanding the differences from the existing metrics. In the current version of the paper I did not see such investigation.\n\nAlso, for the similarity measure, it is important to understand the context in which we are using them. Authors argue that studying neighbourhoods might make sense, but does not discuss in which context it is important. For example, authors show that PNKA as CKA also shares such properties as the invariance to orthogonal transformations and to isotropic scaling, but again sometimes it can be beneficial, sometimes not, depends on the context.\n\nThus, deeper understanding of pitfalls and studying application areas are important to prevent careless use of the new metric by the community.\n\n[1] Davari et al. Reliability of CKA as a Similarity Measure in Deep Learning. ICLR 2023"
            },
            "questions": {
                "value": "In general, I would like to see the additional analysis as mentioned in the Weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698664500519,
        "cdate": 1698664500519,
        "tmdate": 1699636856601,
        "mdate": 1699636856601,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fEOOFfcVwZ",
        "forum": "Xd46Q82QEO",
        "replyto": "Xd46Q82QEO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_UEwp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_UEwp"
        ],
        "content": {
            "summary": {
                "value": "the submission proposed a point-wise normalized kernel alignment for measuring the similarity of a pair of vector representations that are produced by two trained neural networks on a single data point. The core concept which the proposed similarity score draws inspiration from is the assumption that similar vector representations should have similar neighbours, so we can directly measure the similarity of neighbours of the same point in two representation spaces. \n\nThrough experiments, they showed that trained models are likely to disagree on points with representations that are not so similar, and robust models are likely to agree more since they produce similar representations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. the proposed similarity score is well-motivated, and easy to implement.\n\n2. the experiments show evidence of the effectiveness of the proposed score."
            },
            "weaknesses": {
                "value": "I have several questions regarding the usefulness of the proposed scores.\n\n1. if the assumption is that the neighbours of a single point in two representation spaces matter in the construction of useful similarity scores, then I think an easy and effective approach would be Jaccard distance, and its variants that take distances into consideration.  I wonder how the proposed approach compares to Jaccard distance.\n\n2. it seems natural that models tend to disagree on misclassified data points, so if that is the case, we would then only need to look at the misclassified points as the unstable points rather than using the proposed similarity score to determine the unstable ones?\n\n3. since the comparison is now conditioned on a single data point along with its reference points, when two models are presented to us, how do we determine which model to use? The submission mentioned transfer learning as a use case, but it seems relatively non-trivial to me in terms of how we use the score in selecting the better pre-trained model to transfer from."
            },
            "questions": {
                "value": "n/a"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698706258304,
        "cdate": 1698706258304,
        "tmdate": 1699636856488,
        "mdate": 1699636856488,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zpKK9VSXlk",
        "forum": "Xd46Q82QEO",
        "replyto": "Xd46Q82QEO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_tyLp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7209/Reviewer_tyLp"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel measure for comparing the similarity of latent spaces, with a special focus on its locality property instead of a global one. By independently computing intra-space distances with respect to a specific set of reference points, the authors relate these vectors using the angles between them, assuming a known correspondence between the two sets. The paper then proceeds with three major applications of the method and their validation: i) correlating the measure's similarity output with classification errors on ResNets, ii) out-of-distribution detection, and iii) studying the geometric effects of debiasing techniques on GloVe embeddings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper presents an interesting approach to comparing the similarity of latent spaces and well-motivates its importance;\n- The applications proposed, particularly relating to classification errors and out-of-distribution detection on ResNets and the effects of debiasing on GloVe embeddings, are noteworthy;\n- The experimental setup appears robust, providing valuable insights that can be considered useful contributions to the field;\n- The supplementary material is extensive and also contains the code, enhancing reproducibility;"
            },
            "weaknesses": {
                "value": "- The method explanation lacks some clarity. Multiple readings were necessary due to references to the use of yet-to-be-introduced concepts such as \"neighborhood\" and \"reference points\". I think there's also some mismatch between the method presentation and the general take that the neighborhoods of each point are important to their representation since the reference points are never restricted or searched in the neighbors.\n- Despite the valuable insights from the experiments, their current setting might not be general enough, limiting broader application and significance. For example, the relationship between PNKA and model disagreement on specific data points is limited to only a cross-training setting, without considering other possible variations such as architectural ones. This is something I would expect in a more theoretical work. The reported results are convincing, but, as commendably acknowledged by the authors themselves in the discussion section, the variation in architecture/tasks is not enough to validate the robustness of the proposed claims;\n- There is a noticeable overlap in methodology with cited prior work, particularly Moschella et al. Although the paper frames its method as a kernel method application, it bears a strong resemblance to the direct application of cosine similarity between relative encodings, a technique already explored in the mentioned work. This overlap reduces the novelty of the method but doesn't impact its interesting applications;"
            },
            "questions": {
                "value": "- as described in the weaknesses section, I would ask the authors to please clarify the \"neighborhood\" concept and its relationship with the reference points;\n- In the current manuscript form, I'm recommending a weak reject. However, I'm willing to increase the score if either the lack of variety in experiments or the relationship with previous work is addressed since the former would improve the experimental contributions while the latter the theoretical ones;"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7209/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7209/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7209/Reviewer_tyLp"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7209/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761967238,
        "cdate": 1698761967238,
        "tmdate": 1699636856362,
        "mdate": 1699636856362,
        "license": "CC BY 4.0",
        "version": 2
    }
]