[
    {
        "id": "oyfZW4ziaw",
        "forum": "NDkpxG94sF",
        "replyto": "NDkpxG94sF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_fSn3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_fSn3"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an effective enhancement to DETR-based indoor 3D object detection. The key idea is to add a relative positional embedding between the queries and points. The positional embedding, which is called 3D Vertex Relative Position Encoding (3DV-RPE), calculates the relative positional embedding under the coordinate system of each 3D bounding box generated from the query. After incorporating the positional embedding, the performance significantly increases on both ScanNetv2 and Sun-RGBD."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper has demonstrated the following strengths:\n\n* The approach of the paper has good support from their performance improvement on ScanNetv2 and Sun-RGBD.\n* The vertex relative position encoding (3DV-RPE) has the reasonable intuition of embedding position information for 3D detection and will likely inspire other readers.\n* The qualitative results like Figure 1 clearly illustrate the implication of the method in the paper in guiding models' attention."
            },
            "weaknesses": {
                "value": "* I suggest improving the order of presentation in Sec. 3.2 and Sec. 3.2. For example, I suggest moving the paragraph of \"3DV-RPE\" before talking about \"canonical object space\" and other details. When I read this part, I was quite confused by Sec. 3.2, not knowing how $R$ is generated, what is $P_i$, etc.\n\n* As position encoding is the focus of this paper, I expect the authors to analyze or conduct ablation studies on more position encoding algorithms. Details are in the \"questions\" section below. \n\n* I also haven't found the performance of the baseline without relative position encoding. In case I missed it, I suggest the authors put it into Sec. 4.3 or Sec. 4.4 for a clear ablation study.\n\nTypo on page 5, line 1: fig:rotatedRPE"
            },
            "questions": {
                "value": "1. **Baseline performance.** As mentioned in the weakness section, could you remind me where you have put the baseline performance? It is critical to recognize the improvement of 3DV-RPE. Technically, I wish to see that under the same normalization and other tricks, 3DV-RPE is indeed helpful.\n\n\n2. **Additional analysis.** With position encoding being the center of this paper, I think it necessary to conduct ablation studies on other common formats of position encoding, such as:\n*  Absolute position encoding, in both the formats you proposed like Eqn. 3 and Eqn. 4, or common sin-cos position encoding.\n* More justifications of hyper-parameters. For example, where does 10 come from in $T$'s shape? May I use another number to replace 10?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Reviewer_fSn3"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2646/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698599702299,
        "cdate": 1698599702299,
        "tmdate": 1699636204943,
        "mdate": 1699636204943,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7gC9krwExR",
        "forum": "NDkpxG94sF",
        "replyto": "NDkpxG94sF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_TFsP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_TFsP"
        ],
        "content": {
            "summary": {
                "value": "For the task of indoor 3D object detecion from point clouds, previous sparse detectors neglects to tackle 3D queries outside the bounding box, so the author proposed a 3D vertex positional encoding module (3DV-RPE) to guarantee the locality principle in object detection. Specifically, the proposed method encode relative position information for each query towards its assigned / predicted bounding boxes to provide clear information to guide the model to focus on points near the objects. Moreover, it utilized many widely-adopted tricks to generally improve the performance of the detector (custom backbone / loss normalization / TTA / one-to-many auxillary loss, etc). 3DV-RPE shows competitive results on ScanNetv2 and SUN-RGBD compared to previous methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* this paper pinpoint a interesting gap in previous sparse 3D indoor detectors that how to deal with queries outside the predicted bouding box, and try to prove that whether it is benefical to take this into account for 3D object detection.\n* this paper does a lot of work to incorporate modern network architectures (e.g., ResNet34 + FPN), training strategy improvements to make the detector performs better."
            },
            "weaknesses": {
                "value": "* Unfair comparision:\n    1) The author combines many technical improvements including normalizing box according to object size, one-to-many assignment as auxillary loss, a modified resnet34-fpn backbone, and even TTA. They're all irrelavant to the claimed core contribution 3DV-RPE. So to prove the proposed module is effective, the most convincing way could be adding 3DV-RPE directly onto the baseline GroupFree3D.  Considering that the 3DV-RPE  module can work in a plug-and-play manner in theory, I would expect more results based on other methods such as GroupFree3D, 3DETR or CAGroupFree3D.\n    2) in table 6, the author reports the one with 3DV-RPE + TTA (77.8 / 66.0), does all other ablation attention results are also reported with TTA?\n    3) the author reported the best results for the proposed method, how about the ablations? how many times have you run for each ablation choice in all tables? Does the fairness of the comparison is guaranteed?\n    4) Given the best set of paraters for the authors final model, change the choices in loss functions can affect the hungarian matching cost matrix, thus it's hard to say the improvement / performance drop comes from the module / improper cost weights.\n    5) Why some ablations are done with ScanNet while others use SUN-RGBD (e.g., Table 4)? Does it means the coordinates normalization works similarly on ScanNetv2?\n\n* minor contributions:\n    1) Actually I think the RPE and normalized coords are designed in similar ways: Point-RCNN has adopted to convert box to  canonical coords and do normalizations on oritentaion. Moreover, in anchor-based detectors, they already use the anchor boxes' W and H to normalize the regression targets. Here the author uses dynamic bounding boxes from predictions, which has also been explored in methods like MetaAnchor, etc.\n    2) So many un-relavent tricks to improve the detection performance. I don't like the way to do whatever it can to improve the results. Rather, the author should focus on the main contribution. After the core module being sufficiently discussed, one can further improve its results with more tricks. Here the author put all stuff together, which makes me doubt where the improvement come from.\n\n* Most of the references are before year 2023, so I think more recent works in year 2023 should be included.\n\n* I recommend against reporting results using TTA, as this leads to cutthroat competition and more potentially unfair comparisons; for example, TTA may be different in different papers, but is always written as \"TTA\"."
            },
            "questions": {
                "value": "* How much fraction does the queries outside predicted bounding boxes account for with respect to the total number of queries? 10%? 20%? The author should provide a investigation to this problem.\n* Why the non-linear functions is designed in this way? how it is derived? is their any insights to do so?\n* Why does the PE is added in the way in Eq. 1? I think the form of matmul(Q, K) + R does not match the intended aim of the paper. Instead, I think matmul(Q+R, K) should be more proper? or add a relative PE to Q and a global PE to K?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2646/Reviewer_TFsP"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2646/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763359994,
        "cdate": 1698763359994,
        "tmdate": 1699636204875,
        "mdate": 1699636204875,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kecfdT7r8R",
        "forum": "NDkpxG94sF",
        "replyto": "NDkpxG94sF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_c9AZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_c9AZ"
        ],
        "content": {
            "summary": {
                "value": "The manuscript proposes a 3d object-detection-specific position encoding method that significantly improves performance for 3d DETR-like object detection.\nThe 3d position encoding encodes the relative position of key, value points to the object query points to allow the transformer to learn to attend to points inside the object bounding box more easily.\nWith the addition of the position encoding and some other tweaks, the proposed method, V-DETR, outperforms CNN-based methods. A first for transformer-based detectors in 3d."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The proposed approach for relative position encoding is intuitive (and illustrated well in Fig 1), and experiments clearly show that it leads to a big improvement for Transformer-based methods and leads to a new state of the art wrt. to CNN-based methods as well. \n\nOverall the quality of writing and illustration is very high. The detailed pipeline visualization clearly shows the recurrent nature of the approach. The visualization of the attention for each of the corners is also very illustrating. \n\nThe manuscript pays attention to practical aspects as well: The use of a precomputed lookup table for the relative PE is a nice and practical way to safe valuable GPU memory.\n\nThe experiments are expansive and convincing. The ablations do help clarify the different choices of the hyperparameters."
            },
            "weaknesses": {
                "value": "The precomputed lookup table was the hardest to follow (Eq 3) since the connection to Eq 4 was not immediately obvious. One more sentence there to explicitly connect the two would be helpful. I.e. T represents a discretized set of possible \\Delta P that we interpolate into."
            },
            "questions": {
                "value": "Page 5 has a broken figure reference.\n\nI dont understand how T in Eq(3) is initialized/set? What range do the T values take? -5 to 5 as indicated by the signed-log function?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2646/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794577609,
        "cdate": 1698794577609,
        "tmdate": 1699636204805,
        "mdate": 1699636204805,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vnOtCGrbh9",
        "forum": "NDkpxG94sF",
        "replyto": "NDkpxG94sF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_YhUd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2646/Reviewer_YhUd"
        ],
        "content": {
            "summary": {
                "value": "This paper presents one improvement over DETR-based methods for 3D object detection. The idea is first to predict a coarse bounding box and then only allow attention weights to be learned within the bounding box for better-using locality as one important inductive bias for 3D object detection. Experiments are done on the ScanNetV2 and Sun RGB-D benchmarks. Results show improved performance over baselines. Extensive ablation studies are also presented."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- the proposed method improves over state-of-the-art methods on ScanNetV2 and Sun RGB-D.\n- the proposed modification to the DETR-based method is valid and reasonable.\n- ablation studies are solid."
            },
            "weaknesses": {
                "value": "- the proposed method is more like just a small fix to DETR-based method.\n- the proposed fix is also specific to DETR-based backbones.\n- the proposed fix may be vulnerable if the first stage predicting the coarse bounding boxes fail. For example, if the bounding boxes are very off, then preventing later layers to attend to out-of-the-box regions may make it impossible to recover. \n- the paper writing can be improved. For example, the figure layouts are quite messy. The organization for Sec. 3.1 and 3.2 is a bit hard to follow. It looks like Sec. 3.1 focuses on laying out the basic pipeline of DETR and Sec. 3.2 discusses more into the contributions of the paper, but actually the content are mixed together.\n-  there are also claims that are unsupported in the paper. For example, the sentence in the introduction section \"We attribute the discrepancy to the limited scale of training data available for 3D object detection\" is not well supported. Can you use less data to train 2D detectors to show it's really the data scale issue?"
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2646/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698875006425,
        "cdate": 1698875006425,
        "tmdate": 1699636204734,
        "mdate": 1699636204734,
        "license": "CC BY 4.0",
        "version": 2
    }
]