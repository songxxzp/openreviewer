[
    {
        "id": "eLHLWWhTNI",
        "forum": "kNPcOaqC5r",
        "replyto": "kNPcOaqC5r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_XDuj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_XDuj"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose a way to learn a denoising map, called LPN, which is exactly the proximal operator of a scalar function which should approximate the true log image prior. They make use of the characterization of nonconvex proximity operators as gradient of convex functions from (Gribonva & Nikolova, 2020) and parametrize their denoiser as the gradient of (an ICNN.+ a quadratic term). They also suggest a specific loss, called \"proximal matching loss\" such that, when the denoiser is trained to denoise Gaussian noise with this loss, it should approximate the prox of the true log image prior. They also propose a convergence proof of the PnP-PGD algorithm with plugged LPN denoiser and experiment on different datasets and inverse problems."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is generally well presented and well written. \n- The idea to parameterize a denoiser as the gradient of an ICNNs is new in the PnP literature. \n- The most interesting contribution of the paper is for me the proximal matching loss. \n- The verification of the nonconvexity of the learned prior is also interesting."
            },
            "weaknesses": {
                "value": "Here are several potential issues that I spotted while reviewing the paper.\n\nMajor weaknesses : \n- The end the proof from Theorem 4.1 is I think not true, and the presented result not valid. Indeed, the definition of subdifferential subdiferential for convergence of nonconvex PGD is not the usual subdifferential but the limiting subdifferential. With this notion, the first equivalence from C.48 is not true when $\\phi_\\theta$ is nonconvex, and only the implication holds. Therefore, the algorithm can not converge to a fixed-point as presented, but only to a critical point of $h + \\eta^{-1}\\phi_\\theta$.\n- The targeted objective function $h + \\eta^{-1}\\phi_\\theta$ contains the stepsize (which is then a regularization parameter). This is uncommon in optimization and not desirable, as a change in the stepsize affects the objective function and the obtained result. Moreover, the stepsize (and thus the regularization parameter) must be bounded by $1/L$, is this limiting in practice and does it impact the performance ?\n- The algorithm analyzed for convergence is just the classical Proximal Gradient Descent (PGD) (or Forward-Backward). \nWhy do you use the convergence analysis from (Bot et. al, 2016) which is specific for an accelerated version of this scheme. You could use directly the (most commonly used) convergence result from (Attouch et. al, 2013) of PGD in the nonconvex setting.\n- \"Definable\" is an important notion that should be defined. Moreover, the stability properties of Definable functions ( by sum, composition, inverse, derivative) are extensively used without referencing the proof of these results. Same comment for the fact that the exponential is definable. \n- You experiment with PnP-ADMM when the presented theoretical result is with PGD. If this is correct, this is a major issue. Indeed, the theoretical convergence results of ADMM in the convex setting are not the same as the ones for PGD. \n\nMinor weaknesses : \n- Lemma C.2 :  I think that $f_\\theta$ is only invertible on $Im(f_\\theta)$ and $\\phi_\\theta$ is only differentiable on $Im(f_\\theta)$. If this is really true on the whole space, can you explain why ? \n- Section 1 : \"for almost any inverse problem, a proximal step for the regularization function is always present\" I do not understand this sentence and what you mean by \"present\".\n- Section 1 : In (Romano et. al, 2017), there is no prox involved. \n- Section 2 : Contrary to what you seem to explain, PnP is really not limited to ADMM !! \n- Section 3 : Parameterizing a network as the gradient of an ICNN as already been proposed in the literature, in particular in the Optimal Transport community. These works should be cited as well. \n- Section 3 : You explain that the chose parameterization is more general and universal than (Hurault et. al, 2022). I am very doubtful about this statement, given the fact that the ICNN parameterization is very (and I think way more) constraining. A way to support your affirmation would be to compare the performance with both denoisers for denoising and PnP restoration. \n- In most PnP algorithm, the Gaussian noise parameter $\\sigma$ on which the denoiser is trained acts as a regularization parameter. Here, you do not mention this parameter, and you do not explain how it is chosen. \n\nThese weaknesses explain my low score, and I am ready to raise my score if the authors answer these limits."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Reviewer_XDuj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2577/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698581953493,
        "cdate": 1698581953493,
        "tmdate": 1699636194854,
        "mdate": 1699636194854,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2tPJ3w9dRt",
        "forum": "kNPcOaqC5r",
        "replyto": "kNPcOaqC5r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_hkxu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_hkxu"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a framework for constructing learned proximal networks (LPN) that offer precise proximal operators for a data-driven regularizer. It also demonstrates a novel training strategy called proximal matching, which ensures that the resulting regularizer accurately captures the log-prior of the actual data distribution. Experiments test the effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper forms a class of neural networks to guarantee to parameterize proximal operators. The idea is novel.\n2.\tSome theoretical results are provided.\n3.\tExperiments show the effectiveness."
            },
            "weaknesses": {
                "value": "1.\tThe paper is not well organized, making it hard to follow.\n2.\tThe experiments are a little weak. See the questions below."
            },
            "questions": {
                "value": "My main concerns are the experimental details.\n1.\tIt is better to give some details on the training of the learned proximal networks. For example, how to learn the non-negative weights?\n2.\tHow to set the \\alpha in \\phi_\\theta in the training?\n3.\tHow to set \\eta in Theorem 4.1 in the training?\n4.\tThe methods compared in this paper are relatively old. It is better to compare the recent methods. Then we could find out the superiority of the proposed method.\n5.\tThe used datasets are very small. Deep learning can only be effective when there is a substantial amount of data.\n6.\tIt is best to verify the effectiveness of the proposed method on common real tasks, e.g., real denoising or deblurring.\n7.\tCompared with other methods, how is the training efficiency? It is better to verify it by experiment.\n8.\tAt the end of the Abstract, \"demonstrating\" should be \"Demonstrating\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2577/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698661465755,
        "cdate": 1698661465755,
        "tmdate": 1699636194771,
        "mdate": 1699636194771,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NtU1HXboLs",
        "forum": "kNPcOaqC5r",
        "replyto": "kNPcOaqC5r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_8FVJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_8FVJ"
        ],
        "content": {
            "summary": {
                "value": "Inverse problems $y = A(x) + v$ are commonly formulated using regularized least squares:\n$$\\min_x \\frac{1}{2} \\|\\| y - A(x) \\|\\| + \\phi(x)$$\n\nwhere $\\phi$ is an appropriate regularizer. Solving this minimization problem often involves the use of proximal gradient methods. This process necessitates the selection of a regularizer, $\\phi$, and the knowledge of its proximal map. A natural approach, leading to Maximum A Posteriori (MAP) estimation, is to choose $\\phi(x) = -\\log p(x)$.\n\nThis paper presents a method for learning the proximal map of $\\phi(x) = -\\log p(x)$ from data, using only samples from $p(x)$. The authors then apply this proposed approach, in conjunction with proximal gradient methods, to various standard inverse problem tasks, demonstrating favorable performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The use of proximal and descent methods in conjunction with deep neural networks to address inverse problems is a dynamic and exciting field of study. Numerous papers have explored these approaches, attempting to approximate Maximum A Posteriori (MAP) estimation in various ways or training regularizers in a supervised manner (which is not always feasible and not even correct). To the best of my knowledge, this paper stands out as the first to present a principled approach for training proximal maps of the log probability and effectively approximating MAP estimation.\n\nAdditionally, the numerical results presented in this paper are well-executed and show promise."
            },
            "weaknesses": {
                "value": "- A straightforward solution to obtain the proximal map of log p(x) is to initially train an energy-based model, E, and then compute the proximal map of og E. The authors should either compare this approach with their proposed method or provide clarification on why this is not considered viable or advisable. For instance, one might anticipate encountering similar challenges as those faced when training energy models when training Learned Proximal Networks (LPNs).\n\n- In a similar vein, a natural point of comparison for the proposed approach would involve using other state-of-the-art unsupervised methods that rely on generative models as priors. While the paper does make a comparison with the less recent adversarial regularizer, it would be valuable to assess its performance against other more recent unsupervised methods.\n\n--- \nAfter rebuttal: The authors have addressed the concerns raised in the reviews and I have increased my score."
            },
            "questions": {
                "value": "- Equation (3.2) should it be \\psi_\\thet(x,\\alpha) ? \n\n- Page 5, \"demillustrates\" should be corrected to \"illustrates.\"\n\n- Page 5, the terminology \"proximal operator of target distribution\" is frequently used but remains undefined. This terminology appears to be uncommon in the field and should be clarified or explained for the readers' benefit.\n\n- It would be insightful to determine whether the log-likelihood computed using LPN matches the log-likelihood computed using other generative models.\n\n- \"Hidden\" in the appendix is that the LPN is first trained on the l1-loss, then it is trained with the proximal matching loss. This should be stated clearly in the main body of the paper. Why this is needed? How bad is LPN trained just with the proximal matching loss?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2577/Reviewer_8FVJ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2577/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698692259989,
        "cdate": 1698692259989,
        "tmdate": 1700585474081,
        "mdate": 1700585474081,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Kjws32K3br",
        "forum": "kNPcOaqC5r",
        "replyto": "kNPcOaqC5r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_fi4Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2577/Reviewer_fi4Y"
        ],
        "content": {
            "summary": {
                "value": "Plug-and-play methods are a framework used for solving inverse problems in image processing, and rely on proximal operators. It's been shown that the proximal operator for the linear inverse problem case is equivalent to a MAP denoiser. In the literature PnP methods almost always rely on MMSE denoiser due to difficulty of learning and designing MAP estimators. In this work, the authors suggest a way to learn a MAP denoiser which they then use in an ADMM algorithm to solve inverse problems. They show the algorithm converges to fixed points of the prior for a particular design of neural networks which guarantees strongly convex mapping. Finally they test the algorithm empirically on toy Laplacian distribution as well as MNIST, CelebA and Mayo-CT datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This work addresses a prevalent problem at the core of PnP methods, which is the use of MMSE denoisers instead of MAP denoisers, despite the fact that the convergence results for PnP holds for MAP denoisers. They offer a novel way to learn a MAP denoiser and provide convergence results."
            },
            "weaknesses": {
                "value": "- The main contribution of the work is to propose a way to learn a MAP denoiser through a proximal loss under equation 3.4. Optimizing for this loss entails that the prior distribution is assumed to be a mixture of Gaussians (or Diracs when $\\gamma$ tends to zero) around the training samples. Why is this a good prior? It seems to me that is a too simplistic prior and in the limit of $\\gamma \\to 0$ a discontinuous prior. \n- Although most of the paper was quite clear I found it unclear whether the final implementation enforced convexity on the prior or not. Under section 2 and section 3, a case was made for convexity: a class of learned proximal network was suggested to ensure convexity, and later under (3.1) another regularization was introduced to ensure strong convexity for recovering the prior. I think these sections do not flow well and the thread of logic is easily lost by the reader. The clarity can be improved. Also on a related note, if convexity is assumed, why is it a proper assumption? It most probably would be a too simplistic of an assumption for image priors. \n- The details of the algorithm can be more elaborated in the main text. Specially, since the algorithm is very similar to the basic score-based diffusion generative algorithms for solving inverse problems, the differences between the two should be pointed out. \n- I find it surprising and contradictory that the PSNR values are higher for this methods compared to other methods that use MMSE denoisers. It is expected that for solving inverse problems using a MAP denoiser result in sharper images with lower PSNR (=higher MSE) while using MMSE denoiser result in higher PSNR (=lower MSE) and more blurry results. This is obvious since, as also stated by the authors, the MMSE denoiser pushed the image towards the mean of the posterior while MAP denoiser pushes the image towards the mode of the posterior. Obviously the mean of the posterior is equivalent to the MSE minimizer, so it should result in lower MSE. \n- Additionally, I found it confusing that the qualitative results for CelebA dataset seem pretty much the same across different methods, and not very good in general. The results look pretty blurry for the proposed method which is surprising given that the method relies on a MAP denoiser. \n- Finally, in recent years, there has been some score based diffusion models algorithms which use priors in denoisers to solve linear inverse problems, which result in significantly better performance. Considering the disadvantage in performance, what are the advantages of this methods? It seems necessary to include a comparison to those models."
            },
            "questions": {
                "value": "Please see the questions raised under the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2577/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699250234970,
        "cdate": 1699250234970,
        "tmdate": 1699636194565,
        "mdate": 1699636194565,
        "license": "CC BY 4.0",
        "version": 2
    }
]