[
    {
        "id": "HrG7FOCUPt",
        "forum": "9gyDdCKTDJ",
        "replyto": "9gyDdCKTDJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_keBn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_keBn"
        ],
        "content": {
            "summary": {
                "value": "Due to the requirements of the expected trajectory segmentations into a discrete set of skills, current methods mostly discretize commonalities among gait types, leading to less smooth transitions. To overcome these problems, the authors introduced Gaitor, leveraging a unified representation to capture the correlations among gait types. With the help of terrain encoding and a learned panner operation, Gaitor can take motion commands into account. Specifically, a modified variational autoencoder is applied to infer the robot's current and estimate the future state, which is also determined by the terrain latent space from the autoencoder. The evaluation is in simulated and real-world settings."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The writing, figures and tables are clear and understandable.\n2. The proposed method is sound. Gaitor uses VAE and autoencoder to transfer the robot state and terrain information into latent space and does further operations like manual control or fuses information on the manifold, which is a good try to integrate multi-information."
            },
            "weaknesses": {
                "value": "1. The elements in the formula should be demonstrated more carefully, there are some units that first appear without description.\n2. In this paper, there are few works to compare. Although it is firstly to do the task, there should be some way to compare the proposed methods with others, or it is hard to evaluate the performance."
            },
            "questions": {
                "value": "No more question."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Reviewer_keBn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698290973542,
        "cdate": 1698290973542,
        "tmdate": 1699636899173,
        "mdate": 1699636899173,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nUrNeejVE1",
        "forum": "9gyDdCKTDJ",
        "replyto": "9gyDdCKTDJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_A1WD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_A1WD"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a system that utilizes a VAE to encode different quadrupedal gaits into a continuous latent space. A planner then can utilize this latent space to continuously switch between gaits to accomplish different locomotion tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The system is able to generate interpretable latent space that can be used to continuously switch between different gaits. It is also demonstrated on a real Anymal robot.\n\n2. The analysis of the latent space demonstrates its interpretability."
            },
            "weaknesses": {
                "value": "I don't understand the approach section. It would be great if the authors could make the description clearer. See questions below."
            },
            "questions": {
                "value": "1. \" All pose orientations are represented in tangent space.\" Can you specify what you mean here?\n\n2. I don't quite understand why it is called a VAE instead of just a neural network that maps input to output. My understanding is that a VAE will try to reconstruct the input at its output, but that doe not seem to be the case here. Perhaps this is why I am very confused when reading the paper. My understanding is the proposed \"VAE\" learns to project the input to a latent space, which is then used to reconstruct the output (which is different from the input). VAE is also used when given the same input to generate multiple plausible outputs, in the context of robots, say given the same user command velocity, generates different gaits that can follow this velocity. I am not sure where is the variational part in the proposed vae.\n\n3.  \"The gait input is a label for each gait. This can be a one-hot encoding for each gait or a slider, where the three gaits, trot, crawl, and pace are [1, 0, \u22121]. The latter is recommended for its simplicity, but the one hot encoding produces the same results and\npermits smooth transitions between gaits.\" I am confused by this sentence, who recommended the latter (and what is the latter?) And are you using this recommended option or are you using the one-hot encoding? And this performance predictor is never used again (I search for PP and performance predictor), what is it used for in the whole system?\n\n4. I am not sure how the different components are used after training. My naive guess is the past trajectory is fed into the vae, and then output the future trajectory for robot control. The encoding of the inputs can be modified by the planner to adjust gaits. It would be nice to make it clearer how the system works.\n\n5. Why is an additional planner needed to deal with terrains since terrain is already an input to the decoder and the training data for the decoder and planner are the same (or could be the same)? Maybe an ablation study is needed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7464/Reviewer_A1WD"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698383561274,
        "cdate": 1698383561274,
        "tmdate": 1700439682401,
        "mdate": 1700439682401,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZAIJuQWVBw",
        "forum": "9gyDdCKTDJ",
        "replyto": "9gyDdCKTDJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_QD8G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_QD8G"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes Gaitor, an imitation learning-based method for learning a continuous latent space of gaits for locomotion. A VAE latent space is trained on examples of expert trajectories. The paper uses the observation made by Mitchell'23 that good controllers can be created as elliptical trajectories in that latent space. The controller learns to predict an appropriate elliptical trajectory conditioned on terrain features. It is shown that the method can be used to automatically transition between gaits by representing the desired gait on a scale (trot = 1, crawl = 0, pace = -1) and continuously interpolating this variable. This experiment was performed in simulation, but transitioning between trot and crawl is possible on the real robot too."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper proposes a promising method for gait transitions for locomotion\n- The method doesn't use gait phases, instead implicitly discovering them from imitation data, which is a scalable approach.\n- The empirical finding that it is possible to transition from trot to crawl is interesting."
            },
            "weaknesses": {
                "value": "- It is claimed that prior methods do not learn a shared representation between skills. However, Caluwaerths'23 proposes Locomotion-Transformer, which in fact does this, and reports similar results to this paper. Comparing to Locomotion-Transformer would help put the results in context. \n- The presentation of the method is poor. \n  - Fig 1 - none of the symbols are defined.\n  - \"Robot-specific encoding\" section: $q_k, ee_k, \\tau_k, \\lambda_k, \\dot{c}_k, \\Delta c_k$ are all undefined.\n  - \"The latter is recommended for its simplicity, but the one hot encoding produces the same results\". So which one was used in the experiments? Were all experiments performed with both?\n  - \"Terrain encoding\" section: the terrain encoding is not defined in this section. Is terrain encoding same as $z_G$? Also $z_G$ is undefined.\n  - Page 4 describes a method diagram in text which would be much more easily explained in a figure. Figure 1 presumably depicts the same information but is not helpful for understanding the method since Sec 3.1 doesn't reference the figure. The reader needs to guess what is the correspondence between the text and the figure. See e.g. Hafner'20 for an example of good presentation.\n  - Eq 1. Y, U, s are undefined. The LTI function is never mentioned in the rest of the paper. Since all of the symbols are undefined, it is unclear whether this is used in the method at all, and if yes where. \n  - \"Training the VAE and Terrain AE\" section: terrain encoder is undefined. Unclear how $\\hat\\theta_c(k)$ is produced. The VAE loss as far as I can tell doesn't depend on the terrain encoder, so it's unclear how the terrain encoder can be trained with those gradients. The terrain decoder is undefined.\n  - There is a missing reference in the second line of Sec 2.\n  - The citation for GECO is wrong. It is Rezende'18\n\nHafner'20, DREAM TO CONTROL: LEARNING BEHAVIORS BY LATENT IMAGINATION. \nRezende'18: Danilo Jimenez Rezende and Fabio Viola. Taming VAE, 2018."
            },
            "questions": {
                "value": "1. Why is it important that the method doesn't use gait phases as an inductive bias? A comparison to Yang'21 that showcases this difference between methods would strengthen the paper.\n2. A discussion of a comparison to Locomotion-Transformer is crucial. \n3. Overall, the paper is promising but I am unable to recommend accept due to poor presentation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698706314531,
        "cdate": 1698706314531,
        "tmdate": 1699636898337,
        "mdate": 1699636898337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "A3PfeKWIV6",
        "forum": "9gyDdCKTDJ",
        "replyto": "9gyDdCKTDJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_st69"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7464/Reviewer_st69"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Gaitor, a framework for learning effective representation of different gaits for quadrupedal locomotion and adaptive terrain traversal schemes. The model is composes of 3 segments: (1) a VAE which encodes history of robot states (proprioceptive) into latent embeddings and decodes to future sequence of states and footholds, (2) an AE which encodes local terrain heightmap filtered using LTI in frequency domain based on future footholds and decodes the same and (3) a planner MLP which takes the phase of the motion and terrain latent to output the radius of an elliptical trajectory in polar coordinates. The latent embedding of past trajectory is filtered to remove high-frequency components as most information is captured by the low-frequency components and then converted into polar form with phase angles. In the polar form, the radius predicted by the planner is used to modulate the latent space to adjust foot-step height and lengths. The proposed setup is demonstrated on a real-world scene."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Gaitor introduces an adaptive planner in the latent space of the VAE. It builds upon the advances introduced by VAE-loco on discretizing the latent space to represent different phases of the footsteps in a gait. Finally, the terrain embeddings are used to modulate the latent trajectories and hence the required footstep height and length for a given heightmap. This helps in building a framework for continuous transition between different quadrupedal gaits."
            },
            "weaknesses": {
                "value": "The paper is not written clearly. There is a lot of missing information and abuse of notations. Further, the authors do not justify their choices via suitable ablations which weakens the overall contributions of their method. Please answer the questions below:\n\nHow are the latent visualizations constructed specifically? From the material in the paper, it seems like only two lowest-variance (low-frequency, low noise) components of VAE latent embedding are selected and transformed into polar coordinates about the mean as center?\n\nIf only the selected components are modulated by the planner predictions of radius, are other components of the latent space discarded before input to decoder? If not, what happens if they are discarded? Else vice-versa? From the context, it seems those are high-frequency components and do not contain much information.\n\nThe inference pipeline is not clearly mentioned anywhere. The inputs are the history of states to the VAE which gives a latent trajectory representation. Now, how are the heightmap features calculated? The paper mentions \u201cThe height of the terrain at the future footholds are measured from this height map\u201d. How do you get the future footholds? How are the predicted states used?\n\nThere has to be an appendix section clearly mentioning the construction of LTI transfer function for getting $y_k$ from $\\theta_k$. What is $y_k$? How is $\\theta_k$ constructed? How do you define angle between FL/FR and RR/RL? What is $w$ in equation (1)?\nWithout any definition, the authors have introduced the subscript \u201c$c$\u201d in equation (4)? Which when followed in section 3.2 becomes more confusing. What are $C$-discrete bins? What is $r^*$?\n\nThe paper is not very understandable at this point. However, it gives the readers an intuition of what is happening and how it is useful in understanding continuous transition between multiple gaits. \n\nThe paper contains remarks like \u201cFor example, it is possible to transition from trot to crawl to pace and the reverse only\u201d without any reason."
            },
            "questions": {
                "value": "See weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790438891,
        "cdate": 1698790438891,
        "tmdate": 1699636898113,
        "mdate": 1699636898113,
        "license": "CC BY 4.0",
        "version": 2
    }
]