[
    {
        "id": "LznGsn5zzi",
        "forum": "dN1IV0Ov8a",
        "replyto": "dN1IV0Ov8a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_h86L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_h86L"
        ],
        "content": {
            "summary": {
                "value": "The research discusses the limitations of current bankruptcy risk prediction models, which primarily rely on numerical data. These models don't harness the available textual information. The study introduces a BERT-based model that predicts bankruptcy risk using long text sequences from Annual Accounts' annexes, even in the absence of explicit risk information. The researchers processed these texts in parallel and integrated them for predictions. They used a dataset of 20,000 annexes from Luxembourg's non-financial companies to train and validate the model, achieving a validation precision of around 73%. The model effectively learns risk information from unstructured and diverse long textual data."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. This paper proposes a method for predicting bankruptcy risk using long text.\n2. The author implemented the method and conducted experiments using the dataset of the Annual Accounts of non-financial companies from Luxembourg, and the accuracy rate exceeded 70%."
            },
            "weaknesses": {
                "value": "1.\tThe method proposed in the paper lacks novelty. As shown in Table 7, the risk prediction task can essentially be framed as a text classification problem (Risky or Not Risky). However, it's worth noting that similar research utilizing a combination of BERT and LSTM for long text classification was introduced four years ago [1].\n2.\tA notable shortcoming of the paper is the absence of comparative experiments. The author did not provide a comparison between their proposed method and established techniques. Furthermore, there was no evaluation against advanced language models such as GPT-4 and LLaMa, which are capable of handling a wide range of tasks.\n3.\tThe paper also suffers from limited references to recent research. In addition to sparse citations of web pages and open-source code, the paper only includes references to a single study from 2022 and one from 2023. This lack of engagement with the latest research trends and findings weakens the paper's overall scholarly depth.\n\n[1] Ashutosh Adhikari, Achyudh Ram, Raphael Tang, Jimmy Lin: DocBERT: BERT for Document Classification. CoRR abs/1904.08398 (2019)."
            },
            "questions": {
                "value": "1.\tCan the long text classification method mentioned in the \"Weaknesses\" section effectively address the issue of bankruptcy risk prediction when trained on the dataset presented in this paper?\n2.\tWhat are the improvements and advantages of the method in the paper when compared to DocBERT and its latest improved methods?\n3.\tIn comparison to large language models combined with in-context learning methods, does the method proposed in the paper demonstrate an accuracy advantage?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Reviewer_h86L"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1892/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697934015709,
        "cdate": 1697934015709,
        "tmdate": 1699636119491,
        "mdate": 1699636119491,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UEIPP7WnQx",
        "forum": "dN1IV0Ov8a",
        "replyto": "dN1IV0Ov8a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_8GNw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_8GNw"
        ],
        "content": {
            "summary": {
                "value": "The article discusses a novel approach to predicting bankruptcy risk for companies using textual information from the annexes of annual accounts. This is in contrast to most existing bankruptcy prediction models, which rely on numerical data like financial statements and ratios.\n\nThe authors propose a BERT-based model that processes parallel segments of a document with BERT and then integrates them for a unified prediction. They use a dataset of 20,000 annexes from the Annual Accounts of non-financial companies in Luxembourg to train and validate their model. Their results show that two models achieved a validation precision of approximately 73%, with performance varying based on the length of the documents.\n\nThe study highlights the potential of using deep learning models to extract risk information from unstructured textual data and suggests that this approach can be applied to other domains requiring the analysis of long text."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The article makes a contribution to a lightly researched topic. Bankruptcy prediction using textual data is often focussed on news sentiment, while the authors target the annual statements by the company.\n- The authors contribute to the literature on using arbitrary length textual data in machine learning applications."
            },
            "weaknesses": {
                "value": "- It is unclear what the main contribution is; is it the application of an arbitrary length BERT model to a specific dataset or is it the specific formulation of the arbitrary length BERT model.\n- While it is nice that the authors use the textual information from the appendices to predict imminent bankruptcy, it is not particularly meaningful given that the predictive information in there is not any better than the financial ratios from the tabular data in those same reports. It would mostly be interesting whether the combined predictive value exceeds the predictive value from the ratios alone."
            },
            "questions": {
                "value": "- Was there a specific reason for how you built your arbitrary length BERT model as opposed to different versions in your references? Does your version perform better for general text classification tasks or did you just find it to work better for the bankruptcy prediction task?\n- Can you explain how the different languages are processed by your model? Does the processing to tokens effectively remove the differences?\n- Is there a way to determine some feature importance from your model. Could there be standard phrases in the dataset suggesting imminent bankruptcy that suggest that it should be relatively easy for a machine learning model to predict a company going under?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1892/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698690772769,
        "cdate": 1698690772769,
        "tmdate": 1699636119422,
        "mdate": 1699636119422,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FshBlx7hn0",
        "forum": "dN1IV0Ov8a",
        "replyto": "dN1IV0Ov8a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_WCJF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_WCJF"
        ],
        "content": {
            "summary": {
                "value": "The authors consider the problem of predicting whether a company is at risk of bankruptcy using modern natural language processing (NLP) and deep learning techniques.  In particular, the authors propose a methodology that first divides large text documents into multiple segments, each of which are evaluated independently using the BERT model, and then combines the output of the BERT model on each segment so as to produce a final Risk or Non Risky prediction.  A variety of compression and integration schemes are considered and the authors demonstrate performance that while not as strong as purely numeric methods, does a reasonable job. The main technical contribution appears to be a methodology for applying the BERT model to large text documents that have a number of tokens that exceed BERT's input dimension."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Overall, I thought this was an interesting and fairly well executed empirical paper.  The authors clearly identified the problem to be solved - predicting bankruptcy risk using only text data - and motivate its importance using an actual corpus of financial statements from Luxemborg.  The authors then describe the key challenge one faces when applying an off the shelf language model, like BERT, to large financial documents and nicely walk through their technical approach to solving this problem.  Finally, they evaluate the performance of several variants on the Luxemborg financial statements data set, demonstrating solid performance for a purely text based model.\n\nI am not an expert in the application of BERT models and am unfamiliar with the common heuristics one might use to apply BERT to long documents, but this paper does present a reasonable approach."
            },
            "weaknesses": {
                "value": "My main criticism of this paper is in the empirical findings.  First, it was rather unclear how the training and test set were determined. Was a random selection of documents held out in the test set?  Was the test set the same as that used by Mai et al.?  Finally, where do the \"Risky\" vs \"Non Risky\" labels come from?\n\nNext, I can accept the fact that the performance of a pure text based classifier might not be as good as one that uses financially relevant numeric values, but I think the authors should have directly compared their performance wrt Mai et al.'s work or even a basic approach, e.g. randomly sampling a single 512 token segment from each training document.  Doing so would have demonstrated the benefit of the summarization and integrated prediction approach and justified their usage.\n\nI also found the tables and figures in the experiments and results section hard to interpret.  Was Table 3 an OOS performance measure? How does recall vary by each model configuration? And what conclusion am I supposed to draw from Figure 4? How does it differ from table 3?\n\nLast, I question whether the technical contribution here is significant enough for publication at ICLR.  While I know that a lot of time, energy and technical expertise was required to generate the empirical findings, I'm not sure how broadly this work can be applied."
            },
            "questions": {
                "value": "-what does the following phrase on page 4 mean: \"For this reason, the shuffling and selection of train, test and validation data are done before the pre-processing\"?\n-doesn't the number of segments (and therefore the number of documents trimmed) also depend on delta, the number of overlapping tokens?\n-is sequence/overlap important at all?  What if one just randomly samples segments instead?\n-Can this approach be applied to other corpuses with large text documents."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1892/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699067467880,
        "cdate": 1699067467880,
        "tmdate": 1699636119343,
        "mdate": 1699636119343,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Epyt2vNBCW",
        "forum": "dN1IV0Ov8a",
        "replyto": "dN1IV0Ov8a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_QYDH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1892/Reviewer_QYDH"
        ],
        "content": {
            "summary": {
                "value": "The authors suggest using document segments analyzed via BERT, with and without LSTM networks, for bankruptcy prediction. Despite an unbalanced dataset, their best model attained a 73.3% precision rate. The research also reveals that models using concatenation are nearly as precise as other models discussed in the paper and excel with longer texts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Capable of forecasting bankruptcy using extensive text sequences in multiple languages: French, German, and English.\n- Includes an analysis of the model's performance in relation to document length and variations in the number of hidden layers."
            },
            "weaknesses": {
                "value": "- Relies solely on textual information, and as acknowledged by the authors, numerical data remains crucial for risk prediction.\n- Should still compare to traditional default prediction models in finance, like FIM\n- It will be practical to predict a term structure of bankruptcy probabilities, not just treat it as a simple classification task."
            },
            "questions": {
                "value": "none"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1892/Reviewer_QYDH"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1892/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699257974273,
        "cdate": 1699257974273,
        "tmdate": 1699636119273,
        "mdate": 1699636119273,
        "license": "CC BY 4.0",
        "version": 2
    }
]