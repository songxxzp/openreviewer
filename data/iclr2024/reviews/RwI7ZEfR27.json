[
    {
        "id": "vRQKCyxOEo",
        "forum": "RwI7ZEfR27",
        "replyto": "RwI7ZEfR27",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_xyph"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_xyph"
        ],
        "content": {
            "summary": {
                "value": "The authors train a neural network on fMRI recordings of brain activity: similarly to Large Language Models, the network is trained to predict missing values (random or future) with a self-supervised loss. The paper empirically demonstrated that the learned representations can be used in a variety of downstream tasks, even on a different dataset of fMRI recordings (HCP)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The performance metrics (R and R squared) reported by the authors are impressive given the variability of brain responses across subjects. This ability of the learned representations to generalize beyond the training set (UKB) to a new dataset with new subjects (HCP) is impressive."
            },
            "weaknesses": {
                "value": "A standard protocol for evaluating representations \"downstream\" is to fine-tune a linear predictor or \"probe\" on top of the representations [1, 2]. The fact that the fine-tuned predictor is linear is important: it can measure how well the representations \"cluster\" [3], or linearly correlate, with downstream labels. Yet in this paper, the fine-tuned predictor is a nonlinear neural network with three layers. This raises doubts on whether the representations actually correlate with downstream labels (e.g. age), if they need to undergo many nonlinear transformations before the linear prediction layer. Could the authors comment on this?\n\nThe authors use the terminology of \"foundation model\" and \"language model\" which suggest a novel approach to analyzing fMRI recordings; yet, at its core, their model is a neural network trained with a self-supervised loss (e.g. predict random or future missing values) on fMRI recordings. And there is a rich and existing literature of relevant works that is worth acknowledging. Consider for example [4, 5] as well as their own reference sections. With this context, could the authors explain what contributions they make that are novel with respect to the current literature?\n\n[1] Alain and Bengio, Understanding intermediate layers using linear classifier probes, ICLR workshop 2017.\n\n[2] van den Oord et al. Representation Learning with Contrastive Predictive Coding. Preprint 2019. \n\n[3] Wang et al. Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. ICML, 2020.\n\n[4] Caucheteux et al. Deep language algorithms predict semantic comprehension from brain activity. Nature scientific reports, 2022. \n\n[5] Pasquiou et al. Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps. ICML, 2022."
            },
            "questions": {
                "value": "I believe the authors make interesting contributions and would be willing to raise my score if my concerns and questions (in the weaknesses section) are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6480/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697724871351,
        "cdate": 1697724871351,
        "tmdate": 1699636725472,
        "mdate": 1699636725472,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "48FkcXYSpv",
        "forum": "RwI7ZEfR27",
        "replyto": "RwI7ZEfR27",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_mZsL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_mZsL"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an transformer architecture based model to (a) reconstruct fMRI sequences and (b) predict clinical variables. As fMRI recordings can be seen as multivariable sequences with rich temporal and cross-variable dependencies, such application has a lot of merit and might give rise to a foundational model for fMRI data analysis.\n\nThe architecture of the model follows other built for similar purposes, and is trained to predict masked-out patches of fMRI BOLD sequences. The model is trained on a large corpus of data from UK BioBank, the largest fMRI data repository currently available.\n\nBrainLM shows performance superior to several benchmarks (but: see a question about those below)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is written very clearly, one can follow it easily, the material is presented logically, clearly, and at the same time with sufficient amount of details.\n\nI wholeheartedly support the motivation behind his work. Indeed a LLM-based approach to fMRI sequence analysis makes perfect sense, this methodology should yield great results and help fMRI community to overcome multiple issues with heterogeneity of the data, allowing to pull together large dataset enabling us to train powerful models for neuroscience research and clinical application.\n\nThe way the authors approach the problem is in my opinion technically sound and their solution is exactly what one might expect to see in this context. This gives me a lot of confidence in the soundness of their results and future applicability of the BrainLM model."
            },
            "weaknesses": {
                "value": "Table 3: In the section on related work you mention some models that were trained on fMRI to narrowly predict just one clinical variable, and, presumably, those models are state of the art in their respective predictions of clinical variable. However, in Table 3 you seem to compare BrainLM against some other results. My question here I guess whether the comparison presented in the table reflects the state of the art achieved by other models in predicting certain clinical variables, and not just state of the art using a certain method. The fact that an LSTM or an SVM performs poorly is not that interesting to see, what would be interesting to see is how much better or worse performance we get when compared to the state of the art method specifically trained to predict GAD-7 for example. Same for other clinical scores, a methods does not have to predict all of them at once. (If, in fact, the methods you use in this comparison are the current state of the art, please let me know that this is the case and I will withdraw this criticism)\n\nTable 3: Are the \"competitor\" results obtained by you training these methods on the same data, or these are the numbers reported in the respective studies by the authors of those methods?\n\nThe worry I have in those questions above is whether the benchmarks presented are the \"strong\" ones."
            },
            "questions": {
                "value": "Table 1: It appears that allowing the model to see more context (less masking) yields significantly better better performance. (a) Have you tried to train the model with even less masking (MR=0.1) and what were the results? (b) If the trend of \"less masking = better performance\" continues, then what would be the limit of this: at what point using less masking will start to hurt generalizability?\n     \nTable 2: It would help the reader a lot, if, in addition to MSE and R^2 values, you would also report the absolute error in the original units of measurement. For general clinical variables such as age it would help the general public to better understand what kind of error the model makes as measured in years (which is immediately understandable to anyone). For clinicians working on GAD, PHQ, etc scales it would also be immediately impressive to see the performance estimate directly in those units.\n\nPage 5 last paragraph: When you were fine-tuning BrainLM to regress metadata variable, did you predict all of the listed variables (age, neuroticism, PTSD, anxiety) at once as 4-head output, or it was a separate fine-tuning process per variable?\n\nTable 3: What does the \"Raw data\" row indicate? For example for \"Age\" we have \"2.0 +/- 0.22\"? Does this somehow show the variability of age in the dataset (unlikely as 2.0 is too small number for age variability)? Or is this the error that a naive linear model makes? Unclear.\n\nFigure 4: \"CLS\" abbreviation is not explained anywhere in the text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6480/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698308846789,
        "cdate": 1698308846789,
        "tmdate": 1699636725363,
        "mdate": 1699636725363,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cLYLrqH1uC",
        "forum": "RwI7ZEfR27",
        "replyto": "RwI7ZEfR27",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_NWMt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_NWMt"
        ],
        "content": {
            "summary": {
                "value": "The paper describes a new model for fMRI data trained in a self-supervised manner and then fine-tuned to predict a variety of downstream tasks of interest in neuroscience including brain activity forecasting, clinical outcome prediction and brain network identification. The model is shown to enable better performance than a variety of reported baselines on the above tasks."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper operates at the intersection of two areas of intense interest (large-scaled foundation models and neuroscience), and it situates itself well in both domains with a clear setup and motivation, and clear illustration of the modeling paradigm chosen. The results look impressive relative to the baselines chosen."
            },
            "weaknesses": {
                "value": "My main concerns lie with the fact that the network is very modestly sized for a foundation model, and that the baselines aren't a priori motivated in a way that would support the contributed model as truly SOTA. \n\nRegarding the former, 13M parameters is smaller than the MLP, LatentODE, and LSTM baselines, and much smaller than what I would consider to be even a small foundation model. For example, HuBERT-Base is a 90M parameter model trained on ~1K hours of speech data (12 layers and 8 heads with larger dimensions than BrainLM). So while BrainLM is a model trained on a nontrivial amount of fMRI data using SSL, it is remarkably small for a foundation model. That would be fine if performance were good relative to a set of baselines chosen based on prior results on fMRI decoding, but I'm not sure if this were the case. At least, the paper does not make it obvious (for example, the NODE, LatentODE, and GCN citations point back to the original papers, none of which have neuroscience applications). Thus, the baselines are also novel, so it's unclear how impactful beating them should be. Considering that the UKB data was released in 2016 and the HCP data published in 2021, I would be surprised if there are no baselines in the literature against which the present contribution can be evaluated. Without this contextualization against past work, neither the performance numbers nor having trained a small SSL model on thousands of hours of fMRI data is sufficiently impactful for ICLR in my judgement. \n\nSome additional comments: \n* In discussion of large-scale SSL for neuroscience, the paper would benefit from also considering Kostas et al. 2021 10.3389/fnhum.2021.653659. \n* More sophisticated methods could be used for interpretability than attention maps (e.g. Chefer et al. CVPR 2021). \n* The legend for Fig. 5 has LatentODE, LSTM, and NODE whereas the text talks about ODENets and non-pretrained BrainLM. Please add the non-pretrained BrainLM results or correct the text. In addition, the text could make a clearer mapping from legend to citations (e.g. \"NODE (Chen et al.), LatentODE (Rubanova rt al.)\"). Finally, I am surprised that there is an unpretrained BrainLM baseline in table 4 but not table 3.\n* Something strange seems to be going on with NODE training -- it performs much worse than other methods and gives a large *negative* $R^2$ value in table 4 (likely indicating severe model mismatch, and giving me concern about whether training failed entirely for this model). \n* Considering the claims regarding \"springboard for accelerated research\" via a foundation model, the paper should make explicit that weights and code will be released."
            },
            "questions": {
                "value": "* Was figure 3 randomly sampled or cherry-picked? \n* The generalization numbers ($R^2=0.464$ within dataset or $.278$ across) need to be contextualized -- how do we know they are good?\n* Why are the 1% and 100% training results of interest? Should we not be surprised that more data improves performance, and if it is surprising why not show a trend over more than just two data sizes? \n* 40% dropout seems quite high -- is this correct, or a typo? \n* Stats on fig 5: how were they done? Hard to imagine BrainLM beats LSTM and LatentODE at later timepoints given the visualized error bars, was it something like BrainLM vs the average of the rest such that the effect of NODE dominated? \n* What motivated the specific network architectures chosen? They vary substantially in number of parameters. \n* What were the other training details (e.g. learning rates and their schedules, dropout and other regularization for the SSL training, gradient clipping if any, etc)? These would be fine in an appendix but should be included for reproducibility."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6480/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812838485,
        "cdate": 1698812838485,
        "tmdate": 1699636725243,
        "mdate": 1699636725243,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bX7QyNg3sV",
        "forum": "RwI7ZEfR27",
        "replyto": "RwI7ZEfR27",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_4kZC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6480/Reviewer_4kZC"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose BrainLM, a foundation model designed to analyze fMRI brain activity recordings. BrainLM is trained on 6,700 hours of fMRI data using a Transformer-based architecture. Experimental results show that the proposed BrainLM generalizes well to diverse downstream tasks. Through fine-tuning, it can accurately predict clinical variables such as age and anxiety, while in zero-shot learning, it can identify intrinsic brain networks from fMRI data, offering an approach to understanding spatiotemporal brain dynamics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is written clearly and is well-structured; the motivation is intuitive and the method is easy to follow.\nThe author collected a large-scale fMRI dataset, which enhances the reliability and generalizability of the pre-trained BrainLM. \nExtensive experiments on diverse downstream tasks like clinical variable prediction and brain state prediction are relatively comprehensive. The additional attention analysis also covers the spatial patterns in the brain."
            },
            "weaknesses": {
                "value": "Lack of novelty, the MAE-like pretrain model and method used in this paper are reasonable, but they are known in the field.\n\nLack of comparative baselines: The baselines used for both clinical variable prediction and brain state prediction are somewhat limited. Baselines such as SVM are outdated. The unsupervised MAE-like model mentioned in the related work should also be considered for comparison.\n\nBesides random masking and future masking, more mask strategies should be investigated, like uniform masking and parcel-level (spatial) masking."
            },
            "questions": {
                "value": "What is the computational cost of the pretraining?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6480/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6480/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6480/Reviewer_4kZC"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6480/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698846877645,
        "cdate": 1698846877645,
        "tmdate": 1699636725142,
        "mdate": 1699636725142,
        "license": "CC BY 4.0",
        "version": 2
    }
]