[
    {
        "id": "ctpbia0szu",
        "forum": "pijvVzhRdZ",
        "replyto": "pijvVzhRdZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_4hah"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_4hah"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the topic of federated pretraining, and the authors propose a distributed pretraining method, which utilizes meta-learning to simulate the distributed scenario and also balances performance and fairness. The proposed method is evaluated on three public datasets and outperforms compared methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-\tThis paper studies an important topic. Exploring distributed pretraining strategies is helpful for downstream tasks.\n-\tThe motivation for performing pretraining in a distributed way is clear.\n-\tThe paper's organization is easy to follow.\n-\tThe proposed method outperforms the compared methods on three datasets."
            },
            "weaknesses": {
                "value": "-\tThe observation of centralized pretraining causes side effects like performance biases are not well analyzed/explained.\n-\tThe idea of using meta-learning to simulate distributed scenarios may not make sense for non-iid settings. If the clients' data are non-iid distributed, using local data for pretraining may not help. The local simulation cannot represent the global distributions.\n-\tThe meta-learning method part is not clear. The data split needs to be clarified.\n-\tThe technical contribution of applying meta-learning for a new distributed pretraining setting might be marginal.\n-\tCompared with using public datasets for local pretraining, this method suffers further communication costs.\n-\tThe experimental settings of splitting classes into pretraining and unseen downstream tasks are not practical.\n-\tSome experiment details lack of explanation."
            },
            "questions": {
                "value": "-\tWhy does centralized pretraining cause side effects like performance biases? It is better to elaborate more on this.\n-\tThe meta-learning part is not clear. How to split the unseen task data and the client data for pretraining? The assumption that the downstream tasks are unseen may not be proper enough. For example, if a client joins FL, it usually has specific goals, and the client data will be task-specific. The clients have no motivation to hold unrelated data for pretraining. And it is also weird to keep the task-specific (downstream) data unseen.\n-\tFollowing the previous point, the experimental settings are also not practical to me. First, clients in FL usually may not hold 'new classes' for pretraining tasks; the client data are strongly related to the task in general. Second, for real-world FL, client local data are valuable and cost a lot to annotate. It does not make sense to split out part of classes for pre-training; instead, using as much data as possible to promote local performance is important.\n-\tIf public datasets are available for pretraining, why don't we include them? It would be interesting to follow Nguyen et al.'s idea that uses some public data to pre-train the model and add this into comparison.\n-\tWhy does the Non-IID setting present higher accuracy than the IID setting? When data becomes Non-IID, the model should suffer a performance drop.\n-\tSome Non-IID related methods (e.g., SCAFFOLD[1], FedDyn[2]) also aim to learn a good global model, which can serve as the initialized model. Adding them into comparison is helpful.\n-\tIn Table 5, the centralized pretraining is based on a centralized dataset from all the clients; why does this introduce significant performance variance? If the centralized data are from all clients, the pretraining should present less variance than random initialization. Also, it needs to be clarified how to build the centralized dataset.\n\n[1] Karimireddy, Sai Praneeth, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. \"Scaffold: Stochastic controlled averaging for federated learning.\" ICML, 2020.\n\n[2] Acar, Durmus Alp Emre, Yue Zhao, Ramon Matas Navarro, Matthew Mattina, Paul N. Whatmough, and Venkatesh Saligrama. \"Federated learning based on dynamic regularization.\" ICLR,2021.\n\nOverall, this paper studies an important topic, FL pretraining in a distributed manner, and also considers unseen data and fairness. The proposed method shows better performance and performance fairness than the compared methods. However, the experimental settings are not practical to me. Furthermore, the authors show a good motivation that some existing pretraining methods may suffer performance variances, but this interesting observation needs more in-depth analysis and explanations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Reviewer_4hah"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698291821161,
        "cdate": 1698291821161,
        "tmdate": 1699636312198,
        "mdate": 1699636312198,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JOHL4NuQbt",
        "forum": "pijvVzhRdZ",
        "replyto": "pijvVzhRdZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_khz5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_khz5"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces CoPreFL, a pre-training approach for federated learning that aims at training a pre-trained model to serve as a good initialization point for FL. The authors demonstrated that by doing so, a better performing and fair global federated model can be achieved for federated clients. Specifically, the authors utilize meta-learning techniques and incorporate model performance variances among models as an additional term in the meta-objective to promote fairness. Interestingly, the method also additionally considers a scenario where the server holds a server dataset that can be used in the meta-training procedure. The paper also conducted empirical experiments to showcase the superior performance and fairness of the model trained by CoPreFL."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is clearly written.\n2. Handling of the scenario where the server holds a portion of the data is interesting and important, which could also be practical due to the wide presence of public datasets.\n3. The experiments show promising results."
            },
            "weaknesses": {
                "value": "1. The paper lacks theoretical performance/fairness guarantees or analyses of the proposed algorithm.\n2. The practicability of the method requires further justification, in terms of the number of tasks and amount of data required.\n\nMore details can be found below in the Questions section."
            },
            "questions": {
                "value": "1. Why is it the case that the existing works one federated meta learning for personalization are inapplicable to the problem setting of this paper? For the three papers (Jiang et al., 2019; Fallah et al., 2020; Collins et al., 2021) cited in the introduction, is it possible to simply replace the personalization stage of their algorithms with a federated global model training? If possible, can they be compared to as baselines in the experiment section?\n2. In scenario II, why is it reasonable to use the server\u2019s data as the unseen dataset for downstream tasks? How to make sure the artificial tasks generated from the server data are now a good representation of potential downstream tasks? The final goal of the algorithm is quick adaptation to the downstream tasks of clients, rather than the server. Is there a mismatch here for the optimization objective? Please justify this point since Scenario II is also an important claimed contribution of the paper.\n3. The artificial partition of the server\u2019s dataset into $|m|$ equal partitions also seems to be lacking justification. Also, empirically speaking, how well does your method work as compared to use (all local support data + all server data) for normal FedAvg training as the pre-trained model?\n4. Can the authors briefly introduce FedMeta in the main text since it is an important baseline? Also, you probably need to highlight the difference between FedMeta and CoPreFL.\n5. In reality, does the CoPreFL method require access to a large number of tasks to work well? For example in the experiments of this paper, we only perform 5-way classification for CIFAR-100 data, which comprises 100 classes. I am guessing that this is done so that a variety of tasks could be generated. Let\u2019s say that my final goal is to train a good and fair model on CIFAR-100 now, how should I go about training the meta pre-trained model? Could the author clarify this point?\n6. I believe it is a bit unclear in the paper that how does FedAvg and q-FFL (serving as baselines) do meta learning and hence can be compared to in the experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698396232350,
        "cdate": 1698396232350,
        "tmdate": 1699636312133,
        "mdate": 1699636312133,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1nXtTPfJIB",
        "forum": "pijvVzhRdZ",
        "replyto": "pijvVzhRdZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_n2CX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_n2CX"
        ],
        "content": {
            "summary": {
                "value": "Recent works showed that initializing federated learning (FL) with a pre-trained model can improve the FL performance compared to random initialization. However, all these works have considered the pre-trained model to be trained centralized and didn't tackle the scenario that the pre-training datasets are distributed across multiple clients and cannot be shared due to privacy issues. To fill in this gap, this paper exploited the idea of meta-learning and proposed an FL-based pre-training method to achieve a good initialization for unknown downstream FL tasks. Both the average performance and fairness across the FL participants are considered in the pre-training objective."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Inspired by the meta-learning methods, this paper introduced a new FL pre-training method. Even though the idea of balancing between average performance and fairness is not new, it's the first time to be applied to the FL pre-training stage.   \n\n- The authors provided a relatively comprehensive literature review and clearly presented the novelty of the proposed method compared to existing works.\n\n- The experimental results are impressive. The proposed algorithms are shown to outperform all the tested baselines in both average performance and fairness metrics."
            },
            "weaknesses": {
                "value": "My major concern is about the motivation of the proposed FL pre-training problem. I'm not convinced that an additional fairness-aware pre-training process is needed for FL. Specifically,\n\n- This paper has focused on a setting where the pre-training dataset is not centralized. However, I wonder whether such a setting exists in any real-world application given so many open-sourced pre-trained models (e.g., Bert, GPT2, ViT, etc.) and large-scale public datasets (Common Crawl, Wikipedia, ImageNet, etc.) in different areas. Some real-world examples are needed to clarify the necessity of the FL pre-training stage.\n\n- Even though the empirical results show that the proposed methods outperform the \"Centralized\" baseline, the centralized model tested in Table 5 is actually personally trained with a subset of data. There is no public large-scale pre-trained model tested in the experiments.       \n\n- In Section 4, FedAvg is used in the fine-tuning stage in all the experiments. However, I think the comparison between CoPreFL+FedAvg and Centralized+FedAvg is not enough to show the superiority of the proposed method. Why is the fairness issue must be tackled in the pre-training stage instead of the fine-tuning stage? How if I start from a public pre-trained model and do fine-tuning with any fairness-aware FL method (e.g., Centralized+FedProx)? Note that model pre-training is usually much more expensive than fine-tuning. Then, isn't it more sensible to consider the additional steps for optimizing (2) in the fine-tuning stage?"
            },
            "questions": {
                "value": "-- In Eqs. (1) and (2), what does the $\\mathcal{G}$ denote? Does $p(\\mathcal{G})$ represent the distribution of a single downstream FL task or all the downstream tasks? If $p(\\mathcal{G})$ is the distribution of a single task $\\mathcal{G}$, there should be an additional expectation over $\\mathcal{G}$ for both (1) and (2). Otherwise, the variance equation in (2) is weird. Why did you compute the variance of loss over clients in different FL tasks? For different downstream tasks, the loss function $f$ might be even not comparable.   \n\n-- In Algorithm 1 Line 17, How is the gradient computed on the server side with distributed data?\n\n-- In Appendix B, the authors mentioned that they assessed various balancer values $\\gamma$ in all scenarios and reported the best-performing value. How did you define the \"best\" here given the accuracy-fairness tradeoff?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Reviewer_n2CX"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698927604052,
        "cdate": 1698927604052,
        "tmdate": 1699636312065,
        "mdate": 1699636312065,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D2yLFUHyct",
        "forum": "pijvVzhRdZ",
        "replyto": "pijvVzhRdZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_8PDC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3574/Reviewer_8PDC"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces CoPreFL, an approach that uses meta-learning techniques to create pre-trained models capable of adapting to various FL tasks while balancing utility performance and fairness across clients. The authors explore two scenarios: one where data is exclusively owned by clients and another where both clients and the server possess data. The paper provides empirical results on various settings using CIFAR100, TinyImageNet, and FEMNIST, along with comparisons to several FL baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written, with clear and efficient communication of ideas. The federated learning settings and the problem addressed are highly relevant and important within the field of federated learning. The proposed solution exhibits good empirical performance on CIFAR100, TinyImageNet, and FEMNIST, in comparison to other baselines, even though the authors note that no baselines from other works are available for this particular task."
            },
            "weaknesses": {
                "value": "My main concern relates to the novelty of this approach and its performance guarantees. Let me elaborate further:\n\n* **Novelty** - Algorithm 1 seems very similar to FedMeta [1] except for the objective which is a linear combination between a fairness term and a utility term.\n* **Performance Guarantees** - CoPreFL currently lacks formal performance guarantees. This work would significantly benefit from a formal analysis of the proposed method(s) to provide a better understanding and confidence in their behaviour and their performance. Currently, evaluating the empirical results is challenging due to the nature of the baselines, which (to my understanding) have been adapted to accommodate pretraining and are not actual baselines (as the authors also identified) since they are optimized for entirely different scenarios.\n\n\n[1] Federated Meta-Learning with Fast Convergence and Efficient Communication. Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, Xiuqiang He"
            },
            "questions": {
                "value": "**Main questions:**\n\n* What are the algorithmic differences between FedMeta and algorithm 1?\n\n* Algorithm 2: What is the motivation behind applying the meta update to the temporary global model? Wouldn't applying the meta-update to the local models (akin to personalized FL) make more sense in the context of FL? Can you provide a real example of scenario 2?\n  \n* How should the support and query sets be selected in practice by each client?\n\n * What is the difference between the performance variance across clients during pretraining and downstream tasks for high $\\gamma$ in the noniid settings? \n\n* Experiments: Could you provide additional details regarding your selection process for the number of communication rounds and local epochs? Additionally, considering that you've reported performance on the worst-performing clients, is there a reason you didn't consider AFL or qFFL for larger values of q, such as q=20, which optimize for worst-case fairness across clients? \n    \n* Does the phrase \"All of these schemes are adopted during the pre-training phase to construct initial models.\" in \"Baselines for pre-training\" mean that qFFL and FedAvg algorithms were modified to consider pertaining? \n  \n* Can you please explain CoPreFL performance on the Non-IID settings of tables 1, 2 and 3? How can data heterogeneity across clients have no large impact or even provide better results (especially given that local epochs are > 1)? My understanding is that the heterogeneity introduced across clients in the experiments is low.\n\n*Also please see minor suggestions & typos:*\n\n\n* section 2: \"ptre-training stage\"-> pre-training stage\n\n* page 4 prior to Eq. 2: \"achieving performance gains any unseen FL task\"-> achieving performance gains on any unseen FL task\n\n* Section 3.2.: the phrase \"local training iterations\" is misleading because the algorithm illustrates only a single local epoch, even though on experiments you consider 5.\n\n* Fix the rephrasing in the abstract and conclusions to clarify that both scenarios are addressed: where clients own the data exclusively, and where both clients and the server own the data.\n\n* page 5: \"The objectives of our pre-trained model are to strike a balance\" -> The objective of our pre-trained model is to strike a balance"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3574/Reviewer_8PDC",
                    "ICLR.cc/2024/Conference/Submission3574/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699485115862,
        "cdate": 1699485115862,
        "tmdate": 1700737926910,
        "mdate": 1700737926910,
        "license": "CC BY 4.0",
        "version": 2
    }
]