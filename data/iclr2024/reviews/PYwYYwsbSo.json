[
    {
        "id": "HYNetLQHgX",
        "forum": "PYwYYwsbSo",
        "replyto": "PYwYYwsbSo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an innovative approach to identifying the \"optimal\" instruction for large language models with the aim of improving generative quality. This work falls under the burgeoning area of prompt search methods, which have gained significant attention recently, exemplified by methods such as APE, RLPrompt etc. Unlike conventional methods that optimize discrete instructions, the authors propose optimizing a low-dimensional \"soft prompt\" using dimensionality reduction. The optimized soft prompt is applied to an open-source Lifelong Learning Model (LLM) to generate instructions for a black-box LLM. The optimization process is iterative, involving zero-shot evaluation of the black-box LLM's performance, which is then used in a Bayesian optimization scheme to refine the soft prompts. This iterative process continues until convergence. Experimental results on the BBH benchmark show that the proposed method yields superior performance across all 32 tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed methodology is both innovative and well-explained, making a valuable contribution to the area of prompt optimization in large language models.\n- The empirical results are compelling, demonstrating superior performance across all 32 tasks on the BBH benchmark.\n- The use of Uniform as a comparative baseline effectively underscores the benefits of the proposed iterative Bayesian Optimization (BO) process."
            },
            "weaknesses": {
                "value": "- The paper could benefit from a broader evaluation scope. Considering additional tasks such as reasoning QA GSM8K, machine translation, or summarization could provide a more comprehensive view of the method's effectiveness.\n- The inclusion of only two comparative baselines, APE and Uniform, limits the robustness of the evaluation. Expanding the set of comparative baselines could provide a more holistic understanding of the method's performance relative to existing work. For example, RLprompt and Autoprompt are also two good prompt search methods.\n- The paper presents a puzzling result related to APE's performance, which is reported to have only a 0.04 accuracy in Figure 1. Upon closer inspection, it becomes apparent that the original APE experiments were based on instructgpt, where the prediction probability could be obtained. While this paper employs the more powerful Turbo 3.5 API, which cannot access the prediction  probability. Thus I think the comparison here is not fair enough, as APE is a much weaker version than the original paper. This discrepancy introduces confusion and could affect the perceived validity of the comparative results.  This drawback again highlights a more fair comparison is required, e.g., other prompt search baselines are needed. Also, what about the comparison with zero-shot COT, 'Please Think step by step'? \n- There is ambiguity in the claim about the method being applicable for zero-shot evaluation. While it's true that the proposed method employs a black-box LLM API for zero-shot generation, the Bayesian Optimization (BO) process requires labeled data. This seems to contradict the zero-shot claim and may constitute an overstatement."
            },
            "questions": {
                "value": "- I wonder why the results of APE are so weak in Figure 1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3882/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3",
                    "ICLR.cc/2024/Conference/Submission3882/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730513024,
        "cdate": 1698730513024,
        "tmdate": 1700631271023,
        "mdate": 1700631271023,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fKL7QT1PCT",
        "forum": "PYwYYwsbSo",
        "replyto": "PYwYYwsbSo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_4arY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_4arY"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to optimize the instructions for black-box large language models. The proposed method uses an open-source LLM to convert a soft prompt to an instruction, and then uses the instruction as input to the black-box LLM. Bayesian optimization is then used to optimize the soft prompt, which can iteratively propose new soft prompts and instructions to be evaluated by the black-box LLM."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method of using another open-source LLM to help convert a soft prompt to an instruction and then using the instruction as input to the black-box LLM is an interesting and intuitive idea. \n- The graphical illustrations in Figure 2 and 3 are nice and helpful for understanding.\n- The results in Figure 4 indeed show that the proposed method improve over APE and Uniform."
            },
            "weaknesses": {
                "value": "- One overall observation from the experimental results which concerns me is that it seems that APE does not consistently perform better than Uniform? Both Figure 4 and Figure 1 seem to suggest this, for example, in Figure 1, the improvement over APE seems to be larger than over Uniform. This is an unexpected observation and I think should be explained, because it may suggest that performances of APE might be underestimated in the experiments here.\n- I have some questions and concerns about the instruction-coupled kernel. First of all, it seems that to calculate this kernel between a pair of input soft prompts, you need to have the evaluated scores for both soft prompts (correct me if I'm wrong)? If this is the case, then when you calculate the vector $\\boldsymbol{k}$ in equations 4 and 5, this instruction-coupled kernel cannot be used to calculate these kernel values and therefore these kernel values will simply use the normal squared exponential or matern kernel? In this case, I wonder how much this instruction-coupled kernel actually helps the performance of the Bayesian optimization, because the vector $\\boldsymbol{k}$, which directly measures the distance between a new soft prompt and other previously evaluated soft prompts and therefore has a huge influence on the uncertainty measure, cannot make use of it. I see that you have an ablation study in Table 4 to show the effect of using the instruction-coupled kernel, but why did you only show the comparison for a small number of selected tasks? I think to see whether this kernel is actually useful, it's important to fairly run this ablation study in all tasks and make an overall comparison.\n- About the ablation study (Section 4.3), it looks like the scores \"w/o Manual\" is in general better than \"Manual\"? This is also puzzling because it implies that the meta-prompt used by APE may not be useful...\n- The proposed method InstructZero seems to only optimize the zero-shot performance of the instructions instead of few-shot performance. However, since you already have access to these input-output exemplars which are used as input to the open-source LLM, why don't you also use them as input to the black-box LLM to improve the performance? So this may bring into question how practical the experiments are.\n- (minor) Equations 4 and 5, it seems that the matrix $K$ is not explained."
            },
            "questions": {
                "value": "My questions are listed under \"weaknesses\" above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831444964,
        "cdate": 1698831444964,
        "tmdate": 1699636346624,
        "mdate": 1699636346624,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FvvblGVMIX",
        "forum": "PYwYYwsbSo",
        "replyto": "PYwYYwsbSo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use Bayesian optimization to learn an instruction with an open-source LLM so that the instruction improves the zero-shot results of a black-box LLM. Since instructions are discrete, this work instead iteratively learns a small soft prompt which then gets decoded as an instruction. Each updated instruction is evaluated on the black-box LLM whose training accuracy is used to find a better soft prompt."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is an interesting direction toward automating prompt engineering for API models, and shows strong results."
            },
            "weaknesses": {
                "value": "It would be equally interesting to see qualitative analysis of the errors and various failures modes by the method and the different components used for optimization (e.g. open-source/black-box LLMs)."
            },
            "questions": {
                "value": "Some of the similarity metrics are chosen because black-box models don't necessarily return the log-probs. An ablation could have been run where an open-source model is used for both instruction proposal and loss evaluation. Then, we have access to log-probs and/or gradient and will have a better understanding of how much performance we are losing. Could be interesting, not saying this should have been run."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3882/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3882/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698886341371,
        "cdate": 1698886341371,
        "tmdate": 1699636346558,
        "mdate": 1699636346558,
        "license": "CC BY 4.0",
        "version": 2
    }
]