[
    {
        "id": "XVDPQVLycx",
        "forum": "x5txICnnjC",
        "replyto": "x5txICnnjC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_mbP3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_mbP3"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors use mirror descent principles to derive the distribution of final synaptic weights, under certain assumptions. Theoretical findings demonstrate that this distribution is determined by mirror descent potentials. Analyzing synaptic weight distributions before and after training is crucial for understanding brain mechanisms. The paper applies mirror descent theory to distinguish learning rules in the brain, modeling it under chosen synaptic geometry. Drawing from this theory, the paper shows that, under specific assumptions, weight changes in dual space follow a Gaussian distribution. This insight aids in inferring synaptic geometry from the weight distribution. The authors validate this approach through experiments on artificial neural networks and demonstrate its applicability to real neural data."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The application of concepts from mirror descent to underscore the significance of selecting the appropriate distance function is a commendable idea."
            },
            "weaknesses": {
                "value": "The main drawback is the multitude of assumptions made in the article, leading to a highly robust conclusion. I've outlined what I consider to be the most unreasonable five assumptions:\n\n1. Our brain is a feedforward network with no feedback and lacks any dynamic processes.\n2. During learning, only the neurons in the last layer of our brain update.\n3. Our brain should exclusively perform a supervised learning task.\n4. Our brain uses gradient descent algorithms.\n5. The optimal values for our brain's neurons for a given problem are unique and deterministic.\n\nEach of these five assumptions is overly restrictive, and some are evidently incorrect, conflicting with known experimental evidence. \n\nMoreover, the conclusion itself also appears highly unreasonable: the distribution of synaptic strength in our brain neurons, as well as the brain's structure and the environmental context (task execution), appear to be unrelated. The distribution of synaptic strength is solely related to geometry.\n\n And the conclusion itself lacks significance. What matters is, assuming the article's conclusion is correct, why we would choose this specific geometry, what advantages it offers, and how we arrive at such a choice."
            },
            "questions": {
                "value": "see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "no"
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Reviewer_mbP3"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698245956343,
        "cdate": 1698245956343,
        "tmdate": 1699636688243,
        "mdate": 1699636688243,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "X0fR2LMHrx",
        "forum": "x5txICnnjC",
        "replyto": "x5txICnnjC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_GuwS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_GuwS"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a theoretical framework for understanding the geometry of synaptic changes based on the synaptic weight distribution. In particular, they show that the synaptic weight distribution in real brains are inconsistent with vanilla gradient descent, which assumes Euclidean distances in weight space. Based on the Mirror descent framework, they derive a theorem that shows that the distribution of weights after learning depends on the initial distribution plus a Gaussian in the dual space for large models and data. The authors then show that the theorem holds in a linear regression setting, and that hypothesizing the wrong potential yields non Gaussian weight distribution. Then, the authors show that their theorem holds well despite unsatisfied assumptions in the case of classic deep learning convnets fine-tuned on ImageNet data. Finally, they consider biological data and conclude that both the distribution before and after learning are needed to conclude about the geometry of synaptic changes, but that vanilla SGD can be ruled out."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strengths of the paper are:\n\n**Originality:** The approach is original and principled, and it can make verifiable predictions about the biology. It is nice that the theory is robust to changes in the potential.\n\n**Quality:** The quality of the text and figures is high.\n\n**Clarity:** The paper stays very clear despite the theorem being a tad math-heavy.\n\n**Significance:** I think tackling the question of what geometry is followed by synapses in the brain is significant. It is true that most computational neuroscience work assume vanilla SGD so the question whether the resulting weight distributions are coherent with biological data is an important point."
            },
            "weaknesses": {
                "value": "The main weakness of the paper is that even though the theory is agnostic to the loss function and dataset, it seems that it is not agnostic to the architecture given section 4.3. So it would maybe make sense to also try more plausible architectures than ANNs to test the theory like continuous Hopfield networks or Spiking networks trained with surrogate gradients for instance, or at least vanilla RNNs, since the brain is highly recurrent. This would provide a sense of how important is the architecture vs the learning rule."
            },
            "questions": {
                "value": "- Section 4.4: I find the choices of the initial $w_0$ surprising to demonstrate the fits, isn't $w_0$ supposed to be the distribution before learning? If yes then it is surprising that it needs to be a mix of two constants since it is likely not the case in brains. Could the authors elaborate on that?\n\n- Can you elaborate on the link between geometry of plasticity and the locality of the learning rule? I would expect non Euclidean geometry to be non local since the metric tensor needs to be inverted, however Eq 7 does look local. \n\n- Isn't the use of optimizers such as Adam a way to have a different geometry of plasticity in ANNs?\n\n\nMinor: \n\nFig 3B: caption is not coherent: top/bottom should be left/right.\n\nFig 4: I see the histograms in pink and not blue as written in the caption."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Reviewer_GuwS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698408857191,
        "cdate": 1698408857191,
        "tmdate": 1699636688100,
        "mdate": 1699636688100,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C9Ga3FagmR",
        "forum": "x5txICnnjC",
        "replyto": "x5txICnnjC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_DFTN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_DFTN"
        ],
        "content": {
            "summary": {
                "value": "The paper uses the mirror descent framework to derive results for the distribution of weights in converged networks. The paper shows that under a linearity assumption (and an L2 loss), the final distribution of weights is Gaussian, and this result can be used to analyse weight updates in trained deep nets and also synaptic updates in brain regions."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:\n1. The paper is, for the most part clearly written, and understandable. The mathematical sections in the main paper are also quite accessible and easy to follow.\n\n2. The idea for using the mirror descent to analyse synaptic weight changes is an elegant one, and the simplifying the analysis using the linearity assumption indeed seems to make the problem more tractable for use on networks applied to data.\n\n3. The experiments in section 4 are fairly thorough in validating the theory presented in section 3."
            },
            "weaknesses": {
                "value": "1. The distinction between \"loss function\" and \"potential\": The paper claims in section 2 that the mirror descent framework splits a synaptic weight update gradient into two terms: one dependent on \"external errors\" i.e. the loss function $l$, and one \"intrinsic to the synapse\" i.e. the potential $\\phi$. However, I am skeptical that this is generally true: to the best of my understanding, we can say that gradients with respect to the potential $\\phi$, $\\Delta\\phi$ are independent of gradients wrt the the loss $\\Delta l$. However, given that both the loss function and potential are functions of the synaptic weights, and that the loss function is either chosen by the practioner or unknown (in the case of the brain), unless we _explicitly_ choose $l$ to represent _only_ errors extrinsic to the synapse, it is not clear to me how we can guarantee the above statement. Relatedly, it is also not clear to me whether we can always pick a loss function that only captures non-synapse-related changes in weights, and if we can guarantee that we have managed this in every use case.\n\n2. Finally, the paper claims in section 1 to \"make experimental predictions\" and provide \"new theoretical insights...about learning algorithms in the brain\". In section 4.4, while it is clear from the results and the analysis that a non-Gaussian distribution of weights under the linearity assumption might indicate a non-Euclidean synaptic geometry, it is not clear how we can interpret this for insights about how learning happens in the brain, and for potential plasticity mechanisms. It is also not clear how extensible the analogy is from deep recurrent networks is to the brain -- synaptic weight changes may not be analogous to network weight updates via gradient descent, and therefore any theoretical results based on gradient descent may not port easily to neuroscientific insights.\n\nThe weaknesses taken together seem to make the paper fall short of the claims in the introduction. Without the interpretability, and further experimentation with neuroscience data, it is not clear to me what the framework adds in terms of neuroscientific insight. While it might be useful for analysing deep net behaviour, again, it is not clear how this can be used to improve deep net training either.\n\nMinor point:\nTerminology -- the terms \"loss function\", \"distance\" and \"geometry\" are used interchangeably without clarification, throughout the paper, and particularly in sections 1-2.1. It is not until section 2.1 that the distinction between the three terms and what they indicate becomes somewhat clear. This hinders readability and generally makes it very hard to grasp the premise of the paper or its implications without these terms being clearly explained."
            },
            "questions": {
                "value": "1. How can we guarantee that the loss function / potential function separation truly represents a separation between extrinsic and intrinsic factors in the weight changes?\n\n2. How to evaluate whether the linearity / Gaussian assumption has been violated, in cases where the loss and potential function are unknown?\n\n3. How to make the \"geometry of synaptic weight changes\" more interpretable for neuroscientific insight?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Reviewer_DFTN"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698768394612,
        "cdate": 1698768394612,
        "tmdate": 1700303828971,
        "mdate": 1700303828971,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "izzQy52qF0",
        "forum": "x5txICnnjC",
        "replyto": "x5txICnnjC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_jXnh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6281/Reviewer_jXnh"
        ],
        "content": {
            "summary": {
                "value": "This paper develops a theory, based on mirror descent, of the distribution of synaptic weights changes. In particular, this distribution depends on the geometry of synaptic plasticity. They test theory predictions which are largely verified."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I\u2019m a big fan of the ambition in this paper. It\u2019s original, the results are good, and this line of work could have big implications. That being said, I found the paper really lacking in clarity (see below)."
            },
            "weaknesses": {
                "value": "The big assumption that the brain is doing gradient descent\u2026\n\n\u201cNotably, even if the brain does not estimate gradients directly, as long as synaptic weight updates are relatively small, then the brain\u2019s learning algorithm must be non-orthogonal to some gradient in expectation\u201d What\u2019s the actual citation for this?? (i.e. not a review)\n\nI found the paper pretty dense, and not easy to follow what was going on where, and I always had to keep lots of things in mind at any moment. I\u2019m not sure exactly what to suggest, but considerable rewriting / putting things in appendices / focussing on intuition would be a good idea.\n\nCouldn\u2019t parse Fig 3. Needed more help in the caption / annotation..\n\n\u201cNevertheless, with this data we can rule out a Euclidean synaptic geometry, and if we do have access to w0, then our results show that it is indeed possible to experimentally estimate the potential function.\u201d Where do you show this? It\u2019s not in Fig 5.\n\nI didn\u2019t follow the explanation before eqn 14. Could do with some clarifying."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6281/Reviewer_jXnh",
                    "ICLR.cc/2024/Conference/Submission6281/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699246342994,
        "cdate": 1699246342994,
        "tmdate": 1700699731608,
        "mdate": 1700699731608,
        "license": "CC BY 4.0",
        "version": 2
    }
]