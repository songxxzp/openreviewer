[
    {
        "id": "2zbDfBWXjR",
        "forum": "RBs0IfPj5e",
        "replyto": "RBs0IfPj5e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission790/Reviewer_gYSb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission790/Reviewer_gYSb"
        ],
        "content": {
            "summary": {
                "value": "The manuscript presents a method based on a diffusion model for backmapping coarse-grained MD results to full atom coordinates. By incorporating self-supervised training strategies, the proposed method can be generalized to multiple different coarse-graining (CG) methods. Experimental results indicate that the proposed method achieves better performance than state-of-the-art methods in backmapping CG configurations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method can be applied to multiple different CG methods without the need for retraining.\n\n2. Experimental results demonstrate that the proposed method outperforms baseline methods."
            },
            "weaknesses": {
                "value": "1. The Equivariance handling approach in the method constructs a reference coordinate system using the first three amino acids of each protein sequence. This implies that if the positions of the first three amino acids vary, the reference system will also differ, which may not be an ideal approach.\n\n2. In Table 3, the Mean Absolute Error (MAE) of bond length for BackDiff (cons) can reach 0, which appears too good to be true.\n\n3. In Table 3, the numerical values of the standard deviation (std) in the second and third rows are almost in the same range as the mean values, which is strange."
            },
            "questions": {
                "value": "1. Is the model used in the method SE3 equivariant?\n\n2. Given that the model learns the displacement of omitted atoms from alpha carbons, why not directly learn displacement in the local coordinate system of each amino acid? This approach could ensure that the representation is SE3 equivariant.\n\n3. I am not familiar with the PED dataset. Why were only 92 proteins selected out of 227 for training and testing data?\n\n4. What do you mean by single- and multi-protein experiments? What is the primary difference? When frames are used for data partitioning, is it possible for different frames of the same protein to appear in both the training and testing sets, potentially leading to data leakage?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698502647653,
        "cdate": 1698502647653,
        "tmdate": 1699636006440,
        "mdate": 1699636006440,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Rbd4cuLtYB",
        "forum": "RBs0IfPj5e",
        "replyto": "RBs0IfPj5e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission790/Reviewer_np12"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission790/Reviewer_np12"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a generalized transferable backmapping method that can be applied to arbitrary CG mapping without the need for retraining. The paper formulates backmapping as an imputation problem, where the model generates C alpha-atom distance vectors conditioned on CG atoms and CG auxiliary variables (aggregated properties of groups of atoms). The model can achieve generalization across different CG mappings by training with (semi)-randomly selected CG atoms and auxiliary variables. The model generates output in Cartesian coordinate space but produces well-constrained bond lengths and angles by imposing manifold constraints. The model is compared to a recent transferable generative modeling work, with experiments conducted following similar settings including the dataset and metrics, as well as a recent all atom conformer generation model.   \n\nThis paper shows clear novelty and strengths, but I still have some questions regarding the experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThis is a first backmapping algorithm generalized for arbitrary CG mappings. \n2.\tThe idea of formulating the generalized backmapping problem as an imputation problem is novel and makes a lot of sense."
            },
            "weaknesses": {
                "value": "-\tHave you re-implemented the baseline models (especially CGVAE) to condition them on other CG variables such as N and sidechain COM for the UNRES benchmark? If BackDiff is conditioned on C alpha, N, and side chain COM, while CGVAE is conditioned only on C alpha as in its original paper, it would be hard to tell if the performance difference is coming from the method or the difference in information given to the models. The same applies for MARTINI and Rosetta benchmarks. Alternatively, you could report the performance of BackDiff conditioned on C alpha only, with no CG auxiliary variable constraints on side chain COM. \n-\tTable 1 and Table 2 report the mean RMSD across 100 sampled structures. However, a large mean RMSD of the backmapped structures could also suggest high diversity among all atom conformations, rather than high error in the structures, since one CG structure can correspond to many all atom conformations. Reporting the minimum RMSD across 100 samples should be a better metric for assessing error.\n-\tHow did you select the PED entries for testing? The three test proteins all look pretty linear and disordered. How does the model perform on a globular protein?\n-\tCould you report the diversity of the generated structures conditioned on the same CG structure? For example, in the referred baseline [1], the authors reported quantitative metrics for diversity, such as the Earth Mover\u2019s Distance for side chain torsion angles. \n-\tCould you provide a speed analysis of your method, for example how much time required to backmap a frame, similar to what was done in [1]?\n-\tIt could be interesting to see how the model performance changes as we increase the CG resolution (the number of CG atoms and CG auxiliary variables), especially in terms of the diversity of generated all atom conformations. This could provide insights into the CG system\u2019s entropy. This is not a requirement, but just a curiosity."
            },
            "questions": {
                "value": "-\tYang & Bombarelli\u2019s model is called GenZProt and not CGVAE."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803373360,
        "cdate": 1698803373360,
        "tmdate": 1699636006352,
        "mdate": 1699636006352,
        "license": "CC BY 4.0",
        "version": 2
    }
]