[
    {
        "id": "MHXAwwCTlU",
        "forum": "FRCHDhbxZF",
        "replyto": "FRCHDhbxZF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission349/Reviewer_pGhB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission349/Reviewer_pGhB"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on tackling the practical challenge of real-world scale scene flow. The method employed in this study can be summarized as follows: 1) a slow teacher NSFP is identified; 2) a fast student FastFlow3D is recognized; 3) the teacher is adopted to create auto-labels for supervising the student."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper carries out a thorough series of experiments to validate the efficacy of the straightforward autolabel concepts and raises several intriguing questions. Furthermore, the paper includes experiments designed to address these questions, potentially offering valuable insights to the autonomous vehicle industry."
            },
            "weaknesses": {
                "value": "The idea lacks novelty, particularly for consideration at ICLR. In my opinion, this paper would be better suited for ICRA or WACV, as they tend to focus on more application and system-oriented research."
            },
            "questions": {
                "value": "1. For the full point cloud setting, what is the exact number of points in average? Have we applied ground point removal so the number of points has been significantly reduced. I know there is a discussion in 3.1, but I want to confirm the actual number of points and settings in the later experiments.\n2. Algorithm 1 can be removed; it does not provide any useful information.\n3. (This is not important) I feel we should not call this scene flow foundation model; scene flow is only a single problem in Computer Vision/Perception."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698528879881,
        "cdate": 1698528879881,
        "tmdate": 1699635962426,
        "mdate": 1699635962426,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zSMBZu6AaK",
        "forum": "FRCHDhbxZF",
        "replyto": "FRCHDhbxZF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission349/Reviewer_E12X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission349/Reviewer_E12X"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method called ZeroFlow that combines the strengths of optimization-based and feed-forward methods to achieve efficient and label-free scene flow estimation.\nIt introduces an optimization-based teacher method, which generates pseudo labels, and uses these labels to supervise a feed-forward student model. \nIt conducts extensive quantitative evaluations and achieves comparable performance to NSFP and FastFlow3D."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The overall writing of the paper is good, with a clear description of the motivation and implementation of the proposed approach.\n- As can be seen from Table 1, the proposed method achieves a good balance between performance and efficiency.\n- The paper verifies the proposed ideas through a series of experiments."
            },
            "weaknesses": {
                "value": "- The innovation and contribution of the paper mainly lie in the new application of the distillation strategy, and I suggest the authors provide further analysis or insights into the scene flow estimation task.\nI think the achieved performance of the proposed approach is highly dependent on the quality and effectiveness of the existing works.\nThe authors combine two previously published works, using NSFP to generate pseudo labels and training the FastFlow3D model using these labels.\n\n- In Sections 3.2 and 3.3, the author provides a detailed description to help understand the proposed method, but it is difficult for me to detect the author's new in-depth thinking about this work from these descriptions.\nAt the same time, Section 3 contains many statements on existing work, such as 3.1. This section might benefit from providing a more in-depth analysis of combining the strengths of optimization-based and feed-forward methods.\n\n- The quantitative results in Table 2 on Waymo Open are less competitive, making the method's performance on this dataset not very convincing.\n\n- The overall style of the article is more like a technical report than a research paper, and I feel that it contains more engineering skills."
            },
            "questions": {
                "value": "Please refer to the Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698682475248,
        "cdate": 1698682475248,
        "tmdate": 1699635962312,
        "mdate": 1699635962312,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vJtnLSM9Bv",
        "forum": "FRCHDhbxZF",
        "replyto": "FRCHDhbxZF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission349/Reviewer_q16v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission349/Reviewer_q16v"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a scalable point-cloud-based scene flow approach via distillation. Given unlabeled raw point cloud data, the paper first calculates pseudo-GT scene flow using a test-time optimization-based method (Neural Scene Flow Prior), which tends to demonstrate much better accuracy than feed-forward approaches. Then given the pseudo GT, the method trains a feed-forward model in a supervised manner. With this distillation pipeline, their method archives comparable/sometimes even better accuracy than the optimization-based method and of course much better than other feed-forward methods, while maintaining real-time performance. This pipeline is scalable as what it needs is just unlabeled point cloud data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ Good performance (Table 1)\n\n   The method achieves better accuracy over previous work while maintaining real-time performance. This source of gain requires the cost and time of generating pseudo-GT using the existing optimization-based approach. However, this can be done offline in a parallel way, so it's not a critical concern.\n\n+ Simple, effective idea\n\n   This distillation idea is very simple, but previous work on point-cloud-based scene flow methods hasn't tried the idea yet. The paper demonstrates that this simple idea is working and demonstrates that it's scalable by using large-scale diverse unlabeled data. It would be great if the computed pseudo-GT would be released to the community.\n\n+ In-depth analysis\n\n  Not only the main experiments, the paper provides in-depth analysis, such as accuracy versus dataset size (Fig. 4), endpoint residual maps (Fig. 5), and variance study (Table 7 and 8). This clearly helps a better understanding of the paper. The paper is pretty much self-contained."
            },
            "weaknesses": {
                "value": "There seem to be not many weaknesses in the paper but some minor questions related to the accuracy.\n\n- In Table 1, how can ZeroFlow XL 3X (Ours) outperform the NSFP w/ Motion Comp baseline as ZeroFlow's accuracy can be bounded by the accuracy of pseudo GT (i.e., NSFP)? Would it be also possible to include the accuracy of pseudo GT in Table 1?\n\n- In Fig. 4, why is FastFlow3D better than 'Ours' when the dataset size is less than 100%? I thought ZeroFlow's backbone was based on FastFlow3D, but what change made it underperform FastFlow3D?"
            },
            "questions": {
                "value": "(just a remark) By the way, there is a recent paper [a] that significantly improves the runtime performance of NSFP by 10 or 30 times (varying different datasets). The proposed approach can reduce the compute cost for pseudo GT generation by using this faster method. \n\n[a] Fast Neural Scene Flow, ICCV 2023"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809292476,
        "cdate": 1698809292476,
        "tmdate": 1699635962243,
        "mdate": 1699635962243,
        "license": "CC BY 4.0",
        "version": 2
    }
]