[
    {
        "id": "I2EMoNlmZa",
        "forum": "p9pBJv1DTz",
        "replyto": "p9pBJv1DTz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_YZDa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_YZDa"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new text-based gaming multi-agent benchmark CuisineWorld, inspired by the video game Overcooked, proposes a method MindAgent for central control of multiple agents using LLM by designing prompts, and conducts experiments with the benchmark and the method including human experiments."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces a new text-based multi-agent cooperation benchmark, with a vivid visual appearance.\n\n- The paper conducts experiments involving more than 2 agents and human.\n\n- The paper shows some efforts in transferring the method in real-world gaming scenarios Mindcraft."
            },
            "weaknesses": {
                "value": "1. The Benchmark's Contribution Falls Short\n\n- The CuisineWorld, based on the video game Overcooked which is popular for measuring multi-agent cooperation and has many existing environments already[1][2]. The benchmark introduces more cuisines but falls short in diversifying kitchen maps when compared to previous Overcooked environments.\n\n- Table 12 made a good summary of related benchmarks though some related embodied multi-agent cooperation benchmarks with most of the features in the table are missing, such as [3][4].\n \n- While CuisineWorld boasts an appealing visual design, it does not directly align with the paper's experiments. The paper primarily relies on text-based states and interactions (Figure 26, even during human experiments, where humans are restricted to a textual interface with lots of text description of the game state)\n\n- In section D.2, the statement \"In this game, the actions of human players can be obtained from an inverse dynamic model by checking pre-conditions and post-effects\" is confusing to me. How was Figure 22 obtained? It seems to be in real-time with human players using the keyboard to move, how's the time step defined here and the \"goto\" action for the LLM agent implemented?\n\n- The benchmark predominantly employs a \"new auto-metric collaboration score CoS for assessing the collaboration efficiency\". However, this metric is defined as the average task success rate with different time intervals for each dish that appears highly tailored to the specific environment and lacks a clear connection to \"cooperation efficiency\".\n\n- The absence of a train/test split is concerning, as prompt engineering can substantially impact performance. A thorough understanding of how the prompt is tuned for different tasks is crucial.\n\n- From C.3.4, level 3 has only two similar recipes which differ only with the words \"salmon\" and \"tuna\", only one demonstration may decrease the task difficulty significantly for the LMs, raising doubts about the benchmark formation.\n\n2. Claims Need Stronger Support from Results\n\n- In section 5.1, The paper claims \"more agents will lead to higher collaboration efficiencies. Thus, indicating that the LLM dispatcher can coordinate additional agents to execute tasks more efficiently\". However, from Table 1, 4 agents perform worse than 3 agents in most scenarios, and even 2 agents achieve the highest score in levels 2 and 4, which contradicts the claim. It may provide more insights if the paper can provide more analysis on these contradictory results instead of only ablating on level_3, which seems to be the only level that \"looks normal\" (a.k.a 2 agents < 3 agents < 4 agents with somewhat clear gaps)\n\n- Table 4, \"For a fair comparison, all tests employed identical prompt inputs\" using \"identical\" prompt for different LM families may not be \"fair\", especially if the prompt is \"tuned\" specifically for one model. More details on the prompt engineering process may help clarify these concerns.\n\n- Table 3 presents a perplexing scenario where four agents using a two-agent demo outperform four agents using a four-agent demo, albeit marginally. This result could benefit from a clearer explanation.\n\n- Novel game adaptation of Minecraft seems very promising, but the details are extremely limited. It would be more convincing if there were more details and formal experiments on it. For example, how is the \"adaptation\" conducted? What's the additional human effort required (such as prompt engineering and rounds of re-playing for prompt tuning)?\n\n3. Method's Limited Contribution\n\n- The method employed in the paper primarily relies on intensive prompt engineering, without introducing novel designs for multi-agent cooperation.\n\n- It's well known that LLMs can perform \"in-context learning\", providing demonstrations and reasoning steps can help improve performance, there's nothing new to take away from the method and experiments.\n\n- As mentioned above, the \"emergent ability\" of MindAgent is not well supported by the results.\n\n- Providing only screenshots of part of the prompts as in Figures 6 and 7 is not enough. More details on the full prompt and game episode may help clarify these concerns.\n\n[1] On the utility of learning about humans for human-ai coordination\n[2] Too many cooks: Bayesian inference for coordinating multi-agent collaboration\n[3] Building cooperative embodied agents modularly with large language models\n[4] A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied Tasks"
            },
            "questions": {
                "value": "Please address the concerns raised in the Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3098/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698541162559,
        "cdate": 1698541162559,
        "tmdate": 1699636256134,
        "mdate": 1699636256134,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0C9yoDABpQ",
        "forum": "p9pBJv1DTz",
        "replyto": "p9pBJv1DTz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_RwfK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_RwfK"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an infrastructure, MindAgent, for evaluating planning and coordination capabilities in the context of gaming interaction. To facilitate multi-agent planning capabilities of LLMs, the paper designs an effective set of prompt templates, memory modules, and state and action processing modules. Additionally, the paper reformulates the optimization objectives and constraints of multi-agent planning into natural language descriptions and uses them as prompts to guide LLM planning. The paper also introduces a virtual kitchen game called CuisineWorld as a benchmark for LLM-based multi-agent planning. Furthermore, the paper evaluates the planning capabilities of various LLMs in multi-agent collaboration tasks and human-agent collaboration tasks in CuisineWorld using MindAgent."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "***Originality & Significance***\n\nAlthough this work is mainly application-oriented for LLMs, its novelty lies in proposing an infrastructure to explore the potential of LLMs in multi-agent planning and conducting experiments on multiple LLMs. I believe this work will inspire the LLM community and provide a valuable test bed for evaluating LLM capabilities.\n\n***Quality & Clarity***\n\nThis work provides detailed descriptions and examples of the components of MindAgent. The paper also offers a good description of the environment setup and level settings in CuisineWorld. Furthermore, the paper validates the abilities of multiple LLMs, such as GPT-4, through multi-agent collaboration and human-agent collaboration tasks, and provides detailed experimental settings. I think the paper is clear and of high quality."
            },
            "weaknesses": {
                "value": "Please refer to the questions section."
            },
            "questions": {
                "value": "1. Have the authors considered incorporating a human-agent communication module in MindAgent? As suggested by Gao et al. [1], introducing interpretable human-agent communication into collaborative games can effectively improve human-agent collaboration performance and human subjective preferences. Natural language is the best medium for human-agent communication, which is also a natural advantage of LLM-based agents in human-agent collaboration.\n\n2. Can the design of MindAgent support collaborative games that require more domain-specific knowledge? For example, Multiplayer Online Battle Arena (MOBA) games [1], First-person Shooter (FPS) games [2], and Diplomacy [3] have very complex gameplay and their outcomes heavily depend on the planning and collaboration capabilities of the agents. The authors could discuss how the infrastructure needs to be modified when extending it to other games, which would enhance the generalisability of the infrastructure.\n\n---\n\n[1] Gao, Yiming, et al. Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective. ICLR. 2023.\n\n[2] Jaderberg, Max, et al. Human-level performance in 3D multiplayer games with population-based reinforcement learning. Science. 2019.\n\n[3] FAIR, et al. Human-level play in the game of Diplomacy by combining language models with strategic reasoning. Science. 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3098/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698768453851,
        "cdate": 1698768453851,
        "tmdate": 1699636256058,
        "mdate": 1699636256058,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nNInwZg9Lu",
        "forum": "p9pBJv1DTz",
        "replyto": "p9pBJv1DTz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_DUbr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_DUbr"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an infrastructure for LLM-based agents to perform task distribution across a number of agents. It focus on planning and coordination ability of LLM with in-context learning from a few examples. The work tests on a multi-agent gaming environment, CuisineWorld, as well as a few other multi-agent collaboration environments, and obtain promising results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Contributions:\n\n1. Evaluate LLM agent in a multi-agent gaming environment; test LLM's ability to serve as a task allocator.\n\n2. Proposes a collaboration score to evaluate and benchmark coordination agents."
            },
            "weaknesses": {
                "value": "1. Technical novelty: The technical novelty of this work is lacking because the multi-agent setting is really just adding an LLM call to allocate what different agents should do. Concretely, it is a simple prompting and what is supposed to be an optimization problem is all packed into one LLM call. This doesn't seem to be a very principled way of studying the agent allocation. \n\n2. Problem setting: the multi-agent collaboration problem is reduced to a top-down allocation: a distributor distributes tasks for agents to do. But for a collaboration problem to work, there should also be communication between the agents, which this work does not study.\n- the title is also quite misleading: it is titled \"emergent interaction\" however, there is no real interaction between the agents, i.e., communication of agent's individual's ability, limitation, progress etc. It is more of a allocation / coordination problem of a central agent.\n\n3. Experimental results: The work evaluate on Minecraft environment, but there has been quite a few LLM-based Minecraft agents, and the work does not offer comparison between this method and existing works as baselines."
            },
            "questions": {
                "value": "1. What are the common failure cases of the LLM agent allocation? Under what environment / optimization constraints would the agent fail to allocate works correctly?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Reviewer_DUbr"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3098/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826823611,
        "cdate": 1698826823611,
        "tmdate": 1699636255984,
        "mdate": 1699636255984,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m5B0RalEqJ",
        "forum": "p9pBJv1DTz",
        "replyto": "p9pBJv1DTz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_tSpT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_tSpT"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new benchmark CuisineWorld for evaluating the planning and coordination capabilities of LLMs in multi-agent settings. Different from previous research, this benchmark is characterized by (1) its incorporation of multi-task objectives, (2) the involvement of more than two agents, and (3) the utilization of a centralized system for coordination. In this context, an LLM functions as the centralized system. At every timestep, the LLM processes each agent's state along with a prompt including recipes, demonstrations, the fundamental rules of the game, and memory history, and outputs the optimal actions for the agents. The paper demonstrates that GPT-4 has a strong planning capabilities on the proposed benchmark."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The creation and development of a new benchmark, entailing a substantial amount of effort, is a significant strength of the paper.\n- The introduction of a novel metric, CoS (Coordination Score), to assess coordination capabilities is a noteworthy contribution."
            },
            "weaknesses": {
                "value": "- The proposed LLM coordination system, MineAgent, lacks novelty as its approach of leveraging scratchpad or memory has been extensively explored in prior research.\n- The proposed environment features limited state and action spaces and furnishes all the requisite recipes to solve tasks, possibly oversimplifying the challenge. In this situation, heuristic or RL planners could be readily employed. However, the paper does not provide comparisons with these approaches.\n- The proposed environment bypasses low-level control, further oversimplifying the problem. From my understanding, an agent can move to any location with a single action, without the need to consider spatial information. This eliminates the need for spatial reasoning in the LLM planner.\n- The paper claims that the LLM can seamlessly adapt to new planning problems across different domains, but this assertion is questionable considering the dependence on context length. While the simplicity of the current setting allows all environment information to be described within 1K tokens, this approach may prove inadequate for more challenging environments. Additionally, engaging in manual prompt engineering to enhance performance may entail significant monetary costs.\n- The description of the environment setting requires further clarification. Does $\\tau_\\mathrm{int, (1)}$ mean that a new task will be added at every timestep? What is the maximum horizon of an episode?\n- The paper only highlights the emergent behavior of GPT-4 while neglecting to discuss its potential drawbacks. A more balanced perspective could be achieved by including examples of GPT-4's failure cases."
            },
            "questions": {
                "value": "See the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3098/Reviewer_tSpT"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3098/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698988527826,
        "cdate": 1698988527826,
        "tmdate": 1699636255871,
        "mdate": 1699636255871,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oCo1Qgtiet",
        "forum": "p9pBJv1DTz",
        "replyto": "p9pBJv1DTz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_t1AF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3098/Reviewer_t1AF"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new gaming scenario and related benchmark based on a multi-agent virtual kitchen environment, CuisineWorld.  It introduces MindAgent, which demonstrates the in-context learning multiagent planning capacity of LLMs and brings several prompting techniques that help facilitate their planning ability. Extensive evaluations are conducted with multiple LLMs and prompting settings on the benchmark, including deploying the system into real-world gaming scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The work is solid and important to the community which provides a benchmark that supports the implementation of a general multi-agent infrastructure that encompasses collaboration between large language models (LLMs) and human-NPCs.\n\nThe paper is well-written and organized."
            },
            "weaknesses": {
                "value": "1.\tThe font size of Figure 4 is too small.\n2.\tThe paper seems not provide a clear definition of the terms $q_{pim}$ and $c_{pim}$ in Equation 2."
            },
            "questions": {
                "value": "As weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3098/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699093939890,
        "cdate": 1699093939890,
        "tmdate": 1699636255787,
        "mdate": 1699636255787,
        "license": "CC BY 4.0",
        "version": 2
    }
]