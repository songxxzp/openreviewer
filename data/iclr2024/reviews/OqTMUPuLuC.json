[
    {
        "id": "noWUVYaBif",
        "forum": "OqTMUPuLuC",
        "replyto": "OqTMUPuLuC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_Cxkm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_Cxkm"
        ],
        "content": {
            "summary": {
                "value": "The paper includes a LLM into a framework which controls the decisions of a driving agent in a simulator. The authors define a concept, they call knowledge-based driving, and argue how their framework implements this and performs better than data-based methods. They test against one reinforcement learning based baseline in the Highway-env simulator."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea to use an LLM for scenario understanding and decision making in driving is very interesting. The authors have proposed a decent suggestion for integration and practically showed that it works.\n\nThe figures help getting a good top-level overview of the modules. Some parts are missing like how does the correction module work which is only an arrow in Figure 5?"
            },
            "weaknesses": {
                "value": "The language could be clearer, less vague and heavily simplified to make the arguments easier to understand. \n\nThe evaluation against a single self-trained RL baseline makes it hard to estimate the performance. Since it seems there is no limit to the perception of the own agent, another fair comparison would be a simpler approach where a statistical or rule-based approach would have all information of all cars and drive. Without having a state-of-the-art RL method that is already optimized on highway-env it is hard to see if the performance gain comes from the proposed method or from the failure to adopt the RL method on the task.\n\nConceptually it is hard to imagine right now how this is supposed to drive in real time. Is the video sped up or slowed down? It is a challenge of the last decade how to get convolutional networks fast enough to be usable in a car. The computation challenges are not discussed at all. What is the reaction time of this and is execution speed a bottleneck?"
            },
            "questions": {
                "value": "- What are the more precise concepts of knowledge-driven human driving that inspire this?\n- Instill knowledge-driven capabilities sounds very vague. Methods that acquire experiences from real-world dataset covers all learning-based methods depending on what you mean with acquire. The abstract could be more concrete, it's hard to take away anything apart from that a LLM seems to do decision making while following a continuous learning scheme. \n\nThe language is hard to follow and the citations do not seem to support the claims well. In the Introduction, the sentence \"This phenomenon inevitably leads to the marginal performance of data-driven methods.\" is one example for a broad claim without enough support in citations. There are autonomous cars driving in cities today with vision algorithms which are data-driven. They do not show marginal performance. The citations for this claim are one work describing a methodology to categorize corner cases in three common sensor modalities, so not very related, and the second citation \"Chen et al. 2022\" seems to be a catch all \"survey of surveys\" which is a large list of autonomous driving surveys with some added, partially trivial, thoughts. \n\nOther examples where statements are too broad and hard to understand are: \"Furthermore, this task is particularly formidable and expensive for autonomous driving systems due to the complex challenge of iterating diverse and unpredictable driving scenarios.\" What is this sentence supposed to say? The authors should heavily simplify their language to deliver their points clearer. Formidable and expensive can be understood in many different ways and distracts from the core argument the authors want to make.\n\nClaims that the knowledge-based system is how a human drives can not be supported by the current state of research and not by the citations in this paper. I think the paper would benefit from not making the claim that they imitate a system in humans but limit themselves to saying, they designed a framework to include an LLM in a continuous learning setting where it outperforms certain other approaches. \n\nPlease add enough details from Johnson et al. 2019 to understand the vector similarity on an idea level. Make the paper more self-complete.\n\nWhat is the data the LLM is trained on? If the training data contains driving situations from several countries, how to make sure it is following the appropriate traffic rules?\n\nWhat are the 5 human crafted experiences and why are they needed?\n\nFigure 7 a) could be easily replaced by a table to save space. \n\nIt is a bit unsatisfactory to have only a comparison against one baseline which was re-trained on this particular data. Is there no standard scenario on Highway-Env or another RL-based approach that was already applied to Highway-env to compare against? I could not find one myself so I don't see this as a downside in my rating but I think it would make the paper stronger if the authors could find a way to compare against more than one baseline."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Reviewer_Cxkm"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777637315,
        "cdate": 1698777637315,
        "tmdate": 1699636272808,
        "mdate": 1699636272808,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xN8k5wi0lW",
        "forum": "OqTMUPuLuC",
        "replyto": "OqTMUPuLuC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_48LR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_48LR"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a framework for utilizing the few shot and self-correction capabilities of LLMs for the task of AV planning, where the following abilities of the framework are highlighted:\n- Store successful experiences in memory and leverage them to improve future rollouts through similarity retrieval and usage in few-shot prompting.\n- Ability to learn from unsuccessful experiences (ones with collisions) by applying LLM self-correction and storing the modified experience among the successful experiences in the memory\n\nThe above components, dubbed as reasoning and reflection modules respectively, are integrated along with memory in a closed loop setting without any back-propagation objective. \n\nA number of prompting techniques including chain-of-thought and few-shot prompting are used to get better reasoning. The environment used for experiments (Highway-Env) only requires four discrete decisions, hence the LLM is prompted to select one amongst these four decisions for each frame after going through CoT reasoning.\n\nThe experiments are used to demonstrate the following key claims:\n- The memory module combined with few-shot prompting provides much better results than using no memory module (zero-shot) or using lesser shots. \n- The more the number of experiences in the memory, the better.\n- The ability to generalize is better with more few-shot experiences fed into the LLM\n- Adding successful and corrected experiences both help in improving performance\n- Better generalization capability compared to RL method GRAD."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The motivating idea of human knowledge distillation for AV planning is sound, interesting, and under-explored.\n\n- The overall framework formulation towards leveraging LLMs via appropriate prompting, retrieval, and self-correction is interesting and well set up. It would have been exciting to see formulations for LLMs assisting planning stacks (instead of directly doing discrete action decision making) - which could be much more valuable to existing systems.  \n\n- The flywheel effect created from storing both successful and unsuccessful + corrected experiences in memory is an important contribution.\n\n- The paper provides a good foundation for other exciting work to build upon, especially with the promise to open source upon acceptance.\n\n- The experiments are fairly extensive towards investigating all the different components of the proposed framework."
            },
            "weaknesses": {
                "value": "-  One of the main proposed advantages is better generalization through instilling human knowledge-driven capabilities instead of a data-driven only approach. However, the experimental settings derived from HighwayEnv are too restrictive to help extrapolate how such LLM based reasoning would perform on diverse new scenes using retrieval + few shot prompting. While it is perfectly fine to work with restricted settings and smaller datasets for new research work, the bridge to answer the most interesting questions is too long.\n\n- As mentioned in strengths section, providing directions and initial experiments on assisting planning stacks (instead of directly doing discrete action decision making) could provide a lot of value.\n\n- The experiment settings used to demonstrate generalization are not too convincing. The number of lanes and traffic density is changed, but this is still an extremely similar environment where the retrieved few-shot scenarios could be nearly directly applicable.\n\n- Under the above setting, it is possible that with a large enough memory module the task reduces to simply copying the answer from one of the retrieved experiences. It would be good to see a baseline where the decision from one of the retrieved experiences is used as is (voting with mixture of experts or winner takes all)\n\n- The metric movement with CitySim in Figure 7b and Table 1 correction row do not seem significant to make the corresponding claims?\n\n- Nit: The key frame sampling for successful experiences seems like an important detail that has not been explained.\n\n- Minor nit: The claim for this being the first work addressing AV planning via leveraging LLMs might need to be revised with recent papers like GPT driver (depending on chronology)."
            },
            "questions": {
                "value": "- What kind of diverse interactions do we get from the Highway-env simulator? Would it be possible to evaluate the framework under more interactive / challenging conditions, especially wrt agent interactions? It would be interesting to see the generalization to intersections, interactions with peds, aggressive agents etc.\n\n- The correction experiences intuitively should provide a strong boost to performance since they are akin to hard example mining and injecting reasoning about the negative outcomes. However the corresponding results in Table 1 do not show strong improvements. Is it possible understudied and warrants more extensive experimentations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821572279,
        "cdate": 1698821572279,
        "tmdate": 1699636272724,
        "mdate": 1699636272724,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QR5UQkVxgV",
        "forum": "OqTMUPuLuC",
        "replyto": "OqTMUPuLuC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_RmuT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_RmuT"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a novel and interesting approach leveraging LLMs in autonomous driving to perform knowledge-based reasoning about making high level driving decisions. The approach is motivated by how humans learn to drive. There are three straightforward pieces of the method: reasoning, recall, and reflection. The method is evaluated in simulating driving scenarios and positively compared against a SOTA RL method and ablations of the approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed method is well-motivated by human behavior and generally clearly explained. The experiments justify each portion of the method for achieving the goal task of autonomous driving.  The method is novel, simple, and has potential to be used in the real world. Overall, an interesting perspective on the self-driving car problem."
            },
            "weaknesses": {
                "value": "The memory module requires more description in Section 3.2. The process of storing experiences is somewhat unclear. The writing could be interpreted to mean that every scenario is stored separately or that the similarity between the keys is used to map similar experiences to the same memory store (which seems to be what the authors are actually doing). Either a new figure or updates to the existing figures would also add to clarity and precision.\n\nThis paper never discusses limitations. I strongly recommend making room to discuss the relationship between this approach and approaches which focus on safety. In fact, the \u201creflection\u201d module is being presented as a safety mechanism. However, the trustworthiness of the results from the LLM is never discussed. Diving into reliability and limitations is important in a method which claims to address safety for transparency in a safety critical task where results are currently deployed in the real world.\n\nI thought the following claim in the abstract was slightly misleading given LINGO-1 (which the authors do cite). \u201cTo the best of our knowledge, we are the first to instill knowledge-driven capability into autonomous driving systems from the perspective of how humans drive.\u201d I think that the correct way to phrase what the authors mean is specifically saying that they are the first to \u201cuse human-like knowledge-based reasoning to make autonomous driving decisions\u201d or something similar since leveraging it in decision making is the distinction with prior work. \u201cInstill\u201d is a vague term which could also describe what LINGO-1 is doing."
            },
            "questions": {
                "value": "It is fairly odd in the experiments that two different GPT versions are used. Why did the authors not just use GPT-4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3243/Reviewer_RmuT"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699274051900,
        "cdate": 1699274051900,
        "tmdate": 1700600370962,
        "mdate": 1700600370962,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YPqtN1ZD3L",
        "forum": "OqTMUPuLuC",
        "replyto": "OqTMUPuLuC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_LJSU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3243/Reviewer_LJSU"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel framework for autonomous driving systems based on LLM and tailored components. Contributions of this paper are several folds:\n\n- Knowledge-Driven Paradigm: The paper introduces a knowledge-driven paradigm for autonomous driving, differentiating it from existing data-driven approaches. This paradigm is inspired by human driving, which relies more on knowledge and understanding rather than mere data accumulation.\n\n- DiLu Framework: The authors propose the DiLu framework, integrating large language models (LLMs) with autonomous driving systems. Several modules are proposed based on recent advances of AI agent: A Reasoning Module that utilizes LLMs for decision-making based on common-sense knowledge; A Reflection Module that assesses decisions and updates them based on safety and correctness, using the knowledge from LLMs.\n\n- Experimentation and Results: Extensive experiments demonstrate the framework's capability to make proper decisions, its strong generalization ability, and the potential for real-world application. The paper compares DiLu with reinforcement learning methods, showing its superior performance in generalization and adaptability."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Innovative Approach: The integration of LLMs into autonomous driving systems represents a significant shift from traditional data-driven methods, potentially offering more adaptable and human-like decision-making.\n\n- Generalization Ability: DiLu shows a strong ability to generalize from one environment to another, a crucial aspect for real-world applicability.\n\n- Continuous Learning: The framework's ability to continuously evolve and improve through its memory and reflection modules is a key strength."
            },
            "weaknesses": {
                "value": "- Complexity and Scalability: The integration of LLMs and the need for continuous updating and reflection may introduce complexity, potentially impacting the scalability of the system.\n\n- Real-World Application: While the framework shows promise, the transition from controlled experiments to real-world application can be challenging, given the unpredictable nature of real-world environments.\n\n- Dependence on LLMs: The framework's reliance on LLMs means that its performance is heavily dependent on the capabilities and limitations of these models.\n\n- Evaluation thoroughness: The authors only evaluate the proposed methods with oversimplied metrics (collisions) and compared to a simple baseline (RL). The limitation of the evaluation poses a question mark on how such system actually performs in the real driving scenarios, compared to sota autonomous driving systems."
            },
            "questions": {
                "value": "While LLM-based agent systems have shown success in various embodied systems, the adaptation of it in the AV tasks is still unclear to the reviewer. AI agent system has shown prominent success in task planning for open world robotic tasks, but AV has a different setting (with different challenges). The motivation and advantages of using AI agent system for AV needs to be elaborate more.\nOn the other hand, the authors didn't evaluate the proposed framework thoroughly enough (with only simple metrics and simple baselines). This further raises questions of the reviewer regarding how promising or what are the key advantages of using AI agent system in AV setting.\nFinally, the proposed AI agent follows a typical setup compared to the other existing works in robotics tasks. The authors should highlight more on the unique challenges and design choices tailored for the AV task."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699595089444,
        "cdate": 1699595089444,
        "tmdate": 1699636272548,
        "mdate": 1699636272548,
        "license": "CC BY 4.0",
        "version": 2
    }
]