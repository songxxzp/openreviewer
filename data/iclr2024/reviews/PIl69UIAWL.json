[
    {
        "id": "o9zTYRe6Yg",
        "forum": "PIl69UIAWL",
        "replyto": "PIl69UIAWL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_DjB6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_DjB6"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose GraphLLM to enhance the graph reasoning ability of LLMs. Specifically, GraphLLM is an end-to-end approach that integrates LLMs with graph Transformer modules. Compared to existing graph2text approaches, the proposed method can improve accuracy and reduce context length. Experimental results on four graph reasoning tasks, including substructure counting, maximum triplet sum, shortest path, and bipartite graph matching demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Applying LLMs to graph-related problems is a recently emerging topic with rich potential.  \n2. The proposed method can combine graph machine learning (i.e., graph Transformer) and LLMs to better capture the graph structural information.  \n3. Experiments demonstrate the efficacy of the proposed method in improving accuracy and reducing context length.  \n4. The authors have released the codes to facilitate reproducibility."
            },
            "weaknesses": {
                "value": "1. I would strongly suggest applying the proposed method besides simple artificial graph tasks, where off-the-shelf algorithms already exist to perfectly solve them. Experiments on more real-world tasks such as node classification, link prediction, graph classification, etc., can better demonstrate the effectiveness of the proposed method. This is especially important for a technical paper where new approaches are introduced, as opposed to the previous observation-based papers such as NLGraph and GPT4Graph.  \n2. One major advantage of using LLMs compared to GNNs is explainability. Therefore, I would recommend conducting some analyses in this aspect. For example, if the proposed method cannot produce reasons for its prediction, it is likely that the proposed method captures some spurious correlations and does not truly \u201csolve\u201d the problem.   \n3. I also wonder whether the authors have considered directly comparing with graph Transformers or GNNs, to see whether LLMs have advanced the field.  \n4. Based on my understanding, one major advantage of the Graph2Text pipeline is being able to utilize close-sourced LLMs such as GPT-3.5 or GPT-4 without any fine-tuning step, since we only need to input data and related information (prompts, queries, etc.) to APIs. In comparison, as the proposed method needs to be trained end-to-end, it increases the computation cost and can only operate with open-sourced LLMs (in order to obtain gradients), which limits the applicability.  \n5. All things considered, the technical contribution of the paper is okay but not too novel, considering that all three components are heavily based on the existing literature, i.e., node understanding is a standard Transformer, structure understanding is essentially equivalent to Ma et al., 2023, and prefix tuning follows the common practice of LLMs. It would make the paper stronger if these components could be customized to further enhance the performance.  \n6. Minor: the authors claim one advantage of graph Transformers over GNNs is \u201cits decoupling of node information and structural information\u201d. Experimental evidence could be provided to support this claim."
            },
            "questions": {
                "value": "See Weaknesses above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4455/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698650801321,
        "cdate": 1698650801321,
        "tmdate": 1699636421047,
        "mdate": 1699636421047,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PiKSgTfGv5",
        "forum": "PIl69UIAWL",
        "replyto": "PIl69UIAWL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_B4te"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_B4te"
        ],
        "content": {
            "summary": {
                "value": "GraphLLM introduces a new method for boosting graph reasoning abilities of LLMs. It introduces a graph encoder using a transformer encoder-decoder for encoding node text descriptions and a graph transformer for incorporating structure. These are combined to generate key value prefixes for an LLM to use. \n\nThey show results on 4 different small-size graph reasoning tasks. They show great performance on these tasks compared to the text only (graph2text) baselines. They also show a large reduction in the number of input tokens to the LLM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper offers a clever approach to incorporating graph reasoning into LLMs. \n\n1) The architecture is smart and sensible, and the integration via prefix tuning makes this relatively simple to integrate. \n\n2) The experimental results are very strong compared to the baselines. GraphLLM essentially completely solves these tasks\n\n3) The graph transformer design is important, as evidenced by the ablation in table 7. \n\nOverall, the main strength of this paper is the architecture design. The architecture is quite smart. It can utilize node text features as well as  graph features to solve some tasks."
            },
            "weaknesses": {
                "value": "The main weaknesses of this paper are in its experimental evaluation. The architecture seems potentially powerful but under explored. \n\nLLMs are general purpose reasoners over text and graph2text takes advantage of that. GraphLLM is purposely built and trained for these specific graph reasoning tasks. It would be shocking if it didn't do better. As a consequence, most of the results are not \"interesting\". Graph2text is a single representation that can be used for all four tasks. The prefixes from GraphLLM are tailored to each task individually. Yes, LLM fine-tuning is a more comparable setting, but also less interesting as once we are finetuning, we could be using many other architectures (e.g. GNN). The more interesting question would be can we use GraphLLM as a general graph->prefix encoder that enables the LLM to perform different fundamental tasks better\n\nThis leads to the second weakness, the experiments do not show that GraphLLM is \"useful\". The tasks tested do not require machine learning, they can all be solved explicitly. Why would I use a complex ML architecture to replace a simple program? I think the architecture is smart and there are many avenues to demonstrate utility but these experiments do not demonstrate it. The experiments do demonstrate that GraphLLM is capable of performing graph reasoning tasks and there is value there. There would be much more value in showing more general capabilities. \n\nGPT-4 shows pretty good results on 3 of the tasks with few shot CoT. While still significantly below GraphLLM, LLMs alone may be able to learn these tasks if large enough and especially if fine-tuned or the prompt optimized. Would be interesting to see llama2-70b finetuned on these tasks.  \n\nThe comparison of input tokens does not seem to account for the text input to the node understanding encoder. In fairness, this is a much smaller encoder so it does not matter as much. \nHowever, the main issue here is that the design of graph2text seems intentionally designed to maximize the number of tokens. Example: For the max triplet sum task, why does it matter that \"[Cornelia Brooks's] petite frame and delicate features give her a dainty and ethereal presence\"? (Appedix D). In addition, the text uses the term \"connected with\" to describe edges but the question itself asks about \"friends\". I think this results in a poor showcasing of the LLM baselines. Even reading the shortest path text seems confusing as a human. Does the distance from earth matter? What does activating a wormhole mean? Why are we even dealing with \"wormholes\"? The only description of the task is \"Starting from wormhole 1, How much dark matter we\u2019ll need at the minimum to reach Wormhole 2?\""
            },
            "questions": {
                "value": "Questions:\n\n\"The encoderdecoder is newly initialized and updated with the guidance of the pre-trained LLM.\" This is very confusing and it is not clear what it means? How does the pre-trained LLM provide guidance?\nIs the encoder-decoder initialized from a pre-trained model or is it only the token embeddings?\n\nShouldn't prefix tuning require an embedding for each prefix value as well as each key? i.e. L x 2K x d?\n\nWhat are the instructions for generating each node's text features? Why can't this just be done using a template?\nAre the instructions generated for each node \n\nFor task 1, is it always the same substructure being identified?\n\nFor all the tasks is the input to the LLM (after the prefix) always the same? \n\nHow is exact match defined? Does it mean exact match appears in the output somewhere? Looking at the GPT-4 failure case examples in the appendix, it is hard to tell how this metric is applied? \n\nSuggestions:\n(Forgive me if any of these were done and I missed it)\n\nExplicitly mention that in prefix tuning, the LLM parameters are fixed. \n\nI don't think $d$ is explicitly defined. I take it as the dimension of the node and graph understanding encoder/decoders.\n\nStylistically, it looks better if G, E and V have a consistent style\n\nIn the introduction, I am not sure \"inefficiencies\" is the right word choice. What is inefficient about it? \"difficulties\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4455/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826653283,
        "cdate": 1698826653283,
        "tmdate": 1699636420976,
        "mdate": 1699636420976,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jqyw6TDOOM",
        "forum": "PIl69UIAWL",
        "replyto": "PIl69UIAWL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_ryJZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_ryJZ"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes GraphLLM, a new approach to enhance the ability of large language models (LLMs) to understand and reason about graph data. It identifies a key limitation of current methods that convert graphs to text (Graph2Text), which forces LLMs to implicitly learn graph structures and results in lengthy contexts. GraphLLM integrates a graph learning module with the LLM via end-to-end training. This allows the LLM to leverage the graph module's strengths in an efficient way through a condensed graph-enhanced prefix. Experiments on 4 graph reasoning tasks show GraphLLM substantially improves accuracy over Graph2Text methods while reducing context length and accelerating inference."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Novel integration of graphs and LLMs.\n\nGraphLLM proposes a novel end-to-end approach to combine graph learning models and LLMs. This allows each component to be optimized to complement the other for different graph reasoning tasks.\n\n* Significant performance gains.\n\nGraphLLM improves accuracy by 54.44% on average over the best Graph2Text method, showing its effectiveness. Also, GraphLLM reduces context length by 96.45% compared to Graph2Text, enhancing efficiency. Besides, GraphLLM achieves 3.42x faster inference over the best Graph2Text method due to context reduction."
            },
            "weaknesses": {
                "value": "* Limited graph tasks evaluated.\n\nThe paper evaluates GraphLLM on four graph reasoning tasks, including substructure counting, maximum triplet sum, shortest path, and bipartite graph matching. Although these tasks cover basic graph reasoning abilities, they are still relatively simple, which might overestimate how GraphLLM performs on noisier graphs with complex relational patterns. More complex graph reasoning tasks could better demonstrate the capabilities and limitations of GraphLLM. For example, tasks requiring multi-hop reasoning on large graphs might be more challenging.\n\n* Lack of analysis on scalability.\n\nThe datasets used in the paper are all small with fewer than 20 nodes on average. Thus, the ability of GraphLLM to handle large, real-world graphs is unclear. Evaluations on larger datasets would be informative.\n\n* Restricted node features.\n\nThe tasks only use textual node features. Testing on graphs with non-textual node attributes would make the approach more broadly applicable.\n\n* No comparison to other graph models.\n\nThe paper only compares GraphLLM against methods that convert the graph to text (Graph2Text). However, established graph neural networks like GNNs, GCNs, and graph transformers have been optimized specifically for graph reasoning. Comparing to these dedicated graph reasoning models could better highlight if GraphLLM actually improves over the state-of-the-art in graph representation learning. For example, how does GraphLLM compare to a graph transformer without the attached LLM on the tested graph reasoning tasks? This could isolate the benefits of the LLM integration. Similarly, comparisons to GNN variants on standard benchmarks could reveal where GraphLLM excels or lags behind existing graph-specific architectures. The improvements over Graph2Text may simply be because LLMs struggle with learning from text descriptions of graphs. Graph models designed for relational reasoning may be more competitive. In essence, without comparing to specialized graph reasoning models, it is hard to discern if GraphLLM's integration of LLMs and graph networks is truly advancing state-of-the-art performance. Adding these comparisons would give a clearer sense of GraphLLM's capabilities relative to the field of graph representation learning overall."
            },
            "questions": {
                "value": "Please check the weakness section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4455/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698928168241,
        "cdate": 1698928168241,
        "tmdate": 1699636420881,
        "mdate": 1699636420881,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "R4Tl9mnLrC",
        "forum": "PIl69UIAWL",
        "replyto": "PIl69UIAWL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_wWow"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4455/Reviewer_wWow"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces GraphLLM, an approach to integrate graph learning models with LLMs via graph transformer and prefix tuning. The authors compare with baselines across four graph reasoning tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I can see the contribution of this paper in trying to apply LLMs for graph learning/reasoning tasks, which I think is interesting.\n\nThe paper is well-organized.\n\nOther than the performance comparison, the authors report the efficiency comparison, which I appreciate.\n\nThe authors further report the performance of gpt-3.5-turbo and gpt-4, other than LLama."
            },
            "weaknesses": {
                "value": "The authors claim their proposed method is an end-to-end approach. I wonder the applicability of their model to existing pre-trained LLMs. Can the proposed method be easily adapted or integrated into existing pre-trained LLMs without fine-tuning? If so, what is the formal definition of end-to-end? If not, will this introduce a large burden for training resources? It seems to me that end-to-end is not a good strategy for LLMs, which contradicts the most powerful capability of one model to fit multiple tasks and applications in LLMs.\n\nThere are multiple ways to condense the length and size of context windows, especially in the community of natural language processing. The authors should be more cautious about this when presenting this as the contribution, and should consider comparing their methods with baselines and approaches that address the length and size constraints in the NLP community.\n\nAmbiguous preliminary. In the paper of prefix tuning, the prefix indicates a vector that concats to the front of the input and the representations in hidden layers. In the prefix tuning section of this paper, the authors introduce notations of QKV while not giving formal definitions that correspond to the graph learning scenario. Moreover, what is the input here, only K and V? Should the input also be Q? Before each layer in the transformer, where should the prefix be concatenated? How is this related to the graph learning scenario?\n\nLimited technical novelty. This paper simply combines the graph transformer and prefix tuning of LLMs. In particular, the graph transformer serves as a learning model on top of the graph, then the output of the graph transformer is concatenated to LLMs via prefix tuning. The technics of graph transformer and prefix tuning are both well built, studied and employed by the research community.\n\nHave authors consider comparing with or integrating P-tuning v2, which has shown better performance than prefix tuning.\n\nI suspect that different instructions can cause the LLMs to generate significantly different results and performance. Have the authors conducted experiments or analyses to investigate different instructions? How did the authors choose the instructions?\n\nAll the tested graphs are relatively small. I wonder if the proposed method can be used in large-scale graphs such as ogb-arxiv/ogb-products/ogb-ppa. If the proposed method can be extended to large graphs, how will the authors sample the neighbors? Will neighbor sampling affect the performance?\n\nLack of baselines. One important line of baselines that are missed here is the graph neural network-based ones for graph reasoning tasks. I don\u2019t think the experiments are comprehensive without comparing to methods that are designed to solve the graph reasoning problem. In fact, it is surprising that the authors only compare with NLP-based methods on solving graph tasks."
            },
            "questions": {
                "value": "see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4455/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699246298775,
        "cdate": 1699246298775,
        "tmdate": 1699636420789,
        "mdate": 1699636420789,
        "license": "CC BY 4.0",
        "version": 2
    }
]