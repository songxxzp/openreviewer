[
    {
        "id": "WMzHWtaQsM",
        "forum": "Y3NBqtrQat",
        "replyto": "Y3NBqtrQat",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_SoMm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_SoMm"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to improve on existing methods to parse scenes into object representations to better detect small/occluded objects. The method combines a bottom-up mechanism which tries to parse the scene into K object slots and a top-down mechanism which detects conflicts between the slot-based reconstruction and the original image and searches for a slot assignment which reduces conflicts. The approach gives improved results over benchmark algorithms on synthetic datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is mostly clearly written (there is some awkward grammar/wording) and makes excellent use of figures to illustrate results.\n\nThe proposed method is simple and effective.\n\nThere is a good amount of analysis and visualisation to explain the method."
            },
            "weaknesses": {
                "value": "The proposed method outperforms older SOTA models but does not clearly outperform some more recent work which incorporate different forms of \u201cobject\u201d guidance into a bottom-up model:\nhttps://openaccess.thecvf.com/content/WACV2023/papers/Sauvalle_Unsupervised_Multi-Object_Segmentation_Using_Attention_and_Soft-Argmax_WACV_2023_paper.pdf\nhttps://arxiv.org/pdf/2305.19550.pdf\nGiven that these works involve some similar ideas to the current paper, it seems worthwhile to address them.\n\nThe section on \"generalization to real-world scenarios\" contains almost no information about what experiments were run or what the results were. If these results are important to evaluate the proposed method they should be explained in the paper."
            },
            "questions": {
                "value": "How does this method differ from other recent work with similar performance? What are the advantages of this proposed approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636045925,
        "cdate": 1698636045925,
        "tmdate": 1699636868659,
        "mdate": 1699636868659,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5u6TCAtaFX",
        "forum": "Y3NBqtrQat",
        "replyto": "Y3NBqtrQat",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_uwGV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_uwGV"
        ],
        "content": {
            "summary": {
                "value": "Inspired by Reverse Hierarchy Guidance, a theory related to human vision, the authors\npropose an improvement for object-centric models based on clustering features into\nslots. Central to the approach is measurement of conflicts between spatial feature\nsimilarities and the clustering predicted by the model. The paper shows that established\nobject-centric models can be improved by minimizing conflicts during training and/or by\nchosing the sampled segmentation with the least conflicts during inference. In\nparticular, the segmentation of small objects is improved which are more frequently\nmissed by existing methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Existing methods are consistently improved on established, synthetic datasets.\n- The authors provide an analysis that explains *why* the proposed method works by\n  qualitatively and quantitatively inspecting segmentation performance for objects of\n  different sizes. Beyond providing an improvemend model, the paper therefore also\n  improves the understanding of object-centric modeling approaches.\n- The Figures provided by the authors are helpful to understand the contribution. Beyond\n  aggregated quantitative evaluation, the authors present figures that qualitatively\n  showcase the improvements of the proposed method."
            },
            "weaknesses": {
                "value": "- In the main text, the proposed method is only evaluated on relatively simple,\n  synthetic datasets. As shown in the supplement, the method can be combined with\n  state-of-the-art object-centric models that scale to natural images, but the\n  performance improvements do not seem to be significant.\n- The mathematical description of the method in Section 3 is imprecise at several\n  places. How exactly are the mappings $\\mathcal{K}$ and $\\mathcal{Q}$ defined? I.e.,\n  what are the dimensionalities of the quantities involved in equation 3? In equation 4,\n  the term in the summation does not depend on the summation index $K$."
            },
            "questions": {
                "value": "- The performance comparison in Table 1 uses FG-ARI to quantify segmentation\n  performance. It has been pointed out several times in the literature that this metric\n  is problematic (e.g., Engelcke et al 2020, Karazija et al. 2021, Monnier et al. 2021). \n  How do the proposed methods perform in terms of the Object IoU metric?\n- Does the Object IoU metric include evaluating IoU for the background segment?\n- How were the object sizes chosen that where used to differentiate small, medium and\n  large objects? Which fraction of the objects is small, medium and large, respectively?\n  Beyond the agregated evaluation, it could be helpful to present a scatter plot of\n  object size vs IoU for all objects in the evaluation set.\n- How were the hyperparameters selected?\n- Which performance is achieved when the features are clustered using a conventional\n  approach such as normalized cuts instead of Slot Attention?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7275/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7275/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7275/Reviewer_uwGV"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698660768754,
        "cdate": 1698660768754,
        "tmdate": 1700652150274,
        "mdate": 1700652150274,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wZl9zFZTvW",
        "forum": "Y3NBqtrQat",
        "replyto": "Y3NBqtrQat",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_TuCC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_TuCC"
        ],
        "content": {
            "summary": {
                "value": "The paper's major contribution is introducing idea of top-down modulation in Reverse Hierarchy Theory to the standard slot-attention model aimed for object-centric learning. The major architecture novelty is  a top-down path from the slots of slot attention model to attend the image features and directly generate an attention map by a CNN decoder. This attention map is in turn used to compute a conflict map against the original object mask produced directly by the slot representation through a spatial broadcasting. The conflict loss appears to be the major driving force for the model to improve its ability of discovering small objects, which other models often fail to detect. The model demonstrates superior performance to other models on several benchmark datasets with pure colors, but also generalizes to CLEVRTex which introduces some texture within each object with a dominant distinct color."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) All the benchmark result show that the proposed model outperform previous models.\n\n(2) The idea of conflict loss between the two object mask maps appear novel.\n\n(3) Analysis of the representation of objects in CLEVRTex dataset shows that the model learned a representation that has smaller variance in intra-object feature (locked to image grids) than inter-object feature, which may help better group pixels within an object into a same slot. Such analysis is helpful for partially understanding why a model learns better (but I still remain somewhat puzzled, please see my comment in Questions)"
            },
            "weaknesses": {
                "value": "(1) At inference, the model needs to be run for multiple times to get a performance gain. This increases computational time. \n\n(2) I think it is worth acknowledging some limitation observed in the visualization. One of the examples in ObjectsRoom of Figure 4 actually shows the proposed model is the only one that hallucinates the yellow color of the floor seen through the hollow part of the triangle shape. From the supplementary material, it seems often \"fill in\" the hollow part o the triangle in the segmentation mask, which should actually be background. From visual inspection, it seems that for the more challenging datasets such as CLEVRTex, missing small and partial objects is still frequent. And the model appears to often ignore the detailed texture in reconstruction but only captures the average color. Of course all models have limitations, I think it is worth pointing these out in discussion, and it will be interesting to postulate why texture often gets ignored.\n\n(3) It is more of a question but also a weakness (only for the sake of gaining insight): I still lack full understanding of where the teaching signal or inductive bias comes from to get the improvement. See my comment (1) in Questions."
            },
            "questions": {
                "value": "(1) Although conceptually it makes sense that top-down modulation should help in object perception, because obviously the brain uses it, the computational mechanism of why it helps in the experiments presented in the paper still remains puzzling to me. I am happy to see the analysis in Figure 7 of the intra-object vs. inter-object feature variance and Figure 6 illustrates the failure of bottom-up only network. But my question is: what even caused these improvement. My guess is that \"in-principle\", when the top-down attention from the slot includes some aggregated information over pixels of the objects, it is possible for the low-level features to be biased towards such aggregated information. But \"in-principle\" does not mean this is guaranteed. Moreover, what drives the network being able to learn to detect small objects better? It sounds that the paper indicates that the conflict loss term is the guidance, but the conflict term is simply the conflict between two masks that are both internally generated and to be learned, with no additional inductive bias or teaching signals by introducing the top-down pathway. \n\nTo illustrate my point in more detail: if the slot representation has already lost one small object in the object masks M as in Figure 2, why would it necessarily produce the mask of the missing object through the attention to low-level feature and eventually show in the attention map A? Why would not minimizing the conflict loss C drive A to be more close to M (which will remove the small object) instead of vice versa? There seems to be no teaching signal directly from the image to constrain the attention map A, so I would guess that A is initially random in early stage of learning and is taught by M. Is that the case? If indeed A starts being better than M (it includes the missing objects while M does not), then why not just include A alone in the model? Why bother introducing M? \n\nOne guess is that the major contributor for the better ability of detecting small objects is just the extra depth in the attention map pathway introduced by the top-down attention. If so, would introducing more iterations in the original slot attention model achieve similar improvement? I wonder if the authors can elucidate the actual mechanism.\n\n(2) I would like to get a confirmation that no component of the network is pretrained on other tasks. If some of them are pre-trained, please explain.\n\n(3) At inference time, the model is run N times and the one with the smallest conflict C is chosen. I wonder whether the performance improvement mainly comes from this selection process. What happens to the performance if you set N to 1? I wonder if the authors think that this variation has some similarity to the brain? Perhaps the brain does not always detect all objects with one (or two) glances. The ones being missed by the brain depends on what a person's initial top down attention is on."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698757432867,
        "cdate": 1698757432867,
        "tmdate": 1699636868431,
        "mdate": 1699636868431,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YgnwqhoOKI",
        "forum": "Y3NBqtrQat",
        "replyto": "Y3NBqtrQat",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_UGEP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7275/Reviewer_UGEP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to add a top-down attention mechanism in current standard Object Oriented Learning models to overcome a blindness issue that occurs for occluded and small objects in crowded scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method introduced for using the top down guidance adds a loss function during training that is based on minimising a consistency measurement that evaluates the match of low features extracted with the object slots using KL divergence between these two factors.\nAt inference time, the number of iterations for the refinement with the top down consistency approach has an impact on the final performance, and it might be a nice way to having a compromise between inference computational time and final performance.\n\nA thorough experimental set-up with ablation studies is reported, demonstrating the higher accuracy of the model in comparision to state-of-the art and the contribution to each of the components."
            },
            "weaknesses": {
                "value": "The connection to human visual system is rather weak, and even though it can serve as inspiration, there is no evidence that this could be a computational model for human computations of top down signals. There are other works that point to recurrent connections and other mechanisms for human brain modeling."
            },
            "questions": {
                "value": "See weaknesses points"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699020789938,
        "cdate": 1699020789938,
        "tmdate": 1699636868317,
        "mdate": 1699636868317,
        "license": "CC BY 4.0",
        "version": 2
    }
]