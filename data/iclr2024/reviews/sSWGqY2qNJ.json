[
    {
        "id": "jzU7qTbBWa",
        "forum": "sSWGqY2qNJ",
        "replyto": "sSWGqY2qNJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes \"Indeterminate Probability Theory\", which is claimed as an extension of classical probability theory. Based on the proposed theory, the authors derive an analytical expression of general posterior, which has some applications such as IPNN and CIPNN. Experimental results validate the proposed theory."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper claims to extend classical probability theory, which is very ambitious and is definitely important if this is true."
            },
            "weaknesses": {
                "value": "The main contribution of this paper is the proposed \"Indeterministic Probability Theory\", but it is far from satisfaction to be a theory, especially when it is stated to be \"an extension of classical probability theory\". It is actually built on the axioms of classical probability theory, added with a specific generation process of random variables, and three proposed \"candidate axioms\", thus it at most becomes \"a special sub-field of classical probability theory\". \n\nEven worse, the paper claims that \"our most important contribution is that we propose a new **general analytical** and **tractable** probability equation\", but neither is theoretically validated: for **general analytical**, it is analytical, but it is not discussed enough why the proposed two-phase protocol is general; for **tractable**, it is also not verified the error of approximation via Monte Carlo methods. There are some experimental results to verify the effectiveness of Monte Carlo, but is over-simplified to validate it in such a general theory as is claimed, and more importantly, the effectiveness of Monte Carlo in this paper is not \"proved\" yet. \n\nTo be honest, section 3 is more like a section of \"problem formulation + proposed approach\": The two-phase protocol is more like the problem formulation, the axioms are more like some assumptions of independence, and the complexity reduction using Monte Carlo is more like the proposed approach."
            },
            "questions": {
                "value": "What do you want to say in Section 2? It seems that the example does not go beyond classical probability theory, i.e., all definitions, quantities and calculations are consistent with definitions and axioms in classical probability theory.\n\nWhat is new in your indeterminate probability theory? Specifically, I am confused why eq. (4) must be 0 or 1 in classical probability theory. Could the authors give some references? The authors should give references, clear derivations or rigorous counter-examples when refuting something in classical probability theory, as it is based on rigorous mathematics. \n\nHow general your proposed theory is? For example, does your theory enable A and Y to be any kind of random variables, and can the two-phase protocol in your theory model any data-generation process? If not, then the generality of your theory should be discussed. \n\nIn page 5 the authors say \"...Otherwise, Candidate Axiom 2 and Candidate Axiom 3 cannot both be true\". In my opinion, it is strange to discuss the soundness of an axiom once it is proposed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697617155207,
        "cdate": 1697617155207,
        "tmdate": 1699636397632,
        "mdate": 1699636397632,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ChRiYuwGYA",
        "forum": "sSWGqY2qNJ",
        "replyto": "sSWGqY2qNJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to introduce a new theory of probability to cope with imperfect observations, in the sense that the reported value can be different from the true experimental result. This is done through the introduction of an \"observer\", which can be imperfect, in the sense that it is noisy. The theory is then applied to various case studies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "I do not really perceive any strong point in the paper, other than the fact that modelling imperfect observational process is an interesting, yet arguably old topic."
            },
            "weaknesses": {
                "value": "This paper is puzzling me in more than one ways, and I will focus on the main ones (some for which the authors can offer a rebuttal, mostly when it concerns the content and not the form of the paper). \n\nA first thing is that the paper is written in a very unusual way, at least for a paper of computer science and/or machine learning. It is very rare to directly start with a mathematical formulation, without making first an introduction (and possibly related work) positioning the proposal and its originality. \n\nA second thing is that the paper is very quick on some technical details, while being very verbose on rather basing thing such as classical applications of probabilistic conditioning. It is also a bit cryptic in terms of language as well as bit naive about some aspects. For instance, P2 top, it is not true that one cannot apply Bayes rule in continuous setting, and it has been numerous, numerous times. At this point, what means indeterminate is also quite obscure. Similarly, it is not clear for the naive Bayes what exactly means $P(A^j=a^j_{i_j}|Y=y_l)$ being not solvable? It can certainly be estimated from data, even in case of noisy observations or untrue assumptions (potentially leading to biased estimates, but it can nonetheless be estimated). \n\nA third thing is that it is unclear what authors really understand by \u201cindeterminate\u201d: is it that the observational process is noisy, or that the obtained probabilities are ill-known and hence that one should consider sets of possible probabilities? The paper suggests the first case, yet in such a situation I really do not see what is different between what is proposed in the paper and the consideration of noisy data where one does know or can estimate the noise process? Given that there is a huge literature on learning from noisy (and/or imprecise) data, at least a positioning with respect to those should be done. Indeed, if the main idea of the paper is to have $P(y_{obs}=y|y_{true}=y)<1$ ($y$ here can be either the output value or a feature value) and then to proceed from that, then I would argue that considering such a situation is not new at all. Similarly, if indeterminate means ill-defined, then there is a whole literature about that (see, e.g., work following the book on Peter Walley on imprecise probabilities and similar). Claiming to build a new theory of probability should be backed up by being very precise about why previous theories do not answer the considered problem. \n\nA fourth thing is that it is really unclear to me why the current experiments, that merely show accuracy results for standard problems, do show that the theory is \u201cvalid\u201d? I would equally question a statistical learning theory or more generally an uncertainty theory whose axioms cannot be the subject of tests and falsification? All theories of uncertainty I know of that are a bit serious in terms of operationally are subject to falsifiability, and this especially true for probabilistic theories (see the Ellsberg paradox for a good example of attempted falsification). Also, since Softmax does not enjoy peculiarly good properties from a theoretical perspective, I would not consider it as a strong baselines against which to test the axioms of a theory?"
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethical concerns"
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698589216177,
        "cdate": 1698589216177,
        "tmdate": 1699636397530,
        "mdate": 1699636397530,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4DdfJbqlyA",
        "forum": "sSWGqY2qNJ",
        "replyto": "sSWGqY2qNJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
        ],
        "content": {
            "summary": {
                "value": "This is an extremely ambitious paper that attempts to construct a new theory called indeterminate probability theory. The key idea of Indeterminate probability theory is to introduce a new concept of auxiliary observers and to treat the results of each random experiment as an indeterminate probability distribution, while still preserving the assumption of mutual independence. As a result, the posterior probabilities of the system can be derived in a form that is easy to handle analytically, an important benefit in applications.\nThe authors demonstrate the applicability of this idea to regression and classification problems by combining it with neural networks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I am very grateful to the authors for sharing their novel attempt at this paper. I enjoyed reading this paper very much.\n- The paper devotes a great deal of effort in its presentation to illustrate new ideas that are outside of the conventional wisdom. The paper is very well written and its organization is designed to appeal to a diverse audience. In particular, it is designed to be easily understood by explaining the core ideas by means of toy examples.\n- The practical contribution of this paper is very significant. Traditionally, posterior probabilities in statistical machine learning have been approximated by some kind of approximation method (e.g., Markov chain Monte Carlo or variational methods), but the ideas in this paper have the potential to be a new option to add to that."
            },
            "weaknesses": {
                "value": "First of all, let me emphasize that I am trying to be very open minded in understanding the value of this paper. My grade on my first peer review may not be very high, but I am prepared to improve it as soon as I properly understand the value of this paper.\nMy concern is whether this paper could create a new system of probability theory (i.e., a major historical breakthrough) or whether it provides a new perspective on approximation and interpretation for the system in a form that is easy to handle in applications (i.e., a new alternative alongside MCMC and VB), a somewhat excessive Is it an appealing proposition? I would like to inquire in the question section for more details."
            },
            "questions": {
                "value": "My question can be summarized very simply as to whether or not indeterminate probability theory can be expressed in terms of a definition of probability space using abstract probability space.\n\nFirst of all, I understand this new insightful strategy of the authors as follows (Perhaps this understanding of mine is incorrect. If I am wrong, I would be very grateful if you could correct me.) \n- The authors' system introduces uncertainty as an auxiliary variable for observers. If this were to be expressed in the context of a conventional standard Bayesian analysis, the observer could be represented as making an observation error according to the auxiliary random variable.\n- Next, since this auxiliary random variable is not needed to describe the system, we will try to eliminate it in some way. In a conventional standard Bayesian analysis, this can be done by eliminating the auxiliary random variable by marginalization. However, a problem arises here. If the auxiliary random variable is shared by all observers, the system loses observer independence (Axiom 2 of the proposed probability theory) when it is eliminated.\n- Therefore, the proposed probability theory simply ignores the auxiliary random variable while simultaneously assuming Axiom 2.\n\nIf we were to use such a strategy, it would certainly seem that we could view the system as different from classical probability theory (as mentioned in the paper, we could of course make special cases that are equivalent to classical probability theory in special circumstances).\n\nFollowing this intuition, my interest is in what the authors' system would look like if it were represented in an abstract probability space. That is, a situation where all randomness in the world is governed by an abstract space $\\Theta$, where all randomness is lost if the abstract space is determined at a point $\\theta\\in\\Theta$, and where all variables can be described deterministically. In the abstract space, random variables are represented as a projection of the world as a map to an object, e.g., $Y(\\theta), X(\\theta), A(\\theta)$ can be uniquely determined for a given source $\\theta$. Can the authors' system be represented using such a conventional abstract probability space? Or is it a deviation from that rule?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4295/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4295/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772236660,
        "cdate": 1698772236660,
        "tmdate": 1700388286660,
        "mdate": 1700388286660,
        "license": "CC BY 4.0",
        "version": 2
    }
]