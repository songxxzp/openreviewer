[
    {
        "id": "wS976dAG4n",
        "forum": "hv3SklibkL",
        "replyto": "hv3SklibkL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_UKss"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_UKss"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an efficient graph parsing algorithm to infer the pooling structure that drives graph pooling. The pooling structure is trained end-to-end. It achieves competitive real-world performance and good memory and time efficiency."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Clear presentation of method.\n\n2. Extensive experiments on both graph and node tasks."
            },
            "weaknesses": {
                "value": "1. Time complexity. Though the paragraph above Proposition 4 claims that the time complexity of each pooling layer is $O(n^{(k)})$, the computation of edge score $C$ still takes $O(m^{(k)})$ time.\n\n2. Proposition 5 is doubtful. The argmax operator may not produce unique output when the multiset has several equal maximum elements. \n\n3. The performance gain in ablation study is not significant. In Table 4, the performance difference between the origin model and the model with  Mean pool is smaller than the score deviation."
            },
            "questions": {
                "value": "1. The point 1 and 2 in the Weakness section.\n\n2. The argmax operator in DOM is not differentiable. How to train the whole model end-to-end?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698318573709,
        "cdate": 1698318573709,
        "tmdate": 1699637157158,
        "mdate": 1699637157158,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DF4T857baJ",
        "forum": "hv3SklibkL",
        "replyto": "hv3SklibkL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_xTBe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_xTBe"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to construct a graph pooling method called a graph parsing network (GPN) that can be personalized to every graph and has a good balance of maintaining the node information and high memory efficiency simultaneously. \nThe method is built upon existing GNNs and designs a novel algorithm to construct personalized pooling trees for graphs. The empirical results on graph classification show its effectiveness and efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well written, clearly showing its motivation and model structure.\n2. The novel part lies in that it designs a novel algorithm that can adaptively form clusters layer by layer that minimizes loss of information of graph structure and node features, and since it does not have learnable parameters in the graph parsing algorithm. \n3. The empirical results on graph classification and reconstruction demonstrate that the proposed model has a good ability to maintain the graph structure and node feature information."
            },
            "weaknesses": {
                "value": "1. It seems that GPN works well on small-sized graphs from the experimental results. Discussion on large-sized graphs is expected to be included in the paper. \n2. If the tree is high for some large-sized graph, the performance might be worse due to over-smoothing.\n3. For the model itself involving GNNs, it is not clear how you train this model."
            },
            "questions": {
                "value": "1. What does a 'different GNN` mean in node classification? $\\mathbf{H}^{(k)}$ in Eq. 3 is the same as '$GNN^\\prime(\\mathbf{X}^{(k)}, \\mathbf{A}^{(k)})$` in eq. 10."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Reviewer_xTBe"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698640817736,
        "cdate": 1698640817736,
        "tmdate": 1699637157044,
        "mdate": 1699637157044,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XUJ0GfBwc7",
        "forum": "hv3SklibkL",
        "replyto": "hv3SklibkL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_4RVW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_4RVW"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel graph pooling method, namely Graph Parsing Network (GPN), which aims to learn an individual pooling structure for each individual graph in an end-to-end fashion while being memory and time efficient. Specifically, the authors generate the assignment matrix, which is used to transform the larger graph into its compressed smaller graph by mapping nodes of the original graph into certain clusters, per graph. Also, this assignment matrix is generated based on the graph parsing algorithm that infers pooling structures of graphs from their edge scores, i.e., firstly selecting the dominant edges and then expanding them to construct the node assignment matrix for graph pooling. The authors evaluate the performance of the proposed Graph Parsing Network (GPN) on graph classification and node classification tasks as well as the graph reconstruction task, showing its effectiveness and efficiencies."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The motivation to adaptively condense different graphs based on their differences in graph structures (i.e., edge importances) is sound.\n* The idea of using a graph parsing algorithm to make an individual pooling structure for each graph is interesting and reasonable.\n* The proposed GPN surpasses existing graph pooling methods on both graph-level and node-level tasks.\n* The proposed GPN is efficient in terms of memory usage and computational time, particularly compared to the node-clustering-based (assignment-matrix-based) graph pooling methods."
            },
            "weaknesses": {
                "value": "* This work may be similar to the idea of [1] which considers and manipulates edges during graph pooling (i.e., making the cluster assignment matrix with edges), since this work also performs edge-centric graph pooling with the cluster assignment matrix that is generated from edges. \n* Equation (4) lacks details on motivation. I understand that, in order to perform backpropagation with edge scores, edge scores should be added or multiplied with other learnable variables. On the other hand, it is unclear why the edge scores should be multiplied in this way (Equation (4)) and what may be the effect of this multiplication on node features.\n* The authors may further perform the statistical test on the main results (Table 1 and Table 2) since the performance of the proposed GPN is comparable against other performant baselines when considering mean and standard deviations together.\n\n---\n\n[1] Edge Representation Learning with Hypergraphs, NeurIPS 2021."
            },
            "questions": {
                "value": "* In Equation (10), it may be better to represent the superscript on GNN' according to its layer index, since GNN' is different across different layers. \n* In Figure 5, the proposed GPN is memory efficient compared to the baseline that uses the cluster assignment matrix for graph pooling. However, the GPN also uses the cluster assignment matrix for graph pooling. In this vein, I am wondering why there exists a significant difference in efficiency while both methods are similar in using the cluster assignment matrix."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9196/Reviewer_4RVW"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698757024970,
        "cdate": 1698757024970,
        "tmdate": 1700377724730,
        "mdate": 1700377724730,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BJzIWValx8",
        "forum": "hv3SklibkL",
        "replyto": "hv3SklibkL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_H5gS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9196/Reviewer_H5gS"
        ],
        "content": {
            "summary": {
                "value": "This paper deals with graph pooling, i.e., compressing graph information into compact representations. The paper contains a mostly experimental study of various methods. The proposed graph parsing network constitutes a novel contribution, it adaptively learns personalized pooling structures. Experimental results show that the method outperforms state of the art graph pooling methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed approach does seem novel, and it also seems to perform well compared to existing graph pooling networks."
            },
            "weaknesses": {
                "value": "Graph pooling can elegantly be cast into a compression framework and would hence benefit from an analysis of\nits fundamental limits based on information theory. The pooling of a graph structure (potentially with some side information as\nconsidered) here is a classical information-theoretic problem, i.e., how to best store all the information characterizing the graph\nin a vector of finite length or even better a bitstring of finite length. It may well be that the entire field of graph pooling as\ncurrently considered in the ML literature does not take this perspective, but reading this paper makes it clear that many of the questions\nasked here would benefit from such a perspective.\n\nGenerally, this reviewer finds the paper to be quite ad-hoc and also it uses a lot of jargon, not always defined or consistently used. The language is also confusing in many places."
            },
            "questions": {
                "value": "none"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699113065072,
        "cdate": 1699113065072,
        "tmdate": 1699637156815,
        "mdate": 1699637156815,
        "license": "CC BY 4.0",
        "version": 2
    }
]