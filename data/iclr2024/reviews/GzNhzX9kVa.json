[
    {
        "id": "Hw5vRYq2tc",
        "forum": "GzNhzX9kVa",
        "replyto": "GzNhzX9kVa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the calibration properties of deep neural networks (DNNs) using neural architecture search (NAS) search space. The motivation stems around the observation that, calibration properties of DNNs have not been thoroughly studied in the past, and NAS search space allows to create a comprehensive dataset of neural network architectures, which can be evaluated to study calibration properties. The dataset encompasses several bin-based and other calibration measurements across 117,702 unique neural network architectures. Particularly, the NATS-Bench has been used to curate the proposed dataset as it allows more broader search space, comprising models of various sizes. The study also includes eleven recent vision transformer architectures. The proposed analyses aims to answer seven different questions, including the interplay between accuracy and calibration, if calibration performance generalizes across datasets, the impact of bin sizes on calibration measurement, and which architectures are better for calibration. Post-hoc temperature scaling method is used as a calibration technique."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The study of calibration properties of deep neural networks is an important research direction as it could allow developing well-calibrated architectures.\n\n- The paper develops a comprehensive benchmark of neural network architectures that are then evaluated on different datasets to answer various questions. Further, recent vision transformer architectures have also been included as part of evaluation.\n\n- Some questions included in the study are interesting and important: such as the Impact of bin sizes on calibration measurement and can model calibration be generalized across different datasets.\n\n- Overall, the paper is well-written and it is not difficult to read and understand."
            },
            "weaknesses": {
                "value": "- Overall, the new questions posed and studied by the paper boils down to 1), 3) and 6) which are:\n\n-- Model Calibration across different datasets\n\n-- Reliability of calibration metrics\n\n-- Impact of bin size on calibration metrics\n\n- Other questions are mostly expansion of existing studies. This seems to undermine the overall contributions of the paper to some extent.\n\n-Only post-hoc temperature scaling is used as a calibration technique to evaluate pre- and post calibration performance of a large chunk of models. There have been several new calibration methods, especially in train-time calibration paradigm, such as [A], [B] and [C].\n\n-In 4.3: 1) What are the possible reasons of ECE showing consistent results with other metrics, although some other metrics are theoretically different? 2) Also, it is not clear that which calibration metric should be preferred over others in the scope of studies?\n\n- What is the significance of 4th question (i.e. does a post-hoc calibration affect all models uniformly) in terms of advancing the research and algorithmic development in calibration?\n\n- The abstract mentions \u2018data pre-processing\u2019 methods for improving calibration but such methods are discussed nowhere in the paper, including the related work.\n\n\n[A] Liu, B., Ben Ayed, I., Galdran, A. and Dolz, J., 2022. The devil is in the margin: Margin-based label smoothing for network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 80-88).\n\n[B] Patra, R., Hebbalaguppe, R., Dash, T., Shroff, G. and Vig, L., 2023. Calibrating deep neural networks using explicit regularisation and dynamic data pruning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1541-1549)\n\n[C] Hebbalaguppe, R., Prakash, J., Madan, N. and Arora, C., 2022. A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 16081-16090)."
            },
            "questions": {
                "value": "- How the proposed study and dataset would be helpful toward the development of new calibration methods for classification?\n\n- It is a bit hard to grasp how the current analyses addresses the question of how reliable are calibration metrics?\n\n- Would the finding that the bin size has a more substantial impact on Post-ECE be relevant for any train-time calibration technique too?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethical concerns could be identified."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1053/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1053/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698736185127,
        "cdate": 1698736185127,
        "tmdate": 1699636031557,
        "mdate": 1699636031557,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zgk9HYSD4Q",
        "forum": "GzNhzX9kVa",
        "replyto": "GzNhzX9kVa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a study that analyzes the relationship between NAS and calibration powers of neural networks. The paper combines CIFAR-10, CIFAR-100, and ImageNet as the dataset in which multiple architectures are tested and measure its calibration powers. The study of the paper thus focuses only on image classification problems using small- and medium-scale datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. I really value the topic of calibration as I believe it is a good feature to have in many classification tasks and systems. I think the paper tackles an important problem.\n\nS2. The clarity of the paper is good, the narrative flows well, and is easy to understand and follow."
            },
            "weaknesses": {
                "value": "W1. The motivation about why NAS + Calibration is important is missing in the paper. Unfortunately, the paper lacks a clear justification for studying NAS + Calibration. It is not clear intuitively why this is a good direction to explore. It is not clear why a wholistic approach is not worth exploring over NAS + Calibration. Unfortunately, the paper makes the reader believe that the analysis was done just because it has not done before. I think the paper really needs to justify why NAS + Calibration is a good angle to study.\n\nW2. The study uses small- and medium- scale datasets for analyzing the relationship between NAS + Calibration. In particular, the study uses CIFAR-10, CIFAR-100, and ImageNet datasets for the analysis. While I understand that small datasets are easier to handle given the NAS component of the study, it is questionable the conclusions one can get from these small datasets. While ImageNet is larger, compared to modern large-scale datasets, such as, LAION, its use is also questionable. Modern image classification methods are trained using foundation models that use really large-scale datasets (e.g., LAION) and those are the worth studying in my opinion since they are the ones adopted in industry and are making an impact. I think the paper needs to justify the use of these small- and medium-scale datasets. Otherwise, the conclusions drawn from the studies are not solid."
            },
            "questions": {
                "value": "Please see the Weaknesses stated above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698843694933,
        "cdate": 1698843694933,
        "tmdate": 1699636031482,
        "mdate": 1699636031482,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zj4P7thrt3",
        "forum": "GzNhzX9kVa",
        "replyto": "GzNhzX9kVa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_S1Jc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1053/Reviewer_S1Jc"
        ],
        "content": {
            "summary": {
                "value": "This paper conducts several investigations about the calibration problem of the deep neural networks. This paper introduces a calibration dataset based on the NATS-Bench for generating massive CNNs with different topologies or model sizes. This paper adopts the calibration dataset and evaluate the different calibration metrics to analyze the calibration properties in deep neural networks. This paper provides extensive explorations and conclusions through the benchmarks"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis paper raises 7 initial questions for exploring the calibration properties in deep neural networks.\n2.\tThis paper builds a benchmark based on models generated by NAS for evaluating the calibration metrics.\n3.\tThis paper conducts extensive experiments to analyze and answer the questions."
            },
            "weaknesses": {
                "value": "1.\tThe proposed calibration benchmark might be limited since it contains only convolution neural networks for image classification. I\u2019m concerned about how about the calibration properties for other tasks, e.g., object detection or NLP tasks. It\u2019s more convincing when extending the benchmark for more architectures and more tasks.\n2.\tMost architectures and networks are generated from the similar search space, which might have similar effects and are limited for the conclusions. Varying the search spaces and using human designed architectures are necessary.\n3.\tDifferent architectures on different benchmarks/dataset might require different hyper-parameters. Though it\u2019s hard to search optimal/sub-optimal parameters for different models, it will affect the experimental results.\n4.\tThis paper explores the calibration properties in neural networks, but I\u2019m much concerned about how those findings impact the future research or guide the designing process for both accuracy and calibration performance."
            },
            "questions": {
                "value": "See the weaknesses above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698974476345,
        "cdate": 1698974476345,
        "tmdate": 1699636031420,
        "mdate": 1699636031420,
        "license": "CC BY 4.0",
        "version": 2
    }
]