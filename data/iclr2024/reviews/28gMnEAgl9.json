[
    {
        "id": "ye9Plo5Rw1",
        "forum": "28gMnEAgl9",
        "replyto": "28gMnEAgl9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_As6m"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_As6m"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an evaluation of Large Language Models (LLMs) on abstract reasoning tasks. The authors introduce a new benchmark for evaluating LLMs on abstract reasoning and conduct extensive experiments on language models. The results show that LLMs currently achieve limited performance on abstract reasoning tasks compared to other natural language tasks. The authors also explore the impact of fine-tuning and prompt design techniques on abstract reasoning performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This article attempts to address a topic of great interest - whether large models possess the capacity for abstract reasoning.\n2. The authors provide a comprehensive evaluation and conduct extensive experiments on various language models."
            },
            "weaknesses": {
                "value": "1. Similar conclusion has been explored by previous studies [1][2]. \n\n[1] \"Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks.\" arXiv preprint arXiv:2307.02477 (2023).\n\n[2] \"Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners.\" arXiv preprint arXiv:2305.14825 (2023)\n\n2. Lack of experiment with larger models or advanced models. Fine-tuned on smaller models cannot sufficiently draw the conclusion."
            },
            "questions": {
                "value": "1. Can you experiment with more advanced models Llama-2, with better performance than Llama1, Alpaca, or fine-tune with larger models (13B, 70B)? \n2. The details of fine-tuning experiments, such as training data, training steps. Do you consider incorporating the instruction about \u201chow to induce\u201d, \u201chow to deduce\u201d into supervision?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2575/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698832895654,
        "cdate": 1698832895654,
        "tmdate": 1699636194556,
        "mdate": 1699636194556,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aPoaNL0LDx",
        "forum": "28gMnEAgl9",
        "replyto": "28gMnEAgl9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_LbQe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_LbQe"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the abstract reasoning abilities of LLMs. The authors propose a benchmark for evaluating language models in order to comprehensively assess their abstract reasoning capabilities. Their experiments reveal that current LLMs struggle with abstract reasoning tasks and techniques that have previously improved performances on other NLP tasks do not result in significant enhancements for abstract reasoning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper investigates abstract reasoning abilities of Large Language Models by creating a new benchmark combining existing datasets with novel datasets adapted from vision tasks for language models, which has not been extensively studied before.\n2. The evaluation is pretty extensive including a wide range of models and tried a few techniques beyond just simple prompting. \n3. The paper is well-written and organized.\n4. The proposed task has not yet been solved by LLMs."
            },
            "weaknesses": {
                "value": "1. this task will be automatically solved when models of better reasoning capabilities become available.\n2. The authors frame abstract reasoning as \"a potential task for effective measurement of the cognitive abilities of neural models\", so the utility of this benchmark is mostly evaluation of LLMs. One concern is that there isn't an actual application that would benefit from studying this kind of reasoning capabilities."
            },
            "questions": {
                "value": "1. Have authors considered fine-tuning?  It would be nice to show even fine-tuning Llama2 is not enough for solving the abstract reasoning tasks.\n2. Curious to see how zephyr-7b-beta (https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) performs on the proposed benchmark.\n3. How is open-ended QA evaluated?\n4. Do the authors have plans to maintain a leaderboard for this task? Will there be a held out test set?\n5. What is the data releasing plan for this benchmark?\n6. Also curious about human performance on this benchmark. For example, I couldn't figure out the example in Figure 6."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2575/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699212812615,
        "cdate": 1699212812615,
        "tmdate": 1699636194484,
        "mdate": 1699636194484,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SoXVfestwP",
        "forum": "28gMnEAgl9",
        "replyto": "28gMnEAgl9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_2kzP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2575/Reviewer_2kzP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to evaluate the abstract reasoning ability of LLMs by curating a set of datasets. Overall the authors show that the performance of current LLMs are limited and various techniques do not help."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well written and easy to follow  \n- The curated benchmark seems high quality\n- The experiments are extensive and demonstrate the main point.\n- The observation that basic techniques do not improve performance is significant."
            },
            "weaknesses": {
                "value": "- This new benchmark introduced are largely existing datasets thus with limited novelties. There are also existing works on evaluating the inductive reasoning ability of LLMs such as https://arxiv.org/pdf/2306.09841.pdf. \n- This paper does not evaluate slightly more complicated prompting methods, such as simply generating more samples of code and filter by number of training examples passed. Existing papers proposing more complicated pipelines: https://arxiv.org/pdf/2212.10923.pdf, https://arxiv.org/abs/2309.05660 ,https://arxiv.org/abs/2310.08559"
            },
            "questions": {
                "value": "n/a"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2575/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2575/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2575/Reviewer_2kzP"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2575/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700415905339,
        "cdate": 1700415905339,
        "tmdate": 1700415905339,
        "mdate": 1700415905339,
        "license": "CC BY 4.0",
        "version": 2
    }
]