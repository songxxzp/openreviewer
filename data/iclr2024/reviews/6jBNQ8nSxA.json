[
    {
        "id": "zkPKgfv0gH",
        "forum": "6jBNQ8nSxA",
        "replyto": "6jBNQ8nSxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_T4hh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_T4hh"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses the urgency of timely patching in open-source software to mitigate vulnerabilities. However, the volume and complexity of patches can cause delays. Various machine learning methods, including a notable one called GraphSPD, have been used to address this, but they lack broader context understanding. The paper proposes a new framework using Large Language Models (LLMs) to improve security patch detection accuracy by aligning multi-modal inputs. This framework outperforms existing methods, indicating the potential of a language-centric approach for better security patch detection and software maintenance."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Novelty in Approach:\n\n\tThe proposed framework introduces a novel method of leveraging Large Language Models (LLMs) to enhance security patch detection. By aligning multi-modal inputs, it extracts richer information from the joint context of patches and code, which is a fresh approach compared to existing methods.\n\n\tImproved Accuracy:\n\n\tThe framework significantly outperforms baseline methods on targeted datasets, showcasing a substantial improvement in detection accuracy which is crucial for timely addressing of software vulnerabilities.\n\n\tLanguage-Centric Focus:\n\n\tThe language-centric approach harnesses natural language instructions to guide the model, which is a distinctive and important shift from traditional syntax or structure-based methods, opening new avenues in patch detection techniques.\n\n\tPractical Applicability:\n\n\tThe results underline the practical applicability of the framework by demonstrating precise detection capability which is vital for secure software maintenance in real-world settings.\n\n\tAddressing a Timely Issue:\n\n\tWith the rapid expansion of OSS, the urgency to address the accompanying surge in vulnerabilities is paramount. This work addresses this timely and critical issue by advancing the methods for swift and accurate security patch detection, thus contributing to the broader goal of enhancing software security and reliability."
            },
            "weaknesses": {
                "value": "Despite the advancements, the state-of-the-art GraphSPD method discussed in the text still primarily focuses on local code segments. This limitation in capturing a broader context of how functions or modules interact could potentially hinder the effectiveness and comprehensiveness of the security patch detection process, especially in complex or large-scale software systems."
            },
            "questions": {
                "value": "The experiments utilized two datasets, PatchDB and SPI-DB, for evaluation. How representative are these datasets of the real-world OSS ecosystem? Were they sufficiently diverse and large-scale to validate the generalizability and robustness of the proposed framework across different types of software systems and security patches?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3467/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698303307768,
        "cdate": 1698303307768,
        "tmdate": 1699636299712,
        "mdate": 1699636299712,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kz4qbM9VJb",
        "forum": "6jBNQ8nSxA",
        "replyto": "6jBNQ8nSxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_z5t8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_z5t8"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a new security patch detection framework, LLMDA, leveraging LLMs for patch analysis and data augmentation, while aligning various modalities. This allows the system to extract richer information from the joint context of patches and code, boosting detection accuracy.\n\nThe authors also demonstrate that a language-centric approach, coupled with a well-designed framework, can yield significant performance improvements in the context of security patch detection. The experimental results show the effectiveness of the proposed approach for security patch detection."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper introduces an effective method that aligns multi-modal input for more accurate security patch detection.\n\nThe experimental results show the effectiveness of the proposed approach for security patch detection compared to the used baselines.\n\nSome of the ablation studies about the proposed method were conducted."
            },
            "weaknesses": {
                "value": "The explanation, description, and instructions can contain biased features supporting the model in security patch detection. In this case, the model does not need to understand the true meaning of the data. Ablation studies for this problem are needed to demonstrate that the model is actually also based on the source code data for security patch detection. If only providing the data (which should be considered as the main factor instead of the explanation, description, and instructions) and the model cannot work well, the model is not a practical solution.\n\nThe model configuration of the proposed method and baselines used in the experiments are not mentioned in the paper. Without these, it is hard to justify the performance of the used models.\n\nThe threats to the validity of the model were not mentioned, for example, in terms of the model designs, the use of hyper-parameters, and the used datasets. I think if the model strongly relies on the explanation, description, and instructions instead of the data, how is it applicable to solve reality security patch detection problems where maybe only data are available?"
            },
            "questions": {
                "value": "The comprehensive intuition of using Hierarchical Attention Mechanisms in the proposed method was not mentioned or investigated. How do Hierarchical Attention Mechanisms help to improve the model performances?\n\nHow about the model configuration of the proposed method and baselines used in the paper?\n\nIn Stochastic Batch Contrastive, how do the authors define the positive and negative pairs?\n\nSome recent methods (e.g., 1 and 2) focus on learning the syntactic and semantic features at the source-code level (the main element we should and need to rely on). That seems more practical than mainly based on the explanation, description, and instructions. How is the proposed method compared to these methods in terms of learning the syntactic and semantic features of the source code data?\n\n1. PatchRNN: A Deep Learning-Based System for Security Patch Identification. Xinda Wang, Shu Wang, Pengbin Feng, Kun Sun, Sushil Jajodia, Sanae Benchaaboun, Frank Geck, 2021.\n\n2. GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics. Shu Wang; Xinda Wang; Kun Sun; Sushil Jajodia; Haining Wang; Qi Li, 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3467/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3467/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3467/Reviewer_z5t8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3467/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698733731459,
        "cdate": 1698733731459,
        "tmdate": 1699636299603,
        "mdate": 1699636299603,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rgqNqYTfnU",
        "forum": "6jBNQ8nSxA",
        "replyto": "6jBNQ8nSxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_pMnS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_pMnS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new multi-modal architecture and a loss function that can classify software patches as security critical or not. This architecture consumes the patch itself (the diff), the provided explanation of the patch, a description of the patch (could be from an LLM) and an instruction that guides the training objective."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Fusing different types of inputs into a single model for detecting security patches.\n+ Shows improvements over the recent methods.\n\nThe idea of using natural language descriptions/explanations + the code (or the diff) together in a single model is promising and can be used in other program security applications. This paper proposes a reasonable way to achieve this and improve the SOTA (GraphSPD) significantly."
            },
            "weaknesses": {
                "value": "- Problematic writing, after Section 3, the writing is low quality and almost looks like a result of an AI model (translated/paraphrased)\n- The technical solutions (especially the loss functions) are not explained well. The design choices are poorly motivated.\n- Some results seem suspicious, e.g., in the ablation study, removing the patch altogether from the model's input barely causes any performance drop. A deeper ablation study might be needed.\n\nThere are many head-scratchers in this paper after Section 3 in terms of writing. For example, weird phrases like \"Dominance Demonstrated\" clearly indicate that something is off. The method PBCL is referred to as SBCL, which I'm assuming is because the word Probabilistic and Stochastic are synonyms. Moreover, the name of the technique (LLMDA) is written as \"Low-Level Malware Detection Algorithm\" in the appendix, and I can't see how this is a proper name for this method. I would like to hear the author's justifications for this situation. Unfortunately, without a significant rewrite, this paper is not up to the standards we would expect from ICLR.\n\nMoreover, there's a lack of intuition for some of the design choices (especially PBCL), it provides some performance improvements in the ablation study but I'm not sure what it actually achieves. I would recommend a case study (e.g., analyze some representations w/ and w/o this loss) and provide a better intuition for it.\n\nFinally, there's a red flag in the ablation study that removing the patch itself from the input barely hurts the performance. Some possibilities: a bug in evaluation (testing on the train, training on test?) the LLM-provided patch explanations, or the Code-LLM might be suffering from test set leakage (since these models are trained on everything). This is the problem of using pre-trained LLMs for studies like this, you cannot make sure that the models are not trained on the testing samples or they might even have seen more data about these patches from various other training data sources. I'm not entirely sure how to confirm/refute this but right now, it is a red flag to me that the patch code itself has little importance on your results. What are your ideas to address this concern?"
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Some phrases and the overall very awkward language in most of the paper hint at foul play (paraphrased from another paper, translated from another language using a model). I recommend a review."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3467/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698899378201,
        "cdate": 1698899378201,
        "tmdate": 1699636299529,
        "mdate": 1699636299529,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5KUqQQT8M0",
        "forum": "6jBNQ8nSxA",
        "replyto": "6jBNQ8nSxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_aN2M"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3467/Reviewer_aN2M"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new security patch detection framework called LLMDA (Low-Level Malware Detection Algorithm) that leverages large language models (LLMs) and multimodal input alignment. the paper makes notable contributions in advancing security patch detection through an innovative multimodal framework powered by LLMs and contrastive learning. The results highlight the potential of language-centric techniques in this application domain."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The idea of using LLMs to generate explanations and instructions for patches is novel and creative. \nPrior works have not exploited LLMs in this manner for security patch analysis. \nThe overall system design and methodology are well-conceived and technically sound. The ablation studies in particular are thorough. This work makes important strides in advancing the state-of-the-art in security patch detection. The performance gains are significant. \n\nIn summary, this paper makes noteworthy contributions through its novel application of LLMs and represents an important research direction for security. The original ideas, rigorous experiments, and potential impact make it a valuable work."
            },
            "weaknesses": {
                "value": "Only two datasets are used in the experiments. Testing on a more diverse range of projects and codebases would better showcase the generalizability. \nThe datasets used are fairly small, with PatchDB having 36K samples and SPI-DB only 25K. For deep learning, these sizes are quite modest. Training and evaluating on larger corpora could lend more statistical power."
            },
            "questions": {
                "value": "1.Could you provide the exact prompts used to generate the explanations and instructions? This context would help with reproducibility.\n2.The ablation study removes one component at a time. How does performance degrade when ablating multiple components together?\n3.Can you apply the case study analysis to a larger and more diverse sample of patches? Any insights on patterns?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3467/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699137900489,
        "cdate": 1699137900489,
        "tmdate": 1699636299463,
        "mdate": 1699636299463,
        "license": "CC BY 4.0",
        "version": 2
    }
]