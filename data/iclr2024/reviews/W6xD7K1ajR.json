[
    {
        "id": "dylTlAjFhU",
        "forum": "W6xD7K1ajR",
        "replyto": "W6xD7K1ajR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_KcFU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_KcFU"
        ],
        "content": {
            "summary": {
                "value": "Drawing from the two redundant problems of Kynk\u00e4\u00e4nniemi et al. (2019) that employing representative subsets of generative and real samples would give the similar results as standard Precision and Recall (P&R) ratio, and empirical observations of the dataset that 1) samples of similar hubness values have the similar ratios of 1 vs. 0 in P&R, and 2) phi^prime with high hubness values are enough for manifold identification, the authors propose a method using subsets of generative and real samples with certain hubness criterion in conjunction with approx. k-NN to reduce time and space complexity."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The observations in Fig. 1 and 2 are intriguing.\nThe authors dissected ratio and manifold identification as separate components and conducted well-supported experiments.\nThe results are promising."
            },
            "weaknesses": {
                "value": "The observations in Fig. 1 and 2 are highly empirical while they serve as necessary foundations of the method."
            },
            "questions": {
                "value": "The description of Fig. 2 is confusing. For example, \"Hubness\" and \"non_hubness\" are only explained the the main text not in the description of the figure. And I cannot understand \"the times a sample is included in the k-NN hypersphere of a sample of the other distribution, i.e., valid \u03c6\u2032 (FFHQ)\".\nPlease add theoretical analysis of the interesting observations in section 4.2.\nA brief introduction of approximate k-NN method would be helpful (but since I am not an expert in this filed, it depends on you).\nSince the observations are highly empirical, could you add more experiments about t choice (experiments in table 5)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2573/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2573/Reviewer_KcFU",
                    "ICLR.cc/2024/Conference/Submission2573/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2573/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698789301329,
        "cdate": 1698789301329,
        "tmdate": 1699902866205,
        "mdate": 1699902866205,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3nuzuvI1D6",
        "forum": "W6xD7K1ajR",
        "replyto": "W6xD7K1ajR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_SeVE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_SeVE"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of efficiently assessing generative models on their precision and recall. Intuitively, precision of a generative model measures the quality of samples produced, and recall measures the coverage or diversity of the samples. Unlike scalar evaluation metrics like inception score and FID, computing precision and recall is much more computationally intensive (quadratic complexity in samples, as opposed to linear) because of the need for measuring pairwise distances between the samples. This paper exploits the \"hubness\" property of high-dimensional datasets to speed up the computation of precision and recall. \n\nTo estimate precision and recall of a model with output distribution $\\hat p$ against a true distribution $p$, we need to estimate how much of $p$  is covered by $\\hat p$ and vice-versa. A popular way to do this (proposed by Kynka\u00a8anniemi et al 2019) is by measuring how many samples of $p$ fall within the support of $\\hat p$ where the support is approximated by a union of hyperspheres centered around samples from $\\hat p$ with radii being the distance to kth nearest neighbors. (There are other ways to estimate precision and recall, for example, Simon et al 2019 use a discriminator to classify samples from both distributions, but this paper focuses on the Kynka\u00a8anniemi et al method.) The hubness phenomenon results in a few samples from both $p$ and $\\hat p$ to be the most popular nearest neighbors to almost all points. This paper exploits this by first using a linear time algorithm to find these \"hubs\" and then use these to compute P&R.\nThrough experiments, the paper demonstrates the savings in compute and storage, as compared to Kynka\u00a8anniemi et al P&R evaluation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper well written, and explains the proposed method clearly.\n- The experiments convincingly demonstrate savings on compute time and storage for real world datasets, across a variety of model architectures.\n- The ablation study and the experiment on robustness against the truncation trick are a nice addition to the experiments section."
            },
            "weaknesses": {
                "value": "- The proposed speedup is specific to one particular way of P&R estimation i.e. using the Kynka\u00a8anniemi et al 2019 method based on nearest neighbors. This method only gives two scalar values corresponding to P and R. In contrast, Simon et al. ICML 2019 method gives the whole PR curve. \n- The proposed method seems to work well when the P&R values are \"reasonably good\" i.e., away from 0 and 1. It is not clear how well the method works in corner cases. It would be good to check this with toy experiments on high dimensional Gaussian mixtures for which P&R take corner values close to 0 and 1 also. \n- Although the experiments are convincing, no theoretical guarantees are provided that bound the approximation error."
            },
            "questions": {
                "value": "- As I stated above, it would be interesting to see how well the proposed approximations hold up on models with relatively poor P&R, not just good models. It would be good to check this with toy experiments on high dimensional Gaussian mixtures for which P&R take corner values close to 0 and 1 also."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2573/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837721952,
        "cdate": 1698837721952,
        "tmdate": 1699636194230,
        "mdate": 1699636194230,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "x61Te1KC7q",
        "forum": "W6xD7K1ajR",
        "replyto": "W6xD7K1ajR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_ctE8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2573/Reviewer_ctE8"
        ],
        "content": {
            "summary": {
                "value": "The paper presents efficient Precision and Recall (eP&R) metrics for evaluating deep generative models trained on large-scale datasets, which provide nearly identical results to the original P&R metrics with less computational costs. The authors propose a hubness-aware sampling method to remove two kinds of calculating redundancy in original P&R metrics. Besides, the efficiency of eP&R is further improved by adopting approximate k-NN methods. Experiments conducted confirm the effectiveness and generalizability of the eP&R metrics."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This work proposes efficient precision and recall (eP&R) metrics for assessing generative models to approximate results as the original P&R metrics with lower consumption in time and space. Specifically, eP&R metrics reduce time complexity from $O(n^2logn)$ to $O(mnlogn)$ and reduce space complexity from $O(n^2)$ to $O(mn)$, where $m$ is less than $n$.\n2. In addition, an approximate k-NN algorithm is employed for the identification of hub samples to further improve the efficiency of eP&R metrics."
            },
            "weaknesses": {
                "value": "1. The authors indicate in Sec. 4.3 that the numbers of hub samples, i.e. $m_r$ and $m_g$ are far less than the number of samples of original sets, i.e. $n$. However, the specific conditions for the validity of this conclusion are not provided. From the experimental results in Table 2, the ratio of $O(m_r)$ or $O(m_g)$ to $O(n)$ is about 0.6, which is not consistent with the statement $m_r \\ll n, m_g \\ll n$.\n2. In Observation 4.1 and Figure 1, the authors roughly divide hubness values into three groups and claim that samples with similar hubness values are effective representative samples in P&R ratio calculation, which lacks generality and specific analysis. Further illustration is needed to explain why the hubness value split points are chosen as 12 and 24, and whether this observation holds in many other datasets. Observation 4.2 and Figure 2 have the same issue.\n3. In Sec. 4.2, the authors point out the insensitivity of hubness-aware sampling to exact k-nearest neighbor (k-NN) results, which might be confusing since in Table 4, the Precision and Recall change greatly when k is taken from 3 to 10. Therefore, specific mathematical descriptions are required to substantiate this viewpoint.\n4. The font size of the annotations in Figure 1 and Figure 2 is too small to identify clearly. Besides, the explanation for (a) in Figure 2 is unclear, which can be directly replaced by 'hubness' and 'non-hubness'."
            },
            "questions": {
                "value": "1. In Sec. 4.3 in the third stage of complexity analysis for eP&R, why calculating pairwise distances for samples between $\\Phi_h^{hub}$ and  $\\Phi_r$ instead of  calculating pairwise distances for samples in $\\Phi_h^{hub}$ ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2573/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2573/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2573/Reviewer_ctE8"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2573/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698845937958,
        "cdate": 1698845937958,
        "tmdate": 1699636194138,
        "mdate": 1699636194138,
        "license": "CC BY 4.0",
        "version": 2
    }
]