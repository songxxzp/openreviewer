[
    {
        "id": "XQaKut0E6D",
        "forum": "NTWtNjlThd",
        "replyto": "NTWtNjlThd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_ZUV4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_ZUV4"
        ],
        "content": {
            "summary": {
                "value": "The authors propose to explicitly disentangle texture and shape information in slot attention by structuring the architecture in a specific way that encourages this. The image is passed through an edge detection filter to remove part of the texture information, which is then used to predict only the per-slot masks. The texture model takes the normal image as input and predicts the usual per-slot images, conditioned on the information from the shape encoder. Multiplying the two results in the usual slot attention reconstruction."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The motivation for the variety of modeling decisions is expressed clearly.\nThe experimental evaluation is thorough with many tests to evaluate specific contributions of the method. I especially like the disentanglement analysis experiments that confirm what type of information is represented by what encoder. It is encouraging to see that this decomposition appears to even improve results, a difference to many disentanglement methods that limit capacity instead."
            },
            "weaknesses": {
                "value": "The main weakness for me is the lack of consideration for the applicability on real world data. All the experiments are performed on tasks where a simple notion of texture and shape is possible. This is especially the case of approaches like DINOSAUR, where a simple Sobel filter will likely not work on the higher-dimensional features. I am therefore worried that the proposed approach is only useful in the toy examples studied, but not in more realistic use cases.\n\nThe approach proposed in the paper only *biases*, not enforces, the two models to focus on shape and texture information separately. In the case of the even just slightly more complex CLEVR dataset, we already see that the disentanglement results are degrading (end of section 5.2)."
            },
            "questions": {
                "value": "- It would be good to see ablation tests on exactly how much of an impact the quality of the edge filter has (for example, how well does it still disentangle if you don't use any edge filter at all?), or an experiment that uses slightly more complex textures (ClevrTex for example). For me, this is the most critical point since it pertains to how well we can expect it to work with realistic data; if it can be addressed I am willing to change my score to an accept.\n- In the generative experiments, what happens when you sample shapes instead of textures?\n- It is not clear to me if basing the approach on the ISA approach instead of base SA is necessary at all, or simply a modeling choice"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773699031,
        "cdate": 1698773699031,
        "tmdate": 1699636977714,
        "mdate": 1699636977714,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uCKNkdrzoB",
        "forum": "NTWtNjlThd",
        "replyto": "NTWtNjlThd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_Vx4x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_Vx4x"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an extension to previous Slot Attention and the subsequent Invariant Slot Attention algorithms for object discovery and representation factorization. Specifically, the proposed formulation incorporates the explicit goal of disentangling shape and texture into separate latent components.  This is achieved through constructing two streams of data, one specifically devoid of texture/color information through the application of a sobel filter. The feature representation from the latter is considered to be shape-only, with the assumption that the representation learned from the remaining stream should encompass everything else (textures and colors)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- It's a bit surprising to see that a weak application of the equivariant constraints still works sufficiently well here.\n- Writing was generally clear, especially with regard to its relation to Slot Attention and Invariant Slot Attention"
            },
            "weaknesses": {
                "value": "- Works such as Lorenz et al. seem more closely related to this work than stated in the related works section. Specifically, the task of unsupervised landmark detection is nearly identical to the object-centric learning framework. Furthermore, both works are based on the same two-stream information bottleneck setup where you apply some sort of transformation to ensure either shape or texture information is only available in one stream but not the other. I think it would be necessary for the authors to elaborate further in the paper on the relation to works in that section of the writing.\n- I think one of the strengths of the prior work ISA was the incorporation of more realistic settings such as Objects Room, CleverTex, and WaymoOpen. However, the results in this work seem limited to simpler synthetic datasets with only very smooth almost mono-color textures. I think it would be necessary to demonstrate improved results on at least some of those harder datasets to convincingly show that the solution proposed here is a step in the direction of real-world applicability."
            },
            "questions": {
                "value": "- Are there known limitations to using the sobel filter? How does the sobel filter setup perform on high frequency texture patterns?\n- Can the authors also clarify the exact formulation for the variance regularization loss? Is the variance computed across dimensions like layernorm? or more like batch norm and across batch elements?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801597141,
        "cdate": 1698801597141,
        "tmdate": 1699636977602,
        "mdate": 1699636977602,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nlyz4h5JTX",
        "forum": "NTWtNjlThd",
        "replyto": "NTWtNjlThd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_Acn7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_Acn7"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to explicitly disentangle shape and texture of objects, while training using an unsupervised autoencoding loss. The paper shows that this disentanglement can achieve competitive performance at object discovery while achieving significantly higher performance on image reconstruction. Further the paper shows that their representations are indeed disentangled by doing a property prediction task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- the motivation of disentangling shape and texture seems promising\n- the paper proposes a  unique approach for disentangling texture from shape using Sobel Filter.\n- the paper has good and dense comparisions in its experiment section\n- the paper does a good job at presentation and figures."
            },
            "weaknesses": {
                "value": "- the paper motivates the intro with better representation, generalization and downstream transfer by having an explicit disentangled representation, however doesn't compare with ISA or SA with that metric. \n- The paper relies on sobel filter to achieve this disentaglement but doesn't do a good job at explaining how exactly does the Sobel filter work and is able to remove the texture. Is sobel filter limited to CLEVR images for removing filter or can scale to COCO like images?\n-  The paper says: \"However, to the best of our knowledge, no research has been carried out on the explicit disentanglement of the texture and shape dimensions in object-centric learning,\", i don't think this is true as there is work such as: D3DP (https://arxiv.org/abs/2011.03367), that do disentangle shape and texture explicitly in an object-centric manner. They use adaptive instance norm instead of using Sobel filter."
            },
            "questions": {
                "value": "- How does the paper compare against ISA or SA in terms of Figure 2 or other downstream tasks such as the one considered in this paper https://arxiv.org/pdf/2305.11281.pdf?\n- What is the intuitive idea + the math behind sobel filter? Would such Sobel Filter generalize to real world texture like the one seen in COCO?\n-  I think this authors should discuss D3DP in their paper.  Also compare against AdIN, as a way of disentangling shape and texture instead of using  Sobel Filters.\n\nI'm happy to change my reviewer if the authors address my concern."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823661146,
        "cdate": 1698823661146,
        "tmdate": 1699636977473,
        "mdate": 1699636977473,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YFAc9EnRDL",
        "forum": "NTWtNjlThd",
        "replyto": "NTWtNjlThd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_7UTn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7955/Reviewer_7UTn"
        ],
        "content": {
            "summary": {
                "value": "The authors develop a network architecture to explicit extract shape and texture information from images, thus extending an approach to extract position, orientation and scale. The architecture is specific to the problem at hand, removing texture information to help extract shape and using shape-derived masks to extract texture information. The benefit of the disentangled representation is demonstrated in both scene understand tasks and image reconstruction tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Great results on image reconstruction tasks, good results on scene understanding tasks, good results on qualitative measures.\n * Improved latent representations are amendable for better interpretation."
            },
            "weaknesses": {
                "value": "* The architecture is explicitly designed for shape and texture and cannot be extended to other latent dimensions, thus limiting the significance of the results. This represents a significant effort which is ad-hoc and hence should be saved only to crucial latent dimension; not sure texture is such.\n * Texture decoding uses shape information, which reduces the applicability of the method outside the context of the current projectt.\n * Shape decoding uses texture removing filter, which may by itself be responsible for some of the benefits of the approach."
            },
            "questions": {
                "value": "* Why was rotation invariance removed from the experiments?\n * Is the new shape and texture dimensions disentangled from position and scale information? To what extent were position and scale varied in the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835753671,
        "cdate": 1698835753671,
        "tmdate": 1699636977364,
        "mdate": 1699636977364,
        "license": "CC BY 4.0",
        "version": 2
    }
]