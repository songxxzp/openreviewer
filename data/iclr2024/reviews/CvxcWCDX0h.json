[
    {
        "id": "wIjzuJCqxi",
        "forum": "CvxcWCDX0h",
        "replyto": "CvxcWCDX0h",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_LvQG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_LvQG"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to solve the noise pair phenomenon that exists in multi-modal contrastive learning, so as to avoid these noise samples from affecting the training of the model.The paper proposes a re-weighting method to set different weights for different samples, and designs a weight acquisition scheme. Some experiments were conducted to verify the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is simple and easy to understand\n2. The proposed method is reasonable"
            },
            "weaknesses": {
                "value": "The paper misses some important references, such as DataComp: In search of the next generation of multimodal datasets, which proposes many baseline methods to solve noisy samples in multimodal contrastive learning. For example, the simplest solution is to use CLIP after training to filter the training samples. Due to the lack of discussion and comparison of these key and closely related methods, I believe that this paper cannot be accepted.\nAt the same time, the most important thing is that, in my opinion, the method proposed in the paper lacks novelty. The basic idea of the proposed scheme is common in solving learning with noisy samples."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2836/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2836/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2836/Reviewer_LvQG"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697894357871,
        "cdate": 1697894357871,
        "tmdate": 1699636227248,
        "mdate": 1699636227248,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nJif2Xkx3E",
        "forum": "CvxcWCDX0h",
        "replyto": "CvxcWCDX0h",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_UYnq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_UYnq"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the noisy text challenge in the image text contrastive learning problem. The authors provide an intuitive idea by learning a weight of each data pair. However, this leads to an impractical solution because of the massive amount of newly introduced variables. To remedy it, the authors follow DeCL work by reformulating it into a probability framework that can be effectively optimized via stochastic expectation maximization. The results of the designed experimental setting show improvement on the standard benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper presents an intuitive idea of assigning different weights according to the noisiness of data pairs. The methodology part is mostly easy to follow with a clear motivation. Despite some concerns and questions on the experimental setting, the reported results show an improvement over the baseline CLIP and DeCL."
            },
            "weaknesses": {
                "value": "1. I recognize the new part of solving the noisy text problem by formulating it into a probabilistic framework and optimized with a similar solution proposed by DeCL (Chen et al., 2022). While this still inevitably greatly limits the contribution of this work. The technical novel part is marginal. \n\n2. Missing related works. There are several important works in vision language learning domain that are missing, including but not limited to  \n\n\t[BLIP] BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation, icml 2022 \n\n\t[ALIGN] Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision, icml 2021 \n\n3. In the experiment, I was not quite sure why the reported CLIP results (e.g. table 1 and 2) are far lower than the numbers reported in the original CLIP or following papers. For instance, top1 accuracy of zero-shot classification on imagenet-1k, the reported CLIP is 17.71. However, its number is 76.2 reported in ALIGN (see table 4 in ALIGN). The authors mentioned the batch size difference. This huge gap makes the experiment less convincing.  \n\n   Another noticeable difference, is the added 10% random noise. I was not sure how much this part affected the final results. However it leads to another missing parameter analysis on the different added noisy levels from 0%.  \n\n4. This paper only covers one backbone, I.e. RN-50. I would like to see other backbones such as ViT variants. \n\n5. Typo. Page 8, table 3 caption, \u201ccccuracy\u201d. \n\n   Page 8, it seems only 13 datasets are evaluated, not 14."
            },
            "questions": {
                "value": "What does the index \u201cj\u201d mean in Eq 1 and the last equation in page 3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698296054758,
        "cdate": 1698296054758,
        "tmdate": 1699636227171,
        "mdate": 1699636227171,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NDuUgIipas",
        "forum": "CvxcWCDX0h",
        "replyto": "CvxcWCDX0h",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_6kBB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_6kBB"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a comprehensive exploration of noise-robust contrastive learning and introduces an innovative approach for addressing noisy data pairs. The authors propose the incorporation of learnable stochastic weights, informed by a Bayesian inference framework, to dynamically adjust the significance of each data pair. To facilitate the learning of these weights, the paper reformulates the problem within a probabilistic framework and devises a stochastic expectation maximization algorithm.The paper evaluates the method on several multi-modal contrastive learning benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper introduce a new method to combat with noisy data pairs through learnable stochastic weight from the Bayesian inference framework.\n\nExtensive experiments have been conducted to verify the effectivenss of the proposed method."
            },
            "weaknesses": {
                "value": "1. One primary concern revolves around the claimed novelty of the research problem. While the authors assert that they are the first to address the issue of contrastive learning with noisy data pairs, existing studies have already explored similar territories. For instance, RINCE (CVPR 2022) focuses on mitigating the impact of noisy views (false positives) and presents a theoretically-grounded robust infoNCE loss function. More recent studies in noisy correspondence learning tackle issues like mismatched pairs and false negatives in diverse tasks, including partially view-aligned clustering, video-text retrieval, visible-infrared person re-identification, and image-text matching. Furthermore, [1] formally investigates noisy many-to-many correspondences and introduces an innovative training framework that outperforms its CLIP counterpart in multiple settings.I believe it is crucial to provide a more in-depth clarification of the distinctions between this paper and previous works. Additionally, it would be valuable to expand the related works section to offer a deeper understanding of these differences.\n   [1] Robust Cross-Modal Representation Learning with Progressive Self-Distillation, CVPR 2022\n\n2. The paper lacks sufficient detail and background information. Notably, explanations and prerequisites related to concepts such as the gamma distribution/prior and Bayesian inference are notably absent. Furthermore, some equations are inadequately elucidated and appear to be missing essential derivations.\n3. The paper's comparative analysis is limited to CLIP and DeCL, neglecting other crucial baselines, like [1], which specifically address the same issue of noisy data pairs.\n4. It is recommended to supplement the paper with additional experimental analyses that illuminate the inner workings of the proposed method. For instance, incorporating visualizations of the learned weights for positive and negative pairs, akin to Fig. 5 in [1], would enhance the reader's understanding of the method's underlying mechanisms."
            },
            "questions": {
                "value": "Please see the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751791742,
        "cdate": 1698751791742,
        "tmdate": 1699636227097,
        "mdate": 1699636227097,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jzwGtifte3",
        "forum": "CvxcWCDX0h",
        "replyto": "CvxcWCDX0h",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_g84h"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2836/Reviewer_g84h"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the issue of noisy pairs in vision-language pre-training by proposing a weighted contrastive loss that estimates the noisiness of data pairs using Bayesian techniques. The proposed method is evaluated on the CLIP model and demonstrates reasonable improvements compared to vanilla CLIP."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem of addressing noisy pairs in vision-language pre-training has practical implications and is valuable.\n2. The proposed method takes into account both the false positive and false negative problems in contrastive learning."
            },
            "weaknesses": {
                "value": "1. There is a concern regarding the originality of the problem studied in this paper. The claim of being the first to consider the noise problem in contrastive learning is incorrect, as several prior works have already addressed this issue.: Robust Cross-Modal Representation Learning with Progressive Self-Distillation, Ranking info noise contrastive estimation: Boosting contrastive learning via ranked positives, Cross-Modal Retrieval with Partially Mismatched Pairs and Debiased Contrastive Learning, to name a few.\n\n2. Given the focus on noisy pairs, the related works section should provide a comprehensive discussion covering noisy labels, noisy correspondence, and robust vision-language pre-training. Moreover, the approach of incorporating soft weights into contrastive learning is not novel in either the noisy label or vision-language learning community.\n\n3. The proposed method does not show notable improvements compared to vanilla CLIP, particularly according to Table 2.\n\n4. The estimation of the confidence of noisy pairs through the joint posterior distribution over the global model parameter and local random weight (Eq. 2) is still unclear. It lacks sufficient details and intuitive explanation, making it difficult to understand how the confidence of noisy pairs is estimated."
            },
            "questions": {
                "value": "In the implementation details, the authors manually simulate around 10% noisy pairs. The rationale behind this choice is unclear. It would be more informative to evaluate the method on naturally occurring partially-matched pairs, such as the 3% to 22% range found in CC. Additionally, exploring performance on even noisier datasets with 30% or 50% noisy pairs would provide a more challenging scenario for evaluation if the simulate noisy pair is needed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806417168,
        "cdate": 1698806417168,
        "tmdate": 1699636227025,
        "mdate": 1699636227025,
        "license": "CC BY 4.0",
        "version": 2
    }
]