[
    {
        "id": "58wLTdimwQ",
        "forum": "AcRfzLS6se",
        "replyto": "AcRfzLS6se",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a white-box OOD detection method: BLOOD, by using the fact that the tendency of between-layer representation transformations of ID data is smoother than the corresponding transformations of OOD data for Transformer network.\n\n-Hypothesis: During the model\u2019s training, smooth transformations between DNN layers are learned, which corresponds to natural and meaningful progressions between abstractions for ID data. And these progressions will not match OOD data, so the transformations will not be smooth.\n\n-The smoothness is defined as the difference of the mapping between the current representation its infinitesimally close neighbourhood's representation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Looking at the smoothness of the layer is novel and hasn't been explored in prior research for OOD detection.\n\n2. An unbiased estimator for the smoothness is proposed to reduce the computation.\n\n3. BLOOD demonstrates superior performance over various OOD detection methods for RoBERTa and ELECTRA in text classification datasets."
            },
            "weaknesses": {
                "value": "1. The experiments exclusively focus on Transformer-based models and text classification. I am curious about the performance of BLOOD when applied to image classification datasets and Convolutional Neural Networks (CNNs). Additionally, the study lacks a comparison with the latest state-of-the-art methods for out-of-distribution (OOD) detection in CNNs, such as ASH (Extremely Simple Activation Shaping for Out-of-Distribution Detection, ICLR23), ReAct (ReAct: Out-of-distribution Detection With Rectified Activations, NeurIPS21), and DICE (DICE: Leveraging Sparsification for Out-of-Distribution Detection, ECCV2022). Furthermore, there is no analysis provided to explain why the concept of BLOOD is restricted to text classification and not applicable to other domains.\n\n2. While Figure 1 qualitatively illustrates the smoothness difference, the author did not offer an explanation for the observed difference between in-distribution (ID) and out-of-distribution (OOD) data. I wonder whether there is an analysis or understanding of this phenomenon, specifically why the learned progressions on ID data do not align with OOD data and how to define this misalignment."
            },
            "questions": {
                "value": "Please see the weaknesses section, I am willing to raise my rating if the author can addresses those issues."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL",
                    "ICLR.cc/2024/Conference/Submission3628/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698659261701,
        "cdate": 1698659261701,
        "tmdate": 1700708060321,
        "mdate": 1700708060321,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5dMEXlwkPP",
        "forum": "AcRfzLS6se",
        "replyto": "AcRfzLS6se",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_woCv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_woCv"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new OOD detection method called BLOOD, designed for a white-box setting where only pre-trained weights and model architectures are accessible, but without access to training data. It leverages the smoothness of between-layer representation transformations in ID data compared to OOD data. The method is evaluated using datasets for text classification tasks, demonstrating its superior performance over other methods with comparable resource requirements."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors propose a novel and effective scoring method for OOD detection based on the smoothness between Transformer layers that is applicable to pretrained models without access to training data. They provide a detailed performance analysis, including both strengths and limitations. The paper also presents an interesting finding regarding the relationship between smoothness and the complexity of the training dataset. The paper is well-organized and clearly written overall."
            },
            "weaknesses": {
                "value": "The proposed method does not perform competitively on simpler datasets, such as those with fewer classes in ID, or semantic shift as OODs. This inconsistency in performance across different datasets and settings suggests that relying solely on the smoothness of the representation may not be fully optimal for general OOD detection tasks. \n\nIn Table 2, the calculated effect size is greater in the \u201cMean\u201d approach than in the \u201cLast\u201d approach, which appears to contradict the results in Table 1."
            },
            "questions": {
                "value": "- In Section 4.3, there are certain inconsistencies in the presented results (e.g., RoBERTa model on the MG and NG datasets), which seem to challenge the hypotheses by the authors. Given the variations in performance, can you provide additional evidence or discussion, such as whether certain architectures or settings are preferred by the proposed method? \n- I\u2019m curious if BLOOD can be extended to open-box settings. \n- Is it possible to apply BLOOD to OOD detection tasks in computer vision? Any insights or preliminary findings on this would be valuable. \n- Could you provide more detailed explanation of how the CLES measurements in Tables 2 and 3 were computed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698660406422,
        "cdate": 1698660406422,
        "tmdate": 1699636318231,
        "mdate": 1699636318231,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1ZQMYzbZQd",
        "forum": "AcRfzLS6se",
        "replyto": "AcRfzLS6se",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_Bnog"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_Bnog"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an out of distribution detection method called BLOOD which measures the transformation smoothness between layers by using the frobenius norm on the jacobian matrix. The proposed approach is then evaluated across several text classification dataset for OOD detection task."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method is simple and can be easily applied on different tasks and network architectures, where OOD detection is required.\n- The paper is easy to read and overall the paper is well written.\n- The proposed method has been shown to perform well across different text classification datasets in comparison to standard OOD methods."
            },
            "weaknesses": {
                "value": "- The experimental results are not very strong or convincing. I would have expected some experiments on vision datasets as there has been a significant amount of OOD detection work focussing on vision datasets. Also, this approach can be easily applied on those tasks and will give better understanding how well this approach works.\n- Most of the baselines considered in the comparisons are very old for OOD detection. There has been a significant amount of work focusing on last layer contributions to OOD detection similar to this paper (for eg. [a,b]). The authors should show comparisons against SOTA OOD baselines.\n\n\n\nReferences:\n- [a] Sun et. al. React: Out-of-distribution detection with rectified activations. Neurips, 2021.\n- [b] Djurisic et al. Extremely simple activation shaping for out-of-distribution detection. arXiv preprint arXiv:2209.09858, 2022"
            },
            "questions": {
                "value": "Please address the weakness mentioned above.\n\nWhy does BLOOD_mean performance significantly worse than the baselines in most of the cases? Whereas in some case it performs better than BLOOD_{L-1}. Can the authors explain that?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722875749,
        "cdate": 1698722875749,
        "tmdate": 1699636318148,
        "mdate": 1699636318148,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xgTDo14e2j",
        "forum": "AcRfzLS6se",
        "replyto": "AcRfzLS6se",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_Txyj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3628/Reviewer_Txyj"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles OOD detection problems by analyzing the smoothness of the feature transformation between intermediate layers in a network in a pre-trained network. The idea behind the notion of smoothness in this paper extends from Liptischitz continuity. The method is evaluated on popular pre-trained models such as RoBERTa and ELECTRA on multiple texts analysing data sets such as SST, SUBJ, AGN etc. The results are compared with competitive baselines, which demonstrates its effectiveness in most of the cases."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "OOD detection is an important research problem that plays a significant role in developing trustworthy AI. Hence, the paper addresses the problem which can be of interest to a larger audience. \n\nThe method itself relies on the transformation features between the layers, which are estimated from the pre-trained models. Hence, this method does not require labelled examples from downstream tasks which is another strength of this method."
            },
            "weaknesses": {
                "value": "In the paper, it is mentioned that the method is robust to complex tasks and less competitive for easy tasks. However, the explanations are just based on empirical performance, lacking clear insight and understanding behind such outcomes.  \n\nThis is a similar line of work on OOD detection employing variance of gradients [a], which play a direct role in the smoothness feature transformation in the intermediate roles. \nIt is better this paper acknowledges such works and argues how such methods differ from their proposed method. \n\n[a] Agarwal, Chirag, Daniel D'souza, and Sara Hooker. \"Estimating example difficulty using variance of gradients.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "Please see the weakness.\n\nI wonder how this method would work in vision tasks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698866562530,
        "cdate": 1698866562530,
        "tmdate": 1699636318080,
        "mdate": 1699636318080,
        "license": "CC BY 4.0",
        "version": 2
    }
]