[
    {
        "id": "xIoLIT11n5",
        "forum": "f8S3aLm0Vp",
        "replyto": "f8S3aLm0Vp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_KT7c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_KT7c"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on protecting the training data and detecting unauthorized training data usages in the text-to-image diffusion models. In detail, this paper first defines two types of element-level injected memorizations on the text-to-image diffusion models. Based on the definition of the injected memorizations and their memorization strength, this paper introduces an approach for detecting unauthorized training data usages in the text-to-image diffusion models. In detail, the proposed method modifies the protected dataset by adding designed unique and invisible contents (signal contents) on these images, so that the model will learn the memorizations on the signal contents if it has unauthorized training or fine-tuning on the protected training data. Experiments on four datasets and recent diffusion models (Stable Diffusion and VQ Diffusion) indicate the performance of the proposed method is good."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. [Novelty & Motivation] This paper links the unauthorized\ntraining data usages problem to the memorization of the\ntext-to-image diffusion models, which is an novel and\ninteresting direction. The design of the proposed method is\nreasonable. The motivation of this paper is clear. Detecting\nunauthorized training data usages in the diffusion models is\nan important and urgent problem, but it have not been\nwell-studied by existing works.\n\n2. [Studied Models] The experiments are conducted on the\nstate-of-the-art text-to-images diffusion models in the\nreal-world (Stable Diffusions) and advanced model\ntraining/personalization techeniques (LoRA and Dreambooth).\n\n3. [Practicality] The proposed method only requires the\nblack-box access to the examined models, which makes it\npractical in real-world usages.\n\n4. [Performance] The detection performance of the\nproposed method is high, it achieves 100% detection accuracy\namong various settings with nearly unnoticable perturbations\non the training/generated samples. The comparisons to\nexisting methods or potential other methods are\nwell-discussed in the introduction and the evaluation.\n\n5. [Writting] Overall, the presentation is good, and the\nwriting is easy-to-follow."
            },
            "weaknesses": {
                "value": "1. [Texutal Inversion] Is it possible to detect the\nunauthorized data usages with Textual Inversion [1] (a\npersonalization technique the for text-to-image diffusion\nmodels)? \n\n2. [Efficiency] I did not find the discussion about the time\ncost of the proposed method. Helping the potential users\nknow the approximated time cost is benificial.\n\n3. [Summary Table for Symbols] A table summarizing the\nmeaning of all symbols used in this paper can be added to\nmake this paper more clear.\n\n[1] \"An Image is Worth One Word: Personalizing Text-to-Image\nGeneration using Textual Inversion\"."
            },
            "questions": {
                "value": "Please see \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2187/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698666164339,
        "cdate": 1698666164339,
        "tmdate": 1699636152482,
        "mdate": 1699636152482,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lrqdLJZ1pX",
        "forum": "f8S3aLm0Vp",
        "replyto": "f8S3aLm0Vp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_P3dG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_P3dG"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new scheme to detect the unauthorized data usages in text-to-image diffusion models, where the images are imperceptibly warped for protection. The warped images are able be memorized by diffusion models during the training, which offers the possibility to detect the existence of the usages of such data from the trained diffusion model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It is an interesting approach by exploring the properties of the diffusion models, i.e., memorizing duplicated contents in the training data, for the detection of unauthorized data usages.\n\n2. This paper is well written and easy to follow.\n\n3. Good robustness over different diffusion models."
            },
            "weaknesses": {
                "value": "1. The authors mention that, compared with the sota schemes which focus on the sample-level memorization, this paper focuses on the element-level memorization. I think it does not matter whethat it is sample-level or element-level, the most important is which one offers higher performance. The authors do not logically or experimentally justify the advantage of element-level memorization over the sample-level ones.\n\n2. The motivation of introducing two types of injected memorization is not well explained. The reviewer is confused with the necessarity of the trigger function. \n\n3. Insufficient Evaluation. Only less than 20 models are constructed during the evaluations, which is far from enough to demonstrate the effectiveness of the approach. It lacks of evaluation regarding the distortion of the image after the warping. It also lacks the discussion on the potential countermeasures against the proposed approach."
            },
            "questions": {
                "value": "1. What is the value of the coating rate used in section 4.2? If only a small portion of the data is protected, it is quite strange that selecting only a portion from the whole dataset to train the model would still be accurately detected with 100% accuracy. If the selection does not overlap with the protected portion, the detection mechenism should not work, right?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2187/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2187/Reviewer_P3dG",
                    "ICLR.cc/2024/Conference/Submission2187/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2187/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767193906,
        "cdate": 1698767193906,
        "tmdate": 1700728416997,
        "mdate": 1700728416997,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gLk3JZ69GF",
        "forum": "f8S3aLm0Vp",
        "replyto": "f8S3aLm0Vp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_gKsK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_gKsK"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses concerns related to unauthorized data usage in the training or fine-tuning process of text-to-image diffusion models. The authors highlight the potential misuse of data, where a model trainer might utilize images without proper permission or credit. To tackle this issue, the paper proposes a method that detects unauthorized data usage by implanting injected memorization into protected datasets during model training. This involves stealthy image-warping functions that remain imperceptible to humans but can be captured and memorized by diffusion models. By analyzing the presence of the injected content, the proposed method can effectively identify models that have illegally employed unauthorized data. The experiments conducted on various text-to-image diffusion models, including Stable Diffusion and VQ Diffusion, using different training or fine-tuning methods, demonstrate the efficacy of the proposed detection approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper addresses the issue of unauthorized data usage within text-to-image diffusion models, a critical and pressing concern within the artistic field. It presents a potential solution to safeguard the copyrights of artistic creators.\n2) The solution is sound and solid, which is quite easy to follow. The authors borrow some ideas from image warping and injected memorization into the task."
            },
            "weaknesses": {
                "value": "1) Some typos and grammar errors exist, e.g., pp. 7, \"we assume the subsets provide by different data sources...\" should be \"we assume the subsets provided by different data sources\".\n2) In the experimental results section, the authors shall provide more quantitative results (in terms of, e.g., PSNR, SSIM or the residual) for comparing the original sample image and its coated counterpart."
            },
            "questions": {
                "value": "1) Why use image-warping operation to implement the coating? Is it possible to employ some other operators?\n2) Does the image warping is reversible? It seems that the coated images are permanently damaged by the warping."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2187/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699439852894,
        "cdate": 1699439852894,
        "tmdate": 1699636152310,
        "mdate": 1699636152310,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ml0vtQZ7Np",
        "forum": "f8S3aLm0Vp",
        "replyto": "f8S3aLm0Vp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_vEW1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2187/Reviewer_vEW1"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a method to detect unauthorized data usage during the training or fine-tuning process in text-to-image diffusion models. This unauthorized data includes cases where a model can collect images of an artist without permission or generate similar images without giving credit to the artist. The paper addresses this issue by modifying the protected data by planting an injected memorization in the training of the diffusion model. This is done by adding unique contents on the protected image data using stealthy image warping functions that are not perceptible to humans but captured and memorized by diffusion models. The model is then analyzed whether it has the injected content and unauthorized data is detected this way. Experiments are presented on many state-of-the-art diffusion models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is written well and the problem that the paper is trying to address is clearly illustrated. Some visual examples are also provided. Results are also shown on many recent text-to-image diffusion models."
            },
            "weaknesses": {
                "value": "Lots of experiments are presented. It will be good to have a robustness analysis also with these experiments. How robust is the proposed method to different image transformations like compression, blurring, smoothening, sharpening and more. Will this affect the detection performance?\n\nIt will be good if the authors can discuss adversarial ways in which the proposed technique can be defeated."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2187/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699472988756,
        "cdate": 1699472988756,
        "tmdate": 1699636152228,
        "mdate": 1699636152228,
        "license": "CC BY 4.0",
        "version": 2
    }
]