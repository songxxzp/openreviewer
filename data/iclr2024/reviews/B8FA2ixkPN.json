[
    {
        "id": "LlopjHaU41",
        "forum": "B8FA2ixkPN",
        "replyto": "B8FA2ixkPN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_Vfdc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_Vfdc"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces GML-NeRF, a new multi-NeRF approach designed to enhance the model's capacity for effectively representing complex scenes. GML-NeRF utilizes a hybrid NeRF architecture that combines a shared 3D dense grid parametrization, known as Instant-NGP, with multiple independent MLP decoders. \n\nThe proposed approach enables the prediction of color and density values associated with each camera ray by employing a weighted sum of independent MLP predictions, essentially creating a 'mixture of experts.' The weights for this summation are determined by a separate MLP with a Softmax output layer, called soft gating module. The author's findings indicate that GML-NeRF outperforms other multi-NeRF methods, delivering higher rendering quality for large-scale scenes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The ray-based multi-NeRF approach distributes training rays across various NeRF models, offering greater flexibility compared to point-based multi-NeRF techniques. The GML-NeRF approach proposed in this study demonstrates enhanced effectiveness through the increase in the number of MLPs rather than merely widening the capacity of a single MLP. This method is particularly versatile and applicable to a wide range of scenes, regardless of whether they lack prior, scene-specific knowledge."
            },
            "weaknesses": {
                "value": "The paper exhibits several notable weaknesses. First, the soft gate module's mechanism is not comprehensively explored. It remains unclear whether the estimated scores are primarily based on scene geometry or if they serve mainly for the minimization of balancing the regularization term within the loss function.\n\nAdditionally, there appears to be a discrepancy between the motivating concept presented in Figure 1 (b) and the ray allocations depicted in Figure 4 (left), where rays are equally distributed between two NeRFs (i.e., MLPs). This contradiction raises questions about the method's consistency and its alignment with the initially proposed approach.\n\nLastly, the results obtained do not demonstrate a significant improvement when compared to other existing methods. This raises concerns about the overall effectiveness of the proposed technique."
            },
            "questions": {
                "value": "The balancing regularization aims to enforce equal weighting between MLPs. However, it seems that the assignment should ideally be based on scene geometry. This raises a concern, as your visualization in Figure 4 (left) appears counterintuitive, showing equal weights between two MLPs for the body of the truck. Can you provide clarification on this matter?\n\nRegarding the ablation study on uniform fusion, it's not entirely clear whether you trained the model with the gating module and then computed the average between MLPs during testing, or if you trained the model without the gating module from the beginning. Can you please clarify on this process for a better understanding of your methodology?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Reviewer_Vfdc"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698781705798,
        "cdate": 1698781705798,
        "tmdate": 1699636551678,
        "mdate": 1699636551678,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7mAiq0OHd7",
        "forum": "B8FA2ixkPN",
        "replyto": "B8FA2ixkPN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_3Q2w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_3Q2w"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to ensemble sub-NeRFs on complex scenes by a trainable ray-based gate. The gate module learns the preference of sub-NeRF for each ray. The results of different sub-NeRFs are fused with the gating score. A depth-based mutual learning method is proposed to enhance the rendering consistency among multiple sub-NeRFs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The motivation of learning ray-based allocation for different sub-NeRFs is interesting.\n2. It designs a multiple NeRF network based on Instant-NGP to validate the learning-based ray allocation.\n3. A depth mutual learning loss is proposed to align the depth of different sub-NeRFs to avoid overfitting.\n4. It adapts several multi-NeRF methods to validate its core designs."
            },
            "weaknesses": {
                "value": "I have several concerns about the network design and results.\n\n1. One of the motivations of this paper is that complex scenes need more network parameters and the parameters need to be allocated in the ray dimension. In the network design, the hash table is shared. The sub-NeRFs only contain 2 small decoders. Since in Instant-NGP, the decoder only contains very few parameters than the hash table (no more than 1%), it is unclear to me why the proposed method gets very good quality improvement with a minor increase of parameters.\n2. The Block-NeRF uses a fixed and image-level ray allocation. As stated in paper A.3, the training of sub-NeRFs in Block-NGP is independent. So I assume the hash tables are not shared in Block-NGP. Therefore, Block-NGP will have 2 large hash tables. It is unclear to me why it only gets a very small improvement than Instant-NGP (20.783 vs 20.722 on TAT, 26.015 vs 25.951). Therefore, I think the detailed training of Block-NGP should be provided. In the paper of Block-NeRF, it also exploits the interpolation of results of sub-NeRFs in the inference. This paper should also provide details of the inference of Block-NGP.\n3. For Table 4 of Importance of pixel-granularity fusion, it is unclear how the Image-level fusion is performed.\n4. For Table 3 of Importance of the ray-level allocation, when using \"fusing multi-NeRFs\u2019 outputs in the point dimension\", it is unclear how the point outputs are fused. What kind of gate is used for point fusion? Is it a point-based or ray-based gate?\n5. Since this method learns pixel-level ray allocation, this method needs to directly compare the fixed pixel-level ray allocation methods. The Mega-NeRF actually allocates rays across different sub-NeRFs although the ray-allocation is determined by 3D points. The sub-NeRFs in the Mega-NeRF are trained independently and the results are interpolated by 3D distance. The hash tables may not be shared in Mega-NeRF. However, it can still be compared by setting the proposed method as not sharing hash tables. Since the image-level Block-NeRF is compared, I think the pixel-level Mega-NeRF is also worth comparison.\n6. In Table 2, what is the accuracy if we train Uniform fusion with depth mutual loss?\n7. The results of other datasets without depth mutual loss are needed to better analyze the effects of gate and depth mutual loss.\n8. What is the result if Switch-NGP uses all the sub-NeRF outputs weighted by gating scores? This can actually be seen as a learnable point-based allocation method aligning with the training setting of the proposed method."
            },
            "questions": {
                "value": "My questions are in the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809568280,
        "cdate": 1698809568280,
        "tmdate": 1699636551584,
        "mdate": 1699636551584,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zgv6iY1VOY",
        "forum": "B8FA2ixkPN",
        "replyto": "B8FA2ixkPN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_PcY6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_PcY6"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed two techniques to improve NeRF's modeling capability of complex scenes.\nThe paper jointly trains K NeRFs along with a learnable weighting scheme to combine the K NeRF's outputs into one.\nThe paper also proposes to use one NeRF's depth rendering to supervise another NeRF's depth output.\nExperiments show that the proposed method outperforms many efficient NeRF baselines including DVGO, Instant-NGP.\nHowever, the proposed method performs slightly worse than MipNeRF360.\nThe author argues that MipNeRF360 trains slowly, and also compares against MipNeRF360 trained only for one hour (which is about the same time needed by author's model to train). In this case, the proposed method works better."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The overall idea seems valid.\nThe paper is relatively easy to follow."
            },
            "weaknesses": {
                "value": "1. By the time of submission, I believe ZipNeRF paper was already out there and there was an open-source implementation of it. Gaussian Splatting was also available. Probably the author should compare against these two approaches too. For the following reasons: (a) ZipNeRF is built on Instant-NGP and is able to handle varying resolution training images which is more suitable than Instant-NGP to model relatively large (and unbounded) scenes; (b) Gaussian Splatting, by design, is able to handle the occlusion issue (mentioned by the author as a challenge in modeling complex scenes) as it's an explicit representation.\n\n2. I'm a bit skeptical about the claim in experiments that since MipNeRF360 is too slow, you compare against MipNeRF360 trained for one hour. Is the main claim of the paper about efficiency? I mean, you can use always bump up the number of GPUs in training to reduce the training time if that's a problem.\n\n3. It seems, by the end of the day, the author only uses two NeRFs (K=2) in their framework, though in the abstract the author claimed that they construct \"an ensemble of sub-NeRFs\". Does the method only work with K=2? If it works in more general settings with K > 2, the author should demonstrate that. Does having more sub-NeRFs help improve the rendering quality?\n\n4. In Figure 5, the blue curve scales the width of a NeRF. Which NeRF's width is scaled? Is it any of the baseline NeRFs shown in Table 1? And on what dataset the experiment is conducted? Is the PSNR performance averaged across one scene, multiple scenes?\n\n5. Also in Figure 5, I think it makes more sense to compare against the following: You scale the resolution of the feature grid used in Instant-NGP, and show how the performance of Instant-NGP scales. Since I think the key to model large scale scenes well is to leverage locality, and in Instant-NGP, you need to bump up the feature grid's resolution to better leverage locality."
            },
            "questions": {
                "value": "Figure 5. is a bit confusing. Why \"GML-NeRF with two independent sub-NeRFs\" does not overlap with the \"2x NeRFs\"?\nI guess these are two different approaches? But I'm really confused here. The author could do a better job to clarify this.\n\nEq. (3), G(r)'s output is a K-dimensional vector? Do the elements of the K-vector sum to one or not? I guess not, as there is no such constraint imposed through losses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5430/Reviewer_PcY6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699058701386,
        "cdate": 1699058701386,
        "tmdate": 1699636551496,
        "mdate": 1699636551496,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7yF6qbadim",
        "forum": "B8FA2ixkPN",
        "replyto": "B8FA2ixkPN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_MyQ8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5430/Reviewer_MyQ8"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new learnable multi-NeRF framework for neural rendering, adopting partitioning and using different models to capture a scene.  The method aims to address the point visibility problem in Switch-NeRF by assigning confidence score with respect to rays rather than 3D points. The work is also different from other ray/pixel-based approaches in which allocation rule is manually-defined. A depth loss regularization is used to guide the training of subnets besides the default color supervision. Experiments on multiple datasets shows that the proposed method can achieve competitive rendering results quantitatively and qualitatively."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Using scene partitioning and learning with multiple subnetworks is a promising direction for improving the scalability and performance of scene rendering tasks. The authors propose a simple and effective learnable framework and have shown promising experimental results.\n\n2. The paper is well-organized and easy to follow. The authors also present sufficient discussion for comparing with related work.\n\n3.  Experiments on multiple-datasets and the comparison with modern SOTA methods are provided to verify the method and the modules inside."
            },
            "weaknesses": {
                "value": "1. I have some concerns regarding the validity of the depth regularization. The fused depth is estimated by weighting depths from different subnets (which is named as sub-depth for simplification). In this regard, the sub-depth with higher weighting score is supposed to be closer to the target depth, thus the difference between them should be smaller, and the one between the sub-depth with lower weighting score and the target is large.  Simply summing them together may cause the training penalize more for the sub-depth with lower weighing score, which seems less proper.  The authors need to give more discussion (may with ablation study) about it.\n\n2. The ablation study with more subnetworks can achieve better rendering result while a smaller value (i.e., 2) is used by default in this paper. What\u2019s the consideration behind it? I think using a larger number of subnets may introduce difficulty for training. The difficulty in training convergence may significant grow as ray capacity and the number of subnetwork increases, as there may be a great number of possible arrangements. In contrast, using prior knowledge (e.g., nearby points or pixels may highly go through the same subnet) is likely to be helpful for reducing the complexity. The authors need to give more discussion about it as well as analysis on training complexity.\n\n3. For a detail in the design, is sharing the feature grid necessary?  The authors mentioned that it is helpful for reducing parameters. If using different feature grids for subnets, it may introduce some problems due to the lack of global index.  It would be better to give some discussion and experimental result to validate the design. \n\n4. The authors need to discuss the limitation of the work. It is unclear that if the method can handle the scene with translucent objects. The method is built on the assumption that each ray is associated with a single confidence score, i.e., depth value. But depth estimation is naturally a problem for translucent objects."
            },
            "questions": {
                "value": "Please see the questions in the ``Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699364372520,
        "cdate": 1699364372520,
        "tmdate": 1699636551397,
        "mdate": 1699636551397,
        "license": "CC BY 4.0",
        "version": 2
    }
]