[
    {
        "id": "8JQDUSNDOe",
        "forum": "mR5pknv2oP",
        "replyto": "mR5pknv2oP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_wTSJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_wTSJ"
        ],
        "content": {
            "summary": {
                "value": "This paper shows that you can improve LLMs performance and LLM generalizability by a) first asking the LLM to show its work solving the same problem, effectively decomposing the problem into two smaller problem that the LLM has previously demonstrated proficiency on. They then use the solution obtained by chain of thought reasoning to train a new model that can solve the same problem without the decomposition step, and iteratively build up more powerful models. \n\nThey further address a number of useful technical issues in the implementation of this idea and how it differs from \"standard\" reinforcement and self supervised learning techniques. They explicitly discussing how to avoid error avalanching challenges using sanity checks and voting methods. \n\nThey demonstrate this using a standard and well chosen example of addition of integers. The generalizability in question is the ability of the model to scale up to more digits. In particular, they show that the self training methods can typically increase the generalizability by 5-10 digits."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "In the dimensions of originality, quality, clarity and significance, this paper is strong.  Along those dimensions, there are three primary strengths to this paper: \n1. The beautifully clear idea and and associated exposition. This paper makes it crystal clear what problem they are trying to solve and how they are going to solve it.\n2. Excellent performance results. Being able to generalize from 7 to 29 digit numbers is a strong result\n3. Their solution to error avalanches, which is a novel mix of meromorphic testing and voting/ensembling methods. \n\nTaking each of the dimensions in turn. \n\n## Originality\nThe idea of replacing a MCTS with a chain of thought is quite\nnovel. This is different from other approaches to generalization\nbecause it does not rely on any quantity of data (e.g. semi-supervised\nlearning, data programming) instead using a generative model to\ngenerate its own data, while exploiting specific capabilities of \n\n## Quality \n\nThere were two points where the quality of this work was highlighted:\nThree points where the quality of this work really came through were:\nFirst, the detailed discussion of Error Avalanching in section 2.2 and\n3.3.1 greatly improved this paper and has useful applications even\noutside the LLM generalization (e.g. for testing). The second area was\nthe the supporting information was complete and well thought out. It\ndid a good job providing details and expanding on the results.\n\n## Clarity\nThis had a clear statement of need and approach. I could clearly follow what they were trying to do, what the limitations of current practice were, and what was new in their approach. \n\n## Significance\nThe use of addition is strong choice because this is an area where\nLLMs are known to struggle. Work in addressing that is significant\nautomatically because there are huge gains to be made in the area."
            },
            "weaknesses": {
                "value": "## General comments:\n- Stylistically, too much hyperbole as the results stand on their own. The discussion of alpha-* methods is curious but feels overblown. Most of the discussion is focused around a reinforcement learning perspective with the self learning and self teaching saved for the related work sections. It is likely a pedantic distinction, but some discussion of why this is reinforcement learning rather than semi-supervised learning would be useful. I believe the answer to this is that the methods here generate their own data rather than incorporate unlabeled data, but this distinction was hard to find in the discussion and felt drowned out by the hyperbole about alpha-*\n\n- The results of this paper are very specific to the BYT5 models and the addition datasets. Those are very good examples for this paper, however the claims made are broader than a single model and a single dataset. In its current form, this a really a single method that works on a single dataset. A more compelling result would be multiple models and multiple forms of generalization. \n\n\n## Originality\nNo weaknesses identified\n\n## Quality\n\nThe primary weakness in the quality of the work and the experiments\nwas an over-reliance on a limited set of models and tests. Those tests\nwere well chosen, but in its current from, this is a single dataset,\nsingle model proof of concept.\n\n\n\n## Clarity\nThe related work seemed incomplete. In particular, the connections to\nsemi-supervised learning and other data efficent labeling methods\nwasn't discussed but felt very relevant to the discussion. \n\nThe discussion could be significantly improved in two ways:\n1. Some discussion of the specific results of this paper should be\n   included. For instance, why is the generalization accuracy higher\n   for 10-20 digit numbers than it is for 4-6 digit numbers? \n2. The point about compute inefficency is a good one, but if it is\n   included, specific references should be included for ways to\n   improve the compute effiency would strengthen this section. \n\n## Significance\n\nThe use of addition as a reference example is both a strength and a\nweakness of this work. While I listed arithemetic above as a strength\nbecause it is a known area where LLMs struggle, it is also a weakness\nbecause pocket calculators have been able to add 30+ digit numbers\nsince they replaced slide rulers. That isn't meant to attack the\npremise of this work, as I said, it is a strength, but the\nover-reliance on a toy problem undercuts the significance of this\npaper. The\nclaims made are about self teaching and generalization and those would\nbe better illustrated with a more broad cross section of problems, and\non problems that are not already solved by readily available, cheap\nelectronic devices such as calculators. \n\n## Specific Concerns:\n- page 7, paragraph 2. They claim \"we use K=5, which was found to be a good balance between computational speed and accuracy\". I think this is an important claim that greatly impacts their results, but no data is provided to support this claim."
            },
            "questions": {
                "value": "Questions are minimal and there are a number of specific questions \n\n- Figure 6) This is a key figure for the paper and I have a number of questions about it:\n1. I can't meaningfully read the accuracy from these bars. \n2. There is better behavior in the middle than on the ends\n\n- What are the key data efficient and curriculum learning references that you can use to improve these results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698095227991,
        "cdate": 1698095227991,
        "tmdate": 1699636373279,
        "mdate": 1699636373279,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MVfJujwVn2",
        "forum": "mR5pknv2oP",
        "replyto": "mR5pknv2oP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_WpSN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_WpSN"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a proof-of-concept demonstration showing that language models can reinforce themselves to some degree through chain-of-thought (CoT) reasoning and fine-tuning on self-generated answers. The authors suggest utilizing the models' CoT capability as a policy improvement operator, similar to how Monte-Carlo Tree Search enhances AlphaZero. Experiments conducted on synthetic addition tasks reveal that small models, pretrained on data containing only a few digits, can self-learn to solve addition problems with up to 28 digits."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Linking CoT with Monte-Carlo Tree Search is an interesting and, as far as I know, novel idea. Exploring the direction of optimizing language models through self-training shows promise for model training.\n2. The authors present intriguing observations on how error accumulation prevention enhances self-learning.\n3. The paper is easy to follow."
            },
            "weaknesses": {
                "value": "1. Although the proposed method demonstrates strong self-learning abilities in synthetic addition tasks, I generally perceive it as being quite specific to those tasks. More specifically, the simplify-then-guess approach and curriculum appear to necessitate a distinct hierarchical structure that can be solved recursively.\n2. The experimental results are not enough to confirm the feasibility of the proposed method. The absence of baseline methods raises concerns about whether the proposed method performs well or if it simply learns basic addition operators that are easy to learn. Additionally, I am unsure why the self-learning process fails at 29 digits. I recommend that the authors conduct a more comprehensive evaluation on the failure cases.\n3. The authors propose hypotheses that, in my opinion, are inappropriate. For instance, the authors mention that \"a sufficiently large pre-trained language model might be able to forgo the supervised training period entirely and begin self-training immediately, perhaps with only a few examples of in-context demonstrations.\" It would be safer to avoid phrasing it like this as there is no supporting evidence from relevant references or experimental results.\n4. Some necessary details are missing. Please refer to the Questions part."
            },
            "questions": {
                "value": "1. How is the supervised training dataset generated? What distribution of prompts is used for answer generation during self-training? Approximately how many tokens are used for training in each phase?\n2. How does curriculum learning contribute to final performance? I see no results in Appendix J."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4086/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4086/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4086/Reviewer_WpSN"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698585638324,
        "cdate": 1698585638324,
        "tmdate": 1699636373200,
        "mdate": 1699636373200,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VnK73W926S",
        "forum": "mR5pknv2oP",
        "replyto": "mR5pknv2oP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_btm4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_btm4"
        ],
        "content": {
            "summary": {
                "value": "The paper presents SECToR (Self-Education via Chain-of-Thought Reasoning) which helps language models to teach themselves new skills using chain-of-thought reasoning. SECToR contains two phases. The initial supervised fine-tuning phase employs curriculum learning to gradually introduce more complex addition problems. The self-training phase helps the model successfully generalize to N + 1 digit addition, even though it has been primarily trained on addition problems ranging from 1 to N digits, facilitated by chain-of-thought reasoning. SECToR also employs self-consistency and commutativity checks, to mitigate errors during self-training."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The article introduces the SECToR method, which achieves self-learning through chain-of-thought reasoning. This approach provides a new avenue for autonomous learning in language models."
            },
            "weaknesses": {
                "value": "1. This article lacks specific details regarding the dataset used, including the sizes of the training and testing sets, as well as the methodology for constructing the dataset (including both fast and slow datasets). \n\n2. Figure 4 and the simplify-then-guess process is rather confusing. Can the authors provide a more detailed explanation or illustrative example of the simplify-then-guess process? (see question1,2).\n\n3. The article should include a comparative experiment, specifically training the model directly on N+1 data to compare with the self-generated training data. The paper should also place greater emphasis on its motivation and advantages, as it appears that generating a large amount of additional data is a relatively simple and straightforward task. The current approach, in my opinion, may increase computational costs as it involves generating and verifying the data manually. Perhaps the article could explore applying this method to more challenging datasets beyond simple addition, where data acquisition is more challenging.\n\n4. The article needs further improvement in terms of its presentation and image formatting. Some images are extending beyond the text width, which affects the overall layout and readability."
            },
            "questions": {
                "value": "1. In section 3.3.1, when saying \u201ctaking the first guess of a solution\u201d, is the solution to the 8-digit problem or the 7-digit problem? If all the guesses belong to the simplified problem, how  the majority voting is conducted? Do the authors sample different answers for each sub-problem and conduct majority voting separately? \n\n2. What is fast add? Does it mean generating the answer directly without using CoT (slow)?\n\n3. This paper mentioned that \"Training examples for each type are prefixed with a special token depicting their type, so the model can differentiate between the two.\" Could the authors please clarify what special token is being used for this purpose? \n\n4. This paper mentioned that \u201cSECToR checks that the answers generated by simplifying for one step, followed by immediately fast adding the subproblem emit identical answers for both a problem and its commutative twin.\u201d I found the presentation somewhat confusing. Take figure 2 for example, do the authors do it by adding 4 and 14+12? If so, how to obtain the answer for 14+12?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698819039192,
        "cdate": 1698819039192,
        "tmdate": 1699636373108,
        "mdate": 1699636373108,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JonLL2kA6K",
        "forum": "mR5pknv2oP",
        "replyto": "mR5pknv2oP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_KjP6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4086/Reviewer_KjP6"
        ],
        "content": {
            "summary": {
                "value": "The authors present a method for self-improvement of large language models via iterative chain-of-thought prompting and fine-tuning. Via this method they are able to produce a fine-tuned model that exceeds the current state of the art on zero-shot addition of numbers with large numbers of digits."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The motivation for this paper is sound and strong. Self-improvement is likely to become an increasingly important area of research as data sources for training large models become exhausted. \n\n- The results are well-presented, easily interpretable and improve on the current state-of-the-art in the particular domain under consideration."
            },
            "weaknesses": {
                "value": "- There are some missing citations e.g. in the self-improvement of LLMs space (https://arxiv.org/abs/2309.03409, https://arxiv.org/abs/2211.01910, https://arxiv.org/abs/2309.16797) and in the fine-tuning of LLMs via prompted LLMs space (https://arxiv.org/abs/2212.08410, https://arxiv.org/abs/2212.10071). \n\n- My main concern is that this paper only demonstrates the benefit of the proposed method on a single toy domain: addition of numbers with many digits. Therefore, it is hard to assess whether this method can have more general impact for self-improvement. In particular, the use of commutativity in the method seems overfit to this domain, and wouldn't naturally generalize to a wider range of tasks. \n\n- The paper does not make the setting precise until Section 3.3 (the italicised sentence). This framing should be provided much earlier in the paper, so as to avoid confusion for the reader. \n\n- An important baseline is missing: namely what would happen if you kept training on the programmatically generated data with the curriculum that is used for the first phase of training? Can the authors comment on whether their method can outperform this baseline? \n\n- Does the fine-tuned model lose the \"general\" capabilities that make it so valuable in the first place? The authors do not verify that fine-tuning does not reduce performance on standard LLM benchmarks. Can they comment on this? \n\n- In Section 3.3.1 it is very unclear where the dataset of problems with N digits comes from. Is this generated by the large language model itself, or is this pre-generated synthetically? If the latter, the utility of the method is reduced, because the method is no longer self-contained. Could the authors clarify? \n\n- In Section 3.3.1 it is unclear why the iterative method of \"simplify then guess\" is required. If the chain of thought prompt reduces N+1-digit addition to N digit addition, and the fast addition for N digits is highly reliable, then surely further decomposition is not required? It would be useful to see an ablation of the full \"simplify then guess\" method, compared with the simpler \"one step\" one which I have suggested here."
            },
            "questions": {
                "value": "See \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699221667968,
        "cdate": 1699221667968,
        "tmdate": 1699636373027,
        "mdate": 1699636373027,
        "license": "CC BY 4.0",
        "version": 2
    }
]