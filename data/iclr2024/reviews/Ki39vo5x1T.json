[
    {
        "id": "RGbkhiaaEA",
        "forum": "Ki39vo5x1T",
        "replyto": "Ki39vo5x1T",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_38dU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_38dU"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of learning personalized policies on observational data collected from heterogeneous multiple sources. To ensure privacy and other data safety requirements, this paper studies the problem under a specific federated setting with a central server that collects no raw data from individual data sources. \n\nFirst, based on a federated averaging algorithm, this paper proposes a policy learning algorithm that abides by the federation requirement. \n\nThen a regret analysis is provided for the algorithm, which considers two notions called global regret and local regret. For both notions, finite sample regret upper bounds depending on quantified heterogeneity are presented. \n\nFinally, experimental results verify the dependence of the regret on the client heterogeneity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Significance**: this paper studies offline learning under heterogeneous data sources, an important problem setting in machine learning\n\n**Quality**: the quality of the paper is good. Definitions are introduced without ambiguity; theoretical results looks solid to me; experimental details are given.\n\n**Originality**: this paper considers the federation under the problem setting, which I deem as original\n\n**Clarity**: this paper is very well written and easy for the readers to follow."
            },
            "weaknesses": {
                "value": "I did not detect any major technical flaw or major weakness in this paper. \n\nStill, I have a few questions I hope the author can address. Please see the Questions session. \n\nFurthermore, I think this paper, as a theoretical work, would significantly benefit from adding a sketch of proof for its main results."
            },
            "questions": {
                "value": "I think the problem setting is original. However, it is unclear to me what the technical novelty of this paper is. \n\nSpecifically, in the analysis/proof of the theorems, does there exist any technical challenge and how are they resolved? \n\nAny novel trick adopted?\n\nIt would be great if the author could elaborate on this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7156/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698291572050,
        "cdate": 1698291572050,
        "tmdate": 1699636847891,
        "mdate": 1699636847891,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JUt4ZZMrwQ",
        "forum": "Ki39vo5x1T",
        "replyto": "Ki39vo5x1T",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_D9wE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_D9wE"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of learning personalized policies from heterogeneous data sources in the federated setting.\nThey proposed a federated policy learning algorithm that averages locally trained policies with doubly robust policy evaluation. And, they provided finite-sample analysis on global and local regret bounds in terms of a mixture of distribution of clients and a relative distribution shift to all other clients, respectively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This work provides finite-time regret upper bounds of the proposed policy learning algorithm in global and local perspectives, which characterize the effect of client skewness and client heterogeneity on global policy learning and individual policy learning of clients, respectively.\n2. This work empirically demonstrated the effect of client heterogeneity on federated policy learning and suggested a skewed mixture for global policy training to overcome the performance degradation due to distribution shift."
            },
            "weaknesses": {
                "value": "1. It seems that the proposed algorithm is an application of FedAvg to CSMC. I wonder if there are some special challenges when extending offline policy learning algorithms to the federated setting with FedAvg, which have not been addressed in other federated learning or federated RL literature.\n2. The regret analysis holds only when the algorithm converges to the optimal policy, which is not always guaranteed. In the paper, the authors claimed that it is still possible to achieve optimal policies via some additive term and appropriate choice of policy class, but it is vague and not convincing enough. It would be nice if you could provide further clarifications on the solution that enables the algorithm to achieve the optimal policy for general policy classes beyond linear policy classes.\n3. It seems that Assumption 1-(c) requires a full exploration of all actions, which is quite strong given that there are some offline RL works suggesting that full coverage of state-action space is not necessary.\n4. In the experiments, the algorithm was demonstrated in very limited settings. I wonder if this could be applied to more general and realistic settings. Also, it would be nice if you could compare the performance with other baseline algorithms."
            },
            "questions": {
                "value": "See the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7156/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7156/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7156/Reviewer_D9wE"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7156/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698614392014,
        "cdate": 1698614392014,
        "tmdate": 1699636847763,
        "mdate": 1699636847763,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i9oXdIW1L6",
        "forum": "Ki39vo5x1T",
        "replyto": "Ki39vo5x1T",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_eGKx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_eGKx"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of learning personalized decision policies from observational bandit feedback data across multiple heterogeneous data sources. In the federated setting, a central server aims to train a policy on data distributed across the data sources without directly accessing the raw data. The paper proposed a policy learning algorithm amenable to federation, based on the\nfederated averaging algorithm with local model updates provided by online cost-sensitive classification oracles.  Finite-sample upper bounds are provided for a notion of global regret, and local regrets for each agent. Empirical local and global regret bounds are compared across different experimental settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Overall the paper is written with a good clarity. The authors studied a practically significant problem of learning personalized decision policies from multiple heterogeneous data sources, and demonstrated that the proposed algorithm can be extended to the federated setting. \n- The assumptions and the regret upper bound analysis were detailedly described. In particular the theoretical analysis on local regret was a good compliment to the analysis on global regret, and shows their discrepancy due to client heterogeneity. \n- The local and global regret bounds were compared empirically via simulated data."
            },
            "weaknesses": {
                "value": "- The upper bounds were based on a few detailed data assumptions, such as local ignorability, unconfoundedness, and overlap. Although the paper mentioned that some of the assumptions can potentially be relaxed, there is a lack of details on the discussion, and which assumption may not be relaxed fundamentally. \n- In the theoretical analysis part (section 4-5), the main innovation part for the algorithm / estimator design and regret analysis in comparison to prior works was not clearly highlighted. \n- The empirical evaluation did not include any comparisons with other baselines, or any real dataset, and the heterogeneous setting was fairly simply constructed."
            },
            "questions": {
                "value": "- Can the nuisance parameters be learnt jointly instead of being required to be separately known or estimated in the policy value estimates?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7156/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698625289168,
        "cdate": 1698625289168,
        "tmdate": 1699636847645,
        "mdate": 1699636847645,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rwXsjkCOTY",
        "forum": "Ki39vo5x1T",
        "replyto": "Ki39vo5x1T",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_oHDw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7156/Reviewer_oHDw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an federated optimization procedure for off-policy learning over heterogeneous data sources, where the observational data is collected by multiple clients using different behaviour policies and stored only locally.\nSpecifically, the central server needs to maximize the doubly robust policy value estimator (Zhou et al. 2022b) over the (parametric) policy space, without transferring the raw observational data. In the proposed procedure, this is achieved by letting each client locally compute its model update by calling an online const-sensitive multi-class classification (CSMC) oracle and then the server performs a global update via a weighted average over the local model updates.\n\nTo the best of my knowledge, this is the first work that studies off-policy learning under federated setting."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem of off-policy learning in federated setting is well-motivated, and the authors have provided a solution with regret guarantee."
            },
            "weaknesses": {
                "value": "1. My main concern is the technical novelty, and I'd appreciate if the authors can provide more clarification on the contribution compared with the existing work mentioned below.\n\nBased on my understanding, the main difference of this paper, compared with existing off-policy learning method using doubly robust estimator, e.g., Zhou et al. (2022b), lie in the optimization oracle. i.e., this paper needs to solve the CSMC problem over multiple heterogeneous clients to update the policy, instead of in a centralized setting. However, I am not sure if this has led to any technical challenge in obtaining the global regret bound in Theorem 1.\n\n2. With CSC, we typicaly have a non-concave non-convex objective function to optimize, which makes finding the policy that maximizes Eq 8 difficult. Therefore, I expected the regret analysis to cover the situation where the FedAVG-CSMC procedure can only provide policy with certain approximation error. Moreover, even if the objective function is easy to optimize, it still seems to be unrealistic to assume we can obtain the exact maximizer of Eq 8 under federated setting, as this requires infinite number of iteration/communication rounds.\nI'd appreciate it if the authors can provide more insights on how the current analysis can be extended to allow for approximation error of Eq 8."
            },
            "questions": {
                "value": "In Section 3.2, notations like $X^{C}, Y^{C}$ are not formaly defined.\n\nThe author mentioned that Assumption 3 can be easilly satisfied under regularity assumption. Can the authors provide a more formal description of the regularity assumption?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7156/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698889024480,
        "cdate": 1698889024480,
        "tmdate": 1699636847535,
        "mdate": 1699636847535,
        "license": "CC BY 4.0",
        "version": 2
    }
]