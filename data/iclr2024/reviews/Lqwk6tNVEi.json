[
    {
        "id": "RDOzvgtQu0",
        "forum": "Lqwk6tNVEi",
        "replyto": "Lqwk6tNVEi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_Wxvo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_Wxvo"
        ],
        "content": {
            "summary": {
                "value": "This paper studies source-free domain adaptation without accessing the source labelled data when conducting target adaptation. Specifically, the authors propose to utilize diffusion models to generate positive key features for facilitating the unsupervised clustering in target adaptation. The whole framework consists of three key components: 1) the source representation learning; 2) diffusion model learning and 3) target model adaptation. Experimental results on several public datasets demonstrate that the proposed model can outperform recent baselines with different gains."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1)\tThis paper investigates source-free domain adaptation, which is a much more practical setting compared with source-need domain adaptation.\n2)\tA diffusion model is employed in the domain adaptation framework, which is less explored in the scenario of source-free DA.\n3)\tAblation studies are given to show the effectiveness of the proposed components."
            },
            "weaknesses": {
                "value": "1)\tAlthough the diffusion models are less explored in the scenarios of source-free DA, the technical contribution of this paper is quite limited. No new diffusion model is proposed to address the domain shift problem in DA and the authors simply use an existing model in this step.\n2)\tAs this paper generates examples in the adaptation procedure, it is not clear what are the advantages of using diffusion model compared with other generative models like GAN. There are also lots of baselines that generate samples in the adaptation process and the authors did not discuss and compare with them. See references below.\n\n[1] Qiu Z, Zhang Y, Lin H, et al. Source-free domain adaptation via avatar prototype generation and adaptation. IJCAI 2021.\n\n[2] Li R, Jiao Q, Cao W, et al. Model adaptation: Unsupervised domain adaptation without source data[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020: 9641-9650.\n\n3)\tThe source-free setting is a little different from existing work, as this paper uses source data to train the diffusion model. However, existing source free models do not use any source data to train the generative models. \n4)\tThe experimental results are not convincing. The authors directly copy the results from the baselines; however, their network backbones are different. Thus, the comparisons are not fair. For example, in Table 2, baseline DaC\u2019s results are directly cited from its original paper, and it uses the backbone of ResNet-50. However, the authors use ResNet-101 in this paper. I strongly recommend the authors to rerun the experiments.\n5)\tMore ablation studies should be given to verify the effectiveness of the proposed diffusion model. What if we directly use the target\u2019s kNN samples as the positive keys?\n\nThere are lots of typos in the paper. The authors need to carefully read and polish the paper. Some of the typos are listed as follows:\n\u201cTo transition from $z_0$\u201d should be \u201cTo transit from $z_0$\u201d.\n\n\u201cWe use an SGD optimizer\u201d should be \u201cWe use a SGD\u201d.\n\nIn equation (1), the norm should be $\\Vert \\cdot \\Vert_2$."
            },
            "questions": {
                "value": "1.)\tMore ablation studies should be given to verify the effectiveness of the proposed diffusion model. What if we directly use the target\u2019s kNN samples as the positive keys? It is not clear how different number of k-nearest neighbors will affect the model\u2019s performance.\n\n2.)\tThere are also lots of baselines that generate samples in the adaptation process and the authors did not discuss and compare with them. \n\n3.)\tThe experimental results are not convincing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698480036727,
        "cdate": 1698480036727,
        "tmdate": 1699636132961,
        "mdate": 1699636132961,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Sz6iMkeoDu",
        "forum": "Lqwk6tNVEi",
        "replyto": "Lqwk6tNVEi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_oyCL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_oyCL"
        ],
        "content": {
            "summary": {
                "value": "The paper highlights challenges in diffusion models for source-free domain adaptation and introduces discriminative neighborhood diffusion (DND) as a solution. \nBy leveraging pre-trained source representations, DND facilitates unsupervised clustering through its latent k-nearest\nneighbors and significantly enhances performance in SFDA scenarios.\nExtensive evaluations demonstrate the discriminative potential and state-of-the-art effectiveness of DND across various benchmark datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- the idea of using diffusion models for source-free domain adaptation sounds interesting and reasonable\n\n- the paper is overall well-written and easy to follow\n\n- the results on three widely used domain adaptation datasets are impressive"
            },
            "weaknesses": {
                "value": "- In source-free domain adaptation, the suggested approach demands an extra diffusion model and necessitates the storage of source data features, leading to substantial efforts in the source domain. This situation renders the term \"free\" somewhat unrealistic, presenting a major concern.\n\n- A recent work [a] also uses diffusion models for test-time adaptation, which is similar to source-free domain adaptation as depicted in a recent survey [b]. Could the proposed method work for single-epoch target adaptation, and how about the comparison?\n\n- Another concern is that only three small datasets are used to evaluate the performance of the proposed method, large-scale datasets like DomainNet [c] are also important. Also, target adaptation under class shift (e.g., partial-set domain adaptation in SHOT (ICML-2020)) is not studied in the experiment.\n\n- Since previous SFDA methods typically adopt the ResNet-50 backbone, the comparisons are not fair in these tables (the proposed method is based on ResNet-101). And how is the diffusion model used in the source domain, would the pre-trained diffusion model bring additional gains?\n\n\n\n\n\n[a]. Gao, Jin, et al. \"Back to the source: Diffusion-driven adaptation to test-time corruption.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[b]. Liang, Jian, et al. \"A comprehensive survey on test-time adaptation under distribution shifts.\" arXiv preprint arXiv:2303.15361 (2023).\n\n[c]. Peng, Xingchao, et al. \"Moment matching for multi-source domain adaptation.\" Proceedings of the IEEE/CVF international conference on computer vision. 2019."
            },
            "questions": {
                "value": "pls see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698728208016,
        "cdate": 1698728208016,
        "tmdate": 1699636132892,
        "mdate": 1699636132892,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2nqcTINXNV",
        "forum": "Lqwk6tNVEi",
        "replyto": "Lqwk6tNVEi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_VVzG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_VVzG"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an approach to source-free domain adaptation using diffusion models. the diffusion models are built using the intuitive idea that \"you are close to your neighbors\". Experiments on three standard domain adaptation datasets are provided."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Source-fee domain adaptation is a challenging problem. The proposed solution is novel and effective. Experiments validate the effectiveness of the proposed approach. Overall a good paper."
            },
            "weaknesses": {
                "value": "I do not see any."
            },
            "questions": {
                "value": "How will your approach work for the domain generalization problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794824362,
        "cdate": 1698794824362,
        "tmdate": 1699636132787,
        "mdate": 1699636132787,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1oE2gs8vVB",
        "forum": "Lqwk6tNVEi",
        "replyto": "Lqwk6tNVEi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_6XN2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2015/Reviewer_6XN2"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method: discriminative neighborhood diffusion (DND). DND formulates a diffusion model using pre-trained source domain representation and combine it with contrastive learning to promote unsupervised clustering of the target domain in the domain adaptation process."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper introduces the diffusion model into the SFDA problem, and the proposed method is simple and effective."
            },
            "weaknesses": {
                "value": "1) DND may violate the problem setting of SFDA, i.e., learning a target model with only a pre-trained source model and target data introduced by SHOT.\n2) The writing logic of the paper is chaotic and difficult to read, especially in the introduction section. In addition, it is not advisable to use a large space in the method section to introduce existing work: IADB, and a brief explanation is sufficient.\n3) This method requires a large number of hyperparameters, and it seems difficult to quickly find suitable parameters. And there is a lack of hyperparameter sensitivity experiments.\n4) The persuasiveness of conducting ablation experiments on a relatively simple dataset, Office-31, is not strong. It is recommended to supplement the results of ablation experiments on the Office-Home or VisDA-C."
            },
            "questions": {
                "value": "1) Does diffusion model learning violate or relax the problem setting of SFDA, because the diffusion model pre-training requires source data. Other SFDA methods only use source data to pre-train a source model, but DND uses source data to train a source model and a diffusion model.\n2) You maintain ResNet-101 as the encoder G across all datasets, but ResNet-50 is used as the encoder by other SFDA methods on both Office-31 and Office-Home. So are the performance comparisons on Office-31 and Office-Home unfair (Table 1,2)? And whether the results of other methods in Tables 1,2,3 are your reproduced results? Some of which are different from the results in the original paper (such as NRC++, original paper: 88.1, you reported: 87.8).\n3) To our knowledge, the training of the diffusion model is very time-consuming, could you conduct a runtime analysis between DND and other SFDA methods (eg. DaC and NRC++)?\n4) The target adaptation part in Figure 1 mistakenly divides the inverted triangles into class 0 and the diamonds into class 1.\n5) There is an error in the pseudocode of algorithm 1: if the maximum value of t is T in algorithm 1, then z_{\\alpha_{T+1}} is obtained, but in reality, the algorithm should end after z_{\\alpha_{T}} is obtained."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2015/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2015/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2015/Reviewer_6XN2"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699624988612,
        "cdate": 1699624988612,
        "tmdate": 1699636132711,
        "mdate": 1699636132711,
        "license": "CC BY 4.0",
        "version": 2
    }
]