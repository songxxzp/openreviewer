[
    {
        "id": "SHyH9kUBVr",
        "forum": "UB03wcP8RH",
        "replyto": "UB03wcP8RH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_TwpG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_TwpG"
        ],
        "content": {
            "summary": {
                "value": "**Summarization**:  \nThis paper proposes a multi-task contrastive loss (MTCon) to combine the multi-task domain and contrastive learning. The main contributions of this paper could be summarized into one point, i.e., incorporating task weightings that consider the uncertainty of each task, reducing the impact of uncertain tasks, and leading to better out-of-domain generalization for unseen tasks.  \n\n**Reasons To Accept**:  \n1. A multi-task contrastive loss. The paper introduces a multi-task contrastive loss MTCon, which combines contrastive learning with multi-task scenarios. This loss showcases the potential for enhanced embedding generalization across tasks.  \n2. A weighting scheme. This paper incorporates task weighting, offering a mechanism to address uncertainties in different tasks.  \n\n**Reasons To Reject**:  \n1. Unclear Motivation: The paper lacks a clear and convincing motivation, especially considering the abundance of prior work that combines multi-task and contrastive learning [1-3]. The authors do not provide a coherent rationale for this combination, and the specific domain and problem targeted remain unclear.  \n\n2. Insufficient Novelty: The proposed method appears overly simplistic and lacks significant innovation. From the outlined approach in the paper, it appears to have limitations in terms of generalizability and transferability, with limited performance across different datasets.  \n\n3. Failure to Address Potential Conflicts Among Different Similarity Notions: Multi-task learning often involves different similarity metrics, and the paper does not seem to consider how to handle potential conflicts or issues arising from the use of multiple similarity notions.  \n\n4. Outdated Comparative Methods: The chosen comparative methods in the paper do not appear to represent the state-of-the-art in the field. The paper lacks sufficient evidence to demonstrate the competitiveness of the proposed approach within the competitive research landscape.  \n\n5. Lack of Targeted Title and Unclear Pipeline: The title should ideally provide a clear indication of the paper's focus and contributions, while the pipeline should serve as a visual guide for readers to understand the proposed methodology. The absence of a targeted title and an unclear flowchart can hinder the paper's accessibility and understanding, making it challenging for readers and researchers to grasp the core message and methodology.  \n\n**Summary Of the Review**:  \n\nIn summary, this paper introduces a multi-task contrastive loss (MTCon) that combines multi-task scenarios and contrastive learning, primarily by incorporating task weightings to address uncertainty in tasks and improve out-of-domain generalization. While the contributions are promising, the paper suffers from unclear motivation, limited novelty, a lack of consideration for handling similarity conflicts, and outdated comparative methods. Furthermore, the title of the paper lacks specificity, and the absence of a clear flowchart hinders accessibility and understanding. These combined factors indicate that the paper does not meet the standard for acceptance.\n \n\nReference:  \n[1] Ravikiran Parameshwara, Ibrahim Radwan, Akshay Asthana, Iman Abbasnejad, Ramanathan Subramanian, Roland Goecke: Efficient Labelling of Affective Video Datasets via Few-Shot & Multi-Task Contrastive Learning. ACM Multimedia 2023: 6161-6170  \n[2] Junichiro Iwasawa, Yuichiro Hirano, Yohei Sugawara: Label-Efficient Multi-task Segmentation Using Contrastive Learning. BrainLes@MICCAI (1) 2020: 101-110  \n[3] Yu Zhang, Hao Cheng, Zhihong Shen, Xiaodong Liu, Ye-Yi Wang, Jianfeng Gao:\nPre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding. CoRR abs/2305.14232 (2023)"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "See summary"
            },
            "weaknesses": {
                "value": "See summary"
            },
            "questions": {
                "value": "See summary"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6334/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698840219389,
        "cdate": 1698840219389,
        "tmdate": 1699636696970,
        "mdate": 1699636696970,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nkXUZOhZHH",
        "forum": "UB03wcP8RH",
        "replyto": "UB03wcP8RH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_BR7u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_BR7u"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a multi-task contrastive learning loss function, MtCon, which learns representations under many measures of similarity between examples. They show strong results on three multi-task vision datasets over vanilla contrastive learning baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper is clearly written and easy to follow. \n - The method (MtCon) is simple, and the authors provide an uncertainty-motivated derivation of their method. \n - The experiments on the three datasets (Zapp050k, CUB200-2001, MEDIC) show that MtCon works better in multi-task settings compared to the chosen baselines."
            },
            "weaknesses": {
                "value": "- The authors provide a derivation of the MtCon loss function to arrive at Eqn (8), but it ends up simply learning a scalar weight for different contrastive learning tasks and regularizing the scalar weights. Seeing that it is so straightforward, I think the paper culd benefit from 1. more discussion on if this loss function is better suited for *specifically* for contrastive learning (unless I'm missing something, most of the analysis and theory could apply to any multi-task setting, even if it isn't contrastive), and 2. more task-weighting baselines like the ones mentioned in prior work. The one multi-task weighting baseline XEnt-MT already seems pretty close to MtCon in terms of performance, so I imagine the other multi-task weighting methods work well too.\n - Even at high noise levels, the weight of the noisy tasks doesn't fall that low compared to other tasks (in Figure 3). I think a useful ablation might be to manually set the weight of the noise task to a very low or very high number and show how performance changes."
            },
            "questions": {
                "value": "- How is the MtCon weighting scheme specifically suited for contrastive learning? If it isn't specific to contrastive learning, should more multi-task weighting baselines be compared to? \n  * Is this method just a simple multi-task weighting scheme applied to contrastive learning tasks? \n - How does the MtCon weighting scheme connect to prior work on multi-task weighting? \n\nI'm open to having my mind changed, looking forward to your response."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Reviewer_BR7u"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6334/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699032110427,
        "cdate": 1699032110427,
        "tmdate": 1699636696855,
        "mdate": 1699636696855,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "etDvdYt2QQ",
        "forum": "UB03wcP8RH",
        "replyto": "UB03wcP8RH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_EEgJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_EEgJ"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to develop a new method, Multi-Task Contrastive Loss (MTCon), which combines contrastive learning and multi-task learning to obtain robust representations that capture multiple similarity metrics. MTCon achieves this by learning task weights that reflect the uncertainty associated with tasks. Experimental results on three multi-task datasets, Zappos50k, MEDIC and CUB200- 2011, show that the proposed approach enhances generalization performance on out-of-domain tasks. Furthermore, the proposed approach  has better performance than the weighted multi-task cross-entropy counterpart for both in-domain and out-of-domain scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper introduces a novel result that combines multi-task learning and contrastive learning.\n\nTheoretical results are proven for a simplified version of the problem.\n\nExperimental results on three datasets show that the proposed approach based on the multi-task contrastive loss has overall better results than a similar model based on the cross-entropy loss."
            },
            "weaknesses": {
                "value": "The results on the MEDIC set do not support the overall claims and conclusions of the study. Specifically, the paper claims that the proposed model learns task weights that capture the uncertainty of the tasks. However, when the results on some of the MEDIC tasks are inferior as compared to those of the baselines, the authors speculate that is due to higher uncertainty in those tasks. This seems to be a circular argument as the main assumption of the proposed approach is that the task uncertainty can be learned through task-specific weights. More analysis of those tasks and their weights is needed to better understand when the proposed approach helps and when it may not."
            },
            "questions": {
                "value": "The authors cite  Alam et al. (2018; 2022) to explain the negative results for some of the MEDIC tasks.  But what was Alam et al.'s  basis for concluding that there is  inherent uncertainty for some of the MEDIC  tasks? it would be interesting to know how strong their argument was to avoid propagating information that may only be speculative."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Reviewer_EEgJ",
                    "ICLR.cc/2024/Conference/Submission6334/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6334/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699063413808,
        "cdate": 1699063413808,
        "tmdate": 1700185317671,
        "mdate": 1700185317671,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sYL7YoyX98",
        "forum": "UB03wcP8RH",
        "replyto": "UB03wcP8RH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_yq2P"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6334/Reviewer_yq2P"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Multi-Task Contrastive Loss (MTCon), a new method that combines multi-task and contrastive learning to improve representation learning. MTCon uses multiple projection heads to handle different notions of similarity across tasks. It also incorporates a weighting scheme to downweight more uncertain tasks, improving generalization. Through experiments on 3 datasets, MTCon is shown to outperform multi-task cross-entropy and prior contrastive methods on both in-domain and out-of-domain tasks. For example, it improves average out-of-domain accuracy by 3.3% over multi-task cross-entropy. Analysis indicates the weighting scheme helps MTCon better handle noise in the training tasks. The paper also provides theoretical analysis bounding generalization error based on task noise levels. Overall, MTCon introduces a novel approach to multi-task contrastive learning that achieves state-of-the-art performance by handling multiple similarity metrics and task uncertainty."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper presents a novel approach for combining multi-task and contrastive learning, which to my knowledge has not been done before. The use of multiple projection heads and learned weighting scheme specifically for handling multiple disjoint similarity metrics is creative and original. \n- The paper is well-organized and clearly explains both the proposed method and experiments. The problem formulation and notation are clear.\n- This work makes both empirical and theoretical contributions. It pushes forward the state-of-the-art in representation learning, achieving superior performance to prior multi-task and contrastive methods."
            },
            "weaknesses": {
                "value": "- The theoretical analysis makes some simplifying assumptions (e.g. abundance of source tasks) that may not perfectly hold in practice.\n- All datasets used are for computer vision. Testing MTCon on a wider variety of modalities (text, audio, etc) could better demonstrate generalization.\n- The experimental evaluation is quite thorough, but lacks ablation studies to isolate the impact of different components of MTCon (e.g. projection heads vs weighting scheme). Ablation studies would provide more insight.\n- The comparison to prior work is limited to a few baselines. Comparing against a broader range of multi-task representation learning methods could better situate MTCon.\n- The hyperparameter analysis is quite brief. A more extensive sweep over training hyperparameters and architectural choices could be illuminating."
            },
            "questions": {
                "value": "- Have you considered any other proxies for estimating task uncertainty besides the constructed pseudo-likelihood? How does using other uncertainty estimates impact performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6334/Reviewer_yq2P"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6334/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699164102753,
        "cdate": 1699164102753,
        "tmdate": 1699636696631,
        "mdate": 1699636696631,
        "license": "CC BY 4.0",
        "version": 2
    }
]