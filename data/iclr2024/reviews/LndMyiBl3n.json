[
    {
        "id": "rA6XBjndzp",
        "forum": "LndMyiBl3n",
        "replyto": "LndMyiBl3n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new method, SheAttack, for attacking Graph Neural Networks (GNNs) in the Restrict Black-box attack setting. This method aims to diminish the quality of graph data by manipulating node distinguishability. The approach utilizes a Modified Silhouette Score (MSS) to assess graph quality across various homophily levels. Experiments show that SheAttack performs effectively on both homophilic and heterophilic graphs and offers comparable results to more knowledge-intensive white-box attacks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Clarity**: The paper is well written and clear to understand.\n\n**Quality**: The assumptions made about real-world scenarios and RBA are well-considered.\n\n**Significance**: The problem addressed is significant due to the growing need to detect vulnerabilities in graph neural network models. The problem setting in this paper (RBA) seems more aligned with real-world scenarios compared to white-box and grey-box attacks."
            },
            "weaknesses": {
                "value": "* The attack proposed relies heavily on node features to achieve a quality cluster to replace ground-truth labels when calculating the Silhouette score. This dependence is a significant vulnerability. If one adds noise to features and incorporates a de-noising mechanism within the base model, the attack's efficacy could be undermined since the attacker wouldn't know about the noise or how to de-noise the features.\n\n* Given that the attacker has access to node features, it might be more impactful to target both the structure and features. Not leveraging this information seems like a missed opportunity.\n\n* The attack lacks a theoretical foundation; it's mainly empirical. There are no guarantees about the efficacy of the attack.\n\n* The paper seems to have limited novelty. The idea of using clustering due to the absence of label information in RBA and the shift loss has been previously explored. The primary innovation appears to be the modification of the Silhouette score, which has its challenges.\n\n* In Section 3.2, the authors propose modifications in $a$ and $b$ to accommodate the absence of ground-truth labels. However, the later modifications in $b$ do not address the issue of pushing nodes of different classes further apart.\n\n* The parameter $\\Delta$ plays a significant role in the problem definition (Section 2), yet it isn't discussed in the methodology or experiment sections. It's unclear how much perturbation is excessive or how this was determined and verified.\n\n* Please ensure notation consistency. In Section 2, both notations $f_\\theta(X;A)$ and $f_\\theta(X,A)$ are used.\n\n* The related work section mentions interesting algorithms not used as benchmarks. Specifically, the absence of some RL-based methods was noticeable. Why were they excluded? Modifications to the benchmark could also be applied to other methods."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698708417071,
        "cdate": 1698708417071,
        "tmdate": 1699635938252,
        "mdate": 1699635938252,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M0nRCJ8U4W",
        "forum": "LndMyiBl3n",
        "replyto": "LndMyiBl3n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission128/Reviewer_8KRc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission128/Reviewer_8KRc"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new black box attack on the graph structure that uses a variant of the silhouette score as one component of the attacker's loss. This captures distances between intra-class/cluster and inter-class/cluster instances and reflects the difficulty of the classification problem. The authors argue that this loss is agnostic to whether the graph is homophilic or heterophilic. Their attack does not require knowledge of the node labels."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The theoretical insights are interesting even though they rely on several simplifying assumptions.\n\nThe attack can scale to larger graphs such as ogbn-arxiv and ogbn-products.\n\nThe black box threat model is relevant and interesting to study but has received relatively less attention in the past."
            },
            "weaknesses": {
                "value": "The threat model only enforces a global budget, and completely ignores any local constraints e.g. w.r.t. the degree of the nodes. This is likely to lead to unrealistic and noticeable attacks. While the authors perform an empirical analysis in section G and conclude that \"unnoticability of SheAttack is in an acceptable range.\" I do not necessarily agree. First, the averaged results in Table 22 can be misleading since there is likely a big skew in the distribution of changes, and second the mean values are already large.\n\nThe experimental evaluation focuses on a fixed perturbation ratio (mostly 0.2 and sometimes 0.1) which can be considered unrealistically large. An in-depth ablation study w.r.t. different perturbation budgets is missing.\n\nThe paper would benefit from formalizing and describing the threat model in much more detail. For example, the authors state \"only training inputs excluding node labels, are known to attackers.\" Does this mean that the attacker also does not have access to the training node labels. I assume that this is the case. If yes, a reasonable baseline would be to compare previous (adaptive) attacks [1] using clusters as a surrogate for labels.\n\nIf I am wrong and the attacker does have access to training node labels, then they can train a surrogate and use the predictions for the test labels (instead of true labels) which is likely to work much better than using the unsupervised clusters, and likely also better than using \"node embeddings generated by supervised GCN as input to generate clusters\".\n\nReferences:\n1. Mujkanovic et al. \"Are Defenses for Graph Neural Networks Robust?\""
            },
            "questions": {
                "value": "1. How does the attack peform when introducing local budget constraints (e.g. relative to the node degree)?\n2. How does the attack compare to an attack where instead of the true labels we use the predictions from the victim model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837938554,
        "cdate": 1698837938554,
        "tmdate": 1699635938183,
        "mdate": 1699635938183,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iZ3f8HKNCG",
        "forum": "LndMyiBl3n",
        "replyto": "LndMyiBl3n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission128/Reviewer_e7Jw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission128/Reviewer_e7Jw"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors study the problem of restrict black-box attacks (RBA) on GNNs. It first introduces the Silhouette Scores, which is used for quantifying the difficulty of a clustering problem, to the RBA attacks on GNNs. Then it introduces a RBA attack named SheAttack by minimizing the silhouette score of the graph. And a scalable version of SheAttack is also proposed for the large-scale graphs. The experimental results on homophily and heterophily graph benchmarks demonstrate its effectiveness compared to other RBA baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper study the problem of restricted black-box attacks, which is both practical and noteworthy.\n2. This proposed method is effective in both homophily and heterophily settings. And the scalable version of SheAttack can also work on the large-scale graphs.\n3. The experimental results on both homophily and heterophily graphs show that SheAttack can outperform other RBA baselines."
            },
            "weaknesses": {
                "value": "1. Although the authors include the experimental results on large-scale graphs, the comparison between SheAttack and some existing powerful baselines, such as PRBCD, on the large-scale graphs is missing.\n2. In this paper, the authors highlight that SheAttack is applicable to the heterophilic settings while existing RBA methods cannot. However, I think it would be better if some robust GNNs for heterophily graphs can be included during the comparison, such as [1]. \n3. I recommend the authors can include the comparison of the running time among different methods to verify the efficiency of SheAttack.\n\n[1] Robust Heterogeneous Graph Neural Networks against Adversarial Attacks. AAAI 2022"
            },
            "questions": {
                "value": "1.\tCould you please provide some comparisons between PRBCD/PRBCD-shuffle with SheAttack on large-scale graphs? \n2.\tPlease add the experimental results of SheAttack against RobustGNN for heterophily graphs.\n3.\tPlease include the comparison of running time among different methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698908093494,
        "cdate": 1698908093494,
        "tmdate": 1699635938062,
        "mdate": 1699635938062,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DScQe7JVwb",
        "forum": "LndMyiBl3n",
        "replyto": "LndMyiBl3n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the restricted black-box attack scenario where attackers only have access to node features and the graph structure. To solve this problem, the authors introduce the Modified Silhouette Score (MMS) to measure a graph\u2019s quality and propose a Silhouette score-based attack. Extensive experiments are conducted."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The studied restricted black-box attack is a practical scenario and an important problem.\n2. The motivation of this paper is clear and the idea of introducing the Silhouette Score to measure the quality of a graph is interesting.\n3. Extensive experiments are conducted."
            },
            "weaknesses": {
                "value": "1. The proposed SheAttack depends on various hyper-parameters, which may significantly affect the performance of the proposed method and lack detailed theoretical support or empirical analysis. For example, the number of clusters $k$, the propagation layer/time on the adjacency matrix, and the $\\lambda$ that balance the Shift Loss and Silhouette Score-based Loss. \n2. The proposed method does not seem to be consistently effective in all scenarios in Tables 1&3.\n3. The writing of this paper needs to be further improved. For example, the citation format of references in Introduction and Preliminaries seems strange. 'Aggreation function' should be 'Aggregation function\u2019. The definition of poison attacks and evasion attacks on page 3 is confusing."
            },
            "questions": {
                "value": "1. In Figure 3, why do GRBCD and RandAttack show different Modified Silhouette Score at epoch 0?\n2. How would the proposed method perform when the victim model is not a two-layer GNN? In other words, when the propagation layers/times in the proposed method and victim model are not the same, would the proposed method still be effective?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission128/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU",
                    "ICLR.cc/2024/Conference/Submission128/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699264203706,
        "cdate": 1699264203706,
        "tmdate": 1700663602218,
        "mdate": 1700663602218,
        "license": "CC BY 4.0",
        "version": 2
    }
]