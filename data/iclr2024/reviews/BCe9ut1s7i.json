[
    {
        "id": "rT51k0EN98",
        "forum": "BCe9ut1s7i",
        "replyto": "BCe9ut1s7i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission228/Reviewer_fyi7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission228/Reviewer_fyi7"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors find that existing works on improving the adversarial robustness of object detectors give a false sense of security. They propose a simple yet effective recipe for fast adversarial fine-tuning on object detectors with adversarially pre-trained backbones. They explore the potential of different modern object detectors to improve adversarial robustness using our recipe and demonstrated interesting findings. The empirical results set a new milestone for adversarially robust object detection."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Propose a simple yet effective recipe for fast adversarial fine-tuning on object detectors with adversarially pre-trained backbones\n- Conduct large-scale empirical study"
            },
            "weaknesses": {
                "value": "- Lack of practicality\n\nIn this paper, the authors are motivated by some real-world practical security-sensitive applications such as autonomous driving and video surveillance. However, later on, there is no such evaluation. Thus, it lacks a thorough discussion on the transferability of their findings across different applications. For instance, the applicability of their observations to tasks such as real-time detection in autonomous vehicles unclear. Future iterations of the work could benefit from a section discussing the limitations and potential practicality of the findings, supplemented by experiments in diverse application scenarios.\n\n- Lack of overhead evaluation\n\nThe authors propose modifications to the detector architectures (i.e., the backbone networks) to improve adversarial robustness. However, the discussion on the computational overheads, particularly in real-time applications, remains unclear. A more detailed analysis of the trade-offs between increased robustness and computational efficiency will strengthen the paper practical contributions since this paper is motivated by the practical real-world applications such as autonomous driving. \n\n- The methodology and setup of the re-evaluation is not convincing\n\nThe method and setup for the re-evaluation are not comprehensive. For instance, their evaluation may be very specific to the dataset, which means that the findings are not general. Also, it is unclear whether their selected re-evaluated targets are representative or state-of-the-art. Without such justification, it is unclear whether their findings are representative or not. Thus, I would recommend the authors to provide more discussion."
            },
            "questions": {
                "value": "Provide more evaluation and discussion on the practicality, overhead, and justification for evaluation methodology and setup."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission228/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698614112691,
        "cdate": 1698614112691,
        "tmdate": 1699635948467,
        "mdate": 1699635948467,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EP1FPofwzu",
        "forum": "BCe9ut1s7i",
        "replyto": "BCe9ut1s7i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission228/Reviewer_wtFb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission228/Reviewer_wtFb"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the problem of adversarial robustness for object detection task is investigated and the study has some practical value. The authors improve the robustness of the backbone network through adversarial training methods, and the profile improves the stability of the prediction results on the detection task. The authors validate this idea through a large number of experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Extensive experimental validation. The article conducts experiments on several publicly available datasets as well as detectors to comprehensively validate the effectiveness and robustness of the proposed method.\n2. Clear diagrams. The figures and tables are well-designed and help readers understand the content of the article.\n3. Clear background introduction. The article provides a thorough review of related work on object detection defense in the introduction section, which provides readers with good background knowledge."
            },
            "weaknesses": {
                "value": "1. Overall lack of innovation. Although the authors reveal the importance of the backbone network in the overall robustness of the model, this idea is not uncommon [1]. Similar ideas have been proposed by related scholars to illustrate the importance of backbone networks. Since this is a backbone network analysis related to object detectors, the authors should provide more backbone network analyses related to object detectors, e.g., EfficientNet [2], MobileNet [3], DarkNet [4]. In addition, the authors did not propose too novel improvements in the adversarial training phase of the backbone network.\n2. more validation for different tasks. Since the backbone network has a huge impact on the detector, I think the authors' approach should not be limited to the detector task, but the authors can try the results of image segmentation, as well as image categorization to evaluate the enhancement of the robust backbone network. I believe that the idea that robust backbone networks improve the robustness of the detector is applicable on a wide range of tasks. Since as an universal idea, I think the authors should not limit themselves to one task.\n3. How do the authors consider about the gap between pre-trained models and downstream task features? Why are robust features trained using existing adversarial training methods a good feature for detectors? I look forward to the authors' reply about the inspiration and thoughts on the object detection task for robust feature design for backbone networks.\n\n[1] \"Do Adversarially Robust ImageNet Models Transfer Better?\" NeurIPS Proceedings. 2020.\n[2] \"Efficientnet: Rethinking model scaling for convolutional neural networks.\" arXiv preprint arXiv:1905.11946.\n[3] \"Mobilenets: Efficient convolutional neural networks for mobile vision applications.\" arXiv preprint arXiv:1704.04861.\n[4] \"You only look once: Unified, real-time object detection.\" In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 779-788."
            },
            "questions": {
                "value": "Please refer to the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission228/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761381279,
        "cdate": 1698761381279,
        "tmdate": 1699635948363,
        "mdate": 1699635948363,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ifDWXqo9OQ",
        "forum": "BCe9ut1s7i",
        "replyto": "BCe9ut1s7i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission228/Reviewer_xgd4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission228/Reviewer_xgd4"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an adversarial defense method for object detection. The proposed new recipe mainly involves a robust backbone and FreeAT. Experiments demonstrate the effectiveness of the proposed method, especially the importance of a robust backbone."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1.[experimental evaluations] I'm glad to see the experimental evaluations are comprehensive. All types of detectors are covered in this paper -- two-stage ones, single-stage ones, as well as the DETR family.\n\n2.[reveals deficiencies in previous works] Previous works leveraged a relatively weaker adversary for evaluation. So they are not providing as good robustness as advertised."
            },
            "weaknesses": {
                "value": "1.[important, references] Contradictory to what has been described in the introduction, using an adversarially robust backbone for downstream tasks is not completely uninvestigated. See F. Croce, N. D. Singh, M. Hein (2023). Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models. ICML Workshop New Frontiers in Adversarial Machine Learning. Adversarial backbone makes the adversarial training faster in order to reach a good level of robustness. And this paper tells us some similar conclusions about the importance of the backbone in the segmentation task. Based on this, it is not appropriate the finding on a robust backbone is a novelty of this paper.\n\n2.[clarity] Without a change in architecture, how can the detector achieve a faster inference speed?\n\n3.[novelty] While the previous adversarial training does not use adversarially robust backbones,  switching the backbone is not something new, and the robust backbone is not a contribution of this paper. Plus, a robust backbone has demonstrated its importance in previous works. Even if the previous work is a workshop paper, it is at least published instead of a preprint. So we have to take it into account. I would treat this point differently if the mentioned paper is merely an unpublished preprint -- but it is not."
            },
            "questions": {
                "value": "See weaknesses.\n\nI'd recommend Weak reject. This is a good paper, and shows good findings. But, the proposed \"new recipe\" only involves two parts (1) robust backbone, and (2) fast adversarial training. The two parts are not original, and are borrowed from the classification domain. Overall, the technical contribution does not sound sufficient for ICLR, especially given that the core conclusion has been revealed by other publications already. If this paper is submitted before the arxiv timestamp of the segmentation paper mentioned above, I would have written something different. I appreciate more on original ideas instead of simply borrowing existing works from a different domain."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission228/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807168193,
        "cdate": 1698807168193,
        "tmdate": 1699635948289,
        "mdate": 1699635948289,
        "license": "CC BY 4.0",
        "version": 2
    }
]