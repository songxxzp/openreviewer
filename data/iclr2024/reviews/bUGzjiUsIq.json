[
    {
        "id": "8CAk5tpHQZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_svcR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_svcR"
        ],
        "forum": "bUGzjiUsIq",
        "replyto": "bUGzjiUsIq",
        "content": {
            "summary": {
                "value": "In this submission, authors investigate the understudied problem of partially annotated multi-label classifcation, where  only a subset of positive classes is annotated. To deal with this problem, authors propose a new method named Partially Annotated reinforcement learning with a Policy Gradient algorithm (PAPG) which can overcome the challenges associated with a scarcity of positive annotations and severe label imbalance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem, partially annotated multi-label classifcation, is novel.\n\n2. A novel method named PAPG is proposed, which can overcome the challenges associated with a scarcity of positive annotations and severe label imbalance. \n\n3. Experiments validate the effectiveness of the proposed PAPG method."
            },
            "weaknesses": {
                "value": "1. The motivation might be unreasonable. As stated in abstract, \"This task encounters challenges associated with a scarcity of positive annotations and severe label imbalance\". These challenges are indeed problem to deal with, but in my opinion, the main challenges correspond to that the negative samples are unknown or we do not know which are negative samples among the remaining unlabeled samples. In other words, the main challenges are the same as PU learning.\n\n2. For the two challenges mentioned in this paper, i.e., a scarcity of positive annotations and severe label imbalance, it is unclear how can the proposed PAPG method overcome them.\n\n3. As stated in Introduction, \"Consequently, many advanced methods of PU learning (Su et al., 2021; Acharya et al., 2022; Luo et al., 2021) cannot readily adapt to our multi-label settings\". In my opinion, if we focus each label one by one, it is a PU learning problem. Thus, the partially annotated multi-label classifcation problem can be solved via binary relevance strategy where the base classifier is trained with any off-the-shelf PU learning methods.\n\n4. For multi-label classification, it is very important to model the correlations among labels. But it is unclear how can the proposed PAPG method model label correlations.\n\n5. The writtting can be greatly improved. For exampe:\n(1) The title is inappropriate.\n(2) Errors exist in notations (especially the first paragraph in section 3.1).\n(3) What does RARL mean in the last sentence of this paper?"
            },
            "questions": {
                "value": "If author disagree with my comments in Weaknesses, please clarify them in the rebuttal phase."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2768/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697437207677,
        "cdate": 1697437207677,
        "tmdate": 1699636219850,
        "mdate": 1699636219850,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tTpUcYHcR9",
        "forum": "bUGzjiUsIq",
        "replyto": "bUGzjiUsIq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_Ab3u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_Ab3u"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the problem of partially annotated multi-label classification, where only a subset of positive classes is annotated, leading to imbalanced and challenging learning scenarios. The proposed idea exploits reinforcement learning and designs local rewards assessed by a value network and global rewards assessed by recall functions to mitigate class imbalance issues. The proposed approach is evaluated across various classification tasks and demonstrates its effectiveness in improving upon previous methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Multi-label annotations are challenging. Partial labeling is a great way to alleviate labeling overheads.\n\n- The approach introduced in the paper is straightforward, aligning with intuitive problem-solving strategies. It offers a clear and understandable solution to the challenges at hand."
            },
            "weaknesses": {
                "value": "- The literature survey for weakly supervised learning in this paper is incomplete. The survey only covers some settings under multi-class single-label scanrio and misses the weak supervion under multi-label learning, such as missing-label learning. This miss is critical as the major novelty of this paper comes from proposing method in this setting. The comparisions with such methods are also missing, so that the effectiveness of the proposed method is not well supported. The baselines are considerably inadequate, and the results on some famous multi-label classification dataset, such as NUS-WIDE dataset, are missing.\n\n- The proposed method itself is simple and straightforward. Therefore, it would be better to further analyze the design choices of the proposed model to claim the impact of the proposed method. For example, why is the loss function used? Is there any better option for the authors to try for the loss function?"
            },
            "questions": {
                "value": "It would be better to add several more results in the main paper, and the novelty is debatable."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2768/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697733089805,
        "cdate": 1697733089805,
        "tmdate": 1699636219757,
        "mdate": 1699636219757,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3bMStCZkhi",
        "forum": "bUGzjiUsIq",
        "replyto": "bUGzjiUsIq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_QJLy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_QJLy"
        ],
        "content": {
            "summary": {
                "value": "The proposed methods explore a new approach on partially annotated multi-label classification by using RL-based framework. The approach contains a local rewards assessed by a value network and global rewards assessed by recall functions to guide the learning of policy network. The experiments on binary image classification, multi-label image classification, and document-level relation extraction show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The proposed methods explore a pretty interesting direction (RL based design) on partially annotated multi-label classification.\n\n+ the paper is well-organized and have clear figures and demonstrations.\n\n+ The paper is technically sound and provide necessary analysis.\n\n+ The author test the algorithm on multiple tasks."
            },
            "weaknesses": {
                "value": "- usually the algorithms contain the DRL methods will have a relatively higher variance on the performance. May I know what is the variance of your model's F1 and mAP in multi-label image classification?\n\n- How many time did you repeat your experiments?"
            },
            "questions": {
                "value": "- How large is the computation overhead in algorithm compared with the standard supervised learning?\n\n- What will be the obstacles if you run this algorithm on a very large image dataset compared to the standard supervised learning? For example, 9 million partially annotated training images (OpenImages V6)? \n\n- How many time did you repeat your experiments? May I know what is the variance of your model's F1 and mAP in multi-label image classification?\n\n- It would be better if you can show a figure reflecting the training process, e.g., x-axis: training steps, y-axis: accumulated reward or mAP."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2768/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697966022399,
        "cdate": 1697966022399,
        "tmdate": 1699636219691,
        "mdate": 1699636219691,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BUjMQpXZdY",
        "forum": "bUGzjiUsIq",
        "replyto": "bUGzjiUsIq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_LdF2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2768/Reviewer_LdF2"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the PAPG framework to deal with the partially annotated multi-label classification.\nIt first discussed the partially annotated learning in the multi-label classification tasks, which bears great significance.\nAnd then proposed the local and global rewards which is the main contribution of this paper.\nWith an iterative training strategy, PAPG gains good results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper touches on the partially annotated multi-label classification, which is an area of great significance.\n2. This paper has some experiments to support its conclusions.\n3. This paper is easy to follow, especially the descriptions of the modelling process of RL in Sec. 3.2, which is very clear.\n4. The proposed PAPG gains promising results on multiple benchmarks."
            },
            "weaknesses": {
                "value": "1. Methods do not support assertions.\nThis paper claims the local reward is the immediate reward in Sec. 1. and it provides immediate value estimation of each action in Sec. 3.2\nHowever,  these immediate rewards are summed up in dimension $C$ to get the final reward according to Eq. 3.\nIt does not have immediate properties.\nIt has the same frequency as the global reward.\nIf this problem is not well explained, then this problem will be fatal.\nI see no reason to use RL for this task.\n\n2. Poor formula expression. It is shown in \"Question\" part of my review."
            },
            "questions": {
                "value": "1. Whether $\\theta$ or $\\theta^*$ is used in getting $\\overline{\\mathcal{y}}$ in line13 of Algorithm 1.\n2. I am confused with this formula, $\\hat{y}^c_i=V_\\lambda(x_i)_c=1$. Please explain the process and meaning of it.\n3. I think the dataset for the training value network is $(X, Y, \\overline{Y})$, not $(X, Y \\cup  \\overline{Y})$, according to Eq. 4.\nIt uses $ Y$ and $\\overline{Y})$ , not $Y \\cup  \\overline{Y}$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2768/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2768/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2768/Reviewer_LdF2"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2768/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698717274536,
        "cdate": 1698717274536,
        "tmdate": 1699636219620,
        "mdate": 1699636219620,
        "license": "CC BY 4.0",
        "version": 2
    }
]