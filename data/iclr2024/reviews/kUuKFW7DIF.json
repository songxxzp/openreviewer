[
    {
        "id": "WTBQGRPci4",
        "forum": "kUuKFW7DIF",
        "replyto": "kUuKFW7DIF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_nPyR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_nPyR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed to improve the self-supervised learning (SSL) method for speech signal by applying the multiple resolution processing. The motivation is to capture varying levels of information present at different resolution of speech signal. Specifically, a hierarchical Transformer is incoperated into the HuBERT-style masked prediction based model architecture. Experimental results on LibriSpeech, SUPERB and ML-SUPERB demonstrateds superior performance compared to the original HuBERT method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1, This paper proposed new innovative method to deal with a classical problem. Self-supervised learning (SSL) has been widely studied in the past several years to leverage the unlabeled data for deep learning. This paper tackled the SSL probelm from the model architcture aspect that performed the task of multi-resolution masked units prediction. As speech signal carries both short-term and long-term characterstics, e.g., semantic level, acoustic level, etc., applying multi-resolution processing is indeed a reasonable way to analyze speech signal. While it's been applied in other domain of speech area, this paper applies it on SSL for the first time. Their contribution not only comply with this paper, but also opens a door for more potential work in this area in the future.\n\n2, The experiments are comprehensive, clearly demonstrating the effectivness of the proposed method."
            },
            "weaknesses": {
                "value": "The writing/presentation of the paper could be improved."
            },
            "questions": {
                "value": "1, Have you or are you considering to evaluate your method on the ASR accuracy on the real conversational data, e.g., AMI, ICSI, Ali-meeting, etc. ? If you have already done with these evaluations, how is the performance compared with the original HuBERT method?\n2, In the paper, it seems two types of resolution are adopted in the method. What the performance will be if you increaes the resolution types to 3 or more?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Reviewer_nPyR"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2381/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698618901066,
        "cdate": 1698618901066,
        "tmdate": 1699636173352,
        "mdate": 1699636173352,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "53ieuJAhXU",
        "forum": "kUuKFW7DIF",
        "replyto": "kUuKFW7DIF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_hKsL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_hKsL"
        ],
        "content": {
            "summary": {
                "value": "The authors investigate a multi-resolution evolution of HuBERT, MR-HuBERT, which augments the HuBERT architecture by integrating a lower time resolution (40 ms) transformer into the model, in addition to the standard higher resolution (20ms) processing (c.f. Figure 1).\n\nExtensive experiments on the well known LibriSpeech, SUPERB, and ML-SUPERB datasets are conducted, and indicate that MR-HuBERT generally performs on-par or better than HuBERT, and significantly better on LibriSpeech when the amount of labelled data is very limited (1 hour).\n\nIn addition, inference speed in terms of Multiply-Add Cumulations (MACs) is reduced by 9% and 13% by the base and large variants of MR-HuBERT relative to HuBERT."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- To the best of my knowledge, MR-HuBERT is the first approach to explicitly address the integration of multi-resolution information into the pre-training of a single model, as claimed.\n- Solid performance relative to HuBERT, with strong gains over appropriate baselines when limited task data is available.\n- Extensive evaluations on important datasets, at multiple operating points in terms of masked pre-training (e.g. 60K vs 960 hrs) and labeled data (e.g. 1,10,100 hrs of Librispeech).\n- Extensive appendix with detailed additional results and ablations.\n- Code and models will be publicly released."
            },
            "weaknesses": {
                "value": "- Somewhat lower in ML novelty, as a more straightforward evolution of HuBERT.\n- As acknowledged (limitations, appendix E), MR-HuBERT was not trained on augmented data like WavLM, leaving this as future work, and so performance lags behind WavLM. \n- The important section on MR-HuBERT's architecture (3.2) could be improved. The processing steps are adequately described, and Figure 1 is for the most part clear enough, but with several functions f and outputs H, the relation between figure 1 and the description could be better---is equation 2 correct? Also, the operators in (eq. 2) and (eq. 3) should be introduced, as should $\\phi$. Are the high resolution encoders in figure 1 the same?\n- MACs are not usually a strong indication of inference speed on GPUs. This should be quantified further and/or perhaps de-emphasized in the abstract, as appropriate.\n- minor: speech Self-Supervised Learning (SSL) models -> Self-Supervised Learning (SSL) speech models\n- minor: we evaluate MR-HuBERT at two resolutions -> we evaluate a two resolution variant of MR-HuBERT"
            },
            "questions": {
                "value": "See previous section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2381/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699118615345,
        "cdate": 1699118615345,
        "tmdate": 1699636173181,
        "mdate": 1699636173181,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9cVzck24xY",
        "forum": "kUuKFW7DIF",
        "replyto": "kUuKFW7DIF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_vPyr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_vPyr"
        ],
        "content": {
            "summary": {
                "value": "The authors propose an extension of HuBERT armed with multi-resolution perception and understanding capability. The authors show the proposed methods generally outperform HuBERT with sizable improvements in, if not full stack, a wide range of speech tasks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of multi-resolution encoder makes a lot of sense as acoustic concepts typically happen with different rates, and different speech tasks also require features with diverse granularity. According to the self-contained review on related works, this work, if not the first one, is among the early explorations on using multi-resolution encoder for self-supervised speech representation learning. Some bullet points:\n\n1. The proposed method achieved sizable improvement in the SuperB evaluation series. \n\n2. The proposed method exhibits computational efficiencies, specifically a 9-13% reduction in computation.\n\n3. The authors conducted extensive ablation studies to understand the effectiveness of different components. Detailed hyper parameters are also shared for reproducing purposes."
            },
            "weaknesses": {
                "value": "My major concerns are:\n\n1. The ASR performance is not really better comparing to HuBERT.\n\n-- According to Table one, the proposed method is better than HuBERT when the hours of labeled speech is no more than 10; However, as we scaled up the labeled speech, HuBERT shows better performance in dev. \n\n-- According to SuperB evaluation, HuBERT large is still better (though not much) compared to the proposed method. \n\n\n2. One major invention, the sampling module that employs a blend of upsampling and downsampling to achieve flexible ratio between any two resolutions, do not show clear benefits when compared to just simple sampling module. \n\n-- According to Table 10, the proposed sampling strategy only becomes more powerful when using 100 hour of labeled speech, and the benefit is not significant. When only using 1 and 10 hour of labeled speech, the simple sampling strategy is actually doing better in terms of ASR. \n\n-- According to Table 18, it shows different design choices and configurations would clearly affect the downstream performance, and there is on clear winner."
            },
            "questions": {
                "value": "I agree that the multi-resolution ideas is interesting, and the authors\u2019 model do achieve very promising performance according to SuperB evaluation. My main questions have been posted in 'Weakness' section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Reviewer_vPyr"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2381/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699141641077,
        "cdate": 1699141641077,
        "tmdate": 1700968850432,
        "mdate": 1700968850432,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tjViRAquXU",
        "forum": "kUuKFW7DIF",
        "replyto": "kUuKFW7DIF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_MxEg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2381/Reviewer_MxEg"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel approach to multi-resolution pre-training for speech, designed to leverage information at various resolutions effectively. The authors demonstrate performance improvements in several downstream tasks, such as speech recognition, when compared to the prior work HuBERT."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper proposes a novel method for pre-training speech data at multiple resolutions within one model. The improvements on several downstream tasks are significant when using unlabelled data at different scales. The figures and tables are also well presented."
            },
            "weaknesses": {
                "value": "There're two problems need to be solved before acceptance.\n1. The positions of $f_1^q$ and $f_2^q$ are reversed in equation 2. According to your description, the $\\tilde{H}_0$ is first processed by $f_1^q$.\n2. In HuBERT, there's only one output sequence, so it is sent to a CTC layer when fine-tuning. However, in MR-HuBERT, there're two output sequences. How are the two sequences of different lengths combined and sent to CTC? I didn't find the details in the paper."
            },
            "questions": {
                "value": "See the two problems listed in the above weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2381/Reviewer_MxEg",
                    "ICLR.cc/2024/Conference/Submission2381/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2381/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699303148337,
        "cdate": 1699303148337,
        "tmdate": 1699732825398,
        "mdate": 1699732825398,
        "license": "CC BY 4.0",
        "version": 2
    }
]