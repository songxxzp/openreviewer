[
    {
        "id": "Uo6NuFd7Lb",
        "forum": "wgmOXVTGdb",
        "replyto": "wgmOXVTGdb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_t8xx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_t8xx"
        ],
        "content": {
            "summary": {
                "value": "In this paper, VAE and GAN are combined with DETR to realize multimodal layout generation. A large-scale ad banner data set with 7,196 samples containing English characters is presented. According to the experimental results of three data sets on ad banner, CGL, and CLAY, the method achieves SOTA performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper is easy to follow. \n\n* A large-scale ad banner dataset is collected for the layout design task.\n\n* The results show that the model achieves excellent performance."
            },
            "weaknesses": {
                "value": "* Many technical details are not well-motivated and validated, e.g., VAE and DETR structures. \n\n* It seems the method combines multiple popular techniques and the novelty in the technical part is unclear. \n\n* Simply considering the box layout and ignoring font information and box aspect ratios makes the task less extensible. \n\n* The method requires dozens of loss functions for supervision. I am not sure how to tune weighting factors and make sure each term properly works."
            },
            "questions": {
                "value": "The importance and necessity of VAE design is not validated. As the method takes a generative pipeline, I am interested in the variations and the latent spaces. Moreover, a proper validation of this key design is also important."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Reviewer_t8xx"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8305/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698068896482,
        "cdate": 1698068896482,
        "tmdate": 1701053026905,
        "mdate": 1701053026905,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IWN3wBIsIu",
        "forum": "wgmOXVTGdb",
        "replyto": "wgmOXVTGdb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_EPYk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_EPYk"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed LayoutDETR which can inherit high quality and realism from generative modeling, while reformulating content-aware requirements as a detection problem. It learns to detect in a background image the reasonable locations, scales, and spatial relations for multimodal foreground elements in a layout."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- study layout generation and visual detection with a unified framework\n- proposed a new banner ads dataset\n- achieve state of art in layout generation in terms of metrics of realism, accuracy, and regularity\n- built graphical system and conduct user study"
            },
            "weaknesses": {
                "value": "- the empty space detection on a background image and the layout generation of foreground can be decoupled as two separate steps. It is better to compare with such a baseline, and justify the superiority of doing it with a joint model.\n- the proposed dataset (images) is collected in prior work. The new contribution here is the detected text objects, background inpainting and the text class annotation, which is not as significant as a new dataset.\n- There are some concerns about the quality of data set. According to the way the data set was constructed, there are only texts as foreground objects, without other elements such as vector shape, image. This is very limited. Also, the inpainted background may contain artifacts which the generator can leverage for text location prediction. How is the text image patch obtained? If it's cropped from the original image, it has the same background patten, which may contain shortcut information for layout prediction."
            },
            "questions": {
                "value": "- please clarify whether there are only text as foreground object in the dataset and all the experiments.\n- why Crello dataset is not multi modal? What is the unique part of the proposed data set?\n- explain whether it's possible to apply this paper to the problem: \"Towards Flexible Multi-modal Document Models\"\n- Eq 6, should it be p_1^i ?\n- the paper does not evaluated diversity of the generated results. It would be good to show some visual examples of different design variations for one background image."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The banner ads images may contain copyright logos, faces, or other protected images."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8305/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698559306786,
        "cdate": 1698559306786,
        "tmdate": 1699637032738,
        "mdate": 1699637032738,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gxanZlwP8v",
        "forum": "wgmOXVTGdb",
        "replyto": "wgmOXVTGdb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_Gw2u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_Gw2u"
        ],
        "content": {
            "summary": {
                "value": "The paper studies graphic layout generation conditioned multimodal inputs, including background image, foreground image and text.\n\nThe main contribution is to adapt an exciting Transformer-based detector architecture as a content-conditioned layout generator and explore its training under different generative frameworks including GAN, VAE and VAE-GAN.\n\nA new ad banner dataset with rich semantic annotations is created and will be released for the training and evaluation of generative models for graphic layouts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is studying an important problem. Conditioning layout generation models on rich contents will certainly make the models more practically useful.\n\n2. The newly constructed banner dataset with detailed and rich annotations can be of value to the layout generation community.\n\n3. The evaluation is extensive and the results look good."
            },
            "weaknesses": {
                "value": "1. The amount of technical contribution is small. While I appreciate the great effort that has been input into the work on building the system, testing different design choices and building the banner dataset, I think technical novelty and insight brought by the paper is limited. The whole work is more like constructing a working system by borrowing techniques from another domain directly (e.g., DETR) and combining components from other existing layout methods, e.g., (Kikuchi et al., 2021) and (Li et al., 2020), without any significant modification. Thus, the paper may not be of great interest to the ICLR audience, and perhaps fits better with more system-oriented conferences or journals.\n\n2. The evaluation is insufficient. The paper is aimed at conditional layout generation. However, all the quantitative metrics as well as the user study only evaluate layout quality, and another important aspect of results is ignored \u2014 how well generated layouts match the input contents. Thus, an experiment on layout-content consistency is needed but is missing in the current paper."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8305/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698570998029,
        "cdate": 1698570998029,
        "tmdate": 1699637032600,
        "mdate": 1699637032600,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZFxziQX8bw",
        "forum": "wgmOXVTGdb",
        "replyto": "wgmOXVTGdb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_j8Mq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8305/Reviewer_j8Mq"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the layout generation task by reformulating it as a detection problem. A transformer-based architecture, i.e., LayoutDETR, is proposed to detect reasonable locations, scales and spatial relations for elements in a layout. A new banner dataset is established with rich semantic annotation. The proposed solution is further integrated into a graphical system to scale up the layout generation process."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of applying the visual detection framework for the layout generation task is interesting and effective. The collected could be useful for future research in the community. The experimental results show the effectiveness of the proposed method under six evaluation metrics."
            },
            "weaknesses": {
                "value": "1. The first contribution of this paper is that no existing methods can handle all those modalities at once. However, as shown in Table 1, Vinci can also use these modalities as conditions.\n2. The computation cost analysis of the proposed solution is missing. Since the model contains a variety of input modalities, I was wondering about the computational cost and runtime analysis of the proposed method and existing works.\n3. It would be better to show the diversity of the generated layouts and discuss the limitations of the proposed method."
            },
            "questions": {
                "value": "1. How to distinguish the foreground image and the background image if the background images are defined with arbitrary sizes?\n2. Why Image FID that uses image features pre-trained on ImageNet could be used to evaluate the quality of the rendered graphic designs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8305/Reviewer_j8Mq"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8305/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698676649816,
        "cdate": 1698676649816,
        "tmdate": 1699637032479,
        "mdate": 1699637032479,
        "license": "CC BY 4.0",
        "version": 2
    }
]