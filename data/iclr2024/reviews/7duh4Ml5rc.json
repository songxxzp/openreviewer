[
    {
        "id": "5gBq2WJEFJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission41/Reviewer_egTB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission41/Reviewer_egTB"
        ],
        "forum": "7duh4Ml5rc",
        "replyto": "7duh4Ml5rc",
        "content": {
            "summary": {
                "value": "This paper presents a control system perspective of the ANNs training process and views the training algorithms as controllers. In addition, the authors analyzed several optimization methods (SGD, SGDm, AdaM, PID, LPF-SGD, HPF-SGD, Fuzzy PID) on different types of ANNs (CNN, FFNN, GAN, CycleGAN, ResNet). Through experimental studies, the authors conclude that different ANNs should use different training algorithms to achieve their best performance."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The control system perspective on the ANN training process is nice, although it is not new. Combining PID controller and fuzzy logic is novel to the best of my knowledge. There is a potential that the Fuzzy PID controller can actually improve the training process."
            },
            "weaknesses": {
                "value": "The presentation quality of the current manuscript can be further improved. \n\nThe novelty of this paper is weak. The idea of interpreting ANN training as controller design is not new. The idea of Fuzzy PID is new but incremental compared to [Wang2020]. In addition, the authors did not show the advantage of Fuzzy PID compared to other optimizers in the numerical section. It would be great if the authors could provide a rigorous proof of the convergence of the training algorithms through the lens of stability theory in control literature.  \n\nThe dataset used in the numerical section is limited, and the model used in this part is too simple and unrepresentative. The results obtained in the main paper are inconsistent with those in the appendix (Figure 2 vs. Figure 15)."
            },
            "questions": {
                "value": "1. Eq 2: it is abnormal to have 'text' in an equation. Many variables in Eq 7 are not well introduced. \n2. In section 2, what is theta_0? is it the weight of a specific node? Do you only consider one node here?\n3. Eq 1: how can we know the value  theta^* ahead? More details on the derivation of eq 1 to 5 is needed.\n4. In Figure 1, what is the output? is it the output of the ANN model of the model weight? This figure is a bit confusing.\n5. Under eq 15, why the system FFNN is stable under that inequality condition? Could you please explain more?\n6. In Table 1, the results for LPF-SGD are strangely low, any intuition? \n7. From Fig 2(b) and 2(c), AdaM clearly is the best one, why the stability of AdaM is bad? Also, the expression \"stability is a lower\" does not make sense from a control perspective, you either say stable or unstable. \n8. From Fig 14-15, it seems that SGD and SGD-m works better than Fuzzy PID, PID, and AdaM for larger dataset and other models. This is very different than the case for MINIST results as shown in Fig 2, why is this? Any intuition?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission41/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697387454710,
        "cdate": 1697387454710,
        "tmdate": 1699635928258,
        "mdate": 1699635928258,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C9xH4Xeufy",
        "forum": "7duh4Ml5rc",
        "replyto": "7duh4Ml5rc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission41/Reviewer_jZKP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission41/Reviewer_jZKP"
        ],
        "content": {
            "summary": {
                "value": "This paper interprets the training of neural networks as a feedback controller on the parameter of the network. Several commonly used training algorithms are interpreted as proportional or PI controllers."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "+ Neural network training, or understanding why neural network training works is an interesting question. \n+ The interpretation in the paper is interesting and uses control theoretic ideas that are well-known."
            },
            "weaknesses": {
                "value": "- The technical problem considered in the paper is too simple to represent training of neural networks in my opinion. In particular, it assumes there is a single equilibrium, $\\theta^*$, and the feedback is in the error between $\\theta$ and $\\theta^*$. A better model would be that we have the output $y(\\theta)$, for example, the loss on the training set. But there are many $\\theta$'s that give the same loss. For example, suppose that we can make the training loss 0, and $y(\\theta_1*)=y(\\theta_2*)=...=y(\\theta_n^*)=0$ for some $n$. The challenge is that $n$ maybe very large, we don't know any of the $\\theta_i^*$, and the feedback is on the error in $y$. The system is actually nonlinear, with many equilibriums, and convergence is much harder to understand."
            },
            "questions": {
                "value": "Looking at some nonlinearities would help. For example, just having one layer of ReLU, and see if the theory in the paper still works."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission41/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission41/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission41/Reviewer_jZKP"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission41/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700245882,
        "cdate": 1698700245882,
        "tmdate": 1699635928100,
        "mdate": 1699635928100,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5r7iLAMgKp",
        "forum": "7duh4Ml5rc",
        "replyto": "7duh4Ml5rc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission41/Reviewer_WG3Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission41/Reviewer_WG3Y"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the point of view of considering optimization neural networks as a control problem. They then investigate different known optimizers and controllers on a set of tasks.  I had great difficulty understanding the logic of this paper, my best guess is that the goal is to understand why certain optimizers are chosen for specific tasks in deep learning."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- I like that more recent neural network architectures such as  forward-forward neural network are considered\n- In general the view of neural network training from the perspective of control and the respective methodology (like PID and fuzzy controllers) is of interest\n- In general the paper tries to adress different domains, such as GAN-like training, vision, and feedforward neural networks"
            },
            "weaknesses": {
                "value": "- The paper is written very poorly. It is very difficult to understand what the intentions of the the authors are. There are countless examples, starting with the title: \"Based on What We Can Control Artificial Neural Networks\"   Other examples include for instance \"To analyze the learning progress of most ANNs, for example, CNN using backpropagation algorithm, FFNN using forward-forward algorithm, and GAN such a generative model using random noise to generate sample\" (page 2)\n\n- I don't see how the experiments make sense given the research question. It look to me that standard classification tasks are considered, with standard architectures and evaluations."
            },
            "questions": {
                "value": "Could you answer in simple terms:\n1. What are the contributions of this paper?\n2. Why is the perspective of \"optimizers are controllers\" relevant?\n3. What are the research questions you are trying to answer with the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission41/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699098948558,
        "cdate": 1699098948558,
        "tmdate": 1699635927982,
        "mdate": 1699635927982,
        "license": "CC BY 4.0",
        "version": 2
    }
]