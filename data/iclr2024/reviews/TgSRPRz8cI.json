[
    {
        "id": "mKTMC6nhvk",
        "forum": "TgSRPRz8cI",
        "replyto": "TgSRPRz8cI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_oyqb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_oyqb"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new feature collage strategy for the generative diffusion model to avoid boundary artifacts when synthesizing large-size images, termed Patch-DM. Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space. Experiments reveal the superiority of 1K resolution generation results on several datasets with 64\u00d764 patches."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper proposes a new feature collage strategy for generative diffusion model to avoid boundary artifact when synthesizing large-size images."
            },
            "weaknesses": {
                "value": "1.\tThe novelty is relatively small and the impact of this paper may be limited since the proposed method only focuses on the boundary artifacts produced by the patch collage.\n2.\tLacking comparisons with aggregation sampling strategies proposed in StableSR [1], the sampling strategy in StableSR can be performed without more parameters and training. \n3.\tThe experiments only measure models with FID, lacking results measured under other metrics, e.g., CLIPScore.\n4.\tFigures 5 and 6 look confusing. (Which pictures are from which datasets or methods seem to be unclear)\n\n[1] Wang, J., Yue, Z., Zhou, S., Chan, K. C., & Loy, C. C. (2023). Exploiting Diffusion Prior for Real-World Image Super-Resolution. arXiv preprint arXiv:2305.07015."
            },
            "questions": {
                "value": "Can the model be performed to generate images of more than 1K or arbitrary resolutions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1444/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1444/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1444/Reviewer_oyqb"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1444/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698320462119,
        "cdate": 1698320462119,
        "tmdate": 1699636073068,
        "mdate": 1699636073068,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0Z4K6x4fOr",
        "forum": "TgSRPRz8cI",
        "replyto": "TgSRPRz8cI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_Tdt5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_Tdt5"
        ],
        "content": {
            "summary": {
                "value": "This work aims to resolve the limitation of the existing diffusion models towards generating high-resolution images. To this end, the authors present the ideas of feature collage, position embedding, and global conditioning to develop a unified approach, namely Patch-DM, to generate high-resolution images. Moreover, potential applications of outpainting and inpainting are also demonstrated. Comparisons on low-resolution images are conducted to reveal that the proposed method doesn't underperform by a large margin compared to other methods. Comparison of high-resolution images reveals that the proposed method achieves state-of-the-art results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The ideas of feature collage, position embedding, and global conditioning and their impact on image generation is interesting.\n2. The proposed method achieves state-of-the-art results on high-resolution image synthesis"
            },
            "weaknesses": {
                "value": "1. On Low resolution image synthesis as in Table 2, the proposed method is not comparable to that of state-of-the-art. \n2. Some of the implementation details, reasoning behind choices, are missing in the description. Please refer to the comments under Questions for details."
            },
            "questions": {
                "value": "1. Section 5.2: Since every image is segmented into smaller patches, the total number of model parameters is much smaller than other large diffusion models. => The computations might be lesser, why should the number of model parameters be lesser? Authors argue that they use light weight models, but it\u2019s unclear what architectural changes they made for it as compared to existing diffusion models, and how those changes are justifiable. In fact, authors might be able to generate better quality images with heavier architectures and make Table 2 performance comparable to that of previous diffusion models. \n\n2. Beyond patch generation: The first one is to add patches inside the original images so that the generated images can have a 2\u00d7 resolution compared to the ones in the training dataset. => Why do we need to add patches to original images? During test time the images are supposed to be generated from random noise and hence there is no need for adding patches to original images. This sentence is confusing and should be rewritten for clarity. Also the position embedding adaptations is not well explained, so is the reason for different choices with respect to the two methods mentioned under this category.\n\n3. Image inpainting: No details of the position embedding and the related changes is mentioned in this case. \n\n4. Image inpainting: The details could be incomplete. It is unclear how the original contents in the non-masked region is maintained in the output. Why is the global embedding not used?\n\nMinor Fix: \n- Section 5.2, still be \u201drecovered\u201d during => still be ``recovered'' during"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1444/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698480294040,
        "cdate": 1698480294040,
        "tmdate": 1699636072979,
        "mdate": 1699636072979,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aQCy0Oy3ff",
        "forum": "TgSRPRz8cI",
        "replyto": "TgSRPRz8cI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_3rts"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_3rts"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a patch-based denoising diffusion model called Patch-DM for generating high-resolution images. The key contributions are: 1. Introduces a feature collage strategy to avoid boundary artifacts when synthesizing images from patches. It combines partial features from shifted patches to predict features for a new patch. 2. Achieves state-of-the-art FID scores on 1024x512 natural images and 1024x1024 LSUN/FFHQ images using a lightweight model. 3. Demonstrates Patch-DM can directly generate high-fidelity 1K resolution images with minimal patch boundary effects. 4.Reduces memory complexity compared to full-image diffusion models for high-res synthesis. 5.Shows applications like image outpainting, inpainting, super-resolution without any post-training. 6. Validates through ablation studies that feature collage is better than pixel collage for spatial consistency. 7. Provides an effective patch-based generative modeling approach using diffusion models for high-resolution image synthesis with reduced costs."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "\u2022\tProposes Patch-DM, a novel patch-based denoising diffusion model that can generate high-resolution images directly without relying on hierarchical sampling. This simplifies the sampling procedure.\n\u2022\tIntroduces a new feature collage strategy to avoid boundary artifacts when synthesizing images from patches. It forces consistency by combining partial features from shifted patches.\n\u2022\tAchieves state-of-the-art FID scores on generating natural images and LSUN/FFHQ images using a lightweight model, outperforming prior patch-based methods.\n\u2022\tQualitative results show Patch-DM can produce high-fidelity 1K resolution images with minimal patch boundary effects."
            },
            "weaknesses": {
                "value": "\u2022\tBased on my experience and recent related publications (e.g., \"Weather Diffusion-PAMI'23\"), patch-based diffusion models often lead to reduced inference efficiency. I hope the authors can provide specific comparisons of inference time and overall efficiency, especially compared to previous GAN methods.\n\u2022\tThe proposed method has limited technical contributions. The authors did not provide detailed explanations or theoretical justifications to explain why the Patch Collage in Feature Space strategy can avoid artifacts. Furthermore, the research and exploration of Semantic Code are not sufficiently in-depth.\n\u2022\tThe authors should provide a quantitative comparison of image inpainting and image outpainting results. Quantitative results would better demonstrate the superiority of the proposed method."
            },
            "questions": {
                "value": "\u2022\tWhy does the Patch Collage in Feature Space strategy avoid artifacts? Can a detailed analysis and explanation be provided? This is crucial for future work.\n\n\u2022\tWhat is the running speed of the proposed method? How much slower does the Patch Collage in Feature Space strategy make the model inference speed?\n\n\u2022\tWhat are the limitations or further areas of exploration for the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1444/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762839789,
        "cdate": 1698762839789,
        "tmdate": 1699636072910,
        "mdate": 1699636072910,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4YYTO2QybW",
        "forum": "TgSRPRz8cI",
        "replyto": "TgSRPRz8cI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_7jCc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1444/Reviewer_7jCc"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a denoising diffusion model, Patch-DM, for generating high-resolution images (e.g., 1024\u00d7512), trained on small-size image patches (e.g., 64\u00d764). The major contribution of the paper is a new feature collage strategy, which is designed to avoid the boundary artifact when synthesizing large-size images. The authors demonstrate the effectiveness of  Patch-DM on mage synthesis results on their newly collected dataset of nature images (1024\u00d7512), as well as on standard benchmarks of LHQ(1024\u00d7 1024), FFHQ(1024\u00d7 1024) and on other datasets with smaller sizes (256\u00d7256), including LSUN-Bedroom, LSUN-Church, and FFHQ. The show state-of-the-art FID scores on all six datasets for the proposed model. Further, Patch-DM also reduces memory complexity compared to the classic diffusion models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper is reasonably well written and easy to follow \n2)  The quantitative results demonstrated in Table 1 and Table 2 shows that the model outperforms state of the art."
            },
            "weaknesses": {
                "value": "1) The paper is not sufficiently novel. I'm not working in this domain, but the only novel part that the authors state is creating the collage of the patches in the feature / latent space based on their spatial embeddings. This does not sound like something that has not been done before in the field of image generation. It would  be helpful if the author come up with a more comprehensive literature survey that provides more related works to this particular  design choice and clearly shows the difference. For example, from a short search I found the following relevant paper: [1] https://arxiv.org/pdf/2207.04316.pdf --  Improving Diffusion Model Efficiency Through Patching \n[2] https://arxiv.org/abs/2304.12526 -- Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models (note the paper was first submitted on April 2023).\n\n2) Even if we consider the combination of Patch Diffusion in the latent space sufficiently novel, from the analysis in the supplementary material, I find that faces demonstrate usual artifacts around eyes and mouse (and I think that this is happening despite training on a dedicated dataset). Midjourney models generate much better faces. It would be great to understand why the proposed model fails on those."
            },
            "questions": {
                "value": "1) Can you please add comparison to other techniques in the supplementary? It might be useful to reduce the example to great examples vs. poor examples and provide some discussion on failure modes\n2) In Table 2 - \"We bold the numbers to denote the best numbers in the same category.\" --> can you please explain what you mean by \"the same category\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1444/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818782730,
        "cdate": 1698818782730,
        "tmdate": 1699636072843,
        "mdate": 1699636072843,
        "license": "CC BY 4.0",
        "version": 2
    }
]