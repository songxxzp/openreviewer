[
    {
        "id": "4DSnJatVpv",
        "forum": "0SgPbbyrWh",
        "replyto": "0SgPbbyrWh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_KUjb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_KUjb"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method that partitions the surface of the unit hypersphere into a into a quasi-centroidal hyperspherical voronoi diagram with maximally separated generator points, which is beneficial for ANN search especially with cosine similarity. Experiments on four datasets show that OSC-LSH aperforms better than the conventional LSH approaches, such as PR-LSH and FlyLSH."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of optimal spherical codes for LSH is a natural advantage for approximate nearest neighbor search."
            },
            "weaknesses": {
                "value": "The writing is so bad with many missings or minor errors, or unclear-ness."
            },
            "questions": {
                "value": "What is the relationship between OSC and Spherical Hashing [1]?\n\n[1] Jae-Pil Heo, Youngwoon Lee, Junfeng He, Shih-Fu Chang, Sung-Eui Yoon: Spherical hashing. CVPR 2012: 2957-2964"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9173/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697961334885,
        "cdate": 1697961334885,
        "tmdate": 1699637154186,
        "mdate": 1699637154186,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Us5Pv8EIYP",
        "forum": "0SgPbbyrWh",
        "replyto": "0SgPbbyrWh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_RRUE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_RRUE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to construct LSH for nearest neighbor search by finding a set of points on the unit sphere. As separating these points on the sphere is difficult, the authors propose to learn these points by gradient descent."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1.\tThe idea is presented clearly.\n2.\tUsing optimal spherical codes to construct LSH makes sense."
            },
            "weaknesses": {
                "value": "1.\tGraph-based methods and vector quantization methods are widely used for vector search now and show significantly better performance than LSH. The authors state that \u201cWhereas graph-based techniques perform very well in low dimensions, their performance is suboptimal in higher dimensions, and cannot be used in distributed settings.\u201d This is NOT true! The HNSW paper shows that proximity graph works quite well for high dimension vectors, and the Pyramid paper uses proximity graph for distributed vector search. Also, the FAISS library uses many variants of PQ and the IVF index for vector search. I am not convinced of the practical impact of this paper unless the authors show that the proposed LSH achieves better time-recall curve than graph and quantization methods. Note that time-recall curve is a standard method to evaluate the performance of ANNS, and examples can be found in the HNSW paper.\n[1] Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs (HNSW)\n[2] Pyramid: A general framework for distributed similarity search on large-scale datasets (Pyramid)\n[3] Product Quantization for Nearest Neighbor Search (PQ)\n\n2.\tExperiments are very limited. (1) Nowadays, million or even billion scale datasets are common for vector search (check the Pyramid paper) but the authors use a datasets of 10,000, which are extremely small. (2) The proposed method needs to check every vector in the dataset to compute Hamming distance, which is infeasible for very large datasets. (3) Pls use standard time-recall curve to compare the performance of the authors in the main experiments. The influence of m/d can be used as a micro experiment to check the influence of parameters. \n\n3.\tI think the paper is not ready for publication is its current state and would benefit from substantial revision for another conference. For instance, there are multiple missing references even in the introduction. Some statements are not logical or scientific due to the lack of checking. For example, \u201cLSH\u2026, where the imperative is to swiftly identify similar items without sacrificing accuracy.\u201d, well, LSH actually sacrifices accuracy to identify similar items swiftly; \u201cTo balance between accuracy and query time, we can make sure the centroids used for the space partitioning are maximally separated\u201d, balance is a vague term, and how does maximal separation leads to such balance?; \u201cExisting LSH has \u2026(ii) limited use cases\u201d, what exactly are the use cases your proposed method can handle and existing LSH cannot?; \u201cThese methods however are limited for use with a specific hash length or embedding size\u201d, why is the case? To my knowledge, at least random projection allows to handle arbitrarily long embeddings and flexibly set the length of the embeddings. \n\n4.\tHow does the method handle more general cases, i.e., when dataset vectors are not on the unit sphere? The optimization objective in (1) is different from the max-min objective of OSC. What is the relation of the solution produced by Algorithm 1 w.r.t. the solution of OSC? Can you show that it is a good approximation?"
            },
            "questions": {
                "value": "I would suggest the authors to better prepare the manuscript for a serious submission."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9173/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698206083739,
        "cdate": 1698206083739,
        "tmdate": 1699637154078,
        "mdate": 1699637154078,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6Nrii2N1jw",
        "forum": "0SgPbbyrWh",
        "replyto": "0SgPbbyrWh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_88TD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_88TD"
        ],
        "content": {
            "summary": {
                "value": "Locality-sensitive hashing (LSH) is one of the most vital techniques for solving the approximate nearest neighbor (ANN) search. \nIn this paper, the authors introduce OSC-LSH, a new LSH scheme to enhance search efficiency using Optimal Spherical Codes (OSCs). \nThey argue that by employing optimal spherical codes, one can achieve better hypersphere partitioning and more discriminative hash codes for ANN search in high-dimensional spaces. \nThey develop an optimization algorithm to find the approximate OSC for any embedding size $m$, comparing OSC-LSH with two baselines RP-LSH and FlyHash, and showcasing its benefits through empirical results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Novel Approach: Using spherical codes as a foundation to improve the efficiency of LSH is a novel idea that has been less explored in prior work. Even though some researchers have considered cross-polytype, they did not provide a systematic investigation.\n\n2. Practicality: An optimization method is proposed to identify the approximate OSC for any embedding size $m$, making OSC-LSH practical for different scenarios.\n\n3. Empirical Results: The empirical results in the experiments demonstrate the superiority of the proposed method over traditional LSH methods in terms of both quality and speed."
            },
            "weaknesses": {
                "value": "W1. Dependency on Optimal Spherical Codes: The efficacy of OSC-LSH is tied to the quality of the spherical codes. However, as pointed out by the authors, the identification of the optimal spherical codes is computationally prohibitive, especially when $d$ (and $m$) is large. In cases where optimal codes are hard to find, this method might not offer significant improvements.\n\nW2. Ambiguity in Distortion Definition: The paper frequently references the concept of \"distortion\" when discussing the benefits of using Optimal Spherical Codes (OSC) in LSH. However, a clear and concise definition of distortion is missing, making it difficult to fully understand and evaluate the proposed method's effectiveness. While Figure 1 shows the minimum distance in a self-comparison context, it doesn't provide a comprehensive view of the distortion in the mapping process from the input space to the output space.\n\nW3. Concern of the Optimization Objective: Under the assumption that all data points are normalized, the Euclidean distance between any $c_i$ and $c_j$ is inversely proportional to their inner product. Thus, it is problematic to directly replace Euclidean distance in Equation (1) with the inner product in Equation (2). Is there any typo in Equation (2), e.g., removing the \"$-$\" or maximizing $L$?\n\nW4. Unconvincing Empirical Results.\n\nW4.1. Lack of End-to-End Comparison: While the paper compares the new approach with RP-LSH and FlyHash, it would be beneficial to see the end-to-end comparisons with other state-of-the-art ANN search methods, such as FAISS and HNSW.\n\nW4.2. Scalability Concerns: Although the authors claim they have improved the efficiency issue, the paper doesn't delve deep into the scalability of the proposed method, especially when dealing with extremely large datasets.\n\nW5. Poor Presentation: This paper seems to be written in a hurry way. For example, there exist many \"???\" and empty \"().\" The two Algorithms are isolated from the main paper, and no explanation is provided. In the experiments, they claim to use five datasets, but I failed to find the results on CIFAR10."
            },
            "questions": {
                "value": "Regarding W1:\n\nQ1: Could you provide the time complexity of finding the OSCs and discuss any alternative way to accelerate this process?\n\nRegarding W2:\n\nQ2: Can the authors provide a rigorous definition of \"distortion\" as used in the context of this paper? How is it measured, and what makes it a suitable metric for evaluating the quality of the mapping?\n\nQ3: Given the emphasis on minimizing distortion with OSC, could the authors provide comparisons with other methods in terms of this metric? This would offer a clearer perspective on the proposed method's advantages."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9173/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698656798488,
        "cdate": 1698656798488,
        "tmdate": 1699637153957,
        "mdate": 1699637153957,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CFBclpCg4N",
        "forum": "0SgPbbyrWh",
        "replyto": "0SgPbbyrWh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_d26L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9173/Reviewer_d26L"
        ],
        "content": {
            "summary": {
                "value": "The authors propose OSC (Optimal Spherical Codes) as a technique for generating sparse representations that can be used for locality sensitive hashing. The code vectors are generated by an optimization procedure that maximizes the minimum angle between any pair of code points. They show that their approach outperforms FlyLSH and random projections LSH. \n\nWhile their technique is very similar to the approach proposed by Andoni et al., the main advantage seems to be the flexibility in choosing the embedding dimension."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "There could be some (computational) advantage to the flexibility in using different embedding dimensions (though they have not explored this in the paper)."
            },
            "weaknesses": {
                "value": "1) On the datasets they consider, there is not a marked improvement over the baselines.\n2) It seems that they are performing an optimization procedure for computing the code vectors, but not actually using any data - it seems like if you are going through the trouble to optimize the code vectors then it might help to actually use the data (so that the code vectors chosen can reflect the actual underlying data distribution)."
            },
            "questions": {
                "value": "It would be useful to understand if the flexiblity in the choice of embedding dimension actually produces interesting tradeoffs (recall vs computation, etc). If not what do you see as the main advantage over Andoni et al?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9173/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814269920,
        "cdate": 1698814269920,
        "tmdate": 1699637153833,
        "mdate": 1699637153833,
        "license": "CC BY 4.0",
        "version": 2
    }
]