[
    {
        "id": "MwhFqxBvQe",
        "forum": "KZaEdLM4Gn",
        "replyto": "KZaEdLM4Gn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_89Qo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_89Qo"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a prompting method for dialog response generation. The method enables the LLM to incorporate the conceptual tools into its planning and action. It constructs three characters on the same LLM: thinker, planner, and executor. Thinker provides general guidelines; planner decides which conceptual tool to use; and executor composes the final output. Experiments are conducted on two dialog response generation tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The problem of incorporating conceptual tools is interesting and significant. \n- The paper compares with various approaches."
            },
            "weaknesses": {
                "value": "- The paper is poorly written. Many key concepts are not clearly defined. The method description is difficult to follow. Details about the experiment tasks are missing like what these tasks are about and how the evaluation metrics are computed. \n- The approach is simply multi-persona prompting, which has been done in various papers (the authors also cited those papers). I do not see a significant novelty compared to previous approaches. \n- The approach requires too much human knowledge in designing the prompt. The prompt is highly customized to the problem setting. \n- The approach relies entirely on the LLM capability of interpreting the prompt.  \n- Performance gains compared to baselines are marginal."
            },
            "questions": {
                "value": "Can you discuss the differences of your method compared to each baseline approach? \n\nWhy can't we just use the same approach for functional tools to handle conceptual tools?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Reviewer_89Qo"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698734250571,
        "cdate": 1698734250571,
        "tmdate": 1700725950062,
        "mdate": 1700725950062,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "U3iWnLzOmD",
        "forum": "KZaEdLM4Gn",
        "replyto": "KZaEdLM4Gn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_X47T"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_X47T"
        ],
        "content": {
            "summary": {
                "value": "The paper expand the traditional LLM's tools definition which is mainly for functional tools, to conceptual tools within the context of dialogue systems. Furthermore, the paper introduce a multi-persona collaboration framework: Think-Plan-Execute(TPE). The effectiveness of TPE was demonstrated across multiple dialogue response generation tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper extend the traditional LLM's definition of functional tools to cognitive tools for dialogue system. Serving a novel perspective to address complex dialogue systems. Based on the cognitive tools, TPE, a tailored and explainable top-down dialogue planning framework is designed to produce more explainable and personalized. Extensive experiments on different datasets are conducted to prove the effectiveness of the proposed framework."
            },
            "weaknesses": {
                "value": "Some section description of the paper is not very clear to understand,  For example, the formulation part of section 3.2, it's better to be illustrated with some examples.  The cognitive tools seem to lack a formal formulation like the functional tools."
            },
            "questions": {
                "value": "1. It's a little difficult to understand the formulation symbols in section 3.2, it's better to illustrate with some intuitive example.\n2. In this paper's experiment, the cognitive tools seem corresponding the dialogue strategies? Is there more formal definition based on traditional dialogue  theory for it like definition for functional tools? or it changes with different domain dataset?\n3. For Table 1's result, Why there is no TPE in the Zero-shot ChatGPT methods? And for CIMA's  F1 score, the ReAct methos is much better than other methods, is there any possible explanation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698804054023,
        "cdate": 1698804054023,
        "tmdate": 1699636414153,
        "mdate": 1699636414153,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6clE7SkLmB",
        "forum": "KZaEdLM4Gn",
        "replyto": "KZaEdLM4Gn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_U93G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4406/Reviewer_U93G"
        ],
        "content": {
            "summary": {
                "value": "The  paper introduces planning and reasoning framework known as TPE for dialogue systems.  This framework is designed to guide Large Language models in generating more reasonable dialogues. TPE consists of three main components:\n\n The Thinker - The Thinker attempts to comprehend the current state of the human/persona involved in the conversation. It analyzes the previous conversation to estimate the intent or emotional state of the other persona in the conversation. It then formulates a textual explanation, referred to as a \"thought,\" which describes this state and suggests possible next steps.\n\nThe Planner-  The Planner takes the thoughts generated by the Thinker and devises a set of possible actions based on these thoughts, expressed through text.\n\nThe Executor -  The Executor executes one of the plans generated by the Planner, resulting in a follow-up dialogue that is presented to the user.\n\nThe authors also introduce the concept of \"concept tools\" in the paper, which is defined as \"a cognitive concept used to facilitate systematic or investigative thought.\"\n\nThis paper proposes a framework that decomposes the dialogue generation process into smaller, explainable segments. It compels Large Language Models to first consider the intentions of the person asking the question, similar to a theory of mind approach. This is followed by the generation of a set of strategies that could be useful in fulfilling the user's intentions, and then the creation of conversational text. This approach is distinct from the traditional end-to-end text generation approach.\n\nThe authors conducted experiments using two multi-source strategy and dialogue datasets, FoCus and CIMA. They compared their TPE approach applied to Large Language Models (such as Chat GPT and GPT-4) with other approaches, evaluating various metrics including F1 scores, BLEU, BERT score, and ROGUE. The results demonstrate that their approach outperforms other methods across these metrics.\n\nFurthermore, the authors performed an ablation analysis, highlighting the significance of each component within their framework and emphasizing the importance of the Thinker and Planner components in their research."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper proposes an interesting idea that is to re-enforce thinking and planning through textual information in Large Language Models. Overall, the idea seems reasonable, and important because a method like this will not only enable LLM's to think about intermediate dimensions ( thinking about the user and planning ) before generating a response but also these intermediate dimensions can serve as explanations for the response generated by the user. \nThe authors also conduct a detailed analysis of why their approach works well on tasks that involve strategic planning through dialogue and a detailed study that show why the the thinker and planner components work"
            },
            "weaknesses": {
                "value": "While the overall picture makes sense, the paper is not adequately presented. To begin with the authors introduce several key components/ definitions that aren't well grounded in the literature. For example, the definition of conceptual tools should be grounded from a more credible source in cognitive science. Further, the paper mentions that the thinker tries to estimate the emotions of the persona involved. Emotions are not defined/referenced well in the paper and can mean a lot of things. A little suggestion. would be to look at the literature on Theory of Mind and try to define the thinker in a manner that aligns with the terms used in the literature . \n\nFurther, the I feel the main paper lacks in details about the implementation of thinker, planner, and executor. These details are mentioned in the Appendix. However, I feel that these details should be a part of the main paper."
            },
            "questions": {
                "value": "1. Are there any technical novelties that the paper proposes?\n2. Can there be alternatives in which the thinker can be designed and if so how do they compare with the current approach used in the paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4406/Reviewer_U93G"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805071241,
        "cdate": 1698805071241,
        "tmdate": 1699636414072,
        "mdate": 1699636414072,
        "license": "CC BY 4.0",
        "version": 2
    }
]