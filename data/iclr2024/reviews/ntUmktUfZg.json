[
    {
        "id": "LztgtFZdlq",
        "forum": "ntUmktUfZg",
        "replyto": "ntUmktUfZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_833z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_833z"
        ],
        "content": {
            "summary": {
                "value": "- The authors suggest a new method for domain-incremental continual learning, leveraging recent approaches in conditional generative models. Specifically, the authors generated samples to train a domain discriminator which, in turn, is used as expert gate, to route samples at inference time to the appropriate expert model.\n- Furthermore, the paper suggests a new benchmark dataset for domain-incremental learning, named DermCL, combining different dermatologic datasets.\n- They evaluate their approach on 3 vision and 1 text (QA) tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper addresses a relevant topic, namely domain-incremental catastrophic forgetting. \n- The approach follows a simple and neat idea, which is to employ generated samples to train a gate model, instead of using them in an augmentation step to finetune the classification model.\n- The authors provide a good summary of related work.\n- The authors conduct extensive experiments with various datasets and multiple modalities (image, text)."
            },
            "weaknesses": {
                "value": "- It is hard to connect the table with the text -> e.g. in tab 1: where is ER? Whats CaSSLe? What\u2019s the difference between G2D and G2D (Full FT) \u2013> roughly explained much later in the text? Why are different methods compared for different (vision) datasets?"
            },
            "questions": {
                "value": "- Will the new benchmark dataset be published?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Reviewer_833z"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8161/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698578741633,
        "cdate": 1698578741633,
        "tmdate": 1699637011092,
        "mdate": 1699637011092,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0UUflgEqKn",
        "forum": "ntUmktUfZg",
        "replyto": "ntUmktUfZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_YtsH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_YtsH"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed to address the domain-incremental learning problem by learning domain-specific models combined with a model capable of distinguishing between domains. This domain discriminator is trained using synthetic data from a continually fine-tuned generative model. An important empirical demonstration is that the authors show that this indirect approach (i.e., first identify the domain, then solve the problem) works better than when directly learning a model to solve the problem in all domains while replaying the same synthetic data sample."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I consider demonstrating that it can be more efficient to address a domain-incremental learning problem in an indirect way (i.e., G2D; first identify the domain, then solve the problem) than in a direct way (i.e., Generative Replay; directly learn to solve the problem in all domains) an important and insightful contribution."
            },
            "weaknesses": {
                "value": "Unfortunately, I think that the paper does not provide enough experimental details to properly assess whether the comparison between G2D and Generative Replay is performed in a fair manner. In particular, based on the provided details, it is unclear to me whether Generative Replay has been implemented in an optimal manner. Examples of details / explanations that should be provided:\n\n- How is / are the classifier model(s) finetuned? In section 5.4. it is stated \u201cwe fine-tune only 1.04 ~ 2.5% of trainable parameters\u201d. How was this percentage decided? How is it decided which parameters are fine-tuned? Is this approach of fine-tuning the same for the classifier models of G2D and the classifier model of Generative Replay? \n\n- With Generative Replay, how are the loss on the replayed data and the loss on the data from the current task weighed? Are they simply added? Or are they balanced in such a way as to approximate the joint loss over all domains so far?\n\n\nCould the authors explain why they took the S-iPrompts results from the Wang et al (2022a) paper, but not the S-liPrompts results?\n\nOn p5 towards the bottom the authors claim that ER with a limited buffer size is an upper bound for generative replay. This does not seem correct."
            },
            "questions": {
                "value": "Most importantly, the authors should provide full details regarding how the generative replay experiments were implemented in order for the reviewers to be able to judge whether the key comparison of this paper was performed in a fair manner.\n\nCould the authors explain why they took the S-iPrompts results from the Wang et al (2022a) paper, but not the S-liPrompts results?\n\nI would be happy to actively engage in the discussion period."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8161/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698674606018,
        "cdate": 1698674606018,
        "tmdate": 1699637010978,
        "mdate": 1699637010978,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NH5FMUkhLJ",
        "forum": "ntUmktUfZg",
        "replyto": "ntUmktUfZg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_9jT2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8161/Reviewer_9jT2"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes tackles the setting of domain incremental learning by leveraging generative models as a routing mechanism. Specifically, for each task / domain $t$, the proposed approach\n1. trains a domain specific expert $f_t$, \n2. finetunes a pretrained generative model trained on $(x,y)$ pairs from task $t$, \n3. trains a domain discriminator on the aggregated synthetic samples from all $t$ domains seen so far by sampling from the respective generative models. \n4. At test time, the domain discriminator infers the task from the query data, and fetches the appropriate domain expert to make a prediction. \n\nThe authors evaluate the proposed method across four benchmarks, spanning both text and images, and real world medical imaging. Results show better performance than using the learned generative models for replay."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The approach is interesting; by decomposing the general domain incremental learning problem into (1) domain identification and (2) expert retrieval, the proposed approach is able to see performance gains. \n2. The approach provides a fresh perspective on the use of synthetic data for domain incremental learning, which is potentially less vulnerable to sub-par generated samples."
            },
            "weaknesses": {
                "value": "1. The authors fail to discuss the computational cost of the method. How is the task discriminator trained ? Is it trained from scratch at every new domain, or continually learned ? What is the training cost of having to train two additional models (task classifier and generator) compared to expert learning ? \n2. How does this approach scale ? My understanding is that it does so poorly if the task discriminator is not trained continually. More generally, it seems that the authors don't quite understand the computational efficiency related to PEFT approaches; taking LoRA for example, the computational cost saved from not performing a gradient update step on the full parameters is quite small compared to the cost of having to compute forward and backward passes in the model. The \"gains\" from peft are really in parameter efficiency and serving of these models. \n3. Relevance of the setting : The authors provide initial motivation of the setting in the paper, where model weights may be made available, but not the actual data used for training. I have trouble seing healthcare institutions open-sourcing generative models of their data, but not the actual data itself. I would appreciate if the authors could point me to such instances."
            },
            "questions": {
                "value": "1. T5 is an encoder decoder model, thus enabling conditional generation. How are you generating synthetic data from this model, i.e. where is the data fed to the encoder coming from ? Do you have a separate generator for this ? \n2. is the classifier at task t finetuned from task t -1 ? or finetuned from the pretrained model ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8161/Reviewer_9jT2"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8161/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698781372267,
        "cdate": 1698781372267,
        "tmdate": 1700174052132,
        "mdate": 1700174052132,
        "license": "CC BY 4.0",
        "version": 2
    }
]