[
    {
        "id": "W4bzm7HhlI",
        "forum": "eI6ajU2esa",
        "replyto": "eI6ajU2esa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission820/Reviewer_AKHJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission820/Reviewer_AKHJ"
        ],
        "content": {
            "summary": {
                "value": "The core idea of the paper is to use motion as a temporal constraint to improve the robustness of video perception tasks. The paper presents a test-time optimization algorithm using the temporal constraint and tests which is then evaluated on UCF101 and HMDB-51 by conducting a video classification task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Using motion as a constraint for video defense is intuitive and effective for certain types of attacks. \n2. The proposed test-time optimization is intriguing.\n3. The analysis section is resourceful. \n4. The paper is easy to follow."
            },
            "weaknesses": {
                "value": "1. The main concern is the assumption of the paper may be too strong. Authors assume all the attacks will destroy the optical flow and that the flows can be recovered given the existing information. In Figure 5, the authors demonstrate how the motion consistency is different in clean, attacked, and defended videos. However, this may not be a general situation, for example, the rectangular occlusion attack (ROA) mentioned in [1]. There are many other types of common video attacks that have not been discussed in the paper. \n2. I understand that the proposed method is a test-time optimization method, but it can not be an excuse to not compare with other relative existing methods in the paper. \n3. Necessary ablations are missing. There are hyperparameters like step size, K, and bounds but the authors did not mention how sensitive is the framework towards those hyperparameters. \n\n[1] Wu, T., Tong, L., & Vorobeychik, Y. (2019). Defending against physically realizable attacks on image classification. arXiv preprint arXiv:1909.09552."
            },
            "questions": {
                "value": "1. How long will it take for test-time optimization to defend each type of attack? \n2. During the experiments, have authors ever encountered certain types of attacks that were not very suitable for the proposed defense methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission820/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission820/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission820/Reviewer_AKHJ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698262608389,
        "cdate": 1698262608389,
        "tmdate": 1699636009287,
        "mdate": 1699636009287,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UQUy9ckArL",
        "forum": "eI6ajU2esa",
        "replyto": "eI6ajU2esa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission820/Reviewer_NZbs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission820/Reviewer_NZbs"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method to help video perception by fixing the potential corruption of video signals. The fix replies on the shift reflected in the motion flows. The idea is to improve the video perception by adopting test-time video repairing. The proposed method is claimed to be effective to both corrupted and attacked (under certain assumptions) videos."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method is supported with the very intuitive idea and straightforward implementations that is easy to follow.\n- The writing is basically easy-to-follow. The technical section can be quick to understand even to someone who not actively working in this domain.\n- The experiments provide empirical evidence to support the effectiveness of the proposed method under different protocols and on different datasets."
            },
            "weaknesses": {
                "value": "- The experiments lack comparison with other existing solutions in this line. This makes the estimation of method significance hard.\n- The proposed methods rely on the multiple terms of constraints, such as smoothness, brightness etc. However, all these constraints are studied for long in previous works. I thus have no confidence about the novelty of the proposed method in this paper.\n- In the related works, the authors discuss the motion estimation methods, \u201cRobustify Machine Learning Models.\u201d (I believe \u201crobustify\u201d is a typo here) and \u201cAdversarial Attacks and Defenses on Videos\u201d. However, to someone not familiar with the domain, it is expected to discuss whether the used techniques in the method such as the involved consistency terms and the idea of \u201crepairing then perception\u201d has been adopted in related works. I would expect the authors to make more clear claim and elaboration about the novelty of the proposed method."
            },
            "questions": {
                "value": "Overall, my concern is on the novelty of the proposed method and its empirical evidence. I would expect more elaboration on the novelty and a comparison with related works published recently to help calibrate the experimental significance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698582157862,
        "cdate": 1698582157862,
        "tmdate": 1699636009219,
        "mdate": 1699636009219,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rOFqIw5QsS",
        "forum": "eI6ajU2esa",
        "replyto": "eI6ajU2esa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission820/Reviewer_rbXC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission820/Reviewer_rbXC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a motion-based method for improving the robustness of video\nclassification models to adversarial pertubations and natural corruptions such as\nnoise or challenging wheather conditions. The base model first computes optical\nflow and then classifies the flow field using an established architecture. As a defense,\nthe authors optimize a small change to the input images in order to minimize the\nwarping loss as used for training unsupervised optical flow estimation methods. The\nvideo is then classified using the adapted images with the original model. This\ntest-time optimization is shown to improve the robustness of the model for several\nattack strategies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Robustness to noise and adversarial pertubations is a very relevant topic. Explicitely\n  using the motion in videos to improve robustness is a plausible and interesting\n  approach.\n- The paper is well written and therefore easy to follow."
            },
            "weaknesses": {
                "value": "In my view, the main weakness of the paper is the empirical evaluation of the\nadversarial robustness of the model. However I do not have a background in adversarial\nrobustness and would therefore be interested in the other reviewers' opinions about\nthese points. \n\n- The evaluation in section 4.3 seems to be irrelevant to me. The adversarial pertubation\n  is optimized using the original, undefended model but tested on the adapted, defended\n  model. From a high performance on these stimuli we do not learn anything about the\n  robustness of the adapted model.\n- In section 4.4, attacks against the adapted model are considered.\n    - The first two attacks use knowledge of the test time loss in the optimization of\n      the adversarial pertubation. The additional constraints however seem to be \n      limiting. For example, an adversarial pertubation that hardly changes the optical\n      flow estimate as optimized in \"Adaptive Attack 2\" will clearly be problematic for\n      the defense. However, adversarial pertubations with this property are only a\n      subset of all adversarial pertubations. There might be strong adversarial\n      pertubations that cannot be found with this approach.\n    - Using gradient approximation as in Adaptive Attack 3 is a much stronger approach.\n      Consequently, much stronger pertubations are found in which only a small fraction\n      of the performance is restored by the defense (Table 5 last row). As mentioned by\n      the authors, the better performance of the multiple constraints defense seems to\n      mainly stem from the computational cost of attacks.\n- Only gradient-based attacks are considered in this paper. Since gradient-based attacks\n  are computationally difficult for a defense relying on test-time optimization, it\n  would be interesting to also consider a gradient-free attack\n  (cf. [Carlini et al. 2019](https://arxiv.org/pdf/1902.06705.pdf)).\n\nIn summary, I am not convinced that the adapted model is adversarially substantially\nmore robust than the base model. The good results reported for many attacks rather seem\nto be due to the computational cd of optimizing adversarial pertubations due to the\nuse of test-time optimization."
            },
            "questions": {
                "value": "- What is the clean performance for the results reported in Table 1? Is it 86.6 as\n  reported in Table 2? If so, the defense seems to only restore model performance to a\n  small degree. Why is this the case?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740872205,
        "cdate": 1698740872205,
        "tmdate": 1699636009149,
        "mdate": 1699636009149,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2DbKJwrQvw",
        "forum": "eI6ajU2esa",
        "replyto": "eI6ajU2esa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission820/Reviewer_EksZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission820/Reviewer_EksZ"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors find that natural corruption and adversarial attacks harm both video classifiers and motion estimation. Thus they try to improve the model's robustness by a test-time constraint using motion information. Experiments on UCF and HMDB demonstrate its effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and organized, with clear figures and tables.\n- The logic is clear and easy to lead.\n- As the authors claim, `this is the first inference-time defense for videos that uses motion consistency to improve robustness.`"
            },
            "weaknesses": {
                "value": "As I'm not familiar with this research topic, I may not give a fair review:\n1. What does the `standard` mean in different tables?\n2. How about the time consuming? Is it better than those methods that need training?\n3. Is this method suitable for those with videos with quick motion?\n4. How does this method extend to general action recognition, since most of the current video backbones only use RGB frames?"
            },
            "questions": {
                "value": "- The reference style in the main paper may be wrong. `Mao et al. (2020)` should be `(Mao et al., 2020)` for ICLR.\n- The caption for Table 4 is wrong."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812961208,
        "cdate": 1698812961208,
        "tmdate": 1699636009081,
        "mdate": 1699636009081,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L5FcD3HBlS",
        "forum": "eI6ajU2esa",
        "replyto": "eI6ajU2esa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission820/Reviewer_Zd57"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission820/Reviewer_Zd57"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a solution based on the recovery of action information to address the issues of distribution shift and adversarial attacks in computer vision models, thereby enhancing the accuracy of the model during testing. The paper, from the perspective of action information consistency, designs multiple constraints to recover action information and validates the method on two datasets. Experimental results show no significant improvement under noisy conditions but demonstrate satisfactory results under adversarial attacks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper conducts experiments using various types of adversarial attacks, and the proposed method shows clear improvements.\n- The design of the adversarial attacks is innovative. The paper also discusses the impact of adaptive adversarial attacks, and even under strong adaptive attacks, the proposed method still performs well.\n- The proposed method is relatively simple and can be applied at the testing phase. It can be used in conjunction with other methods to enhance model robustness. Depending on the need, one can choose whether or not to use this method."
            },
            "weaknesses": {
                "value": "- This paper investigates the issue of robustness in video action recognition, but it lacks comparison with test-time adaptation (TTA) methods, such as [A-B]. These TTA methods also aim to adapt to out-of-distribution data when the input data is disturbed by noise. Although these TTA methods mainly focus on updating model parameters, and this paper primarily focuses on adjusting the input data, how to prove that data processing is superior to model parameter adjustment? I believe a comparison should be made based on experimental results.\n- Under noisy conditions, many TTA methods can achieve desirable results, while the improvement brought by this paper's method is relatively low.\n- In appendix A.2.1, under noisy conditions, the average performance improvement brought by this paper's method is very low and can even be counterproductive under certain noise conditions. Does this indicate an issue with the approach of changing input data?\n- How to verify the reliability of the long-range photometric consistency in section 3.3? Are there any ablation study results reflecting the performance gain brought by each part?\n- The explanation of the formula content in Algorithm 1 in the main body is not clear enough.\n\n[A] Temporal Coherent Test-Time Optimization for Robust Video Classification. ICLR23\n[B] Video Test-Time Adaptation for Action Recognition. CVPR23"
            },
            "questions": {
                "value": "- What does \u03c9 represent in Equation 3? Is it necessary to obtain it through additional training?\n- How is the ground truth flow obtained in Figure 3? Is it supervised? This is not clearly described in the paper.\n- In appendix A.3.1, the method is compared with the RAFT method (2020), which is out-of-date. Why not compare it with newer methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698842503491,
        "cdate": 1698842503491,
        "tmdate": 1699636009009,
        "mdate": 1699636009009,
        "license": "CC BY 4.0",
        "version": 2
    }
]