[
    {
        "id": "qG417Cgadv",
        "forum": "knl4kGCagT",
        "replyto": "knl4kGCagT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_6cYD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_6cYD"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a series of technical improvements to better train neural networks with derivative constraints that are common in physics-informed settings. A new activation function, the integrated ReLU (IReLU) is proposed, along with other fixes such as denormalization and label rescaling."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- **The paper addresses an important open problem and presents concrete improvements over a comprehensive set of experiments.** Training derivative constrained networks is central to solving a lot of the physics-related applications, and it can be difficult in practice since it is hard to balance the derivative constraint in the total loss function. This paper proposes methods that address this difficulty by respecting the different numerical scales of the system. Improvements across many different network models as well as applications (quantum chemistry, fluid dynamics, diffusion-reaction, etc.) are shown in the experiment section.\n- **Related work is discussed properly.** The authors adequately address the existing literature on derivative constrained neural networks and points out that their work differs from the literature in that they try to find general drop-in replacements that are suitable for a variety of different tasks and architectures."
            },
            "weaknesses": {
                "value": "- **The organization of the paper has room for improvement.** There is a motivation section in which the authors write about the experiments in detail, including the dataset size, numerical scales and units of the quantities of interest, but these details do not directly contribute to motivating the proposed methods. \n- **Some observations are left unexplained/unexplored.** In section 3 results, the authors observed that the \"energy loss divided by 1000 is typically much lower than the force loss,\" and that \"it is not easy to improve the relative difference, even for large values of $\\beta$.\" Why should this be the case? Why does the energy loss in figure 1(b) show high variance with high $\\beta$? Despite this being mostly a methods paper, I wish there was more discussion providing insight and analysis on these empirical observations.\n- **Some intuitions can be made more mathematically precise.** It is a good thing that the paper provides lots of intuition and insights on the problems and solutions presented. However, some of these intuitions can be difficult to understand for readers not familiar to the subject. For example in section 4.2 \"...DC NNs are more sensitive to *units* compared to typical training without derivative constraints because of the linearity of derivatives\", and \"we can interpret the constant $c$ as determining the *units* of $x$\". It is still unclear to me why some of the internal normalization (e.g. batch normalization) will not respect the units. It would be greatly helpful if the authors would include a short example of a concrete model and toy data to further elucidate this point."
            },
            "questions": {
                "value": "- On the results in section 3: why does it makes sense to divide the energy loss by 1000 in the first place? Would it be more reasonable to somehow plot the \"variance explained by the model\" instead of the unscaled losses?\n- How is label rescaling different from the usual dataset-preprocessing? In your opinion, why didn't previous works consider this simple procedure?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6220/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6220/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6220/Reviewer_6cYD"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793239180,
        "cdate": 1698793239180,
        "tmdate": 1699636679033,
        "mdate": 1699636679033,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "z8GniZRMjT",
        "forum": "knl4kGCagT",
        "replyto": "knl4kGCagT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_LFn2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_LFn2"
        ],
        "content": {
            "summary": {
                "value": "The paper tackles the problem of unstable training of derivative-constrained (DC) neural networks. Specifically, the authors proposed IReLU activation function to replace ReLU, which may lose training signals in DC settings. Furthermore, they also proposed eliminating normalization layers in current networks and rescaling the labels to reduce the sensitivity of the network with respect to units. Experiments were conducted on on a variety of architectures, datasets, and tasks including quantum chemistry and physics-informed neural networks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper tackles an important problem of stabilizing training of derivative-constrained neural networks. \n\n* The writing of the paper is clear. \n\n* Experiments are conducted on a wide range of tasks and architectures."
            },
            "weaknesses": {
                "value": "* The authors should introduce a name for their proposed method. \n\n* The ideas of the papers are quite incremental and mostly based on intuition. For example, the authors hypothesize that derivative-constrained NNs are sensitive to units without any theoretical/empirical evidence."
            },
            "questions": {
                "value": "1. The experimental results are questionable, especially ones with quantum chemistry neural networks where we can observe huge improvements. Can the authors provide more detailed clarifications/explanations for these improvements?\n\n2. Why label rescaling is not necessary for PINN experiments? Does this mean the label rescaling is only designed for quantum chemistry experiments? Again, the results on quantum chemistry datasets are questionable.\n\n3. Have the authors tried alternatives of ReLU, such as SiLU, ELU, etc.?\n\n4. I would appreciate if the authors included ablation studies to show the effectiveness of each component: iReLU, denormalization, label rescaling. \n\n5. Normalization techniques were proposed to improve stability when training neural networks. Why removing them in the paper's setting can improve training stability? I would expect a more detailed answer other than the intuition of sensitivity to units mentioned in the paper.\n\n6. Can IReLU be applied in derivative constraints involving higher-order derivatives, such as second-order? If not, can we have a more generic activation function for such cases?\n\nI look forward to the authors' response and will be happy to increase my score if the authors can address my concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820908106,
        "cdate": 1698820908106,
        "tmdate": 1699636678928,
        "mdate": 1699636678928,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JjjP93VSD3",
        "forum": "knl4kGCagT",
        "replyto": "knl4kGCagT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_WsvB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6220/Reviewer_WsvB"
        ],
        "content": {
            "summary": {
                "value": "Motivated by the convergence discrepancy of the loss terms in physics-informed training of neural networks, the paper proposes a new activation function, IRELU, and a label rescaling method, while abandoning common normalization techniques."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper tries to address an important challenge with PINNs, concerning the discrepancy between loss terms in physics-informed training. \n- The direction taken by authors in focusing on the units of derivatives and labels is interesting."
            },
            "weaknesses": {
                "value": "- As also pointed out by the authors, the proposed IRELU activation has limited usability in physics-informed models, where one might need derivatives of an arbitrary order w.r.t. inputs, while derivatives for IRELU are $0$ for third and higher order derivatives. Even for second order PDEs, the effects of a constant second derivative of $1$ in IRELU (for $x>0$) need more attention and study. \n- Preventing vanishing and exploding gradients is one major characteristic of RELU. The gradient propagation of IRELU is not studied, though. As in your experiments, physics-informed training usually involves training with the solution data as well (IC, BC, etc.), where the first order derivative of IRELU ($=x$ for $x>0$) appears in the optimization. This is concerning for exploding gradients, especially since the paper also abandons normalization.\n- The notion of the 'difficulty of learning derivative-constrained info based on the loss scaling term' is inaccurate. While convergence discrepancy of different loss terms is known to happen in physics-informed training, the convergence rate is shown to be in favor of the residual loss (derivative-constrained term) in some cases [1].\n- Other works have studied activation functions in the physics-informed setting before [2, 3]. Lack of review and comparison with such works is surprising. Moreover, the authors do mention the adaptive loss scaling methods, but, there is again no comparison with those methods.\n\n\n[1] Wang, S., Yu, X., & Perdikaris, P. (2020). When and why PINNs fail to train: A neural tangent kernel perspective. ArXiv. /abs/2007.14527\n\n[2] Sitzmann, V., Martel, J., Bergman, A., Lindell, D., & Wetzstein, G. (2020). Implicit neural representations with periodic activation functions. Advances in neural information processing systems, 33, 7462-7473.\n\n[3] Jagtap, A. D., Kawaguchi, K., & Karniadakis, G. E. (2020). Adaptive activation functions accelerate convergence in deep and physics-informed neural networks. Journal of Computational Physics, 404, 109136.\n\n### Minor Comments\n- There are a few grammatical errors, and the readability can also be improved.\n- In Sec 3.2, Results, the references to Fig. 2 seem to be meant for Fig. 1."
            },
            "questions": {
                "value": "1. A more in-depth study of the proposed activation function would be really helpful. Authors may want to explain what characteristics IRELU shares with RELU and how it addresses the issues with polynomial activation functions.\n2. The presentation and readability can be greatly improved by adding more plots instead of tables; Especially, in the experiments and ablation study to show how the proposed methods contribute to addressing the loss discrepancy. Also, the plotting style in Figures 1a and 1b is not informative and rather confusing. \n3. Section 4.2 is very limited in justifying the proposed rescaling method and how it improves the learning of the derivative-constrained info. I would appreciate more details and insights regarding the choice of $C$ and why normalization methods are discouraged.\n4. As mentioned in the Weaknesses, comparison with other activation functions that are designed for or tested with PINNs is crucial."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698994474866,
        "cdate": 1698994474866,
        "tmdate": 1699636678828,
        "mdate": 1699636678828,
        "license": "CC BY 4.0",
        "version": 2
    }
]