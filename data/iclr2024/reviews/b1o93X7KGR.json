[
    {
        "id": "VCjsr6HB4E",
        "forum": "b1o93X7KGR",
        "replyto": "b1o93X7KGR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission799/Reviewer_ehoA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission799/Reviewer_ehoA"
        ],
        "content": {
            "summary": {
                "value": "This paper attempts to improve DINO -- one of the state-of-the-art methods in end-to-end object detection using transformers. Training process of DINO is framed as a reinforcement learning problem. Typically, in transformer-based object detectors, one sets multiple queries from feature maps. This query selection in DINO is replaced with the eta-greedy technique from reinforcement learning literature. The paper evaluates on COCO and shows improved performance over DINO."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I found following strengths in the paper:\n\n- the idea of using reinforcement learning technique for improving DINO is interesting.\n- the experimental results on COCO show good improvements, which might be relevant to practitioners."
            },
            "weaknesses": {
                "value": "I noted following points for improvements.\n\n- Clarity of the presentation can improve significantly.\n\nThe paper assumes from abstract and introduction that the readers are already familiar with DINO and DETR like object detectors. It was difficult to read the paper without recapping these literature. There are lots of terms that needs introduction, e.g., \"query\", \"top K-selection\", \"eta-greedy approach\", etc. It would improve readability if these terms are introduced atleast at the high conceptual level.\n\nThere are several very strong claims, which is not really backed up in the paper. The work claims that there is \"the pattern of using inappropriate queries\", but only few qualitative results are shown. I think quantitative data that shows this pattern would help. Another example is \"First, both of situations show pattern that using sub-optimal queries/strategy. Second, the reasons of both situations are lack of exploration of potential better queries/strategy.\". I think any empirical or theoretical evidence for both the claims would strength the paper.\n\n- Evaluation on only one data-set is fairly limited.\n\nThe paper compares to other approaches on COCO. No other data-sets are considered. I think showing the trend over different data-set would make the results more solid.\n\n- The paper contains too many grammar mistakes.\n\nFor example, \"The structure of DINO model could be separated into 6 functional blocks. That is backbone, trans former encoder, query selection, transformer decoder, bipartite matching, denoising part. Too keep the comparison of two different learning easy to read, we illustrate only the query selection relating\". Another example, \"The impact of this modification is readily apparent, as shown in Figure 1, it is obvious that DINO with \u03b5-greedy no longer employs the largest initial box to predict small object.\"\n\nMy feeling is that the paper has been rushed for submission at ICLR. There might be some interesting ideas, but it would benefit from thorough revisions."
            },
            "questions": {
                "value": "1. Can related work also discuss how this work locates within the state-of-the-art?\n\n2. \"To bridge the gap between supervised learning and reinforcement learning,query selection in DINO as a multi-armed bandit problem.\" Can this sentence be explained more? What is the \"gap\"?\n\n3. \"Together, the experimental and theoretical findings support presence of reinforcement properties ....\". May I know what are theoretical findings in this work? I feel that one is relying more on the intuition.\n\n4. Abstract states that it only requires few lines of code. Can this be illustrated in the paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Reviewer_ehoA"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698336433828,
        "cdate": 1698336433828,
        "tmdate": 1699636007076,
        "mdate": 1699636007076,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mRiLOobTT8",
        "forum": "b1o93X7KGR",
        "replyto": "b1o93X7KGR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission799/Reviewer_UZB1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission799/Reviewer_UZB1"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to replace the hard-topk operation for proposal selection in the DINO object detection algorithm with a policy gradient based selection along with epsilon-greedy exploration.  This substantially improves object detection quality.  While the basic idea is sound, the writing and presentation are substantially flawed.  Additionally, it's not clear that this is the only way or the best way to improve credit assignment on the proposal selection.  \n\nnotes: \n  -Paper studies exploration/exploitation in training the DINO model, which is a strong supervised transformer algorithm for object detection.  \n  -Apply epsilon greedy to query selection DINO.  Simple modification to the existing algorithm but yields substantial performance improvement of 0.3 AP, and bigger gains on the smaller model.  \n  -Frame box proposal as a multi-armed bandit problem."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-The experimental improvement seems nice.  \n  -Replacing a hard-max with a better credit assignment mechanism, in this case epsilon-greedy and policy gradient, is a logical improvement."
            },
            "weaknesses": {
                "value": "-There are substantial writing issues in the introduction and grammatical/flow issues.\u00a0 For example, \"The dilemma is about to exploit what model has already experienced\" could be rewritten.\u00a0 Even just running the paper through a standard grammar checker could help to fix these issues.\u00a0\u00a0\u00a0 \n\n-The introduction also should do more to explain how DINO works in some more detail and how bounding boxes and proposed.\u00a0 A general ML researcher will have a rough sense of this, but just re-explaining this would make it easier for a typical reader."
            },
            "questions": {
                "value": "-I found Figure 1 to be confusing, since it seems like DINO (epsilon greedy) is worse than baseline DINO since it doesn't light up the airplanes at all.  I can see in Figure 3 that epsilon greedy is better than baseline DINO, although I'm a bit confused about this figure as well, because I'm not sure if I'm looking at the learned selection once the algorithm is trained or if I'm looking at the epsilon-greedy exploration policy during training.  \n\n  -I find the motivation to be a bit confusing.  If you are doing supervised object detection, you have the ground truth bounding box, so why do you need to turn it into a bandit problem and do exploration?  I suppose it makes sense that if the original system uses a non-differentiable top-k selection, that optimizing this better could be helpful.  \n\n  -Have you considered other ways of replacing the hard-topk operator?  For example when searching I quickly found this paper: https://arxiv.org/abs/2002.06504"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800303920,
        "cdate": 1698800303920,
        "tmdate": 1699636006989,
        "mdate": 1699636006989,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1Z9rfWaFiW",
        "forum": "b1o93X7KGR",
        "replyto": "b1o93X7KGR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission799/Reviewer_jc6H"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission799/Reviewer_jc6H"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the implicit reinforcement learning properties in transformer-based object detection."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is interesting, and it is easy to follow and understand."
            },
            "weaknesses": {
                "value": "What do 36 and 12 epochs mean in the abstract? Does that mean you should play your algorithm in the 34th and 12th epoch?\n\nI found it hard to understand Figure 1. I don\u2019t see the advantage of (c) over (b).\n\nWhat is the difference between n in Eq (3) and t in (10)? I would like to understand how to relate the training iteration and time step of RL.\n\nI am interested to see the complexity increase of the method compared to the baseline."
            },
            "questions": {
                "value": "Please see my comments in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission799/Reviewer_jc6H"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699193405969,
        "cdate": 1699193405969,
        "tmdate": 1699636006919,
        "mdate": 1699636006919,
        "license": "CC BY 4.0",
        "version": 2
    }
]