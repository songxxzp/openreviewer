[
    {
        "id": "eMhEyW4eQq",
        "forum": "joMMM9eadc",
        "replyto": "joMMM9eadc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_MZmK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_MZmK"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of finding feasible solutions to integer programming problems. The authors propose a novel framework that generates complete feasible solutions end-to-end. Their framework learns the embeddings for IP instances and their solutions and then uses diffusion models to learn the distributions. Finally, they perform sampling with trained models.\n\nKey results: From their experimental results, it appears that their sampling methods provide solutions with a higher proportion of which are feasible solutions and have smaller objectives than our approaches.\nTrained on small-size datasets, their models are able to scale to large-scale instances."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. From their experimental results, it appears that their sampling methods provide solutions with a higher proportion of which are feasible solutions and have smaller objectives than our approaches.\n2. Trained on small-size datasets, their models are able to scale to large-scale instances."
            },
            "weaknesses": {
                "value": "Major comments:\n\n1.\t\u201cFor SCIP, we adopt the first solution obtained through non-trivial heuristic algorithms during the solving phase.\u201d I don\u2019t know whether this comparison is fair. Did you try, for example, using the solutions they get within a fixed window of time?\n\n2.\tWhy do you compare your algorithm mostly with SCIP instead of Gurobi which is possibly a much better solver.\n\n3.\tHow does the objective value that you sampled compare to the optimal solution? How close are they? If they are far from each other, having a high feasible ratio does not mean anything. The feasible region increases exponentially, so there could be a large number of feasible solutions that are far from the optimal solution.\n\nMinor comments:\n\n1.\tIn \u201cRelated work\u201d, you mentioned \u201cour method aims to learn the latent structure \u2026, without any reliance on the IP solver.\u201d, but you still need to complete partial solutions use Completesol heuristic from SCIP.\n\n2.\tIn page 8, the first paragraph, you mentioned \u201cthe coverage is set to 0.1 and 0.2 due to the difficulty in finding feasible partial solutions when C > 0.2.\u201d. What do you mean by difficulty? Does it mean that you cannot find any feasible partial solutions within 30 generated solutions?\n\n3.\tIs it possible to generate repeated solutions so that the performance is not improving?\nPossible typoes: Page 3 last paragraph: DDIM then"
            },
            "questions": {
                "value": "Combined in the \"Weaknesses\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3028/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3028/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3028/Reviewer_MZmK"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698474754689,
        "cdate": 1698474754689,
        "tmdate": 1700492780858,
        "mdate": 1700492780858,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wOL3Yt4tEV",
        "forum": "joMMM9eadc",
        "replyto": "joMMM9eadc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_wgcj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_wgcj"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel framework that generates complete feasible solutions end-to-end (i.e., assigning all variables using neural networks) for Integer Programming (IP) problems, in contrast to most prior works that generate partial solutions (i.e., only assigning a subset of variables using neural networks).\nSpecifically, it proposes a contrastive learning approach to capture the relationship between the IP instances and the solutions, a diffusion model to generate solution embeddings, and a guided sampling strategy to enhance the feasibility and quality of solutions.\nExperiments on four datasets show that the proposed method outperforms previous state-of-the-art methods in terms of feasible ratio and objective value."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThis work is well motivated and the paper is easy to follow.\n2.\tWhile most previous methods can only generate partial solutions, this work represents a valuable attempt to an end-to-end framework to generate complete feasible solution.\n3.\tExperiments demonstrate the effectiveness of the proposed method.\n\n\ta)\tExperiments on four datasets demonstrate the effectiveness of the proposed methods compared with Neural Diving and SCIP in terms of feasible ratio and objective value.\n\n\tb)\tThe scalability test demonstrates that the proposed method can generalize to large instances.\n\n\tc)\tThe ablation study demonstrates the effectiveness of the IP guidance.\n\n\td)\tThe authors also conduct hyperparameter tuning experiments to investigate the effect of the gradient scale $s$ and the leverage factor $\\gamma$."
            },
            "weaknesses": {
                "value": "1.\tThe authors may want to add [1] as a baseline.\n2.\tThe prediction loss defined in Eq. (3) empirically performs better than that from general diffusion models. It would be better to provide some intuitive interpretation. Moreover, the authors may want to provide the inference algorithm of the modified diffusion model.\n3.\tAs diffusion generative models may suffer from inefficiency in both training and inference, the authors may want to report the training and inference time.\n\n[1] Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, and Xiaodong Luo. A gnn-guided predict-and-search framework for mixed-integer linear programming. In The Eleventh International Conference on Learning Representations, 2023."
            },
            "questions": {
                "value": "1.\tIs this work the first one to generate complete solutions? \n2.\tSee Weakness 2. The training loss defined in Eq. (3) is different from general diffusion models. Does it cause a different inference algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698662095072,
        "cdate": 1698662095072,
        "tmdate": 1699636247914,
        "mdate": 1699636247914,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fTI8bdnGu7",
        "forum": "joMMM9eadc",
        "replyto": "joMMM9eadc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_jBX3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_jBX3"
        ],
        "content": {
            "summary": {
                "value": "A solution generation method is adopted to estimate binary solutions of integer programming. The method includes a contrastive learning  gaining initial representations of solutions and instances, and a conditioned generative model estimating binary solutions. Guided sampling is adapted from present diffusion models to increase the feasibility ratio."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Applying cutting-edge deep learning to solve integer programming problems is encouraging. This research focuses on generating feasible solutions by generative model and borrows the powerful representation learning capability of neural networks. The method is technically sound by simply applying contrastive learning and diffusion model for solution estimation."
            },
            "weaknesses": {
                "value": "My first concern is the insufficient comparison in experiments. As described in related work, considerable literature attempted to improve the diving method in solvers. Except Neural Diving (Nair et al., 2020), many follow-up works continue similar research topics. More recent methods should be compared. Even by only comparing Neural Diving, the results are not enough. The training time and resource usage are not clear, which is important to show practicality and efficiency of applying multiple deep neural networks in the proposed method. Moreover, the functions of contrastive model and generative model are not showcased by ablation study.\n\nMany works apply deep learning methods to solve integer programming problems with totally feasible solutions. To name a few, \"A general large neighborhood search framework for solving integer linear programs\", \"Learning large neighborhood search policy for integer programming\", \"Mip-gnn: A data-driven framework for guiding combinatorial solvers\". The advantage of this research over this line of works is not clear. The use case of the given method is not given. Many descriptions are not well explained (see questions).\n\n-----------------After rebuttal-------------------------\n\nI appreciate authors' detailed rebuttal. I still think the novelty is not high. The results and literature added in rebuttal are important and should have been in the original version. I raised my score a bit to 5."
            },
            "questions": {
                "value": "1. Why SCIP is chosen in experiments but not Gurobi, given the fact that Gurobi often performs better than SCIP. \n2. GCN is described by \"It does not explicitly incorporate objective and constraint information during sampling, often resulting in infeasible complete solutions.\" In Gasse et al. (2019), GCN always gains feasible solutions.\n3. Any integer programming problem can be converted into a 0-1 programming. But the conversion increases the number of constraints a lot. How large integer programming can the method solve?\n4. What is the advantage of contrastive learning compared to supervised learning? Additional experiment should be provided to see the effect of contrastive learning without labeled solutions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3028/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3028/Reviewer_jBX3",
                    "ICLR.cc/2024/Conference/Submission3028/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698771078329,
        "cdate": 1698771078329,
        "tmdate": 1700864934204,
        "mdate": 1700864934204,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JWU1GH6XcM",
        "forum": "joMMM9eadc",
        "replyto": "joMMM9eadc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_CS3k"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3028/Reviewer_CS3k"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a learning based IP solver. For problem and solution embedding, the solver took the GCN framework, combined with contrastive learning inspired by CLIP. In addition the authors adapted DDPM/DDIM by introducing IP specific guidance into the sampling procedure. Experiments on several IP problems showed superior performance to both Neural Diving and SCIP."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Several key components were designed to make the solver specifically effective for IP. Experiments are solid."
            },
            "weaknesses": {
                "value": "To better validate that the quality of the proposed solver, comparison between the found optimal objective value and the ground-truth (global optimum) would be more convincing, the paper only provided relative comparison between the proposed solver and two baseline approaches."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699610481568,
        "cdate": 1699610481568,
        "tmdate": 1699636247726,
        "mdate": 1699636247726,
        "license": "CC BY 4.0",
        "version": 2
    }
]