[
    {
        "id": "XmIKvS8p9C",
        "forum": "OqLrv5oH6r",
        "replyto": "OqLrv5oH6r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission264/Reviewer_qXVo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission264/Reviewer_qXVo"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a novel paradigm, WSHFL,  for integrating programmatic weak supervision with on-device federated learning. The key ideas are composed of 2 components: automatic labeling function (heuristics) generations and federated learning with WeaSEL (Weakly Supervised End-to-end Learning). The authors conduct experiments to show that both components work across three benchmark tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "To the best of the reviewer\u2019s knowledge, the idea of incorporating federated learning with programmatic weak supervision proposed in this paper is novel. This work is clearly motivated and it obviously fills the need for distributed programmatic weak supervision, especially with privacy concerns. I also appreciate the authors\u2019 consideration of data beyond the text (i.e. ECG)."
            },
            "weaknesses": {
                "value": "Overall, despite this paper(WSHFL)\u2019s obvious merits, the method construction itself is incremental. The ideas of automated labeling functions generations have been a relatively well studied topic. If possible an open-source code base for federated learning with WeaSEL or other non end-to-end programmatic weak supervision would be very beneficial to the community."
            },
            "questions": {
                "value": "From the automatic labeling functions generation scheme, for example, the unigram proposal mechanism still can pose private data leakage risks. I would very much appreciate it if the authors can offer some ideas about initial solutions around this issue."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Reviewer_qXVo"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission264/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698799386684,
        "cdate": 1698799386684,
        "tmdate": 1699635952059,
        "mdate": 1699635952059,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XRW4XAspLu",
        "forum": "OqLrv5oH6r",
        "replyto": "OqLrv5oH6r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission264/Reviewer_W4Yv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission264/Reviewer_W4Yv"
        ],
        "content": {
            "summary": {
                "value": "The title is clear and gives a good indication of the paper's main focus. The abstract provides a concise overview of the problem, the proposed solution, and the results. The introduction sets the context well, highlighting the importance of learning from on-device data and the challenges associated with it. The motivating example of arrhythmia detection provides a real-world context, making it relatable for readers. This paper introduces a new method, WSHFL, that bridges the gap between federated learning and programmatic weak supervision, addressing a challenge in the field. Addressing the issue of on-device data annotation is timely and relevant, given the increasing importance of privacy and on-device computations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper introduces the concept of Programmatic Weak Supervision (PWS) into the federated setting, and the topic of on-device data annotation is timely and important."
            },
            "weaknesses": {
                "value": "1.\tThe novelty seems limited as PWS has already been explored in centralized settings. The paper's main contribution appears to be the adaptation of an existing technique to a federated scenario rather than introducing a fundamentally new approach.\n\n2.\tFigure 1 aims to visualize the strategy for generating LFs in the WSHFL method. However, the figure appears to be a high-level representation without detailed annotations or explanations. The flow between the different stages (a to d) and the significance of the values associated with the \"IF nice\" statements are not immediately clear. A more detailed caption or accompanying text might help in understanding the figure's content.\n\n3.\tThe paper mentions comparisons with fully supervised baselines, but there seems to be a lack of comprehensive comparison with state-of-the-art methods in FSSL. Such a comparison would be crucial to establish the proposed method's effectiveness and relevance in the current research landscape."
            },
            "questions": {
                "value": "see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission264/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834656752,
        "cdate": 1698834656752,
        "tmdate": 1699635951992,
        "mdate": 1699635951992,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LqlDDCA7Z5",
        "forum": "OqLrv5oH6r",
        "replyto": "OqLrv5oH6r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission264/Reviewer_mKax"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission264/Reviewer_mKax"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the challenges of leveraging on-device data for training intelligent mobile applications. The data is distributed on client devices and it is sensitive data, making it difficult to obtain expert annotations for traditional supervised machine learning. Current federated learning techniques typically use unsupervised approaches and cannot capture expert knowledge through data annotations. To address this issue, the paper introduces a method called Weak Supervision Heuristics for Federated Learning (WSHFL). WSHFL utilizes labeling functions, which are heuristic rules, to annotate on-device data in cross-device federated settings. The paper presents experimental results across two data modalities, text and time-series, demonstrating that WSHFL achieves competitive performance compared to fully supervised methods without the need for direct data annotations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper addresses the problem of obtaining labels for the data distributed across devices and training a model using the labeling signal obtained. I like the motivation and introduction of the problem. \n\n\n2. The authors provide a solution based on programmatic weak supervision (PWS) in which the expert feedback is incorporated using a set of heuristic rules, which is more efficient than asking for annotations of each data point. The authors apply it in the federated learning setting since the data cannot leave the client device i.e. not sharable. The proposed solution generates a set of candidate labeling functions on each client and then uses expert feedback to select accurate labeling functions that are used to train the model using WeaSEL model (Cachay et al. 2021). \n\n\n3. Experiments on natural language and time series domains are provided that demonstrate the feasibility and effectiveness of the proposed approach WSHFL."
            },
            "weaknesses": {
                "value": "1. I find the method section 3 dense and confusing.  I have following confusions/questions. How are the candidate LFs generated on client? What is exactly happening at the server, in particular in ExpertQuery function? This function is providing $u_t$ and the TrainClient function is giving estimates $\\hat{u}_t$. What is the neural network trained on and for what purpose? $u_j$ is a variable denoting whether $\\lambda_j$ is selected or not, but statements like \u201c where we sequentially inspect the candidates in or der to discover members of our desired class ($u_j=1)$ make it look like it is one of the classes in $\\mathcal{Y}$. The presentation of section 3 can be improved greatly to make it more lucid. There is very little horizontal space between the algorithm block. \n\n2. The solution is aimed at federated learning setting, so privacy should be ensured. It is not clear to me whether LFs can leak personal information and does the overall solution ensures privacy."
            },
            "questions": {
                "value": "1. How does the method ensure privacy? The data is not shared with the experts/serve but I think there is a potential risk of information leak via labeling functions.\n2. How many times are each method run in experiments? Does running more times reduce variance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission264/Reviewer_mKax"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission264/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699133604754,
        "cdate": 1699133604754,
        "tmdate": 1700714827165,
        "mdate": 1700714827165,
        "license": "CC BY 4.0",
        "version": 2
    }
]