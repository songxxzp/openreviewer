[
    {
        "id": "MqI4zodE48",
        "forum": "frjDLUebFY",
        "replyto": "frjDLUebFY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_5iQh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_5iQh"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce FlexPO, a reinforcement learning transformation selector for program compilation. FlexPO works by selecting a sequence of program transformations that improves the observed runtime of a program. Unlike prior work, FlexPO employs an activation predictor, which estimates which transformations might be fruitfully applied in the future."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "FlexPO tackles an important problem of improving program compilation. A massive amount of effort goes into designing existing compiler pipelines, and we already know that they fall short of optimal. Using ML techniques to help is a great idea."
            },
            "weaknesses": {
                "value": "Overall, two large points confused me about this submission:\n\n1) The authors seem to ignore the cost of the actual compilation procedure. This is fine, and has been studied under the name \"super optimization\" for a long time. But it seems to me that comparing FlexPo, which is a profile-guided, multi-shot, expensive optimizer, with standard O3, which is a heuristic-guided, single-shot, and \"fast\" optimizer, doesn't make much sense. At a minimum, the authors should report and compare the compilation time of their approach. At best, the authors should compare with other approaches that use a similar amount of time.\n\n2) I do not understand the motivation of predicting which transformations are dormant or active. It seems this is not ablated in the experiments either -- perhaps the authors could clarify why this prediction is difficult, and include an experiment using ground-truth dormant/active information?"
            },
            "questions": {
                "value": "Q1) I don't understand what F1 is showing me. Shouldn't the x-axis be time? I imagine a very naive solution could consider a very large search space, it just couldn't do it effectively. \n\nQ2) \"However, their framework faced difficulties... to the expansive search space\" -- what are the difficulties? what are the times?\n\nQ3) After S3, I still do not know if the authors are seeking a single, global order that works for all programs or are generating an \"instance-optimized\" order-per-program.\n\nQ4) Can you explain why it is difficult to determine whether or not a transformation will induce a change to the underlying IR? It seems a very simple strategy would do the trick: \"clone the current IR, apply the transformation in question, and then see if anything changed.\" Sure, it's O(n) in the size of the program, but so is constructing the feature representation described in S6...\n\nQ4) The text right above F2 makes it seem like each entry in the feature vector is going to have three states: whether the transformation has been applied, and, if the transformation has been applied, whether or not the transformation is now dormant (you  call these 1, 0, and -1 in S4). But F2 only shows 2 states.\n\nQ5) I'm confused about what the activation predictor does up until S6. First, the authors say that their ML model is going to predict whether or not a transformation is active or dormant. Then, the authors say that the features used as inputs to the model will be... whether or not a transformation is active or dormant. At first glance, this seems like quite the easy problem! :D After reading S6, I (think I) understand that the activation predictor estimates which transformations will *still* be active after applying all *currently* active transformations. \n\nQ6) S6 introduces additional features used by the RL agent that are not those described in S5... this is the first time it becomes clear to me that the activation predictor is going to be a component inside of an existing RL system. After reading S6, I still cannot say for certain if the activation predictor is trained inside the RL loop or ahead of time in a supervised fashion.\n\nQ7) In S7.3, you compare FlexPO with a certain number of itreations to the existing optimization modes. But FlexPO has a huge advantage in that the agent gets to observe the runtime delta as a reward function. O3 and Oz, as far as I know, use cost models, not actual execution. At best, this is a comparison between a traditional optimizer and a profile-guided optimizer. At worst, I imagine that FlexPO takes *significantly* longer to run than O3 and Oz! Heck, even executing a search routine *one time* on an input large enough to be interesting is probably 10x more expensive than the compilation procedure... Perhaps you could consider FlexPO a type of \"superoptimizer?\" \n\nQ8) At a minimum, you should plot the results are Pareto scatter plots, with compilation time on one axis and runtime on the other. If you looked into how existing GCC/Clang O3 works, and gave it the same amount of time to try transformations as FlexPO, what would the results be?\n\nTypo: \"Mammadli et al. Mammadli et al. (2020)\" and \"Kulkarni et al. Kulkarni et al. (2004) \""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Reviewer_5iQh"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3913/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800260642,
        "cdate": 1698800260642,
        "tmdate": 1699636351435,
        "mdate": 1699636351435,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nYdoa7MneP",
        "forum": "frjDLUebFY",
        "replyto": "frjDLUebFY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_gVMu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_gVMu"
        ],
        "content": {
            "summary": {
                "value": "FlexPO uses reinforcement learning and the status of optimization steps to address the phase ordering problem. Unlike common practices, FlexPO doesn't limit optimization options based on human knowledge. Instead, it tracks which optimizations are applied and whether they are active or dormant, and uses them to represent program status. This approach leads to better speedup and smaller program sizes compared to -O3 and -Oz flags."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- It shows that RL w/ the activation predictor to predict dormant status can be effective in tackling the phase-ordering problem"
            },
            "weaknesses": {
                "value": "- It claimed to introduce a novel program representation based on the dormant status of applied optimizations, but it seems the representation is not used in the pipeline as observation. Also, it is unclear how effective the proposed dormant representation is compared to the other program representations. \n- Its evaluation needs to be improved. RL is not an established SoTA for tackling the problem. It would be critical to compare FlexPO to random, Genetic Algorithm, and other algorithms. It would be helpful to show curves from a more comprehensive set of programs (averaged) in Fig. 7,9,11. The current results appear to be selectively chosen.. \n- Not relying on human knowledge is considered a fundamental feature in data-driven machine learning. However, it's worth noting that harnessing human knowledge can be an efficient approach to reducing search complexity. I believe that certain dormant relationships can be statically inferred from the optimization implementation or learned just once."
            },
            "questions": {
                "value": "1. Can you please clarify how you determine an optimization is dormant? Do you compare the IR of the program before and after the optimization?\n2. Can you elaborate on how you integrate the dormant representation with your observation? In observation, you only mentioned the vector features that directly extracted from the programs."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Reviewer_gVMu"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3913/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826576694,
        "cdate": 1698826576694,
        "tmdate": 1699636351356,
        "mdate": 1699636351356,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cfWBwIUEOC",
        "forum": "frjDLUebFY",
        "replyto": "frjDLUebFY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_voGU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_voGU"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to learn the \"dormant\" transformations such that it does not have to rely on human expertise. The word dormant is used throughout the paper to describe cases where multiple calls of a certain optimization pass does not incur any more improvement.\n\nThe paper first dives into a program representation: a vector of active/dormant status of applied transformations. The paper assumes that the combination of the active/dormant status in the vector helps determine various characteristics of the program. Diving into more details about the vector, it seems that there are 3 elements (1: transform was applied + had effect, 0: transform was not applied, -1: transform was applied + had no effect).\n\nThe paper describes the input and output of the policy network where the input is the above representation from a run, and output is the likelihood of each transformation pass having impact in the subsequent run. The paper naturally drops this into a reinforcement learning environment.\n\nThe paper experimented the accuracy of activation predictor, end-to-end comparison between FlexPO and Oz/O3 (claims 12% faster than O3). The paper attributes this to fewer executed instructions and branch instructions.\n\nOverall, I do like the paper, but there seems to be some weaknesses to be addressed.\nI would like to re-evaluate after rebuttal."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper presents a very simple yet neat way of representing a program: vector of transformations."
            },
            "weaknesses": {
                "value": "- It is difficult to understand some of the figures.\n- The paper lacks the design details of the FlexPO besides its high level design. Seems to make it very difficult to reproduce.\n- Comprehensive set of results for runtime/code size against other approaches seem to be missing. IMHO it is very difficult to judge if the FlexPO has superior performance versus other approaches. It would be of more help if the authors can present in which benchmarks it performed better & why."
            },
            "questions": {
                "value": "* Please provide relation between the elements of Fig. 4 and Fig. 5, as it would be helpful to better understand the design.\n* Was the 56-element vector following AutoPhase include all the information? For example, wouldn't the graph approach in Cummins et al. 2020 complementary to the work?\n* Can you provide the compilation time overhead of the approach for big programs? In some real scenarios, we want very fast compilation without compromising on the runtime performance.\n* Can you provide more details about the FlexPO design? Size of the network, how some of the design decisions were made etc. It would be a great addition for the future researchers that build on this work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3913/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699110053171,
        "cdate": 1699110053171,
        "tmdate": 1699636351292,
        "mdate": 1699636351292,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JSmHidwVhU",
        "forum": "frjDLUebFY",
        "replyto": "frjDLUebFY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_wMoc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3913/Reviewer_wMoc"
        ],
        "content": {
            "summary": {
                "value": "The phase-ordering problem in compiler optimization, which is to find an optimal sequence of compilation transformations, is constrained by the vast number of potential transformation combinations. Traditional methods address this by *aggressively* pruning the search space using expert knowledge, but this risks excluding optimal solutions and lacks scalability. This paper introduces a more *conservative* approach using machine learning, which only eliminates non-optimal solutions, thus remaining adaptable to new transformations. The proposed solution, FlexPO, integrated with a reinforcement learning model, can explore an exponentially larger search space, resulting in programs that are up to 12% faster or 17.6% smaller than those generated by contemporary compilers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "* Applying \"learning\" domain information is a novel and effective strategy.\n* The resulting compilation framework could be highly beneficial for both researchers and practitioners."
            },
            "weaknesses": {
                "value": "* The paper lacks a comparative evaluation of the quality of dormant transformation prediction with existing works, such as [Kulkarni et al. 2004]."
            },
            "questions": {
                "value": "Thank you for submitting to ICLR 2024. The paper presents an interesting approach to reducing the search space by leveraging dormant information. While this is not the first work to utilize such information in solving the phase-ordering problem, its application to reduce the search space seems novel and effective, potentially yielding higher-quality code than -O3 and -Oz. My questions are as follows:\n\n* What is the typical range of compilation time when using FlexPO?\n* Considering that this work isn't the first to utilize dormant information in compiler transformation, a comparison with existing predictors like [Kulkarni et al. 2004] in terms of prediction quality would have been beneficial. How does FlexPO\u2019s quality of prediction compare?\n* In Section 5, the effect of a transformation (1) or its lack (-1) generally depends on which transformations are applied beforehand, which is essentially the phase-ordering problem. However, in Figure 3, the input to the activation predictor is a simple bit vector that doesn't capture this aspect, and the model appears to predict the dormant probability without considering this ordering information. How does FlexPO account for this?\n* In Section 6, FlexPO utilizes a database to reduce evaluation time for duplicate IRs. Could you elaborate on how this cache is implemented? Does it involve bitcode-by-bitcode comparison, or does it employ a hashing mechanism or something else to expedite comparison?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3913/Reviewer_wMoc"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3913/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699666642536,
        "cdate": 1699666642536,
        "tmdate": 1699666642536,
        "mdate": 1699666642536,
        "license": "CC BY 4.0",
        "version": 2
    }
]