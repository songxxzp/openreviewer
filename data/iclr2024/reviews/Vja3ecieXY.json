[
    {
        "id": "u6PPwV9Fm8",
        "forum": "Vja3ecieXY",
        "replyto": "Vja3ecieXY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_U1j2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_U1j2"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose GreenTrainer, a method to reduce the FLOPs of LLM fine-tuning by selective back-propagation. GreenTrainer consists of three techniques: tensor FLOPS profiling, tensor importance evaluation, and tensor selection (for update). Experiments show that the proposed method can achieve similar accuracy while reducing up to 64% of training FLOPs, which makes training faster and reduces energy usage."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is generally well-written and easy to follow. \n2. The proposed method can reduce the training FLOPs more compared to existing efficient fine-tuning methods like LoRA. \n3. The ablation studies are comprehensive, showing the effectiveness of the tensor selection mechanism and the scalability with larger models."
            },
            "weaknesses": {
                "value": "1. The template is highly altered to fit in more content. For example, the author section is removed, which may violate the policy. \n2. The paper misses some references to existing work that uses similar techniques. For example, [a] also uses sparse update for the model and a similar optimization goal as Equation 5 to get the tensor selection scheme, which also considers the backward cost for weights and activations.  Other related works include [b, c]. The authors should discuss and differentiate from existing works. \n3. There are some other efficient training methods focusing more on FLOPs reduction instead of parameter reduction like [d]. The authors may also want to include them as baselines since LoRA and Prefix-tuning are not designed for computation efficiency. \n4. Despite the effective FLOPs reduction, I would expect the method to use more GPU memory compared to methods like LoRA due to the larger optimizer states (since more weights are updated). The authors may also discuss the memory usage compared to the baseline methods, and see whether it can be combined with LoRA to achieve reduced memory and FLOPs at the same time (e.g., only add LoRA to updated tensors). \n5. The tensor importance estimation is based on the gradient information. Is it consistent throughout the training, or will the importance change?\n\n\n[a] Lin et al., On-Device Training Under 256KB Memory\n[b] He et al., Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning\n[c] Kwon et al., TinyTrain: Deep Neural Network Training at the Extreme Edge\n[d] Evci et al., Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning"
            },
            "questions": {
                "value": "Please see the weakness section. Thanks!"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Reviewer_U1j2"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2162/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698271005225,
        "cdate": 1698271005225,
        "tmdate": 1700695294479,
        "mdate": 1700695294479,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8y4l2cSjbs",
        "forum": "Vja3ecieXY",
        "replyto": "Vja3ecieXY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_CgrN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_CgrN"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose Green-Trainer for reducing the training cost for adapting pre-trained large language models to downstream applications. The idea is to leverage adaptive backpropagation for adaptively selecting the most appropriate set of LLM\ntensors for fine-tuning based on their importance and backpropagation cost in training. This is achieved by measuring the tensor importance based on the cumulative gradient changes of its weight updates in training. Also, a new FLOPs model is built for finding the optimal tensor from an exponential number of possibilities. Compared with existing fine-tuning methods, the proposed Green-Trainer can reduce 64% training FLOPs while achieving similar accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The problem of reducing the FLOPs when fine-tuning LLM is important. And the authors propose an effective method for achieving this while maintaining the model accuracy. \n\n2. The authors include a clear motivation for conducting adaptive backpropagation to reduce the computation cost of existing fine-tuning methods for LLMs. \n\n3. The authors conduct extensive experiments to demonstrate the effectiveness of the proposed method compared with the baseline methods."
            },
            "weaknesses": {
                "value": "1. The  novelty of the proposed method is rather limited. In particular, the method for evaluating the tensor importance has already been proposed for neural network pruning. And the authors did not cite any relevant literature here. \n\n2. The writing of the paper is sometimes confusing. For example, in section 3.1, it is not clear how such profiling is done for different layers in LLM. The authors should give some concrete examples of the FLOPs for these layers to better demonstrate the idea of tensor FLOPs profiling. \n\n3. Since the proposed dynamic programming can only find approximate solutions, there is no discussions on the accuracy of the found solution using the proposed approach."
            },
            "questions": {
                "value": "1. In the experiments, the authors only fine-tune the model for 5 epochs, then it is possible for some fine-tuning methods (eg. FT-Top2) to have the underfitting issue, how about fine-tuning for more epochs?\n\n2. How the running time is measured? There is a lack of hardware specifications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2162/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698681841086,
        "cdate": 1698681841086,
        "tmdate": 1699636149440,
        "mdate": 1699636149440,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HuJ7ftYcnG",
        "forum": "Vja3ecieXY",
        "replyto": "Vja3ecieXY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_P1Bv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_P1Bv"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes GreenTrainer, an approach for improved balancing of task quality and cost tradeoff of model finetuning.  The main idea is that only tensors that are important for the downstream task should be trained during finetuning so as to simultaneously minimize any quality loss and computation (FLOPs) costs. The paper further presents an algorithm for identifying important tensors for a downstream task at runtime to ensure adaptivity. The evaluation results show up to 64% reduction in FLOPs cost with little or no quality loss compared to fine-tuning the full model, and up to 4% quality improvement compared to existing FLOPs reduction techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Model fine-tuning is an important aspect of deep learning, and so the paper is tackling an important and timely problem in trying to reduce the computation costs of finetuning while preserving task quality. \n\nThe idea of identifying important tensors at runtime for the target downstream task is interesting and seems more promising than the existing static approaches. It seems that this would be the right solution for the problem, assuming it could be done efficiently. \n\nThe quality and reduction improvements presented in the evaluation are quite impressive."
            },
            "weaknesses": {
                "value": "The main concern is the vagueness on the efficiency or costs of identifying important tensors during finetuning. This makes it difficult for me to judge whether or not this is a practical approach. The tensor selection is simply claimed to be O(N), but I find this to be insufficient to understand the runtime costs. Specifically, I could not glean the following pertinent information from the draft.\n\n1. What is the e2e finetuning time of GreenTrainer compared to baselines.  \n\n2. How frequently are important tensors identified? Is it per iteration, per epoch (as suggested by Figure 1), or some other intervals? What is the frequency for the experimental results? \n\n3. What is the `m` binary vector, or at least the number of important tensors, for the experimental results?"
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2162/Reviewer_P1Bv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2162/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698889676170,
        "cdate": 1698889676170,
        "tmdate": 1700284835086,
        "mdate": 1700284835086,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "49tX2LM5ex",
        "forum": "Vja3ecieXY",
        "replyto": "Vja3ecieXY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_B8AP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2162/Reviewer_B8AP"
        ],
        "content": {
            "summary": {
                "value": "To address the significant computing costs and environmental impact associated with LLM fine-tuning, this paper proposes \"GreenTrainer,\" a new technique designed to minimize FLOPs through adaptive backpropagation. GreenTrainer selectively fine-tunes the most relevant parts of the LLM based on their importance and the computational cost of their training. Experimental results demonstrate that GreenTrainer can reduce training FLOPs by up to 64% compared to traditional full fine-tuning methods, while maintaining accuracy compared to full-finetuning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper addresses an important problem mentioned within it: fine-tuning 10K Llama-13b models can be 6.9 times more expensive than pre-training 175Bs. It is crucial to reduce carbon footprint and energy consumption in order to make LLMs sustainable.\n\nTraditional PEFT methods, such as LoRA and adapter, focus on reducing (learnable) parameters but discuss less about fine-tuning FLOPs and throughput. This work explores ways to actually reduce training costs, and the proposed method allows for flexible trade-offs between computation cost and fine-tuning quality.\n\nThe authors thoroughly compare the performance on SciTLDR and DialogSum datasets, demonstrating that GreenTrainer achieves up to 4% higher performance with faster training speed compared to existing schemes. Furthermore, the authors provide detailed analysis by varying importance metrics (Table 4), FLOPs reductions (Table 3), and LLM model sizes (Table 5)."
            },
            "weaknesses": {
                "value": "The justification for the effectiveness of adaptive selection is not clear. Language models (LLMs) are typically over-parameterized, and updating a random set of sparse parameters can achieve similar performance. Therefore, it is important to understand why and how adaptive selection properly selects the parameters that are worth fine-tuning. Baselines such as random selection, Fisher, and SNIP should be discussed to provide a comprehensive analysis.\n\nIt should be noted that adaptive selection can introduce additional complexity in the training process. Although the paper presents strategies to reduce this cost (dynamic programming), it still adds a layer of complexity to the training process with a complexity of O(N^2 T). There are concerns that this overhead will grow with the size of the model and soon become non-negligible.\n\nThe benchmarks in the paper only include summarization tasks and do not provide a holistic evaluation. To claim that a method reduces FLOPs without compromising accuracy, it is necessary to evaluate it on more benchmarks, such as GLUE and E2E NLG Challenge. Even within the summarization tasks, GreenTrainer does not show superior performance compared to LoRA under the **same latency budget**, as shown in Table 2 for FLAN-T5, where GT-0.4 and LoRA are shows very close performance and throughput."
            },
            "questions": {
                "value": "It is unclear whether the fine-tuning process includes the DP (data parallelism) overhead or if it is counted separately. It would be helpful to clarify the ratio of DP overhead during fine-tuning.\n\nHow X% of FLOPs saving can lead to a X% reduction in latency in Tab 2? LLMs fine-tuning  is  both  computation- and **memory-intensive**. Even with the same FLOPs, the latency can vary significantly depending on how the computation is allocated. For example, updating last 2 blocks may have similar performance with updating a partial set of all blocks, but the latency of latter one is much higher as it back-propagates to the first layer. To provide a more comprehensive understanding, additional benchmark details are needed to justify these observations.\n\nTo further evaluate the performance of GreenTrainer, more experiments should be conducted to compare it against baselines such as GLUE (which should be relatively inexpensive to execute) and other tasks like hellaswag, webquestions, and piqa. The community is also interested in the performance on Llama. If the 7B model is causing out-of-memory (OOM) issues, reporting the performance with LoAR and GreenTrainer only, or performing on OpenLlama-3B, would be valuable as well."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2162/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699144154312,
        "cdate": 1699144154312,
        "tmdate": 1699636149310,
        "mdate": 1699636149310,
        "license": "CC BY 4.0",
        "version": 2
    }
]