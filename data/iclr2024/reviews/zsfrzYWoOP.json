[
    {
        "id": "j955v9Me7D",
        "forum": "zsfrzYWoOP",
        "replyto": "zsfrzYWoOP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_bHFH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_bHFH"
        ],
        "content": {
            "summary": {
                "value": "In the growing field of machine learning-driven visual content generation, integrating human feedback can greatly enhance user experience and image quality. This study introduces FABRIC, a method that uses the self-attention layer in popular diffusion-based text-to-image models to condition the generative process on feedback images without additional training. Through a thorough evaluation methodology, the study demonstrates that iterative human feedback significantly improves generation results, paving the way for personalized content creation and customization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Iterative Workflow: The research emphasizes an iterative process, allowing for continuous refinement and improvement of generated images based on previous feedback.\n2. Dual Feedback System: By utilizing both positive and negative feedback images from previous generations, the method provides a balanced approach to influence future image results.\n3. Reference Image-Conditioning: This approach manipulates future results by conditioning on feedback images, offering a dynamic way to steer the generative process.\n4. Enhanced User Experience: By integrating human feedback into the generative models, the research ensures a more tailored and enhanced user experience in visual content generation.\n5. Potential in Personalized Content Creation: The findings have significant implications for creating personalized visual content based on individual user preferences and feedback.\n\nOverall, the paper introduces a robust and flexible method for refining machine-generated visual content through iterative human feedback, ensuring better alignment with user preferences."
            },
            "weaknesses": {
                "value": "1. Limited Expansion of Distribution: The method struggles to widen the distribution beyond the initial text-conditioned one provided by the model.\n2. Feedback Loop Limitation: Since the feedback originates from the model's output, it creates a cyclical limitation where the model might only reinforce its existing biases.\n3. Diversity Collapse: As the strength of the feedback and the number of feedback images increase, the diversity of the generated images tends to diminish. The images tend to converge towards a single mode that closely resembles the feedback images.\n4. Binary Feedback System: The current feedback collection method only allows users to provide binary preferences (like/dislike) for the images. This limitation prevents users from providing nuanced feedback about specific aspects of an image.\n5. Lack of Detailed Feedback: Users cannot specify which particular aspects of an image they appreciate or dislike. This restricts the model's ability to fine-tune its output based on detailed user preferences."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1988/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698107053090,
        "cdate": 1698107053090,
        "tmdate": 1699636130553,
        "mdate": 1699636130553,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "J9uAQOZhMf",
        "forum": "zsfrzYWoOP",
        "replyto": "zsfrzYWoOP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_vmZN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_vmZN"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a training-free method for text-to-image generation with iterative feedback, which is a novel and useful tool. The FABRIC framework is proposed and experiments are well-designed, showing the effectiveness of the method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper proposes a very interesting and practically meaningful topic.\n2. The method design is reasonable, which utilizes the power of self-attention in Stable Diffusion.\n3. Despite this is the first training-free iterative-feedback generation work, it designs interesting and sound experiments.\n4. The proposed method has great potential to optimize a lot of tasks based on Stable Diffusion."
            },
            "weaknesses": {
                "value": "The weakness of the paper mainly lies in writing. It is better to incorporate more method descriptions, including model design and formulations in the main script instead of the appendix."
            },
            "questions": {
                "value": "I'd like to accept this paper if the writing problem is addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1988/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1988/Reviewer_vmZN",
                    "ICLR.cc/2024/Conference/Submission1988/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1988/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698496613426,
        "cdate": 1698496613426,
        "tmdate": 1700805724894,
        "mdate": 1700805724894,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qVfDeKlstk",
        "forum": "zsfrzYWoOP",
        "replyto": "zsfrzYWoOP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_dJNm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1988/Reviewer_dJNm"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel method to control diffusion models to generate user-preferred images through iterative feedback. This method is based on augmenting the attention module. The proposed method is training-free and model-agnostic (as long as attention plays a core role in the image generation model), and can generate images based on any user preferences by having them provide positive and negative labels of their preference on images."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed technique is model-free and training-agnostic, and is easily applicable to most attention-based image generation methods.\n\n- The proposed technique surpasses baselines and enable existing models to follow preferences reasonably\n\n- Extensive exploration of important parts of the proposed technique: the trade-off between diversity and quality, and the effects of adjusting feedback strength on PickScore."
            },
            "weaknesses": {
                "value": "- **Limited technical novelty**: While the proposed method is effective in incorporating user feedback, the extension to enabling 'iterative feedback' is rather naive, and the feedback is constrained to binary labels (which the author(s) have acknowledged as a limitation). It would be more interesting to explore more advanced way of users' feedback across multiple rounds, and incorporating other modalities, such as text explanations beyond binary preferences.\n\n- **Lack of human rating in a paper focused on iterative human feedback**: While the author(s) have used reasonable proxy to evaluate the effectiveness of the model in following human preferences, it would strengthen the paper if the author(s) can include some form of user study, given this papers' focus is in incorporating human feedback in the image generation process.\n\n- **Missing discussion to some prior work**: I believe the proposed method has some technical similarity to prompt-based image editing methods, such as instruct-pix2pix [1] and prompt2prompt. [2] While the proposed method is different in the types of feedback and preference investigated, it would be great if the author(s) can systematically compare and survey related techniques that use attention map for feedback and/or image editing. I also have some doubts about whether it is reasonable to claim that the method \"outperformed\" supervised-learning baselines (HPS), see question below.\n\n*References:*\n\n[1] InstructPix2Pix: Learning to Follow Image Editing Instructions. Tim Brooks*, Aleksander Holynski*, Alexei A. Efros. CVPR 2023\n\n[2] Prompt-to-Prompt Image Editing with Cross Attention Control. Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, Daniel Cohen-Or. ICLR 2023."
            },
            "questions": {
                "value": "- While the paper claims to outperform a supervised-learning baseline (HPS LoRA), it is unclear to me how does HPS relate to PickScore, as they both appear to measure human preference. Would the author(s) please clarify how might they relate to each other? As the models are evaluated on PickScore but LoRA-tuned on HPS.\n\n- How does the method relate to/differ from prompt2prompt and instruct-pix2pix? As stated above, it would be helpful to systematically compare them (and other related prior work) in a table."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1988/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1988/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1988/Reviewer_dJNm"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1988/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698897933202,
        "cdate": 1698897933202,
        "tmdate": 1700673378645,
        "mdate": 1700673378645,
        "license": "CC BY 4.0",
        "version": 2
    }
]