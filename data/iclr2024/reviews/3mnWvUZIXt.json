[
    {
        "id": "mP9gkzD31A",
        "forum": "3mnWvUZIXt",
        "replyto": "3mnWvUZIXt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_ZrZp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_ZrZp"
        ],
        "content": {
            "summary": {
                "value": "This study offers a theoretical analysis of representation learning from video-based observations without labeled actions. The problem is formulated as a block Markov Decision Process with exogenous noise. Endogenous states are acquired through an encoder trained with one of three methods: a temporal contrastive loss, a single-state reconstruction loss (autoencoder), or a future state reconstruction loss.\n\nThe primary contribution of this paper is the establishment of a theorem that sets an upper bound on representation learning for future state prediction and the contrastive learning approach without noise. It also provides a lower bound in the presence of exogenous noise for these approaches, indicating that agents cannot distinguish between exogenous and endogenous noise. These results are further validated through experiments conducted in both a grid world and a visual environment. In cases without exogenous noise, representation learning proves successful, but it fails in its presence."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The paper is well-written, and the proofs are clear and concise.\n- The results address a significant and novel problem, namely, representation learning from noisy video-based data, which is of great interest in the current Reinforcement Learning (RL) community.\n- The theoretical results quantitatively address a major challenge in current methods.\n- The empirical results align well with the theoretical findings.\n- The study explores multiple approaches for representation learning.\n- Assumptions are thoroughly explained and justified.\n\nIn conclusion, I believe this work should be accepted, as it offers significant and relevant insights to the action-free RL research community. The paper's strengths and contributions make it a valuable addition to the field."
            },
            "weaknesses": {
                "value": "- While the paper is strong in many aspects, it would be beneficial to expand the experimental evaluation to a wider variety of environments to further validate the results.\n- Minor errors, such as unclosed brackets in equations under Assumption 3, should be corrected for clarity and correctness."
            },
            "questions": {
                "value": "Could we see some additional experiments in the revision?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Reviewer_ZrZp"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698682333863,
        "cdate": 1698682333863,
        "tmdate": 1699636670278,
        "mdate": 1699636670278,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZPPW4PABKB",
        "forum": "3mnWvUZIXt",
        "replyto": "3mnWvUZIXt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_TsKD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_TsKD"
        ],
        "content": {
            "summary": {
                "value": "The paper provides theoretical and empirical results for representations learning for decision-making using video data (without explicit knowledge of the actions). Two settings are studied: one where there is iid noise in the observation, and a setting where there is \"exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background\". Three techniques are compared: autoencoding, temporal contrastive learning, and forward modeling. Theoretical and empirical results are provided."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Interesting research questions that can have a big scientific impact\n- overall well-written\n- experiments follow good practice"
            },
            "weaknesses": {
                "value": "- Some parts of the text are not clear/accurate (see the remarks and questions below in the \"questions\" section). There are also typos, e.g. \"(...) temporal contrastive learning is probne to fail (...)\"\n- It is unclear how the key messages that are supposed to come from the theorems are actually deduced (see questions below)."
            },
            "questions": {
                "value": "Unclarities in the text:\n- The abstract mentions \"We evaluate these representational learning methods in two visual domains, proving our theoretical findings.\" Empirical evaluation can never prove theoretical results except if it looks at all possible cases for instance. In general, it can only illustrate them.\n- Beginning of Section 3, it is mentioned that \"Our goal is to learn a decoder $\\phi : X \\rightarrow [N]$ that learns information in the underlying endogenous state $\\phi^*(x)$ while throwing away as much irrelevant information as possible.\". I don't understand this sentence. Isn't it an encoder that is learnt? What is an endogenous state and what is $phi^*$?\n- \"ACRO achieves optimal performance across all tasks.\": do the authors mean better than other algorithms instead of optimal? (the optimal is not exactly reached and also basically not known.\n\nTheorems\n- What is $\\alpha$ in Theorem 1?\n- For Theorem 1, unless I'm mistaken, the only discussion that is directly about the theorem mentions \"These upper bound provide the desired result which shows that not only can we learn the right representation and near-optimal policy but also do without the online episodes scaling with ln |\u03a6|.\" How can that interpretation be made from the theorem?\n- For theorem 2, it also unclear how the interpretations can be deduced from the theorem itself."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698786717779,
        "cdate": 1698786717779,
        "tmdate": 1699636670155,
        "mdate": 1699636670155,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QrCkjC5Vmt",
        "forum": "3mnWvUZIXt",
        "replyto": "3mnWvUZIXt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_tXAJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_tXAJ"
        ],
        "content": {
            "summary": {
                "value": "This paper studies representation learning from videos in the context of reinforcement learning. In particular, this work focuses on representation learning in the presence of noice, either iid or exogenous. The theoretical results show that while the current methods should be able to work well with iid noise, the agent may need exponentially more samples when exogenous noise is present.\nThe experiments are conducted on GridWorld and VizDoom, and show that existing representation learning methods such as ACRO [1], temporal contrastive learning, VQ-VAE can learn with iid noise. \n\n[1] Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information, Islam et al, https://arxiv.org/abs/2211.00164"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The work presents thorough theoretical analysis of representation learning from videos with iid and exogenous noise and arrives at an interesting conclusion\n- The experimental results shed light on how temporal contrastive method performs compared to models that output images"
            },
            "weaknesses": {
                "value": "The experiments feel a little bit detached from the theoretical results: the are no experiments with iid noise, and the results with exogenous noise seem to mainly point to the fact that some representation methods are better than others, not that exogenous noise breaks everything. Only in Figure 6 do we see exogenous noise breaking forward modeling, while ACRO still works.\n\nI'm willing to raise my score if the authors present results with iid noise or justify the absence these results.\n\nSuggestions and comments:\nSection 4.2: \"remembering all of them can easily overcome the network\u2019s capacity focusing on the agent\u2019s state can better help the future predictions.\" reads weird.\nPage 2: \"probne\" should be \"prone\".\nAbove Equation 2, given $(x^{(i)}, k^{(i)}$ is missing a parenthesis\nAssumption 1: noisy-free should be noise-free\nJustification for Assumption 3: missing parenthesis in P_for\n\nSuggested additional related work:\n1. INFOrmation Prioritization through EmPOWERment in Visual Model-Based RL, Bharadhwaj et al, https://arxiv.org/pdf/2204.08585.pdf\n2. Joint Embedding Predictive Architectures Focus on Slow Features, Sobal et al, https://arxiv.org/abs/2211.10831\n3. Learning Invariant Representations for Reinforcement Learning without Reconstruction, Zhang et al, https://arxiv.org/abs/2006.10742"
            },
            "questions": {
                "value": "Can authors explain the connection between the theoretical part and experiments better? What do the results say in relation to the theoretical conclusions?\n\nIn Figure 4, the results seem to show that forward modeling and VAE are actually able to handle the exogenous noise. This is contrary to the theoretical result, is that right?\nOnly in Figure 6 do we see that indeed when noise is strong enough the forward modeling objective fails."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Reviewer_tXAJ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794097662,
        "cdate": 1698794097662,
        "tmdate": 1700667981946,
        "mdate": 1700667981946,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AwcpI5ADxM",
        "forum": "3mnWvUZIXt",
        "replyto": "3mnWvUZIXt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_sJQE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6169/Reviewer_sJQE"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces theoretical analysis for pre-trained representation learning using video data and focuses on two settings: where there is iid noise in the observation and where there is also exogenous noise in the observations. \n\nMore specifically the paper investigates three methods for video pre-training - autoencoding, temporal contrastive learning, and forward modeling, and introduces two main theorems. The first theorem provides an upper bound for the setting where there is only iid noise, and the second provides a lower bond when the observations also include exogenous noises. The first theorem leads to the conclusion that learning a representation from videos is provably correct when there is no exogenous noise, while the second means that learning is exponentially hard when there is exogenous noise (in contrast to learning from trajectory data, where the corresponding actions are available). The proofs were provided for temporal contrastive learning, and forward modeling, while evaluation and comparison to learning form trajectory data (ACRO) are provided for all three learning procedures (vector quantized variational autoencoder, temporal contrastive learning, and forward modeling)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This work introduces, for the first time, theoretical analysis and justification for pre-trained representation learning of policies from video data (under certain assumptions). In addition, the paper validates the theoretical analysis in practice, by experimenting on two challenging visual domains (GridWorld and ViZDoom). \n\nThe paper is well organized and clear to read and understand."
            },
            "weaknesses": {
                "value": "Although tested empirically, the paper does not provide a theoretical analysis for autoencoder-based approaches. Adding this analysis would make this work more complete. \nIn addition, the observation that temporal contrastive representation fails in the presence of exogenous noise is only empirical, justified with intuition, and lacks a more formal poof. \n\nThe analysis is restricted to training a fixed representation using only video data, without any fine-tuning stage of the learned representation. It would be nice to see an analysis of the common scenario of the fine-tuning stage.\n\nThe evaluation for iid noise with varying strength is missing (evaluation similar to Figure 6 but with iid noise). This evaluation is important for reliably comparing the performance of the setting with iid noise to that with exogenous noise."
            },
            "questions": {
                "value": "I would like to ask the following questions:\n\n1. Why are encoder-based approaches harder to analyze?\n\n2. If Assumption 3 (Margin Assumption) holds also for the exogenous noise in addition to the endogenous states, would learning from video data still be exponentially worse than learning from trajectory data? If the answer is yes, it means that learning a representation from videos is provably correct for cases where the margin assumption holds for all the transitions in the data. \n\n3. In addition to the intuition, is it possible to prove the observation that temporal contrastive representation falls short in the presence of exogenous noise, compared to the forward model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6169/Reviewer_sJQE",
                    "ICLR.cc/2024/Conference/Submission6169/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826388895,
        "cdate": 1698826388895,
        "tmdate": 1700737674169,
        "mdate": 1700737674169,
        "license": "CC BY 4.0",
        "version": 2
    }
]