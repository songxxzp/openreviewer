[
    {
        "id": "OsI288env2",
        "forum": "hJEMTDOwKx",
        "replyto": "hJEMTDOwKx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_2Nr6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_2Nr6"
        ],
        "content": {
            "summary": {
                "value": "Semantic id is an interesting and promising topic.\nThis task reform counting id to the identifier with semantic, which will faciliate many intelligence application including e-commerce.\nThis work presents a self-supervised framework to learn semantic IDs with a generative language model.\nBy progressive learning and contrastive learning, the authors achieve sequential discrete semantic indexier.\nThe paper is well-motivated and well-written.\n\nMajor Concerns:\n1. We have not seen a full section to anlayze the semantic IDs by demonstrating all sorts of key examples.\nAs a rising domain, many readers may wonder what the semantic IDs exactly look like and how they benefit the downstream tasks.\n2. In your experiments, could you provide some human annotator evaluation for the semantic of your generated IDs?\nThis is a key experiment, though we have seen enough assessment."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Semantic id is an interesting and promising topic.\nThis task reform counting id to the identifier with semantic, which will faciliate many intelligence application including e-commerce.\nThis work presents a self-supervised framework to learn semantic IDs with a generative language model.\nBy progressive learning and contrastive learning, the authors achieve sequential discrete semantic indexier.\nThe paper is well-motivated and well-written."
            },
            "weaknesses": {
                "value": "Experimental analysis is not sufficient to support the contribution."
            },
            "questions": {
                "value": "Major Concerns:\n1. We have not seen a full section to anlayze the semantic IDs by demonstrating all sorts of key examples.\nAs a rising domain, many readers may wonder what the semantic IDs exactly look like and how they benefit the downstream tasks.\n2. In your experiments, could you provide some human annotator evaluation for the semantic of your generated IDs?\nThis is a key experiment, though we have seen enough assessment."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698640152871,
        "cdate": 1698640152871,
        "tmdate": 1699636365761,
        "mdate": 1699636365761,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ufgPDJGXSv",
        "forum": "hJEMTDOwKx",
        "replyto": "hJEMTDOwKx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_HnqK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_HnqK"
        ],
        "content": {
            "summary": {
                "value": "Discrete semantic IDs are useful in information retrieval tasks. They are often learned by performing some sort of hierarchical clustering over off-the-shelf item representations which is not ideal as they may not be aligned with the downstream task. This paper presents an approach to learn discrete semantic IDs of items in a self-supervised manner. The proposed approach uses a transformer decoder architecture which encodes the item description and decodes it into semantic IDs which is further coupled with a small transformer model that consumes these semantic IDs, item description and tries to perform MLM task. The paper also describes and suggests ways to circumvent the challenges encountered while learning these semantic IDs."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is in general well-written and easy to follow\n- The approach is novel for learning semantic IDs in information retrieval, and the optimization challenges in such learning problems is highlighted"
            },
            "weaknesses": {
                "value": "My major concerns with the paper are the weak evaluation and baselines, and overall the training seems to need a lot of bells and whistles to succeed.\n- DPR dual encoder is not a strong baseline; DPR is almost 10% behind SOTA dual-encoder approaches on standard benchmarks\n- Baselines in section 4.2 are weak since they are using an off-the-shelf text encoder and hence have no knowledge about the task; a very simple baseline that could be tried here is to train a dual-encoder model on this corpus and then cluster the embeddings"
            },
            "questions": {
                "value": "- The learned semantic ID lengths seem to be very small (1-3), is this because of training instability when scaling to larger ID lengths? Do the other generative baselines also use the same ID lengths?  \n- Why not use the full MS-Marco dataset instead of the 1M sampled one?\n- How does the performance gets affected when using a more powerful reconstructor? perhaps an ablation on the number of layers in the reconstructor might be helpful here\n- Is the contrastive loss $\\mathcal{L}_{\\text{contrastive}}$ computed over all documents?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4028/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4028/Reviewer_HnqK",
                    "ICLR.cc/2024/Conference/Submission4028/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790056529,
        "cdate": 1698790056529,
        "tmdate": 1700676480438,
        "mdate": 1700676480438,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qBhsyYlNqD",
        "forum": "hJEMTDOwKx",
        "replyto": "hJEMTDOwKx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_dU5G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_dU5G"
        ],
        "content": {
            "summary": {
                "value": "The authors propose LMIndexer, a self-supervised method to learn the semantic IDs of documents using sequence-to-sequence models. A semantic ID of a document is a sequence of integers that are indexes/row numbers of a codebook embedding matrix. Three loss functions are designed and used to train the sequence-to-sequence model: a reconstruction loss, a contrastive loss, and a commitment loss. The proposed method is evaluated on three downstream tasks: sequential recommendation, product search, and document retrieval. The results show good improvement over some SOTA methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-\tThe proposed method formulates the semantic ID learning problem as a sequence-to-sequence learning method, which is novel according to related work discussed in the paper.\n-\tTechnical challenges are described clearly.\n-\tSOTA techniques are used in the proposed framework.\n-\tThe experimental results show that the proposed method outperforms some SOTA methods in the three downstream tasks."
            },
            "weaknesses": {
                "value": "-\tThe paper says that the proposed method \"learns the document\u2019s discrete semantic embeddings and its hierarchical structure simultaneously\". But it is not clear what the authors mean by the hierarchical structure of a document, how the proposed method is guaranteed to learn such a structure, and whether the proposed method actually learns such a structure. \n\n-\tThe size of the semantic ID (T) is set to less than or equal to 3 in the experiments, which is surprisingly small. Figure 5 shows the performance increases with T. Why not trying bigger T values? Would an ID with length 3 be informative enough?\n\n-   How should the codebook size be determined? It seems that only three sizes are tried in the experiments. How does the size of the codebook affect the performance?\t\n\n-  The performance metric used in ID quantitative study, AMI (in Table 1), is not defined or explained. \n\n-   Not clear what the word clouds picture (Figure 3) is trying to show? The text explaining it is confusing. What do you mean by \u201ctwo semantic ID prefixes\u201d? Are the two prefixes from the same generated ID or two different IDs? \n\n-   It would be better if authors provided other performance metrics such as latency for the retrieval in comparison with baselines.\n\n-  The authors mentioned the model could be fine-tuned on downstream tasks such as retrieval or recommendation tasks. Fine-tuning would change the model weights and then the previously generated semantic IDs would be changed as well, which may affect the ground-truth ID used in fine-tuning. Does it cause any problem?"
            },
            "questions": {
                "value": "Please see the questions in the above section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818037028,
        "cdate": 1698818037028,
        "tmdate": 1699636365587,
        "mdate": 1699636365587,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YFGCEvEzDb",
        "forum": "hJEMTDOwKx",
        "replyto": "hJEMTDOwKx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_4DWK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4028/Reviewer_4DWK"
        ],
        "content": {
            "summary": {
                "value": "This paper formulates the problem of learning semantic IDs by simultaneously capturing the document's semantic representations and its hierarchical structure. It introduces an innovative self-supervised approach designed to acquire semantic IDs directly from the input document using a generative language model. Experimental results on five datasets from various domains demonstrate that the proposed method consistently outperforms competitive baselines by a significant margin."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper presents the \"LMINDEXER\" approach as a solution to the challenges inherent in generating semantic IDs from textual data. The approach is carefully crafted to capture both the semantic representations and hierarchical structure of documents simultaneously.\n\n2. The paper demonstrates the effectiveness of the LMINDEXER approach through empirical evidence gathered from experiments on three distinct downstream tasks, utilizing data from diverse domains.\n\n3. The paper exhibits a well-organized structure and offers an easily digestible reading experience."
            },
            "weaknesses": {
                "value": "1. While this paper presents an approach termed LMINDEXER, it's important to note that the novelty of the method is somewhat limited. Additionally, the paper lacks a comprehensive discussion of related work, including notable prior efforts that have explored the use of encoders for text encoding and decoders for reconstruction in the context of information retrieval. Several works, such as [1], [2], and [3], have examined similar techniques and deserve acknowledgment for their contributions to the field.\n\n[1] Less is More: Pretrain a Strong Siamese Encoder for Dense Text Retrieval Using a Weak Decoder (EMNLP 2021)\n\n[2] A Contrastive Pre-training Approach to Learn Discriminative Autoencoder for Dense Retrieval (CIKM 2022)\n\n[3] RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder (EMNLP 2022)\n\n\n2. In the context of document retrieval, it would be beneficial to broaden the comparison to include more generative retrieval baselines. For instance, evaluating how the LMINDEXER approach compares to FM-index-based SEAL or other recent generative retrieval methods would provide a more comprehensive understanding of its performance. Focusing solely on comparisons with DSI, which may be considered a relatively weaker baseline, might not offer a complete picture of the method's capabilities.\n\n3. While the proposed self-supervised approach has the potential to address the \"new document problem\" by automatically acquiring semantic IDs, it would be valuable to see experimental results that explicitly address this issue. Incorporating experiments that involve adding new documents to the model and assessing its adaptability and performance in such scenarios would provide a more robust evaluation.\n\n4. An important consideration when using automatically generated semantic IDs is the possibility of duplication. It is crucial to include a discussion or explanation of how the LMINDEXER approach handles or mitigates this potential issue. A detailed exploration of the approach's robustness in preventing or addressing duplication would enhance the paper's completeness and practicality."
            },
            "questions": {
                "value": "1. The authors should consider expanding their related work section to include the most recent developments in generative Information Retrieval (IR) techniques. Additionally, they should include a comparative analysis of these recent works alongside the proposed LMINDEXER method in the experimental section. This would provide a more comprehensive overview of how LMINDEXER stacks up against the state-of-the-art in generative IR.\n\n2. It is essential for the authors to address the issue of handling new documents within the LMIndexer framework. The paper should discuss how this framework manages the addition of new documents, what mechanisms or strategies are employed, and the performance of the LMIndexer approach in comparison to baseline methods when confronted with this \"new document\" scenario. This analysis would help assess the adaptability and robustness of the approach.\n\n3. To ensure that distinct semantic IDs are assigned to different documents, the paper should provide detailed explanations and discussions regarding the mechanisms and safeguards in place within the LMIndexer framework. Experimental results or case studies showcasing how the system maintains distinct semantic IDs for various documents would add substantial value to the paper, reinforcing its practicality and effectiveness in preventing semantic ID duplication."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4028/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824512477,
        "cdate": 1698824512477,
        "tmdate": 1699636365510,
        "mdate": 1699636365510,
        "license": "CC BY 4.0",
        "version": 2
    }
]