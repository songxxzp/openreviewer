[
    {
        "id": "yCUN5xk2M8",
        "forum": "7FHrZuKogW",
        "replyto": "7FHrZuKogW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
        ],
        "content": {
            "summary": {
                "value": "A neural diffusion GNN model coupling the evolution of both node features and graph adjacency matrix is proposed. Analytical studies on the contractive properties of this model across model layers are provided."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Using a diffusion process to model the joint evolution of node features and graph adjacency matrix seems to be novel. Numerical experiments indicate that such an approach can provide robustness against adversarial attacks."
            },
            "weaknesses": {
                "value": "1. The analytical results show contractive properties of the feature/adjacency matrix evolution across model layers for a given input. I am unclear how this proves robustness of the GNN model to input or structure perturbation. \n\n1. Missing comparison to the work \u201cOn the robustness of graph neural diffusion to topology perturbations,\u201d NeurIPS 2022. What are the additional things we learn from this current paper? The results in the NeurIPS 2022 paper relate explicitly to robustness w.r.t. input perturbations."
            },
            "questions": {
                "value": "1. Please give more information on the attack type. Is it inductive, modification/injection, whitebox/blackbox?  \n\n1. What is the adaptive attack procedure? It seems the paper simply uses unit tests from Mujkanovic et al. (2022). These cannot be considered to be adaptive attacks for the proposed model. Mujkanovic et al. (2022) has emphasized this point too: \"we cannot stress enough that this collection does not replace a properly developed adaptive attack\".\n\n1. GNNGuard is mentioned but not used as baseline in Table 1. \n\n1. The attacks used do not seem strong enough (I am unclear of their settings as well). E.g., in Table 1, even under 25% attack, GCN still has >40% accuracy. In other related papers on GNN adversarial attacks (e.g., Fig. 1 of Mujkanovic et al. (2022)), usually GCN would have performed much worse with accuracies below 20-30%."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697789471770,
        "cdate": 1697789471770,
        "tmdate": 1699636606794,
        "mdate": 1699636606794,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YzQHti11K5",
        "forum": "7FHrZuKogW",
        "replyto": "7FHrZuKogW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_SPJa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_SPJa"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce an approach to enhance the robustness of GNNs against adversarial perturbations by leveraging the concept of contractive dynamical systems."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper presents a novel architecture, CSGNN, that innovatively integrates the principles of contractive dynamical systems to enhance the robustness of GNNs against adversarial poisoning attacks.\n2. The simultaneous evolution of node features and the adjacency matrix is a distinctive feature that can potentially offer intrinsic resistance to adversarial perturbations.\n3. The authors fortify their claims with a rigorous theoretical analysis."
            },
            "weaknesses": {
                "value": "1. Inadequate Literature Review: The paper's glaring omission of pivotal related works is concerning. The idea of enhancing NN robustness via dynamical systems isn't novel, even within the GNN realm. The authors' failure to acknowledge, let alone differentiate their work from seminal papers [1][2][3][4][5], is a significant oversight.\n    \n\n2. Lack of Clear Motivation: The paper's design choices seem arbitrary, with many equations appearing devoid of clear rationale. For example:\n>The reasoning behind assuming a piecewise constant function in eq(6).\n>The ambiguity surrounding the gradient operator of $A$ in eq(8).\n>The seemingly ad-hoc design of eq(8) and its alignment with the paper's theorems.\n>The choice to enforce symmetry on $\\tilde{\\mathbf{K}}_l$.\n>The intricate design of the adjacency matrix update in eq(14) lacks clear justification.\nThe paper should not be a mere mathematical exercise; it should be accessible and provide clear motivations for design choices.\n\n3. Reproducibility Concerns: The absence of code hinders the verification of the paper's claims. Critical aspects, such as adherence to the adjacency update mechanism in eq(14) and the positive definiteness of $\\tilde{\\mathbf{K}}_l$, remain unchecked.\n\n4. Computational Overheads: The complete matrix representation in eq(14) suggests significant computational demands. The authors should elucidate the memory and time overheads.\n\n5. Narrow Attack Scope:\nThe paper exclusively focuses on poisoning attacks. Is this indicative of the theorems being specifically tailored for such attacks? The theorem statements, including their assumptions and conclusions, don't seem to impose such constraints. What is the rationale behind primarily considering poisoning attacks? Reference [6] suggests that injection attacks pose a greater threat than poisoning attacks. The authors should address these concerns and expand their experiments to include injection attacks, irrespective of the model's performance against them.\nAdditionally, the inclusion of black-box attacks in the evaluation is necessary.\nThe model exhibits suboptimal performance on the Pubmed dataset. Does this suggest that the efficacy of your models and theorems is dataset-dependent? It would be insightful to understand how the model fares on different datasets, especially those characterized by heterophily.\n\n6. Lack of Large-Scale Graph Datasets:\nThe current evaluation is limited to smaller datasets such as Cora, Citesser, and Polblogs. It would be beneficial to see how the model performs on more extensive, widely-recognized datasets like the ogbn series.\n\n\nOverall, I believe this paper has promise. However, in its present state, I cannot endorse its acceptance. I strongly urge the authors to undertake a thorough revision and consider resubmitting to an upcoming top-tier machine learning conference.\n\n[1] Zakwan, Muhammad, Liang Xu, and Giancarlo Ferrari-Trecate. \"Robust classification using contractive Hamiltonian neural ODEs.\" IEEE Control Systems Letters 7 (2022): 145-150.\n\n[2] Kang, Qiyu, Yang Song, Qinxu Ding, and Wee Peng Tay. \"Stable neural ode with lyapunov-stable equilibrium points for defending against adversarial attacks.\" Advances in Neural Information Processing Systems 34 (2021): 14925-14937.\n\n[3] Huang, Yujia, Ivan Dario Jimenez Rodriguez, Huan Zhang, Yuanyuan Shi, and Yisong Yue. \"Fi-ode: Certified and robust forward invariance in neural odes.\" arXiv preprint arXiv:2210.16940 (2022).\n\n[4] Yang, Runing, Ruoxi Jia, Xiangyu Zhang, and Ming Jin. \"Certifiably Robust Neural ODE with Learning-based Barrier Function.\" IEEE Control Systems Letters (2023).\n\n[5] Song, Yang, Qiyu Kang, Sijie Wang, Kai Zhao, and Wee Peng Tay. \"On the robustness of graph neural diffusion to topology perturbations.\" Advances in Neural Information Processing Systems 35 (2022): 6384-6396.\n\n[6] Chen, Yongqiang, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han, and James Cheng. \"Understanding and improving graph injection attack by promoting unnoticeability.\" arXiv preprint arXiv:2202.08057 (2022)."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698760379714,
        "cdate": 1698760379714,
        "tmdate": 1699636606678,
        "mdate": 1699636606678,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4kQXtZwkDC",
        "forum": "7FHrZuKogW",
        "replyto": "7FHrZuKogW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_fwuD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_fwuD"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel approach to enhance the robustness of Graph Neural Networks (GNNs) against adversarial perturbations using contractive dynamical systems. The authors establish the mathematical foundations of their architecture, offering theoretical insights into its expected behavior. Through real-world benchmarks, they validate its effectiveness, achieving comparable or superior performance to existing methods. The paper's contributions encompass a new GNN architecture, a theoretical framework for behavior analysis, and empirical proof of its ability to bolster GNN resilience against adversarial attacks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper addresses the critical issue of improving GNNs' robustness against adversarial attacks. It introduces an innovative approach to enhance Graph Neural Networks' (GNNs) robustness against adversarial perturbations by employing contractive dynamical systems. The simultaneous evolution of node features and adjacency matrices is a unique aspect of this approach, demonstrating a high degree of originality.\n\n2. The paper provides a rigorous mathematical derivation of the proposed architecture and comprehensive empirical evaluations. The authors offer theoretical insights into the expected behavior of their method, and empirical results affirm its effectiveness in bolstering GNNs against adversarial attacks.\n\n3. The paper is well-written, ensuring clarity and accessibility for readers."
            },
            "weaknesses": {
                "value": "No obvious weaknesses from my perspective."
            },
            "questions": {
                "value": "1. What are the assumptions behind Theorem 1 & 2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767002295,
        "cdate": 1698767002295,
        "tmdate": 1699636606525,
        "mdate": 1699636606525,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0ix5pOdrFb",
        "forum": "7FHrZuKogW",
        "replyto": "7FHrZuKogW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
        ],
        "content": {
            "summary": {
                "value": "This work introduces massage passing layers in the context of graph representation learning, inspired by differential equations with contractive properties, that have promising capabilities in improving the robustness of GNNs. This claim is then further strengthened by a complete theoretical analysis and extensive benchmark covering many GNN architectures & threat models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Paper is well written.\n- Complete theoretical analysis supported by strong results."
            },
            "weaknesses": {
                "value": "Unfortunately, the paper is not self-contained for readers with no background in contractive systems and dynamical systems. Since I'm not familiar with these techniques, it's hard for me to point out any weaknesses beyond educated guesses."
            },
            "questions": {
                "value": "I do not have major questions about the manuscript."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824338261,
        "cdate": 1698824338261,
        "tmdate": 1699636606419,
        "mdate": 1699636606419,
        "license": "CC BY 4.0",
        "version": 2
    }
]