[
    {
        "id": "XAfhPJKJKf",
        "forum": "i8bdPSmOwk",
        "replyto": "i8bdPSmOwk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_TEdQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_TEdQ"
        ],
        "content": {
            "summary": {
                "value": "1.\tThe authors observe the unstable gradient in conditional sampling process. And the proposed momentum-driven gradient filtering algorithm to stabilize the conditional clean estimation gradient is sound, which uses the historical gradient to constrain the current gradient.\n2.\tThe motivation of the gradient suppression is also reasonable. The prediction error is larger at the early stage of denoising process, so the corresponding gradient should be suppressed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe authors observe the unstable gradient in conditional sampling process. And the proposed momentum-driven gradient filtering algorithm to stabilize the conditional clean estimation gradient is sound, which uses the historical gradient to constrain the current gradient.\n2.\tThe motivation of the gradient suppression is also reasonable. The prediction error is larger at the early stage of denoising process, so the corresponding gradient should be suppressed."
            },
            "weaknesses": {
                "value": "1.\tAlthough the momentum gradient updating is reasonable, this may not be the first work to introduce momentum gradient updating to diffusion reverse sampling process. The work [1] has designed an adaptive momentum sampler to boost the performance, which also uses first-order and second-order. Since this work is also recent, so it is fine to me. Although that work focuses on unconditional sampling, I think maybe you should discuss the relation and difference between your work and that work.\n\n[1] Boosting Diffusion Models with an Adaptive Momentum Sampler\n\n2.\tFor the gradient suppression, I agree with the motivation that the direction error is larger at the early stage of the denoising process, and the corresponding sampling process should be adjusted. However, according to Algorithm1, the conditional gradient is suppressed. Since the semantic and layout is constructed when t is large, and the gradient compression is larger there, it may destroy the semantic matching between the final generated image and the condition. This may be more serious in some tasks with stricter requirement, such as inverse problems."
            },
            "questions": {
                "value": "See the weakness part"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4280/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671128343,
        "cdate": 1698671128343,
        "tmdate": 1699636395752,
        "mdate": 1699636395752,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "422QIJ6TqR",
        "forum": "i8bdPSmOwk",
        "replyto": "i8bdPSmOwk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_SuQ1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_SuQ1"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an approach for conditional sampling in denoising diffusion probabilistic models (DDPM). It figures out that the performance gap between the clean and noised sample-based methods is mainly caused by the incorporation of estimation deviation in the clean-estimation process, and tries to solve it by implementing momentum-driven gradient filtering and a guidance suppression scheme. The proposed method exhibits superior performance in clean guided conditional image generation, and showcases its state-of-the-art capability in arbitrary style transfer tasks without the requirement of labeled datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The author theoretically analysis the drawbacks of the clean guided methods and provide some results to proof their claims. \n2. The author propose a method to solve the problem, and conduct experiments to its effectiveness.\n3. Except the style transfer part, the motivation is clear and the paper is well-written."
            },
            "weaknesses": {
                "value": "1. About the style transfer task, I do not think it is appropriate to appear in this paper. According to my understanding, the goal of this paper is to bridging the performance gap between clean and noised sample-based methods. However, the experiment of style transfer task has no relationship with this topic. Therefore, I think the author better give an explanation about why conducting this part of experiments. Besides, according to the above reason, I also recommend the author to remove Section 2.3.\n2. Lacking the results of other works on improving clean-estimation guidance in style transfer task.\n3. The authors claim in Section 4.2 that the clean classifier+guidance function proves to be less reliable than the noise-robust classifier. Could the authors give a more direct proof like Figure 2?\n4. About the experiments in Section 5.1:\n1) the authors do not clarify which table is the results of this experiment\n2) the authors mention FreeDoM and Universal Guidance in the paper, but only provide the results of ADM+FreeDoM. What about the results of DiT+FreeDoM and DiT/ADM+Universal Guidance?\n5. The authors is recommended to prove the results of other methods on image generation task for comparison.\n6. In Section 5.2, there is no description about what is I_cs.\n7. In Section 5.3, the ablation results on style transfer task indicate that \"Raw+Filtering & Suppression\" can achieve the best results on L_content. However, it's results on L_style is only the third best. Does this indicate that \"Raw+Filtering & Suppression\" tends to preserve the original image's features rather than transferring to a new style?"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4280/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4280/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4280/Reviewer_SuQ1"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4280/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747121621,
        "cdate": 1698747121621,
        "tmdate": 1699636395665,
        "mdate": 1699636395665,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zYKMtEnDcJ",
        "forum": "i8bdPSmOwk",
        "replyto": "i8bdPSmOwk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_hNt5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4280/Reviewer_hNt5"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on conditional sampling of denoising diffusion probabilistic models with momentum-driven noise-free guidance. The proposed sampling method utilizes clean guidance functions, eliminating the need for additional training. Most importantly, they find that the primary reason for the worse performance of the previous noise-free guidance is by inaccurate clean estimations, especially during the early denoising stage. Then, they propose several simple yet effective methods for solving this problem. Furthermore, they demonstrate the feasibility and generalization capability on several downstream tasks like conditional image generation and style transfer."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The studied research topic DDPMs' conditional sampling is important and interesting in AIGC, which can be easily embedded into multiple DDPMs.\n2. The authors found that the primary reason for the worse performance of the previous noise-free guidance is by inaccurate clean estimations, especially during the early denoising stage, which is also their main motivation.\n3. The authors proposed the momentum-driven gradient filtering to filter noise in the gradient.\n4. The experimental results on two downstream tasks including conditional generation and style transfer show that SOTA performance with many previous latest methods."
            },
            "weaknesses": {
                "value": "1. Limited Novelty: We know that momentum can obtain a more stable updating process, but as shown in Fig. 2b, the trends of filtered gradient and unprocessed gradient are almost the same rather than a gradual stabilization process. The simple method proposed in this paper is not the most effective solution to prevent noise in the gradient, but only alleviates the problem of early stage noise to some extent\n2. Limited Performance Improvement: In Table 1 in Section 5.1, I note that the proposed method shows the limited improvement compared with 'raw clean guidance', e.g., DiT in sFID, Prec and Rec, and ADM in Prec and Rec.\n3. Missed Experiments: 1) In Table 1 in Section 5.1, I note that the authors only compared clean estimation-based conditional without comparing noise-guidance-based methods. I am curious whether the results generated by the proposed method are comparable to noise-guidance-based methods. 2) In figures 5, 6, and 7 of the qualitative results in the appendix, I can't see any comparisons with other baselines. Please add some experiments to show its ability. 3) what is the specific sampling cost in the experiments? Please add experiments to compare clean-estimation guidance techniques."
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4280/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698760874046,
        "cdate": 1698760874046,
        "tmdate": 1699636395580,
        "mdate": 1699636395580,
        "license": "CC BY 4.0",
        "version": 2
    }
]