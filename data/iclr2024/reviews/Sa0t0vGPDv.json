[
    {
        "id": "UFFQDEhPNV",
        "forum": "Sa0t0vGPDv",
        "replyto": "Sa0t0vGPDv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_NqbF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_NqbF"
        ],
        "content": {
            "summary": {
                "value": "Generative models may hallucinate APIs when generating their responses. To this end, this paper proposes FARS to use constrained decoding to limit the token selection during API calls, making LLMs generate desired API formats. Specifically, the authors construct a finite state machine to enforce the decoding to follow the structure Begin-API-Argument-Value-End and limit the number of available tokens to the number of designed states (e.g., # APIs when generating APIs).  The implementation is based on the dynamic trie implementation to save the space cost. Experiments show the effectiveness of FARS compared with unconstrained LLMs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. FARS is a novel approach that involves an inference-time intervention to enforce LLMs to generate the correct API formats\n2. The approach is sound and well-illustrated.\n3. Experiment results show the improvement is quite apparent."
            },
            "weaknesses": {
                "value": "1. Lack of wall time analysis. I am not sure if this method will bring much extra time cost since the approach seems to involve many CPU operations. It will be good to add a wall time comparison.\n2. The approach is more like eliminating \"syntax\" error but not \"semantic\" error. Will FARS eliminate \"syntax\" error but increase \"semantic\" error? For example, the function is originally semantically correct but with a wrong format, whereas FARS corrects the syntax but brings semantic errors. It will be good to see how much performance is obtained by \"syntax\" correction and if FARS introduces more \"semantic\" errors.\n3. Lack of some implementation details. Please see questions for details."
            },
            "questions": {
                "value": "What temperature is used in the experiments? The comparison may be less convincing if the temperature is high for baseline models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2019/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2019/Reviewer_NqbF",
                    "ICLR.cc/2024/Conference/Submission2019/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2019/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791846596,
        "cdate": 1698791846596,
        "tmdate": 1700512223571,
        "mdate": 1700512223571,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VLqefyWmfT",
        "forum": "Sa0t0vGPDv",
        "replyto": "Sa0t0vGPDv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_msYT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_msYT"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new approach called FARS to enable Large Language Models (LLMs) to generate the right API calls without the need for shortlisting instructions or examples. The approach uses a finite state machine-based constrained decoding algorithm to ground the generation of LLMs to a set of available APIs. The paper demonstrates the effectiveness of FARS on three datasets - SNIPS, MultiWOZ, and a Smart Home Control dataset, showing significant improvements over an unconstrained LLM."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The paper introduces a novel approach to address the problem of generating the right API calls without shortlisting instructions or examples.\n2) The use of a finite state machine-based constrained decoding algorithm provides a structured and grounded approach to API generation.\n3) The experimental results on the three datasets demonstrate the effectiveness of FARS, showing significant improvements over an unconstrained LLM."
            },
            "weaknesses": {
                "value": "1) The paper could provide more details on the implementation of FARS, including the specific steps and algorithms used to integrate the finite state machine with the LLM.\n2) The paper lacks a thorough discussion of the limitations and potential future directions of the proposed approach."
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2019/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2019/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2019/Reviewer_msYT"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2019/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698829791419,
        "cdate": 1698829791419,
        "tmdate": 1699636133181,
        "mdate": 1699636133181,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wMsV093UKy",
        "forum": "Sa0t0vGPDv",
        "replyto": "Sa0t0vGPDv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_QTFS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2019/Reviewer_QTFS"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel approach called FSM-Augmentation to make Language Models generate correct API calls by grounding their output in a Finite State Machine that describes valid API calls. This method, FARS, aims to address the issue of LLMs \"hallucinating\" plausible but incorrect API calls by using a constrained decoding algorithm based on FSM.\n\nFARS's approach allows for the dynamic selection of API arguments and free-text values, improving upon traditional methods that rely on fixed argument orders. The FSM design enables the LLM to predict the order and subset of arguments, enhancing flexibility and accuracy."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper introduces a finite state machine-augmented approach, which is an improvement over traditional LLMs that often hallucinate plausible but incorrect API calls. By grounding the LLM's generation process in a finite state machine, the model is constrained to produce only valid API calls, which is a practical solution to a common problem in LLM outputs.\n\n2. No Need for External Retrievers: Unlike other methods that rely on external retrievers or exemplars to guide the generation of API calls, FARS operates independently by incorporating the API catalog information into the FSM. This reduces the complexity and potential points of failure associated with external dependencies."
            },
            "weaknesses": {
                "value": "1. The effectiveness of FARS is contingent on the FSM's knowledge of the available API catalog. It is not clear how easy to update FSM if there is a new API function added\n2. Potential Overhead during inference. Creating and updating the FSM to reflect the current state of API offerings could introduce overheads. How fast is the inference speed of FARS compared with unconstrained LLM?\n3. The scope of the paper's evaluation is limited to the Vicuna-33B model's performance on specific datasets. A broader assessment across various models would provide a more comprehensive understanding of FARS's effectiveness and generalizability."
            },
            "questions": {
                "value": "1. What is the retrieval model used in API retrieval setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2019/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699255182838,
        "cdate": 1699255182838,
        "tmdate": 1699636133122,
        "mdate": 1699636133122,
        "license": "CC BY 4.0",
        "version": 2
    }
]