[
    {
        "id": "tul4oRzHr0",
        "forum": "Qwxe8WKSgy",
        "replyto": "Qwxe8WKSgy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_uy5T"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_uy5T"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors develop a machine-learning-guided large neighborhood search (LNS) procedure that provides a heuristic approach to general MIPs. This includes several improvements over existing (LNS) procedures including:\n- A new approach to handling general binary variables, wherein a learning model is used to predict the tightness of bounds placed on these variables\n- A new way of encoding MIP problems as graphs, wherein the graph includes nodes for the objective function\n- A method wherein a learning model is used to generate local branching constraints\nThe authors provide extensive computational results on a range of problems."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The paper features some novel improvements to machine-learning-guided large neighborhood search approaches to MIP. This is a timely topic with high potential significance. The computational results are extensive and impressive."
            },
            "weaknesses": {
                "value": "Overall, I found this paper to be extremely unclear and poorly written. For example:\n- The authors state that \"we represent each general integer variable with $d=\\lceil \\log_2(ub - lb) \\rceil$ variables, where ub and lb are original variable upper and lower bounds, respectively. The subsequent optimization is applied to the substitute variables\". The authors should show this substitution more explicitly. The authors seem to indicate that the bound-tightening scheme is then fixing some of these substitute variables. I am aware of some common binarization schemes (e.g. Owen & Mehrota 2002), but the bound-tightening scheme given in algorithm 1 does not seem to correspond with a variable-fixing approach to any binarization scheme that I can think of.\n-  I was completely unable to understand even at a high-level what their \"branching\" approach entailed until I read Algorithm 3 in the appendix. Readers should not have to read the appendix to make sense of the main text. In fact, their algorithm does not really \"branch\" as far as I can tell. \"Branching\" typically means building a search tree that divides the space of solutions. Instead, the algorithm adds local branching constraints similar to Fischetti and Lodi (2003) or Liu, Fischetti and Lodi (2022), but doesn't actually carry out the branching part of this procedure. Note: the authors might disagree with the statement \"the algorithm adds local branching constraints\", as the authors differentiate between \"global branching\" and \"local branching\", but in either case the constraint that is added takes the form $\\sum\\_{i \\in D} |x^{t+1}\\_i - x_i^t| \\leq rn$, which is a local branching constraint as defined in Fischetti and Lodi 2003.\n- In order to understand how the authors defined a neighborhood for their large neighborhood search procedure, I again had to consult the appendix. This is a critical detail of a large neighborhood search algorithm, and should be made much more clear.\n- I cannot tell what data was used to train these models in any of the experiments.\n\nThe three improvements (bound tightening scheme, graph encoding & learning approach, \"branching\" learning approach) in the paper each seem somewhat marginal. However, I don't view this weakness as something that would necessarily prevent publication of this work, as the combination of these improvements does seem to be a significant advancement in the design of heuristic procedures for MIPs."
            },
            "questions": {
                "value": "What binarization scheme did you use?\nWhat training data did you use in your computational experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Reviewer_uy5T"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5004/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698444552277,
        "cdate": 1698444552277,
        "tmdate": 1699636488563,
        "mdate": 1699636488563,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nAgb0XqfC1",
        "forum": "Qwxe8WKSgy",
        "replyto": "Qwxe8WKSgy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_zCZB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_zCZB"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose the BTBS-LNS technique to solve the MIP problem in order to cope with the problem that the LNS technique often falls into local optimality. The authors claim that their technique effectively escapes local optimality, and extensive experiments on a large number of instances show that it leads the SCIP and LNS baseline, is comparable to Gurobi, and even performs better early in the run."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The article is praiseworthy for its extensive experimental data and significant findings. The authors have selected a large number of baselines for comparative experiments on different benchmarks, which are demonstrated by a large number of figures and tables. These experimental results strongly prove the effectiveness of the new technology.\n\n2. The paper is laudable for its well-structured and logical presentation, providing a comprehensive understanding of the research topic."
            },
            "weaknesses": {
                "value": "1. On page 4, in \u2018THE BINARIZED TIGHTENING SCHEME\u2019 chapter, the authors mention that the analysis for MIPLIB shows that all unbounded variables have either upper or lower bounds, and the authors have therefore designed virtual upper/lower bounds. Could there be meaningful MIP instances other than MIPLIB where variables exist simultaneously with no upper or lower bounds? If it exists, can BTBS-LNS handle it? Are there serious robustness problems with ignoring such instances? \n\n2. On page 8, in 'Hyperparameters' under section 4.1, the authors mention the use of SCIP as the default solver, noting that this is the blue box part of Fig. 1. In my understanding the SCIP solver should correspond to the 'MIP solver' on the right hand side of Fig.1, and the boxes for Neighborhood Search and Branching Policy on the left hand side are similarly blue, is this a minor graphing and writing error, or am I misunderstanding that SCIP is equally involved in these stages?\n\n3. As described in the experiment part, the authors conduct experiments on those MIP instances that are encoded from other combinatorial problems, including set covering, maximal independent set, combinatorial auction, and maximum cut. Actually, there are specific optimization solvers for each of those combinatorial optimization problems, and MIP solvers do not represent the state of the art in solving those problems. As a submission to a top-tier conference, it is required to compare their proposed method against the real state of the art.\n\n4. In fact, there exist standard benchmarks for evaluating MIP solvers, i.e., Hans Mittelmann's benchmarks (https://plato.asu.edu/bench.html). Why don\u2019t the authors test their proposed method and baseline solvers on those standard benchmarks?"
            },
            "questions": {
                "value": "Please see my comments in \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I do not have ethic concern about this paper."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Reviewer_zCZB"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5004/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698565720652,
        "cdate": 1698565720652,
        "tmdate": 1699636488442,
        "mdate": 1699636488442,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zr3IaVJ0hU",
        "forum": "Qwxe8WKSgy",
        "replyto": "Qwxe8WKSgy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_38AJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_38AJ"
        ],
        "content": {
            "summary": {
                "value": "A deep learning-based approach for providing primal solutions to mixed-integer programming (MIP) problems is described. The primary contributions are given as follows. First, the paper proposes \"binarized tightening\" for variable encoding / adjusting bounds during search. Second, a tripartite graph model is proposed in which the \"standard\" bipartite graph model is extended with nodes representing the objective function. Third, the paper uses a large neighborhood search fix-and-resolve strategy and claims this is a variable branching strategy. Fourth, they compare the approach to SCIP and Gurobi on the several MIP datasets and claim good performance.\n\nOverall, this is a paper that unfortunately is not good enough for acceptance. This is especially disappointing because it has some fascinating ideas; I think both the tripartite graph and the bound tightening, if properly explained, could be important contributions.\n\n=====\nI have raised my score from a 3 to a 5. See my comment for more information."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The tripartite graph structure is an interesting idea. One might argue that the objective information was already present in the graph, so this isn't necessary to add in this way, however I think the objective nodes could provide an interesting flow of information between parts of the problem that are connected through objective components.\n\n2. The binarized tightening is indeed new for the learning to optimize literature. It reminds me of tightening schemes in constraint programming, so it would be nice if the authors could make that connection in their work. There is an imitation learning aspect to this that I am not sure is really so new, but in general the encoding of the variables is interesting.\n\n3. The performance of the approach is quite promising."
            },
            "weaknesses": {
                "value": "1. This paper is not well written and unfortunately this results in a variety of issues. Please have a professional proofreader check for typos, there are several including in the abstract (e.g., there must be a \"the\" before \"Mixed\").\n\na. Key contributions of the paper are barely even discussed in the main text. Information about the branch and search method, tripartite graph, etc., is all in the back. And these are not just details, in my opinion. This paper basically abuses the page limit with lots of redundant text (BTBS is defined several times...) and then expects the reviewer to read the appendix to actually understand what is going on. Sorry, I am not willing to do that. Furthermore, the bound tightening scheme seems somewhat arbitrary -- there are many tightening/filtering strategies, see the CP literature.\n\nb. There are experiments at the start of the paper before the reader can even really understand what is being tested, on what instances, etc. This is essentially a visualization for marketing purposes rather than science.\n\nc. The conclusion is essentially non-existent, nor do the authors discuss weaknesses of their work.\n\n\n2. I take great issue with the big claim in the abstract that the approach performs competitively with Gurobi and SCIP. As best I can tell, this approach is a heuristic, meaning this is an apples and oranges comparison. If this approach actually finds optimal solutions and provides a proof, then I truly have no idea how, which only furthers my first argument.\n\n3. The paper makes several claims/arguments that I just do not follow/support.\n\na. Backdoor variables: I see no theoretical or empirical proof that this paper finds them. It is just a conjecture that it is finding backdoors; we do not really know. The seminal paper on backdoors from Williams, Gomes and Selman (\"Backdoors to typical case complexity\") is not even cited. \n\nb. The paper argues that current approaches \"becom[e] ensnared in local optima\". The implication is that this method does not, but of course, it does. This is a sentence that can be written about essentially any heuristic method and is thus not a valid argument for this paper about why it is novel or better than anything else. Table 1 continues this misconception and basically gets everything wrong about metaheuristics and \"addressing local optima\". Succinctly put, LNS itself is a high level strategy for avoiding local optima, the adaptive neighborhood size of other approaches is also a mechanism for doing so. The header just makes no sense for categorizing the techniques.\n\nIn the example with (3), I do not view this issue as a fundamental flaw of LNS. LNS is just a framework that can be implemented however the user likes. They are correct that fixing integer variables to specific values in their domains is ineffective (again, see the past 20 years of the constraint programming literature), but this has nothing to do with LNS as a framework.\n\n4. The experiments are all given 200 seconds for solving. What a surprise that SCIP and Gurobi do not solve many instances that well in that time frame. It is totally unreasonable and completely disconnected with the time limits that one would have when solving a general MIP problem. Generally ten minutes is considered a reasonable amount of time for a heuristic on a large-scale real-world problem. For solving to optimality with SCIP or Gurobi, one would usually allow for 24 (or more) hours.\n\nFurthermore, the experiments do not provide sensitivity analysis or ablation in the main text beyond comparing different branching schemes. Maybe there is more in the appendix, but those are critical details for the main text."
            },
            "questions": {
                "value": "1. Can this method prove optimality?\n2. Is there an inherent reason why the bound tightening works in powers of two?\n3. Why do you claim that MIPs are more difficult than IPs? Please cite the CS theory that says this is the case."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5004/Reviewer_38AJ",
                    "ICLR.cc/2024/Conference/Submission5004/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5004/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698661502893,
        "cdate": 1698661502893,
        "tmdate": 1700559884216,
        "mdate": 1700559884216,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HYMVfWOgis",
        "forum": "Qwxe8WKSgy",
        "replyto": "Qwxe8WKSgy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_5yM1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5004/Reviewer_5yM1"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an ML-guided LNS framework for MIPs. It combines a binarize-and-tighten scheme to address general integer variables and a branching policy to help escape local optima. It also has a search policy to guide destroy variables. In the experiment, the new method is compared against a variety of ML-guided approaches and heuristic approaches. The presented results show that the proposed method finds better solutions at a faster speed."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper proposes a combination of ML-guided search policy and branching policy for LNS in MIP solving. Various techniques and engineering designs are proposed. The novelty of the paper comes from those details. \n\n2. The effectiveness is demonstrated in experiments with different settings and ablation studies."
            },
            "weaknesses": {
                "value": "1. The writing for some important parts is difficult to understand. I don\u2019t follow the argument for the BTBS scheme. Though intuitively the method itself makes sense to me. In figure 1, are the neighborhood search and branching policy two separate local searches in one iteration? From the pseudocode in Appendix, it looks like you destroy and repair the variables you got by taking the intersection of the branching and LNS policies.  But in other places, you said the branching policy is on top of the LNS.\n\n2. Details on how you implement the branching policy are totally missing, e.g., how you collect data and train. The variant BTBS-LNS-L looks very similar to Sonnerat et al. The design for the branching policy is not well-justified conceptually.\n\n3. Minor weakness: The experiment is comprehensive with lots of information, but without a summary it makes readers get lost. It would be nice to summarize the takeaways, especially for those ablation studies."
            },
            "questions": {
                "value": "See the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5004/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817245382,
        "cdate": 1698817245382,
        "tmdate": 1699636488242,
        "mdate": 1699636488242,
        "license": "CC BY 4.0",
        "version": 2
    }
]