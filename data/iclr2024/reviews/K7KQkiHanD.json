[
    {
        "id": "moqu3UINPk",
        "forum": "K7KQkiHanD",
        "replyto": "K7KQkiHanD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_QDBh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_QDBh"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a general form of low-rank adaptation for vision and language large models, based on a unified formula which the authors claim to encompass serveral previous parameter efficient finetuning methods such as VPT and LoRA. As for training networks with GLoRA, the authors exploit an evolutionary strategy to search for the best subnet after training the supernet. Extensive experiments on vision and language benchmarks show the effectiveness of the propose method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper rethinks serveral previous PEFT methods and unifies them with a general form, contributing a novel perspective.\n2. To obtain the task-specific GLoRA network, the authors first train the supernet and then search for the best subnet.\n3. Extensive experiments are conducted on both vision and language benchmarks, and also in few-shot learning and domain generalization, showing the effectiveness GLoRA."
            },
            "weaknesses": {
                "value": "1. The presentation of the paper could be improved, especially when comparing with previous PEFT methods. The authors could draw figures or list tables to show how existing methods can be integrated into GLoRA framework, e.g. what are the specifications of the A/B/C/D/E support tensors in Eq. (10).\n2. I wonder how much training time (supernet training and subnet searching) does GLoRA cost, such that to compare with existing methods more clearly from the perspective of training efficiency."
            },
            "questions": {
                "value": "1. There exist some typos: 1) \"PETL\"(maybe PEFT?) at the end of page 3 (first line of Sec. Limitations); 2) 4th line of page 4: \"wieght\" -> weight.\n2. How about the performance if we do not add the weight/bias scaling term: W_0 x A and D x b_0 in Eq. (10) ? Or else, which of the five tensors are really necessary in terms of efficiency and efficacy ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Reviewer_QDBh"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2326/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698466751000,
        "cdate": 1698466751000,
        "tmdate": 1699636165038,
        "mdate": 1699636165038,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KBx0xPiP5V",
        "forum": "K7KQkiHanD",
        "replyto": "K7KQkiHanD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_8AV4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_8AV4"
        ],
        "content": {
            "summary": {
                "value": "The paper presents Generalized LoRA (GLoRA), an efficient framework for fine-tuning machine learning models. Building on Low-Rank Adaptation (LoRA), GLoRA introduces an advanced prompt module that not only refines pre-trained model weights but also modulates intermediate activations. Uniquely, this prompt module operates individually across each model layer, ensuring versatility across various tasks and datasets.\n\nGLoRA employs a cohesive mathematical strategy to adapt to new tasks, modifying both weights and activations. This methodology positions it strongly for transfer learning, few-shot learning, and domain generalization.\n\nThe authors substantiate GLoRA's efficacy through experiments on diverse datasets and tasks, encompassing downstream fine-tuning, few-shot learning, domain generalization, and recent popular LLMs. The results demonstrate GLoRA's superior performance over prior techniques in these areas. Remarkably, despite its heightened capability, GLoRA demands fewer parameters and computations without incurring additional inference costs, akin to LoRA, making it an optimal choice for resource-constrained applications."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "GLoRA effectively consolidates previous parameter-efficient fine-tuning methods within Equation 10. Importantly, all adjustable support tensors are linear, which makes structural re-parameterization readily accessible.\n\nThe paper highlights GLoRA's commendable capacity to generalize across diverse tasks, an invaluable quality in machine learning and a frequently challenging facet of model development."
            },
            "weaknesses": {
                "value": "Structural re-parameterization requires storing the full set of weights (including bias) for every individual downstream task. This means that as the number of these tasks increases, the storage needs can become prohibitively large. Although this approach might improve inference performance, the substantial storage overhead can be a major impediment for real-world deployment, especially when multiple tuned-models are needed to handle different downstream tasks.\n\nThe clarity of the paper is occasionally compromised by abrupt topic transitions, such as the unexpected introduction of \"GLoRA with Higher Capacity\" in section 2.6, without prior elucidation of terms like H_i and H_ini. A more coherent and gradual introduction of these concepts would enhance readability.\n\nThe authors touch on memory and training time costs but fail to provide concrete figures to substantiate their claims. Offering detailed, quantitative data on these costs would provide readers with a clearer picture of GLoRA's practical ramifications."
            },
            "questions": {
                "value": "Please refer to 'weakness' part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Reviewer_8AV4"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2326/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698733556714,
        "cdate": 1698733556714,
        "tmdate": 1699636164955,
        "mdate": 1699636164955,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iRswZ7XKEg",
        "forum": "K7KQkiHanD",
        "replyto": "K7KQkiHanD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_1LBP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_1LBP"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new PEFT module named Generalized LoRA (GLoRA), which can be applied to different tasks. The authors claim that GLoRA is more general than existing PEFT modules since it can facilitate efficient parameter adaptation by employing a more scalable structure search. Moreover, the authors conduct multiple experiments including few-shot learning and domain generalization tasks to demonstrate the effectiveness of GLoRA."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. GLoRA has a re-parameterization design. It is more similar to LORA than Adapter. It makes GLoRA more flexible since it does not need to change the structure of the original backbone. And it incurs no extra inference cost.\n2. GLoRA integrates multiple methods and can perform similar effects as most of the existing PEFT modules.\n3. The authors conduct multiple experiments to demonstrate the generality and effectiveness of GLoRA."
            },
            "weaknesses": {
                "value": "1. It seems that GLoRA is not general, since it has an evolutionary search procedure to obtain the suitable components. The idea is similar to Neural Prompt Search [1]. GLoRA is not a fixed design as existing modules, which might limit its practicality.\n2. GLoRA has a large search space, which might yield huge time costs. However, the authors have not mentioned the actual training time and memory cost of GLoRA, which is very important for PEFT modules.\n3. The authors introduce multiple PEFT modules including AdaptFormer, LoRA, etc. So could GLoRA simulate all of these modules? As far as I know, these modules are applied on different layers (LoRA in multi-head self-attention layers, while AdaptFormer in MLP layers). And which layer is GLoRA applied in practice?\n\n[1] Neural Prompt Search. In https://arxiv.org/abs/2206.04673."
            },
            "questions": {
                "value": "See \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2326/Reviewer_1LBP"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2326/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699029036130,
        "cdate": 1699029036130,
        "tmdate": 1700711428654,
        "mdate": 1700711428654,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FlH3fzupTg",
        "forum": "K7KQkiHanD",
        "replyto": "K7KQkiHanD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_jzkZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2326/Reviewer_jzkZ"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses an enhancement to Low-Rank Adaptation (LoRA), which is call GLoR and can be a flexible approach to optimize model inference results. Experiments on llama and vit shows that GLoRA can improve over original LoRA consistently."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is clearly presented and well organized. The authors also provide a detailed discussion of related works and variants.\n\nGLoRA referneces the inspirations from RepVGG, which introduces fusable parameters during training to improve model capacity. This can generally bring improvements without extra inference cost as shown in the experiments. \n\nGLoRA offers a unifed framework that includes multiple fine-tuning paradigms and provides a more generalized prompt mdule design per layer. The final scheme is searched via evolutional algorithms, providng better capacity and flexibility."
            },
            "weaknesses": {
                "value": "The authors claim that GLoRA can be \"seamlessly integrate into the base network\", but it seems such design is for linear layer only. But there are many other type of operators like conv / normalization layers. How can GLoRA be combined with those layers?\n\nThe evolutional search (Sec 2.4) is crucial for GLoRA as it decides which layer and scheme to use during fine-tuning. However, the details of the search and final chosen paradigms are not clearly discussed in the main paper. \n\nAs the abstract emphasiss the llama experiments. The table 2 is not solid neough to support the authors' claim. For example, the mean and variance is not included; the number of learnable paramters is missing; the lora baseline for llama-v2 is not reported. Seems like the experiments are rushed and may not be solid."
            },
            "questions": {
                "value": "No extra inference cost is the novelty from RepVGG or LoRA, which should be claimed as the contribution of GLoRA\n\nThe main experiments are based on ViT but abstract emphasis for llama. Please make the claim conssitent."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2326/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699265522529,
        "cdate": 1699265522529,
        "tmdate": 1699636164814,
        "mdate": 1699636164814,
        "license": "CC BY 4.0",
        "version": 2
    }
]