[
    {
        "id": "xOBAXbtSXV",
        "forum": "D7KJmfEDQP",
        "replyto": "D7KJmfEDQP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_1bWs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_1bWs"
        ],
        "content": {
            "summary": {
                "value": "The paper tries to theoretically understand the impact of gradient mismatch between tasks when merging these models together. The first shows how model merging and gradient mismatches are related to each other and shows the errors that are induced due to that, based on these insights they propose a new method to reduce gradient mismatch. Next, they demonstrate how many past model merging methods are the special case of their new method and finally establish the relationship with Bayesian inference. They conclude with a small set of experiments to demonstrate the usefulness of their method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(S1) The originality of the work lies in providing the theoretical connection between model merging and the gradient mismatch problem (the identification of gradient mismatch as a problem of model merging cannot be attributed to this work, see weaknesses). Moreover, the connection with the Bayesian inference is also interesting. Additionally, the insight that the work extends RegMean (Jin et. al;2023) to non-linear parts of transformers is useful.\n\n(S2) The paper is well-written for the most part and easy to follow along. However, there are things that are not clear and are listed as Questions below.\n\n(S3) The work improves the understanding of model merging and might be useful to the people working on the model merging."
            },
            "weaknesses": {
                "value": "(W1) The idea of identifying gradient mismatch as a problem has been claimed as one of the main contributions throughout the paper (abstract, intro, and other sections). However past works like TIES-Merging [1] have identified this problem and proposed detailed empirical studies to quantify the degree of this problem and then propose some fixes that lead to significantly improved performance. \n\n(W2) Moreover, in the current version of the paper, TIES-Merging is discussed in passing but the differences compared to that works are not properly highlighted.\n\n(W3) The experimental section is pretty thin and the results presented are weak. See more details in the Questions below."
            },
            "questions": {
                "value": "**Need to address these questions for me to retain my score:**\n\nQ1: The papers need to be positioned better, to adjust the main contribution and highlight the similarities/differences compared to TIES-Merging [1] which claims to identify and ameliorate interference when merging models.\n\n\n\n**Need to address these as well for me to consider increasing my score:**\n\nQ2: Ideally all the experiments should also compare with TIES-Merging as that method is the closest to the final method proposed in this paper. And addresses the exact same problem that this paper tries to get at. Hence, not including that as a baseline leaves lots of open questions about the utility of the proposed method. If these comparisons are added then I will update my score as I feel this work makes a good theoretical contribution but the experimental section leaves a lot of ambiguity about the utility of the final method.\n\n\nQ3: The experimental results are very weak and seem insignificant. For example in Table (nlp), the experimental setting seems to be not well designed due to multiple reasons (i) the performance of all the methods lies between 96.1-96.8 which is quite a narrow range to make any claim about any of the methods performing better or worse than the others. for example, the difference between your method and TA is 0.3% which is not significant from my experience. Hence, either the experimental setting is too simple to highlight the differences between these methods or the methods all perform the same. An experimental setting from past papers like Task Arithmetic, TIES-Merging can be adopted for such experiments. \n\nQ4: It is not clear how the approximations made in the paper about using fisher instead of hessian after the gradient mismatch as the model becomes bigger, something on this would be useful. Moreover, could these be the reasons why the method does not lead to significant improvements in both vision and NLP settings?\n\n\nQ5: Figure-1 (right), it is not clear to me how this gradient mismatch is computed. Seems like you are adding 5 tasks on Roberta (IMDB) but then what circles represent the gradient mismatch between which models on which data? Is it a pairwise comparison of gradient mismatch or are the models being added? Please clarify exactly what this figure means. \n\n\nQ6: Moreover, the Figure-1 (right) it is shown that as the gradient mismatch decreases the test error also decreases significantly (by ~2). however, this finding seems to be inconsistent with the results in table-3 where the performance difference between TA and your method is very minimal (0.3). What is the reason behind this? In general, what is the reason behind not leading to enough improvements over TA in the nlp setting even when there is a significant gradient mismatch for TA?\n\n\n**Other questions on clarifications and details:**\n\nQ7: How is the alpha selected in your proposed method? It is mentioned in many places that alpha is not tuned.\n\nQ8: Please specify the number of samples you use to compute the fisher. \n\nQ9: For Figure-2 (left) the best performance for both TA and your method seems to be comparable to each other. I agree that your method might not need to tune for alpha but in most practical cases obtaining a small validation set and tuning alpha is not that hard. Moreover, the proposed method need to compute the fisher (requires backward pass on a subset of training data) whereas TA need validation set to tune alpha (inference on a small number of val example), so overall the peak memory usage of the proposed method would be higher while TA requires additional data. This trade-off should be highlighted in the paper.\n\nOverall, I feel that the theoretical contributions of this work are nice and would be useful to the community, I expect the author to at least position the contributions of the work better in light of past works. Moreover, strengthening the experiments section would highly increase the quality of this works\n\n[1] Resolving interference when merging models, Yadav et. al."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3827/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698452632788,
        "cdate": 1698452632788,
        "tmdate": 1699636340617,
        "mdate": 1699636340617,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3RgO1FtPCN",
        "forum": "D7KJmfEDQP",
        "replyto": "D7KJmfEDQP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_V4z1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_V4z1"
        ],
        "content": {
            "summary": {
                "value": "The describes a structured way of understanding linear combination of parameters. The concept of ``target model`` is introduced as a way of measuring fitness of merges. Subsequently, modification of the ``Task arithmetic`` loss is introduced such that the gradient mismatch between the target model and the averaged models is minimized. Experimental results show comparable results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The introduction of the paper is very well written and framed the problem in clearly.\n- The idea of defining a ``target model`` is very useful concept in this space."
            },
            "weaknesses": {
                "value": "- Section 3, overall, was difficult to follow with seemingly several notational errors and cluttered paragraphs, see questions and suggestions section."
            },
            "questions": {
                "value": "**Questions**\n\n- Eq(3)  should be \n$$\\alpha_{1}\\bar{\\ell}_{1}(\\theta) + \\alpha_{2}\\bar{\\ell}_{2}(\\theta)$$\n right?\nIn other words, the optimization is looking for $\\theta$ that optimizes both losses which is $\\theta_{1+2}$. If this is not a mistake then Eq(5) is wrong. \n- what does $t$ stand for in Eq(8)\n- the error between $\\bar{\\theta}_{TA}$ and $\\theta_{1:T} = \\theta_{1:T}$? please clarify/correct?\n\n**Suggestions**\n- The discussion in the last paragraph in page 3 is best to be had in the experimental section with some data.\n   or under its own section with further details.\n- Section 3.1 is difficult to follow/understand, mainly because of several math annotation issue, and not well\n   organized paragraphs. For instance, the first two paragraphs can simply be phrased as `target model` definition\n   rather than using unnecessary details and confusing notations.\n- I generally, like the framing of the problem and the idea of ``target model``. I think the paper has good potential. I suggest re-writing of section 3, highlighting the problem and the solution (perhaps computational aspect and other details) and differing questions of generality and applications to later section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3827/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698539249761,
        "cdate": 1698539249761,
        "tmdate": 1699636340544,
        "mdate": 1699636340544,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AkaNlyxeqZ",
        "forum": "D7KJmfEDQP",
        "replyto": "D7KJmfEDQP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_vWCx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_vWCx"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses an interesting problem in the domain of model merging and offers a novel perspective by connecting gradient mismatches to the inaccuracy of weighted-averaging methods. The paper also proposes a new uncertainty-based scheme to improve model merging, which is a valuable contribution."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "+ The authors connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve performance by reducing the mismatch.\n+ The authors propose a unified explanation on previous model merging technique. \n+ The new method shows consistent improvements for large language models and vision transformers in terms of performance and robustness to hyperparameters."
            },
            "weaknesses": {
                "value": "+ My major concern lies in the problem setup. I admit that model merging is a well-defined problem with much previous literature, as is discussed in the submission. But I still wonder why we need this technology. If we could obtain the data for each task, why don't we simply perform multi-task learning on these data? If we couldn't, how could we obtain the fisher information matrix on each task, which is required to approach Eq.12? It seems like a contradiction and I think more clarification on the application scenario of the model merging technique is needed, in spite of the abundance of previous literature.\n\n+ The second concern is an important missing baseline. The derivation in section 3 is similar in some degree to Regmean[1] though the latter takes linear regression as an example and then extrapolates to neural networks.  Therefore,  I would list Regmean as one of the must-to-compare baseline methods."
            },
            "questions": {
                "value": "+ In my opinion, the model merging technique takes two or more models as input and outputs a merged model. Therefore, the performance of a merged model on down-stream tasks (compared to the unmerged model) is only a single datapoint in the experiment. In other words, what if we use different hyper-parameters to train the base model on each task? Will your method outperform others under other hyper-parameters?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3827/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3827/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3827/Reviewer_vWCx"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3827/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698589229142,
        "cdate": 1698589229142,
        "tmdate": 1699636340464,
        "mdate": 1699636340464,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BOLkl6IWKu",
        "forum": "D7KJmfEDQP",
        "replyto": "D7KJmfEDQP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_idAX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3827/Reviewer_idAX"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a powerful method to average two models. Specifically, the proposed method averages the model by minimizing the gradient mismatch of different models. The paper provides a deep analysis of why their method makes more sense than others.\n Also, the paper validates their method in multiple datasets from both the NLP domain and the image domain."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "From my viewpoint, the weight of LLM is knowledge abstracted from data, which stresses the importance of quickly merging knowledge learned from the dataset. I believe the topics of the paper fit into this conference and have a certain inspiration for future works in this domain. \n\nThe motivation of this paper is extremely clear by analyzing the gradient of merged models. When I read the paper, I enjoyed the motivation despite the heavy math."
            },
            "weaknesses": {
                "value": "I have some minor concerns about this paper. Before I lay out the weaknesses list, I would like to mention that I\u2019m not an expert on NLP and my comments are probably incorrect.\n\nFinetuning vs data-driven model averaging. Maybe I don\u2019t have the background.  I\u2019m curious about the advantage of the proposed model merging over simply fine-tuning the model. In my understanding, for the proposed method to work, we would need data to calculate the gradient matrix -- that\u2019s why I call the proposed method as a data-driven model averaging. In this case, why don\u2019t we just simply fine-tune the averaged model using the LORA on the data in hand? And fine-tuning sounds more straightforward. Thus, I would recommend having a discussion/quick comparison between those two.\n\nAgain, I\u2019m a bit concerned about the time efficiency since the proposed method requires the second-order Hessian matrix, especially when compared with the simple strategy. Although it doesn\u2019t matter for the inference, it might be still worth knowing if this Hessian calculation is practical or not. So I suggest to make it clear. \n\nIn short, I have some concerns about the comparison with simple fine-tuning and time efficiency. So I currently vote for the weak accept. Again, it might be because I don\u2019t have too much domain knowledge. So I would be happy to hear back from the authors during the rebuttal in case I misunderstand anything."
            },
            "questions": {
                "value": "Please address the question above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3827/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698774433509,
        "cdate": 1698774433509,
        "tmdate": 1699636340281,
        "mdate": 1699636340281,
        "license": "CC BY 4.0",
        "version": 2
    }
]