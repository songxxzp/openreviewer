[
    {
        "id": "5tBeVjxdou",
        "forum": "q6WXlm2Kxo",
        "replyto": "q6WXlm2Kxo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission401/Reviewer_caGX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission401/Reviewer_caGX"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes masked diffusion model (MDM) for self-supervised learning. Masked diffusion is inspired by the use of the denoising diffusion as a representation learning approach. However, instead of using different levels of Gaussian noise, it uses masks, which at different timesteps of the forward process, blocks out more of the image. The inverted process is then learning to undo this masking operation.\nThe ability of masked diffusion to learn a useful representation for image segmentation is investigated on public datasets of both medical images (GlaS and MoNuSeg) as well as natural images (FFHQ-34 and CelebA-19) and compared both to standard supervised approaches (recent variations of convolutional and transformer based models) and to representation learning approaches based on the Masked AutoEncoder (MAE), the standard denoising diffusion probabilistic model (DDPM) and self-supervision approaches such as SwAV."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Self-supervised learning is highly relevant and the manuscript is well written and easy to read.\n\n- The approach appears to be novel and while the idea is perhaps not extremely original given prior work, the contribution is still solid.\n\n- The approach is compared to a large number of other relevant approaches and consistently appears to do best, whether in the fully supervised case where 100% of the data is used for training the downstream segmentation task or in a more limited case where only 10% of the data is available for training the downstream segmentation task.\n\n- The experiments appear to be easy to reproduce as the authors plan to release the code on acceptance."
            },
            "weaknesses": {
                "value": "- \"This paper decomposes the interrelation between the generative capability and representation learning ability inherent in diffusion models.\" - I am not really sure what is meant by this or why it is significant.\n\n- \"a scalable self-supervised representation learner...\" - What is meant or referred to with scalable here? It does not appear to be mentioned elsewhere.\n\n- \"While the prediction task demands a focus on high-level, low-frequency structural aspects of images,\" - I would have liked this to be better explored or more well supported to make statements such as this.\n\n- \"the representation ability of diffusion models does not originate from their generative power.\" - I don't see where this is investigsted in the proposed manuscript. E.g. the generative power of the proposed model is not shown.\n\n- Will trained model weights also be released on acceptance?\n\n- I am concerned by the apparent lack of a validation set. There seems to be a number of hyper parameters involved such as the choice of timesteps, blocks, patch sizes and training schedules covered in section B. Other choices such as loss function (SSIM or MSE) were also made. It is unclear if test sets were involved in these choices and if so can we expect the reported results to generalize?"
            },
            "questions": {
                "value": "- See the question in the above related to the use of validation sets."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission401/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698788854526,
        "cdate": 1698788854526,
        "tmdate": 1699635966980,
        "mdate": 1699635966980,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ksRg9RiD5K",
        "forum": "q6WXlm2Kxo",
        "replyto": "q6WXlm2Kxo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission401/Reviewer_Sbaz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission401/Reviewer_Sbaz"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel approach to self-supervised learning using diffusion models. The authors introduce \"masked diffusion\", where portions of data are probabilistically masked and subsequently reconstructed through a diffusion process. This dynamic masking strategy offers a distinct advantage over traditional static methods, enabling the capture of complex data patterns.\n\nEmpirical results showcase the method's excellence, outperforming established self-supervised benchmarks and achieving state-of-the-art performance on multiple datasets. \n\nIn essence, this work suggests a potential paradigm shift in self-supervised learning, emphasizing the significance of dynamic masking and diffusion models in data reconstruction and representation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:\n\n1. **Novel Concept**: The paper presents a new approach in self-supervised learning using diffusion models. The probabilistic mask for data occlusion offers an alternative to traditional static methods, suggesting a different way to approach representation learning.\n\n2. **Empirical Evidence**: The results and ablation studies provide evidence of the method's performance. The proposed technique shows improvements over vanilla MAE, DDPM, and certain traditional models on segmentation datasets."
            },
            "weaknesses": {
                "value": "Areas of Improvement for the Paper:\n\n1. **Benchmarking for Segmentation Tasks**: The primary focus on segmentation necessitates benchmarking against specialized self-supervised learning (SSL) methods designed for this task, both at the instance-level and pixel/patch-level. A direct comparison with methods such as Leopart, IIC, MaskContrast, DenseCL, MoCoV2, and DINO on standard datasets like COCO and PVOC would provide a holistic evaluation. Refer to paper: Self-Supervised Learning of Object Parts for Semantic Segmentation for methods specific to semantic segmentation.\n\n2. **General SSL Representation Benchmarking**: If general SSL representation learning is the core objective, the method should be contrasted with prevailing SSL techniques (e.g., DINO, MoCoV2) across a spectrum of downstream tasks, including classification, object detection, and linear probing.\n\n3.**Demonstration of Versatility**: To set this work apart, the authors can also consider to showcase results across diverse data domains. Presenting outcomes on datasets related to audio, text, or time-series would emphasize the method's adaptability.\n\n4. **Robustness Against Noisy Data**: The paper could benefit from an evaluation of the model's robustness against noisy or corrupted data, providing a measure of its real-world applicability.\n\n5. **Interpretability and Visualization**: Including a section on interpretability, with visualizations illustrating the diffusion process or the dynamic masking strategy, would help readers better grasp the underlying mechanisms.\n\n6. **Discussion on Limitations**: A more explicit section discussing the method's limitations, potential pitfalls, or scenarios where it might not be the best fit would offer a balanced perspective."
            },
            "questions": {
                "value": "If some points in the weaknesses section are addressed, the score can be increased."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission401/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698799690719,
        "cdate": 1698799690719,
        "tmdate": 1699635966883,
        "mdate": 1699635966883,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O1qq4jvmIl",
        "forum": "q6WXlm2Kxo",
        "replyto": "q6WXlm2Kxo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission401/Reviewer_x7rC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission401/Reviewer_x7rC"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a pre-training strategy for image segmentation motivated by the recent success of diffusion models. First, an image is masked with different masking ratios, t. Then, the masked image and the mask ratio are given as input to a Unet to restore the original image with SSIM loss. This architecture is called the Masked Diffusion Model (MDM). Once MDM is trained with unlabeled data, a small segmentation network that takes the representation of a decoder as input is trained with a supervised loss on the available labeled data. \nThe experiments are presented on both medical and natural image datasets. The results demonstrate that MDM achieves better performance compared to some SoTA self-supervised learning methods such as MAE and DDPM."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper present an extensive experimental evaluations on 2 natural and 2 medical image data sets with ablation studies."
            },
            "weaknesses": {
                "value": "- My main concern is the novelty of the method. The paper mentions that with the fixed t, the method degrades to a vanilla masked autoencoder with SSIM loss. This basically means that the only contribution of the paper is masking the image with a dynamic masking ratio during training, which concerns me regarding the contribution of the paper.\n\n- Although the improvement achieved by this small change is interesting on Glas 10% case (IOU is 76.19 for MAE and 82.70 MDM with MSE; which is quite a significant improvement with only this small change (assuming MAE in table 1 is trained with MSE loss)), the results on FFHQ-34 shows that this finding cannot be generalized across datasets (IoU of MAE is 57.06 while MDM with MSE is 55.06).\n\n- Table 4 shows that using SSIM improves the performance significantly both for DDPM and MDM while MDM is still being better. I think a more fair comparison of MDM w/ SSIM loss would have been with MAE w/ SSIM loss, since it would show the effect of changing t dynamically.\n\n- It is not very clear from the paper which decoder level representation is given as input to the segmentation network. Is it only the last layer or some combinations of the last few layers? I also think it would be interesting to know the performance change as a function of using different decoder level features. Additionally, for fair comparison, the same level decoder features should be used for also DDPM and MAE. I didn't see a clear statement about this in the paper."
            },
            "questions": {
                "value": "- Please address my concerns in the weaknesses section, especially the ones related to the contribution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Reviewer_x7rC"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission401/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698855441212,
        "cdate": 1698855441212,
        "tmdate": 1700738289695,
        "mdate": 1700738289695,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C496Mylfdk",
        "forum": "q6WXlm2Kxo",
        "replyto": "q6WXlm2Kxo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission401/Reviewer_V2xK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission401/Reviewer_V2xK"
        ],
        "content": {
            "summary": {
                "value": "This paper applies masking to diffusion models and shows improvement in segmentation tasks for both medical and natural images. The authors also try to use SSIM instead of MSE for pre-training in order to improve the downstream segmentation performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The statistical results shown in Table 1 look promising if all the methods are compared fairly."
            },
            "weaknesses": {
                "value": "1. The writing of this paper needs to be improved. Many claims in the introduction section are not very well-supported (e.g. \"such efforts risk deviating from the theoretical underpinnings of diffusions\") and are not very well organized.\n2. It is not convincing enough to conclude that the representation learned is better while only tested on segmentation downstream tasks.\n3. The choice of SSIM over MSE is rather empirical and not well justified."
            },
            "questions": {
                "value": "1. The authors chose SSIM over MSE to improve the segmentation performance. However, there are also other types of choices such as normalized cross-correlation, MAE etc. It is also more of a trade-off between learning a general representation than tuning toward specific downstream tasks (e.g. segmentation in this case). The authors need to justify more about this.\n\n2. Since the goal of the proposed method is to learn a better representation, how well the method performs on other downstream tasks?\n\n3. Figure 2 and Figure 3 are quite repetitive and it is very hard to conclude which methods are better. Reporting Dice scores along each figure will be helpful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission401/Reviewer_V2xK"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission401/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699029345657,
        "cdate": 1699029345657,
        "tmdate": 1699635966756,
        "mdate": 1699635966756,
        "license": "CC BY 4.0",
        "version": 2
    }
]