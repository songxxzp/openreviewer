[
    {
        "id": "7jNjDn2h0o",
        "forum": "ktdETU9JBg",
        "replyto": "ktdETU9JBg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_Z1Pi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_Z1Pi"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use diffusion models as the decoder.  \nThe diffusion decoder is conditioned on both a vector-quantized latent image representation and a textual image description (losslessly coded separately).  \nThe proposed methods achieve realistic reconstructions at bitrates as low as 0.003 bits per pixel, significantly outperforming previous works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The technical contribution is novel to me. I like the idea of conditioning the generative codec on a vector-quantized image representation along with a global textual image description to provide additional context.  \n2. The paper is well written and easy to follow. Enough background information is provided to general readers. It is a great work bridging learnt image compression and AIGC.  \n3. The results are significantly better than previous works.   \n4. Ablation studies are thorough and convincing."
            },
            "weaknesses": {
                "value": "1. Though the perceptual quality is SOTA, the decoding complexity is not compared. It is better to show the decoding complexity since diffusion models tend to be slower. Comparing the decoding complexity (i.e. latency and flops) with previous perceptual image compresion methods can provide more helpful information to the community.   \n2. Missing citations. Following Hoogeboom et al 2023, previous SOTA PO-ELIC should be compared or at least discussed if it is hard to make direct comparison: He, Dailan, et al. \"PO-ELIC: Perception-Oriented Efficient Learned Image Coding.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022. \n3. Other Suggestions. The idea of conditioning the generative codec on image representation along with an extra descriptor (which is losslessly coded) is very interesting. I noticed that the following work provides a theoretical perspective on this conditional coding setting and also explains that the perceptual quality measured by FID is not affected by bitrate, please consider discussing this to provide more information to readers.\nXu, Tongda, et al. \"Conditional Perceptual Quality Preserving Image Compression.\" arXiv preprint arXiv:2308.08154 (2023)."
            },
            "questions": {
                "value": "Overall I think this is a good work. Please refer to the weakness part for the discussion phase"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2661/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697530765783,
        "cdate": 1697530765783,
        "tmdate": 1699636206605,
        "mdate": 1699636206605,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4mHh0evD8o",
        "forum": "ktdETU9JBg",
        "replyto": "ktdETU9JBg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_p6Yn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_p6Yn"
        ],
        "content": {
            "summary": {
                "value": "## Summary\n* The authors present a technique to compress images into 0.003 bbp by text-to-image latent diffusion models. They show that in very low bitrate, pretrained caption becomes a very efficient latent representation for image compression."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "## Strength\n* There has been several diffusion based image compression works. A major problem of diffusion based compression is that what special advantage can diffusion brings with the cost of decoding time. This work find a specific scenario (ultra low bitrate) that is hard to be achieved by GAN models, which justifies the adoptation of diffusion over GAN, and I like it a lot.\n* The visual results look strikingly good. No zoom-up is needed to see the obvious advantage over other methods.\n* It is also interesting to see that text is a efficient representation for image compression."
            },
            "weaknesses": {
                "value": "## Weakness\n* I am not really sure what is the point of evaluating LPIPS in Fig.3. Obviously MS-ILLM and HiFiC are trained with LPIPS, and this brings unfair advantage over the proposed approach. And as the authors are optimizing their approach towards divergence based perceptual quality [Blau 2018], using FID and KID should be enough. Reporting MS-SSIM and mIoU is also weird. \n* The authors think achieveing a low MS-SSIM, PSNR and LPIPS is a weakness, which I can not agree. By RDP theory [Blau 2019], it is absolutely normal for perceptual codec being outperformed on image-wise distortion metrics.\n* The authors are enouraged to present results in their original aspect ratio. Currently some results in Fig. 1 looks weird as they are squeezed horizontally."
            },
            "questions": {
                "value": "## Questions\n* In MS-ILLM, the VQ-VAE is forzen once after pre-trained. While in this paper the VQ-VAE participate the end-to-end training. Then a natural question to ask is whether include the VQ-VAE of MS-ILLM in training improves the result?\n* A recent preprint [Conditional Perceptual Quality Preserving Image Compression] also justifies the adoptation of side information in image compression. The authors can probably connect their work to rate-distortion-perception trade-off with the approach similar the in preprint."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Reviewer_p6Yn"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2661/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697781606536,
        "cdate": 1697781606536,
        "tmdate": 1699636206487,
        "mdate": 1699636206487,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DVkMiGC1iN",
        "forum": "ktdETU9JBg",
        "replyto": "ktdETU9JBg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_FDrq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_FDrq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an image generative compression framework called PerCo. This model applies the diffusion model to the field of image compression and achieves visually good performance at extremely low bit rate compression. Compared to previous methods, this work leads to better visual quality as measured by subjective metrics like FID and KID."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed method combines text and image description for the diffusion model to improve compression performance. Compared to previous works, it achieves higher quality and more realistic image representation at very low bit rates. The model proposed is valuable for future exploration of applying diffusion models to the field of image compression.\nMoreover, the semantic logic and argumentation of this article are clear. The extensive comparative analysis also makes the article more convincing."
            },
            "weaknesses": {
                "value": "1\uff09The training and inference complexity of such diffusion-based methods is usually large. The authors should provide some preliminary results like running time or memory consumption.\n\n2\uff09Another existing diffusion-based image compression framework [1] combining text and image information can be discussed.\n\n[1] Pan, Zhihong, Xin Zhou, and Hao Tian. \"Extreme Generative Image Compression by Learning Text Embedding from Diffusion Models.\" arXiv preprint arXiv:2211.07793 (2022)."
            },
            "questions": {
                "value": "A minor question: on page 4, in \u201cLocal spatial encoding\u201d paragraph line 6, \u201cThird, we proceed to quantization of $H_s$ to obtain $z_g$ via vector quantization\u201d.  From my understanding, $z_g$ should be $z_l$ ? (ps, a typo here: \u201cquatization\u201d to \u201cquantization\u201d )"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2661/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698643880376,
        "cdate": 1698643880376,
        "tmdate": 1699636206424,
        "mdate": 1699636206424,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "T4l1DZBVzl",
        "forum": "ktdETU9JBg",
        "replyto": "ktdETU9JBg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_6W37"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2661/Reviewer_6W37"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new image compression method, which decodes compressed latent features with a iterative diffusion model, instead of a single-pass feed-forward decoder. Specifically, the introduced diffusion compressor conditions on two kinds of features:  (1) a global textual image description obtained from a image captioning model; (2) a vector-quantized image representation in latent space.  According to the experimental results, the proposed method beats the state-of-the-art methods in visual quality at ultra-low bitrate."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper introduces a new image compression architecture. It proposes to combine a global textual image description and a vector-quantized latent image representation as the conditions of the latent diffusion model to decode the images.\n- The reconstruction results are much better than the exisiting works at ultra-low bitrates."
            },
            "weaknesses": {
                "value": "- The idea of applying diffusion model on image compression is not new (as reviewed in the paper). But at least for me, combining it with textual information is interesting and motivating for image compression task.\n- The proposed method only optimizes the distortion/perceptual term but drops the rate term. It is not justified why the rate term can be dropped.\nWhat impact will have if include the rate term into optimization? \n- One limitation of diffusion model is the inference speed. This paper do not provide the running time of the proposed method, especifically the decoding time. A fair comparsion of running time (both encoding and decoding ) with the competing methods (both learned and traditional) should be provided and discussed."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2661/Reviewer_6W37"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2661/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699343113129,
        "cdate": 1699343113129,
        "tmdate": 1699636206362,
        "mdate": 1699636206362,
        "license": "CC BY 4.0",
        "version": 2
    }
]