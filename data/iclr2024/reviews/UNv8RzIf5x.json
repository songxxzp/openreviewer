[
    {
        "id": "0Qz1yNGwTW",
        "forum": "UNv8RzIf5x",
        "replyto": "UNv8RzIf5x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_ceHs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_ceHs"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the concept of \"class-generalization error,\" which measures the generalization performance of the algorithm for each individual class. It further applies previous information-theoretic tools to derive various bounds. Empirical studies validate the proposed bounds in different neural networks. Finally, the authors discussed some possible applications of these bounds."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The motivation to investigate the class-wise generalization error is reasonable.\n2. Although not in-depth enough, this paper has related the class-generalization error to several applications."
            },
            "weaknesses": {
                "value": "### Major Concerns\n1. \"...provide bounds for the expected generalization over the whole data distribution, which implicitly assumes that the model generalizes uniformly for all the classes.\" \n   * I am afraid that I cannot agree with this statement. Considering the expected generalization error over the whole data distribution means measuring the model **on average** over all the classes, not **uniformly**, especially when the classes are imbalanced.\n2. The number of training samples in Figure 1 is the whole sample number of all the classes.  \n   * To interpret the reason for the different generalization gaps over classes, we need first to consider whether the classes are balanced.\n      - In the website of the CIFAR 10 dataset: \"...The training batches contain the remaining images in random order, but some training batches **may contain more images from one class than another**. Between them, the training batches contain exactly 5000 images from each class.\"\n      -  So, could the authors also plot the class-wise gap w.r.t the sample numbers for each class?\n   * Moreover, introducing label noise (5%) for each class will cause an imbalanced sample number for each class, which means the class-wise sample numbers in the right plot must be different (in terms of the given label not true label). That's why we observe a different trend.\n     - How the label noise is introduced? Have you introduced the noise on both train data and test data? If only on the train data, there is a distribution shift. If on both, it's the above-mentioned class imbalance.\n3. Assumption 1, Lemma 1, and Theorem 1 seem problematic. \n   * The authors assume that the learning algorithm is symmetric w.r.t each training sample. As the paper is motivated, the generalization gap is non-uniform w.r.t each class. How could two samples from different classes be symmetric to the algorithm output of the whole dataset $P_{W|S}$?\n   * Could the authors provide a detailed derivation for Lemma 1? I cannot find any proof for this.\n   * Based on Assumption 1 and  Lemma 1, Theorem 1 is not related to the sample number $n_y$ and indicates all the samples inside a class contribute equally to the generalization. However, this is counterintuitive, where the samples close to the decision boundary should be more important.\n4. The theorems are based on tiny modifications on previous MI and CMI bounds, which are not novel to me.\n\n### Minor Concern\nThe citation format is incorrect, please pay attention to the use of citet and citep."
            },
            "questions": {
                "value": "Please see the previous section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Reviewer_ceHs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8003/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698173913083,
        "cdate": 1698173913083,
        "tmdate": 1699636986347,
        "mdate": 1699636986347,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ldBqUl00OL",
        "forum": "UNv8RzIf5x",
        "replyto": "UNv8RzIf5x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_yBBn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_yBBn"
        ],
        "content": {
            "summary": {
                "value": "Several recent works have provided information-theoretic generalization bounds, which apply in an average case over all classes. This paper takes a more fine-grained approach, and obtains bounds that hold for each specific class. Specifically, the difference between training and population loss for a given class is bounded in terms of an information measure involving training data for that specific class. The bounds are numerically evaluated. Some applications and extensions are discussed, including the sub-task problem and sensitive attributes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper gives a clear presentation of the problem at hand, and motivates well why it is interesting to tackle. The numerical evaluation is detailed for the main problem of the paper. Related literature is mostly well-covered. The connections to the sub-task problem and sensitive attributes are intriguing."
            },
            "weaknesses": {
                "value": "The theoretical machinery is essentially identical to prior work (Xu & Raginsky, Steinke & Zakynthinou, Bu & Veeravalli, Harutyunyan et al, etc). The only difference is in the introduction of the definition of classwise generalization error \u2014 after this, all the steps proceed as in these earlier works (some minor differences in the current CMI derivation). It also seems to me that the results can be derived in simpler ways (see questions below). Now, this in itself is not necessarily a weakness, provided that the end product is useful. There are some steps towards establishing this in Section 4, which to me is the most interesting part of the paper, but it does not go quite far enough. For instance, evaluations on particular sub-task problems, or algorithmic design for fairness inspired by the results, could be promising directions for extending these results."
            },
            "questions": {
                "value": "\u2014 It seems as if all of your results follow straightforwardly by the same technique as you use for Theorem 7. Consider a distribution $P_Z$ on a space $\\mathcal Z = \\mathcal T \\times \\mathcal X$, where $\\mathcal T$ is, for instance, the label space or a sensitive attribute. Then, apply standard techniques for information-theoretic bounds with the joint distribution $P_{W\\vert Z}P_{Z\\vert T=t}$. With this, you can avoid the machinery with indicator functions used for the CMI derivations.\n\nIn the CMI setting, I am aware that $W$ still depends on the parts of the supersample where the labels are not the specified one in the class-generalization error. But since this part of the supersample only appears through $W$, it is marginalized out. In a similar vein, $W$ can depend on any other random variable (e.g., pre-trained), which also becomes marginalized out.\n\nOne potential way to exploit this would be to actually use the non-$t$ data to construct a more informed prior. Consider the data-split method in PAC-Bayesian bounds, as in \u201cTighter PAC-Bayes bounds\u201d by Ambroladze et al or \u201cOn The role of Data in PAC-Bayes Bounds\u201d by Dziugaite et al. This can be combined with the CMI approach (or the standard MI bounds), so that the prior is allowed to depend on data from $P_{Z\\vert T\\neq t}$.\n\n\u2014 For the sub-task problem, are the target classes assumed to be known?\n\n\u2014 Regarding the worst sub-population performance: isn\u2019t it the case that $\\text{gen} = E_T \\text{gen}_T \\leq \\max_t  \\text{gen}_t$? It is not clear to me why it needs to be re-written as an information-theoretic bound to establish a statement similar to (15). Furthermore, does this really motivate that the two are closely correlated? The maximum is clearly an upper bound, but I do not see why this indicates that they should be correlated.\n\n***\nMinor comments:\n\n\u2014 After 1, you require $n_y < n$. Isn\u2019t $n_y\\leq n$ fine?\n\n\u2014 The term \u201coverfit\u201d seems a bit unclear (compare \u201cbenign overfitting\u201d, e.g.). Does this necessarily imply a high population loss?\n\n\u2014 I believe the term \u201csupersample\u201d usually refers to the entire set of $2n$ samples. It seems that you use it to only refer to a single pair of samples. Is this correct?\n\nAssumption 1: satisfying -> satisfies; \\citep when needed"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A (accidentally wrote questions here)"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8003/Reviewer_yBBn"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8003/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698415407635,
        "cdate": 1698415407635,
        "tmdate": 1700134951337,
        "mdate": 1700134951337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DBb29XnCjE",
        "forum": "UNv8RzIf5x",
        "replyto": "UNv8RzIf5x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_mpfA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_mpfA"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the class-dependent generalization error through using information-theoretic analysis. The authors begin by demonstrating the necessity of providing class-dependent generalization bounds, highlighting the potential variability in the generalization error across different label classes. They proceed to present class-dependent information-theoretic generalization bounds, including KL divergence-based bound, weight-based CMI bound, $f$-CMI bound and loss-difference CMI bounds. Additionally, empirical results are provided, along with extensions of their findings to other problem settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Compared with previous works, this paper has the following pros:\n1) As demonstrated in its empirical results, previous information-theoretic bounds fail to capture the generalization behavior of individual label classes, while the bounds in this paper overcome such limitations;\n2) The class-dependent generalization bounds introduced here can also be used to bound the standard generalization error; 3) The analytical framework of this paper is extendable to other problem settings, such as learning in the presence of sensitive attributes, a domain where previous information-theoretic bounds have not been applied.\n\nIn addition, this paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "One main limitation is that the empirical results are confined to ResNet50 on CIFAR10/Noisy CIFAR10. Adding more experimental settings (e.g., SVHN) would further show the effeteness of the proposed bounds.\n\nFurthermore, I have some technical concerns; please see the questions below."
            },
            "questions": {
                "value": "Major concerns:\n\n1. Regarding Definition 2: Is the class-generalization error defined in Eq.(6) equivalent to Eq.(3) in Definition 1? If so, could you rigorously demonstrate their equivalence?\n\nTo my understanding, it is natural to see that Eq.(3) is the same as the following expression:\n$$\n\\mathbb{E}\\_{\\bf Z}\\left[\\mathbb{E}\\_{U,W|{\\bf Z}}\\left[\\sum\\_{i=1}^n\\left(\\frac{\\mathbb{1}\\_{\\{Y\\_i^{-U\\_i}=y\\}}}{\\sum\\_{i=1}^n \\mathbb{1}\\_{\\{Y\\_i^{-U\\_i}=y\\}}}\\ell(W,Z^{-U\\_i}\\_i)-\\frac{\\mathbb{1}\\_{\\{Y\\_i^{U\\_i}=y\\}}}{\\sum\\_{i=1}^n\\mathbb{1}\\_{\\{Y\\_i^{U\\_i}=y\\}}}\\ell(W,Z^{U\\_i}\\_i)\\right)\\right]\\right].\n$$\nBy definition, we know that $\\sum\\_{i=1}^n\\mathbb{1}\\_{\\{Y\\_i^{-U\\_i}=y\\}}+\\sum\\_{i=1}^n\\mathbb{1}\\_{\\{Y_i^{U_i}=y\\}}=n^y_{\\bf Z}$, and I think on average we also have $\\mathbb{E}\\_{U}\\left[\\sum\\_{i=1}^n\\mathbb{1}\\_{\\{Y_i^{-U_i}=y\\}}\\right]=\\mathbb{E}\\_{U}\\left[\\sum_{i=1}^n\\mathbb{1}\\_{\\{Y_i^{U_i}=y\\}}\\right]=n^y_{\\bf Z}/2$. However, this may still not be sufficient to derive Eq. (6). This also raises the question of whether we can use the class-dependent CMI bounds to bound the standard generalization error, i.e. is Corollary 2 a bound for standard generalization error or some other generalization notion?\n\n2. Regarding Corollary 1: Is it tighter than the classic individual mutual information bound in Bu et al. (2019) when $\\sigma_Y$ does not depend on $Y$ (e.g., using loss boundedness instead)? I think this might be accurate due to the following:\n$$\n\\mathbb{E}\\_{P_Y}\\sqrt{D(P_{W,X|Y}||P_{W}\\otimes P_{X|Y})}=\\mathbb{E}\\_{P_Y}\\sqrt{\\mathbb{E}\\_{P_{W,X|Y}}\\log\\frac{P_{W,X|Y}P_{Y}}{P_{W}\\otimes P_{X|Y}P_{Y}}}=\\mathbb{E}\\_{P_Y}\\sqrt{\\mathbb{E}\\_{P_{W,X|Y}}\\log\\frac{P_{W,X,Y}}{P_{W}\\otimes P_{X,Y}}}\\leq \\sqrt{I(W;Z)},\n$$\nwhere the last inequality is by Jensen's inequality.\n\nIf this is correct, you could explicitly state that the individual bound can be recovered from your Corollary 1 or Theorem 1.\n\n3. Could you elaborate more on the last sentence in Remark 2, namely \"Therefore, samples from other classes can still affect these bounds, leading to loose bounds on the generalization error of class y\"?  As $\\max(\\mathbb{1}\\_{\\{Y_i^{-U_i}=y\\}}, \\mathbb{1}\\_{\\{Y_i^{U_i}=y\\}})=\\mathbb{1}\\_{\\{Y_i^{-U_i}=y \\\\;{\\rm or}\\\\; Y_i^{U_i}=y\\}}$. I understand the other parts in Remark 2. However, I don't understand why samples from other classes contribute to the looseness of the bounds. \n\n4. My previous question also raises another concern regarding the comparison between Theorem 4 and Theorem 3: I agree that $I_{\\bf Z}(\\Delta_y L_i; U_i)\\leq I_{\\bf Z}(f_W(X_i^{\\pm}); U_i)$; however, I would like to point out that we also have $\\max(\\mathbb{1}\\_{\\{Y_i^{-U_i}=y\\}}, \\mathbb{1}\\_{\\{Y_i^{U_i}=y\\}})I_{\\bf Z}(f_W(X_i^{\\pm}); U_i) \\leq I_{\\bf Z}(f_W(X_i^{\\pm}); U_i)$ (doesn't this imply that\n $\\max(\\mathbb{1}\\_{\\{Y_i^{-U_i}=y\\}}, \\mathbb{1}\\_{\\{Y_i^{U_i}=y\\}})$ makes Theorem 3 tighter instead of looser?) Therefore, it is uncertain whether Theorem 4 is tighter than Theorem 3 or not. The empirical results suggest that Theorem 4 is tighter, but I hope the authors could clarify why this is expected.\n\n**I would be happy to increase my score if authors could adequately address my main concerns.**\n\nMinor comments:\n\n1. There is a related work that could be included: Hrayr Harutyunyan, et al. \"Improving generalization by controlling label-noise information in neural network weights.\" ICML 2020. In that work, they decompose the mutual information term by chain rule: $I(W;Z)=I(W;X)+I(W;Y|X)$, and using $I(W;Y|X)$ as a regularization term. This might be the first work to incorporate label information into information-theoretic bounds.\n\n2. Notations are not always consistent. For example, in Eq.(6), the selection random variable in the loss function is ${\\bf U}_i$ but it becomes ${U}_i$ in the identity function.\n\n3. In Theorem 8 in the Appendix, you may use the widely accepted term for the loss pair-based CMI, namely *evaluated CMI* or *e-CMI*, which was initially introduced in the original CMI paper (see Section 6.2 in the arxiv version of Steinke \\& Zakynthinou (2020)).\n\n4. After Eq. (26) and Eq. (48): \"Next, Let\" ---> \"Next, let\". There might be more similar typos.\n\n5. When the authors or the publication are not\nincluded in the sentence, the citation\nshould be in parenthesis using **\\citep{}** instead of **\\citet{}** or **\\cite{}**. Most of citations in this paper are not in parenthesis while the authors or the publication are not part of the sentence. For example, in the first sentence of introduction, He \\& Tao\n(2020) should be (He \\& Tao\n(2020)) by using **\\citep{}**."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8003/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698536445090,
        "cdate": 1698536445090,
        "tmdate": 1699636986115,
        "mdate": 1699636986115,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "e5pfNz5uYC",
        "forum": "UNv8RzIf5x",
        "replyto": "UNv8RzIf5x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_Lz6e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8003/Reviewer_Lz6e"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses focusses on the generalization performance for individual classes rather than the whole data distribution. The authors argue that existing generalization bounds, which typically apply to the average performance across the entire data distribution, do not capture the variations in performance across different classes. To address this gap, the paper introduces a novel information-theoretic bound for class-generalization error using the KL divergence. Additionally, it proposes tighter bounds derived from the conditional mutual information (CMI). The results are supported with experiments on CIFAR dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This is the first work which has introduced class wise generalization bounds (as per the authors) which is an interesting and important idea. They identify that information theoretical based bounds are a natural class of bounds to use for this setting which is interesting.\n\n- The paper is generally well written."
            },
            "weaknesses": {
                "value": "In my opinion, the main weakness of the paper is the incremental nature of this work. The use of KL divergence and CMI in deriving generalization bounds has been explored in prior literature. The work is essentially following the previous works with this additional conditioning. I don\u2019t see any new technical challenges that appeared due to this conditioning. Neither have the authors mentioned that. \n\nSo, the main contribution seems to be showing that information theoretical generalization bounds can be adapted to subsets of data easily."
            },
            "questions": {
                "value": "- I wanted to ask if there have been any previous works on computing class wise generalization bounds. Or, are there any works on generalization bounds for a subset of dataset with a particular attribute?\n- The authors state that information theoretic bounds are natural for this setting as they depend on both the algorithm and the data. It would be useful to discuss this in more detail and discuss why it would be hard to obtain class wise generalization bounds for other types like stability based or hypothesis based. Couldn\u2019t differing property of the subclasses be captured in some way to get different generalization bounds for different classes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8003/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698981243957,
        "cdate": 1698981243957,
        "tmdate": 1699636985960,
        "mdate": 1699636985960,
        "license": "CC BY 4.0",
        "version": 2
    }
]