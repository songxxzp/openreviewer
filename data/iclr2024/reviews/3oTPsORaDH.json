[
    {
        "id": "DAGw1W9bZr",
        "forum": "3oTPsORaDH",
        "replyto": "3oTPsORaDH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_mXJL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_mXJL"
        ],
        "content": {
            "summary": {
                "value": "## Summary\n\nThe paper investigates the integration of physical inductive biases, equivariant Graph Neural Networks (GNNs), and Neural Ordinary Differential Equations (ODEs) to improve model prediction accuracy. The authors validate their approach on 3 datasets: N-body, molecular dynamics, and captured human motion data. The technical contributions are sound though not groundbreaking. Given the paper's strengths and incremental contribution, I recommend a borderline acceptance.\n\n## Detailed Comments\n\n### Contributions\n\n1. The paper shows that the error bound between the predictions and the ground truth outperforms previous methods focused on average accelerations.\n2. It establishes that when the incremental function is either E(3) or O(3), the combined Neural ODE and equivariant GNN also possess these properties.\n3. It shows enough empirical validation and ablation studies for later scholars to save their time and make proper choices.\n\n### Comments and Suggestions\n\na) Lack of Visual Illustration: Apart from human motion data, the paper does not provide visual illustrations for any of the datasets. This makes it challenging to grasp the scope of the method's applicability, especially for readers not specialized in fields like molecular dynamics or N-body systems.\n\nb) Figure 4 Inconsistency: The first column in Figure 4 is hard to interpret due to inconsistent color coding of initial conditions and predictions across different columns. It would be helpful to maintain color consistency.\n\nc) Unclear experiment in Figure 2: It is unclear which experiment or dataset Figure 2 refers to, leading to possible confusion for the readers.\n\nd) Inconsistent Sectioning for Human Motion Experiment: Unlike the other experiments, the human motion experiment is not provided a standalone section, making it confusing for readers.\n\ne) Future Direction on Scalability: The paper could benefit from discussing scalability issues for large graphs. Since all examples in the paper involve graphs with fewer than 1,000 nodes, it would be interesting to explore the method's applicability to larger networks. Some relevant references include:\n\n- [MultiScale MeshGraphNets](https://arxiv.org/abs/2210.00612)\n- [Multi-GPU Approach for Training of Graph ML Models on large CFD Meshes](https://arxiv.org/abs/2307.13592)\n- [Efficient Learning of Mesh-Based Physical Simulation with BSMS-GNN](https://arxiv.org/abs/2210.02573)\n- [LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation](https://arxiv.org/abs/2302.01503)\n\n## Conclusion\n\nThe paper presents a sound technical approach integrating physical inductive biases, equivariant GNNs, and higher-order Neural ODEs to improve model prediction accuracy. It's a sound but not groundbreaking paper. Therefore, I recommend a borderline acceptance for this paper."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "See above"
            },
            "weaknesses": {
                "value": "See above"
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Reviewer_mXJL"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6713/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698359135074,
        "cdate": 1698359135074,
        "tmdate": 1699636771197,
        "mdate": 1699636771197,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qCvgybi8Lx",
        "forum": "3oTPsORaDH",
        "replyto": "3oTPsORaDH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_rsLd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_rsLd"
        ],
        "content": {
            "summary": {
                "value": "The authors present an innovative graph neural network framework that introduces second-order continuity into the modeling process. Unlike traditional discrete updates in other graph neural networks, they employ neural ordinary differential equations to capture continuous trajectories. This approach preserves the equivariance property of the underlying graph neural networks. Their model is rigorously evaluated across a range of standard test systems, including time evolution of N-body systems, molecular trajectories, and human motion trajectories. In all experiments, their model consistently outperform existing methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The paper is well written and structured\n- The authors introduce a novel framework for graph neural networks that incorporates second-order continuity by utilizing neural ODEs. This innovation enables more accurate modeling of physical systems, as many are governed by second-order laws.\n- Their approach stands out by allowing the modeling of continuous trajectories, in contrast to existing graph neural networks that rely on discrete updates.\n- They rigorously prove the claims they make, such as the preservation of equivariance and the derivation error bounds. \n- Their model undergoes extensive testing on various time series prediction tasks, consistently outperforming previous models and showcasing its superior performance.\n-  The insightful ablation study underscores the significance of incorporating second-order dynamics and utilizing a continuous model instead of a discrete one.\n\nIn conclusion, I consider this paper to be a significant and valuable addition to the community, and I recommend its acceptance."
            },
            "weaknesses": {
                "value": "- Run times for the various methods are not reported. Given the neural ODE nature of SEGNO, it's reasonable to assume that this model might have longer execution times compared to some of its competitors. It would be advantageous to include these run times in the appendix, with brief mentions in the main text for clarity."
            },
            "questions": {
                "value": "- Can SEGNO be included in a Markov Chain Monte Carlo (MCMC) framework aimed at accelerating Molecular Dynamics simulations, a common application for predicting future trajectory states? Typically, such applications require Metropolis-Hastings corrections to asymptotically sample from the equilibrium distribution.\n\n- Graph neural networks are known for their transferability, as demonstrated by other methods on the QM9 dataset. While acknowledging the difference in tasks, do the authors envision the potential for SEGNO to be employed in a similarly transferable manner?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6713/Reviewer_rsLd"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6713/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794930587,
        "cdate": 1698794930587,
        "tmdate": 1699636771081,
        "mdate": 1699636771081,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kqJsJpeHqA",
        "forum": "3oTPsORaDH",
        "replyto": "3oTPsORaDH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_GrTs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6713/Reviewer_GrTs"
        ],
        "content": {
            "summary": {
                "value": "In this work, authors combine neural ODE with equivariant GNN to propose a second order equivariant GNODE (SEGNO). Authors prove that the SEGNO maintains equivariance. The study prove that the discrepancy between the trajectory learned by SEGNO and the ground truth is bounded. Results show that the SEGNO provides relatively superior performance on various dynamical systems."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Learning dynamical systems with physics-based inductive bias is an important problem to be studied.\n2. Combining equivariance with NODE is an interesting approach. \n3. Several interesting and varied datasets are considered for empirical examples including n-body systems, MD22, and motion capture datasets. \n4. The results show that the SEGNO outperforms baselines for several tasks including molecular dynamics, and motion capture."
            },
            "weaknesses": {
                "value": "1. The idea of combining GNODE with an equivariant GNN is fairly straightforward. In fact, there are several works on GNODE that employ a second-order bias (Gruver et al., Bishnoi et al., both cited in the paper). While the backbone GNN can have some effect on the GNODE (as shown in the work: Thangamuthu, A., Kumar, G., Bishnoi, S., Bhattoo, R., Krishnan, N.M. and Ranu, S., 2022. Unravelling the performance of physics-informed graph neural networks for dynamical systems. Advances in Neural Information Processing Systems, 35, pp.3691-3702.), there are no restrictions on employing an equivariant GNN backbone with GNODE. Thus, the novelty of the work may be limited.\n\n2. In the present work, GMN is used as the backbone GNN along with the GNODE based inductive bias. The choice of the specific backbone may be appropriate for some datasets such as motion capture. However, the architecture does not perform well for molecular datasets or even n-body systems. Evaluation on additional backbone architectures is missing.\n\n3. The baselines considered are simple and not necessarily SOTA. For the MD22, there are several equivariant GNNs such as DimeNet, NequIP, Allegro, MACE, BOTNet, Equiformer, etc. (and many more newer architectures) that have shown SOTA performance. It is not clear why such advanced baselines or graph architectures are not used.\n\n4. The metrics used for comparison does not necessarily capture the complete picture regarding the dynamics. There are several metrics such as energy violation error, momentum error, rollout error etc. in the literature. Moreover, for atomic structures additional metrics such as JS divergence of the radial distribution functions capture how well the predicted the structure is similar to the ground truth. Such metrics have not been included in the present work leading to an incomplete evaluation. \n\n5. There are several works on articulated rigid body in the literature including physics-informed GNNs such as Hamiltonian NNs, and Lagrangian graph neural networks for articulated body. Comparison with such baselines are not included in the work."
            },
            "questions": {
                "value": "1. Authors may rephrase the text ``accurately approximate'' in the proof of theorem 4.2?\n2. Theorem 4.1 is a standard proof for any dynamical system and is not specifically related to SEGNO. It is not clear why this is a property of SEGNO and discussed under section 4. Authors may comment.\n3. Proposition 4.2 is trivially dependent on the universal approximation theorem and is not needed to be stated as a proposition. Essentially, it proves that a NN can approximate the function $f(q,h)$ by minimizing the error between $q_{\\theta}$ predicted by a NN and the ground truth $q$. This how every NN is trained. Authors may explain why this warrants a separate proof. \n4. The present work focusses on combining equivariant GNNs with GNODEs. There are several ways of considering baselines. One set of baselines would be different equivariant architectures directly employing a data-driven approach to predict the dynamics. This is how some of the baselines are included in the present work. However, extensive literature shows that physics-informed inductive bias such GNODE, Hamiltonian GNN, and Lagrangian GNN can provide superior performance. Comparison with other such physics-informed GNNs such as Hamiltonian and Lagrangian GNN would have been insightful. \n5. Another set of baselines would be GNODE with different equivariant backbone architectures. This has not been extensively evaluated in the present work. In the present work, authors employ GMN as the backbone. While it makes sense for the motion capture video, it is not clear why GMN would be a good backbone for the MD simulation dataset. Backbones such as NequIP would be better for such cases. Authors are encouraged to evaluate this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6713/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699188902216,
        "cdate": 1699188902216,
        "tmdate": 1699636770981,
        "mdate": 1699636770981,
        "license": "CC BY 4.0",
        "version": 2
    }
]