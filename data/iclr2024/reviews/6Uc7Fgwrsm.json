[
    {
        "id": "24jOtRnHfH",
        "forum": "6Uc7Fgwrsm",
        "replyto": "6Uc7Fgwrsm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission999/Reviewer_sgeX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission999/Reviewer_sgeX"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the general form of sample mixup by proposing OmniMixup that learns the optimal sampling strategies to sample instances. The core idea is to generalize existing sampling selection techniques to a learnable function. Then, authors analyzed the generalization bound of this approach. Experiments on image classification and molecular property prediction demonstrate the effectiveness of this approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of generalizing all sampling strategies into one unified framework is interesting and novel.\n2. The proposed OmniMixup framework is easy to follow.\n3. The experiments are showing the effectiveness of the approach on two applications.\n4. There are extensive theoretical analysis, which should be encouraged."
            },
            "weaknesses": {
                "value": "1. My major concern is that the operating range or limitation of this approach is not clear. Let me be clear: can this OmniMixup replace all other mixup approaches in applications? It seems not since this only deals with sample-level approaches (as shown in Sec. 3.2). There are other manifold space-based mixup approaches not discussed nor even compared. So, I\u2019m confused the practical value of this approach: is it replacing existing approaches, or just a plugin for them?\n2. The design of OmniMixup only supports sample-based approaches, while manifold mixup (Verma 2019) has been widely used in applications. It remains unclear whether this unified framework can include that type of approaches and how can they be compared.\n3. The complexity of this approach is not discussed. From algorithm 1, it seems that this paper requires non-trivial optimization or iteration to select the best MPSD. However, this is not discussed in the paper. I\u2019m not trying to be mean on this; but the efficiency should be very important in Mixup based approaches since the essence of Mixup family is simple and useful. Therefore, efficiency matters.\n4. Experiments are weak, which is another major concern of mine. First of all, the comparison methods are not enough to show the effectiveness of this algorithm (manifold mixup, for instance, in not compared). Second, the datasets to perform image classification are not enough. Given that Mixup has been widely used in image domain, Cifar-100 is not enough. Authors should include more datasets and methods for comparisons."
            },
            "questions": {
                "value": "See weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697704428462,
        "cdate": 1697704428462,
        "tmdate": 1699636026347,
        "mdate": 1699636026347,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4uBsy8wb6h",
        "forum": "6Uc7Fgwrsm",
        "replyto": "6Uc7Fgwrsm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission999/Reviewer_39U8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission999/Reviewer_39U8"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a mixup-based data augmentation technique that can be universally applied across various data modalities. While it extends the manifold mixup, which blends data in the latent space learned by the model rather than a specific data space, it employs a generalized form of the mixup methodology that encompasses a range of mixup-based algorithms. This generalized mixup is formalized, and its objective function's generalization bound is derived from the Rademacher complexity perspective. Building on this foundation, the paper proposes the OmniMixup methodology, which utilizes mixup pairs optimized for the derived bound in data augmentation. The introduced method is applied in both the vision domain and the graph data domain for molecule modeling, demonstrating improved performance compared to baseline models."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces OmniMixup, a generalized form of the mixup methodology that encompasses various mixup algorithms. It mathematically demonstrates that other mixup algorithms can be reduced to specific instances of OmniMixup.\n- The generalization bound for the objective function of OmniMixup is derived using Rademacher complexity.\n- An algorithm is presented to optimize the derived generalization bound, and a method to obtain the optimal MPSD is proposed.\n- Based on the measured M-score, the authors select suitable latent feature acquisition models and mixup algorithms across diverse modalities and apply the proposed methodology."
            },
            "weaknesses": {
                "value": "- While the proposed OmniMixup is understood to theoretically sample data pairs optimized for the generalization bound, considering it only shows a slight performance improvement compared to mixup and isn't compared to recently proposed methodologies, the provided experimental results seem insufficient in showcasing its true effectiveness.\n- Although the paper claims that OmniMixup can be applied across various modalities, the experiments presented are limited to low-resolution images and molecule graph data datasets. This restricts the ability to ascertain OmniMixup's broad applicability across different modalities.\n- The motivation behind the design choice of MPSD in each modality is not adequately explained.\n- It appears that a cost is associated with obtaining the optimized MPSD for mixup application. If this cost is significant and the performance improvement over other mixup methodologies is marginal, there might be limited incentive to employ OmniMixup."
            },
            "questions": {
                "value": "- Are there experimental results for other image datasets, and if so, how do they compare with existing mixup methodologies? Specifically, are there results for datasets that display relatively low performance during standard training, especially those with high resolution or various types of noise? The outcomes presented in the paper indicate only modest performance improvements when compared to baseline mixup results, making it challenging to discern its effectiveness. It would be better to show the experiments for little harder datasets to demonstrate the data augmentation effect of the proposed method.\n- Has the method been tested on datasets of different modalities, e.g., NLP? Given that the mixup is applied in the latent space, it seems feasible to conduct experiments across various modalities.\n- Are there results for other design choices of OmniMixup apart from the one used in the paper? Given OmniMixup's highly generalized representation, an ablation study exploring various design choices seems warranted.\n- Is there a cost analysis experiment for executing the OmniEval algorithm? While the cost might vary based on the model choice for deriving features, if the performance justifies the incurred cost, it might be worthwhile to consider the methodology's application.\n\n- Some notations in the paper could benefit from further clarification.\n- The experimental descriptions are unclear. I interpreted from Figure 1 that higher performance corresponds to a lower M-score, but it's ambiguous what \"performance\" specifically refers to and how it's represented in quartiles.\n- Numerous supplementary experiments appear necessary. If the aforementioned issues are addressed, I anticipate that the methodology could be a promising approach for data augmentation across various modalities, including the vision domain."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Privacy, security and safety"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Reviewer_39U8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698144066808,
        "cdate": 1698144066808,
        "tmdate": 1699636026269,
        "mdate": 1699636026269,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9SqFK7D2oi",
        "forum": "6Uc7Fgwrsm",
        "replyto": "6Uc7Fgwrsm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission999/Reviewer_CqYZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission999/Reviewer_CqYZ"
        ],
        "content": {
            "summary": {
                "value": "The authors first propose OmniMixup framework that works with arbitrary Mixing-Pair Sampling Distribution (MPSD). Essentially, it determines how to choose a pair of samples to produce virtual examples that are not out-of-distribution. Then they find that the Mahalanobis distance (M-Score) is highly correlated to the performance of given MPSD so propose OmniEval for choosing optimal MPSD before training."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Overall, the paper is well-written, and its ideas are presented in a clear and easily understandable manner for readers to follow.\n2. The paper introduces OmniMixup, a generalized framework that extends the concept of Mixup and addresses the limitations of modality-specific approaches. It introduces Mixing-Pair Sampling Distribution (MPSD) and provides a theoretical analysis framework for evaluating the generalization ability of different approaches. To the best of my knowledge, the OmniMixup framework is novel.\n3. The theoretical aspect of the paper appears to be solid."
            },
            "weaknesses": {
                "value": "Overall, my main concern is that the experimental results do not sufficiently demonstrate OmniMixup's advantage in terms of model performance. For instance, the advantage shown in Table 1 is less than 0.6%, and the advantage shown in Table 2 is not statistically significant. The limited empirical evidence diminishes the significance of formulating the framework."
            },
            "questions": {
                "value": "1. Section 2.3 of [1] presents a case that demonstrates how mixup may lead to a classifier that does not minimize the empirical loss on the data. I am interested to know if OmniMixup can avoid this issue.\n2. Is it possible to utilize a pre-trained model in the first step of Algorithm 1, eliminating the need for training with ERM?\n3. I noticed that Table 1 does not include standard deviations like Table 2. Since the improvement of OmniMixup on the CIFAR dataset is marginal, for example, only 0.2%, which could potentially be influenced by randomness. It would be helpful for the authors to include standard deviations, similar to Table 2.\n4. The experiments section should include more baselines, such as Local-Mix and C-Mixup. This would help demonstrate if the optimal pair sampling distribution in OmniMixup outperforms strategies designed by experts.\n5. Figure 1 is not clear enough for me. To demonstrate the relationship between the estimated M-Score and their respective model performances, it might be more effective to provide a scatter plot or plot their ranks similar to Figure 8 in [2]. Additionally, calculating the Kendall-tau correlation could further justify your points."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission999/Reviewer_CqYZ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698770210552,
        "cdate": 1698770210552,
        "tmdate": 1699636026201,
        "mdate": 1699636026201,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hkogVIe9Y2",
        "forum": "6Uc7Fgwrsm",
        "replyto": "6Uc7Fgwrsm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission999/Reviewer_AcyS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission999/Reviewer_AcyS"
        ],
        "content": {
            "summary": {
                "value": "The way the paper is written is quite confusing. From my current understanding of it, the authors formalise the mechanism of the choice of the samples to be mixed as a distribution that can be automatically selected through an algorithm that considers the mahalanobis score. They frame previously existing mixing techniques as a subcase of their own, derive some bounds and provide some experiments that are supposed to exhibit the superiority of the proposed technique."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper tries to provide a theoretical framework that drives the selection of the samples to be mixed."
            },
            "weaknesses": {
                "value": "- The motivation of the paper is confusing. The authors first mention that mixup is hard to apply across different modalities, but it's not clear what the authors are doing specifically about it. This is even more confusing when mixup techniques performed in latent space are brought up, yet I seem to understand the authors did not use those techniques.  \n- It is not clear why the authors do not compare Omnimixup with the extensively available mixup variants. For instance, sticking to image processing: why is there not a comparison with CutMix [1], RegMixup [2], PuzzleMix [3], AugMix [4] just to mention a few. Similarly other baselines of Mixup variants for molecular data should be considered.\n- From the image classification experiments, it looks like the models of the baselines have not been properly trained. For instance, in [2] the numbers reported for Mixup and ERM on WideResNet-28-10 are higher. \n- The paper often refers to manifold intrusion, which is a questionable concept introduced in the Mixup literature but not adequately studied or quantified. It is not really clear how Omnimixup either proves its existence or is doing something about it. \n- If access to CLIP is required to perform Omnimixup on images, then one would be better off using CLIP directly as a classifier and fine-tune it/use smarter strategies to use it. What's the point of even bothering about Omnimixup to get marginal accuracy improvements on toy datasets like CIFAR-10/100?\n- An algorithm box to exemplify omnimixup would help.\n- The presentation is extremely chaotic and confusing, some terms are used without being properly defined, and one needs to jump back and forth between different parts of the paper to try to figure out what's going on. \n\n\n[1] https://arxiv.org/abs/1905.04899\n[2] https://arxiv.org/pdf/2206.14502.pdf\n[3] https://arxiv.org/abs/2009.06962\n[4] https://arxiv.org/pdf/1912.02781.pdf"
            },
            "questions": {
                "value": "- Is the mixing performed in input space or latent space? \n- The search procedure seems to come at a high computational expense. Could the authors precisely report and discuss the cost of searching both theoretically and empirically? If this cost is inferior to training few models with ERM, even ensembling should be considered as a baseline."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795447494,
        "cdate": 1698795447494,
        "tmdate": 1699636026109,
        "mdate": 1699636026109,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YCOyaeBnhH",
        "forum": "6Uc7Fgwrsm",
        "replyto": "6Uc7Fgwrsm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission999/Reviewer_wmTG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission999/Reviewer_wmTG"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the Mixup technique and proposes to sample across different modalities to explore the generalization of Mixup training. Through extensive theoretical analysis, the authors find out that the Mahalanobis distance is essential for the capabilities of Mixup. By proposing a novel Mixing-Pair Sampling Distribution to summarize the most popular Mixup strategies, a uniform framework is introduced to provide a holistic understanding of Mixup. By conducting rigorous experiments, the performance of the proposed OmniMixup is carefully validated."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper is well-written and easy to follow.\n- The provided generalization bound is rigorously derived and provides a solid understanding of introducing the expected M-Score criteria.\n- Through careful empirical validation, the performance OmniMixup is shown to surpass ERM and Mixup."
            },
            "weaknesses": {
                "value": "- First, could the author justify the significance of Mixup over multiple modalities? What is the basic motivation and novelty?\n- It seems that the modalities are just sampled from image and text features provided by CLIP. However, it is questionable to call these two types of features multimodalities, because CLIP is a very strong model, and its feature spaces are perfectly aligned with each other. Is it possible that the proposed method can be applied to low-level multimodalities?\n- Is there any intuitive understanding of the theoretical result? How is the direct comparison of the proposed generalization bound to vanilla Mixup and ERM?\n- Is the hyperparameters $\\tau$ and $\\beta$ carefully selected?\n- The experimental improvements are quite marginal, which again raises concern about the significance of proposing such a holistic framework. Moreover, the M-score is addressed in this paper, however, the comparison in Table 3 seems to challenge the claim: the M-scores of Mixup and OmniMixup are very close to each other."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission999/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821672818,
        "cdate": 1698821672818,
        "tmdate": 1699636026023,
        "mdate": 1699636026023,
        "license": "CC BY 4.0",
        "version": 2
    }
]