[
    {
        "id": "Ui0t3CSW1b",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission315/Reviewer_APZm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission315/Reviewer_APZm"
        ],
        "forum": "F5ERvanO6m",
        "replyto": "F5ERvanO6m",
        "content": {
            "summary": {
                "value": "This work introduces an idea based on stochastic mechanics to provide approximate solutions to the time-dependent Schroedinger's equation, and neural parameterizations of various quantities involved."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea is very innovative and I especially liked the use of Nelsonian dynamics."
            },
            "weaknesses": {
                "value": "The approach is limited to very simple/small systems (harmonic oscillators and interacting distinguishable particles of only a handful of particles).  \n\nThe discussion is also quite limited, and bypasses a vast amount of literature in the field, including time-dependent variational wave functions based on neural network parameterizations. \n\nFor example: \n\n\"Another family of approaches, FermiNet (Pfau et al., 2020) or PauliNet (Hermann et al., 2020),\nreformulates the problem (1) as maximization of an energy functional that depends on the solution of\nthe stationary Schrodinger equation. This approach sidesteps the curse of dimensionality but cannot \u00a8\nbe adapted to the time-dependent wave function setting considered in this paper.\" \n\nThe approach that reformulates (1) as a static, variational problem does not date to 2020 and it is as old as quantum mechanics itself. \nAlso, neural variational parameterizations of the wave function are routinely used to solve the time-dependent Schroedinger's equation. These approaches are based on Dirac and Frenkel's time-dependent variational principle, and have been used in several works, starting e.g. from https://www.science.org/doi/10.1126/science.aag2302, https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.100503 and many more."
            },
            "questions": {
                "value": "1) The approach is shown for very small systems, and in cases that are solved easily with many other approaches (including, for example, using a discrete basis and using the time-dependent variational principle with a neural network wave function). Do the authors have a sense of the scaling in terms of number of particles/ can they show a case that goes beyond what can be simulated exactly? \n\n2) A grid-based discretization seems to be used in the paper, at least in Figure 1 d. Can the authors clarify how does the discretization enter their algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Reviewer_APZm"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission315/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697196454083,
        "cdate": 1697196454083,
        "tmdate": 1700741299193,
        "mdate": 1700741299193,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "A0LLxrm1hM",
        "forum": "F5ERvanO6m",
        "replyto": "F5ERvanO6m",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission315/Reviewer_oJtq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission315/Reviewer_oJtq"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a stochastic formulation of the Schr\u00f6dinger equation. The proposed formulation can be used to simulate quantum mechanics with high efficiency. \nA key difference between this new formulation and the one proposed by Nelson is that the new method employs the gradient of the divergence operator to facilitate the neural computations.\nThey also prove theoretically that the loss function used to train neural networks is upper bounded by the L2 distance between the true process that samples from the quantum density and an approximate process which the neural network tries to predict.\nExperimental results show that the proposed method is superior to the baseline method PINNs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The new stochastic formulation of the Schr\u00f6dinger equation provides an efficient way for quantum mechanics simulation by utilizing the power of neural computation.\n2. Training loss of the neural networks for learning stochastic process is bounded with theoretical guarantees.\n3. The O(Nd) computational complexity looks very promissing and opens the door for large-scale quantum simulation."
            },
            "weaknesses": {
                "value": "1. Seems the neural network employed in this study is a single layer neural network. I am wondering how a single layer neural network could learn dynamics of a complicated wave function. Also the illustrations in the experiment look pretty simple. The authors are encouraged to tackle more complicated cases using the proposed method.\n2. The O(Nd) computational complexity need more elaboration. Is it the computational complexity of training the neural networks on a single trajectory? For learning a stochastic process, we may need to sample many trajectories  in order to learn hidden low dimensional representations of process. I am not sure whether it is fair comparisons with other methods as listed in the table 1."
            },
            "questions": {
                "value": "1. For training losses defined in eq. 11 to eq. 15, because they need integration operation, I am wondering in practice how the integration is done and what is the window length of the integration during the training process at each iteration/epoch.\n2. In page 5, the authors mentioned for each iteration, they will sample new trajectories using eq. 7. How do we handle the cold start problem at the very beginning of the training process. I mean at the beginning of the training process, neural networks have not learned dynamics of the stochastic process. So the trajectories we sampled may be invalid or they will mis-guide the learning of the target stochastic process."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission315/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698475848111,
        "cdate": 1698475848111,
        "tmdate": 1699635958019,
        "mdate": 1699635958019,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5FNY13jH6Q",
        "forum": "F5ERvanO6m",
        "replyto": "F5ERvanO6m",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission315/Reviewer_iLX6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission315/Reviewer_iLX6"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a neural-network-based solver for simulating the time evolution of quantum systems, called Deep Stochastic Mechanics (DSM). DSM is based on Nelson\u2019s formulation of stochastic quantum mechanics where the quantum system evolution is characterized by a stochastic process. The authors captured the correspondence between Nelson\u2019s formulation and a diffusion process, where a partial differentiation equation lies at the heart. Then they propose to approximate the solution to the PDE with neural networks. A training process employs errors of the PDE in the time-evolution and initial points as the loss functions to approximate the solution. Empirical studies of this method are also conducted on several typical quantum systems."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The paper\u2019s approach to simulating quantum systems is very intriguing. It provides insights into the connection between quantum mechanics and diffusion processes and exploits it with neural networks which recently have shown advantages in dealing with diffusion processes. It ends in a stochastic NN-based simulator with low training cost and with theoretical guarantees on the quality of the solution. Since the training process is based on trajectories of the stochastic process, it is naturally adaptive to the structure of the solution and boosts the precision because of the focus on the solution space. \n\nThe experiments demonstrated the performance of DSM to surpass prior methods, tackling the most challenging problem in simulating quantum systems: the curse of dimensionality. It is suggested that NNs have the capability of exploiting the low latent dimension of the simulated quantum system, making use of their advantages in extracting low-dimensional features in high-dimensional data. This observation seems the most interesting part of this approach, which, to the best of my knowledge, is not exploited in other approaches. It is quite possible that a large number of quantum systems effectively have low latent dimensions, and DSM may be well-suited to provide sampling from these systems. \n\nAlthough the materials may not be easily accessible to the general ML audience, the well-organized presentation is likely to deliver the core ideas of this paper to a broader community. The inspiring innovations of this paper make it worthy to be published in ICLR."
            },
            "weaknesses": {
                "value": "Although the experiments cover several interesting cases where DSM works well, the limitation of DSM is not fully discussed in the paper. I would like to understand what cases will fail DSM. For example, does it perform worse on systems with complicated interactions or large latent space? I believe such examples may better illustrate the limitations and the suitable scenarios of DSM."
            },
            "questions": {
                "value": "Additionally, I wonder how the performance of DSM through stochastic quantum mechanics compares to other (NN-based) PDE solvers via Shrodinger\u2019s formulation. Is it possible to exploit the latent space within Shrodinger\u2019s picture, either with NNs or not?\n\nA minor point: in Section 5.1, it is claimed that \"Table 2 shows ... and the training time for ...\", while the training time is not found in Table 2. Where is it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission315/Reviewer_iLX6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission315/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698681082465,
        "cdate": 1698681082465,
        "tmdate": 1699635957890,
        "mdate": 1699635957890,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xNcP8nL9SJ",
        "forum": "F5ERvanO6m",
        "replyto": "F5ERvanO6m",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission315/Reviewer_JVMX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission315/Reviewer_JVMX"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a new approach to simulating time evolution in quantum systems by learning the gradient of the modulus and phase of the wavefunction over time. This is done by using a loss function that ensures the networks parametrizing these gradients satisfy the Schroedinger equation. The main novelty is to evaluate this loss on a batch coming from the samples of a stochastic process that describes the evolution of the modulus squared of the wavefunction. Numerical experiments for low dimensions show a better behavior than PINN.\nMy score is between 6 and 8, leaning towards 6. If more evidence for favourable scaling wrt traditional methods is provided, I can increase my score."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Novel and interesting approach to simulating time evolution in quantum mechanics using deep learning\n- Favourable O(d) scaling compared to PINNs which requires O(d^2) to compute the Jacobian\n- Evaluation of the loss on trajectories coming from the stochastic process governing the modulus squared of the wavefunction, compared to PINNs which require to specify collocation points.\n- Experiments show better performance than PINNs"
            },
            "weaknesses": {
                "value": "- The framework does not seem to allow estimation of non-diagonal observables, eg momentum\n- While I understand the complexity argument for evaluating the loss in O(d), it is unclear to me whether this method can scale better than traditional approaches. In particular, experiment of figure 4 studies the harmonic oscillator for d=1..9. However, if I understand the setting, the Hamiltonian is separable in the dimensions and so the problem has a natural scaling linear in d. I am therefore unsure about the promise for a more favourable scaling than traditional methods.\n- The use of stochastic formulation of quantum mechanics for quantum mechanics simulation is not necessarily novel, however I have not seen references to it. I am not an expert in this field, but one example I found is [Quantum Dynamics with Trajectories, Robert E. Wyatt].\n\nMinor:\n- below eq 5, one of the two u's should be v."
            },
            "questions": {
                "value": "- Can you benchmark the method against traditional solvers for an interacting problem in higher dimension and show a more favourable scaling?\n- How would one estimate the expectation of a non-diagonal operator?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission315/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698681782852,
        "cdate": 1698681782852,
        "tmdate": 1699635957790,
        "mdate": 1699635957790,
        "license": "CC BY 4.0",
        "version": 2
    }
]