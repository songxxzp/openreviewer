[
    {
        "id": "S4wXm2gb0v",
        "forum": "nZP6NgD3QY",
        "replyto": "nZP6NgD3QY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_zdU4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_zdU4"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a model merging method in the context of multi-task learning. The key idea is to take a pre-trained model and fine-tune it separately for each task using task-specific data, resulting in task-specific models. Then the paper introduces a novel method for automatically merging the task-specific parameters without the need for retraining. In essence, this work builds upon the foundations of Task Arithmetic [1] and TIES-MERGING [2] but enhances the process by incorporating adaptive task weights.\n\n[1] Ilharco, Gabriel, et al. \"Editing models with task arithmetic.\" ICLR2023.   \n[2] Yadav, Prateek, et al. \"Resolving Interference When Merging Models.\" NIPS2023."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper is easy to follow. \n- The idea is easy to catch up with."
            },
            "weaknesses": {
                "value": "- The novelty remains a question for me. \n- The practical value of this method is not well supported.\nPlease refer to the questions part."
            },
            "questions": {
                "value": "- I'm not sure the paper has sufficient novelty to be published in the top-tier conference since the proposed method only goes one step further from Task Arithmetic [1] and TIES-MERGING [2] by incorporating trainable weights for task vectors.The concept seems thin to support an entire paper, with only one page (page 6) dedicated to the novel part. Authors should consider diving deeper into this direction. For example, exploring the underlying reasons for the weight relationships between different tasks and their potential correlation with task relationships could enhance the paper's depth. Additionally, the learned weights could be utilized to guide the training of multi-task models, as seen in Auto-lambda [3].\n\n- Is it really necessary to conduct experiments to show the relationship between Shannon entropy and cross entropy? Actually from the information theory, the two concepts are almost the same thing or we can say cross entropy is derived from Shannon entropy. It's kind of trivial or even unnecessary to do experiments in Figure 3. Besides, the usage of Shannon entropy to train the adaptive weights also limits the method can only be used for classification tasks.\n\n- It's better to show the performance of the pre-trained model on each task as well in Tables 1 and 2. \n\n- Limited application of this kind of work. From Tables 1 and 2, we can clearly see that traditional MTL or we say all-shared MTL can achieve a very high accuracy, not to say SOTA MTL methods like AdaShare [4] and AutoMTL[5]. In practice, machine learning engineers might prefer these alternatives due to their superior performance. Besides, for the model merging direction, it's weird to assume that although we may not be able to get the train data for each task, we can still get the pre-trained weights of the model. Most importantly, those task-specific models even need to be trained from the same pre-trained weights. \n\n[1] Ilharco, Gabriel, et al. \"Editing models with task arithmetic.\" ICLR2023.   \n[2] Yadav, Prateek, et al. \"Resolving Interference When Merging Models.\" NIPS2023.   \n[3] Liu, Shikun, et al. \"Auto-lambda: Disentangling dynamic task relationships.\" TMLR2022.   \n[4] Sun, Ximeng, et al. \"Adashare: Learning what to share for efficient deep multi-task learning.\" NIPS2020.   \n[5] Zhang, Lijun, Xiao Liu, and Hui Guan. \"Automtl: A programming framework for automating efficient multi-task learning.\" NIPS2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Reviewer_zdU4",
                    "ICLR.cc/2024/Conference/Submission2378/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2378/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697918742243,
        "cdate": 1697918742243,
        "tmdate": 1700586892768,
        "mdate": 1700586892768,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L8462947wE",
        "forum": "nZP6NgD3QY",
        "replyto": "nZP6NgD3QY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_eRin"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_eRin"
        ],
        "content": {
            "summary": {
                "value": "Merging multiple fine-tuned models without a retraining process along with initial training data has been shown to be feasible, i.e., two existing works, Ties-Merging and Task Arithmetic. However, directly adding models may fail due to potential conflicts and intricate correlations. This paper proposed a new approach to automatically learn the merging weights by minimizing testing-time entropy on unlabeled samples in an unsupervised manner. Instead of the need for initial training data, this paper showed that testing-time entropy can serve as an approximated objective compared to traditional supervised loss. The authors proposed two main ways to learn the merging weights. One is task-wise merging, which learns the coefficient for each task. The other is a more fine-grained version, layer-wise merging, which not only learns the coefficient for each task but also for each layer. In their experiments, they included eight tasks to validate their approach with ViT models. Results have shown improvements in performance (for classification accuracy), generalization capabilities (to unseen tasks), and robustness (to test data distribution shifts) compared to the other two SOTA methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* Originality: Merging multiple fine-tuned models has been shown feasible, but this paper proposed and proved that using testing-time entropy as an objective to learn merging weights is effective and can be automatic. They also suggested that learning weights across different layers is crucial to the success of merging. These show the strength in originality.\n* Quality: The results of the experiments are solid and promising. They closed the performance gap between conventional MTL and task arithmetic-based methods.\n* Clarity: The presentation of this paper is clear. \n* Significance: Developing a single versatile model from ***diverse off-the-shelf fine-tuned models*** is important to LLM communities. Methods proposed by this work can reduce the efforts of collecting initial training data and the need for retraining for merging models. Besides, to merge fine-tuned models without tuning merging weights by grid-search, their automatic method to learn weights via test-time entropy is important to develop the means of model fusion. At last, the results in the paper improved two existing SOTA methods and showed method's strength in several dimensions."
            },
            "weaknesses": {
                "value": "* Though we don\u2019t need to train model again via original training data, we still need to access a certain amount of testing data for testing-time-entropy minimization. How the (minimum) amount of testing data can affect the quality of merging weights ($\\lambda$ in the paper) is encouraged to study and present in the paper.\n* In additional to the amount of testing data, the burden/computational needs/computational time to learn $\\lambda$ to converge via unlabeled testing samples is missing and lack of comparison to the other two SOTA methods. This study should be included and enhance the soundness of the proposed method.\n* I didn't see any restriction or regularization on $\\lambda$, especially in the optimization objective in Sec. 3.2.2. Does $\\lambda$ always need to be $\\sum_{i=k}^K \\lambda_i = 1$?"
            },
            "questions": {
                "value": "* The task relationships across 8 tasks included in the paper can be mentioned. I am curious about the performance changes when we have unrelated tasks and high-correlated tasks. \n* In some cases, can the part of the merging weights be negative terms?\n* Does the $\\lambda$ correlate to the performance gain in Table 1 and Table 2? Is there any relationship between weights and performance gain/loss?\n* (minor comment): It will be nice to move Fig 2 earlier for a better understanding."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Reviewer_eRin"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2378/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698771870111,
        "cdate": 1698771870111,
        "tmdate": 1700633840812,
        "mdate": 1700633840812,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dCZxwJf75r",
        "forum": "nZP6NgD3QY",
        "replyto": "nZP6NgD3QY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_3WDA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_3WDA"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles the problem of **Multi-task learning** in the context of foundation models: While the most common MTL paradigm is to train a single model on multiple tasks jointly, the paper investigates a different direction of merging single-task networks to form a single unified network. Like standard MTL, this approach can be affected by negative interference between tasks, in that naively merging model weights of conflicting tasks leads to poor performance. \nSpecifically, the proposed method builds on task arithmetic: While previous works considers simple uniform averaging of task vectors, this paper proposes `AdaMerging` which automatically learns how to weigh each model when merging the tasks, as well as a per-task *and* per-layer variant. The primary goal is to improve the model performance, as task arithmetic approaches still perform worse than standard MTL training. Finally, a last variant `AdaMerging++` which further integrates some ideas from `TiesMerging` (e.g. by removing redundant parameters and sign conflicts in the task vectors before merging them).\n\nIn practice, we may not have access to the original single task model training data, but only to a set of potentially unlabeled multi-task data. A key insight of the paper is that the entropy of the MTL model predictions is often correlated with the actual loss on the corresponding samples. Consequently, the proposed method directly optimizes the weights of the task vectors $\\lambda$, while minimizing the entropy of the current MTL model's prediction. The proposed `AdaMerging` is evaluated on ViT-backbones from CLIP models, on a suite of computer vision tasks, and compared to task arithmetic methods as well as traditional MTL optimization."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- **Good writing**: The paper is well written and easy to follow, also with good illustrative figures.\n\n- **Interesting research direction**: Task vector arithmetic for foundation model is a novel and interesting take on multi-task learning. Extending it to learning the task vector weights seems like a natural and meaningful direction, and very much in-line with automatic loss/gradient weighing scheme in standard multi-task optimization methods. \n\n- **Good set of ablation experiments**: The results on generalization (unseen tasks and corrupted data), as well as the qualitative visualization of the learned task vectors weights are very insightful."
            },
            "weaknesses": {
                "value": "- The conclusion of **Section 3.2.2** seems a bit strong to me from the conducted experiment: the analysis shows that the entropy and loss of a trained MTL model are nicely correlated, but it does not necessarily mean that they yield equally good directions during training: Doing the same analysis at different timesteps during the MTL model training could show whether and how this correlation holds during training.\n\n- **Discrepancy in supervision** : If I understood correctly, the single-task and MTL baselines use standard supervised training schemes; Task merging baselines (e.g. task arithmetic) are data-free methods and only require the task vectors; finally`AdaMerging` learns task arithmetic weights on unlabelled test samples ($B_k$ on page 6). While these are unsupervised, seeing test samples seems unfair compared to other baselines, especially the task arithmetic ones; it also may not be realistic to have access to a whole (unlabelled) test dataset at once (as opposed to e.g. a few-shot setting)\n\n- The experimental evaluation only considers **ViT-based backbones on small/medium computer vision benchmarks**. This is a bit different from the introduction, which focuses on readily available pretrained foundation models for which the original training data may be unknown. Furthermore, this also raises the question of MTL baselines: there is a very large literature on automatically weighing tasks losses/gradients for computer vision tasks, which may be stronger baselines than `traditional MTL`, and increase the performance gap even more (e.g. GradNorm, PCGrad, GradDrop...etc)\n\n\n**Overal summary**: To summarize, my main concerns are mainly *(i)* the fairness of chosen baselines (in terms of supervision in the case of task arithmetic schemes, and in terms of optimization strategies for traditional MTL) and to a lesser degree *(ii)* the strength of the conclusions derived from the analysis in **Section 3.2.2**.\n\n**Post rebuttal summary** I'm increasing my rating from 5 to 6 as the authors have addressed my main concerns, in particular about the additional requirement of test data; and I think/hope a more in-depth discussion of the trade-offs of the newly introduced experimental setting compared to the ones of traditional task merging and traditional MTL would make the contribution even stronger."
            },
            "questions": {
                "value": "- Does the **traditional MTL** baseline use some form of task weighing ? Intuitively I would expect that a \"good\" set of task vector weights might also be useful for reweighing/rebalancing the different tasks losses/data in traditional MTL training; but it would also be an interesting insight if that is not the case\n\n- Do you have insights on how a **supervised variant of `AdaMerging`** would perform ? It would be interesting to understand how much of the current gap with traditional MTL is due to the different supervision assumption, or due the task arithmetic process itself, versus directly finetuning the model weights  on MTL data.\n\n- Minor note:\n  *  in related work: *Task Arthmetic* -> Task Ar**i**thmetic"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2378/Reviewer_3WDA"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2378/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698786561447,
        "cdate": 1698786561447,
        "tmdate": 1700742610037,
        "mdate": 1700742610037,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wq6KyrPLZp",
        "forum": "nZP6NgD3QY",
        "replyto": "nZP6NgD3QY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_88YY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2378/Reviewer_88YY"
        ],
        "content": {
            "summary": {
                "value": "The paper first points out that multi-task model merging coefficients have a significant impact on the performance of existing merging solutions, and grid search model merging coefficients are unrealistic. Then, this paper proposes a new merging scheme, AdaMerging, based on multi-task entropy minimization to learn the optimal merging coefficients. Finally, the results under various architectures show that the proposed solution is significantly improved compared to existing model merging solutions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper studies model merging without original data, which is an important research direction.\n2. This paper proposes an unsupervised model merging scheme, which is technically feasible. Experimental results show that the proposed scheme has better multi-task performance, generalization, and robustness.\n3. The paper is well organized and easy to understand, and the proposed solutions are easy to follow and implement."
            },
            "weaknesses": {
                "value": "1. In the motivation, the authors need to explain the intuitive motivation for entropy minimization as a proxy objective for loss.\n2. In the experimental analysis, the author needed to explain why AdaMerging has better generalization and robustness."
            },
            "questions": {
                "value": "1. Is AdaMering in Tables 2, 3, and 4 a Task-wise or a Layer-wise version?\n2. Why is the model merging performance closer to traditional MTL in a larger architecture?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2378/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698842374515,
        "cdate": 1698842374515,
        "tmdate": 1699636170779,
        "mdate": 1699636170779,
        "license": "CC BY 4.0",
        "version": 2
    }
]