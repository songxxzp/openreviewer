[
    {
        "id": "O5Tux5sFsj",
        "forum": "ShQrnAsbPI",
        "replyto": "ShQrnAsbPI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_hHgp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_hHgp"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an interesting and novel approach to addressing the challenges of federated continual learning (FCL), particularly in scenarios where data and tasks among different clients are potentially unrelated or even antagonistic. The concept of \"accurate forgetting\" (AF) and the proposed AF-FCL method are well-motivated and empirically evaluated. The paper is well-written and addresses an important problem in the intersection of federated learning and continual learning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper introduces the novel concept of \"accurate forgetting\" (AF) in the context of FCL. It is commendable to challenge the conventional wisdom that forgetting is invariably detrimental and instead show that in specific situations, it can be beneficial.\n\n2. The paper conducts comprehensive experiments to evaluate the proposed method against various baselines. The results show the superiority of the AF-FCL method, which strengthens the paper's contributions.\n\n3. The paper is well-structured and clearly written."
            },
            "weaknesses": {
                "value": "1. The authors' use of feature correlation for replay training is intriguing, though the batch-wise weighting method employed seems somewhat simplistic. Recent research has explored orthogonal training techniques [1] to mitigate the influence of uncorrelated or biased old features. Consequently, a more nuanced feature weighting mechanism might yield improved results.\n\n2. It would be beneficial for the authors to provide a more detailed rationale for the application of the Normalization Flow (NF) model in this context. While any generative model could potentially be used to generate old features with a suitable feature extractor, it is unclear why the NF model was chosen specifically. It may be valuable to conduct experiments to demonstrate the necessity of the NF model in comparison to other generative models.\n\n3. Additional information regarding the architecture of the NF model and the communication cost it incurs would enhance the clarity and practicality of the proposed method.\n\n4. To better simulate the non-iid setting in Federated Learning, it is suggested that the authors consider employing a Dirichlet distribution [2], which could be more representative of real-world data distribution patterns than the current setting.\n\n5. While the paper addresses \"challenging\" datasets, such as CIFAR100 and MNIST-SVHN-F, it is recommended that the authors conduct experiments on truly challenging datasets like ImageNet. Additionally, the paper should include experiments with shuffled task orders for CIFAR100 and other challenging datasets to provide a more comprehensive evaluation of the proposed method.\n\n6. It is advisable for the authors to include comparisons with more recent baseline methods, such as TARGET (ICCV 2023 [3]), to ensure that the proposed approach is benchmarked against the latest state-of-the-art techniques in the field.\n\n[1] Bakman, Yavuz Faruk, et al. \"Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning.\" arXiv preprint arXiv:2309.01289 (2023).\n\n[2] Hsu, Tzu-Ming Harry, Hang Qi, and Matthew Brown. \"Measuring the effects of non-identical data distribution for federated visual classification.\" arXiv preprint arXiv:1909.06335 (2019).\n\n[3] Zhang, Jie, et al. \"TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023."
            },
            "questions": {
                "value": "Please see the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Reviewer_hHgp"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1302/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772312768,
        "cdate": 1698772312768,
        "tmdate": 1700590410244,
        "mdate": 1700590410244,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UpGJh0htpI",
        "forum": "ShQrnAsbPI",
        "replyto": "ShQrnAsbPI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_T35E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_T35E"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors discuss the problem of federated continual learning (FCL). Their solution forgetting problem in FCL is to train an NF Model (a type of generative model). This generative model has two benefits: first, it helps the clients to calculate the distribution parameters of the client data; second, it generates features that will be exploited to train the global model. The authors also propose a new task transition called limitless task pool (LTP), which is more suitable for federated settings. In LTP, clients' tasks are independently selected, and they may or may not share any data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper is well-motivated. \n* The solution is novel but complex.\n* The paper considers realistic scenarios, and it can outperform the prior works.\n* Paper includes various datasets, prior works, comprehensive ablation on the different components of the loss function, and computation analysis."
            },
            "weaknesses": {
                "value": "* It is not straightforward to understand how difficult the baselines are because FedAvg and FedProx, without any continual learning mitigation mechanism, have about 8% forgetting. Maybe this is due to the fact that the performance of the models is not good even in the current tasks.\n* In all the experiments, N (number of clients) is very small (only 10). \n* Please also check out the questions."
            },
            "questions": {
                "value": "1- Do task transitions for the clients happen simultaneously, or do tasks change in different clients independently?\n\n2- Is any example saved in the memory for AF-FCL? What is the memory size for the memory-based baselines (GFCL and FLwF2T)? \n\n3- How robust is AF-FCL to data heterogeneity? Could you please include the information regarding how heterogeneous clients' data distribution is?\n\n4- What is the communication cost for AF-FCL?\n\n5- What is the number of parameters in NF models?\n\n6- Are all the clients participating in the training every round?\n\n7- How is g initialized? What is the forgetting in the NF model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Reviewer_T35E",
                    "ICLR.cc/2024/Conference/Submission1302/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1302/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698788659675,
        "cdate": 1698788659675,
        "tmdate": 1700650340579,
        "mdate": 1700650340579,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i0ApVIuUV2",
        "forum": "ShQrnAsbPI",
        "replyto": "ShQrnAsbPI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_BJsd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_BJsd"
        ],
        "content": {
            "summary": {
                "value": "This work suggested the harm of remembering biased or irrelevant features, which could happen in federated continue learning (FCL) scenarios, and designed a generative methods to mitigate erroneous information by correlation estimation with an NF model. The authors have conducted sufficient experiments to validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The methodology is solid, successfully excluding biased features from the memory bank.\n\n2. The experiments are sufficient."
            },
            "weaknesses": {
                "value": "1. The problem formulation is confusing. In section 3.1 and most parts of section 3.2, the authors explain federated continual learning and a limitless task pool in detail, which is irrelevant to the methodology section. If I understand correctly, the main contribution of this work is disentangling and removing biased harmful features, while FCL merely serving as a relevant scenario. It would be better if the authors introduced the FCL formulation briefly and focused on the biased features in the memory bank.\n\n2. It would be better if the authors could illustrate or formally define \"biased features.\"\n\n3. Despite EMNIST-noisy, the authors haven't explained the reason why using all other datasets could introduce biased features.\n\n4. The term 'task' in the paper seems to refer to the 'data domain', instead of the commonly used task definitions (e.g., classification, segmentation, edge estimation), which is confusing."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Reviewer_BJsd",
                    "ICLR.cc/2024/Conference/Submission1302/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1302/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698913841562,
        "cdate": 1698913841562,
        "tmdate": 1700676643594,
        "mdate": 1700676643594,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VhTxp2QEvN",
        "forum": "ShQrnAsbPI",
        "replyto": "ShQrnAsbPI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_cH3G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_cH3G"
        ],
        "content": {
            "summary": {
                "value": "This paper presents Accurate Forgetting (AF) for Federated Continual Learning (FCL), a method that effectively leverages past knowledge in federated networks. It tackles the issue of biased or irrelevant features in FCL due to statistical heterogeneity. AF weights the generated data based on the current data distribution, effectively \"forgetting\" data that is heterogeneous to the current client and task. It also memorizes previous data by generating pseudo feature vectors based on the distribution in the latent space, thereby retaining information from previous data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Rather than preventing forgetting in continual learning settings, the authors introduce an interesting concept that forgetting is crucial even in these settings. They propose a method that accurately forgets heterogeneous or malign information by assigning lower weights to certain generated feature vectors.\n2. They employ a normalizing flow model to retain previous knowledge through distribution in feature space.\n3. The results, supported by ablation studies, highlight the effectiveness and superiority of their proposed accurate forgetting method over existing leading-edge methods."
            },
            "weaknesses": {
                "value": "1. In Section 4.2's experiment, noise interference is limited to the initial three tasks. This doesn't adequately assess the impact on each method when the noise occurs at random or during intermediate stages, which would be a more general scenario.\n\n2. The problems in Section 4.2 appear to overlap with those discussed in studies on Concept Drifts in Federated Learning (FL). To emphasize the importance and influence of this research, it would be beneficial to distinguish it from Concept Drifts in Federated Learning, incorporate these into the related works, or conduct additional experiments. Consider citing works such as FEDDRIFT (Jothimurugesan et al., 2022), ADAPTIVEFEDAVG (Canonaco et al., 2021), and Flash (Panchal et al., 2023).\n\n3. AF-FCL allows each client to create a feature space distribution, incorporating information from all clients from the previous round. This potential problem is not found in standard FL methods."
            },
            "questions": {
                "value": "1. In section 5.3, the author claims that \"learning in feature space avoids the danger of leaking raw data through the generative model, thus protecting data privacy\". However, a client could theoretically generate raw data by first using the NF model from the previous FedAvg to generate numerous features, then converting these back to the data space using deconvolution methods with h_a from the last FedAvg.\nEven assuming deconvolution is difficult, AF-FCL still permits each client to generate a feature space distribution, which includes information from all clients in the previous round. This potential problem is not found in standard FL methods.\nIs there a more effective solution to this data privacy concern?\n\n2. The potential for malicious data to emerge during the Federated task is a concern. The proposed AF-FCL appears to \"accurately forget\" prior correct data, an issue not expected with other FCL methods that aim at memorizing everything. The effects are unclear in the following scenarios:\n*    The malicious (falsely labeled) data occurs in the middle of the FL task.\n*    Increased heterogeneity among clients and tasks during the FL task, and comparison of AF-FCL to the baseline.\n\n3. Please provide a more plausible real-world scenario where various classification tasks need to be trained within the same model under Federated Learning (FL). This would illustrate the necessity for \"accurate forgetting\" to manage high levels of heterogeneity. Figure 1 provides a clear example. However, if each hospital has different classification tasks (thorax, brain, liver) that they wish to train together under FL, wouldn't it be more reasonable to conduct them in three separate FL environments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1302/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698999948094,
        "cdate": 1698999948094,
        "tmdate": 1699636057411,
        "mdate": 1699636057411,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1YDMgZqseU",
        "forum": "ShQrnAsbPI",
        "replyto": "ShQrnAsbPI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_pq5J"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1302/Reviewer_pq5J"
        ],
        "content": {
            "summary": {
                "value": "The authors consider the problem of Federated Continual Learning (FCL) in which each client is faced with a sequence of (potentially unrelated) learning tasks. The challenge to be solved is that clients maintain performance across all tasks seen so far while learning in a collaborative fashion s.t. they learn a global model capable of handling all tasks seen by all clients during training.\nA novel method is proposed to tackle a rather general definition of FCL leveraging generative replay with Normalizing Flows (NF), Knowledge Distillation to control feature distribution shift and accurate forgetting which aims to exclude uninformative/harmful samples/features from learning. Experiments were conducted on multiple datasets to show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- the FCL definition used here allows for a broad set of continual learning problems in FL scenarios, including scenarios with unrelated or even contradictory tasks (termed Limtless Task Pool (LTP))\n- the problem is relevant, interesting and well motivated (especially in Sec. 4)\n- the paper is written clearly in general. The problem definition as well as the methodogical contribution is clearly elaborated on\n- it is straightforward to follow through the paper\n- experiments show the effectiveness of the approach and an ablation study gives evidence that the proposed method works well in the presented setting\n- code is available"
            },
            "weaknesses": {
                "value": "# Section 4\nWhile the problem shown in Sec. 4 sufficiently supports the parts of the motivation of the paper, it lacks to clearly support the claim that biases in the data have severe impact on the model performance in FCL. However, related work already indicated that this is the case, making an explicit empirical validation somewhat obsolete. Nevertheless it would be great to have some references to fully cover the claims in this section as well.\n\n# Section 5\n- \"Besides, learning in feature space avoids the danger of leaking raw data through generative model, thus protecting data privacy\". This does not protect privacy if the model is leaked because one could still run e.g. membership inference attacks given the first feature extractor. Without any additional protection mechanism (e.g. differential privacy) privacy guarantees are not given. Please rephrase that part. [1][2]\n\n- \"The invertability ensures a lossless memory of the original input.\" Yes, but it's more the bijective property that allows for a lossless memory since if the transformations were not bijective, one could not reconstruct the output uniquely. Please consider rephrasing.\n\n- regarding Correlation Estimation: does a large distance of encodings in the latent space of the NF  (i.e. low likelihood)  imply that tasks/samples/features are contradictory? I think it does not, although your proposed way to measure this might have a certain level of accuracy since the distance and the extent of being contradictory probably correlate. It would be beneficial to see how strong the correlation between distance of tasks in the latent space and \"harmfulness\" during learning is.\n\n# Section 6\n- although the experiments cover most of the claims in the paper, there are still doubts to which extent the empirical results support the claims: All experiments consider image classification tasks of either the same dataset (split into several tasks) or very related datasets (e.g. MNIST and SVHN). Although in the LTP (using EMNIST) setting tasks are sampled randomly by each client, there still might be a quite high correlation among tasks as images of different letters still may share certain features (e.g. \"b\" and \"p\"). An additional experiment on a more diverse datasaet such as CIFAR-100 in the LTP setting would be beneficial to see.\n\n# Minor points\nPlease be consistent in the notation:\n- in the CL (Sec.3) definition $\\mathcal{T}^i$ and $D^i$ both refer to datasets.\n- when introducing CL and FL in Sec. 3, in the CL definition the indexes change: While in the CL definition $x^t_i$ refers to the $i$-th sample of task $t$, $x^i_k$ refers to the $i$-the sample on the $k$-th client in the FL definition.\n- Eq. 1: the last loss should be $\\mathcal{L}(\\theta^t, \\mathcal{T}^T)$\n\n# References\n[1] Suri et. al. 2022. Subject Membership Inference Attacks in Federated Learning.\n\n[2] Hatamizadeh et. al. 2022. Do Gradient Inversion Attacks Make Federated Learning Unsafe?"
            },
            "questions": {
                "value": "# Section 5\n- Assume a task $T_{t-1}$ has been learned successfully and now a client faces task $T_t$ which is unrelated to $T_{t-1}$ but $T_{t-1}$ is not contradictory to $T_t$, i.e. does not harm learning. Since the tasks are unrealted it is likely that they are far off each other in the latent space of the NF, hence the proposed method would weight down $T_{t-1}$ while learning $T_t$. Forgetting in this case would be harmful in this case. Have you considered such cases in the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1302/Reviewer_pq5J",
                    "ICLR.cc/2024/Conference/Submission1302/Senior_Area_Chairs"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1302/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699020472799,
        "cdate": 1699020472799,
        "tmdate": 1700515243679,
        "mdate": 1700515243679,
        "license": "CC BY 4.0",
        "version": 2
    }
]