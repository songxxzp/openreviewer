[
    {
        "id": "YIFXCXy2AP",
        "forum": "jvveGAbkVx",
        "replyto": "jvveGAbkVx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_7v7y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_7v7y"
        ],
        "content": {
            "summary": {
                "value": "The authors shed light on the challenge of fair classification with the option of abstaining from a prediction. Their objective is to develop a post-hoc fair classification algorithm that meets the following four criteria: 1) the accuracy across groups should be almost as good as the provided classifier, 2) the fairness criteria should be maintained within a prescribed threshold, 3) the feasibility of achieving both the aforementioned accuracy and fairness, given a specified abstention rate, must be ascertainable, and 4) a range of fairness criteria can be applied. The suggested algorithm employs a mixed integer problem solver to determine the best abstentions and label flips that minimize classification errors while simultaneously ensuring the desired levels of accuracy, fairness, and abstention rate. Subsequently, the algorithm constructs a neural network to predict these optimal abstentions and label flips. As theoretical findings, the authors highlight the essential conditions needed for the accuracy, fairness, and abstention rate constraints to be feasible, considering various fairness criteria, including demographic parity, equalized odds, and equal opportunity. Experimental outcomes indicate that the new algorithm maintains fairness without compromising accuracy, a distinction from existing methods, which often trade off one for the other."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is clearly written and easy to understand.\n\n2. The experimental results robustly confirm the improvement of fairness without compromising accuracy, distinguishing the proposed algorithm from existing methods like LTD and FSCS.\n\n3. The theoretical analyses provide insightful results that may elucidate the conditions under which the best classifier with optimal abstention satisfies the requirements. This could potentially characterize the Bayes optimal classifier with abstentions, contributing valuable insights into the trade-off between accuracy and fairness."
            },
            "weaknesses": {
                "value": "1. The method proposed evalates the fairness of the learning classifier using abstained sample. This approach seems impractical in real-world scenarios, where actionable decisions are often needed even for abstained cases. Previous studies, like those of LTD and FSCS, suppose that abstained decisions default to human intervention. Consequently, the fairness of the complete system should encompass both algorithmic and human decisions. Unlike these studies, the proposed algorithm's rationale behind its fairness constraints remains ambiguous. It would benefit readers if the authors presented a real-world scenario validating their algorithm's constraints.\n\n2. Using both an error rate objective function and a no-harm constraint seems redundant as they essentially serve the same purpose.\n\n3. The authors state that their algorithm upholds hard fairness constraints. However, the optimization problem they designed utilizes an approximate fairness constraint. Moreover, the second stage might infringe upon this strict fairness constraint since it merely constructs a function that mimics the labels derived from Stage I.\n\n4. While the fairness requirements of the proposed algorithm differ from those in existing studies (LTD and FSCS), the authors use the evaluation metric of the proposed algorithm's fairness in the experiments. This approach is unfair to the existing methods."
            },
            "questions": {
                "value": "1. Can the authors illustrate a specific scenario in which the constraints of their proposed algorithm are essential?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828700665,
        "cdate": 1698828700665,
        "tmdate": 1699636370888,
        "mdate": 1699636370888,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mgxILohXRo",
        "forum": "jvveGAbkVx",
        "replyto": "jvveGAbkVx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_RYdg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_RYdg"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of training fair classifiers, but also caters to other constraints such as not reducing group-wise accuracy and providing a \"do not predict\" option. The main idea of the paper is to increase the feasibility region of the fair classification problem (and other constraints) by abstaining and flipping predictions. The overall constrained problem is solved by Integer Programming. To use the models on unseen data, the paper trains surrogate models to the Integer Programming solution."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is quite well-written. Most design choices are appropriately motivated. Terminology is clean and easy to understand despite the large number of components involved.\n\n2. The experimental results are encouraging.\n\n3. The paper solves a mix of problems that are all quite useful: fairness, abstaining from making decisions, and not reducing accuracy for groups in the data. All of these components are individually addressed elsewhere in prior work, but putting them all together is a nice contribution."
            },
            "weaknesses": {
                "value": "I think the paper needs to address a couple of points before it is ready for publication:\n\n1. The paper claims to provide hard constraint satisfaction guarantees but does not discuss how these guarantees are supposed to hold when replacing AB and FB modules with surrogate models, and when replacing the true label predictor with a surrogate model. Does the generalization ability of these surrogate models not affect the constraint satisfaction? If yes, how? Or is that the guarantees only hold when assuming Bayers Optimal predictors?\n\n2. On a related note, the paper should provide some discussion into the functional form of the surrogate models. In the appendix, the paper mentions using different Neural Net architectures for different datasets. Is there some guidance on how the architectures should be selected? Should one select the optimal architectures using hyperparameter tuning in isolation (one surrogate model at a time) or should the tuning procedure consider the whole end-to-end Integer Program?\n\n3. Perhaps I missed it, but the paper does not provide information about training cost (e.g., wallclock time). Seeing how the training cost scales with number of data points is essential in judging the effectiveness of the proposed procedure."
            },
            "questions": {
                "value": "1. It would be great to get the answers to points 1-3 in the \"Weaknesses\" section.\n\n2. Is it possible to extend no-harm to individual samples, e.g., the prediction on individual samples should not flip from positive to negative?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699520925906,
        "cdate": 1699520925906,
        "tmdate": 1699636370767,
        "mdate": 1699636370767,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HR4x41xylx",
        "forum": "jvveGAbkVx",
        "replyto": "jvveGAbkVx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_GsZB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_GsZB"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on the problem of selective binary classification under fairness, abstention and harm constraints.  To accommodate for all the constraints the authors propose a framework with two basic components: a mechanism deciding from which instances the classifier should abstain and a mechanism deciding to flip the predictions of the classifier. Using these components the authors first formulate the problem of minimizing the classification error under disparity, abstention rate, and no harm constraints with IP.  Then they propose solving the IP problem for a small dataset and use these solutions to train models on the abstention and flipping component to predict near optimal decisions on unseen data. Finally, the authors deploy their framework on several datasets and compare it with competitive baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The work appears to be the first to consider the problem of selective classification under fairness, abstention rate, and no harm constraints on the same time. The proposed approach seems quite interesting especially for being flexible about the type of fairness constraints that one may impose.  In addition,  achieving fairness guarantees without sacrificing accuracy seems of great importance for real world applications. \n\nThe paper appears very-well structured and nicely written. The authors clearly describe their contributions and sufficiently discuss relation to contemporary literature. Moreover, they present the experimental setup in detail. The experimental evaluation appears thorough and the results seem promising."
            },
            "weaknesses": {
                "value": "Even though the paper is nicely and clearly written, there are a few points that could confuse the reader:\n\nIn the Paragraph \u201cStage I: Integer Programming. We approximate h_A and h_F\u2026\u201d \u201capproximate\u201d is confusing as  $h_A$ and $h_F$  are already defined as binary parameters. \n\nIn the optimization problem in section 3.1 the abstention rate and the no harm constraints are not defined for any $z \\in \\mathcal{Z}$, whereas in the IP-Main these constraints are defined for each $z  \\in \\mathcal{Z}$. If IP-Main is a way to practically solve of the optimization problem in section 3.1, the definitions should be consistent. If there is a reason why these definitions should be different, this reason should be made clear.\n\nIt is not clear what is the motivation for section 4.2. Since in IP-Main one does provide a desired abstention rate constraint for each $z \\in \\mathcal{Z}$ it is not clear what benefit would bring further constraints on the difference on the abstention rates. Especially in the case that the cardinality of $\\mathcal{Z}$ is large, additional pairwise  constraints  for each pair $z,z\u2019 \\in \\mathcal{Z}$ would add significant overhead in solving (3). Also, in (3) $z\u2019$ is not defined.\n\nThe reported results in Figure 3 are over only 5 different runs. One could argue that this is a quite limited evaluation. Given that the results do look promising and the error bars are relatively small, showing results over more runs would strengthen the significance of the results. If there are computational limitations that prevented the authors from evaluating their method for more runs, these should be made clear. The same applies for the results of Table 2. In addition, Table 2 is missing confidence intervals and the type of the error bars in Figure 3 are not  specified.\n\nThe authors should consider adding a (brief) discussion on limitations of their approach and on perspectives for future work.\n\n\n\n Typos/Misc:\n- 1st paragraph in section 2 \u201ci.e.\u201d \u2014> \u201ci.e.,\u201d and \u201ce.g.\u201d \u2014> \u201ce.g.,\u201d\n- 2nd paragraph  \u201cto determine which samples to abstain\u201d is not very clear. Suggestion \u201cto determine from which samples the classifier should abstain\u201d\n- Section 4 first paragraph \u201chyperparameter\u201d \u2014> \u201chyperparameters\u201d \n- Bottom of page 5 \u201cas the models are neural network\u201d \u2014> \u201cas the models are neural networks\u201d\n- Top of page 6 right most column of the Table \u201cTBD in 3.1\u201d do the authors mean \u201cTBD in 4.1\u201d? \n- \u201cAn objection may arise that the model\u2019s excessive abstention from a particular group, while not observed in others.\u201d This seems as an incomplete sentence. What do the authors mean here? \n- Missing \u201c.\u201d In footnote 2.\n- Page 8 top \u201cDO\u201d\u2014> \u201cDP\u201d\n- Conclusion \u201cour abstaining process incur\u201d \u2014> \u201cour abstaining process incurs\u201d"
            },
            "questions": {
                "value": "1. With FB one could use any arbitrary vector of random predictions (not necessarily from a classifier) and learn when to flip then or not. If so why would one need a classifier in the first place?\n2. It is not clear what is the motivation for section 4.2. Since in IP-Main one does provide a desired abstention constraint for each $z \\in \\mathcal{Z}$ why would one would like to further constraint the difference of abstention rate?  \n3. why would one would like to further constraint the difference of abstention rate? Also it is not clear in what sense \u201cthe performance will become worse\u201d. It might more helpful to clarify if the authors mean that the IP problem will be harder to solve or if the solution of the problem will have a higher error rate. Not sure that 4.2 adds much, maybe remove it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Reviewer_GsZB"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699625606293,
        "cdate": 1699625606293,
        "tmdate": 1699636370704,
        "mdate": 1699636370704,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cRGOttX2vV",
        "forum": "jvveGAbkVx",
        "replyto": "jvveGAbkVx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_JZKB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4065/Reviewer_JZKB"
        ],
        "content": {
            "summary": {
                "value": "The paper is considering the problem of enhancing fairness guarantees in model outputs. The specific problem considered is focusing on classification with abstention while increasing group fairness and maintaining model performance. \nThe authors argue that the previous approaches on fair classification or abstention don\u2019t incorporate control over accuracy. They propose a 2-stage procedure to overcome this: (1) Integer Programming stage to generate abstention and flipping outcomes for each data point while maintaining accuracy, (2) Training a surrogate model against outputs of stage 1. They test their approach against two baselines on three real-world fairness datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Paper is well structured and easy to read\n\n2. The problem\u2019s scope and methodology is well defined\n\n3. The proposed method seems motivated; they seem to include the \u201cno-harm\u201d constraint along with giving feasibility conditions for disparity thresholds\n\n4. The method is performant in the tasks considered"
            },
            "weaknesses": {
                "value": "The reviewer is not convinced on the feasibility of the IP and the ability of surrogate to learn the patterns in AB or FB. Not a weakness as such, but would like to see a discussion from the authors."
            },
            "questions": {
                "value": "Could the authors show  the comparative performance on multi-group scenario in case of the Law and Compas datasets with the other baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4065/Reviewer_JZKB"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4065/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699668024798,
        "cdate": 1699668024798,
        "tmdate": 1699668024798,
        "mdate": 1699668024798,
        "license": "CC BY 4.0",
        "version": 2
    }
]