[
    {
        "id": "ZMQAnlB5v8",
        "forum": "gZNB1H5IsQ",
        "replyto": "gZNB1H5IsQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_iPwA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_iPwA"
        ],
        "content": {
            "summary": {
                "value": "The paper studies federated learning with client sampling. The authors consider the setting where we can choose the probabilities with which we want to sample clients and propose a new sampling procedure. Namely, they devise an objective that gives us unbiased estimates of the true regret. While the true regret requires information that we, in general, cannot access, the estimates, do not need it, and one can apply FTRL to the obtained problem to update the probabilities on the fly. The authors then proceed to a non-convex convergence guarantee for FedAvg with unbiased sampling. The last section of the paper is devoted to experiments on a synthetic dataset and FEMNIST."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem of client sampling can have a good impact on the FL literature if there is a significant empirical improvement.\n2. The experiments clearly show an improvement obtained from the method on the problems where it was tested."
            },
            "weaknesses": {
                "value": "1. The theory is based on refining the previous results on the variance of clients and applying regret bounds. While there is nothing wrong with taking this approach, I wouldn't consider this a significant theoretical contribution and, therefore, I'd expect a thorough empirical evaluation.\n2. The authors assume that all gradient norms are bounded. This effectively limits the data heterogeneity too. The claim that gradient clipping can be used to justify the assumption doesn't make much sense to me, since that would effectively change the method and require a different analysis.\n3. The experiments are very limited and restricted to synthetic datasets and FEMNIST with a basic CNN.\n4. It was quite hard for me to read the paper due to numerous typos (a subset of them listed below), inconsistent notation, and missing explanations. Sometimes authors refer to claims from later in the paper as if we've already seen them. Some parts of the proofs were quite unclear to me too (detailed in the Questions section of my review). I think the paper would benefit from a major revision.\n\n## Minor\nIn line 5 of Algorithm 1, why is it $w^t$ and not $x^t$? This notation seems different from eq. (1) and line 9 of Algorithm 1. Similarly, in line 10, it is $w^t$ again  \nIn line 8 of Algorithm 1, in the right-hand side it should be $x^{t,r-1}$  \nIn line 8 of Algorithm 1, I think that $\\xi_i$ should depend on $r$ as well, otherwise it's as if we are using the same sample  \nThe notation $r$ for local iteration is not very good as $r$ typically denotes the round, which the authors denote by $t$  \n\"as we concretely discussed in Appendix E.2\" this sentece seems weird since we haven't seen Appendix E.2  \n\"we are the first work that extends\" -> \"our work is the first to extend\"  \nI can see different spellings of \"K-VIB\", for instance, in the last parargraph on page 2. Please make it consistent.  \n\"To be consistency\" -> \"To be consistent\"  \n\"for simply notation\" -> \"for simplicty of notation\"  \n\"important sampling\" -> \"importance sampling\"  \n\"sampler hat outputs\" -> \"sampler that outputs\"  \n\"Thus, the above theorem would translate into regret guarantees\". There has been no theorem up to that point in the text.  \n\"Assumption 4 are\" -> \"Assumption 4 is\"  \n\"as we shown in Appendix 23\" -> \"as we show in Theorem 23\"  \nand so on..."
            },
            "questions": {
                "value": "1. In the proof of Theorem 8, why does the FTRL bound from Theorem 23 apply? Since in Line 16 of Algorithm 2 we sample $S^t$ according to $\\tilde p^t$ rather than $p^t$, the feedback depends on $\\tilde p^t$, so the whole procedure is not equivalent to FTRL.\n2. In equation (41), the authors use unbiasedness of $\\tilde \\ell_t(p)$.\n3. To apply FTRL regret guarantees, we must first show that the objective satisfies the assumptions of FTRL regret bounds. As far as I can see, objective (8) has unbounded gradients, so why can we apply the FTRL theory?\n4. Why the probabilities given in equation (9) add up to 1? According to line 14 of Algorithm 2, $\\tilde p_i^t = (1 - \\theta) p_i^t + \\theta \\frac{K}{N}\\$ for all $i=1,\\dotsc, N$. As far as I can see, this means if we sum them, we get $\\sum_{i=1}^N \\tilde p_i^t = (1 - \\theta)\\sum_{i=1}^N p_i^t + \\theta \\frac{K}{N}\\cdot N = 1 - \\theta + \\theta K = 1 + \\theta (K - 1)$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4540/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698067730903,
        "cdate": 1698067730903,
        "tmdate": 1699636431374,
        "mdate": 1699636431374,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CuA42xqKBJ",
        "forum": "gZNB1H5IsQ",
        "replyto": "gZNB1H5IsQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_SHAe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_SHAe"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates federated learning with adaptive unbiased client sampling. The authors proposed a K-VIB sampler, which helps the FL algorithm to achieve better regret bound. The authors also proved the convergence of a federated learning algorithm, showing that the minimum of gradient converges to a neighborhood around the origin. Experiments are provided to bolster their theoretical contribution."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors considered minimizing the finite-sum objective, which is a standard but popular topic in FL. The paper is basically well-written. It is easy for readers to go through the paper. \n\nThe statements of theory are clear, with detailed proofs in the appendix. Numerical experiments are thorough, with several graphs to demonstrate the promising performance of the sampler."
            },
            "weaknesses": {
                "value": "Despite the strengths mentioned above, there are several weaknesses in the paper.\n\nWeaknesses in contributions:\n\n1. The theoretical part of the paper is extremely similar to the reference paper, Online Variance Reduction for Stochastic Optimization, by Zal\u00e1n Borsos et al.. In fact, the design of K-VIB is essentially identical to the design of Variance Reducer Bandit (VRB), Algorithm 1 in Borsos's paper. It seems that the only difference is \\sum p_i=1 being replaced by \\sum p_i=K, thus resulting in the extra K-related term in the regret bound.  \\sum p_i=K is also set in other published papers, like Nonconvex Variance Reduced Optimization with Arbitrary Sampling by Samuel Horv\u00e1th and Peter Richt\u00e1rik, so it does not count as a contribution of this paper, either. As for the benefit brought by independent sampling, nothing is mentioned except the smaller upper bound shown in Lemma 2. Therefore, it is hard to judge the advantage of using independent sampling. Therefore, I strongly suggest the authors to mention the benefit of independent sampling in details, it will be appreciated if the authors can compare the results between their paper and other similar papers where random sampling is used. After all, independent sampling is claimed to be one of your contributions.\n\n2. The convergence analysis is flawed. The convergence result shown in the theorem is kind of weird: it is deterministic convergence.\nIn stochastic optimization (like here, where sampling is involved), convergence is usually in expectation, almost surely or with high probability. I don't think that it is possible to obtain a deterministic convergence result in a stochastic optimization algorithm. After all, the LHS of (12) is random, which depends on the samples, thus being different in each run of the algorithm. However, the first term in the RHS is deterministic. I also read the proof of the convergence analysis and found multiple severe errors. To name a few, starting from equation (43), the expectation is a mess. In equation (43), the expectation is taken conditioning on the sigma algebra until x^t (so here it should be a conditional expectation!). There should be only one expectation in the third term of the last line in page 25. Also, there is no need to take the second expectation in the equation (44), since the final result of (44) still depends on x^t. Also, in equation (52), the expectation is also conditional on x^t, so it is ridiculous to see, in equation (52),  the expectation disappears. Because of the omission of the conditional expectation, the authors manage to take average of both sides of (53) over time T. This is wrong, remember, equation (53) is conditional on the sigma algebra until x^t. You can not take summation with different conditions (e.g., x^t,x^{t-1}, etc.). The right step here is to take full expectation on both sides of (53) first, which removes all randomness, and them take summation over T. Only in this way, can you sum up equations for different T! Accordingly, the final result should be changed. What's more, showing the minimum of the norm of the gradient lies a neighborhood around zero is a too weak result. Given the current proof, the result can be strengthened without adding extra assumptions. \n\n3. I am not able to check all proofs in details, so I strongly suggest the authors to go over every line of their proofs carefully. When expectation is taken, it is always a good idea to clarify the condition. \n\n4. When claim that independent sampling is the optimal sampling technique, the reason should be independent sampling minimizes the upper bound of equation (14), instead of independent sampling minimizes the left term of equation (14). So please correct this statement in the appendix, the conclusion above equation (17).\n\nWeakness in assumption:\nThe assumption f(x)\u2212f(y)\\leq F in the 13 is relatively strong. In fact, it can be replaced by f(x)\\geq f_{inf}, that is, f(x) is lower bounded (which is a more standard assumption) without jeopardizing the convergence result. Since what you need in the convergence result is an upper bound in expectation, which can be satisfied if noticing that E(f(x^1)-f_{inf}) is always finite and E(f(x^T)-f_{inf}) is always positive.\n\nWeaknesses in presentations:\nThere are many typos in the paper. To name a few, the local mini-batch SGD step in Algorithm seems to have a wrong superscript, T and R should be inputs of Algorithm 1. If the name of your sampler is K-VIB, please do not write K-Vib. The statement of Assumption 4 is also flawed."
            },
            "questions": {
                "value": "In Algorithm 1, g_i^t is denoted as the local update, but later g_i^t is called the gradient. It is confusing to me. Please clarify it.\n\nWhen analyzing the regret bound, the weight \\lambda_i is set as 1/N. How about general \\lambda_i?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4540/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4540/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4540/Reviewer_SHAe"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4540/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698381896326,
        "cdate": 1698381896326,
        "tmdate": 1699636431227,
        "mdate": 1699636431227,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Wxp3SXYdeD",
        "forum": "gZNB1H5IsQ",
        "replyto": "gZNB1H5IsQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_6zGx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4540/Reviewer_6zGx"
        ],
        "content": {
            "summary": {
                "value": "In this study, the Partial Participation regime in Federated Learning is the primary focus. In this regime, only a subset of all clients can participate in the communication round due to the large number of clients and communication bottleneck. Optimal sampling strategies are under consideration; however, obtaining optimal probabilities requires collecting information from all clients. To relax this condition, the adaptive sampling method, K-Vib, is proposed. Theoretical analysis of the proposed sampler is conducted from an online optimization perspective, leading to the acquisition of convergence guarantees for the FedAvg method with this novel sampling procedure."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I appreciate the writing style of this text. The work demonstrates a solid structure, and the motivation is well articulated. I appreciate that the objective function is presented in a general form. The introduction section includes a well-structured literature review, and I particularly like that the authors have provided additional review material in the appendix section. This approach allows the main ideas to be presented in the primary text while offering supplementary details for reference.\n\nI also commend the authors for highlighting specific modifications of the FedAvg algorithm in the text. However, I recommend avoiding color highlighting, as it can pose difficulties for color-blind individuals. The structured contribution section effectively explains the results.\n\nIt's worth noting that all definitions, lemmas, and theorems are well formulated. I reviewed the appendix, and the proofs appear to be accurate. Nevertheless, I'm not an expert in online optimization, so there might be nuances I've missed.\n\nThe experiments serve to illustrate the theoretical findings, but it might be beneficial to expand and provide a more extensive discussion in this section."
            },
            "weaknesses": {
                "value": "**Abstract**\nIn my view, the abstract is somewhat concise and lacks clarity. There are some confusing phrases that need further explanation:\n>A line of 'free' adaptive client sampling\n\nCould you please provide clarification on the meaning of 'free' in this context?\n\n>Promising sampling probability\n\nThis phrase is also unclear. Could you elaborate on what is meant by \"promising sampling probability\"?\n\n>which solves an online convex optimization respecting client sampling in federated optimization\"\n\nThis sentence is confusing as it's not evident how one can solve \"optimization,\" and the repeated use of the term \"optimization\" in close proximity may lead to misunderstandings. Please provide more context or clarification regarding this statement.\n\n**Introduction**\nThe paper presents a robust literature review. Nevertheless, it lacks coverage of studies that explore cyclic client participation using the random reshuffling method introduced in the following papers. \n\nCho, Y. J., Sharma, P., Joshi, G., Xu, Z., Kale, S., & Zhang, T. (2023). On the convergence of federated averaging with cyclic client participation. arXiv preprint arXiv:2302.03109.\n\nMalinovsky, G., Horv\u00e1th, S., Burlachenko, K., & Richt\u00e1rik, P. (2023). Federated learning with regularized client participation. arXiv preprint arXiv:2302.03662.\n\nAdditionally, it would be beneficial to compare the proposed approach with the method utilizing arbitrary sampling for accelerated Federated Learning, as introduced in the following paper:\n\nGrudzie\u0144, M., Malinovsky, G., & Richt\u00e1rik, P. (2023). Improving Accelerated Federated Learning with Compression and Importance Sampling. arXiv preprint arXiv:2306.03240.\n\nIn the pseudocode of Algorithm 1, the authors have employed object-oriented-style notation, such as \"sample.p\" and \"sample.update.\" This notation can be confusing and appears somewhat incongruous alongside mathematical formulas. I recommend revising the pseudocode for clarity and coherence.\n\n**Preliminaries**\n\n>The second term represents the bias induced by the multiple local SGD steps in federated optimization to save communication (McMahan et al., 2017).\n\nThis bias is called client drift and this tern was introduced the paper and became standard in federated learning. I suggest to also use this term for clarity. \n\nKarimireddy, S. P., Kale, S., Mohri, M., Reddi, S., Stich, S., & Suresh, A. T. (2020, November). Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning (pp. 5132-5143). PMLR.\n\n**Methodology of K-Vib Sampler**\n\n>Assumption 4 (Lipschitz gradient). Each objective $f_i(x)$ for all $i \\in[N]$ is G-Lipschitz, inducing that for all $\\forall x, y \\in \\mathbb{R}^d$, it holds $\\left\\|\\nabla f_i(y)\\right\\| \\leq G$.\n\nIt is unclear why this assumption is termed \"Lipschitz gradient\" since it necessitates the objective functions to be Lipschitz, which implies that the gradient is bounded, but not Lipschitz. Could you please clarify this aspect?\n\n>Assumption 5 (Local convergence).\n\nCould you please provide further elaboration on this assumption, along with examples to illustrate how it applies to specific cases?\n\n>Besides, the Lipschitz gradient also can be justified by using gradient clipping during the practical optimization of deep learning models to prevent exploding gradients and guarantee differential privacy (Kairouz et al., 2021). \n\nWhile clipping can ensure that the assumption of bounded gradients is met, it's important to note that the clipping operator is not included in the proposed algorithm. Therefore, I believe this argument does not apply in this context.\n\n>Assumption 9 (Smothness). Each objective $f_i(x)$ for all $i \\in[N]$ is $L$-smooth, inducing that for all $\\forall x, y \\in \\mathbb{R}^d$, it holds $\\left\\Vert\\nabla f_i(x)-\\nabla f_i(y)\\right\\Vert \\leq L\\Vert x-y\\Vert$.\n\nI can recommend to consider more general assumption with personalized constants $L_i$: $\\left\\Vert\\nabla f_i(x)-\\nabla f_i(y)\\right\\Vert \\leq L_i\\Vert x-y\\Vert$\n\n>Assumption 11 (Bounded Global Variance). We assume the weight-averaged global variance is bounded, i.e., $\\sum_{i=1}^N \\lambda_i\\left\\Vert\\nabla f_i(x)-\\nabla f(x)\\right\\Vert^2 \\leq \\sigma_g^2$ for all $x \\in \\mathbb{R}^d$.\n\nThe current inequality employs a universal constant for the bound, which is limiting in its generality. I recommend adopting a more general assumption where the heterogeneity bound is proportional to $\\Vert x \\Vert$ and a certain constant:\n\n$ \\sum_{i =1}^{N} \\lambda_i \\left\\Vert\\nabla f_i(x)-\\nabla f(x)\\right\\Vert^2 \\leq B\\Vert\\nabla f(x)\\Vert^2+\\zeta^2 \\quad \\forall x \\in \\mathbb{R}^d$\n\nSuch assumption is used in the following papers:\n\nGorbunov, E., Horv\u00e1th, S., Richt\u00e1rik, P., & Gidel, G. (2022). Variance reduction is an antidote to byzantines: Better rates, weaker assumptions and communication compression as a cherry on the top. arXiv preprint arXiv:2206.00529.\n\nKarimireddy, S. P., Kale, S., Mohri, M., Reddi, S., Stich, S., & Suresh, A. T. (2020, November). Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning (pp. 5132-5143). PMLR.\n\n**Experiments** \n\nThe current plots are relatively small, making it challenging to discern the behaviors of the methods, particularly in the middle plot of Figure 4. Additionally, the current plots do not employ distinct markers, which poses difficulties for individuals with color blindness. Could you please adjust the plots accordingly?"
            },
            "questions": {
                "value": "Please check questions in the Weaknesses section. \n\nI would also like to inquire if it is possible to obtain convergence guarantees for both strongly convex and general convex cases or if results can be derived for non-convex functions that satisfy the Polyak-Lojasiewicz condition.\n\nIn general, I find this work to be acceptable; however, there are some clarity issues and a lack of convex analysis that concern me. I would be willing to consider raising the score if these issues are addressed. My current score is 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4540/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699049057893,
        "cdate": 1699049057893,
        "tmdate": 1699636431120,
        "mdate": 1699636431120,
        "license": "CC BY 4.0",
        "version": 2
    }
]