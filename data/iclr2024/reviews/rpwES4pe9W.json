[
    {
        "id": "kTFn0FgdDo",
        "forum": "rpwES4pe9W",
        "replyto": "rpwES4pe9W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_CJze"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_CJze"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method called refined tensorial radiance fields that combines coordinate-based networks and multi-plane encoding for novel view synthesis from sparse inputs. The propose method utilizes the propoties of coordinate-based networks to capture the low-freqency signals of the scene, and employs multi-plane encoding to focus on the high-frequency details. A curriculum training scheme is also proposed to progressively adjusts the weights of multi-plane features to prevent overfitting.\nThe paper conducts experiment on both static and dynamic NeRF datasets with sparse inputs. The proposed method outperforms the baselines in terms of PSNR, SSIM, and LPIPS metrics. Experiments also demonstrate the robustness and stability of the proposed method across different scenes and regularization values."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:\n- Overall idea is simple and easy to understand. Writting is overall clear.\n- Enough information is provided for reproduce. Code is also provided as supplemental materials to improve reproducibility.\n- Dense ablation studies are provided in the paper and supplemental materials."
            },
            "weaknesses": {
                "value": "- This paper looks like a technical report more than a technical paper. The key insight I read from this paper is that \"the coordinate-based features are responsible for capturing global context, while the multiple-plane features are responsible for capturing fine-grained details.\". Yet there lacks further explanation and in-depth discussions related to this insight. Specifically, it is well known for NeRF that coordinate input itself struggles at fitting high-frequency details, and thus freq-based positional encoding and its variants [1, 2, 3] has been proposed to resolve this problem. Specifically, in [1] there are discussions and analysis (from NTK perspective) that coordinate input with Fourier representations is able to (1) learn high-freq details and (2) with some progressive learning strategy it is able to learning the frequency space in a coarse-to-fine manner. More technical (or theoretical) discussions regarding the coordinate input and its frequency behavior would make this paper far more interesting.\n\n- Including coordinate inputs inevitably increase the computational cost, as each coordinate has to go through a (usually larger) MLP network instead of grid sampling and small MLP feed-forward as multi-plane feature input. In fact, one key motivation of multi-plane methods is decreasing the training and rendering time required. The paper seems not include any information and discussions regarding training time, computation cost, FPS, etc., which makes comparisons to multi-plane based methods incomplete.\n\n[1] Tancik, Matthew, et al. \"Fourier features let networks learn high frequency functions in low dimensional domains.\" Advances in Neural Information Processing Systems 33 (2020): 7537-7547.\n\n[2] Barron, Jonathan T., et al. \"Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n\n[3] Barron, Jonathan T., et al. \"Mip-nerf 360: Unbounded anti-aliased neural radiance fields.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "- Regarding the coordinate input: What kind of positional encoding is used?\n- Regarding the results (especially for supp. video): How many input views used for objects shown in supp. video? It seems improvements over HexPlane on Dynamic NeRFs are subtle - there are still strong ghost artifacts between frames and the rendered image is noisy."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Reviewer_CJze"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697865154686,
        "cdate": 1697865154686,
        "tmdate": 1699636938706,
        "mdate": 1699636938706,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Rz7HBTKMVN",
        "forum": "rpwES4pe9W",
        "replyto": "rpwES4pe9W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_YmuZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_YmuZ"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a simple but effective improvement for NeRF from sparse inputs, which combines multi-plane encoding with coordinate-based networks. Specifically, the coordinate-based network captures low-frequency structure and the multi-plane encoding is used to model the high-frequency details of the reconstruction. Experimental results justify the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed idea is easy to understand.\n- The results are good and look visually-pleasing."
            },
            "weaknesses": {
                "value": "- The technical novelty is limited. Specifically, the proposed method is a simple combination of multi-plane encoding with coordinate-based networks, both of which are from previous methods, i.e., HexPlane and the original NeRF. The curriculum weighting strategy is more similar to a training trick. Few new technologies were proposed.\n- It would be better to put the results side by side in the supplementary video to facilitate comparison."
            },
            "questions": {
                "value": "Please see weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698500326551,
        "cdate": 1698500326551,
        "tmdate": 1699636938599,
        "mdate": 1699636938599,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RLn3KwkYAk",
        "forum": "rpwES4pe9W",
        "replyto": "rpwES4pe9W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_D6bb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_D6bb"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to use a hybrid of coordinates and multi-plane features for novel view synthesis from sparse inputs. The paper finds that coordinate-based network is better for capturing global context while the multi-plane features are better for fine-grained details. Therefore, the paper also proposes a curriculum training scheme for coarse-to-fine training. The coordinate network is first trained to learn global context, which provides a good initialization especially in the case of dynamic motion and sparse inputs. Then the multi-plane features are activated and increasingly weighted in accordance with the training iterations. Experiments show that the proposed method outperforms dynamic NeRFs using sparse inputs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper provides enough literature review and backgrounds.\n- The paper proposes some effective techniques to improve the existing nerf model. The idea of using the hybrid of coordinate network (for global context) and multi-plane features (for details) seems reasonable to me, especially from the view of optimization. To better train the model, the author also provides a curriculum training scheme. The paper provides experiments to validate the idea.\n- Codes are provided."
            },
            "weaknesses": {
                "value": "- The main concern for the paper is the limited novelty. Although the paper does provide some effective techniques, the majority part of the design heavily relies on several existing methods, such as the multi-plane features and the Laplacian smoothness. The combination of the existing two popular design (coordinate network and multi-plane features) seems direct and straight-forward to me. For me, the contribution of this paper is mainly technical (but still limited). It would be better if any theoretical explanation is provided.\n- Some parts of the paper are not clear and some experiments might be needed (see Questions)."
            },
            "questions": {
                "value": "- \"The key difference is a channel-wise weighting function for multi-plane features\": are there any quantitative ablation studies on the training scheme?\n- Figure 3 is quite confusing, which is inconsistent with Figure 4. In Figure 3, is the coarse rendering image just for illustration or is it indeed generated as intermediate output?. What does the MLP and Residual MLP correspond to in Figure 4?\n- Equation (3): the two conditions seem overlapped.\n- What is the run time of the proposed method compared to baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Reviewer_D6bb"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818124290,
        "cdate": 1698818124290,
        "tmdate": 1699636938493,
        "mdate": 1699636938493,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "w7djUFDCiO",
        "forum": "rpwES4pe9W",
        "replyto": "rpwES4pe9W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_r4Vs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7703/Reviewer_r4Vs"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new approach for novel view synthesis from sparse input images with neural field representations. Based on  the existing work \"TensorRF\", this paper extends the representation with an additional coordinate-based network that should capture global context. Furthermore, the authors propose a progressive weighting scheme for enabling low-frequency modeling with the coordinate-based network and fine-grained details with a triplane representation. \nThe authors conduct experiments on static and dynamic scenes and compare them to various baseline methods such as TensoRF, INGP, FreeNeRF, HexPlane and more."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well written and the method is explained in detail.\nThe visuals in paper are very pleasing and help to understand the method, especially Figure 2 and 3. \nRelated work is well covered.\nVarious baseline methods are used."
            },
            "weaknesses": {
                "value": "1) In my view, the related work section misses concrete details on the relation of existing works to the proposed paper, e.g. in the \u201cNeRFs in the sparse inputs\u201d paragraph it stays unclear which of the mentioned limitations is resolved with the proposed method. Please provide more discussion here.\n\n2) A major limitation of the experimental evaluation is that there is no discussion of training time and overall model size/ number of parameters. A major contribution of previous works (TensoRF and iNGP) is the extremely fast training time (TensoRF ~10min) and model compactness which mainly comes from the fact that only shallow MLPs are used. I\u2019m wondering how the proposed approach performs in training time and model size.\n\n3) It would be great to have experiments on more realistic data, e.g. for the dynamic case there is the  Plenoptic Video dataset used in the HexPlane paper.\n\n4) The contribution is rather limited to extended architecture, additional loss function and a weighting strategy. Even though numbers improve, the technical novelty on top of existing work, e.g. Hexplanes and TensorRF is minor and it remains unclear if it is even worse in terms of training time and model size."
            },
            "questions": {
                "value": "It would be great to hear the authors opinion on the weaknesses 2) about the training time and model size. Can you provide numbers for the training time in comparison to the baselines on both tasks?\n\nPlease follow up on 1) to get a more concrete idea how the author's works position in this field."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7703/Reviewer_r4Vs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834959862,
        "cdate": 1698834959862,
        "tmdate": 1699636938399,
        "mdate": 1699636938399,
        "license": "CC BY 4.0",
        "version": 2
    }
]