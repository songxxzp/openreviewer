[
    {
        "id": "BXa90ADyFW",
        "forum": "bDWXhzZT40",
        "replyto": "bDWXhzZT40",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_1jLE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_1jLE"
        ],
        "content": {
            "summary": {
                "value": "The authors propose ReVar technique for predicting model uncertainty at train and test time. In particular, ReVar is notable for aiming to capture various different sources of uncertainty, including covariance shift and high label noise. ReVar uses bi-level optimization to learn both a primary model f(x) and auxiliary uncertainty model g(x), which serves as an instance-dependent weight function for training data and an uncertainty score. The technique is evaluated favorably against prior works, both on synthetic data and on real datasets for many tasks including calibration, data with label noise and selective classification."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The general premise of an all-purpose uncertainty evaluation tool, useful for both train and test time and adaptive to various sources of uncertainty, is a significant and original contribution that would be very useful\n- The evaluation against prior works on a variety of uncertainty-related tasks is very comprehensive\n- In section 4, the classifications into types 1-3 uncertainty and discussion of how instance weights should respond to these types was a useful step towards putting these different uncertainty problems under one theoretical framework"
            },
            "weaknesses": {
                "value": "- Section 4's work with synthetic data has good potential to be interesting and illustrative of how ReVaR works differently in desired ways for different uncertainty types. However, I found it unclear how the \"theoretical ideal for the instance dependent weights\" listed in table 1 were determined. Some more information on their derivation might be helpful.\n- Occasional minor notational things: Equation 3, definition of $\\theta^*$, should $g_\\Theta$ might instead be $g_{\\Theta^*}$. The text following/explaining equation 6 introduces variables not used in equation 6; some minor rewriting could be useful here. Missing reference to a theory in section 4, scenario 1."
            },
            "questions": {
                "value": "- How were the targets in table 1 derived; why are these targets desirable?\n- In distribution shift settings where we assume access to a validation set from the test distribution, is it not better sometimes to just fine-tune on the validation set (or a portion of it)? It could potentially be a good baseline comparison."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Reviewer_1jLE",
                    "ICLR.cc/2024/Conference/Submission9383/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9383/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698201333373,
        "cdate": 1698201333373,
        "tmdate": 1700417489148,
        "mdate": 1700417489148,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YOWwslT66t",
        "forum": "bDWXhzZT40",
        "replyto": "bDWXhzZT40",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_f1Z8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_f1Z8"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method which learns a weighting function for the cross entropy loss, enabling re-weighting of the terms depending on how difficult (in an uncertainty sense) they are to classify. The method is learnt through a bi-level optimisation process, which is not dissimilar from a 'meta' training objective. The authors demonstrate their results on several datasets using ResNet-50 architectures."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strengths of this paper are it's:\n* Simplicity, the method seems very easy to implement and is intuitive to understand.\n* The experiments are reasonably conclusive and operate on a significant number of datasets."
            },
            "weaknesses": {
                "value": "In terms of weaknesses:\n* The paper seems quite rough, there are many undefined terms and functions ($R^2$, $g(x)$, $G$), missing citations (MMCE), lack of error bars in Table 4 - 7, etc.\n* With a paper being set up the way it has, I would expect some proof, especially with the synthetic setup in Section 4\n* Moreover, I'm not entirely convinced on why this method works, my understanding is that you are simply training the network to produce low variance in its predictions, which is manifested by the network essential learning dirac distributions over the parameters in dropout. It would be nice to see some investigation into this, or at least an explanation.\n* Only performed on ResNet, there are many models available now which can be trained just as easily with similar compute."
            },
            "questions": {
                "value": "* What is the definition of $g(x)$? And how does this relate to $\\theta$. I couldn't find this information when it was introduced, which made this paper very hard to grasp what was happening.\n* How do $w_i$ and $\\Theta$ relate?\n* What is the theory in Scenario 1?\n* What are the associated issues with this approach? I understand the objective of minimising uncertainty, but minimising the metric which provides the uncertainty is not the same thing. I'm concerned that all this is doing is simply collapsing the dropout distribution to all become the same parameters, i.e. it makes no difference on the prediction which parameters are selected. \n\n\nWhilst I think there is some contribution in this paper, I just don't think in it's current form it's ready for publication. I would suggest that the authors improve:\n* The quality of the paper to make it easier to understand what the method is, i.e. define $g(x)$ properly\n* A proof would strengthen the paper significantly. If you can prove why minimising the variance provides improved uncertainty you're onto a winner.\n* Add more architectures, using only ResNet-50 is not enough.\n* I would also suggest removing the empirical evaluation on the top set up. If you have a toy set up like this, it should turn into a proof."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Reviewer_f1Z8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9383/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742819957,
        "cdate": 1698742819957,
        "tmdate": 1700653360017,
        "mdate": 1700653360017,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eqXGBIkC31",
        "forum": "bDWXhzZT40",
        "replyto": "bDWXhzZT40",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_bRmp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9383/Reviewer_bRmp"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose an instance weighting methodology based on an auxiliary network that quantifies the uncertainty of the predictor subject to learning. More precisely, a bilevel optimization formulation enables one to simultaneously learn the predictor and the auxiliary uncertainty quantifier, whereas a meta-level loss enforces to reduce the predictor\u2019s uncertainty by minimizing a variational approximation of Bayesian Neural Networks by means of multiple inference passes employing Dropout regularizations. As the authors show, the method proves to be an effective means to achieve a more uncertainty-aware, and consequently better generalizing predictors."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Strong empirical evidence of the reasonability of the method. Also, the experiments are at an impressive scale, supporting the claims of the work.\n- Rich set of recent baselines considered in the experiments, fair comparisons.\n- I really like that this method allows for augmenting previous robust approaches, e.g., PLEX, with the proposed solution. That significantly boosts its applicability.\n- Computational efficiency concerns are thoroughly addressed in the appendix."
            },
            "weaknesses": {
                "value": "Major:\n\n- The contribution and distinctions to previous works (which e.g. also use a bilevel optimization formulation for reweighting) should be made more clear in the thread of Section 3. Often, it does not become clear when something is new in the course of the ReVaR proposal, and when previous works are revisited.\n- Many grammatical and orthographic issues, e.g., missing articles (\u201c*the* dataset\u201d \u2192 motivational questions in Section 1), misplaced words (\u201ccaptures captures\u201d \u2192 beginning of Section 5), \u2026\n- Section 4 is very hard to read, some design choices also appear arbitrary. For instance, intuitively, what is the role of $X_c$, $X_e$, $W_c$ and $W_e$, and why are the dimensionalities chosen as described in the paper? Elaborating more on the setup would help to better understand the settings and allow for estimating the significance of these results.\n\nMinor:\n\n- Sometimes unclear / inconsistent notation, e.g., \u201cp=w=g(x)\u201d in  Section 1.1, also see my previous comment on $X_c$, $X_e$, $W_c$ and $W_e$.\n- As far as I can see, there is no code served along with the paper, which does not support the reproducibility of this work.\n- Section 4, Scenario 1: \u201e?\u201c Broken reference\n- Details about the U-score model architecture appear in the appendix only \u2013 as this is not as trivial as \u201cnormal\u201d predictors, this should be already hinted at in the main paper."
            },
            "questions": {
                "value": "1. While Section 4 gives a comprehensive overview of different forms of captured uncertainties in $g_\\theta$, I would be also interested in seeing concrete learning behaviors of $g$ in the real-world experiments. Perhaps the authors could augment the results by showing patterns of $g$ in this regime, e.g., by plotting the distributions of the learned weights, and how these evolve over the training. Right now, it is hard to get an impression about the learning dynamics, raising the following questions: Does the novel meta loss slow down the training by making it more cautious, or does it even accelerate the training? Note that I am not referring here to what has been discussed in E.3, but with the focus on learning curves. For instance, setting the maximum number of epochs / data points to control training costs is often a critical consideration in real-world application at larger scales.\n2. Could the U-SCORE and predictor weights be shared? How would this affect the training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9383/Reviewer_bRmp"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9383/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699636798485,
        "cdate": 1699636798485,
        "tmdate": 1699637183195,
        "mdate": 1699637183195,
        "license": "CC BY 4.0",
        "version": 2
    }
]