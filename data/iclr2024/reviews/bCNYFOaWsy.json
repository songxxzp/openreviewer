[
    {
        "id": "NzXPM2KShT",
        "forum": "bCNYFOaWsy",
        "replyto": "bCNYFOaWsy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_ndZy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_ndZy"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of class imbalance in node classification tasks. Authors introduces ToBE (Topological Balanced augmEntation), a model-agnostic technique. The essence of ToBE is dynamic topological augmentation to identify and rectify nodes that are critically influenced by the identified challenges. Results shows promising improvements including reducing bias and enhancing performance in class-imbalanced node classification, outperforming traditional CR techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Instead of the conventional class-rebalancing methods, the paper provides a topological viewpoint to address the issue.\n\n2. The paper offers a theoretical understanding of the disparities in graph topology between majority and minority classes, leading to a deeper comprehension of the root causes of the problem.\n\n3. ToBE is model-agnostic and efficient, and can be easily integrated with other existing techniques.\n\n4. Experiments validate the efficacy of ToBE, showcasing its superiority in terms of performance, robustness, and versatility."
            },
            "weaknesses": {
                "value": "1. The augmentation method introduced in this paper could potentially escalate the computational complexity, presenting challenges for deployment in large-scale scenarios. It might be beneficial to either highlight this as a potential limitation or to delve into a theoretical analysis addressing its implications in expansive applications.\n\n2. As with any data modification technique, augmentation inherently brings the risk of overfitting. It's crucial to recognize this aspect and perhaps consider empirical evaluations or additional experiments to shed light on this concern, suggesting possible mitigation strategies.\n\n3. The manuscript remains silent on the performance of the proposed methodology in multi-class classification environments, as well as its adaptability to tasks other than node classification. Exploring these facets could provide a more comprehensive view of its applicability.\n\n4. While the topological strategy presented is innovative, it seems particularly designed for graph-centric challenges. This specialized focus might limit its direct utility in varied domains, and acknowledging this could provide a more grounded perspective."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3061/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3061/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3061/Reviewer_ndZy"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3061/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698475475417,
        "cdate": 1698475475417,
        "tmdate": 1699636251490,
        "mdate": 1699636251490,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TPSR9hyrgl",
        "forum": "bCNYFOaWsy",
        "replyto": "bCNYFOaWsy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_UMPW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_UMPW"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the problem of class imbalance graph learning. It first revisits several remaining issues of existing methods. Then, from an orthogonal topological paradigm, they theoretically find two fundamental reasons. After that, they propose a lightweight topological augmentation framework called TOBE to mitigate the class-imbalance bias without class rebalancing. Finally, it conducts some experiments to evaluate the proposed method, showing that that TOBE can sometime outperform state-of-the-art baselines on several tasks across multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1.\tThe authors provide their codes.\n2.\tIt provides some theoretical support for the proposed model.\n3.\tIt tests on several widely-used datasets, and the proposed method can sometimes beat the existing methods."
            },
            "weaknesses": {
                "value": "1.\tThe proposed method seems to be meaningless at times. As shown in Table, sometimes the original methods (such as APPNP and GPRGNN) can beat either +ToBE0 or + ToBE1. More over, as shown in Tables 7 and 8, lots of baselines (Vanilla, Reweight, ReNode, and GSMOTE) can sometimes beat either +ToBE0 or + ToBE1.\n2.\tSome grammatical errors, like 1) groundtruth labels \u2013> \u201cground-truth\u201d; 2) Coauthor networks-> \u201cco-author\u201d; and 3) \u201cFig. 5 compares\u201d \uf0e0 \u201cFigure\u201d."
            },
            "questions": {
                "value": "1.\tAs shown in Tables 7 and 8, why lots of baselines can sometimes beat both ToBE0 and ToBE1? As such, why the proposed method is useful?\n2.\tAs we can see, the performance of ToBE0 and ToBE1 are unpredictable. So that, how to decide which one should be used for a given method or setting?\n3.\t\u201cSimilar analysis can extend to k \u2265 3.\u201d --- have you ever proved this?\n4.\tIn Table 3, why the \u201cNode\u201d column only has one type of results?\n5.\tSee the weakness in the \u201c*Weaknesses\u201d part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3061/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698657049564,
        "cdate": 1698657049564,
        "tmdate": 1699636251414,
        "mdate": 1699636251414,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ztb33sGsMe",
        "forum": "bCNYFOaWsy",
        "replyto": "bCNYFOaWsy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_grPF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_grPF"
        ],
        "content": {
            "summary": {
                "value": "The study introduces a post-processing module for semi-supervised vertex classification models in the presence of class imbalance. The module aims to mitigate prediction errors and biases caused by class imbalance by incorporating virtual vertices and establishing connections with original vertices exhibiting high prediction errors or low confidence (referred to as high-risk vertices in the paper). Through long-range message propagation, the proposed approach effectively addresses the challenges posed by class imbalance in semi-supervised vertex classification tasks. Experimental results demonstrate its relative improvement over existing models under real-world scenarios characterized by class imbalance."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "S1. Formulas that accurately describe the AMP and DMP problems were derived, providing precise definitions for these problems.\n\nS2. Extensive experiments consistently show that the proposed post-processing module significantly enhances the learning effectiveness of the current model across multiple metrics and base models.\n\nS3. The writing style is smooth and coherent."
            },
            "weaknesses": {
                "value": "W1. The lack of comparison with other post-processing modules for class imbalance graph learning, such as the classical Residual Propagation method, undermines the persuasiveness of the proposed method's effectiveness. \n\nW2. The study lacks a comparison between the proposed method and the predictive performance of the base model on balanced data, which diminishes its persuasiveness.\n\nW3. The absence of a comparison with the predictions of the base model on balanced data weakens the persuasiveness of the results.\n\nW4. The use of \"relative improvement rate\" may not be the most comprehensive measure to evaluate the model's performance, as some base models may inherently perform poorly in addressing highly imbalanced class semi-supervised vertex classification tasks.\n\nW5. The details of how this module collaborates with other base models are not adequately explained, lacking formulas and clear visual representations.\n\nW6. The study's focus is not novel, and the problem scope is narrow. The proposed method has the potential for broader applications, such as imbalanced edge prediction, and should also consider the module's inductive capabilities. Otherwise, solely emphasizing the relative improvement of the existing model's transductive ability may not hold significant practical significance."
            },
            "questions": {
                "value": "Similar to what was mentioned in the weaknesses:\n\nQ1. How does the effectiveness of this module compare to post-processing modules of other class imbalance graph learning methods?\n\nQ2. How does the performance of this module compare to the base model combined with data balancing during prediction?\n\nQ3. What are the specific formulas and graphical representations illustrating the collaboration between this module and the base model?  Can it be independently developed as a foundational model rather than a post-processing module?\n\nQ4. Can this module be applied to other tasks and demonstrate effectiveness? How does it perform in terms of inductive capabilities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3061/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3061/Reviewer_grPF",
                    "ICLR.cc/2024/Conference/Submission3061/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3061/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805642649,
        "cdate": 1698805642649,
        "tmdate": 1700667566981,
        "mdate": 1700667566981,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6jDWch1olY",
        "forum": "bCNYFOaWsy",
        "replyto": "bCNYFOaWsy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_4g56"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3061/Reviewer_4g56"
        ],
        "content": {
            "summary": {
                "value": "This study delves into the challenge of imbalanced node classification on graphs. The authors explore two phenomena in the underlying graph topology that intensify predictive bias due to class imbalance, both theoretically and empirically. They introduce a model called ToBE, designed to alleviate class-imbalance bias without the need for class rebalancing. Through experiments conducted on various datasets, the effectiveness of the proposed model is demonstrated."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Class imbalance is an important issue in the field of graph imbalance learning, which requires deep investigation."
            },
            "weaknesses": {
                "value": "1. The AMP and DMP phenomena are studied in many previous works. The AMP is basically the heterophily issue studied in previous heterophily GNN and graph anomaly detection literature. The DMP is basically the information insuf\ufb01cient issue studied in previous topology imbalance literature.\n\n2. I find the theoretical analysis has nothing to do with the model design. In the theoretical analysis, this work only analyzes the relation between the imbalance ratio and the severity of AMP and DMP. However, in the model design, this work directly uses model prediction uncertainty to estimate nodes\u2019 risk of being misclassified and simply claims that this risk of being misclassified is due to AMP/DMP, which is not verified in the theoretical part. From my view, there is not any relationship between these two parts. Even without the theoretical part, the model design part looks self-contained.\n\n3. In the model design, this work claims that, for high-risk nodes, the most possible prediction is unreliable, and instead uses the second possible prediction as the estimated label. Why choose the second possible prediction? Why not the third possible? As this part is critical to model performance, I would expect authors to further clarify this.\n\n4. In Figure 2(b), it seems that there is still a large discrepancy between the performance of the minority class and the majority class, even if the AMP/DMP score is the same. That indicates that there are some other factors that influence the performance discrepancy. I would expect the authors to further clarify this.\n\n5. The existing baselines lack comprehensiveness, and there is a lack of thorough comparison with recent approaches, such as [1, 2, 3, 4, 5].\n\n[1] Imgcl: Revisiting graph contrastive learning on imbalanced node classification. AAAI 2023\n\n[2] Balanced neighbor exploration for semi-supervised node classification on imbalanced graph data. Information Sciences 2023\n\n[3] Graphmixup: Improving class-imbalanced node classification by reinforcement mixup and self-supervised context prediction. ECML-PKDD 2022\n\n[4] Imbalanced node classification beyond homophilic assumption. IJCAI 2023\n\n[5] Tam: Topology-aware margin loss for class-imbalanced node classification. ICML 2022"
            },
            "questions": {
                "value": "Please see the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3061/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699522923822,
        "cdate": 1699522923822,
        "tmdate": 1699636251193,
        "mdate": 1699636251193,
        "license": "CC BY 4.0",
        "version": 2
    }
]