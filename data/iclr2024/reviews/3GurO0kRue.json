[
    {
        "id": "XaDa2ExHq3",
        "forum": "3GurO0kRue",
        "replyto": "3GurO0kRue",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_Dvju"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_Dvju"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an approach (SHE) to learning a classifier that performs well for a set of latent subpopulations that are not uniformly represented in the training data. The approach is to learn subpopulation structure through an \u201coptimal data partition\u201d with maximal conditional entropy of the label given the learned subpopulations, effectively identifying subpopulations with balanced label distributions. Evaluation is conducted with respect to a balanced marginal distribution over the subpopulations. An extensive empirical evaluation is conducted using the COCO, CIFAR-100, and ImageNet datasets. The experiments involve comparisons to alternative approaches and ablation studies."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The presentation of the toy example in Figure 2 is clear and compelling for motivating the problem.\n* The theoretical analysis in section 3 is sound (to the best of my knowledge) and the method straightforward to implement.\n* The empirical evaluation is extensive, with comparisons to several baseline approaches in several settings, including on computer vision datasets that have been variably rebalanced, and in the context of fine-tuning large multimodal foundation models."
            },
            "weaknesses": {
                "value": "* The paper is challenging to read, and borders on unreadable at times, due to numerous grammatical errors and unusual choices of terminology, particularly in the abstract and the first two sections. As a reader, I was not able to understand the problem that this paper aims to solve until reviewing the mathematical presentation in section 3. While I like this paper overall, this is enough for me to argue that this paper should not be published without substantial revision.\n* It is not clear how model complexity and finite-sample considerations interact with the core arguments of the work. For example, the toy example in Figure 2 relies on the use of a linear model for the ERM and subpopulation-specific models. However, a more complex, non-linear ERM model could still, in-principle, fit the data well, even if it might not due to data insufficiency for the underrepresented subpopulations. It\u2019s not obvious how this consideration surfaces in the theoretical presentation nor in the experiments."
            },
            "questions": {
                "value": "* How does SHE compare to baselines in-domain, i.e., in cases when both the training and testing data are imbalanced? If I understand correctly, the claim of Proposition 3.2 is that SHE should not underperform ERM (in the limit) but it seems that this is not evaluated in the experiments because of the focus on balanced test distributions.\n* SHE is motivated to address a particular distribution shift problem where there is subpopulation shift over a set of subpopulations with balanced label distributions. How would SHE perform under other notions of subpopulation shift, where it is not assumed that the label distributions are balanced within subpopulations?\n* Could SHE be extended to handle an arbitrary specified target distribution over the latent subpopulation? Would this be as simple as weighting the subpopulation components of the LogSumExp operation?\n* Is there a reason why the model-based $V$ variant of SHE could not depend on both $X$ and $Y$? My interpretation of the method was that $V$ is not used at test time, so this might allow for a scalable model-based subpopulation mapping that matches the performance of the full $N$x$K$ matrix."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Reviewer_Dvju",
                    "ICLR.cc/2024/Conference/Submission5154/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698448533170,
        "cdate": 1698448533170,
        "tmdate": 1700682162823,
        "mdate": 1700682162823,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FpqSsZYuNA",
        "forum": "3GurO0kRue",
        "replyto": "3GurO0kRue",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_FihB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_FihB"
        ],
        "content": {
            "summary": {
                "value": "The paper studied the subpopulation imbalance problem in machine learning. The setting can be described as follows: let the dataset being consist of groups $S$, and under uniform sampling, the probability $\\Pr(S=s)$ varies for different realizations of $s$. If the functions $f_s: \\mathcal{X}\\rightarrow \\mathcal{Y}$ are quite different across different groups, the machine learning algorithm that assumes a uniform $f$ would overlook the groups that contain a small number of samples. \n\nTo overcome the issue, the paper proposed a method to incorporate the subpopulation annotation in the loss function. In particular, the paper proposed the information-theoretic objective to maximize the term of $I(X;Y| v(X,Y))-I(X;Y)$, where $v(X, Y)$ is the random variable for the subpopulation annotation. To learn the optimal partition function that minimizes the term, the paper used the \u2018empirical\u2019 version of the entropy terms as the loss function, and proved that the term convergence with an additive error of $O(1/\\sqrt{N})$ to the actual information \u2018\u2019gain\u2019\u2019 $I(X;Y| v(X,Y))$. Therefore, if we minimize the objective, we are essentially maximizing $I(X;Y| v(X,Y))-I(X;Y)$ given that the joint distribution of $(X,Y)$ is fixed. \n\nThe paper then conducted experiments on several real-world datasets to compare the proposed method with the benchmark algorithms. Experimental results show that their proposed method could outperform the benchmark algorithms in a majority of the settings, albeit the improvements are marginal.  \n\nI have a mixed feelings about this paper. On one hand, it studied a well-motivated problem, and proposed an objective function with some solid theoretical guarantees. On the one hand, the exposition of the objective and the main theorem has some non-trivial problems, and the experiment performance only offers slight improvements over the baselines. As such, I would recommend a \u2018\u2019weak accept\u2019\u2019 due to the pros and cons."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I think the paper studied a well-motivated problem in machine learning. Subpopulation imbalance can be viewed as an extension of the class-imbalance problem in machine learning, and the problem is harder since the \u2018imbalance\u2019 is not easily visible from the dataset. Using a training-based method is a natural idea, and essentially, the core of the paper is to train an annotation algorithm $v(X,Y)$. The paper also contains the novelty in the design of the loss function, which resorts to the tools in information theory.\n\nThe design of the objective function is justified by a theoretical analysis. Although the proofs are mostly standard applications of information theory and concentration inequalities, I appreciate the fact that they are properly written. Due to a hectic review timeline, I did not get time to verify all the calculations in Appendix B. I believe the proofs are correct with a high-level read-through.\n\nThe experiments are conducted on various datasets, and a bulk of benchmark algorithms are used in the comparison. I do appreciate the report on the error range, which justifies that the improvement is not due to statistical fluctuations."
            },
            "weaknesses": {
                "value": "A main criticism I have for this paper is that many assumptions are not explicitly stated, and the quantifiers are not properly stated in the settings and theorems. Furthermore, the paper provided no intuition on how the analysis is conducted. These problems gave me a hard time parsing the result. For instance, my first impression was that mutual information is *not* the correct notion that should be used to measure the gain for \u2018subpopulation harmonization\u2019. In particular, if $f$ is a *deterministic* function of $x$ or even a randomized function whose randomness is *independent of* $x$, then $I(X;Y)$ and $I(X;Y| v(X,Y))$ are essentially the same. (Btw $v(X,Y)$ is a random variable, which I believe you never mentioned.) I think the key in your model is that $y$ is a randomized function of $x$, and the randomness is *dependent* on the choice of $s$. However, such a fact is only clear after carefully reading the proof (!), and the whole thing reads quite confusing at first. \n\nAdditional (hidden) assumptions for the theorem in this paper include the fixed distribution of $(X,Y)$ and a fixed number of groups of subpopulations. Apart from being sloppy and not stated properly, the assumption of a fixed number of groups of subpopulations also implies we should have considerable knowledge of the dataset.\n\nA concern about the experiment is that the improvements compared to the baseline, especially w.r.t. the very basic ERM, are too marginal. I understand that getting the SOTA performance in experiment-based machine learning is an interesting problem, however slight the improvement is. But for this specific problem, the small margin of improvement (which itself is in a low accuracy range) might have low impacts on practice. \n\nMinor: \n- In Table 1, the meaning of $p(\\cdot)$ is overloaded \u2013 the \u2018\u2019class-imbalance\u2019\u2019 distribution is supported on the labels, while the \u2018\u2019subpopulation-imblance\u2019\u2019 distribution is supported on the groups of the subpopulations. I\u2019d suggest using a different notation. \n\n- In theorem 3.3, the Rademacher complexity of $G$ is not properly defined. Instead of simply pointing at the literature, I think the notion should be defined in the appendix with the proper quantifiers.\n\n- Inequality (16) uses McDiarmid\u2019s inequality, but this technical tool was never introduced. :("
            },
            "questions": {
                "value": "Most of the questions are in the ''weakness'' section. A less technical question is as follows. For the toy example in Figure 2, the original (overall) dataset is quite balanced, and an extremely skewed sampling process obtains the imbalanced training data. I understand this is important to test the performances for classification under imbalanced settings. However, can you give practical motivations to consider such a setting where we could have obtained a balanced dataset but, for some reason, have to use a very imbalanced subsampling process for the training dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I do not see any necessity for ethics reviews."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Reviewer_FihB"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792142136,
        "cdate": 1698792142136,
        "tmdate": 1699636509866,
        "mdate": 1699636509866,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "958BB8H0D8",
        "forum": "3GurO0kRue",
        "replyto": "3GurO0kRue",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_TvvJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_TvvJ"
        ],
        "content": {
            "summary": {
                "value": "This work addresses the subpopulation imbalance problem where the training data consists of multiple subpopulations and their proportion is imbalanced. A novel approach, referred to as scatter and harmonize, to identifying the subpopulations and minimizing risk for each subpopulation is proposed. The authors provide a theoretical analysis of the proposed approach and demonstrate its utility through extensive experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Considering a practically important problem with clear motivation.\n- Well-written and easy to follow.\n- Supported by extensive experimental results."
            },
            "weaknesses": {
                "value": "- I find that this study is relevant to various problems/applications. It could be informative if the authors can clarify the relationship to the existing work, including domain generalization, algorithmic fairness, or such.\n- Some details could be improved for completeness: e.g., the subpopulation imbalance problem makes sense only if $p(\\boldsymbol{x},y|s)$ differs by subpopulation $s$."
            },
            "questions": {
                "value": "- I might have missed the detail, but I am not sure if the (optimal) data partition approach is completely novel. Could the authors clarify it? If not, could the authors kindly provide what approaches have been proposed? (maybe for some other problems)\n- Even if the authors focused on the subpopulation imbalance problem, domain generalization and subpopulation shift problems seem highly relevant to this work. Could the authors kindly clarify the relationship between the existing methodologies to tackle the domain generalization and subpopulation shift and the subpopulation imbalance problem? Also, this work is somewhat relevant to algorithmic fairness as well. It might be helpful for future readers to relate the problems conveniently.\n- For Thm 3.3, could the authors elaborate on why minimizing $\\hat{\\mathcal{R}}$ results in maximizing $I(X;Y,\\nu(X,Y))$? It seems like it is true asymptotically but not sure with finite samples.\n- Is it possible to establish an inequality between the (empirical) risk of SHE and that of ERM under the subpopulation-balanced distribution?\n- This work seems to be similar to [Lahoti et al. (2020)](https://proceedings.neurips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html), which ensures fairness with respect to maximal heterogeneity. Might be interesting to investigate the differences and similarities. \n- Could the authors kindly explain why no method other than the proposed one outperforms the ERM across all datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5154/Reviewer_TvvJ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698815912343,
        "cdate": 1698815912343,
        "tmdate": 1699636509778,
        "mdate": 1699636509778,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mNrN0SHF6E",
        "forum": "3GurO0kRue",
        "replyto": "3GurO0kRue",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_acbx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5154/Reviewer_acbx"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to solve the subpopulation imbalance problem. The authors propose a new method named Scatter and HarmonizE (SHE), which discovers and balances the latent subpopulation in training data. Specifically, it builds on the principle of optimal data partition from information theory, which approximately uncovers the hiddle subpopulations and assigns data to subpopulations. Then, it achieves subpopulation-balanced predictions by simply applying a LogSumExp operation. Theoretical analyses are provided to support the validity of the method. Finally, experimental results illustrate the superiority of the proposed method SHE."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "First of all, I have to admit that I am not an expert in the area of subpopulation imbalance, and may miss some related work.\n## Originality\n* To my knowledge, the data partition method for subpopulation recovery based on information theory is somewhat novel although these techniques have been widely used in other sub-fields of machine learning.\n## Quality\n* The proposed method is reasonable. Extensive experiments illustrate its superiority. Besides, theoretical results are also provided to support the validity of the method. \n## Clarity\n* Overall, this paper is well-written and the motivation is very clarified.\n## Significance\n* The proposed method can contribute to the community of subpopulation imbalance."
            },
            "weaknesses": {
                "value": "## Originality\n* There are also many works inspired by the information theory to guide the design of training objectives in machine learning. More discussions can be added.\n\n## Quality & Clarity\n* The proposed method SHE heavily depends on the number of subpopulations $K$, which is unknown in practice.\n* For the equation at the end of Section 3.1, the goal to minimize the error rate of a specific test dataset is not proper because it should be the expected error rate w.r.t. the distribution, and the one for a specific test dataset is only its unbiased estimator.\n\n## Significance\n* The proposed method may have little effect on other sub-fields of machine learning."
            },
            "questions": {
                "value": "1. In Table 1, what is the formal definition of imbalance ratio IR? I have carefully checked this paper and have not found it.\n\n2. From the perspective of computational cost, what about the proposed method SHE against other baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699525271885,
        "cdate": 1699525271885,
        "tmdate": 1699636509697,
        "mdate": 1699636509697,
        "license": "CC BY 4.0",
        "version": 2
    }
]