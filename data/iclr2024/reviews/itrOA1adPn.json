[
    {
        "id": "dSsm6gzT4H",
        "forum": "itrOA1adPn",
        "replyto": "itrOA1adPn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_bdjp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_bdjp"
        ],
        "content": {
            "summary": {
                "value": "The paper trains agents to survive in 3D environments where survival depends on food gathering (and avoidance of harmful items). The appearance of food items can vary in complexity, from two-color items to CIFAR10 classes. Various type of agent architectures are compared, including feedforward vs recurrent, with or without an input for satiety, and linear vs nonlinear activations.\n\nRecurrence and satiety inputs are found to consistently improve performance. However, network size seems to have a very modest effect across conditions, except perhaps for RNNs (judging from Figure 2).\n\nThe authors demonstrate that recurrence is used at least in part specifically for object discrimination, and that the agent's learned value function is influenced by both food countdown and satiety."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The experiment is rather interesting in itself.\n\n- The results, such as they are, seem well supported.\n\n- The paper is well written, though some information is missing - see below."
            },
            "weaknesses": {
                "value": "- The results are not exactly earth-shattering. More difficult tasks seem to benefit from more complex architecture and additional inputs. If anything, the surprising result is the *low* impact of network size on performance (Figure 2).\n\n- Some clarifications are needed, see below."
            },
            "questions": {
                "value": "- Although the architecture is reasonably well-described, the training itself is not, with little detail except for a mention of PPO. E.g. what is the reward function, exactly? \n\n-  From the Discussion: \"In particular, we demonstrated how recurrent brains attended to latent variables beyond the agent\u2019s hunger and the immediate presence of food.\" - I'm sorry, I missed that part. Can you point out more explicitly where this is shown in the paper and what \"latent variables\" are \"demonstrated\" to be attended to, beyond satiety and food items? I agree that this would be quite interesting.\n\n- What's an \"ELU\" nonlinearity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697741088894,
        "cdate": 1697741088894,
        "tmdate": 1699636255865,
        "mdate": 1699636255865,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TuSMbLi3lb",
        "forum": "itrOA1adPn",
        "replyto": "itrOA1adPn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_pa3w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_pa3w"
        ],
        "content": {
            "summary": {
                "value": "In this work, the Authors set to study how differences in environments pose different requirements for neural architectures enabling vision and decision-making. To this end, they have implemented a 3D simulation of a foraging task where agents had to collect positively rewarded objects and avoid negatively rewarded objects. The agents comprised of a CNN to process pixel data and an actor-critic RL module for decision-making; they were trained end-to-end using the PPO algorithm. The Authors varied the architectures/inputs of the agents and compared their performance in environments with varied complexity of visual stimuli."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The text is well-written and easy to follow.\n\nThe description of the experiments is sufficiently detailed.\n\nThe question posed by the Authors is interesting and important.\n\nHowever, the means used to address the question appear insufficient (see below)."
            },
            "weaknesses": {
                "value": "My main concern regarding this work is that the entire study is conducted on a (particular implementation of) an artificial system, only somewhat paralleled to the brain, so all the results may end up being specific to this system and may not generalize beyond it. Should such experiments be conducted with real-life animals representing different \u201ccomplexities\u201d of neural processing, we would be able to learn something about real-world neurobiology. Should the models explicitly contain and consider particular biologically relevant architectural choices, we could be able to learn about the (focused) impacts of such. In current settings, sadly, the results relevant for a (generic) CNN and PPO may not inform us about such things.\n\nMy secondary concern is that I do not agree that end-to-end processing is necessarily beneficial for learning the optimal representations in submodules of the neural network. Specifically, for the longest time, it\u2019s been an ongoing debate with no clear outcome. The examples include audio processing (where SOTA was switching between using mel-spectrograms, then deep-learning representations such as the ones in wav2vec, then again considering mel-spectrograms), vision processing (e.g. using feature-based pre-alignment before training the triplet loss in facial recognition), and control (where control submodules are trained end-to-end, e.g. in quadruped robots with manipulators, but vision models are separately pretrained). Related to this point, I think that the aforementioned cases are relevant and need to be discussed in the paper.\n\nMy ternary concern follows that, in this specific work, the end-to-end training may be unnecessary, increasing the training time but, potentially, not providing new insights. In the specific case of foraging, most of the works successfully operate on simple state representations, reducing the computational time from months on a GPU cluster to seconds on a laptop. I am familiar with only one work using 3D simulation for a foraging task but, likewise, I didn\u2019t find their case well-argued. Either way, if there is indeed a benefit of using an end-to-end model in the current framework, it would make sense to highlight this benefit via a baseline analysis where the blocks of the same model are trained separately.\n\nLastly, if focus on different submodules of the proposed model, the results do not seem surprising. Indeed, more complex architectures are needed to distinguish more complex stimuli (e.g. texture in MNIST digits as opposed to color in apples). Surely, RNNs have the capacity to embody more complete information about the state, compared to feedforward architectures, departing from Markovian task formulation and enabling longer-term planning. These results are known in the respective fields, and the related literature seems relevant enough to be included/discussed in this paper. The other results, such as agents slowing down before stimuli, are interesting but may be specific to the proposed framework \u2013 unless proven otherwise.\n\nOverall, while the results are technically correct and well-described, the concerns above sadly preclude me from recommending the paper to be accepted to the ICLR at this point."
            },
            "questions": {
                "value": "Minor:\n\n-page 2: Merell et al modeled a rat, not a mouse.\n\n-page 3: \u201cthe reward at every frame was equal to the current satiety of the agent\u201d. This reward shaping seemingly contradicts an earlier statement that \u201cIn our framework we reduced the reward function to the survival of the agent, and avoided further fine tuning of the reward\u201d (page 1)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698437348986,
        "cdate": 1698437348986,
        "tmdate": 1699636255781,
        "mdate": 1699636255781,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uxSFfl79Ey",
        "forum": "itrOA1adPn",
        "replyto": "itrOA1adPn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_PwAE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_PwAE"
        ],
        "content": {
            "summary": {
                "value": "This paper develops a simple environment off of ViZDoom that studies the problem of how neural net architectural choices affect performance of varying-complexity visual tasks. Authors develop 4 visual tasks that each require a different level of discriminative image processing capacity to perform well. Each task has objects, which are all placed as vertical images atop a 3D-pixelated plane, and images are classified into 10 different satiety scores, {-25, -20, ..., -5, 10, 20, ..., 50}. All tasks involve choosing an action at each timestep (forward/stationary/backward) in a specific direction (left, right, center) to avoid negative-satiety-score objects and make contact with positive-satiety-score objects to prevent satiety from falling to 0, which kills the agent. The paper calls this \u201cvisual ecology.\u201d\n\nAuthors analyze the effect of architecture and hyperparameters on the lifespan of the agent in each of the 4 tasks, finding a loose correlation between larger kernel count and improved performance. RNNs performed better than fully connected networks on image embeddings, and inputting the satiety score allows the learned value function to more stably track the actual satiety value."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- An interesting problem to study: how environments affect visual processing.\n- Did a thorough set of experiments given the environment\u2019s capabilities.\n- Writing mostly made sense and was clear throughout."
            },
            "weaknesses": {
                "value": "### Overall\n(A1) Paper overall seems geared to a slightly less technical audience than ICLR. For instance, describing each conv layer as a different region of the brain (Section 2.1) seems like a weird thing to do, at least in the AI community. Why is the 4th conv layer analogized to the lateral geniculate nucleus, for example? What is the basis for creating these mappings between conv layers and mammalian brain regions?\n\n(A2) Additionally, some results are presented as interesting by the authors, but to me seem relatively straightforward and expected. For instance, including the input satiety into the architecture should obviously improve performance.\n\n(A3) Related work section should be much more substantial. Have prior papers studied \u201cvisual ecology\u201d or done analysis on neural vision architectures when given an environment the agent must survive/do tasks in? It is hard to evaluate the contributions of this paper without a solid summary of previous work in this area.\n\n### This paper is mainly limited in its analysis by an overly simple environment design.\n(B1) Based on Figure 4C, it seems like satiety decreases at a constant rate, no matter what action the agent is taking. This seems undesirable, as animals expend different amounts of energy depending on different actions. For instance, being stationary should be much less draining on satiety than moving.\n\n(B2) Environment lacks interesting actions beyond moving in different directions or staying put. Additional simple actions may make the environment much more interesting, such as rotating field of view without changing (x,y) position, and needing to perform some manipulative action (such as triggering a set of discrete actions, such as \u201cpulling vegetables out of the ground,\u201d before being able to consume them). These additional actions can also have different satiety costs to them.\n\n(B3) Environment does not accurately model effects of satiety on actions. Decreased satiety should have a harmful effect on the agent being able to take actions. A satiety=1 agent should not be as effective at moving around as a satiety=100 agent. Under this situation, it would be cool to analyze the satiety value at which the agent is most effective at finding food, since it would tend to be more stationary at higher satieties and tend to be less effective at moving around at lower satieties.\n\n### The main claims in the paper could be better analyzed and argued.\n(C1) First abstract claim: \u201cThe complexity of the vision model required for survival on this task scaled with the variety and visual complexity of the food in the environment.\u201d This may sound trivial, but authors should define model complexity. Is model complexity only dependent on parameter count? That seems inadequate, since a huge, deep feed-forward network with the same parameter count as a CNN or an RNN should still not be as \u201ccomplex\u201d due to the inductive biases encoded in the latter two networks. Some of the author\u2019s experimental choices for looking at complexity, such as focusing a lot on number of channels, is probably misguided, since increasing number of channels after a point is known to saturate network performance, as Figures 2D-F show. Things like residual connections, kernel dimension/size, and number of conv layers will probably make for more interesting graphs.\n\n(C2) Second abstract claim: \u201crecurrent network architecture was necessary...for visually demanding tasks.\u201d This claim makes sense from Figure 2C, but I do not feel like it is well-substantiated. For instance, one could feed the current image as well as the last $k-1$ images into the CNN, either stacked channel-wise or arranged as an $(m, n)$ array of images, such that $k = m\\times n$. This would not involve the network being recurrent, but still captures information in the previous $k-1$ observations, and it is possible that this does comparably to RNNs. This claim also might not hold if transformers were used as the architecture.\n\n(C3) Third abstract claim: \u201cDifferent network architectures learn distinct representations of environment and task, leading to different behavioral strategies.\u201d Agent behavior was better investigated in the results, but not necessary the \u201cdistinct representations\u201d part of this claim, though there was Figure 4C which showed the different value functions. One suggestion here is that it would be better to revise Figure 4B and 4C, for instance, to show the sensitivity of all 4 methods of $\\hat{V}$ on the same image observation at the same location in the environment, so that readers can see the \u201cdistinct representations\u201d in image space as well as in value space."
            },
            "questions": {
                "value": "1. How would behavior have changed if there were no drive for survival, but just a drive for collecting high reward (without a limit of 100)?\n2. Suggestion: Authors should compare their designed environment with Fruitbot in ProcGen (https://github.com/openai/procgen#environments), where an agent also tries to get good objects and avoid bad objects.\n3. What was the motivation behind choosing Gabors as one of the tasks? Visually, it seems to be the most contrived of the 4 tasks.\n4. Are object positions in the environment randomly initialized?\n5. What was the mean distance (in terms of optimal number of actions to reach) between each positive-satiety object and its closest positive-satiety neighbor? What was the actual distance traveled by the agent? May be good to measure this. This would be similar to Figure 6\u2019s \u201cWasted Nourishment\u201d but would instead be measuring \u201cWasted actions.\u201d\n6. Was each environment initialized to have an equal frequency of positive and negative satiety objects?\n7. How was the satiety inputted into the network? Was it normalized to be a value between (0, 1)? One could try inputting the satiety into the CNN directly with FiLM layers (https://arxiv.org/pdf/1709.07871.pdf) and see if this increases the effect of input satiety over non-input satiety architectures. Also, why was the input satiety concatenated for the second FC layer instead of the first?\n8. Precisely define the reward function. Section 1 says it is \u201cthe survival of the agent,\u201d but does that mean it is a sparse 0/1 reward, or is it a constant +1 for all timesteps the agent is alive, and 0 else?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3096/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3096/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3096/Reviewer_PwAE"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730670434,
        "cdate": 1698730670434,
        "tmdate": 1699636255710,
        "mdate": 1699636255710,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XOA4LCvqur",
        "forum": "itrOA1adPn",
        "replyto": "itrOA1adPn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_zf5P"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3096/Reviewer_zf5P"
        ],
        "content": {
            "summary": {
                "value": "Motivated by the evolution of animal vision, this paper trains agents in a foraging task with deep RL, in which the complexity of the tasks is varied based on the visual complexity of the food images. The most complex food representations were based on CIFAR-10 images. In contrast to many other deep RL domains, agents are only rewarded for surviving. The results show that more complex visual complexity requires more complex vision models. An interesting observation is that for most complex tasks, recurrent network architectures were necessary. Additionally, the authors show that different network architectures learn different representations of the environment."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Interesting idea to use recent advances in DNN to study visual ecology\n- Since most neural networks for image recognition are purely feedforward it is an interesting result that recurrence facilitates object discrimination on visually complex tasks How is it using the recurrent dynamics? \n- Section 3.3. in particular presents an interesting investigation into how the neural network architecture shapes the reward system of the agent"
            },
            "weaknesses": {
                "value": "- My main issue is the comparison of a simple CNN to an animal vision system, i.e. \"We modeled the CNN after the early mammalian visual system: the base layers were grouped sequentially into the photoreceptor (PR), bipolar (BP), retinal ganglion cell (RGC), lateral geniculate nucleus (LGN), and primary visual cortex (V1) layers.\u201d As far as I understand, it\u2019s just a different number of channels and kernel sizes? Naming the different layers in a network after biological brain regions does not directly make them more biologically realistic.\n- Environments in nature are much more complex than the ones proposed in this paper. To study visual ecology, it seems our agent environments need to be more complex as well.\n- There is a lot of related work in the evolutionary community, which isn\u2019t mentioned, where survival is the only reward mechanism. \n- In conclusion, I would argue that a computational framework on visual ecology has to go beyond one experiment/domain with a slight variation on a deep RL setup"
            },
            "questions": {
                "value": "- How would a model perform that is not \"based on\" the mammalian visual system?\n- How realistic is the vision model when compared to animal vision?\n- In nature, adaptation is a result of evolution and lifetime learning. Wouldn\u2019t it be important for this research to combine both adaptation mechanisms in some way? In particular, the evolution of plastic neural networks with Hebbian learning rules could be relevant here."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3096/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699003189773,
        "cdate": 1699003189773,
        "tmdate": 1699636255639,
        "mdate": 1699636255639,
        "license": "CC BY 4.0",
        "version": 2
    }
]