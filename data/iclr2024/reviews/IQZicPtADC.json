[
    {
        "id": "6O99EjxyRB",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a statistical guarantee for multitask imitation learning for improved sample efficiency. Their contribution builds on others work such as Arora et al by using the Rademacher complexity. Using this they have a tighter bound which will provide benefits of transferring for imitation learning. With theoretical insights, they provide empirical results while comparing with multitask behavioral cloning. The environments they utilize are Cartpole, Frozen Lake, Pendulum, Cheetah, and Walker."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "With the experiments, you have measured some scenarios in both discrete and continuous domains to show that it works. The additional experiments in the supplementary material show the amount of rigor especially with showing the task diversity metric.\n\nThe motivation of the theory makes sense and you provide a good amount of related works to show the relevance of the significance."
            },
            "weaknesses": {
                "value": "Writing\nYou state in the abstract \u201creadily extended to account for commonly used neural network architectures such as multilayer perceptron and convolutional network with realistic assumptions\u201d It would strengthen this claim if you had experiments with convolutional networks to show that it can be done. If not please reconsider modifying your claim.\n\nIn the theoretical contributions paragraph in page one, what do you mean by the second sentence, is that from the Arora et al. paper, if so please say that it refers to that because it sounds off?\n\nExperiment\nFor the BC baseline, it seems like an easy one to compare and in the SM you have BC with 2|D| would it not be appropriate to also show that similar comparison with the main text experiments to show what if BC had more |D| to what your method has?"
            },
            "questions": {
                "value": "Please refer to the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F",
                    "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698380052705,
        "cdate": 1698380052705,
        "tmdate": 1700514723877,
        "mdate": 1700514723877,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jeJ6P5hW83",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_F18A"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_F18A"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses the advantages of using transferred representations in multitask imitation learning. The authors propose that such transfer can improve the efficiency of learning the target task by using representations learned from sufficiently diverse and related tasks, which can lead to a reduced need for data when training on a new task. They provide theoretical guarantee to support the idea that representation transfer is beneficial, which can be extended to neural network architectures such as multilayer perceptron and convolutional networks. The paper also provides empirical analysis that validate the theoretical findings. Experiments are done in simulated environments to show that leveraging data from diverse source tasks can indeed improve learning efficiency on new tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is well organized and nicely written. The contributions are outlined and well emphasized, and the settings/backgrounds are well introduced. Definitions and theorem are formally stated and discussed with remarks. \n- Theoretical results are reasonable as far as I read into. Extensive discussions are provided in the appendix.\n- The topic on multi-task representation learning is interesting and important."
            },
            "weaknesses": {
                "value": "- It would be better to state clearly in the main paper about what assumptions are made in the paper and discuss about the limitations.  \n- It is difficult to read Figure 1-4. The lines are hard to distinguish from one another."
            },
            "questions": {
                "value": "See in weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699512007877,
        "cdate": 1699512007877,
        "tmdate": 1699636251948,
        "mdate": 1699636251948,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4a7M14GJew",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the statistic guarantees of transfer learning with regards to its improvements in sample efficiency, specifically with regards to imitation learning paradigms. The main result of this paper is a bound on the policy error that is indirectly related to the task diversity of the source tasks $T$, the number of demonstrations of the source task $N$, and the number of demonstrations of the target class $M$, and directly related to the Rademacher complexity. Task diversity is intuitively defined as how closely can some learned policy $\\pi^*$ perform on a new task given source tasks.\n\nThe proposed method is split into two stages: first learn a representation embedding $\\hat{\\phi}$ from source tasks, then learn a policy $\\pi$ conditioned on the task-specific mapping $\\hat{f}$ and $\\hat{\\phi}$. The training objective of the first phase is to minimize the log loss of $\\pi$ given a task-specific mapping for source task $t$ and the parameter $\\phi$. The training objective of the second phase is to minimize that same loss using $\\hat{\\phi}$ from above, this time varying the task-specific mapping $f_\\tau$. The authors perform their analysis in the tabular setting, but mention that it may be possible to extend to continuous state-action spaces in theory, and provide empirical results to support this.\n\nThe empirical questions the authors aim to answer is whether multi-task behavioral cloning training can do better than single task behavior cloning training, and ablate over $N$, $T$, and $M$ to see which affects performance the most. They find that increasing $N$ and $T$ are most impactful in improving performance and reducing the demand on target data demonstrations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The main contributions form this paper are two fold: 1) a tighter bound on sample efficiency of multi-task imitation learning paradigms, and 2) empirical results focus on the effectiveness of representation transfer and a new metric to measure task diversity. \n\n- The paper clearly presents the hyperparameters it is interested in that is relevant to their main bound, and does a thorough ablation over each parameter.\n- The proposed KL metric is described in a digestible manner, and good to see thorough results testing its effectiveness. As mentioned, it is an important direction to prompt more empirical work analyzing task diversity.\n- Empirical findings are interpretable, and good combination of graphs and tables.\n\nFinally, the paper is generally free of grammatical errors and typos, and written in a clear manner. Overall, it is likely to be of interest to a smaller community in the multi-task learning space. However, if the authors could provide more results on experiments outside of Mujoco, such as the more challenging tasks mentioned below, it has the potential to raise interest in the larger multi-task imitation learning community."
            },
            "weaknesses": {
                "value": "### High Level Technicals:\n- While the story told in Figures 1-4 are clear, it would have been nice to see some evaluations on at least one multitask environments such such as FrankaKitchen [[1](https://robotics.farama.org/envs/franka_kitchen/franka_kitchen/)] or Metaworld [[1](https://meta-world.github.io/)]. While the current results on Mujoco support the claim, the environments are relatively simple. The results of this paper would be of interest to a much larger community if the same compelling results are shown on just one of the above environments.\n- It would have been nice to see some more interpretation on the results of Spearman and Kendall correlations on the bottom of page 8.\n- Due to the boldness of the lines and overlap, it is a bit challenging to tell the differences between the blue, yellow, green, and red lines. I might suggest using different shapes in or decreasing the boldness of the lines. \n\n### Low Level Technicals\n- On (ii) towards the bottom half of page 7, \"let\" should be capitalized in \"let \\hat{r}_t be the average rewar of the expert...\""
            },
            "questions": {
                "value": "1. Is there any demand on the optimality of the source task demonstrations? For example, would a large batch of suboptimal demonstrations actually deteriorate or stagnate improvement given the proposed method?\n2. I'm curious whether increasing amount of source task data would also make the policy more robust to covariate shift, since it theoretically should have a larger state-space coverage. Or when transition dynamics are stochastic.\n3. Have the authors attempted to generalize their framework to imitation learning algorithms beyond behavioral cloning, such as IRL methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc",
                    "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699542685399,
        "cdate": 1699542685399,
        "tmdate": 1700622649483,
        "mdate": 1700622649483,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "g8GvImml7u",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
        ],
        "content": {
            "summary": {
                "value": "The authors consider, theoretically and empirically, the sample-complexity benefits pre-training a shared representation on multi-task data might provide for behavioral cloning. In theory, they prove a high-probability bound on the performance difference between BC learned on top of the shared representation and the expert data. In practice, they show that on a variety of discrete and continuous control problems, pre-training on multi-task data allows for effective policy learning with limited target-task data."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(+) The theoretical analysis is easy to follow and uses standard tools.\n\n(+) I appreciated how the experiments section was broken down into the statement and testing of various hypotheses."
            },
            "weaknesses": {
                "value": "(-) Overall, I found the theoretical statements to be fairly simple extensions of known results by Tripuraneni et al. and Ross & Bagnell. In essence, by focusing only on behavioral cloning, the authors are able to almost entirely ignore the sequential nature of the imitation problem and apply the standard analysis for multi-task supervised learning. Then, once they have a bound on the KL divergence between the learner and the expert, they can apply the well-known upper bounds for behavioral cloning (https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf) to get an overall policy performance guarantee. So, I really didn't get much out of the theorems they proved.\n\n(-) There's a few pieces of odd terminology throughout the paper. First, instead of \"policy error\", people usually use \"performance difference\" or \"imitation gap\" (https://arxiv.org/abs/2103.03236). Also, I think you're missing a $H^2$ or $\\frac{1}{(1-\\gamma)^2}$ in the first equation in the paper? Second, when people talk about \"number of demonstrations\" (i.e. $|\\mathcal{D}|$ in the paper), they usually mean the number of whole trajectories rather than the number of state-action tuples (as you seem to use it in Table 1). Do you mind re-naming this? I got super confused for a while by why one would need millions of samples for BC to work on a Mujoco task. Can you also clarify whether $N$ and $M$ are measured in terms of trajectories or state-action pairs?\n\n(-) Once you divide the numbers in table 1 by the horizon of the problem (1000 for Mujoco), you realize that they're attempting to learn based on effectively 1-2 demonstrations. This is a somewhat absurdly small amount of data (usually people do ~25 demos for Mujoco tasks). So, while the experimental results make sense to me, I think it is somewhat important to note that they are under fairly contrived settings.\n\n(-) While the idea of a metric to capture the effectiveness of multi-task IL data for learning a transferrable representation is interesting, I found the ideas in Appendix B to be a bit sloppy and the empirical reported correlations in Tables 2/3 to be fairly low.\n\n(-) Most analysis of imitation learning doesn't have to make assumptions about the optimality of the expert policy. In Footnote 1, you note that you do this. Is this actually important for any of your analysis?\n\n(-) I might add some more citations for multi-task imitation learning outside of behavioral cloning. While they are clearly different than your work, it would be good to add in some references and discuss the differences: https://arxiv.org/pdf/1805.12573.pdf, https://arxiv.org/pdf/1909.09314.pdf, https://arxiv.org/pdf/1805.08882.pdf, https://arxiv.org/pdf/2309.00711.pdf. You might also want to cite some work on representation learning for sequential decision making (e.g. https://arxiv.org/abs/2207.08229)."
            },
            "questions": {
                "value": "(1) I think it would be helpful if you could add in a comparable statement to Theorem 1 for single-task BC. You could then give ranges of T and N under which you'd have a meaningful difference in upper bounds between multi-task and single-task BC. The sharpest analysis I know for IL under a deterministic expert assumption is in https://arxiv.org/pdf/2205.15397.pdf -- you might be able to just copy some of their theorems.\n\n(2) In Figure 1, why do some of the performances for the multi-task method start lower than the corresponding BC performances? Do you think this would be fixed if you included target task $\\tau$ in the representation learning step?\n\n(3) Do you have any hypothesis for why, in Figure 2, things look quite bad for CartPole? Is it perhaps because of the kinds of environment modifications you were considering?\n\n(4) In Figures 3 and 4, you're giving the learner quite a bit of source data so perhaps the performance gap is already quite close. If you have the compute resources, could you ablate these results across smaller values of $N$?\n\n(5) Generally, could you be more specific about the ranges over which you varied environment parameters to generate the multi-task data (e.g. what link sizes for Walker)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699572758057,
        "cdate": 1699572758057,
        "tmdate": 1700511420394,
        "mdate": 1700511420394,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BzvVoeAq7i",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Ss6u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_Ss6u"
        ],
        "content": {
            "summary": {
                "value": "The paper posits that there exists a shared representation across a variety of tasks. It trains behavior cloning from a set of source tasks, learns a representation, and then learns a policy for a target task. It proposes that, the policy error is bounded by the diversity of the source tasks. It suggests that training in this paradigm will have better performance and uses less target task data than vanilla behavior cloning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Innovative Concept: The paper introduces an interesting hypothesis about the benefits of learning shared representations from diverse source tasks to improve policy learning in behavior cloning.\n- Theoretical Contribution: It provides a theoretical framework that bounds policy error with respect to the source task diversity, offering a new perspective on the potential for generalization in behavior cloning."
            },
            "weaknesses": {
                "value": "- Lack of Clarity: The paper does not sufficiently describe the \"shared representation\" it aims to learn. A more detailed exposition, possibly including visualizations or analysis of the learned representation, is needed.\n- Theoretical Bound Practicality: The paper presents an order bound on policy error but does not provide a comprehensive discussion on its tightness or practical applicability, leaving its usefulness in question."
            },
            "questions": {
                "value": "Section 4 requires further detail on the nature of the source tasks for each target task investigated. The concept of \"shared representation\" is pivotal yet remains vague within the paper. Is this representation a transformation from a visual image to a latent space, or something else? A detailed analysis or visual depiction of this shared representation would greatly enhance the clarity, perhaps focusing on a single task as an example.\n\nThe paper introduces a theoretical bound but does not elucidate on its tightness or practical applicability. It is essential to quantify or provide conditions under which the bound holds with a fixed constant, thereby ensuring utility in policy improvement with additional data.\n\nHow do you define the \u201cpolicy error\u201d on Page 1? How can it be measured? Is the measurement done in the task reward, action space, or divergence perspective? Besides, you mentioned that f-divergence imitation learning states that a learned policy is minimizing the divergence between expert and learner trajectory. How does the policy error fit / contrast with such existing framework?\n\nGiven the focus on multi-task imitation learning, it is imperative to benchmark against state-of-the-art Meta Learning methods for a comprehensive comparison.\n\n\u201cHowever, current methods require thousands of demonstrations even in simple tasks (Mandlekar et al., 2022; Jang et al., 2021; Ablett et al., 2023)\u201d => *Thousands* of demonstrations seems to misrepresent the SOTA of IL? Refer to https://www.roboticsproceedings.org/rss19/p009.pdf  https://medium.com/toyotaresearch/tris-robots-learn-new-skills-in-an-afternoon-here-s-how-2c30b1a8c573 https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/  Please clarify. \n\nFor all experiments detailed in Section 4, please define the state and action space, including their dimensions.\n\nCan the derived bound be applied to low-dimensional imitation learning that does not learn a representation? Assuming that the learned representation is the identity matrix, can we extend the bound to low-dimensional state space? Is the result implying that, adding more data into pre-training, will result in smaller policy error?  However, given what we saw in https://ieeexplore.ieee.org/abstract/document/10161474/ it seems that more data is not guaranteed to help imitation learning performance on the real robot. Can the author provide some insight? \n\n\nOur result is due to the objective of behavioral cloning, where the method aims to minimize the Kullback\u2013Leibler (KL) divergence between the expert and the learner (Ghasemipour et al., 2019; Xu et al., 2020). => Could you elaborate how the findings from Xu et al., 2020 is related to this statement? \n\nRegarding Equation 4 and the \"under some assumptions\" qualifier, a more intuitive explanation of these assumptions and their impact on the model's generalizability would be essential."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699590619887,
        "cdate": 1699590619887,
        "tmdate": 1699636251724,
        "mdate": 1699636251724,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5ec1xvbIVh",
        "forum": "IQZicPtADC",
        "replyto": "IQZicPtADC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
        ],
        "content": {
            "summary": {
                "value": "The paper provides a tighter statistical guarantee in the sample-complexity of transferring what is learned from source tasks to target tasks and empirical evaluates this on some simple control tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality**\n- The paper uses Rademacher complexity instead of Gaussian complexity, as used heavily by work that the paper references, in order to derive a tighter bound for a sample-complexity bound of the benefits of a representation in transfer learning in multi-task imitation learning (MTIL)\n\n**Quality**\n- Good to create and evaluate algorithms on discrete action space variants of continuous action environments while also evaluating on these continuous spaces to see whether theory that the paper proposes is actually empirically supported in both spaces for the same type of problem domain.\n- The paper includes multiple correlation values in Tables 2 and 3 to cover certain limitations of individual ones.\n\n**Clarity**\n- The paper does a good job throughout explaining technical details and its experimental design.\n- The paper provides intuitive explanations to accompany well-written rigorous definitions, which can help the reader better understand the concept being explained. For example, on page 3, the paper states \"Intuitively, the Rademacher complexity of F measures the expressiveness of F over all datasets X through fitting random noise.\" after providing a rigorous definition of Rademacher complexity in its problem setup.\n\n**Significance**\n- The significance is potentially large, but I'm unsure how well it generalizes, especially due to the limitations of using only the KL-divergence and no other measure of dissimilarity between probability distributions."
            },
            "weaknesses": {
                "value": "1. The paper uses only KL-divergence to measure task-diversity for source and target tasks.\n\n2. The paper doesn't compare using $D_{KL}$ to using other statistical measures of similarity between probability distributions, such as Bhattacharyya distance, which seem much more appropriate to do than the measures that the paper does compare $D_{KL}$ against.\n\n3. **Generally when it comes to Rademacher Complexity in this context of this work, my concerns (really just an overarching single concern) are detailed in the paragraphs below.** However, I welcome thoughts on others from whether these are valid here or out of scope. If out of scope, then I also welcome discussion on how significant is the paper context, really?\n- In the context of bounding sample-complexity in transfer learning, particularly for evaluating the richness of representation classes I wouldn't use Rademacher Complexity because of the importance of nuance in transfer learning on sequential tasks, which this measure avoids accounting for.\n- Brief descriptions of Rademacher Complexity usefulness, main advantage, and main disadvantage for context:\n  - Utility: Measures the ability of a function class to fit random noise, providing a general sense of the capacity of the function class.\n  - Pro: Provides a general and well-understood measure of complexity that is applicable across various learning scenarios.\n  - Con: It may not be as directly relevant to transfer learning scenarios because it doesn't specifically account for the nuances of transferring knowledge from a source to a target task.\n- Given the specific requirements of transfer learning, which often involve understanding the relationship and distributional differences between source and target tasks, measures like Maximum Mean Discrepancy (MMD), Discrepancy Distance, and Task Similarity Measures become more pertinent. These measures are more directly aligned with the challenges of assessing how well a learned representation from one task can be applied to another, which is at the heart of transfer learning.\n- Rademacher complexity, while powerful in many learning theory contexts, does not explicitly address these transfer-specific concerns. Therefore, it's more suited to general learning scenarios rather than the specific complexities of transfer learning.\n- In fact, Gaussian complexity is somewhat similar but might be more suitable in certain contexts, especially in which approximately Gaussian assumptions naturally occur. Therefore, I again question the significance of this finding with Rademacher complexity in practice. \n\n4. Evaluations do not include baselines using Gaussian Complexity in-place of Rademacher Complexity even though Gaussian Complexity may empirically be more useful on some tasks here."
            },
            "questions": {
                "value": "1. What insights do you have as to what causes the issue brought up in \"We note that equation 5 is asymmetrical (i.e.  swapping \u03c4 with one of t \u2208 [T] can yield different diversity estimate.)   This is a desirable property since model transfer generally is not symmetrical (Sugiyama et al., 2007). Suppose we have the expert policies \u03c0,\u03c0\u2032 respectively for environments \u03c4,\u03c4\u2032.  while \u03c0 may stay performant in both \u03c4,\u03c4\u2032, \u03c0\u2032 may degrade when transferred to \u03c4.  We demonstrate this in appendix D where the expert from each environment variation exhibits different robustness\u2014one can stay performant in the target environment while another can degrade in performance.\"\n\n2. On Page 2, the paper states \"The consequence is that we can connect our result with deep-learning\ntheory, where the commonly used neural networks are quantified directly with Rademacher complexity (Bartlett et al., 2021).\"\n  a. Is this the best way to quantify neural network complexity here?\n  b. Could you expound on your answer to 2a?\n  c. What other options are available? \n\n3. Thoughts on using maximum mean discrepancy instead of Rademacher complexity?\n4. Thoughts on using discrepancy distances, as these are directly applicable in assessing transfer learning effectiveness.\n5. Thoughts on using local Rademacher complexities? This would be more nuanced and data-dependent though, and the Rademacher complexity avoids this nuance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I do not have ethics concerns with this work."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 6,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699617741497,
        "cdate": 1699617741497,
        "tmdate": 1699636251655,
        "mdate": 1699636251655,
        "license": "CC BY 4.0",
        "version": 2
    }
]