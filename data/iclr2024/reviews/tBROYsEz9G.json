[
    {
        "id": "p7rNiYdK4P",
        "forum": "tBROYsEz9G",
        "replyto": "tBROYsEz9G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_72Ff"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_72Ff"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for generating tabular data which respects some domain-specific conditions, by introducing the so-called Constraint Layers (CL), which can enforce linear constraints on the features of the generated data. CLs are tested on GAN models and the results on a selection of tabular problems with constraints show how they are effective at preventing generation of data which violates such constraints."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper presents an effective way to enforce linear constraints on (and between) variables for tabular data generated with deep Generative models. The manuscript is generally very clear and presents the contributions in great detail. The method is tested on a comprehensive set of problems and compared with three strong baselines."
            },
            "weaknesses": {
                "value": "From reading the paper, it is not immediately clear how the training procedure with CLs works, and whether CLs can be applied to other generative models, such as Variational Auto Encoders, Normalizing Flows or Diffusion Models. A comparison with methods such as TVAE and TabDDPM (mentioned in the related work) and the application of CLs to them would significantly strengthen the experimental section. A metric to compare the data distribution from the generated distribution is missing from the experiments. Would it be possible to include a metric such as negative log-likelihood or Wasserstein distance?"
            },
            "questions": {
                "value": "- Perhaps a point that I missed from the paper, but how do CLs affect the training? Can gradients backpropagate through these layers? Can CLs be applied to other Generative Models?\n- How does the application of CLs shift the distribution of the generated data? Does it result in an \"overpopulation\" of the regions on the boundaries? If that's the case, the resulting distribution would be skewed from the true distribution especially when the baseline model generates many samples which violate the constraints. Adding other metrics (see weaknesses) would help with investigating this matter.\n- Can CLs impose constraints between categorical variables, or between numerical and categorical variables? For example, if x1 = \"category 1\", then x2 > 5, or similar?\n- Are there cases in which assigning a valid variable ordering is not feasible?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Reviewer_72Ff",
                    "ICLR.cc/2024/Conference/Submission5393/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698770779858,
        "cdate": 1698770779858,
        "tmdate": 1700740275619,
        "mdate": 1700740275619,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EnMou140hz",
        "forum": "tBROYsEz9G",
        "replyto": "tBROYsEz9G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_ikQ7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_ikQ7"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates a lesser-explored challenge in the generation of tabular data\u2014adherence to specific rules or constraints for data entries. It highlights a common issue where existing generative models often fail to respect constraints such as linear inequalities (e.g., one column being less than or equal to another), as they are not designed to fulfill these conditions.\n\nTo address this, the paper introduces a novel approach to adding a constraint layer to standard DGMs, transforming them into constrained DGMs. The study demonstrates that these constrained DGMs are more effective in producing realistic data that adheres to the specified constraints, further improving downstream performance. Moreover, it shows that even applying these constraint satisfaction layers to a pre-trained DGM can significantly enhance the realism of the generated data.\n\nWhile the paper tackles an interesting issue, given the marginal novelty of the paper and the limited number of constraints in the datasets under consideration, I will not accept this paper. I would be willing to increase the score if the authors can provide reasonable answers to my concerns."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1) The paper is well-written and the idea is laid out with sufficient examples to follow through.\n2) Pointing out the fact that many DGMs violate obvious constraints in tabular data is very important and studying it is valuable.\n3) The experimental results seem thorough and the theory checks out."
            },
            "weaknesses": {
                "value": "1) **(Important)** The paper mentions the choice of $\\lambda(i) = i$ is for ease of notation, while different orderings can drastically change the performance of a C-DGM. As an illustrative example, consider tabular data with three outputs $\\langle x_1, x_2, x_3 \\rangle$ with constraints: $x_2 \\le 10$ and $x_1 \\le x_2 \\le x_3$. Now assume the generative model only produces $\\langle 10, 5, 5 \\rangle$. In this case, if the ordering $\\lambda = \\langle 1, 2, 3 \\rangle$ is considered, then $CL(\\tilde{x})$ would be $\\langle 10, 10, 10 \\rangle$ and if the ordering $\\lambda = \\langle 2, 1, 3 \\rangle$ is considered, then $ CL(\\tilde{x}) = \\langle 5,5,5 \\rangle$ with one being significantly closer to the generated distribution than the other. In fact, the notion of \u201coptimality\u201d is not well defined, as each ordering can produce a different optimal with none of them being comparable for defining an optimum. Moreover, the notion of optimality should also consider the discrepancy between the $CL(\\cdot)$ outputs and the generative samples to be minimal.\n2) **(Important)** I might have missed something but the reduction defined for constraints $\\Pi$ can easily turn the number of constraints exponential, meaning that $|\\Pi_1| \\in \\mathcal{O}(exp(|\\Pi|))$. The only reason the current experiments do not hinder the performance is that the number of conditions is fairly small, to begin with. I would require datasets with a much larger number of conditions to be convinced that the post hoc method does not impact the sample generation time.\n3) The paper only considers linear constraints. Even though it is pointed out as a limitation some extensions to non-linear constraints are quite simple. For example, by introducing polynomial features, one can add polynomial constraints to the current approach. Having one entire paper on linear constraints seems rather limited in novelty. I would suggest adding simple experiments as proof-of-concept for such extensions."
            },
            "questions": {
                "value": "1) Even though GANs have achieved popularity for image generation, they are known to fail drastically for tabular data generation. That said, is there any reason why other DGMs such as TVAEs, STaSy, and TabDDPM are not considered in this study given the current limitations of GANs? For a more compelling story, it would be good to include other types of generative models as well. Especially in the post hoc experiments.\n\n2) The reported charts and tables are thorough, but I wasn\u2019t able to find any source code for reproducibility and a footnote claims that the code will be released upon publishing; however, I didn\u2019t find anything to run in the supplementary material."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Reviewer_ikQ7"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698808512265,
        "cdate": 1698808512265,
        "tmdate": 1700671992627,
        "mdate": 1700671992627,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KxcpefK3HT",
        "forum": "tBROYsEz9G",
        "replyto": "tBROYsEz9G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_Yiht"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_Yiht"
        ],
        "content": {
            "summary": {
                "value": "Generating realistic tabular data requires compliance with constraints that encode essential background knowledge on the problem. In this paper, the authors address the limitation and show how deep generative models for tabular data can be transformed into constrained deep generative models, whose generative samples are guaranteed to be compliant with the given constraints. This is achieved by automatically parsing the constraints and transforming them into a constraint layer seamlessly integrated with the dgm. The authors shows the effectiveness of the proposed model with experiments on 6 datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The first to handle with the constraints of tabular data, and the method addressed the problem well."
            },
            "weaknesses": {
                "value": "Tabular data synthesis methods used for the experiments are outdated. Please consider [1] GOGGLE, [2] GReaT, [3] STaSy, [4] CoDi, and [5] TabDDPM if possible.\n\n\n[1] GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure, ICLR 2022\n\n[2] Language Models are Realistic Tabular Data Generators, NeurIPS 2021\n\n[3] Stasy: Score-based tabular data synthesis, ICLR 2022\n\n[4] CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis, ICML 2023\n\n[5] Tabddpm: Modelling tabular data with diffusion models, ICML 2023"
            },
            "questions": {
                "value": "How was the performance improvement of the state-of-the-art methods after applying the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Reviewer_Yiht"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826943445,
        "cdate": 1698826943445,
        "tmdate": 1699636545913,
        "mdate": 1699636545913,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hudTO1Aiqn",
        "forum": "tBROYsEz9G",
        "replyto": "tBROYsEz9G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_DAiC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5393/Reviewer_DAiC"
        ],
        "content": {
            "summary": {
                "value": "The main contribution of this paper is to add constraints on generating synthetic data so that it is aligned with available background knowledge. The paper introduces constraint layers in order to enforce a set of linear constraints that encode the background knowledge. They also prove the correctness of the constraint layers introduced"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The motivation behind the paper is clear and easy to follow. The paper also offers some theoretical justification for their method which makes their paper compelling. The proofs from what I can see are correct. The experiments are well formulated and support the claims of the paper."
            },
            "weaknesses": {
                "value": "The issue with the paper is the proofs can be difficult to follow. It is possible that the authors can spend more time rewording it to make it easier to flow. This also makes it a bit hard to flow and check."
            },
            "questions": {
                "value": "This isn't really a question but I think the use of linear constraints can be advantageous as they are logically complete. Any inconsistency can be identified easily through Farkas's lemma. I think the authors can potentially frame the use of linear constraints in a better light to highlight how its logical completeness can be useful when specifying background knowledge."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5393/Reviewer_DAiC"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5393/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699320777801,
        "cdate": 1699320777801,
        "tmdate": 1699636545786,
        "mdate": 1699636545786,
        "license": "CC BY 4.0",
        "version": 2
    }
]