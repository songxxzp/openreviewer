[
    {
        "id": "yOMnCTLUS8",
        "forum": "d3xKPQVjSc",
        "replyto": "d3xKPQVjSc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_FevT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_FevT"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses a setting where a representation function $\\phi(X)$, (a generalization of propensity score $\\pi(X)$), is available while part of X is unobservable. That is, instead of following the typical approach of choosing X from only observables (expecting $\\phi(X)$ to be a balancing score) and discussing the potential effects of unobservable covariates, they follow the approach of considering X as all covariates including even unobservable covariates. At the same time, they assume that $\\phi(X)$ value is available (while part of X is not observable)\n\nIn the typical approach, when we cannot assume that $\\phi(X)$ is a balancing score, we may suffer confounding bias. In the exact same way in their approach, when we cannot assume that $\\phi(X)$ (in their case it is called the representation function) includes enough information about unobservable covariates, we may suffer a bias. (in their case it is called the representation-induced confounding bias or RICB)\n\nThe authors identify RICB, and propose a technique to estimate the bound.\nComprehensive simulation studies were followed."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Simulation studies are quite comprehensive.\nTheoretical bounds has been proposed. \nThe paper is very well written. It was pleasant to read."
            },
            "weaknesses": {
                "value": "\\textbf{1. Motivation of their approach}\n\nAs discussed in the Summary part of this review, for me it was hard to understand why we need a new approach of choosing X. The concept of RICB is, in essence, equivalent to confounder bias but formulated in a different choice of X. For example, in the traditional way of choosing X as only unobservables and talking about $\\phi(X)$ not being a balancing score, potential effect of unobservable covariates not being included as X can be discussed. So I am not sure about the potential benefit of choosing X to include unobservable covariates.\n\n\\textbf{2. Bounds}\nTheoretical bounds provided should be appreciated, but I cannot be sure how strong this theoretical bound is only from current version of the manuscript."
            },
            "questions": {
                "value": "In terms of Weakness 1: Could you please give a clear motivation of choosing X to include unobservable but considering $\\phi(X)$ as observable, and then reframing the confounder bias we know as RICB in the newly proposed setting? Does the fact that we are dealing with representation learning make some difference? I just want to try to understand.\n\nIn terms of Weakness 2: How tight is the bound for some popular special cases, especially for the settings you did your experiment? Are they practically good?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)"
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Reviewer_FevT"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I went to check out [4] Alicia Curth and Mihaela van der Schaar. On inductive biases for heterogeneous treatment effect estimation. Advances in Neural Information Processing Systems, 2021a. Here is the assumption 1 I found.\n\nAssumption 1. [Consistency, unconfoundedness and overlap] Consistency: If individual i is assigned treatment $w_i$, we observe the associated potential outcome $Y_i=Y_i\\left(w_i\\right)$. Unconfoundedness: there are no unobserved confounders, so that $Y(0), Y(1) \\Perp W \\mid X$. Overlap: treatment assignment is non-deterministic, i.e. $0<\\pi(x)<1, \\forall x \\in \\mathcal{X}$.\n\nI think they don't assume that all confounders are observed inside X.\n\nI believe that the authors not only are failing to answer the question, but they tried to support the motivation of their setting by providing a misinformation. I strongly believe that this paper should be rejected."
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5647/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698437071859,
        "cdate": 1698437071859,
        "tmdate": 1701036460587,
        "mdate": 1701036460587,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "64yud8sH9Y",
        "forum": "d3xKPQVjSc",
        "replyto": "d3xKPQVjSc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_8op8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_8op8"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles the problem of confounding bias induced by learning representation of confounder for CATE estimation. The authors proposed a framework for estimating bounds on the induced confounding bias. A neural framework is used to compute the bounds."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper presents a problem that is novel and related to the representation of learning for CATE, which is a prominent research direction.\n- A detailed analysis of representation-induced bias is provided.\n- Both real-world and synthetic experiments are performed with the proposed framework."
            },
            "weaknesses": {
                "value": "- The motivation for employing CDAG is not quite clear. \n- No theoretical proof of the proposed bounds."
            },
            "questions": {
                "value": "- Could you provide some intuition about learning the representation of all the covariates together instead of the confounder?\n- If learning representation of covariates inducing bias is unavoidable, how does the bias compare with bias due to finite-sample? e.g., How does it compare with the non-representation learning approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Reviewer_8op8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5647/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735322392,
        "cdate": 1698735322392,
        "tmdate": 1699636587057,
        "mdate": 1699636587057,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6o4NvmhuzD",
        "forum": "d3xKPQVjSc",
        "replyto": "d3xKPQVjSc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_Pw4L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_Pw4L"
        ],
        "content": {
            "summary": {
                "value": "Estimating conditional average treatment effect (CATE) estimation widely uses low-dimensional representation learning, which can lose information about the observed confounders and thus lead to bias.\nIn this paper, the authors propose a new framework for estimating bounds on the representation-induced confounding bias (RICB). To summarize, the contributions are three-fold:\n1.\tCATE from representation learning methods can be non-identifiable due to RICB.\n2.\tThe authors propose a representation-agnostic framework to perform partial identification of CATE.\n3.\tThe authors demonstrate the effectiveness of our bounds together with a wide range of state-of-the-art CATE methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is technically sound and well-organized."
            },
            "weaknesses": {
                "value": "It seems that the notations/symbols are not defined correctly. For example, in the section of notations, the authors claim that $\\mu_a^x(x)=\\mathbb{E}(Y|A=1,X=x)$, but $\\mu_a^x(x)$ should be $\\mathbb{E}(Y|A=a,X=x)$. In the same paragraph, the authors claim that $\\mu_a^\\phi(\\phi)=\\mathbb{E}(Y|A=1,\\Phi(X)=\\phi)$, but $\\mu_a^\\phi(\\phi)$ should be $\\mathbb{E}(Y|A=a,\\Phi(X)=\\phi)$. In addition, the authors define $\\pi_a^x(x)= \\mathbb{P}(A=a|X=x)$. I wonder why the authors do not simply $\\pi_a^x$ or $\\pi_a(x)$. Problem arises when the authors introduce overlap assumption. The authors claim that $\\mathbb{P}(0<\\pi_a^x(X)<1)=1$, but I cannot obtain $\\pi_a^x(X)$ from the definition. Indeed, in the definition of $\\pi_a^x(x)= \\mathbb{P}(A=a|X=x)$, The two \u201cx\u201ds in $\\pi_a^x(x)$ should be mapped to \u201cx\u201d in $\\mathbb{P}(A=a|X=x)$. Nevertheless, when $\\pi_a^x(x)$ is changed to $\\pi_a^x(X)$ or $\\pi_a^X(x)$, the mapping procedure is not clear."
            },
            "questions": {
                "value": "1. According to the definition of $X$, $X=\\{X^\\emptyset,X^a,X^y,X^\\bigtriangleup\\}$. At the same time, $X$ is independent of $X^\\emptyset$, $X^a$, $X^y$ ,$X^\\bigtriangleup$ conditioning to $\\Phi(X)$. It is strange to claim Eqn. (4).\n2. In the example \u201cRepresentations with removed noise and instruments\u201d, the authors claim that under Eqn. (5), the validity follows from the d-separation in clustered casual diagram and Appendix B. In appendix B, only investigations related to the example \u201cInvertible representations\u201d are presented.\n3. I suspect the equality of $\\mathbb{E}(Y[1]-Y[0]|X=x)=\\mathbb{E}(Y[1]-Y[0]|X^\\bigtriangleup=x^\\bigtriangleup, X^y=x^y)$ and $\\mathbb{E}(Y[1]-Y[0]|X^\\bigtriangleup=x^\\bigtriangleup, X^y=x^y)= \\mathbb{E}(Y[1]-Y[0]|\\Phi(X)=\\Phi(x) $ in Eqn. (6) under Eqn. (5). Could the authors provide more details?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5647/Reviewer_Pw4L"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5647/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740826348,
        "cdate": 1698740826348,
        "tmdate": 1699636586962,
        "mdate": 1699636586962,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "58NqmYT85N",
        "forum": "d3xKPQVjSc",
        "replyto": "d3xKPQVjSc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_a9aZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5647/Reviewer_a9aZ"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the problem of induced confounding that occurs in neural network based conditional average treatment effect estimation as a result of representation learning that operates over a lossy reduced dimension embedding. The authors propose to account for the confounding by leveraging sensitivity analysis. In particular the authors use the marginal sensitivity model and provide bounds on the CATE. A framework is then introduced to estimate the proposed bound within a neural network training flow. A set of experiments are provided which validate the efficacy of the proposed approach."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This paper addresses a very important, and often overlooked, aspect of representation learning for causal effect estimation. The authors do a commendable job of describing the circumstances under which we should expect to incur bias due to representation induced confounding, and clearly delineate them from existing approaches which don't suffer from the same issues. The proposed sensitivity analysis is intuitive and the authors do a nice job of describing it's integration into the neural network training process."
            },
            "weaknesses": {
                "value": "The largest weakness I see is the same as what is commonly shared throughout the sensitivity analysis literature, namely that practitioners must place assumptions on the extent of confounding."
            },
            "questions": {
                "value": "Given the relative difficulty of CATE estimation in small sample regimes, as the authors point to, it would seem that there are a number of settings where representation based CATE estimation is inappropriate. Given this it would be useful for the authors to compare the bounds provided here and contrast to non-NN based approaches (e.g., BART / causal forests) to give a sense of the relative loss in precision due to the representation induced confounding."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5647/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699399082803,
        "cdate": 1699399082803,
        "tmdate": 1699636586871,
        "mdate": 1699636586871,
        "license": "CC BY 4.0",
        "version": 2
    }
]