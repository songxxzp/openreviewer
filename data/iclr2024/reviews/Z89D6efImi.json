[
    {
        "id": "1AkTSE0BUV",
        "forum": "Z89D6efImi",
        "replyto": "Z89D6efImi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_hxLh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_hxLh"
        ],
        "content": {
            "summary": {
                "value": "Well-known uncalibrated deep photometric stereo works generally rely on the two-stage pipeline, i.e., in the first stage, they predict light source, and in the second stage, they infer surface normals. On the contrary, this paper proposes a one-stage deep neural network pipeline resorting to the well-known Fourier transform of images. The paper further claims that the amplitude and phase of the transformed images can provide useful cues to estimate light, thereby avoiding the need to learn light sources in the photometric stereo setup explicitly. Experiments on conventional benchmark datasets are conducted to show the suitability of the proposed pipeline."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* An attempt to overcome the two-stage approach to uncalibrated photometric stereo problem.\n* Using the ideas from signal processing domain to a classical computer vision problem is compelling."
            },
            "weaknesses": {
                "value": "* The authors do not provide a theoretical backup on the phase and amplitude swap argument presented in the paper.\n* Since the paper is a one-shot, the paper should have conducted experiments showing that the current method could also help resolve GBR. No such experiments or theories are presented in the paper.\n* No training time comparison, memory footprint, or model complexity comparisons are provided in the paper.\n* Despite paper claims to be suitable for non-Lambertian objects,  it is not justified why such an approach is more suitable for non-Lambertian objects.\n* Performance is inferior to previous art, not a major weakness, but a weakness nonetheless.\n* Paper is not well-written. Furthermore, visual presentation must be improved, for instance Fig. 1 is too small to visualize the presented idea. On equations, the dimension of the introduced variables is missing.\n\nRefer Questions section for detailed comments."
            },
            "questions": {
                "value": "## Abstract \n* \u201cfewer interpretations\u201d -> I request the authors to clarify what kind of interpretations we are talking about.\n* two-stage methods discretize the light direction estimations instead of regressing exact light directions due to the learning difficulty and instability. -> In fact the lights placed in the photometric stereo experimental setup are indeed discrete in nature. So I don\u2019t see a problem with previous methods in making such a choice. Furthemore, I don\u2019t see discrete light modeling could lead to instability. Please comment. Also, I request to kindly be specific on the statements made in the paper.\n* \u201cdecomposing inputs\u201d -> what is input here. Please be specific.\n* Inconsistent use of \u201csurface normals\u201d and \u201cshape\u201d throughout. It's better to be consistent.  Go either with surface normal or shape. I recommend using surface normals.\n\n\n\n## Introduction\n* under multiple images -> using multiple images\n* with different lights  -> lights are generally of the similar intensity level. So, not really different in nature.Yet, with many such LEDs/light sources placed at a distance from the object.  Please be on-point.\n* Compared with geometric stereo methods -> Firstly, add citations. Secondly, I believe it should be \u201cgeometric multi-view stereo\u201d methods.\n* high-frequency details on objects\u2019 surfaces -> add citations.\n* owing to the powerful capabilities of deep neural net -> what capabilities of deep neural network?\n* inputting -> using. It is good to be formal.\n\nGeneral Comment on Introduction:\nFollowing up on the claims made in the abstract related to the non-Lambertian objects, refer to the very first line of the abstract. It is not justified in the introduction as to why such a method is more suitable for non-Lambertian objects. I don\u2019t see any arguments placed by the authors in this regard. From the introduction what is clear to me is that the authors are proposing a method to suitably estimate surface normal without a need to explicitly learn lights using PS images. Kindly comment and refine the introduction accordingly.\n\n\n## Method\n* \u201cTheoretically, the shape cues can be extracted solely from the amplitude spectrum\u201d. Please add citations. I am really looking forward to a proof of this. Furthermore, I am interested in a test that could verify the argument presented in the paper for inter-reflecting symmetric objects like vase, refer Kaya et al. 2021 dataset. Moreover, I would like to see a theoretical backup on the phase and amplitude swap argument presented in paper. To be mindful, the product \u2014normal.light ($N^T \\cdot L$), the standard PS equation, will turn to convolutions in the fourier domain, referring to the modulation property of the fourier transform.\n\n* \u201cWe argue that spatial domain with convolutional layers can effectively model structural dependencies, while the Fourier domain can attend to global information and facilitate the disentanglement of shape and light\u201d. I am not completely satisfied by the later part of this statement. Fourier transform indeed can have global information, but does that facilitate disentanglement? Amplitude and phase of light has also to do with light intensity, occlusion, interreflection, polarization, etc. I further see a clear relation to the spherical harmonics theory in estimating normals from images referring to Basri and Jacobs TPAMI 2003, Ramamoorthi and Hanrahan 2001. Unfortunately, these works are not discussed in this paper.\n\n## Evaluation and Benchmark\n* The performance is clearly inferior to the previous art in uncalibrated PS. Also, the paper must conduct experiments on the Kaya et al. 2021 dataset, which to me is more challenging to validate the paper\u2019s claims.\n* Since the paper is one-shot, they should have conducted the experiments showing that the current method could also help resolve GBR. No such experiments or theories are presented in the paper.\n* No train time and test time comparison, memory footprint and model complexity comparisons are provided in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The paper appears to have no ethical concerns."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698316105043,
        "cdate": 1698316105043,
        "tmdate": 1699636043369,
        "mdate": 1699636043369,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FTMd15tHdL",
        "forum": "Z89D6efImi",
        "replyto": "Z89D6efImi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_xXVv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_xXVv"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a one-stage deep uncalibrated photometric stereo network, named UPS-FourNet, for non-Lambertian objects.The authors first present their observation that light and shape information can be decomposed to a certain extent into the phase and amplitude in the Fourier domain. Based on this observarion,  they propose the Fourier Embedding (FourE) block to extract features simultaneously from the amplitude and phase in the Fourier domain along with feature enhancement in the spatial domain, and the Fourier Embedding Aggregation (FourAgg) block to aggregate the amplitude and the phase features, respectively, from multiple photometric stereo images for direct normal regression without explicitly estimating light directions. Experiments show competitive performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The obsevation that light and shape information can be partially decomposed into phase and amplitude in the Fourier domain sounds novel. This can be helpful in the design of UPS methods.\n- The proposed method is end-to-end and can regress normal directly without explicit light estimation.\n- Aggregating amplitude and phase features separately from multiple photometric stereo images sounds novel.\n- Experimental results show improvements over existing one-stage UPS methods, which are also comparable to two-stage methods.\n- Ablation study has been carried out to evaluate the effectiveness of the core components in the proposed method."
            },
            "weaknesses": {
                "value": "- The idea of embedding Fourier transform into deep networks is not new. The FourE block basically has the same architecture as the FouSpa block in UHDFour [Li et al. 2023], and the FourAgg block simply performs separate amplitude and phase features aggregation which is a simple logical choice for feature fusion in the Fourier domain.\n- The proposed one-stage method only focuses on normal regression and cannot recover light information. It is also not clear whether or not the input photometric images have been normalized by the input light intensities. \n- Some claims are not well supported such as the decomposition of the shape and light and the role of Fourier/spatial domain. \n- Other than performing feature extraction in the Fourier domain, the proposed design does not seem to have fully exploit the observation presented by the authors.\n- The evaluations are not comprehensive and detailed enough.\n\n[Li et al. 2023] Chongyi Li, Chun-Le Guo, Zhexin Liang, Shangchen Zhou, Ruicheng Feng, Chen Change Loy, et al. Embedding fourier for ultra-high-definition low-light image enhancement. In ICLR, 2023."
            },
            "questions": {
                "value": "- The claim in Section 3.1 is not well supported. From Figure 1 it can be observed that the shading or lighting variance information is included in phase spectrum. However, it cannot demonstrate the shape information is encoded in amplitude spectrum, as the shapes of the two images are the same. The authors of [Li et al. 2023] also performed the same analysis and arrived at a slightly different conclusion. Are their conclusion compitable with the one drawn in this paper? If not, what leads to the differences?\n- In Section 3.3, it said \u201cWe argue that spatial domain with convolutional layers can effectively model structural dependencies, while the Fourier domain can attend to global information and facilitate the disentanglement of shape and light.\u201d However, there\u2019s no analysis to support this claim. The authors should try to analyze their roles with visualizations.\n- The actual effects of the submodules are not clear enough and not analyzed in detail. It\u2019s better to visualize the sequential feature maps in both Fourier and spatial domain to better support the claims. \n- What\u2019s the training and testing time compared to the existing one/two-stage UPS methods?\n- The ablation study is incomplete. For instance, what\u2019s the performance of \u201cw/o normalization\u201d, \u201cw/o dense block\u201d, \u201cw/o MAP\u201d, etc.?\n- What if only amplitude information or only phase information is considered in the framework? \n- What\u2019s the performance of the proposed method with different number of input images in test time? What is the minimium number of images for getting a plausible prediction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698381621956,
        "cdate": 1698381621956,
        "tmdate": 1699636043290,
        "mdate": 1699636043290,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tXv4PUQRDY",
        "forum": "Z89D6efImi",
        "replyto": "Z89D6efImi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_pDmL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_pDmL"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a Fourier transform-based approach to the uncalibrated photometric stereo problem. This method bypasses the estimation of light direction and directly estimates the surface normal, referred to as a \"one-stage\" process. A central contention of this paper is that the proposed UPS-FourNet implicitly discerns lighting by decomposing inputs using an embedded Fourier transform.\nAuthors claim that the lighting information is primarily concentrated in phases, while shape information correlates strongly with amplitudes. Subsequently, a neural network is designed to learn from these features, achieving results that are competitive with prior works."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The concept of processing amplitudes and phases in two distinct branches and merging them at the end is innovative. However, the paper contains several uncertainties and unsupported claims."
            },
            "weaknesses": {
                "value": "One-stage vs. Two-stages: I respectfully disagree with one of the primary assertions in the paper that the \"one-stage\" UPS method is superior to the \"two-stage\" UPS method. The two-stage UPS methods referenced in this paper treat light direction estimation as a byproduct, which can be advantageous for many downstream tasks. \n\nI agree with that most two-stage methods suffer from inaccurate light estimation, which can consequently introduce errors into the normal estimation stage.\nHowever, some recent works, such as LL22b, have managed to simultaneously optimize the light direction, resulting in enhanced normal/light estimation comparable in accuracy to calibrated photometric stereo. Thus, I am of the opinion that simultaneous estimation of light direction and normal isn't necessarily a drawback.\n\nThe paper's assertion\u2014that \"lighting information predominantly concentrates on phases while shape information is closely related to amplitudes of the Fourier domain\"\u2014lacks sufficient evidence. From Fig 1, it's not evident whether phases indeed yield more lighting information than amplitudes. To further substantiate this claim, I recommend that the authors conduct an ablation study: discard the amplitude branch and observe the affected regions of the object, then do the same for phases. The quantitative assessment in Tab1 is insufficient; additional visualizations would aid readers in gaining a clearer understanding.\n\nThe selection of max pooling and average pooling in the FourAgg block lacks proper validation. The quantitative assessment in Tab1 is insufficient to substantiate the authors' claim in Sec-3.4, at the top of page 6, which states: \"Max pooling emphasizes amplitude features, ... thus enhancing the representation of shape information. ... Average pooling is employed to diminish the influence of phase features, ... aiding in reducing the ambiguity of light directions.\" More visual evidence is needed to validate this assertion. For instance, the authors could illustrate which features are captured by each pooling operation and how these learned features influence the final results in specific regions.\n\nThere appears to be a typo error at the beginning of page 7, where it reads, \"For the FourE block, we remove the Fourier domain (#1), and remove the spatial domain (#2),\" when Tab 1 indicates the opposite."
            },
            "questions": {
                "value": "In summary, many of the claims in this paper are not well substantiated, and much of its insights appear to be more empirical than theoretical, making them potentially less generalizable to subsequent studies or works in other areas. Consequently, I lean towards not accepting this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698725211114,
        "cdate": 1698725211114,
        "tmdate": 1699636043213,
        "mdate": 1699636043213,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "18Nt1CAWxI",
        "forum": "Z89D6efImi",
        "replyto": "Z89D6efImi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_rCYN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1169/Reviewer_rCYN"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a one-stage uncalibrated photometric stereo method based on Fourier transform. Two modules are designed to accomplish this task, namely, Fourier Embedding block which extracts features from Fourier domain and spatial domain and Fourier embeddingaggregation block which is designed to fuse features extracted from multiple inputs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The observation that shape and lighting can be decomposed through Fourier transform is interesting and worth further exploring."
            },
            "weaknesses": {
                "value": "Though the observation is interesting, it lacks enough theoretical and experimental proof to make it a solid contribution.\n\nThe proposed method also can\u2019t achieve SOTA results on DiLiGenT dataset when compared to 2-stage UPS methods."
            },
            "questions": {
                "value": "Though the observation seems to be interesting and somewhat promising. It still needs more proof, either theoretical or experimental, to understand why and how much Fourier transform can help the decomposition of shape and lighting cue. \n\nAlso, Since the results is good but not best, the claimed advantages over 2-stage UPS methods are weak according to my opinion. So given the current state of the work, it\u2019s premature to be published on ICLR."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698768681580,
        "cdate": 1698768681580,
        "tmdate": 1699636043120,
        "mdate": 1699636043120,
        "license": "CC BY 4.0",
        "version": 2
    }
]