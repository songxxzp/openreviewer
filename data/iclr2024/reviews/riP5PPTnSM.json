[
    {
        "id": "5YxV8LwbqO",
        "forum": "riP5PPTnSM",
        "replyto": "riP5PPTnSM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_VDA7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_VDA7"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to adapt a frozen LLM for dense retrieval, by training a shallow (3-layer) adaptor transformer. In particular, for a given LLM, they employ the alignment and uniformity analysis (Wang and Isola, 2020) to find the layers with the best \"alignment\" and \"uniformity\", which become the input of the adaptor transformer. The adaptor transformer then leverages self- and cross-attention to fuse the hidden representations from these two layers, and produces a single dense vector as its final output for retrieval.\n\nThe proposed LMORT method is evaluated on 6 BEIR datasets (which were also used for the alignment and uniformity analysis). The authors show that LMORT works with different LLMs, up to GPT-j-6B, outperforming baseline using a single layer (e.g. best alignment layer, best uniformity layer, or embedding layer). When using GPT-j-6B, it also outperforms baseline DRs such as BM25 and DPR (although it misses comparison with, and performs worse than, more recent DRs in the literature such as Contriever and DRAGON). It also performs worse than cpt-text-L (GPT3-6B) in general, but cpt-text-L finetunes the entire LLM while LMORT trains a shallow adaptor while freezing the LLM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of adapting a frozen LLM for dense retrieval using a shallow transformer is interesting, and leveraging multiple layers from the LLM based on alignment and uniformity analysis is a sound approach.\n\n- Experiments show that the proposed approach indeed works with multiple LLMs of various sizes, and outperforms simpler baseline approaches that utilize a single layer."
            },
            "weaknesses": {
                "value": "- The same 6 BEIR datasets used for evaluation are also used in the alignment and uniformity analysis, which violates the zero-shot setting of BEIR and makes the comparison unfair with the other retrievers. The authors should at least evaluate on additional datasets that were not seen during the analysis. Otherwise, the gain from this alignment and uniformity analysis may have been attained from fitting to the test set.\n\n- The paper does not compare with more recent DRs, which achieve comparable or much higher accuracy than the proposed method despite using much smaller encoders. For example, Contriever-MSMARCO (https://arxiv.org/abs/2112.09118) achieves an average of 0.424 NDCG@10 on the 6 BEIR tasks, whereas the more recent DRAGON model (https://arxiv.org/abs/2302.07452) achieves 0.460 on average. Both models are BERT-base models, which is 50x smaller than the GPT-j-6B used in this work, yet DRAGON outperforms LMORT by 3.5 points on average in NDCG.\n\n- While the proposed method is interesting, I find it difficult to justify its practical use. If it is intended to use as a standalone dense retriever, it performs significantly worse than many recent DRs while using a 50x larger encoder, which makes the embeddings much larger (due to higher dimensionality) and latency much higher.\nAn unexplored alternative application would have been more appealing, which is retrieval-augmented generation (RAG). By adapting a frozen LLM for retrieval, it would indeed be cheaper to encode the queries and can be applied to methods such as kNN-LM (https://arxiv.org/abs/1911.00172). Unfortunately, this direction is not examined in this paper."
            },
            "questions": {
                "value": "- Table 2 compares only with LMORT variants that use a single layer (or two) of the LLM. Have you compared with additional baselines of fusing more layers of the LLMs (either via attention similar to that in LMORT, or via simpler pooling mechanisms)?\nHave you also tried layer selecting methods not based on alignment or uniformity? For instance, choosing first and last layer?\n\n- Why do you only evaluate on 6 datasets from BEIR out of 18? It is unclear to me why the rest of BEIR is omitted and makes the results less convincing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698085792128,
        "cdate": 1698085792128,
        "tmdate": 1699636034948,
        "mdate": 1699636034948,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Aah9xFbtsJ",
        "forum": "riP5PPTnSM",
        "replyto": "riP5PPTnSM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_Zx7X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_Zx7X"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an attempt to merge Dense Retrieval (DR) with Large Language Models (LLM) like GPT-3 and GPT-4, aiming to enhance LLM's memory capacity. At its core, the challenge remains the disconnect between LLM text generation and DR. The authors introduce the LLM-Oriented Retrieval Tuner (LMORT) as a solution, suggesting it can integrate LLM and DR without altering the LLM. Through their analysis, they emphasize the tension between alignment and uniformity within LLM layers, implying that achieving one often comes at the expense of the other.\n\nTheir proposed LMORT method, built on a Transformer-like structure, claims to strike a balance between alignment and uniformity by synergizing the best features of LLM's representation space. Extensive tests on six BEIR datasets are presented as evidence, with results indicating that LMORT's zero-shot retrieval performance improves by 13% as the LLM size increases. However, when compared against robust DR models, LMORT's advantages seem less pronounced, only slightly edging out competitors with minimal layer tuning. While the authors highlight LMORT's efficiency in harnessing LLM's strengths and mitigating their incompatibilities, the presented reductions in training parameters and time raise questions about possible trade-offs. The paper, while presenting an intriguing approach, requires a more comprehensive exploration and validation to truly ascertain LMORT\u2019s potential in the DR landscape."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. LMORT's bidirectional attention sub-layers are an interesting twist on the usual Transformer setup. It's evident they're trying something new by pulling in features from LLM\u2019s alignment and uniformity layers. The idea of mixing and matching these layers is creative, though I remain unconvinced about how revolutionary this really is.\n\n2. One thing I've got to appreciate about LMORT is its aim for a leaner model. They've tried to cut back on unnecessary layers, which could mean it's efficient. The dense vector output is a clear nod towards streamlining, but whether it's a game-changer for dense retrieval is a question I still have.\n\n3. LMORT is trying to bridge the existing capabilities of LLMs for dense retrieval tasks. It's commendable that they\u2019re looking for synergy and not attempting to reinvent everything from scratch. But again, whether it truly harmonizes the best of both worlds is something I believe time (and rigorous testing) will reveal."
            },
            "weaknesses": {
                "value": "1. The objective function of LMORT, given by:\n$$\n\\theta^* = \\text{argmin}_{\\theta} \\sum_{X_q \\in Q} \\sum_{X^+ \\in C^+_{X_q}} -\\log \\left( \\frac{ \\exp(\\text{sim}(X_q, X^+; \\theta, \\tilde{\\phi}_{llm}))}{\\exp(\\text{sim}(X_q, X^+; \\theta, \\tilde{\\phi}_{llm})) + \\sum_{X^-_p \\in C^-_{X_q}} \\exp(\\text{sim}(X_q, X^-_p; \\theta, \\tilde{\\phi}_{llm}))} \\right)\n$$  \nseems to treat all negative pairs equally, pushing their similarity scores toward 0. This could result in a lack of nuanced understanding of varying degrees of negativity or irrelevance among samples. Consequently, as `top_k` retrieval results increase, this undifferentiated approach may adversely affect the precision and relevance of retrieval results, leading to poorer model performance in larger retrieval tasks.\n\n\n2. The method relies heavily on the frozen LLM, which might constrain the adaptability of the LMORT in diverse real-world retrieval scenarios where the underlying pretrained model isn't perfectly aligned with the task at hand.\n\n3. The paper doesn't seem to discuss or account for potential edge cases where the bifurcation between alignment and uniformity layers might cause misrepresentations or omissions of critical data."
            },
            "questions": {
                "value": "**Questions:**\n\n1. Within the objective function, there's a pronounced use of the negative logarithm operating on an exponential function related to similarity measures. This raises concerns:\n\\[ \n\\theta^* = \\text{argmin}_{\\theta} \\sum_{X_q \\in Q} \\sum_{X^+ \\in C^+_{X_q}} -\\log \\left( \\frac{ \\exp(\\text{sim}(X_q, X^+; \\theta, \\tilde{\\phi}_{llm}))}{\\exp(\\text{sim}(X_q, X^+; \\theta, \\tilde{\\phi}_{llm})) + \\sum_{X^-_p \\in C^-_{X_q}} \\exp(\\text{sim}(X_q, X^-_p; \\theta, \\tilde{\\phi}_{llm}))} \\right)\n\\]  \n   Could this cause potential issues in terms of stability or convergence, especially with extremely high or low similarity scores?\n\n2. Is there a comparative analysis with other retrieval methods in terms of computational resources and time? If not, wouldn't this be essential to truly claim the efficiency of the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698667206092,
        "cdate": 1698667206092,
        "tmdate": 1699636034857,
        "mdate": 1699636034857,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BJvjaGpAgL",
        "forum": "riP5PPTnSM",
        "replyto": "riP5PPTnSM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_CcZQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_CcZQ"
        ],
        "content": {
            "summary": {
                "value": "Due to the paradigm discrepancy between text generation of LLM and DR, it is still an open challenge to integrate the retrieval and generation tasks in a shared LLM.\n\nThe paper proposes an efficient LLM-Oriented Retrieval Tuner (LMORT), which decouples DR capacity from base LLM and non-invasively coordinates the optimally aligned and uniform layers of the LLM towards a unified DR space, achieving an efficient and effective DR without tuning the LLM itself. The proposed method could achieve competitive zero-shot retrieval performance compared to a range of strong DR models while maintaining the generation ability of LLM."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The studied problem is an emerging topic in LLMs.\n\n(2) The proposed method has good intuitions.\n\n(3) The paper is well presented and written."
            },
            "weaknesses": {
                "value": "(1) The paper may further explore the capability of the proposed method, when using other (larger) LLMs, such as Llama 2 and falcon (or Flan-T5). The behavior of different LLMs may vary. Although the paper claims general contributions to 'LLM-Oriented Retrieval Tuner', limited LLMs are used in the evaluation.\n\n(2) The paper may further discuss the additional latency by the proposed approach. When using a larger model, such as Llama 2, will the proposed method's retrieval and inference latency/cost be much higher, compared to some baselines?\n\n(3) The designed approach seems to rely on the assumption that the LLM models can be accessed. Currently, there are very powerful LLMs which only provides API, where the proposed method can not be directly applied?\n\nConsidering (2) and (3), for the practical use purpose, it might be unclear whether 'integrate the retrieval and generation tasks in a shared LLM' is an prominent direction to explore in general."
            },
            "questions": {
                "value": "(1) Can the proposed work in some more recent LLMs (e.g., Llama 2 or falcon)? Although the paper claims general contributions to 'LLM-Oriented Retrieval Tuner', limited LLMs are used in the evaluation.\n\n(2) When using a larger model, such as Llama 2, will the proposed method's retrieval and inference latency/cost be much higher, compared to some baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699167432195,
        "cdate": 1699167432195,
        "tmdate": 1699636034780,
        "mdate": 1699636034780,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vR9c84Y0Gm",
        "forum": "riP5PPTnSM",
        "replyto": "riP5PPTnSM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_XYMY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1086/Reviewer_XYMY"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new method, LMORT, to adapt large language models (e.g., GPT-2 Large, GPT-2 XL, GPT-j-6B) for retrieval tasks, by inserting new LMORT layers taking intermediate representations of two layers in the original LLM, which are selected based on their uniform loss and alignment loss. The experimental method shows that their final model outperforms their four ablated LMORT versions, while still largely lagging behind other methods, including BM25 and DPR. \nI have several major concerns about this paper. First, for me the motivations (unifying alignment and uniformity of LLM representation spaces) itself as well as the connection between the motivation and the proposed method is unclear. Also, experimental results are weak and lack baselines, which do not provide convincing results to support the proposed method. \nWhile it is not a major concern, there are several minor issues in writing (e.g., citation formats, abbreviation, introduction). I discussed this in detail in weaknesses. Overall, I don't recommend acceptance in the current form."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is easy to follow\n- Interesting observations about different layer repersentaitons of LLMs in text retrieval tasks."
            },
            "weaknesses": {
                "value": "1. **Unclear motivations and lack of the connections between the motivations and the proposed method design**: I understand that alignment matters in text retrieval but why does uniformity matter? While the authors cited Wang and Isola (2020) briefly, papers should be self-containing and as the cited prior work focuses on non-text domains, more careful consideration and discussions on whether this assumption holds in the text retrieval task should be discussed more. if the final goal based on this motivation is to make the two properties distributed across different layers, why adding the proposed layers can be an effective solutions? Are there any alternative solutions? For instance, several work introduces a new objective to align different layers in transformers. I think this proposed method could be one solution, but explanations on why this is the best way to the discussed issue should be included. \n\n2. **Weak experimental results and lack of baselines**: \nThe proposed method largely lags behind other retrieval models, including BM25 or DPR. Moreover, methods such as Contriever-MSMARCO (similar size as DPR, bert-base) have shown even much better performance than the listed baselines. While the authors claim this proposed method only added a few layers to be updated, how many parameters are exactly updated during training? Even with full parameter updates, if the base model is BERT-base, still the number of the trainable parameters can be less than the proposed method based on 6B LMs. Moreover, billions of parameters (both frozen and trained) are used during inference, which can significantly increase the inference costs. Also, what happens if we simply insert adapters and only update adapter layers during training?"
            },
            "questions": {
                "value": "- Have you compared the proposed method with a baseline which simply inserts adapter layers to GPT2 or GPT--6B? \n\nMinor typos & writing suggestions\n- According to the ICLR template guide, unless the citation is a part of the text (e.g., X et al. (2028) found), the citations should be in parenthesis using \\verb|\\citep{}| (as in ``Deep learning shows promise to make progress\ntowards AI~\\citep{Bengio+chapter2007}.''). Many citations in this paper, particularly Section 2 and Section 3 dropped parenthesis. \n- I found \"larger LLMs\" sounds strange, as LLMs themselves stand as \"large language models\", What is the boundary between larger large language models and smaller large language models? \n- Several abbreviations are defined multiple times throughout the papers e.g., DR is defined twice in the introduction. You don't need to define the same abbreviations multiple times."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1086/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699468650075,
        "cdate": 1699468650075,
        "tmdate": 1699636034716,
        "mdate": 1699636034716,
        "license": "CC BY 4.0",
        "version": 2
    }
]