[
    {
        "id": "H9zO65VLBl",
        "forum": "dtFN6T4aMU",
        "replyto": "dtFN6T4aMU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces the Multi-Agent Sparse Training (MAST) framework, which aims to expedite training and enable model compression in MARL. MAST utilizes gradient-based topology evolution to train multiple agents using sparse networks, incorporating a hybrid TD-lambda schema and the Soft Mellowmax Operator to establish reliable learning targets in sparse scenarios. Experiments on the SMAC benchmarks demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe proposed sparse training framework contributes to making MARL systems applicable to resource-limited devices.\n2.\tMAST can be applied to different methods with the CTDE training framework.\n3.\tExperiments on the SMAC benchmarks provide evidence of the effectiveness of the proposed"
            },
            "weaknesses": {
                "value": "1.\tThe paper utilizes multiple technologies, such as RigL, hybrid TD targets, the Soft Mellowmax operator, and dual buffers, which may make it difficult to discern the specific kernel contribution and novelty.\n2.\tIf the motivation lies in the algorithm, the contribution may seem incremental. Additionally, if the paper aims to design an effective framework, it would be necessary to conduct experiments on other benchmarks, such as Google Research Football, to demonstrate its superiority."
            },
            "questions": {
                "value": "1.\tI would like the authors to clarify their main contribution to help me better understand the paper.\n2.\tSome curves in the results do not appear to converge at the end. Could this be due to the figures being drawn with smooth weight?\n3.\tThe results were obtained with 4 random seeds. Could you provide information about the variance? Is the method stable?\n4.\tThe paper utilizes many technologies, such as hybrid TD-lambda, which introduces several hyperparameters. How do you decide on these hyperparameters in different scenarios, especially in real-world applications? Do you have any suggestions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7594/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP",
                    "ICLR.cc/2024/Conference/Submission7594/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698330886771,
        "cdate": 1698330886771,
        "tmdate": 1700642734370,
        "mdate": 1700642734370,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rWvfYGVqko",
        "forum": "dtFN6T4aMU",
        "replyto": "dtFN6T4aMU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces MAST, a novel sparse training framework for deep MARL, utilizing gradient\u0002based topology evolution to efficiently explore network configurations in sparse models. MARL faces significant challenges in ultra-sparse models, including value estimation errors and training instability. Their experiments show the contribution on FLOPs and performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.The problem that the authors focus on is very important and valuable to explore.\n2.A lot of experiments have been conducted to prove their contribution."
            },
            "weaknesses": {
                "value": "1.The writing logic is bad, making readers hard to follow. For example, what is the relationship of the sparse model in SL, single-agent RL and multi-agent RL? Why does MASK apply to QMix series approaches and when MAST is applied to QMIX series algorithms and leverage the RigL method for topology evolution? The authors use too many words on the related work and basic knowledge of MARL, but not clarify the logic clearly.\n2.Some of the formulas are not numbered.\n3.Cannot the discount rate in RL be 1?\n4.The experiment is conducted only on 4 seeds, which is not enough and strong in RL scenarios.\n5.\u201cThese topology adjustments occur infrequently throughout the training process, happening every 200 episodes (about 10,000 steps) in our specific configuration.\u201d How about under other configurations?\n6.Algorithm 1 of the overall procedure is in supplementary, I suggest to contain it in the main text."
            },
            "questions": {
                "value": "Please see the weakness above. Can the authors give a clear logic of the paper? And the innovative solutions in an easy-understood way?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698667658388,
        "cdate": 1698667658388,
        "tmdate": 1699636920103,
        "mdate": 1699636920103,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eBu9jueMpf",
        "forum": "dtFN6T4aMU",
        "replyto": "dtFN6T4aMU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
        ],
        "content": {
            "summary": {
                "value": "This paper involves sparse training for MARL to reduce the computation cost. Besides, to reduce the value estimation error, a hybrid TD($\\lambda$) and Soft Mellowmax operator are incorporated. Experiments on SMAC show the proposed method significantly reduces the training cost while maintains good performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Using sparse training in MARL is relatively new and an important direction that will inspire the community.\n\nExperiments are conducted on SMAC with extensive analysis."
            },
            "weaknesses": {
                "value": "The clarity of this paper needs to be improved. For example, the proposed method uses RigL to sparse the network. However, the details of RigL are missing, which makes it confusing for readers who are not familiar with the sparse training area.\n\nThe limitation of this paper is not discussed. For example, there are too many key parameters that need to be fine-tuned, making it infeasible to apply to other complex domains.\n\nThe literature review lacks some closely related work, such as [1]. So the statement 'The only existing endeavor to train sparse MARL agents' is inaccurate. Also, dual buffers have some related work like [2].\n\nThe visualization does not look very informative to the reviewer, as there are no specific patterns for the latent space distribution. Perhaps projecting what connections are removed and what connections are remaining and analyzing why it is like that will be interesting.\n\n[1] Parameter Sharing with Network Pruning for Scalable Multi-Agent Deep Reinforcement Learning. AAMAS 2023.\n\n[2] PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration. ICML 2022."
            },
            "questions": {
                "value": "Please see the pros and cons part.\n\nCould you explain more about why 'larger values under a sparse model compared to a dense network' in Section 4.1? Do you mean overestimations?\n\nThe well-known method to deal with overestimation is double Q-learning, have you compared this with SM? Which one is better and why?\n\nHow do you select the value of $\\omega$ as 5 and 10? \n\nWhy does the value in Table 1 exceed 100%? How do you calculate it?\n\nThe common evaluation metric in SMAC is average success rate, why do you use average reward? Do you normalize all tasks' rewards to the same scale?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699071038816,
        "cdate": 1699071038816,
        "tmdate": 1699636920009,
        "mdate": 1699636920009,
        "license": "CC BY 4.0",
        "version": 2
    }
]