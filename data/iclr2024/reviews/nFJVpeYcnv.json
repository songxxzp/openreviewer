[
    {
        "id": "KxKt2FbZeL",
        "forum": "nFJVpeYcnv",
        "replyto": "nFJVpeYcnv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_V2Kp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_V2Kp"
        ],
        "content": {
            "summary": {
                "value": "Existing works in matching bandits mainly focus on the one-sided setting where arms are aware of their own preferences. This paper considers a more general two-sided setting, i.e. participants on both sides have to learn their preferences over the other side through repeated interactions. The authors consider Round-Robin ETC in this two-sided setting and provided $log(T)$ regret analysis."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "While a few typos are present, the paper is generally well-written and remarkably easy to comprehend. The authors have made significant efforts to simplify the presentation, using accessible language to explain complex algorithms and regret analysis."
            },
            "weaknesses": {
                "value": "1. Rationale for the Chosen Scenario:\nIn the context of the discussed setting, the true motivation remains somewhat elusive. Although this paper delves into a novel matching scenario where both parties' preferences are unknown, it lacks a concrete real example to substantiate the practical viability of the proposed algorithm.\n\nFirstly, the proposed algorithm introduces an ETC-style approach, mandating an initial round-robin exploration. However, this random exploration may not align with the preferences of practical agents. Alternative exploration strategies, such as UCB or Thompson Sampling, might offer more practicality.\n\nSecondly, the algorithm necessitates a communication phase, wherein the players will communicate through deliberate conflicts in an index-based order to communicate whether they have achieved confident estimations and the communication proceeds pairwise following the order of index. This represents a demanding requirement for real-world players.\n\nThirdly, the regret analysis assumes that every player adopts the proposed Algorithm 1 and arms adhere to $R$ sample-efficient strategies. Yet, in practical applications of two-sided matching, like those in marriage, college admissions, and labor markets, as outlined in the paper's introduction, meeting these conditions might not be feasible.\n\nIn essence, this paper lacks a demonstrable real-world application that would justify the prerequisites outlined in the algorithm and regret analysis.\n\n\n2. Comparative Analysis with Pokharel and Das (2023):\nNotably, Pokharel and Das (2023) also explored the same matching bandit scenario, where the preferences of both sides remain unknown. Although they did not provide a detailed regret analysis, it is imperative to numerically compare the proposed algorithm with their work. Surprisingly, in the current numerical studies outlined in Section D of the supplement, none of the existing algorithms were subjected to comparison.\n\nReference:\nGaurab Pokharel and Sanmay Das. \"Converging to Stability in Two-Sided Bandits: The Case of Unknown Preferences on Both Sides of a Matching Market.\" arXiv preprint arXiv:2302.06176, 2023."
            },
            "questions": {
                "value": "see weakness. In the rebuttal stage, I would like to see more real justifications as well as numerical comparison with the literature."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4905/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698629538211,
        "cdate": 1698629538211,
        "tmdate": 1699636475610,
        "mdate": 1699636475610,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FmrUTR4OnD",
        "forum": "nFJVpeYcnv",
        "replyto": "nFJVpeYcnv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_QoQ1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_QoQ1"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the bandit learning problem in matching markets where both sides of agents have unknown preferences. It proposes a round-robin ETC algorithm to let players and arms learn their preferences and find a partner in a stable matching. Theoretical upper bounds on the player-optimal and arm-pessimal regret bound are provided."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper considers the setting where both sides of market participants have unknown preferences for the first time. For this setting, the paper proposes a round-robin ETC algorithm and the associated communication protocol to let players and arms adaptively find their stable matching. The upper bound of stable regret for both the player side and arm side is provided."
            },
            "weaknesses": {
                "value": "1. The algorithmic design depends on the known D which reveals the relationship between the players' and arms' minimum preference gap. This assumption is unrealistic since both sides have unknown preferences.  \n2. The algorithm design is a direct extension of previous works (Kong and Li, 2023; Zhang et al., 2022). What is your main technical novelty? \n3. Previous works assume N\\le K as they consider the player-unknown setting to let each player have a chance to be matched. Why assume N\\le K in the two-sided unknown setting?\n4. In this two-sided setting, both sides of the participants are rational agents. The current approach though considers such a setting, the focus is still on the player side. For example, if we assume the player-side preferences to be known and arm-side preferences to be unknown, the optimal result should be on the arm-optimal stable matching. The paper lacks a discussion of the trade-off on the optimality of both sides. \n5. Minor: The communication protocol is not clear enough. This part of writing needs to be polished."
            },
            "questions": {
                "value": "Please see above weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4905/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751237506,
        "cdate": 1698751237506,
        "tmdate": 1699636475532,
        "mdate": 1699636475532,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hGEcLgZ8k4",
        "forum": "nFJVpeYcnv",
        "replyto": "nFJVpeYcnv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_hbNf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_hbNf"
        ],
        "content": {
            "summary": {
                "value": "The paper considers a 2-sided matching problem with N players and K $\\geq$ N arms. No agent on either side is aware of their true preferences a priori; these must be leant sequentially from noisy bandit feedback over T rounds of interaction between the 2 sides. In any given round, the players simultaneously propose to arms of their choice based on some decision rule. If multiple players propose to the same arm, the arm chooses a player of her choice based on her decision rule. The authors propose a solution concept whereby players follow the same decision rule (dubbed Round robin ETC) and each arm follows some \"sample efficient\" learning strategy. Under this premise, the player-optimal stable regret is shown to grow logarithmically in T and so is the arm-pessimal stable regret."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I think this paper contributes well to the line of work on two-sided matching via bandit learning. In particular, theoretical results for the setting where both sides learn over time are new. Additionally, positive results are shown wrt a stronger benchmark (player-optimal matching), which is novel. Other than that, several assumptions common in extant literature (e.g., conditions pertaining to a unique stable match or globally best arms, etc.) seem to have been relaxed."
            },
            "weaknesses": {
                "value": "My concern is there are too many moving parts in the algorithm (the stated version is a composition of several modules) and its presentation, in the current form, is not ideal. The paper certainly could benefit from a better exposition of Section 3.2 (as would the reader)."
            },
            "questions": {
                "value": "The upper bounds in Theorem 1 depend on R implicitly through c. Please define c in the statement of the theorem."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4905/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805183905,
        "cdate": 1698805183905,
        "tmdate": 1699636475422,
        "mdate": 1699636475422,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fAxAOPVy0W",
        "forum": "nFJVpeYcnv",
        "replyto": "nFJVpeYcnv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_X1qd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4905/Reviewer_X1qd"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of two-sided matching bandits in the style of Das and Kamenica (IJCAI 2005), where both the players and arms have unknown preferences over one another and the market is decentralized. The goal is for the players to learn their optimal stable match with low regret. The key challenges are that (1) both sides need to efficiently learn their preferences through limited samples, (2) arms adopt sample-efficient strategies in choosing players, leading to unreliable feedback, and (3) lack of communication and coordination among decentralized players. In terms of results, the authors show that learning can be achieved with $O(\\log T)$ instance-dependent player-optimal regret via a round-robin explore-then-commit approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Develops a new model of decentralized two-sided matching, extending that of Das and Kamenica and Liu et al. Particularly interesting is the authors\u2019 modeling of arms\u2019 learning processes via \u201csample-efficient\u201d algorithms.\n- Provides a thorough analysis of their model, including an optimal $O(\\log T)$ instance-dependent learning algorithm for decentralized agents."
            },
            "weaknesses": {
                "value": "- It is inaccurate to say that there are no other works on matching bandits where both sides\u2019 preferences are unknown. For instance, the paper of Jagadeesan et al. (JACM, 2023) considers a model of matching bandits on a centralized platform where all agents do not know their preferences to start with.\n- I am not fully convinced by the motivation/modeling assumptions here. It would be helpful if there discussion of a specific empirical setting this paper sought to model. (In particular, I do not find the example given of online marketplaces particularly compelling, as my understanding is that most such platforms run based on *centralized* recommendations.)\n- What are the insights that should be taken away from this work? Is it new qualitative understanding, or is it the results themselves? I believe the paper would benefit from a more thorough discussion of takeaways/insights beyond the theorem statements."
            },
            "questions": {
                "value": "- What are the empirical settings that motivate this particular model of matching bandits?\n- What are the key qualitative insights that the authors would like to emphasize?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4905/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699335242912,
        "cdate": 1699335242912,
        "tmdate": 1699636475313,
        "mdate": 1699636475313,
        "license": "CC BY 4.0",
        "version": 2
    }
]