[
    {
        "id": "zcvbqsdWkQ",
        "forum": "V7QAX3zRh0",
        "replyto": "V7QAX3zRh0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_oq6r"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_oq6r"
        ],
        "content": {
            "summary": {
                "value": "While a lot of empirical studies have been proposed to address catastrophic forgetting in continual learning, the theoretical investigation behind continual learning is quite limited. This paper studies parameter isolation based continual learning algorithms through the geometry of neural network loss landscape, and also theoretically characterizes the conditions for zero forgetting under certain assumptions. The theoretical guarantees of zero forgetting for several existing continual learning algorithms  are analyzed by using the framework proposed in this paper. Experimental studies are also conducted to justify the theoretical findings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Considering that the theoretical studies are still lacking for continual learning, investigating the theoretical guarantees for continual learning algorithms is a very important direction in the community.\n\n2. Analyzing existing orthogonal-projection based CL studies, such as OGD and GPM, from the perspective of parameter isolation methods is interesting.\n\n3. The authors also conduct experiments to further backup their theoretical findings."
            },
            "weaknesses": {
                "value": "1. My major concern is about the definition of forgetting in equation (1), which is defined based on the training loss. However, in practice and in most empirical studies we are mainly concerned about the testing loss. This will make the theoretical results less interesting and also prevent the analysis of positive backward transfer.\n\n2. Another concern is about the implications of the theoretical results. Based on the theoretical results, the authors further propose an augmented version of SGD. But the effectiveness of this inspired design is only justified by comparing with vanilla SGD. Note that the theoretical investigations are usually grounded by some restrictive assumptions and particularly the results in this paper are about identifying conditions for zero forgetting. If the advantage of the inspired algorithm cannot be sufficiently verified, it is hard to tell the usefulness of the theoretical findings."
            },
            "questions": {
                "value": "Besides the weaknesses above, I also have several questions:\n\n1. The authors claimed that minimizing the average forgetting is equivalent to minimizing the multi-task loss in section 1.1. I was wondering whether this is true. In the authors' claim, the term $L_t^*$ is treated as a constant that is independent with $\\theta$. But in continual learning, because the learnt model of previous tasks will be used as the initial model for current task $t$, $\\theta_t$ should be correlated with  $L_{i}^*$ for any previous task $i<t$. \n\n2. How do you define the task solutions in Assumption 2?\n\n3. Table 1 is difficult to understand. In what scale will the errors be considered as small?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5981/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5981/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5981/Reviewer_oq6r"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5981/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730046725,
        "cdate": 1698730046725,
        "tmdate": 1699636639953,
        "mdate": 1699636639953,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TLdtFkr2Jx",
        "forum": "V7QAX3zRh0",
        "replyto": "V7QAX3zRh0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_5dAQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_5dAQ"
        ],
        "content": {
            "summary": {
                "value": "This paper looks at some parameter isolation methods for continual learning (including methods like OGD and GPM). It looks at conditions where forgetting is minimised or controllable, by making a 2nd order Taylor series expansion around the converged loss. Assuming that parameters do not change too much during training (ie that the Taylor series expansion is valid), the paper shows that parameter isolation methods satisfy some equations that imply zero forgetting. In experiments, the paper looks at whether the Taylor series expansion assumption holds in practice, and at the forgetting values of some algorithms (including their own algorithm, orthogonal SGD)."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It is interesting to try and theoretically explain why parameter isolation methods may work (or not work) well. Past works have focussed mostly on regularisation and memory based methods. \n\n2. As far as I can tell (aside from one small question, listed later), the derivations of the theorems are correct / intuitively make sense to me. \n\n3. I found the perturbation analysis technique in Section 5.1 interesting."
            },
            "weaknesses": {
                "value": "1. At the end of Section 1.1, the paper claims that minimising average forgetting is equivalent to minimising the multi-task loss. I do not think this is true: there is a missing L_t(\\theta), ie the loss at the current task t. I don't think this was used anywhere, so this should be an easy fix. However, in Section 5, the authors say, \"we report forgetting in terms of accuracy\", which I did not understand. What does this mean (because forgetting is not equal to accuracy)? \n\n2. I'm not sure if OGD and GPM are 'parameter isolation' methods, a claim that seems central to the title and framing of this paper. Previous works like de Lange et al. would characterise these methods as 'constrained replay-based methods'. I do follow the authors' argument in Section 2 that these methods are not allowing parameters to be part of the parameter subspace. If anything, I would say that these methods are a combination of replay and parameter isolation methods (or, if strictly choosing one, it would be replay methods, like in de Lange it al.). \n\n3. Assumption 2 (combined with assumption 1) seems like a very strong assumption to me. The fact that a method like OGD does not have zero forgetting on CL benchmarks (see results in other papers: OGD is not perfect!) is proof to me that assumption 2 does not hold in practice. I was very unconvinced by the experiments in Section 5.1, which looks at whether assumption 2 holds. \n- In the first part (Table 1) the authors do not train until (close to) convergence, hence breaking assumption 1. It is unsurprising that training for a fixed number of epochs with a learning rate that is orders of magnitude lower leads to the parameters changing less, and hence the Taylor series expansion being more predictive (that being said, if one looks at relative values of the Taylor series expansion and E_0(t): E_0(t) is about twice the value of the Taylor value, but always within what are very large standard deviations, making this result very difficult to draw any conclusions from). \n- In the second part (Figure 2), I do not understand what reasonable values of the score or of r are. Is a score of 1 good? What does an r value of 100 mean? Is this small or large? I do not know how to interpret these results. \n\n4. Throughout the experimental section, the authors appear to break assumption 1, hence breaking the theory (at least, for small learning rates; at large learning rates, it appears that assumption 2 does not hold). This is a major problem for me. \n- Also, all the error bars in Table 2 are very large, making any conclusions here hard to see. \n\n5. If I understand correctly, the theory for OGD and GPM requires storing all input data from past tasks and constraining optimisation over this? This is a very strong requirement (and is obviously not allowed in practice in CL). This needs to be made clear, and, in my mind, reduces the significance of this result."
            },
            "questions": {
                "value": "Please see Weaknesses section. \n\nOther minor questions / points: \n1. In the proof of Theorem 1, the authors say that \\Delta_2^T H_1* \\Delta_2 = 0 implies that \\Delta_2^T H_1 = 0. It was not clear to me why this is the case, can the authors please expand on this? \n2. Typo in the line after Equation 3: I believe it should be \\Sum_{o=1}^{t-1}, currently it says t-2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5981/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777957507,
        "cdate": 1698777957507,
        "tmdate": 1699636639845,
        "mdate": 1699636639845,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pSK4zb2bvY",
        "forum": "V7QAX3zRh0",
        "replyto": "V7QAX3zRh0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_W8iZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_W8iZ"
        ],
        "content": {
            "summary": {
                "value": "This paper conducts a second-order analysis of continual learning and derives theorems that lead to small catastrophic forgetting under mild conditions. The authors show that OGD, GPM, and explicit parameter isolation strategies can be explained using the derived theorems."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The theoretical framework is powerful enough to include many existing continual learning techniques."
            },
            "weaknesses": {
                "value": "The second-order analysis is restrictive to the case when the learning rate is small."
            },
            "questions": {
                "value": "1. On page 3, in \"Catastrophic forgetting from the loss geometry viewpoint\", you mention that parameter isolation strategies can provide stronger guarantees than regularization-based methods. Is the intention to stress that your analysis doesn't involve the optimization procedure? I want to confirm this since you did not discuss regularization-based methods in later sections in detail.\n2. Can you also give a brief comparison between your results and the guarantees of the regularization-based methods?\n3. When we talk about the strict parameter isolations, does the network know the task domain index at training and inference time?\n4. Can you explain the columns in table 1? What does \"Taylor\" mean here?\n5. In \"Perturbation analysis\" on page 7, you mention that it is to measure assumption 2, do you mean to verify eq(2)?\n6. Can you give some intuition behind the perturbation score s(r)? Why is it a good measure of the approximation error?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5981/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807636473,
        "cdate": 1698807636473,
        "tmdate": 1699636639728,
        "mdate": 1699636639728,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oDyQHgTVtX",
        "forum": "V7QAX3zRh0",
        "replyto": "V7QAX3zRh0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_9KMy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5981/Reviewer_9KMy"
        ],
        "content": {
            "summary": {
                "value": "The authors construct a unified framework to analyze the effectiveness of parameter isolation methods in continual learning. With the 2nd order Taylor expansion on the objective function, the authors derive some necessary and sufficient conditions for guaranteed non-forgetting. They further show some existing parameter isolation methods are special cases of their framework."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The authors construct a theoretical framework for parameter isolation strategies through the lens of loss landscape.\n\n- Several seminal continual learning methods can be analyzed and explained with their framework."
            },
            "weaknesses": {
                "value": "- My major concern is the significance or novelty of the submission. The framework authors formulate, i.e., analyzing null forgetting in continual learning through loss landscape, is somehow not quite new given some previous works. Besides, though the authors analyze some continual learning methods with their framework, it would be more appreciated if a new continual learning method can be proposed guided by the theoretical framework. The current presentation also makes the experimental part weak, which doesn\u2019t provide any very significant results to the field.\n\n- The authors analyze a few continual learning methods that already have sound intuition on their effectiveness, especially the OGD and GPM. What about other more empirical methods, e.g., the prompt tuning continual learning method [1].\n\n#### Reference:\nWang, Zifeng, et al. \"Learning to prompt for continual learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "What does $\\xi_{\\tau}(t)$ in Theorem 2 mean?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5981/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698950194501,
        "cdate": 1698950194501,
        "tmdate": 1699636639624,
        "mdate": 1699636639624,
        "license": "CC BY 4.0",
        "version": 2
    }
]