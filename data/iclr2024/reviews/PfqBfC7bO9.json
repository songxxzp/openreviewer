[
    {
        "id": "3zrqlfbg3k",
        "forum": "PfqBfC7bO9",
        "replyto": "PfqBfC7bO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission871/Reviewer_vbSV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission871/Reviewer_vbSV"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on unsupervised semantic segmentation and proposes a framework based on causal inference. Specifically, the proposed framework employs two-step pipline to solve the task, which is claimed as intervention-oriented approach (i.e., frontdoor adjustment). The proposed method first constructs a concept clusterbook as a mediator and then adopts concept-wise self-supervised learning for pixel-level grouping. Extensive experiments are conducted on various datasets to demonstrate the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method achieves performance improvements on various datasets.\n- The visualizations are rich and abundant."
            },
            "weaknesses": {
                "value": "- The causal diagram is not solid. Why the path $T \\rightarrow Y$ could be omit?\n- The specific explanation about $U$ is missing. It is not convincing to use question as definition.\n- What are the specific representations of  $T,M,Y,U$? E.g., $T \\in \\mathbb{R}^{D\\times H\\times W}$.\n- Is there any instance or example for explaining Figure 2?\n- The authors claim that the main goal is to group semantic concepts that  meet the targeted level of granularity. How do the items in clusterbook correspond to various granularities?\n- Is is feasible to direct evaulate the mIoU based on results of the concept with respect to the index on clusterBook?"
            },
            "questions": {
                "value": "See Weaknesses*"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Reviewer_vbSV"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission871/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698295279227,
        "cdate": 1698295279227,
        "tmdate": 1700364781368,
        "mdate": 1700364781368,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LbNJfiRGsI",
        "forum": "PfqBfC7bO9",
        "replyto": "PfqBfC7bO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission871/Reviewer_ivD5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission871/Reviewer_ivD5"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses the task of unsupervised semantic segmentation (USS). The author proposes a new method called CAUSE, integrating USS into a causal problem through two steps: learning discrete sub-segmented representation with Modularity theory and conducting do-calculus with self-supervised learning in the absence of annotations. CAUSE bridges causal inference into unsupervised segmentation and obtain semantically clustered groups with the support of pre-trained feature representation. Extensive experiments on various datasets corroborate the effectiveness of CAUSE and achieve state-of-the-art results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "** The authors innovatively treat the USS task as a causal problem to solve the problem of determining the appropriate cluster level. \n\n** The authors propose a discrete sub-segmented representation learning method using Modularity theory, which compensates for the lack of semantic understanding in traditional unsupervised segmentation methods.\n\n** The authors introduce causal inference into the unsupervised segmentation task and enable semantic segmentation with self-supervised learning in the absence of annotations.\n\n** The authors propose a concept drift detection method based on causal relationships, which can effectively detect the concept drift problem in unsupervised semantic segmentation."
            },
            "weaknesses": {
                "value": "** This paper lacks a detailed explanation of the specific methodologies used for constructing the concept clusterbook and conducting concept-wise self-supervised learning.\n\n** The paper could benefit from a detailed explanation of the implementation details, such as the specific architectures used for the segmentation head and the pre-trained model.\n\n** This paper does not discuss the limitations or potential drawbacks of the proposed framework, which would have been useful for readers to understand the scope and applicability of the approach.\n\n** The comparison with recent and state-of-the-art methods in unsupervised semantic segmentation is missing, which could provide a comprehensive evaluation of the proposed framework."
            },
            "questions": {
                "value": "**  Please discuss the limitations or potential drawbacks of the proposed framework? It would be helpful for readers to understand the scope and applicability of the approach.\n\n** Please provide more details on the implementation, such as the specific architectures used for the segmentation head and the pre-trained model?\n\n**  Please discuss the computational complexity of the proposed framework? Please provide any insights or analysis on the computational efficiency of the approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission871/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742857273,
        "cdate": 1698742857273,
        "tmdate": 1699636013526,
        "mdate": 1699636013526,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DaZ8R5iodo",
        "forum": "PfqBfC7bO9",
        "replyto": "PfqBfC7bO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission871/Reviewer_zoBW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission871/Reviewer_zoBW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed an unsupervised semantic segmentation method based on theory of causal inference. It introduce a concept clusterbook to serve as mediator to decide the cluster granularity. The cluster gradularity is considered a challenge and the key that effects unsupervised semantic segmentation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. overall the paper is well written. \n2. The proposed pipeline of modularity clustering works well on benchmarks."
            },
            "weaknesses": {
                "value": "The link between proposed pipeline and causal inference is not clear, even though the authors  pays a lot of attention in explaining what's backdoor and frontdoor adjustments. In addition, some key details of the pipeline are not very clear, which requires further explainations."
            },
            "questions": {
                "value": "1. The link between the proposed method and the causal inference is not very clear. The authors do pay much attention on theory and formulation of frontdoor adjustment, however is there explicit link between it with the proposed pipeline? that is between equation 1 and the algorithm 1 and 2. \n\n2. Calculation of affinity matrix is time consuming? how many samples does it use while calculating the affinity matrix? Does the codebook update while training? or fixed based on pretrained DINO features? In addition, how to guarantee the the codebook spans different levels, how to decide the propoer granularity? \n\n3. STEGO has similar mechanism of contrastive learning. which module does the proposed method benefits more from?  The codebook or the ST learning? \n\n4. A minor issue is that the ALGORITHM 1 should be placed near sec. 3.2 to prevent confusing"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission871/Reviewer_zoBW"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission871/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698764361325,
        "cdate": 1698764361325,
        "tmdate": 1699636013458,
        "mdate": 1699636013458,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aMOczSHnf0",
        "forum": "PfqBfC7bO9",
        "replyto": "PfqBfC7bO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission871/Reviewer_1Vow"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission871/Reviewer_1Vow"
        ],
        "content": {
            "summary": {
                "value": "This article introduces an algorithm CAUSE to address unsupervised semantic segmentation. The algorithm interprets the problem from a causal inference perspective, and mainly consists of two steps, i.e., building concept prototypes by maximising modularity and semantic grouping via concept-wise self-supervised learning. The algorithm has been evaluated on a set of segmentation datasets, like COCO-Stuff, Cityscapes, and VOC."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The causal inference perspective to solve unsupervised semantic segmentation is interesting and novel to me. The algorithm design basically makes sense, and shows promising performance on standard datasets."
            },
            "weaknesses": {
                "value": "My major concern revolves around Sec. 3.3. Writing in this part is not good. It is hard to understand all implementation details. __First__, it is unclear how Eq. 4 is derived. Since this is probably the most important part of the algorithm, more explanations should be given. __Second__, I am confused about how \"find patch feature points in $T$ satisfying $\\mathcal{D}_M[id_q,:]>\\phi^+$\" is implemented in practice. As far as I understand, $\\mathcal{D}_M$ only summarizes prototype-prototype similarities; then how to select features based on the aforementioned rule? __Third__, for the statement \"we set tight negative relaxation ..., ... emphasizing that hard negative mining is crucial to advance self-supervised learning\", does a tight negative relaxation indicate easier negative mining?\n\nThe concept prototype bears high similarity with the work [ref1]. I am wondering whether the sinkhorn-knopp algorithm used in [ref1] can be used here for prototype generation. \n\nFrom Fig. 4, it appears that the method works particularly well in object boundaries (very close to ground-truths for, e.g., persons). While this is impressive for unsupervised segmentation, I am curious how the algorithm improves over other methods in boundary predictions.\n\nThere lacks description of training details. \n\n[ref1] Rethinking Semantic Segmentation: A Prototype View. CVPR 2022.\n\n=======\n\noverall, I am slightly positive to the article. However, since I am not an expert in casual inference, I will see other reviewers' comments and make the final decision."
            },
            "questions": {
                "value": "see [weaknesses]"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission871/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777067801,
        "cdate": 1698777067801,
        "tmdate": 1699636013359,
        "mdate": 1699636013359,
        "license": "CC BY 4.0",
        "version": 2
    }
]