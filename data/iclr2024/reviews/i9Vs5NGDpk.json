[
    {
        "id": "IQBL6hJy7N",
        "forum": "i9Vs5NGDpk",
        "replyto": "i9Vs5NGDpk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
        ],
        "content": {
            "summary": {
                "value": "This paper established consistency of generalized cross validation for estimating prediction risks of sketched ridge regression that enables it to fast tune ensemble parameters. The authors further proposed an resembling trick so that the risk for unsketched ridge regression can be estimated through GCV using small sketched ridge ensembles. Simulations are conducted to validate the theoretical results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper gives asymptotic of squared risk and its GCF estimator for sketched ridge regression so that an it is intuitively understandable as the implicit unsketched ridge regression risk and an inflation term due to randomness of the sketch that is controlled by ensemble size. And this is exploited to provide a method to tune unsketched ridge regression using only sketched ensembles. None of the assumptions are very strong for these theoretical results."
            },
            "weaknesses": {
                "value": "While the results in this paper is interesting, the authors failed to illustrate while tuning (ensembled) sketched ridge is preferred over tuning unsketched ridge regression. It would be better if they provide some intuition and explanation to the results, especially for readers who are not that familiar with sketching."
            },
            "questions": {
                "value": "Because GCV and risk for sketched ensembles converge at rate 1/K to the equivalent ridge for sketched ensembles, does this imply the larger the K the faster the convergence and the better it is? It there a downside if K is too large?\nCould the authors why the result that tuning (ensembled) sketched ridge is equivalent to tuning unsketched ridge regression is useful?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697764899877,
        "cdate": 1697764899877,
        "tmdate": 1699636843141,
        "mdate": 1699636843141,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "E24jvCTIxO",
        "forum": "i9Vs5NGDpk",
        "replyto": "i9Vs5NGDpk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
        ],
        "content": {
            "summary": {
                "value": "The current paper considers generalized cross validation (GCV) for sketched ridge regression ensembles. Specifically, sketching is done across different features and ensembles are based on finite sketches. The paper first derives the asymptotics of squared risk and its GCV estimator (section 2) and then extends to more general subquadratic prediction risk functionals (section 3). The paper also proposes a method for estimating the risk of unsketched ridge regression using sketched ridge ensembles (section 4). All the theoretical results are illustrated using both synthetic and real datasets with CountSketch and subsampled randomized discrete cosine transforms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Overall the paper is very well written and persuasive. The experimental results are very well summarized in the figures.\n\n2. It is impressive that the current paper considers all asymptotically free sketched ensembles and allows for zero or negative penalty \n in ridge regularization.\n\n3. Distributional consistency in Corollary 5 is nice: this allows for classification errors and construction of prediction intervals among other things.\n\n4. It is interesting to know that the finite ensembles by sketching observations do not have GCV consistency, as given in Proposition 7."
            },
            "weaknesses": {
                "value": "It would be beneficial to provide more details regarding computational aspects in the main text. For example, I presume that it is not necessary to compute $\\hat{\\beta}_{\\lambda}^k$ alone in equation (1). \n\nIn other words,  it is only necessary to compute the predicted values \n$X \\hat{\\beta}_{\\lambda}^k$. \n\nThis seems important because it is not necessary to explicitly premultiply $S_k$ to $\\hat{\\beta}_{\\lambda}^{S_k}$ in equation (1). If I am correct, this point can be emphasized at the end of section 2 when it is discussed that matrix inversions are inexpensive after precomputing $X S_k$.\n\nGenerally speaking, it would be helpful to provide more details regarding computational aspects."
            },
            "questions": {
                "value": "1. In figure 1, it would be good to indicate that SRDCT refers to subsampled randomized discrete cosine transform because SRDCT first appears toward the end of page 2.\n\n2. In proposition 6, $S_k^T S_k$ is assumed to be invertible. How strong is this assumption? Some further remarks might be helpful.\n\n3. The ensemble trick in section 5 seems very useful. However, there is no explicit discussion of computational gains over unsketched GCV. Especially, when $K$ is large as in proposition 6, one might need to rely on parallel computing to fully speed up computations. More discussions might be desirable in terms of computational complexity. \n\n4. Is there a known S-transform for CountSketch? Table 4 in the appendix does not include CountSketch."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698958550835,
        "cdate": 1698958550835,
        "tmdate": 1699636843040,
        "mdate": 1699636843040,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yeBUuaY2Nv",
        "forum": "i9Vs5NGDpk",
        "replyto": "i9Vs5NGDpk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
        ],
        "content": {
            "summary": {
                "value": "Motivating by hyparameter tuning (size of the ensemble, size of the sketches), this paper studies the statistical properties of Generalized-Cross-Validation applied on an ensemble of sketched ridge regressors with skecthing applied to the feature space. First, the authors develop squared risk asymptotics and provide consistency results (Thoerem 2) and then, extend these results to subquadratic error functionals (Theorem 3). These findings hold for the general class of asymptotically free sketching matrices. At the origin of the study, is a key theorem (LeJeune et al. 2022), that states that the sketched inversion of a sketched regularized matrix corresponds to the inversion of the initial regularized matrix with another hyperparameter. This gives rise to Theorem 2 that nicely relates the quadratic risk of the ensemble-based estimator to the risk of the rigde estimator plus a randomness term depending on the sketch via Theorem 1 and the so-cllaed S-transform. Moreover, functional and distribution consistency for general error functional are also proved. Simulations on toy and real data shown in the main paper and appendix confirm the interest of the approach for tuning both the regularization level (or sketch size in fine) and the size of the ensemble."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "First of all, I would like to say that this is a very nice paper, very well written, solid and with a strong and insightful content. I have learned a lot when reading it.\nThe main strengths of the paper is its depth of view not only about GCV (which has a simple form) but also about the link between sketched ridge regression and regualrization in ridge regression, and the role of the ensemble trick. \nI appreciated the richness of the discussion and the comments all along the paper.\nOriginality is also present here, with the exploitation of very recent results (LeJeune et al. 2022) but with a special angle here (GCV)."
            },
            "weaknesses": {
                "value": "* Improvment of clarity in Assumption 2 statement and explanation. \nThe paper has the merit to introduce elements of free probability theory useful in Assumption 2. I regret not to have more intuition here: I can easily imagine that a form of independence (I've read the appendix) between $X^TX$ and $SS^T$ is useful but the notion of limiting S-transform is not at all discussed at this stage (page 4) and Assumption 2 remains not clear at all when beginning to read what follows. Same thing for Theorem 1, describe the $|ambda^+$ function.\n* A simple analysis of the complexity in time and memory for the full aproach in constrat to other estimators (CV) would be welcome.\n* Bonus: Is it interesting to come back on other risk estimators (Bootstrap) and clearly identify what could be done with this estimator or not with ensemble of sketched ridge regression."
            },
            "questions": {
                "value": "See my previous comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699208193769,
        "cdate": 1699208193769,
        "tmdate": 1699636842926,
        "mdate": 1699636842926,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tjVM4Bjk8B",
        "forum": "i9Vs5NGDpk",
        "replyto": "i9Vs5NGDpk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_t4Ef"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7125/Reviewer_t4Ef"
        ],
        "content": {
            "summary": {
                "value": "This paper is about the (asymptotic) consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles using tools from random matrix theory. \n\nFor general subquadratic prediction risk functionals, they extend GCV to construct consistent risk estimators, and obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric.\n\nAlthough the consistency result seems intuitive and natural, they point out that GCV of the observation sketched ridge regression, is inconsistent, highlighting the subtlety of this subject."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper presents the theorems in a clear and rigorous way. All notations are presented again on a table in appendix. Theoretical result is supported by experimental result."
            },
            "weaknesses": {
                "value": "No major weakness is spotted."
            },
            "questions": {
                "value": "Asymtpotic freeness seems to be an essential assumption in the paper. Although this assumption is experimentally supported by artifical datasets, I wonder if one can observe similar matching on real-world dataset."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699214637341,
        "cdate": 1699214637341,
        "tmdate": 1699636842694,
        "mdate": 1699636842694,
        "license": "CC BY 4.0",
        "version": 2
    }
]