[
    {
        "id": "Ko047ytxw9",
        "forum": "NhLBhx5BVY",
        "replyto": "NhLBhx5BVY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_cPYQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_cPYQ"
        ],
        "content": {
            "summary": {
                "value": "The authors work on binary as well as instance segmentation of curvilinear structures. This segmentation task is prone to errors such as split and merge mistakes. The authors resolve such errors by extending the topological concept of simple points to superpixels (or supervoxels). While most topological-based methods are computationally expensive, the authors propose an algorithm to reduce the complexity of their method. The authors validate their method on 2 datasets and compare against several topology-aware baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The authors extend the concept of simple points to supervoxels. In the false negative and false positive maps, they check if keeping or removing the connected component (CC) changes the topology or not. If it changes the topology, then they deem it critical and apply high weight to it in the loss function while training. The critical CCs correspond to the split/merge errors that one would like to resolve.\n2) The authors develop an $O(n)$ solution where $n$ is the number of pixels/voxels using standard graph algorithms like BFS. This is much cheaper compared to existing topology-aware methods whose algorithms are atleast $O(n \\log n)$ or $O(n^2)$.\n3) The authors provide adequate proofs of their runtime in the supplementary."
            },
            "weaknesses": {
                "value": "1) In principle, the novelty of the contribution seems limited as an existing concept of simple points has been extended to superpixels (collection of pixels) instead. \n2) The authors should consider comparing against clDice [1] as a baseline since clDice has shown better performances among the topology-aware methods.\n3) The authors do not provide any ablation study. Considering they have hyperparameters $\\alpha$ and $\\beta$ in their loss function, the authors would benefit from providing an ablation study of these loss weights and provide a discussion on how each hyperparameter affects the results.\n\n**References**\n\n[1] Shit, Suprosanna, et al. \"clDice-a novel topology-preserving loss function for tubular structure segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021."
            },
            "questions": {
                "value": "1) Please also see the weakness above.\n2) As the authors claim that they are proposing a topology-aware neural network, they should also evaluate the result on topology-aware metrics like clDice [1], Betti Matching [2], and Betti Number [3].\n3) Please mention if the numbers in bold are just numerically better, or, if t-test [4] has been conducted to check if the performance improvement is statistically significant or not.\n\n**References**\n\n[1] Shit, Suprosanna, et al. \"clDice-a novel topology-preserving loss function for tubular structure segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[2] Stucki, Nico, et al. \"Topologically faithful image segmentation via induced matching of persistence barcodes.\" International Conference on Machine Learning. PMLR, 2023\n\n[3] Hu, Xiaoling, et al. \"Topology-preserving deep image segmentation.\" Advances in neural information processing systems 32 (2019).\n\n[4] Student, 1908. The probable error of a mean. Biometrika, pp.1\u201325."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8037/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8037/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8037/Reviewer_cPYQ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8037/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801243064,
        "cdate": 1698801243064,
        "tmdate": 1699636992510,
        "mdate": 1699636992510,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BISqKgHONg",
        "forum": "NhLBhx5BVY",
        "replyto": "NhLBhx5BVY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_ZGQy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_ZGQy"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a \"supervoxel based topological loss function\" to solve the connectivity-related problems in segmentation tasks. The paper considered the key components of false positives and false negatives as key factors affecting the topology and uses loss functions to optimize them. Through algorithm design, the time complexity is reduced. The theoretical proof is rich, and the effectiveness of the model is verified on EXASPIM2 and DRIVE. The visualization effect shows that the loss function proposed in this paper can effectively improve the visualization effect."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper proposed novel ideas and methods that are simple and effective after being optimized by the proposed algorithm in this article.\n2. The paper verified the effectiveness of the method in both 3D and 2D dimensions."
            },
            "weaknesses": {
                "value": "1. Lack of visual comparison with baseline in Figure 5.\n2. Performance metrics should be described using formulas.\n3. Lack of comparison with more loss functions that can supervise topology changes."
            },
            "questions": {
                "value": "Critical components should not include areas that do not affect the topology structure. In the visualization effect of Figure 4, why is the structure more slender compared to the baseline, and can the proposed loss function optimize the segmentation edge?\n\nWhat are the values of \u03b1 and \u03b2 in the experiment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8037/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698935906404,
        "cdate": 1698935906404,
        "tmdate": 1699636992401,
        "mdate": 1699636992401,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IRd7K9wwde",
        "forum": "NhLBhx5BVY",
        "replyto": "NhLBhx5BVY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_Jbm6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8037/Reviewer_Jbm6"
        ],
        "content": {
            "summary": {
                "value": "Traditional segmentation methods focus on total voxel accuracy. While some critical voxel errors might change the topology, most would not. This paper proposes a method to find those critical voxels and add additional penalty terms to the loss function whenever these voxels are inaccurately predicted.\n\nThe contributions of this paper are as follows:\n1. An algorithm is proposed to detect split and merge errors which disrupt the number of components relative to the ground truth.\n2. The computational complexity of this algorithm scales linearly with the number of voxels under the assumption of a tree graph.\n3. This approach can be easily integrated into available segmentation frameworks as it is built on top of common voxel-based loss functions.\n4. The experiments conducted show the effectiveness of the proposal relative to competing methods on two datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "In addition to the contributions listed above I would highlight the following:\n\n1. The authors provide a good mathematical notation to communicate their methodology.\n2. The didactic images facilitate a better understanding of the approach.\n3. Details of training are explicitly mentioned such as the continuation scheme."
            },
            "weaknesses": {
                "value": "1. The paper could improve in terms of clarity in several cases. Most importantly, Algorithm 2--a critical part of the paper--is very vague and the only explanation provided about it under Corollary 3 does little to make it clearer.\n2. More emphasis needs to be placed that the O(n) gurantee is only valid if critical components affect both local and global topology, i.e. having a tree graph.\n3. The method is only sensitive to the number of components, while topology is much broader e.g. bifurcations, loops. This limitation needs to be communicated.\n4. The approach comes with hyper-parameters which might be time consuming to set."
            },
            "questions": {
                "value": "1. The loss function is introduced in Definition 1, and then expanded again in Section 3.3. A better sense of direction would have been conveyed if the two were mixed and mentioned early on in Section 3 and stated that the rest of the Section focuses on finding N(y^) and P(y^) in Definition 4. Removing G(.) and H(.) and having double sums might improve readablility.\n\n2. The definition originally provided for S(.) does not have a subscript and is clear, but the explanation provided for the case with a subscript is hard to grasp.\n\n3. In Method Section before Definition 1, it is stated that y_i \\in {0,1,...,m} and y^_i \\in {0,1,...,l}. Shouldn't they both sets be the same (no need for l)? Also m, l(?), and n are given without definitions.\n\n4. Positively critical components rely on computing S(y^\u2296y^+), while Algorithm 2 only requries knowing S(y\u2296y^-). Why?\n\n5. Condition 1 and Condition 2 are not really defined as such.\n\n6. Potential typos: Section 3.1.2 line 2: false negative mask -> false positive mask; Two lines above Corollary 1: lemma seems extra."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8037/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8037/Reviewer_Jbm6",
                    "ICLR.cc/2024/Conference/Submission8037/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8037/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699462797289,
        "cdate": 1699462797289,
        "tmdate": 1700649633284,
        "mdate": 1700649633284,
        "license": "CC BY 4.0",
        "version": 2
    }
]