[
    {
        "id": "pzKunYlL2H",
        "forum": "KQe9tHd0k8",
        "replyto": "KQe9tHd0k8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_hQ1X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_hQ1X"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an effective and efficient approach to the problem of Learning from Label Proportions. The proposed approach has two main steps. In the first step, it uses Belief\nPropagation to marginalize the Gibbs distribution to obtain pseudo labels. In the second step, it uses the pseudo labels to provide supervision for a learner. The paper conducted experiments to show the usefulness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem of Learning from Label Proportions could be useful. \n- This paper is well structured and easy to follow.\n- The proposed approach outperforms state-of-the-art approaches."
            },
            "weaknesses": {
                "value": "- The proposed approach is complex; a simple framework is desirable. \n- The proposed approach assumes the case of disjoint bags; it cannot handle non-disjoint bags.\n- The paper lacks theoretical aspects of the proposed approach."
            },
            "questions": {
                "value": "The paper should discuss theoretical aspects of the proposed approach. For example, I am interested in the time and space complexity of the proposed approach since the proposed approach has rather complex framework. What are the computational and memory costs of the proposed approach?\n\nThe graph structure has a significant impact on the proposed approach. How do you determine the number of nearest neighbors? Is there any theoretical background to determine the graph structure?\n\nAs shown in Algorithm 1, the proposed approach uses the iterative computations. Does the proposed approach have a theoretical property to converge? How do you determine the number of iterations, R?\n\nAs shown in Table 1 and 2, for UCI and Criteo datasets, the proposed approach is competitive to the previous approaches. On the other hand, the proposed approach does not work well for CIFAE dataset, as shown in Table 3. Please theoretically justify the experimental results. \n\nSince the proposed approach uses a k-NN graph, it needs a high computational time to construct the graph. In Section 6.1, the paper shows the processing time of only the proposed approach. Is the proposed approach more efficient than the previous approaches?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698389841143,
        "cdate": 1698389841143,
        "tmdate": 1699636960570,
        "mdate": 1699636960570,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "89DaUD9Dpf",
        "forum": "KQe9tHd0k8",
        "replyto": "KQe9tHd0k8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the setting of learning from label proportions (LLP), where we have access to aggregate labels over bags (i.e., grouped instances). The authors provide an approach that (1) implements belief propagation to assign pseudolabels to similar data points and (2) iteratively trains supervised classifiers with the pseudolabels (and the previous classifiers learned embeddings)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The authors provide a new scheme (based on Ising models and belief propagation) to propagate pseudolabels across datapoints taking into account bag constraints and covariate similarity.\n* They also derive a new architecture and objective during bootstrapping their supervised model on the produced pseudolables. This involves an additional hidden layer that produces soft scores over the bag to maintain correct bag proportions.\n* Good experimental gains over existing LLP baselines with large bag sizes."
            },
            "weaknesses": {
                "value": "1.  Lack of explanation/intuition about results. Are there any hypotheses as to why the results of your method are worse in cases with small bag sizes but better in cases with large bag sizes?\n\n\n2. Lack of discussion about work from the field of weak supervision, where there have been similar problems studied in the context of combining weak supervision (labels similar to aggregate labels over bags) and covariate information via clustering [1] and via label propagation [2]. In both cases, a model is trained after pseudolabels are generated (although no iterative refinement is done as these methods start from pretrained representations and supervised models are directly fit on the pseudolabels).\n\n\n3. A few typos that I noted (that don\u2019t overall affect my score):\n* Last line of page 7: \u201cthe iteration seem to help improve performance\u201d, should be \u201citeration seems to help improve performance\u201d\n* \u201cBag constraints\u201d in section 6.1 shouldn\u2019t be capitalized\n\n[1] Chen, Mayee F., et al. \"Shoring up the foundations: Fusing model embeddings and weak supervision.\" Uncertainty in Artificial Intelligence. PMLR, 2022.\n[2] Pukdee, Rattana, et al. \"Label Propagation with Weak Supervision.\" The Eleventh International Conference on Learning Representations. 2022."
            },
            "questions": {
                "value": "* See first point in the weakness section. Are there any particular intuitions as to why DLLP outperforms your method (somewhat consistently) over small bag sizes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698427001214,
        "cdate": 1698427001214,
        "tmdate": 1699636960427,
        "mdate": 1699636960427,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eEYvpwUf2e",
        "forum": "KQe9tHd0k8",
        "replyto": "KQe9tHd0k8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a method for the problem of Learning from Label Proportions (LLP), where only aggregate level labels are available for groups of instances. The proposed method incorporates both bag-level and instance-level constraints to address the LLP problem. Then, the Belief Propagation (BP) algorithm is utilized to solve the problem. Finally, the authors verify the proposed method for the  LLP Binary Classification problem."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The topic of this paper is interesting and important. Learning from Label Proportions (LLP) is a weak-supervised learning paradigm, which is beneficial for privacy protection.\n2. The proposed method exhibits good performance on large bag sizes."
            },
            "weaknesses": {
                "value": "1. The writing of this paper needs great improvement, e.g., the connection between the LLP problem and the parity checks should be clearly elaborated. The intuition behind this should be clarified.\n2. The bag-level and instance-level constraints are commonplace, making the novelty quite limited.\n3. The experiments were only conducted on Binary Classification problems, while the multi-class classification is a more general case.\n4. The formulation of the equations should be carefully checked, e.g., in Eq.(1), according to the definition of $y(S_i)$ (the third row in Section 3), the first term equals 0. Besides, the derivation from Eq.(1) to Eq.(2) should be provided for clear understanding.\n5. The proposed method performs well on large bag sizes, but the authors do not give explanations why this is the case.\n6. According to the results of Tables 4 and 5, the running time of the proposed method is far more than that of DLLP, besides, the running time of other methods is not reported.\n7. According to the results of Tables 9-13, the parameters seem to need very careful fine-tuning, and the sensitivity studies of these parameters are missed."
            },
            "questions": {
                "value": "1. Why do you introduce the Gibbs distribution in the modeling? The reasons should be detailedly clarified.\n2. Are the instances in each bag all labeled? If yes, then the bag level counts will equal the size of the bag.\n3. Is the size of each bag in this paper equal? What if the sizes of each bag are not equal?\n4. In Table 2, why not report the results of large size (512, 1024, 2048) as other tables do?\n5. According to the results of Tables 1-3, it is weird that the performance of DLLP(published in 2017) is better than that of GenBags(published in 2022) and EasyLLP(published in 2023). Please explain these."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698555197467,
        "cdate": 1698555197467,
        "tmdate": 1699636960309,
        "mdate": 1699636960309,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AaZEuUR5rT",
        "forum": "KQe9tHd0k8",
        "replyto": "KQe9tHd0k8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel algorithm for supervised learning from label proportions. One first builds a Gibbs measure that enforces the labels proportions within each bag and incentivizes nearby samples to have the same label. Then belief propagation (BP) is run on this measure, obtaining the marginals for each label. The marginals are converted to hard labels via thresholding. These new labels are then used to train a deep neural net. The network is trained on a double objective: one one side fitting the BP generated labels, on the other preserving the actual proportions of the labels in each bag. One of the internal representations of the network is then used as new covariates from which the BP and training are repeated. This algorithm achieves performances which are competitive with or superior to those of competing algorithms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written\nThe proposed algorithm is interesting and novel. \nThe experimental presented experimental evidence appears complete and compelling.\nThe algorithm achieves a good performance compares to other existing methods."
            },
            "weaknesses": {
                "value": "The proposed algorithm is slower than other algorithms it is comapred to."
            },
            "questions": {
                "value": "1. To enforce the label proportions directly in the BP have you tried sending $\\lambda_b\\to\\infty$ and then doing MAP decoding (i.e. instead of thresholding each marginal, you take the configuration of labels that maximizes the BP approximation to the Gibbs measure)?\n\n2. Can you provide some intuition into the architecture of the network g_L? For example what is the function of the average pooling and how it is applied.\n\n3.This is more of a comment: BP is supposed to be more precise on sparse factor graphs. Your factor graph is not sparse due to the term with $\\lambda_b$ coupling all the variables within one bag. Do you think there is a way to modify the Gibbs measure to keep the desired properties but having a sparse factor graph?\n\n4. Can you comment on the convergence of the BP iterations? Did BP converge? did the convergence time change with the size of  the training set? Did you use some trick to make it converge?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762461108,
        "cdate": 1698762461108,
        "tmdate": 1700555565954,
        "mdate": 1700555565954,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EdIptndI9T",
        "forum": "KQe9tHd0k8",
        "replyto": "KQe9tHd0k8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
        ],
        "content": {
            "summary": {
                "value": "This paper provided an algorithm to perform efficient learning from bag-level label proportions. The author utilized Belief Propagation on parity-like constraints derived from covariate information and bag-level constraints to obtain pseudo labels. Next, the Aggregate Embedding loss used instance-wise pseudo labels and bag-level constraints to output a final predictor. In the end, the authors also provided  experimental comparisons against several SOTA baselines across various datasets of different types."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Learning from bag-level Label Proportions (LLP)  is an interesting and valuable topic in the learning community. Privacy of data is one crucial consideration in this area.\n2. The literature part is clear.\n3. The structure of the paper is easy to follow.\n4. There is extensive experiment analysis on the algorithm performance."
            },
            "weaknesses": {
                "value": "Major\n1. In the setup section (section 3, p3), it lack the assumptions and descriptions on the data distribution (x,y), and bag distribution.\n1.1 For example, for distributions,  the proposed algorithm may not work and or could not converge\n1.2 Without data distribution assumptions, it will limit the guidance for practitioners. \n\n2. There is no analysis of the theoretical guarantee of the algorithm's performance.\n\n3. The proposed algorithm is much slower than the baseline algorithm, and the running time is about one order slower Table 4. However, the performance of the proposed algorithm in Table 2 and 3 are not significantly better in many setups.\n\n4. The 4 datasets in the experimental analysis are not real data on the bag-level. The bags are manually created.\n\n5. Some notations are not reader-friendly. \n5.1 For example, in formula (2), the meaning of  | | is not defined. \n5.2 3rd line in section 3 of p3, [m] is not defined.\n\nMinor\n1. In section 6.1, there is only time for one baseline algorithm, and it lacks time for other algorithms.\n\n2. Near all parameters are tuned. There is no guidance on how to choose them in practice for quick application. For example, there is no guideline for the stopping rule of the algorithm to ensure convergence.\n\n3. In the proposed algorithm, the pair-wise calculation could lead to a high order time complexity. For example, capturing k-nearest neighbors for every point x_i is a very slow process when the data size is large."
            },
            "questions": {
                "value": "1. What's the performance of the proposed algorithm on real bag-level data?\n\n2. What's the time performance of other baseline algorithms?\n\n3. Are there any stopping rules to decide when to stop the iteration and ensure the convergence?\n\n4. What's the distribution and bagging assumption required for the proposed algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824758527,
        "cdate": 1698824758527,
        "tmdate": 1699636960054,
        "mdate": 1699636960054,
        "license": "CC BY 4.0",
        "version": 2
    }
]