[
    {
        "id": "riwEh7rzbk",
        "forum": "efeBC1sQj9",
        "replyto": "efeBC1sQj9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_Ukgp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_Ukgp"
        ],
        "content": {
            "summary": {
                "value": "This paper combines several self-supervised reconstruction objectives as pretraining for motion prediction. The proposed method obtains state-of-the-art performance on two public leaderboards.\n\n\nUpdate:\nThis work demonstrates great performance and their findings might benefit the community, though the structure and idea is not entirely new. I change my score to 6."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strong emperical performance. The proposed method ranks top on two widely used leaderboards."
            },
            "weaknesses": {
                "value": "- Limited novelty: The model structure is not new, which is basically SceneTransformer [A], which should be considered as contributions. For the three pretraining objectives, it is very similar to Traj-MAE[B] and ForecastMAE[C], as stated by the authors as well. Compared to [B] and [C], they achieve better performance, but the paper does not give a thorough analysis regarding the difference. As a result, it is hard to determine the real working part of the method.\n\n[A]Scene Transformer: A unified architecture for predicting multiple agent trajectories. ICLR 2022\n\n[B]Traj-MAE: Masked Autoencoders for Trajectory Prediction. ICCV 2023\n\n[C]Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders. ICCV 2023"
            },
            "questions": {
                "value": "1. Could the authors explain more about the difference between your method and Traj-MAE/ForecastMAE and discuss why your method better performance than them? It might be the case that \"the devil is in the details\" and I think it is important to find out these details as your contributions. Otherwise, the proposed methodology is basically the same as Traj-MAE/ForecastMAE, which has nothing new.\n\n2. Do the authors plan to open source the code so that the community could easily reproduce the results and find out the working part? \n\n3. Missed reference: it seems that some classic transformer based works are not mentioned, which might cause wrong understanding of the contributions of this work:\n\n[D] Motion Transformer with Global Intention Localization and Local Movement Refinement. NeurIPS 2022 Oral\n\n[E] HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. IEEE TPAMI\n\n[F] Multi-modal motion prediction with transformer-based neural network for autonomous driving. ICRA 2022\n\n\nIn summary, the proposed method has strong emperical performance on the public leaderboards but the method described in the paper basically has nothing new compared to existing methods, which makes their contributions unclear. Since the authors neither provide any detailed comparisions and analysis with existing methods nor mention their plans for open source, I do not think the paper could provide much value to the community, thus I give a borderline reject.  If the authors could solve the aforementioned issues, I may change my scores accordingly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3735/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3735/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3735/Reviewer_Ukgp"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3735/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697542576414,
        "cdate": 1697542576414,
        "tmdate": 1700553959142,
        "mdate": 1700553959142,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eeGECGqmsG",
        "forum": "efeBC1sQj9",
        "replyto": "efeBC1sQj9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_siKy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_siKy"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a modeling approaching for the motion prediction problem for AVs that involves pre-training on self-supervised training objectives (masking and prediction of trajectory and road-graph portions) followed by fine-tuning for the downstream motion prediction task. \n\nPre-training is multi-task, with the masking of intermediate trajectory steps towards capturing motion kinematics, masking of road network vector attributes for better road topology and connectivity understanding, and sequential step masking of trajectory steps to create a motion prediction problem similar to downstream and capture spatio-temporal relationships between agent motion and road network.\n\nThis setup and the pre-training tasks with an ablation study of each of their contributions towards the final metrics are the main contributions of the paper. The results are demonstrated on Argoverse 1 and 2 challenges, where the paper achieves SOTA results with a convincing margin."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Pre-training and self-supervised learning for the motion prediction task are under-explored areas, and this paper sets a strong benchmark with strong results on a widely used public leaderboard.\n\n- The authors have opted for a simple stacked-transformer architecture without any bag-of-tricks, that helps keep the focus on the contributions from the pre-training tasks and setup.\n\n- The ablation studies are extensive and well set up, providing insights into contributions from the each of the proposed components.\n\n- Overall presentation of the paper is good and it is easy to follow. Along with the simplistic architecture, it would allow others to reproduce and build upon this work."
            },
            "weaknesses": {
                "value": "- The paper mentions using the test set (unlabeled wrt the actual task) for self-supervised learning. While the test set from Argoverse *is* available to users, the intention is to provide it so that users can run their own inference and submit the predictions. Using the unlabelled part of this dataset (road network, agent motion histories) for pre-training could be giving the model an unfair advantage. I would encourage the authors to report the results without using the test set anywhere in their training / validation, or at the very least report an ablation result without using the test set for pre-training.\n\n- While results are reported on both Argoverse 1 and 2, it would be good to see generalization of the proposed methods to at-least one other dataset such as waymo open dataset or nuScenes."
            },
            "questions": {
                "value": "Mainly the one mentioned in the \"Weaknesses\" section:\n- What is the impact on the results when not using the test set for pre-training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3735/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777548947,
        "cdate": 1698777548947,
        "tmdate": 1699636329529,
        "mdate": 1699636329529,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TROf6PnDOT",
        "forum": "efeBC1sQj9",
        "replyto": "efeBC1sQj9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_fR6X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_fR6X"
        ],
        "content": {
            "summary": {
                "value": "The paper presents SEPT (Scene Encoding Predictive Transformer), a framework for motion prediction crucial for autonomous vehicles operating in complex traffic environments. SEPT leverages self-supervised learning to develop a powerful spatiotemporal understanding of complex traffic scenes. The approach involves three masking-reconstruction modeling tasks on scene inputs, including agents\u2019 trajectories and road networks, pretraining the scene encoder to capture kinematics within trajectories, spatial structures of road networks, and interactions among roads and agents. SEPT, without elaborate architectural design or manual feature engineering, achieves state-of-the-art performance on the Argoverse 1 and Argoverse 2 motion forecasting benchmarks, outperforming previous methods on all main metrics by a significant margin. The pretrained encoder is then fine-tuned on the downstream forecasting task, demonstrating that the model gains beneficial knowledge through pretraining objectives."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. SEPT achieves state-of-the-art performance on two large-scale motion forecasting benchmarks (Argoverse 1 and Argoverse 2), outperforming previous methods by a significant margin in terms of various metrics.\n2. The ablation studies in the paper show that all combinations of the introduced tasks consistently improve the model\u2019s performance. Each task contributes additively to the enhancement of the model's predictive accuracy.\n3. The manuscript is well-written overall and presents its content in a clear manner."
            },
            "weaknesses": {
                "value": "1. The Introduction effectively illustrates the potential of SSL in motion prediction tasks. However, it could benefit from acknowledging previous works such as Traj-MAE and Forecast-MAE that have already explored SSL in motion prediction. The three self-supervised tasks presented appear to be inspired or derived from these preceding studies.\n2. The framework presented in the paper is well-organized and operational, but it seems to lack novelty and groundbreaking contributions in the area of study.\n3. It's observed that the predominant improvement in SEPT's performance relative to the previous state-of-the-art isn\u2019t chiefly attributed to SSL pretraining. This seems to be somewhat divergent from the central thesis and focus of the paper."
            },
            "questions": {
                "value": "1. Regarding the related work, you\u2019ve cited that the lane mask SSL task of Forecast-MAE didn\u2019t exhibit considerable advancement in the ablation study. However, in Traj-MAE, there was a significant enhancement noted in the HDMap mask. Isn't the consistent improvement across all SSL tasks already an established finding prior to this research?\n2. In table 4, there is a noted reduction of 6.4% in minADE on the validation set relative to the baseline without SSL pretraining. Meanwhile, SEPT shows a 10.1% and 12.3% decrease in minADE compared to Traj-MAE and Forecast-MAE, respectively. Could you elucidate whether the baseline model, even without the SSL pretraining, has already exceeded the performance of previous state-of-the-art methods? And what are the primary contributors to this enhancement in performance?\n3. On the other hand, it seems that in Traj-MAE, its pretraining method improved the baseline's 0.732 minADE to a final 0.604 minADE, marking a relative decrease of 17.5%. Would this imply that Traj-MAE's pretraining technique holds a comparative advantage or superiority over SEPT\u2019s methodology?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3735/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3735/Reviewer_fR6X",
                    "ICLR.cc/2024/Conference/Submission3735/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3735/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698829520450,
        "cdate": 1698829520450,
        "tmdate": 1700551906059,
        "mdate": 1700551906059,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fvLVjY2pW5",
        "forum": "efeBC1sQj9",
        "replyto": "efeBC1sQj9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_JZgu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3735/Reviewer_JZgu"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a modeling framework (SEPT) that leverages self-supervised learning to extract spatiotemporal relationships for traffic motion prediction. It involves three masking-reconstruction modeling tasks on scene inputs including agents\u2019 trajectories and road network, pretraining the scene encoder to capture kinematics within a trajectory, spatial structure of road network, and interactions among roads and agents. The proposed approach is evaluated on two public datasets, i.e., Argoverse 1 and Argoverse 2, and achieves state-of-the-art performance."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This work is well motivated in that the encoders built on universal architectures can develop a strong comprehension of traffic scenes through a properly designed training scheme. It leverages self-supervised learning to progressively develop the spatiotemporal understanding of traffic scenes.\n- The proposed method is novel and technically sound.\n- The effectiveness of the proposed SEPT is demonstrated by solid experiments on two of the largest datasets. It achieves significant improvement over the model learned from scratch on all motion forecasting metrics consistently.\n- Extensive ablation study shows that the three tasks collaborate and yield positive effects on the final performance.\n- This paper provides a good literature review, problem formulation, and discussion.\n- This paper is well organized and presented, and thus easy to follow."
            },
            "weaknesses": {
                "value": "- When it comes to model efficiency, the paper only compares with QCNet which is one of the largest models among all comparison methods. Since time-consuming is one of the main drawbacks of previous methods as is claimed in Section 1, it would be good to know the exact inference speeds of SEPT and the other comparison methods.\n- It would be good if the authors could talk more about their research findings in addition to presenting their approach, which I believe will inspire other researchers."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3735/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699074439868,
        "cdate": 1699074439868,
        "tmdate": 1699636329386,
        "mdate": 1699636329386,
        "license": "CC BY 4.0",
        "version": 2
    }
]