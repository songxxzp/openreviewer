[
    {
        "id": "c815SEj3tf",
        "forum": "nOf6sb63dT",
        "replyto": "nOf6sb63dT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_Eg4r"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_Eg4r"
        ],
        "content": {
            "summary": {
                "value": "This paper utilizes the intrinsic characteristics of the generative models as the inherent fingerprints for intellectual property protection. This new method requires no addtional modifications on the training data or the model parameters. The evaluation results on both text generation and image generation tasks demonstrate the effectiveness of this method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Trendy topic\n- New perspective for designing fingerprints\n- Good verification performance"
            },
            "weaknesses": {
                "value": "- Limited application scenarios\n- Lack of robustness evaluation\n- Exceed the page limit"
            },
            "questions": {
                "value": "This paper proposes a novel fingerprinting methods via utlilizing the intrinsic characteristics of the generative models. The fingerprint difference could be strengthened by the re-generation process. The authors provide both theoretical analysis and empirical evaluations to prove the effectiveness of this method. The evaluation results on both text generation and image generation tasks demonstrate the good performance of this method. \n\nHowever, I still have the following concerns.\n\n- Though the proposed method is a good trial to implement fingerprints without any modifications on the training data or the model parameters, the application scenarios for this method are limited. This paper implicitly assumes that there is no information loss during the generation process, which allows for the multi-round re-generation process. In the experiments for text generation, the authors also merely consider the translation task which is consistent with this assumption. However, for other text generation tasks like summarization, this method might not be applicable. Moreover, even for the image generation task, the authors also implicitly assume that the model owner knows the text prompts used by the suspicious generated images. Then what if the text prompt is unknown? I would suggest the authors elaborate more on this in their paper. \n\n- This paper lacks robustness evaluation. For instance, for the image generation task, will image transformations or pixel perturbations on the generated images affect the verification performance? I would suggest the authors add some experiments to evaluate the robustness of their method under various perturbations. \n\n- In Table 2, when increasing $k$ from 3 to 5, the performance for the Cohere authentic model with the M2M contrast model decreases. This result is weird. I hope the authors can add some explanations here. \n\n- The main text of this paper (before citation) has exceeded 9 pages, which violates the page limit for ICLR submission. I am afraid that this will lead to a desk rejection."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698243545318,
        "cdate": 1698243545318,
        "tmdate": 1699637160231,
        "mdate": 1699637160231,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "brXZPHKdGY",
        "forum": "nOf6sb63dT",
        "replyto": "nOf6sb63dT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to verify whether an image or text is generated by a protected model. This method can be useful for IP protection for the model owner."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed method seems interesting. Instead of using watermarks and training-based methods, this method propose a \"re-generation\" strategy, which is novel to existing methods."
            },
            "weaknesses": {
                "value": "1. The paper is poorly written, which misses many necessary introductions and clarifications. For example, in the introduction section, the paper is written to be motivated to provide IP protection for the model owner. However, in the illustrative figure in Figure 1, it is more like to protect the artists (data owner)'s IP. \n\n2. Besides, it is not clear the reason of Algorithm 2, because it is also different from the introduction in Eq. (1) and Figure 1. In Eq. (1) and Figure 1, they both use the protected model for re-generalization. Thus, there is no clues on the reason to also use $G_\\times$ for re-generation. \n\n3. For the theory part, no motivation or clarification on the meaning and use of these theories. \n\n4. The basic assumption of the proposed method also seems problematic. For example, in the image generative models, the paper never discusses how to input the image samples to the model for re-generate. Based on my understanding, the Stable Diffusion models are text to image models. Therefore, how to input images to these models? \n\n5. The paper should also discuss how similar or how different of the re-generation process and the traditional generation process. In practice, there is no way for the ''verifier'' to know how are the original samples are generated. In this way, whether the shift of generation process from re-generation can cause and compromise verification performance should also be discussed."
            },
            "questions": {
                "value": "Plz see the above question."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9219/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9219/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698694226507,
        "cdate": 1698694226507,
        "tmdate": 1699637160107,
        "mdate": 1699637160107,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XrmIn2azj6",
        "forum": "nOf6sb63dT",
        "replyto": "nOf6sb63dT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_Bepi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_Bepi"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a method for verifying data authorship in generative models without conventional watermarking. It discovers latent fingerprints inherent in deep learning models by comparing original data samples with their re-generated counterparts. It introduces a framework for generating and verifying these model fingerprints and establishes a practical protocol to authenticate data ownership in generative models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The approach of uncovering latent fingerprints through regeneration is novel. The observation of distance convergence is straightforward and interesting.\n\n2. The method is easy to implement. It uses standard generative models without requiring complex modifications to the model or additional tools."
            },
            "weaknesses": {
                "value": "1. In the neural language generation experiments, the paper used round-trip translation as re-generation. Since this is a relatively easy task, the same method might not generalize well to other, more demanding text generation tasks, such as creative writing which is more prevalent in real-world applications.\n\n2. The method\u2019s design, focused on distinguishing outputs between specific models, may not be adept at confirming if a piece of content is exclusively generated by a particular model. This is especially pertinent in scenarios where it\u2019s critical to ascertain whether content originated from a specific source, and not just differentiate it from another known model.\n\n3. The method is less effective for certain models as shown in Figure 3 and Appendix D.2.  \n\n4. The theoretical analysis looks good. One concern is that the Lipschitz constant could be larger than 1 for complex/deep models. Thus, the assumption may not hold for real-world generative models. This is not a major issue. Could authors mention this?\n\n5. The description of the method is not very clear. The subsection 3.3 is very short, which makes it very hard to understand. I suggest the authors to give some examples when describing the method. Otherwise, it is very challenging to understand the method after reading Section 3.\n\n6. The cost is very large because we need to repeat it k times to generate an output. Also, from Section 3.3, it is not clear how exactly the re-generation is done for text and image, e.g., line 33 in Algorithm 1. \n\n7. The robustness is not considered, e.g., an attacker could slightly change the words in a text. Will the proposed method still be effective in this case? I would suggest authors to conduct some adaptive attacks to study the robustness of the verification."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801766554,
        "cdate": 1698801766554,
        "tmdate": 1699637159909,
        "mdate": 1699637159909,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OHAOp8OpkE",
        "forum": "nOf6sb63dT",
        "replyto": "nOf6sb63dT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_XHuY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9219/Reviewer_XHuY"
        ],
        "content": {
            "summary": {
                "value": "The topic of intellectual property in Generative Adversarial Networks has been studied for quite some time. In this paper, the authors introduce an iterative re-generation method to enhance the fingerprints within current state-of-the-art generative models. The paper is well-organized and easy to follow, with a simple yet effective main contribution. The proposed method can be easily implemented to protect intellectual property without requiring any white-box settings, making it a lightweight and easily verifiable solution."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The proposed method is easy yet effective. The experiments are conducted comprehensively on both NLP and CV generative models. The proposed method can be easily implemented to protect intellectual property without requiring any white-box settings, making it a lightweight and easily verifiable solution."
            },
            "weaknesses": {
                "value": "- I am still unclear about how to verify the convergence of the distance between one-step re-generation (Distance Convergence). In Equation 2, the distance converges to 0, given that L \u2208 (0, 1). However, how can we guarantee that L is less than 1? Is this only confirmed through experiments?"
            },
            "questions": {
                "value": "Is the value of \\epsilon sensitive in the experiments? Since many LLM or MLM models are black-box, how can one select a sensible \\epsilon?\nIn the Appendix, as k increases, the accuracy does not seem to increase significantly. The experimental results may not be entirely consistent with the analyses in Equation 2. Is this discrepancy due to the presence of some other bad case samples, or is it because the distances are not larger enough?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837819318,
        "cdate": 1698837819318,
        "tmdate": 1699637159799,
        "mdate": 1699637159799,
        "license": "CC BY 4.0",
        "version": 2
    }
]