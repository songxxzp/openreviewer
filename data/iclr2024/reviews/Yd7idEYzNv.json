[
    {
        "id": "a9wFiBUb4t",
        "forum": "Yd7idEYzNv",
        "replyto": "Yd7idEYzNv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_BFci"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_BFci"
        ],
        "content": {
            "summary": {
                "value": "This work proposes EGALA, a scalable graph adversarial attack based on gradient approximation. Specifically, authors exclusively focus on the SGC as the surrogate model for attacking. By formulating the gradient of loss with respect to adjacency matrix as matrix product, EGALA adopts a scalable nearest neighbor search algorithm to identify the edges with largest gradients. Experimental results indicate that EGALA is more effective and efficient than prior scalable attack methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Overall, the paper is well-written.\n- Addressing the scalability issue of graph adversarial attacks is important.\n- Authors have evaluated on large-scale datasets."
            },
            "weaknesses": {
                "value": "- The gradient derivation is exclusively based upon the SGC model, which raises uncertainty about whether EGALA remains applicable to other, more advanced GNN models (e.g., GAT, GPRGNN, etc.). While authors have mentioned this limitation, I believe this is a critical issue and has to be addressed. Otherwise, I regret to say that the contribution of this work may not appear significant.\n- There are some approximation steps in EGALA, such as Equation 16 and the nearest neighbor search. Given that authors have not provided the theoretical analysis on those approximation errors, it is less convincing whether EGALA indeed accurately identifies those edges with largest gradients. One way to address this concern could be comparing the gradients approximated by EGALA with the actual gradients on some small datasets.\n- Authors only attack the scalable defense approach Soft Median. The results would be more compelling if authors could also attack other types of scalable defense methods (e.g., graph purification)."
            },
            "questions": {
                "value": "- Have authors adopted mini-batch training on large graphs? How does the mini-batch training affect the gradient approximation in EGALA?\n- How do authors perform hyperparameter tuning on all GNN models in the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Reviewer_BFci"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3975/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698603692258,
        "cdate": 1698603692258,
        "tmdate": 1699636358939,
        "mdate": 1699636358939,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ecD5wDec4A",
        "forum": "Yd7idEYzNv",
        "replyto": "Yd7idEYzNv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_d4tk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_d4tk"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a graph adversarial attack method, EGALA, which is efficient and can be applied to large-scale graphs. The core idea of EGALA is to reconfigure the computation of loss gradients across the entire adjacency matrix as the inner product of two N-by-d matrices. Then, EGALA utilizes clustering and Approximate Nearest Neighbor Search (ANNS) to efficiently identify the entries with the most significant gradients in the adjacency matrix without the need for exact gradient computation, thus significantly enhancing the model\u2019s scalability. The authors conduct comprehensive experiments across various datasets, demonstrating the effectiveness and transferability of EGALA."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed idea is technically sound and seems novel to me.\n\n2. The proposed method imposes minimal computational burden in terms of gradient calculations, making it highly efficient and memory-saving. It can be extended to larger graphs and avoids the instability associated with random block sampling.\n\n3. The proposed method is easy to implement."
            },
            "weaknesses": {
                "value": "1. The proposed method uses SGC as the surrogate model and cannot be extended to other surrogate models. Additionally, in the experiments, the surrogate model used in the baseline is SGC, which may reduce the baseline's attack capabilities.\n\n2. The experiments in the paper are not comprehensive enough. Providing more ablation experiments would be beneficial\u2014for example, the impact of \u0394_t in the algorithm. I also want to know the performance comparison of the PDG topology attack [1] and EGALA on small datasets.\n\n3. The proposed method is applicable to attacks that only involve structural perturbations, limiting the method's applicability.\n\n[1] Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, and Xue Lin. Topology attack and defense for graph neural networks: An optimization perspective. arXiv preprint"
            },
            "questions": {
                "value": "Please see [Weaknesses] above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3975/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698717843615,
        "cdate": 1698717843615,
        "tmdate": 1699636358804,
        "mdate": 1699636358804,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ImFSvE7DRi",
        "forum": "Yd7idEYzNv",
        "replyto": "Yd7idEYzNv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_rxwz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_rxwz"
        ],
        "content": {
            "summary": {
                "value": "The authors present EGALA, a method for constructing adversarial attacks on two-layer linear graph adversarial attacks at scale. EGALA approximates the gradient computation of the adjacency matrix as matrix product and efficiently identifies large entries in the gradients using Approximate Nearest Neighbor Search (ANNS), offering more scalable attacks with reduced memory and time consumption."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The derivation of the approximating gradient is convincing and elegant. The paper provides a solid theoretical analysis of how to derive the gradient of loss with respect to the adjacency matrix as a simple matrix product. \n\n2. The proposed EGALA improves the efficiency of naive attacks without sacrificing the attack capability in the evaluated transfer attack setting. The author approximates the gradient with a matrix product and leverages the acceleration techniques, ANNS algorithm, to further improve the efficiency. The motivation and design mechanism of this method is sound."
            },
            "weaknesses": {
                "value": "1. EGALA is limited to attacking the surrogate model of two-layer linear GCN (essentially 2-layer SGC), and it can be only applied in the transfer attack setting when the victim model is not the same as the surrogate model. However, it has been shown in [1] that the transfer attack is much weaker than the adaptive attack, and the robustness evaluated under transfer attacks exhibits a strong false sense of security. This concern significantly weakens the contribution of this work.\n\n2. The major baseline PRBCD is a randomized block coordinate method. PRBCD is efficient by selecting a small block size. More importantly, it is a general attack algorithm that can be applied to potentially any GNN model, without being limited to two-layer linear GCNs. Overall, the advantages of EGALA over PRBCD and GRBCD are not convincing enough. First, the attack performances of EGALA, PRBCD, and GRBCD are comparable in the transfer attack, while it is expected that PRBCD and GRBCD will provide much stronger adaptive attacks, especially when the evaluated model is robust GNNs (although no such study is presented). Second, the time complexity depends on many hyperparameters such as block size and number of clusters. However, there is no discussion and ablation study on the hyperparameter setting of baselines such as PRBCD and GRBCD. Therefore, the reported time cost comparison is not convincing enough. \n\n3. There is a lack of time complexity comparison of EGALA and EGALA-N. It will be better to provide detailed analysis as well as corresponding ablation experimental results. In Table 3, the paper shows that EGALA and EGALA-N share the same time and memory cost,  which raises concerns about the advantage of the proposed clustering-based ANNS. Additionally, it is unclear why the cost of EGALA on PubMed is higher than the other baselines.\n\n4. Lack of comprehensive ablation studies on several components, e.g., clustering method, number of clusters and number of closest vector pairs, period of cluster update. These components or hyperparameters can influence the accuracy and computation cost. Ablation studies should be included to show the impact of each technical component.\n\n\n[1] Mujkanovic, Felix, et al. \"Are Defenses for Graph Neural Networks Robust?.\" Advances in Neural Information Processing Systems 35 (2022): 8954-8968."
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3975/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698779112419,
        "cdate": 1698779112419,
        "tmdate": 1699636358707,
        "mdate": 1699636358707,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sxzzfLgBcl",
        "forum": "Yd7idEYzNv",
        "replyto": "Yd7idEYzNv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_ca4y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3975/Reviewer_ca4y"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel strategy, termed EGALA, for performing an adversarial attack on graph neural networks w.r.t. the discrete graph structure. For this, the authors utilize an efficient approximate method for determining the elements with the largest gradient in the N x N adjacency matrix (where N is the number of nodes). The authors compare their method to the state-of-the-art attacks PRBCD and GRBCD."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. In contrast to the state-of-the-art PRBCD and GRBCD, the novel approach EGALA does not rely on randomly sampled candidate edges to achieve efficiency. Instead, EGALA relies on approximate nearest neighbor search (with randomization) to focus always on the important edges.\n1. EGALA is 3.5 times faster than PRBCD and 1.5 faster than GRBCD on the large products graph. The memory cost is about 30% smaller.\n1. In the presented experiments, EGALA quite consistently outperforms PRBCD and GRBCD in terms of attack strength, although, the differences are often small."
            },
            "weaknesses": {
                "value": "1. The empirical evaluation is not exhaustive. E.g., the authors should evaluate also local attacks or visualize the approximation of the gradient (for small graphs). This would make the work more convincing in regard of general applicability as well as that the approximation is sensible. \n1. The authors only consider a grey box setting where the perturbations are transferred between models. This setting certainly has its merits. However, as pointed out previously, it is vital to assess neural networks with adaptive attacks [I, II] to get a proper estimate of the model's robustness. The authors should have prominently placed disclaimers and a comprehensive discussion on for what purpose the attack could be used.\n1. The attack is model specific and thus, it is not straightforward to make it \"adaptive\" for other GNNs than SGC.\n1. In connection to 2 & 3, the authors should craft experiments where they compare their transfer EGALA with an adaptive PRBCD and GRBCD. For example, the authors could attack defenses like Jaccard GCN, or SVG GCN (see [I]).\n1. The authors do neither test nor discuss local attacks on larger graphs like Papers100M (like PRBCD/GRPCB did).\n\nMinor:\n1. The authors could improve the references from Sec. 3.3. to eq. 11\n \n[I] - On Adaptive Attacks to Adversarial Example Defenses, Carlini et al., NeurIPS 2020\n[II] - Are Defenses for Graph Neural Networks Robust?, Mujkanovic et al., NeurIPS 2022"
            },
            "questions": {
                "value": "1. What is the exact asymptotic complexity of the approach?\n1. How is the computational cost affected by the hyperparameters?\n1. Is it necessary to approximate the derivate d a_ij / d e_ij for scalability?\n\nI will raise the score if the questions and other points are addressed accordingly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3975/Reviewer_ca4y"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3975/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792763006,
        "cdate": 1698792763006,
        "tmdate": 1699636358625,
        "mdate": 1699636358625,
        "license": "CC BY 4.0",
        "version": 2
    }
]