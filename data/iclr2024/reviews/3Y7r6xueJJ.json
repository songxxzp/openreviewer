[
    {
        "id": "6W3Zce2r8m",
        "forum": "3Y7r6xueJJ",
        "replyto": "3Y7r6xueJJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_C1FY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_C1FY"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the impacts of spurious correlations in the continual learning setting.\n\nFirst, the paper defines the experimental setups and evaluation metrics for investigating the issue of bias transfer.\n\nThen, the paper conducts experiments, arguing that bias exists and existing CL approaches cannot handle the bias. This is done first for the case of two tasks, and then generalized to longer task sequences.\n\nNext, the paper proposes a method to address the bias. The method consists of retraining the last linear layer using a balanced set of data samples."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Omitted."
            },
            "weaknesses": {
                "value": "In my humble opinion, the paper has several weaknesses:\n\n- The paper has limited novelty. In particular, the proposed problem is a basic combination of continual learning and bias of machine learning models. The proposed approach is a direct variant of Kirichenko et al. (2023). An analogy would be that the paper derives a corollary from a theorem in prior work. \n- In the experimental setting, the paper changes the input data by skewing them towards gray-scale images (or colored) images. This creates several issues:\n  - This setup makes the experiments artificial, human-made, and synthetic. The practical relevance is to be evidenced.\n  - The notation of bias is subjective. The way the paper changes the input data is just to make a shift of distribution or create subclasses from existing classes, rather than creating any bias. Retraining the last layer using a balanced set of data would of course improve in this case as it reduces the performance gap between (sub)classes and improves DCA. Therefore, the story the paper tries to convey is in my eyes a word game that is not convincing."
            },
            "questions": {
                "value": "I have no specific questions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5145/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698782140407,
        "cdate": 1698782140407,
        "tmdate": 1699636508608,
        "mdate": 1699636508608,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9AZnaWke9x",
        "forum": "3Y7r6xueJJ",
        "replyto": "3Y7r6xueJJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_A8St"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_A8St"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the impact of spurious correlations in the CL setting. Through comprehensive experiments, it confirms the existence of bias transfer in CL, affecting model predictions in both forward and backward directions. Then, they establish standard experimental settings, bias-aware CL scenarios, and evaluation protocols and introduce a practical baseline method called \"Group-class Balanced Greedy Sampling (BGS)\" for advancing bias-aware CL techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.    This article has a clear motivation. I also agree that investigating spurious correlations is a highly worthwhile topic in the CL setting.\n2.    The related work section of the article provides an excellent summary of the relationship between CL methods and spurious correlations.\n3.    The paper's approach to investigating bias awareness from three distinct angles, i.e., model bias, the relative focus on the Stability-Plasticity trade-off, and bias transfer, is comprehensive and convincing."
            },
            "weaknesses": {
                "value": "1.    The readability of the paper could be improved. The abstract and introduction should be revised to provide a more engaging and clearer overview of the research. \n2.    The paper introduces the Bias-flipped Mis-classification Rate (BMR) and the Difference of Classwise Accuracy (DCA) as metrics, but it lacks a detailed comparison of these metrics on the proposed benchmark datasets. It would be valuable to provide an in-depth analysis of how these metrics perform under different scenarios.\n3.    Table 1 should include further comparisons of CL baselines. A more comprehensive analysis of the performance of other CL baselines on the proposed benchmark datasets would provide a stronger basis for evaluating the proposed method.\n4.    While this paper introduces the BALANCED GREEDY SAMPLING (BGS) method, its novelty appears to be limited. The paper could benefit from a more thorough exploration of innovative techniques in the bias-aware CL domain.\n5.    The experimental analysis and the overall structure of the paper should be enhanced. This paper reads more like a forward-looking exploration of bias-aware scenarios rather than a comprehensive research work. It would be beneficial to present a more detailed and rigorous experimental analysis."
            },
            "questions": {
                "value": "1.    Can the paper provide a more detailed comparison between its proposed methods BGS and the GDumb and DFR CL methods to highlight their differences in addressing bias-aware CL scenarios?\n2.    Does Table 1 in the paper, which indicates a significant improvement in bias-aware CL scenarios when using the BGS method, imply that BGS may be less robust in scenarios with larger datasets, as increasing data has a limited impact on model improvement in all three scenarios?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Reviewer_A8St"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5145/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824834617,
        "cdate": 1698824834617,
        "tmdate": 1700725903815,
        "mdate": 1700725903815,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qIj4dxIOju",
        "forum": "3Y7r6xueJJ",
        "replyto": "3Y7r6xueJJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_6w81"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_6w81"
        ],
        "content": {
            "summary": {
                "value": "The paper revolves around the subject of bias transfer in continual learning (CL). The authors develop an experimental framework examining six CL strategies using two evaluation metrics across three scenarios, ensuring comprehensive analysis of the problem. Their findings show that CL techniques, unaware of dataset bias, can transfer such biases in both forward and backward directions. In response to this issue, they suggest a novel approach, Group-class Balanced Greedy Sampling (BGS), aimed at mitigating bias transfer. This paper is unique in the sense that it deliberates on the existence of spurious correlations in the CL context and calls for attention to develop bias-aware mechanisms in CL."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors address an often-overlooked issue of bias transfer in CL and provide a well-motivated argument adopting a fresh perspective in the field of CL.\n- Their analysis is fairly extensive, using six CL methods with three different scenarios.\n- The novelty of the proposed BGS method to mitigate bias without requiring any additional hyperparameter tuning enhances the paper's contribution.\n- The empirical evidence that reveals the existence of bias transfer in CL and its subsequent impact on the tasks makes a significant contribution to the field."
            },
            "weaknesses": {
                "value": "- While the empirical investigation of CL provides valuable insights, the novelty of findings and proposed BGS approach could be more explicitly addressed considering existing similar work in the domain.\n- The main limitation of this paper lies in the diversity of the samples used. The authors base their experiments on three benchmark datasets, all of which are synthetically created for Continual Learning (CL). From personal observation, it has been noted that such models can perform adequately even with a few hundred examples, contradicting the need for the 2000 or 4000 examples that BGS involves. By conducting tests in more authentic scenarios (such as shift in time/linguistic diversity, or the nature of the sequence to sequence task (like going from question answering to machine translation to paraphrasing etc)), a stronger foundation of support for the results could be established.\n- The paper's dual research goals are compressed into a limited amount of space, making comprehensive comprehension challenging. More in-depth discussion or a more detailed layout for the proposed BGS method would be beneficial.\n- The underlying mechanisms contributing to bias transfer are not entirely delved into in the paper."
            },
            "questions": {
                "value": "- The role and impact of the stability-plasticity trade-off on bias transfer in CL could be more thoroughly explored.\n- The experimental design lacks uniformity across all three CL scenarios and should strive for a standardized evaluation protocol.\n- It would be insightful to know if the bias transfer problem exists in substantial real-world applications (as shared in weaknesses) and what limitations exist in the experimental setup.\n- Why did you use LWF + Group DRO as a comparison in Tables 1(a) and 1(b) when ER is better performing than LWF? Could you share your rationale here?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Reviewer_6w81"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5145/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698833374946,
        "cdate": 1698833374946,
        "tmdate": 1700611395930,
        "mdate": 1700611395930,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PUnffJOs1J",
        "forum": "3Y7r6xueJJ",
        "replyto": "3Y7r6xueJJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_UUYC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5145/Reviewer_UUYC"
        ],
        "content": {
            "summary": {
                "value": "While most continual learning (CL) algorithms focus on the stability-plasticity trade-off, this study highlights the overlooked impact of dataset bias on knowledge transfer. Through systematic experiments on three benchmark datasets, the authors show that standard CL methods can transfer bias between tasks, affecting both forward and backward learning. The degree of bias transfer depends on whether the CL methods prioritize stability or plasticity. Bias transfer accumulates in longer task sequences. To address this issue, the authors propose a standardized experimental setup and introduce a simple yet effective baseline method called Group-class Balanced Greedy Sampling (BGS)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Amongst the works that look at CL and distribution shift, this is the one of the first papers to do an empirical study on impact of dataset bias on three different forms of CL: task-IL, domain-IL and class-IL. \n\n- The authors do a good job of structuring their findings, by first illustrating results in the two task case, followed by multiple tasks in a sequence. The metrics for bias (BMR/DCA) and CL (normalized $\\mathcal{F}-\\mathcal{I}$) are clearly defined.  In general the presentation is good, and the writing is clear. Particularly, experiment results in section 4 and 5 are well presented with easy to read plots. \n\n- The CKA analysis done on representations of penultimate layer (Sec 4.3) strengthens the empirical results observed.\n\n- The proposed baseline (group-class balanced greedy sampling) is fairly simple and combines ideas from GDumb and DFR. The algorithm presents significantly lower BMR over CL baselines in class-IL and task-IL settings."
            },
            "weaknesses": {
                "value": "- The datasets used for the experiments are small scale and synthetic. Using more natural datasets that evolve over time, e.g. FMoW dataset from Wilds benchmark, or other datasets from the Time-Wilds paper would be helpful. In some of these datasets, there is also group/attribute information that can be used to measure bias. \n\n- The paper can be improved with experiments that use a pretrained model (like CLIP), and then perform continual learning. It would be interesting to see if the same trends hold, or are they amplified/diminished with respect to forward/backward bias transfer.\n\n- I understand that theoretical analysis is not always feasible or even helpful, but for spurious correlations there exist simple settings/distributions in the SC literature where the SC induces failure even in linear models (see [1, 2, 3]). Extending these frameworks to the CL setting and then proving formal claims about forward/backward bias transfer can make the claims in this paper much stronger and build understanding to develop mitigation strategies and algorithms.\n\n[1] Nagarajan, Vaishnavh, Anders Andreassen, and Behnam Neyshabur. \"Understanding the failure modes of out-of-distribution generalization.\" arXiv preprint arXiv:2010.15775 (2020).\n\n[2] Ghosal, G. R., Setlur, A., Brown, D. S., Dragan, A., & Raghunathan, A. (2023). Contextual Reliability: When Different Features Matter in Different Contexts.\n\n[3] Sagawa, Shiori, et al. \"An investigation of why overparameterization exacerbates spurious correlations.\" International Conference on Machine Learning. PMLR, 2020."
            },
            "questions": {
                "value": "- In figure 4, for row 1, why does the CKA value drop even when bias of T1 is zero?\n- In figure 5, how does PackNet do on backward transfer?\n- Also can authors comment on why ER does much better than LWF and PackNet in general?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5145/Reviewer_UUYC"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5145/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699483506905,
        "cdate": 1699483506905,
        "tmdate": 1700630335438,
        "mdate": 1700630335438,
        "license": "CC BY 4.0",
        "version": 2
    }
]