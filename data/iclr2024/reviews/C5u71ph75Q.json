[
    {
        "id": "sLbTWShieE",
        "forum": "C5u71ph75Q",
        "replyto": "C5u71ph75Q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_U1Uk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_U1Uk"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a generative model for protein angles such that they try to not change absolute coordinates too much. The paper takes a functional Lagrangian perspective.\n\n--\n\nPost-response update: The mathematical concerns were adressed during discussion. I think this is a good and clever contribution to the field, while still having some weakness in demonstrating its ML significance."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The main idea of deriving how angles and coordinates are coupled through Lagrangian is outstanding. The paper is well written and method is well derived until around half-way. I found this paper super interesting to read, and this is definitely a promising approach.\n- The results show relatively good generation of variations wrt reference, but there are still quite a lot of room to improve."
            },
            "weaknesses": {
                "value": "- The math in this paper is sloppy and incomplete, and I\u2019m not convinced that the method is correctly derived. I suspect that the Lagrangian is incorrectly derived, but I would be happy to see full derivations of the method to verify if it is. The results have some issues, which implies that something is perhaps wrong.\n- I could not understand the generative model with VAEs and Unets, or the experiments. I\u2019m not sure what the paper or the models try to demonstrate or achieve, despite the clear problem statement of finding safe distributions of angles wrt coordinates. I think the paper deviates from the original problem quite far into somewhere else. I can\u2019t really interpret if the results are good or not.\n- The ML significance of the method is ultimately a bit light. There are only a few experiments, and no comparisons to other ML models. It seems that this paper is about finding variations in proteins. These are conformers, and there is already ML works on doing generative models for those. Comparisons to those are needed, and the paper should better positions itself to wider literature. Currently the paper takes too narrow and isolated perspective to the problem domain."
            },
            "questions": {
                "value": "- Why do you need to include the integral=1 constraint? Isn\u2019t p automatically a proper distribution?\n- I find the notation to be a bit odd. The eq 5 should be defined as a lagrangian; it's not a KL anymore. It has sufficient and necessary conditions for minima, and these should be properly formulated and presented. I\u2019m not sure what is a \u201cfunctional derivative of KL wrt p(Delta x)\u201d. What is a functional derivative? How can you take a derivative wrt a density evaluation at one point? Which point? All of them? Only one? Can you present this concept in more detail? There is an adhoc flavour to this, and I suspect something that the rigor is insufficient to actually claim you are doing a Lagrangian. You need to rigorously derive and present the Lagrangian formalism. If you want to take a functional viewpoint, then you need to derive the functional representations of the objects, eg. a hilbert representation of the distributions.\n- Why does the \\int p d term vanish in the derivative? Why does p(deltak) vanish as well? Surely this should not happen: Shouldn't you need to apply product rule and get Dp * log p/q + p * D(logp/q), where \u201cD\u201d denoted derivatives. I am not convinced this is correct. Please include all intermediate steps so we can verify its correct. Please include rigorous math that shows all the derivatives properly.\n- Similarly, I have trouble understanding eq 7. What does the approx do? How good of an approximation this is? Where does this come from? Please include all intermediate derivations, properly introduce and expose your math, and please include citations to textbooks or works where similar approaches have been done earlier. \n- How does an i\u2019th angle relate to m\u2019th atom i\u2019th coordinate? How come you have the same i'th index for two different things (phi/phi and x/y/z)?\n- Why is there no i in eq 8 suddenly? What is i and j? Why do we take a dot product? I have trouble following the story.\n- If you always normalise all Gaussians, why did you include the int=1 constraint?\n- I\u2019ve lost track where eq 9 comes from. What is this? Aren't Cm user defined constants: why are we now solving for their values? Also aren\u2019t you solving for the lambdas? Why are there none here? It seems that again quite a lot of intermediate derivations are missing, and I can\u2019t verify that this is correct.\n- What does it mean that you predict lambdas with a network? Err\u2026 Lagrangian multipliers can\u2019t be just chosen at will or predicted: the lagrangian formalism dictates under which coefficient values you can say something about your solution optimality. If you don\u2019t follow the lagrangian approach rigorously, you have no guarantees of what you end up with, and it might be of little use, or not do what you think it does. Are you perhaps not even doing a lagrange method but instead perhaps doing a penalty method? Can you clarify the setting and the goals and the overall workflow here? \n- I\u2019m lost on what are you trying to achieve with the VAE, and what\u2019s the point. So you take angles, encode them into latents, and reconstruct the angles. Why is this useful? What are we trying to achieve? If the reason you have a VAE is to evaluate derivatives, then something is wrong. Surely you should be able to just compute your derivatives directly?\n- So the VAE reconstruction as fed to a Unet that outputs lagrange multipliers\u2026 This feels adhoc. Why is it useful to predict lagrange multipliers? Intuitively this sounds wrong: the lagrange multipliers need to be at equilibrium point under lagrange conditions (etc), and not just predicted by some neural network. Can you elaborate what are you trying to do, and what role the lagrange has here? How much rigor are you even aiming at? \n- It seems that in the end you only produce a kind of soft regularisation by something that is inspired or slightly flavored with Lagrangians, but you are not actually doing Lagrangian optimisation. Given that the section 3 is named \u201cconstraints\u201d I was under the impression that you are actually doing Lagrangian constraints, but I don\u2019t think this is the case. Can you clarify what role the Lagrangian has?\n- I\u2019m quite confused what is the overall pipeline, and why you are doing what you are doing. I thought that you wanted to include constraints such that varying angles doesn't change the absolute coordinates too much. But in fig 3 the C\u2019s are not even present anymore, and it seems that the constraints now come dynamically from a Unet, based on coordinate means. What if the coordinate variances are large? What guarantees the Unet to give sensible constraints? How do we even define sensible constraints? What does the final N(mu,tildeSigma) represent, or try to do? Does this distribution still have something to do with constraints? What does \u201cweighed by Lagrange multipliers\u201d mean? Surely you can\u2019t just multiply your equation with some lambda\u2019s: the interpretation does not make sense if the lambdas are not chosen according to the Lagrangian theory.\n- What is the univariate Gaussian baseline? Is this some equation in the paper, or some completely new thing? Can you give a definition? What is empirical estimator? What is standard estimator? What is OAS? Can you elaborate what you estimating, and what\u2019s the story here? I think you are estimating something from the data, but not sure what. Maybe the precision structure? But why do you need the precision.. I thought that you needed the distribution of internal angles that are safe wrt too large absolute coordinate changes. Does this play a role in the experiments?\n- What are local and global constraints? What is \u201cvalid\u201d ramachandran distribution? What does \u201cimproved\u201d 3D variance mean? What do you improve? What is \u201cfull covariance matrix\u201d? Can you give a definition. Why is it full? How big is it? Covariance of what..? \u201cthat approximates distribution better\u2026\u201d Which distribution? Can you give a definition? What it the prior? Is it the eq 1? What is sigma_k,data? \u201cunderestimates the fluctuations\u201d What fluctuations? Of whose? What is the \u201cstandard estimator\u201d? What are you trying to achieve in the experiments? Can you clarify these points?\n- How does the VAE impose global constraints? What are global constraints?\n- Fig4: What is ramachandran reference? Where does the reference come from? What does it represent? What are the Rama samples? Where do they come from? Do these have something to do with data, or do they come from the model? What is MD reference? What does it represent or do?\n- Fig5: What does this figure show? Where do these energy landscapes come from? What did you learn here? Did you just learn to match the MD reference panel with the VAE? What are the axes of this panel? I\u2019m pretty lost what you did in the experiments, or what are you trying to demonstrate. The experiments do not discuss constraints or varying the angles in coordinate-safe ways at all, so I\u2019m wondering if this is the goal anymore. Can you help me understand?\n- What does \u201cfitting density of structural ensemble\u201d mean? What is an ensemble? Why is this an open problem? Are you talking about conformers?\n- \u201cWe obtain samples that are guaranteed to fulfil physical constraints..\u201d. With the amount of \\approx in the paper, this is very hard to believe. Do you really guarantee **this? In what part of the paper is this guarantee made?\n\nAs you can see I lost track around halfway point when the story changes from safe angular variations to generating proteins. I don't see how these two stories connect. I'm looking forward to clarifications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3708/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3708/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3708/Reviewer_U1Uk"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700379086,
        "cdate": 1698700379086,
        "tmdate": 1700557887329,
        "mdate": 1700557887329,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xzZcWkP96X",
        "forum": "C5u71ph75Q",
        "replyto": "C5u71ph75Q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_jsg1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_jsg1"
        ],
        "content": {
            "summary": {
                "value": "The authors parameterize protein structure with internal coordinates and estimate those quantities under the framework of a multivariate gaussian distribution. The authors then train a neural network to simulation data to estimate these parameters, and then sample from it, comparing to the simulation they trained on."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I think it is great the authors are able to define the limitations of their work with respect to the amount of data available for a protein of interest.\n\nThe description of number of parameters to be estimated (2.1) is very clear and helpful for intuition of the model components.\n\nI really like the \u201cVariance along the atom chain\u201d figures. I think they are really clear and show where the \u201cwiggles\u201d happen."
            },
            "weaknesses": {
                "value": "I still have difficulty with the motivation of using ML models trained on simulation data. Why not just run the simulation then? What does this improve beyond the simulation framework?\n\nI would like the TIC plots in Figure 5 better explained. Also, why does it seem that there are many points cut off from the figure?\n\nIt is odd to me that there are no scalar metrics in this work, especially those that allow comparison to other methods.\n\nWhile I understand the potential for this approach, I feel like the authors could do a better job of describing how this method could actually solve understanding of potential protein structure fluctuations."
            },
            "questions": {
                "value": "\u201cTo ensure this, we add an auxiliary regularizing loss in the form of a mean absolute error over \u03bb \u22121 ,\u201d Does this not introduce a Laplace likelihood (or prior) into the posterior? It\u2019d be great to explore that relationship and decision a bit more.\n\nIn Figure 4, looking at the Ramachandran plots, it seems like the samples are not capturing the actual variance in the data. Why is this? Is a Gaussian prior the right prior? What about Laplace or StudentT? Are there other parameters that could fully capture this variability, assuming that it is real?\n\nI would be curious of proteins that have very large degrees of freedom, or move a lot during function."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722838104,
        "cdate": 1698722838104,
        "tmdate": 1699636326783,
        "mdate": 1699636326783,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6N1mIHGRyY",
        "forum": "C5u71ph75Q",
        "replyto": "C5u71ph75Q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_QUDF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3708/Reviewer_QUDF"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the internal-coordinate density modeling of protein structures. One issue in internal-coordinate modeling is: small fluctuations in internal coordinates can lead to large fluctuations of atoms remotely.\n  - The authors first conduct some simulations in section 2.2 to show that even while sampling from the true mean/variance of internal-coordinates, the global atom positions fluctuate a lot.\n  - The authors then proposed adding a constraint on the variance of atom positions, and finding another multivariate Gaussian model on internal-coordinates that is closest (in terms of KL divergence) to the given distribution, while satisfying the variance constraints. This is realized by an approximate solution to Lagrangian formalism.\n  - The overall framework is VAE, with the above-mentioned correction to the Gaussian distribution.\n  - Experiments are conducted mostly on MD simulation data in two scenarios: where the structures have small fluctuations and large fluctuations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper tackles a well-motivated issue in internal-coordinate modeling.\n  - The proposed solution makes sense under the framework of multivariate Gaussian model.  - The experiments do not include enough baselines to validate the practical usefulness of this method. Many related DL methods are mentioned in related work, but they are not compared in the experiments. Although the authors mentioned the main focus of this work is internal-coordinate modeling, I am still interested in a more thorough comparison."
            },
            "weaknesses": {
                "value": "- The experiments do not include enough baselines to validate the practical usefulness of this method. Many related DL methods are mentioned in related work, but they are not compared in the experiments. Although the authors mentioned the main focus of this work is internal-coordinate modeling, I am still interested in a more thorough comparison."
            },
            "questions": {
                "value": "1. Section 3.5: U-net is used to estimate the values for the Lagrange multipliers \\lambda for each constraint. Is there any supervision or auxiliary loss on \\lambda?\n  2. Restricting the fluctuation will restrict the representation power of the model. How to balance that except for hand-tuning the hyper-parameters?\n  3. Any analysis to compare the models learned on the unimodal scenario and multimodal scenario?\n  4. Can the model generalize to generate conformers for new proteins?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828049722,
        "cdate": 1698828049722,
        "tmdate": 1699636326682,
        "mdate": 1699636326682,
        "license": "CC BY 4.0",
        "version": 2
    }
]