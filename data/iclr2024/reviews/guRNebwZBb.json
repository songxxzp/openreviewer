[
    {
        "id": "0PI7wwMUKe",
        "forum": "guRNebwZBb",
        "replyto": "guRNebwZBb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission327/Reviewer_mzWe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission327/Reviewer_mzWe"
        ],
        "content": {
            "summary": {
                "value": "This paper analyzes the convergence behavior of in-context learning under a certain parameter construction and shows that while both LM types converge to their stationary points at a linear rate, prefixLM converges to the optimal solution of linear regression while causalLM may include a bias that may not diminish even if the number of samples grows infinitely. They also show with experiments on both synthetic and real tasks that prefixLM seems to outperform causalLM given the same amount of parameters."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "* **Originality.** The paper reveals the surprising finding that CausalLM may underperform PrefixLM in the task of in-context learning.\n\n* **Significance.** The paper is of significance in understanding the in-context learning mechanism.\n\n* **Clarity.** The paper is well-written and easy to read.\n\n* **Quality.** The experiments are thorough and the theory is rigorous."
            },
            "weaknesses": {
                "value": "* To the reviewer's understanding, this paper hasn't excluded the possibility that there exists a parameter configuration that can allow CausalLM to reach optimal solution in the linear setting."
            },
            "questions": {
                "value": "* **Q1.** (See weakness) If the reviewer's understanding is correct, then a question is whether proving such a statement is possible.\n\n* **Q2.** Is it possible to convert a pretrained CausalLM into a PrefixLM during in-context learning through fine-tuning and improve the performance of ICL?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698500524709,
        "cdate": 1698500524709,
        "tmdate": 1699635959596,
        "mdate": 1699635959596,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GKqalPTYyN",
        "forum": "guRNebwZBb",
        "replyto": "guRNebwZBb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission327/Reviewer_m1Xp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission327/Reviewer_m1Xp"
        ],
        "content": {
            "summary": {
                "value": "The paper argues that in context learning with causalLM is inferior to in context learning with prefixLM. They extend the theory of Von Oswald et al. to include multi-layer Linear Self-Attention and multi-step gradient descent in the setup considered in Von Onswald et al., showing convergence result in the extended setup for both causalLM and prefixLM in context learning. Using their developed theory and experimental validation, they demonstrate that prefixLM is superior to causalLM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper follows an emerging line of papers showing the equivalence of gradient descent to in context learning in a very specific setup where the self-attention is linear, the objective is linear regression and the parameter matrices are hand-constructed.\n\nAbstracting away the limited setup, the paper does a good job extending the theory of Von Onswal et al. The theoretical argument is clear in my opinion and the evidences supporting the main thesis of the work are convincing enough. In particular, the paper does a good job arguing in details why prefixLM is better to causalLM both theoretically and empirically on more realistic setups."
            },
            "weaknesses": {
                "value": "My understanding is that this work aims at demonstrating that prefixLM is superior to causalLM for in context learning. While I believe they do a good job at it, I am under the impression that most projects already used prefixLM when possible. For example, InstructBLIP and Llama2 use prefixLM as far as I can understand. If this is the case that most influential language model or VLM already use prefixLM then I am unclear about the intended impact of this work.\n\nThe models used in this work are internal models that cannot be accessed by anyone outside Google. I believe that this is a big problem for open science and reproducible research. Unless the conclusions made in this work cannot be attained with available open models, which I highly doubt, I urge the authors to consider using open alternative to disseminate their results.\n\n\n\nMinor:\n* The considered theoretical setup seems contrived to me.  Since I don't expect the author to come up with a new theoretical setup, this point is not reflected in my evaluation of this paper. However, I believe that this is a weakness of this line of works and I would appreciate to be convinced why any conclusion made on this setup (LSA, linear regression and hand-crafted parameters) should necessary translate to more realistic setups.\n* Figure 1 is blurry on printed paper."
            },
            "questions": {
                "value": "* Does prior works generally use causalLM instead of prefixLM?\n* Are the empirical results presented in this work reproducible with open models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773072274,
        "cdate": 1698773072274,
        "tmdate": 1699635959524,
        "mdate": 1699635959524,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YbwpL8wW7L",
        "forum": "guRNebwZBb",
        "replyto": "guRNebwZBb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission327/Reviewer_RFAv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission327/Reviewer_RFAv"
        ],
        "content": {
            "summary": {
                "value": "The paper examines transformer-based in-context learning using pre-fixed language models (pre-fixedLM) and causal language models (causalLM). While pre-fixedLMs are empirically observed to outperform causalLMs, the theoretical reasons remain elusive. Through a convergence analysis, the study reveals that pre-fixedLMs optimally converge to linear regression solutions, whereas causalLMs follow online gradient descent dynamics, leading to suboptimal results. Empirical tests validate these theoretical findings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Theoretical understanding of different solutions found by prefix and casual LMs are provided under the linear regression setting, which seems novel.\n2. The paper also provides an empirical study to compare the solution found by prefix and causal LMs in different tasks, which verifies the theoretical intuitions."
            },
            "weaknesses": {
                "value": "1. The experimental setting is limited to a given number of in-context examples which seems to naturally favor prefix LMs. Casual LMs would train the model with different numbers of in-context samples simultaneously while prefix LM using all possible in-context and query partitions with the same in-context length. Testing with fewer in-context examples could be beneficial to provide more comprehensive results.\n2. Another unfairness in the experimental setting is that the nature of casual LMs would basically reduce the number of examples with the same in-context samples compared to prefix LM (i.e. for one input sequence, prefix LMs would enumerate all possible in-context and query partitions but casual LM would only have one for a specific context length). See Q1."
            },
            "questions": {
                "value": "Q1. A simple augmentation could be used to manually feed those other possibilities of partitions to casual LM, so prefix LM and casual LM would be trained with the same number of in-context and query possibilities for a given context length. Under this setting, would prefix LM still perform better than casual LM?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission327/Reviewer_RFAv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824521072,
        "cdate": 1698824521072,
        "tmdate": 1699635959421,
        "mdate": 1699635959421,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "K6amDXXfof",
        "forum": "guRNebwZBb",
        "replyto": "guRNebwZBb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission327/Reviewer_9q6M"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission327/Reviewer_9q6M"
        ],
        "content": {
            "summary": {
                "value": "In this work, authors relate the in-context learning abilities of causalLM architectures with that of an online gradient descent solver, versus the abilities of a prefixLM architecture that show convergence to the optimal solution at a linear rate. I found the experiments well conducted and the paper's results well presented overall. I'm unsure of the problem's relevance, but find the paper interesting regardless."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Primarily a study of ICL's limitations in standard transformer architectures, which use causal self-attention masking and hence causal language modeling objectives. prefixLMs' superiority is also described and the empirical results are interesting."
            },
            "weaknesses": {
                "value": "While I find the results and the paper itself interesting, as I mentioned in my summary of the paper, I'm unsure of the relevance of the problem. I think it would help improve the paper's impact if the motivations were clarified better: specifically, what models actually use a PrefixLM architecture in current literature and demonstrating or citing papers which show these models have a different qualitative behavior that a standard causalLM architecture."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699063149486,
        "cdate": 1699063149486,
        "tmdate": 1699635959362,
        "mdate": 1699635959362,
        "license": "CC BY 4.0",
        "version": 2
    }
]