[
    {
        "id": "YS42lhDsJ0",
        "forum": "4VgBjsOC8k",
        "replyto": "4VgBjsOC8k",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_9rPz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_9rPz"
        ],
        "content": {
            "summary": {
                "value": "The authors examine trained filters in depthwise-separable CNNs in order to shed light into learn representation in this type of CNNs.\nPreliminary visual inspection of those filters shows surprising regularity in their patterns and consistency across layers.\nAfter an initial PCA-based exploration of those patterns, the authors devised an auto-encoder based clustering to identify and visualize those patterns, which correspond to DoG functions and their 1st- and 2nd-order derivatives.\nThe authors analyzed those patterns in various depth-wise CNNs trained on ImageNet-1k and ImageNet-22k to study the prevalence of corresponding filters at different layers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ A novel analysis of CNN filters that focuses specifically on depthwise-separable CNNs.\n+ The analysis results seem novel, robust, and insightful. They demonstrate an important property of depthwise convolution that might make it better suited for future CNN-based architectures than standard convolution.\n+ The insights can help improve the design of depthwise-separable CNNs e.g. w.r.t. kernel size, number of filters per layer.\n+ The insights offer useful parallels to neuroscientific DoG-derivatives models."
            },
            "weaknesses": {
                "value": "These are not major weaknesses, but suggestions to generalize and strengthen the results:\n- ImageNet is object centric. It might be useful to analyze the patterns in a model trained on a scene classification (e.g. Places-365) or other scene-centric tasks (e.g. semantic segmentation of CityScapes) in order to find if new patterns emerge.\n  - To appreciate the impact of the dataset, check the examples of the 1st-layer filters reported in https://arxiv.org/abs/2204.08601\n- Have you considered the impact of other elements of convolution? For example, padding in intermediate layers can skew the filters learned if applied in a one-sided way as reported in https://openreview.net/forum?id=m1CD7tPubNy\n  - I think padding-induced skewness might offer explanation for the observed On-Square and Off-Square patterns. They might simply be skewed versions of the On-Center and Off-Center patterns.\n- Have you considered the impact of global pooling? It was shown to have a profound impact of the weights learned and the patterns that emerge within them https://distill.pub/2020/circuits/weight-banding/\n- It would be insightful to compare the reported findings with Deep Continuous Networks (Tomen et al., ICML 2021), where Gaussian derivative functions also emerge in the learned filters and the authors also draw similar biological parallels.\n\n\nLanguage issues:\n- Use \\citet instead of \\cite to avoid interference with the text (e.g. \"natural images Krizhevsky et al. (2012)\")\n- of both regular and DSCs => regular CNNs and DSCs\n- . in => In\n- We focus on [...[, apply [...] => and apply \n- The samples in each category, exhibit => no comma\n- The On-Centre and Off-Centre clusters, show => no comma\n- the recurring patterns we uncovered, arise => no comma\n- we demonstrated the predominant => that predominant\n- KMEANS (in appendix A.2) => K-Means"
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8688/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797153360,
        "cdate": 1698797153360,
        "tmdate": 1699637089273,
        "mdate": 1699637089273,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4zDFStK7E9",
        "forum": "4VgBjsOC8k",
        "replyto": "4VgBjsOC8k",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_GKik"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_GKik"
        ],
        "content": {
            "summary": {
                "value": "The work posits that convolutional architectures that have depth-wise separable convolution layers learn a few characteristically Gabor-like filters, which is a widely intuited concept for CNNs in general but never really proven in any sense. They demonstrate analytically that this observation spans a zoo of models of various origins with various characteristics and is not a happenstance. They also show that this is not only a phenomenon that shows up in the initial layers of the network as was already demonstrated by several works prior, but in deeper layers of the network as well. However, the authors stop short of drawing strong conclusions out of their novel and interesting observations."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The work is not completely, original in its thesis - scientists have long intuited the nature of convolutional features from the perspective of biological vision and compositionality. There are several well-known images in well-read pieces of work from the original AlexNet paper to the VGG paper and so on, that present the filters in their first layer and their seeming relationships to Fourier or Gabor basis functions, lest one forget the image and its mystery in the AlexNet paper that shows that one GPU learnt color while the other learnt grayscale. What is original in this work is that the authors have noticed that for depth-wise convolutional networks, these features remain Gabor-like much deeper into the network. Not only do they demonstrate that, they also show that there are only a handful of these features and they are all lower-order filters as well. Stronger yet is the correspondence the authors have shown that the more performant the network, the more stronger these observations hold. This observation raises several questions regarding filter complexity, model complexity and regularization for convolutional networks and its relationship to the the order of these filters. This work is strong is so far as it is set to drive other future works in this area in the direction of a potential canonical and foundational vision model."
            },
            "weaknesses": {
                "value": "As strong as these observations are, the reviewer feels that this work is incomplete. The following are the reasons why:\n\n1. The regularization argument: The authors note in several times including in their conclusions that the more lower-order and identifiable the features in a network are, the higher the generalization performance. One leads to wonder if these lower-oder DoG-like or Gabor-like filters have a regularization effect on the networks leading to higher generalization performance. This tantalizing hint should be explored further, even unto discovering a regularization process.\n\n2. Multiple pre-trained models for same architecture: The authors used pre-trained models on Imagenet for their analysis. There is a need here to make these conclusions stronger, that this effect is not only present on these particular instance of these models but are an inherent property of the architecture. To do so, further analysis need to be performed to demonstrate these observations over multiple training runs on imagenet and also over other datasets of both natural images and also images from other domains. This would make the observations stronger.\n\n3. Initialization/fine-tuning argument: In many a work on fine-tuning strategies such as in distillation, knowledge transfer, continual/incremental learning, observations has been made that so-called higher-frequency features often change and lower-frequency features remain unchanged. It also been noted in several works that fine-tuning mobilenets are harder than fine-tuning \"general purpose\" networks such as ResNets. This is largely the reason why most commercial use-cases involving fine-tuning convolutional networks use non depth-wise convolutional networks as their backbones. This here is a good stage to test this hypothesis and provide analytical evidence for or against the idea that networks that learn lower-order features do not change much during fine-tuning.\n\n4. Well-fit, over-fit, under-fit models: These observations are made at the end checkpoint of these models. There arises a temporal question of when in the process of training do these filters form. It was noted by Fergus et al., that the first layer filters on convolutional networks take the shapes of these DoG-like or Gabor-like filters very early on in training and the latter stages of training only change the high-frequency filters. The author's workbench is the ideal setup to test this hypothesis. Accompanying this question is also that of over-fit and under-fit networks. High-frequency filters are often an indication of overfitting in non-neural network settings, such as in dictionary learning for instance. The authors could deliberately overfit some of these networks and demonstrate the emergence of more of their \"other\" category of filters. \n\nThe reviewer understands that ICLR has a page limit on its work, but also would like to recognize that while this work is strong, there are a lot of actionable directions that could make stronger and more conclusive statements on top of the already well-done analysis."
            },
            "questions": {
                "value": "1. The obvious unanswered question from the paper is the mystery layer 10 of EfficientNet-b4 and b6, and layer 11 of b2. This would ideally be the case where multiple checkpoints be needed to verify that this is not just a quirk of the random seed of training this model.\n\n2.  What is happening in the layer 14 of hornet tiny?\n\n3. Is it possible to create a graph of the number of identifiable filters by your clustering algorithm v. the generalization of the network on a standard test dataset? This would further bolster the authors' argument that better networks have more simpler features."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8688/Reviewer_GKik"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8688/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809207867,
        "cdate": 1698809207867,
        "tmdate": 1699637089132,
        "mdate": 1699637089132,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M7b3FlpkZA",
        "forum": "4VgBjsOC8k",
        "replyto": "4VgBjsOC8k",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_hU9E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_hU9E"
        ],
        "content": {
            "summary": {
                "value": "This paper performs an extensive study on how the depthwise convolution (dwconv) kernels in the depthwise-convolution-employed convolutional neural networks (this paper calls them DS-CNNs)  look after training on an image classification task. The authors employ the ImageNet pre-trained DS-CNNs such as ConvNeXts, EfficientNets, and MobileNets for the analysis. The main analysis tools are unsupervised clusterings via autoencoder and k-means clustering, and the clustered kernels are seemingly similar in shape to those of DOG filters (including the first and second derivatives). The authors report several qualitative results of clustered kernel shapes from different architectures and the histogram reflecting the portions of the representative kernel shapes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- To my knowledge, this paper first analyzes the depthwise convolution.\n- The idea of analyzing DS-CNNs by visualizing the weights that are clustered to representative shapes is interesting. \n- This paper is easy to follow."
            },
            "weaknesses": {
                "value": "- The analysis is thought-provoking, but its significance is not fully realized. The ultimate goal of the analysis remains unclear to me. The paper effectively renders the clustered kernel in shapes akin to DOG or its derivatives, but it does not progress towards a more meaningful conclusion. This reviewer feels like there is a missed opportunity to extract and impart lessons, such as a connection to new network design principles for CNNs, which the analysis could potentially offer, yet such insights are not provided in the end.\n\n- This reviewer is questioning the necessity for the advanced and training-needed autoencoder-like denoising/clustering technique in the analysis when K-means clustering appears to suffice for simply examining the trends of the learned kernels, as shown in the authors\u2019 treatment of MobileNetV3. It is speculated that the denoising effect may smooth the actual filter's learned patterns, so the results may not be convincing. Furthermore, while the autoencoder is presumed to be more suitable for this analysis, a clear justification for this expectation is needed to validate its use as an analytical tool.\n\n- The introduced autoencoder-based analysis presumably gives more sophisticated results over K-means-like methods. However, there is speculation that the authors are employing a tool that aligns more closely with the desired DoG patterns. Furthermore, such learning-based methods would give underfitted results when training is not successfully performed."
            },
            "questions": {
                "value": "- I am still not convinced that the patterns of the learned kernels follow DoG shapes, because 7x7 kernels are still small. There are the DS-CNNs that employed much larger kernel sizes, if the authors would like to claim the filter shape is restricted to DOG or its derivatives, the authors should try to verify the claim on the models consisting of larger kernels [1, 2].\n  - [1] Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs, CVPR 2022\n  - [2] More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity, ICLR 2023\n\n-  What is the primary goal of computing the filter classification score in Table 1? and what does it imply when the filter classification accuracy is high?\n\n- Table 1 repots wrong ConvNeXtV2_tiny's top-1 accuracy on ImageNet-1k, which is not 84.9%. Please refer to the original manuscript.\n\nPre-rebuttal comments)\nThis reviewer finds analyzing the depthwise convolution and revealing common DoG-like patterns from DS-CNNs, which gives some insights. However, the impact of the analysis itself and further use cases remain unclear; the potential impact is also problematic and uncertain. Overall, the reviewer believes the paper does not reach the publication standards of ICLR in its present state, I would like to see the other reviewers' comments and the authors' responses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8688/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698853620379,
        "cdate": 1698853620379,
        "tmdate": 1699637089013,
        "mdate": 1699637089013,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jD8NWS5Mri",
        "forum": "4VgBjsOC8k",
        "replyto": "4VgBjsOC8k",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_Jbbg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8688/Reviewer_Jbbg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a study on the nature of the learned convolutional filters of various CNN architectures. They show that the kernels learned by depthwise-separable convolutions (DSC) are similar to DoG-derivatives filters, which draws connections with biologically inspired models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The paper offers a very insightful and novel view on the fact that DSC kernels learn DoG filters, which is to the best of my knowledge a new observation for CNN architectures. The visualizations, especially Figure 2, are very informative and clearly show this property of DSC.\n\n2) The clustering of kernels approach shows that the learned kernels which are DoG filters actually form a basis of DoG filters with specific shapes that the authors identify and show in Figure 5. This observation shows that DSC are more similar to biological models than regular convolutions which could inspire future CNN architectures.\n\n3) The claims of the paper are validated on a wide variety of models and many visualizations are presented, including in-depth study of each layer of each model and a lot of examples of kernels."
            },
            "weaknesses": {
                "value": "1) The authors suggest that better understanding the nature of what CNNs learn, and in this particular case the fact that DSC learn DoG-filters, would lead to architectural improvements or new architectures. However no actual concrete improvements or suggestions are proposed in the paper.\n\n2) The observations are interesting but a more interpretable model is not necessarily correlated to a better performance of the model, for example, vision transformers are the most popular architecture nowadays, they don\u2019t learn filters and are not inspired by biology. A more in-depth study of the performance on various tasks of models with DS-conv against models without would have been a good addition. For example, a study on the differences between ResNet and ResNeXt/ConvNeXt families. Or with a specific architecture by only replacing regular convolution with DSC.\n\n3) The paper claims that DSC learns a basis of DoG filters, which is highlighted by the visualizations and the clustering approach, but it might be the case that ResNet models and other models using standard convolutions also learn a basis of other functions/filters that are less interpretable, but still efficient for the final performance of the model. It is not clear that interpretability is a key advantage.\n\n4) The interpretation of what is the role of each \u2018basis vectors\u2019 DoG filter (such as \u201coff-center\u201d or \u201coff-center cross\u201d) is doing would help clarify what is the advantage for a CNN model to learn such filters.\n\n5) DS, DC, and DSC notations are used interchangeably throughout the paper and it is not clear if they mean the exact same thing or not. Could you clarify or use the same term for consistency ?\n\n6) Most captions of figures are not self-contained and very unclear, especially on describing how the visualizations are obtained and what conclusion should be drawn from the figure."
            },
            "questions": {
                "value": "1) In Figure 7, layer 10 has a strong proportion of \u2018square off\u2019 kernels, do you have an intuition on why this is the case ?\n\n2) Why do you need to use an autoencoder to learn kernel representations, could you not just use the kernels themself and use k-means ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8688/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699543975393,
        "cdate": 1699543975393,
        "tmdate": 1699637088908,
        "mdate": 1699637088908,
        "license": "CC BY 4.0",
        "version": 2
    }
]