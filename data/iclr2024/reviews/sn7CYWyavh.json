[
    {
        "id": "QVOWwMUusP",
        "forum": "sn7CYWyavh",
        "replyto": "sn7CYWyavh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_EK1V"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_EK1V"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hierarchical strategy for symbolic music generation. Specifically, their approach involves a cascade of conditional diffusion models which iteratively generate a series of interpretable representations in a coarse-to-fine fashion. The authors compare their proposed approach to strong baselines through both quantitative metrics and a qualitative user study, demonstrating promising performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is a nice paper overall. Among its virtues are (1) **the quality of the results**, (2) **simplicity of the approach**, (3) **usefulness for controllable generation**, and (4) **clarity of the writing**.\n\n**Result quality**. The proposed method achieves impressive results in both the quantitative evaluation and subjective tests, especially compared to strong baselines. Moreover, the included sound examples are quite compelling, and the contribution of the proposed hierarchical approach to the final outputs is immediately apparent.\n\n**Simplicity**. While the design of the hierarchical approach is somewhat complex, the proposed generative modeling approach is satisfyingly simple, with each stage using the same basic setup despite their structural differences, and later stages adding in well-motivated mechanisms to address clear issues (e.g., autoregressive component to generate locally but with global consistency).\n\n**Usefulness for control**. The proposed hierarchy (both in the data representation and modeling) is helpful for enabling long-form generation w/ global structure. However, it has an additional benefit of enabling interpretable manipulation of intermediate representations. While the authors don\u2019t specifically explore interaction, it is clear that this aspect of the approach could be very powerful for users.\n\n**Well-written**. This paper is extremely clear and well-written, especially relative to the median paper on music generation. Symbolic music generation, especially work that focuses on interpretability, tends to be a very messy subject with lots of in-the-weeds details that often manifest as confusing and poorly-written papers. All symbolic music gen papers tend to require substantial music expertise to fully understand, but this paper does a fantastic job of both minimizing the expertise needed and being exceptionally clear in overall formulation."
            },
            "weaknesses": {
                "value": "There are two primary weaknesses with this work: (1) **unclear if model is copying**, and (2) **impact is limited by data availability**\n\n**Unclear if model is copying**. This model is trained on a very small amount of data, just 909 songs. Despite this, subjectively speaking, the results from the proposed model are quite good. It seems quite plausible that the model is overfit to the training data and producing copies or near-copies. Can the authors provide any evidence that this is not happening?\n\n**Impact limited by data availability**. A broader issue is that extracting the proposed hierarchical representation requires rich annotations aligned with the raw notes: chords, melody, key, phrase boundaries, etc. Some of this the authors extract (e.g. key / phrase boundaries) and some of this comes from human labels (e.g. chords and melody). This limits the overall applicability of the approach to music datasets with such rich labels (POP909), and prevents application to much larger symbolic music datasets (Lakh) which cover more styles.\n\nLow-level comments:\n\n- Table 1 could describe M, \u03b3, \u03b4 in the caption\n- Table 1 would be well-complemented by a Figure 1 showing the languages visually and their relationships to music scores / one another\n- Sound examples page could have qualitative examples from baselines\n- It\u2019s a shame that there is no \u201coverall structure\u201d music in the whole-song subjective study, so users can rate if models produce music with clear long-form structure."
            },
            "questions": {
                "value": "Can the authors provide quantitative or qualitative evidence that the model is not overfit to the training data? If so, I would consider raising my score from a 6 to an 8."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Reviewer_EK1V"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698724233971,
        "cdate": 1698724233971,
        "tmdate": 1700585707447,
        "mdate": 1700585707447,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bhcmrZPmop",
        "forum": "sn7CYWyavh",
        "replyto": "sn7CYWyavh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_JPv8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_JPv8"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to learn to generate a full pop song with piano accompaniment as a hierarchical generation process. This paper defines a music language or representation of 4 levels. The generation process is then defined into four stages: form, counterpoint, lead sheet and accompaniment. In each stage, a diffusion model is used as the backbone generative model, generating the image-like representation at that level."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper proposes a novel hierarchical representation of symbolic music.\n2. This paper proposes a novel task formulation of generating full-song symbolic music and has a good qualitative result and offers a wide range of controlability."
            },
            "weaknesses": {
                "value": "The system, including its condition input, appears complex. The reliance on multiple pretrained models (as referenced in Section 3.3) might be cumbersome. It would enhance the paper's credibility if the authors could provide ablation studies both on the model's architecture and the efficacy of the control input."
            },
            "questions": {
                "value": "I wonder how this method applies to a more general MIDI-like dataset. Or does it rely heavily on the POP909 dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Reviewer_JPv8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762485958,
        "cdate": 1698762485958,
        "tmdate": 1699636357288,
        "mdate": 1699636357288,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "R8CnjLBgSP",
        "forum": "sn7CYWyavh",
        "replyto": "sn7CYWyavh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_JZXS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_JZXS"
        ],
        "content": {
            "summary": {
                "value": "The authors showcase a system to generate complete pop songs in pianoroll format. The approach consists in splitting the generation into a hierarchy of four stages. The representation for each of this stage can be computed directly from the original pianoroll and a bespoke algorithm termed Tonal Reduction Algorithm is introduced to compute the so-called \"Conterpoint\" representation.\nThe different level of the hierarchy are then generated iteratively by conditioning on the preceding stages using a diffusion model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This article features a very well-engineered system. The generated pop songs are convincing and seem to capture well the style of the POP909 dataset.\nThe presentation website features lots of interesting examples that sound well.\nIt shows that this model is able to cover many use cases beyond generation from-scratch: from accompaniment generation based on texture to leadsheet generation."
            },
            "weaknesses": {
                "value": "The main weaknesses seem the lack of details concerning the diffusion model and the sampling procedure.\nThis is even more problematic as it seems that the modeling process is not standard, with the diffusion model used to generate chunks of music in an autoregressive manner. \n\nIt is also unclear how the data is represented as it seems at first sight that the diffusion model used would be a Discrete diffusion model.\nAs such, it is not very accessible for people knowing the standard literature on diffusion models.\n\"We represent key by K \u2208 R2\u00d7M\u00d712, where tonic information and scale information are stored on the two channels\"\nIt may be interesting to emphasize on the non standard points .\n\n\nVery custom Tonal Reduction Algorithm. Seems very close from Polyffusion.\nThe results shown here may not be of interest for the broad ICLR community as the main contributions are mostly about symbolic music generation in a pianoroll format."
            },
            "questions": {
                "value": "The diffusion model used auto regressively\n\nWhat are the pretrained models for chord progression, rhythmic pattern, accompaniment texture?\n\n\"Conterpoint\" term for the second stage is not appropriate as this stage describes the sketch of the melody and harmony t. \"Draft\" or \"Sketch\" stage may be more suitable?\n\nLeadsheet encoded as melody and chords? Are chords in string format?\n\nWhat is the sampling time for a whole song?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831412801,
        "cdate": 1698831412801,
        "tmdate": 1699636357200,
        "mdate": 1699636357200,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IeRA4KeNfx",
        "forum": "sn7CYWyavh",
        "replyto": "sn7CYWyavh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_QD5q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3963/Reviewer_QD5q"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a new symbolic music generation system that can generate a full pop song. By defining four levels of music representations, the system generates piano roll from coarse to fine using a cascade diffusion model. The system is trained on POP909 and evaluated using objective metrics and a subjective listening test. The objective metrics show that the system can generate music with better long-term structural consistence. The listening test results show that the proposed system generates music of better quality."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper is a timely and significant contribution to the field of symbolic music generation. As far as I know, this is the first deep music generation model that can generate a full structural song given high-level structural hints.\n- The demo is impressive! Some of the samples are too good that I wonder if there is some overfitting issue (some nearest neighbor analysis might help clear these doubts).\n- The proposed model is clever. Figure 4 clearly shows how the musical compositional hierarchy imposes a proper inductive bias to the system."
            },
            "weaknesses": {
                "value": "- A discussion on the limitations of the proposed system is missing. I see two main limitations: First, the musical compositional hierarchy adopted here is constrained to pop music. Second, the high-level form and structures still need to be provided.\n- One thing missing in the evaluation is some nearest neighbor analysis to check if the model is returning part of the training data directly.\n- The evaluation doesn't really measure the capability of whole-song generation, but there is no proper baselines as far as I know, so it's fine."
            },
            "questions": {
                "value": "- (Section 1) \"and therefore we need to organize various music representations in a structured way.\" -> I cannot understand this sentence. Why do you mean by \"organize representations\"?\n- (Section 3.2) \"continuous\" -> I'm not sure what \"continuous\" means here. Are you using binary or real-valued piano rolls?\n- (Section 3.2) \"Both melody reduction and simplified chord progression ...\" -> How were these achieved? A pointer to the Appendix would be helpful here.\n- (Section 3.2) \"13 times\" -> Why 13 times? Isn't it 128/12 = 11 times?\n- (Section 3.3) \"We select Sk relevant music segments\nprior to t based on a defined similarity metric on X<k.\" -> Is this X^k or X^<k? The descriptions in this paragraph are somewhat confusing. From Figure 1, it seems like it's both  X^k and X^<k. Please clarify this.\n- (Algorithm 1) Isn't the song length M also an input?\n- (Section 4) \"40 measures\" -> How do you determine the number of measures to be generated?\n- (Section 5.1) \"... and segment them into 8-bar musical segments with a 1-bar hopping size.\" -> What is this segmentation step for?\n- (Section 5.3) \"Using pre-trained VAEs from Yang et al. (2019) and Wang et al. (2020).\" -> Are these the models you used to extract autoregressive controls?\n- (Section 5.3) How did you select the test inputs for the evaluation?\n\nHere are some other comments and suggestions:\n\n- (Section 1) \"(typically ranging from a measure up to a phrase)\" -> I don't think \"phrase\" has a strict definition.\n- (Section 2.3) It's good to scope this section properly as only symbolic music models are discussed here.\n- (Section 3.1) The musical compositional hierarchy discussed in this paper seems to be constrained to pop music. It would be help to discuss this limitation somewhere in the main text.\n- (Section 3.1) \"counterpoint\" -> I personally find this term confusing as we have melody and harmony here -- it sounds more like a \"reduced/simplified lead sheet\" to me.\n- (Section 3.3) \"The time scopes (image widths) of these diffusion models are more or less the same\" -> What do you mean by \"more or less\" the same? Please avoid such wordings.\n- (Section 4) Having this qualitative analysis before introducing the dataset is somewhat misleading. I don't even know what I should expect. Please consider rearranging the sections.\n- (Section 4) \"In Appendix A.4, ...\" -> I would love to see Figure 4 in the main text rather than Figure 2. The sheet music might be hard to understand for ICLR readers.\n- (Section 4) \"long (32 measures)\" -> This is still far from whole song evaluation.\n- (Section 5.3) \"whole-song (32 measures)\" -> I think 32 measures is still far from whole song generation.\n- (Figure 3) It would be great to also include the ground truth for 32-measure generation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Discussions on the copyright of the dataset is missing. Also, a nearest neighbor analysis is missing, which is important to check if the model is returning part of the training data directly."
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3963/Reviewer_QD5q",
                    "ICLR.cc/2024/Conference/Submission3963/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699078392491,
        "cdate": 1699078392491,
        "tmdate": 1700619464974,
        "mdate": 1700619464974,
        "license": "CC BY 4.0",
        "version": 2
    }
]