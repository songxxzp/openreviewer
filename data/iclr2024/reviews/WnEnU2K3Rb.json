[
    {
        "id": "a24ZTDZhnA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_fVMW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_fVMW"
        ],
        "forum": "WnEnU2K3Rb",
        "replyto": "WnEnU2K3Rb",
        "content": {
            "summary": {
                "value": "The authors study anomaly detection in video, presenting two datasets with video-level annotations and an adapted version of AI-VAD, called MFAD, which performs well on the proposed datasets. The presented method is also evaluated on three existing datasets, being compared with AI-VAD and other methods from literature."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Anomaly detection is an interesting and timely topic.\n- The paper is well written and easy to follow."
            },
            "weaknesses": {
                "value": "- The proposed method is incremental w.r.t. AI-VAD.\n- UCF-Crime and XD-Violence datasets are not included in the comparison provided in Table 1.\n- The proposed datasets are rearranged subsets of HMDB51. There was no manual annotation involved, or at least, the authors did not mentione anything about it. Therefore, it is hard to consider the proposed datasets as entirely new. Just as the method, this contribution is incremental.\n- The comparison in Table 1 does not reflect the difficulty / diversity advantages suggested by the authors. I do not see the benefits of the proposed datasets w.r.t. recent benchmarks such as UCF-Crime, XD-Violence or UBnormal.\n- The proposed datasets contain video-level annotations (the videos are labeled either as normal or abnormal), while other benchmarks contain frame or pixel annotations. I believe this type of annotation does not reflect a realistic scenario.\n- There is no time evaluation reported for the presented method. Anomaly detection methods are expected to run in real-time, but it is not clear if MFAD can do this. To me, the method is a bit heavy.\n- There are some some language corrections to be made, e.g.:\n  - \"It\u2019s crucial to\" => \"It is crucial to\" (language abbrevations should be avoided in formal language)."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697359138993,
        "cdate": 1697359138993,
        "tmdate": 1699636183866,
        "mdate": 1699636183866,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qzJbeDuUAI",
        "forum": "WnEnU2K3Rb",
        "replyto": "WnEnU2K3Rb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_A5Te"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_A5Te"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a multi-frame-based video anomaly detection method, that builds on top of [1]. In [1] mostly frame-level attributes are included, while the proposed method extends the method of [1] by including multi-frames encoding features extracted across 16 frames. \n\nFurthermore, the paper cherry picks two groups of anomalies from HMDB51 to show the importance of anomalies across the temporal axis. \n\nThe paper reports interesting results not only on the above two subsets of HMDB51, but also on few benchmark anomaly detection datasets. The results on the benchmark datasets are competitive compared to the chosen state-of-the-art methods, but outperforming them on the two subsets of HMDB51. \n\n[1] Tal Reiss and Yedid Hoshen. Attribute-based Representations for Accurate and Interpretable\nVideo Anomaly Detection, December 2022. URL http://arxiv.org/abs/2212.00789.\narXiv:2212.00789 [cs]."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-Good overview of existing methods and datasets used in anomaly detection. \n-\"Introducing\" new videos to video anomaly detection for benchmarking.\n-Comprehensive and competitive results on the public benchmarks and significantly higher results compared to state-of-the-art on the two subsets of HMDB51.\n-Proper ablation study. which also shows the effect of video encoding features in Table 4."
            },
            "weaknesses": {
                "value": "Despite the interesting results, the paper's method sounds like a simple extension of [1] by introducing temporal features to [1].\nThough the paper has cherry picked videos from HMDB51 and suggests using them for anomaly detection, they need claim this as their data (Table 1), which is not correct.\nThe abolition study shows that video encoder features alone are producing almost similar results with the entire set of features on the subsets of HMDB51, so what is the point in inclusion of other features? \nWhat about including/cherry picking some other videos from HMDB51 that are normal, but are similar to the abnormal videos already included in the two subsets?"
            },
            "questions": {
                "value": "Please see the previous section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2475/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2475/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2475/Reviewer_A5Te"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668666138,
        "cdate": 1698668666138,
        "tmdate": 1699636183795,
        "mdate": 1699636183795,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iFBXqr1Yh6",
        "forum": "WnEnU2K3Rb",
        "replyto": "WnEnU2K3Rb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_HVoz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_HVoz"
        ],
        "content": {
            "summary": {
                "value": "Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary.\nThis paper proposes a method for video anomaly detection that goes beyond the limitations of current benchmark datasets. The authors introduce two new datasets, HMDB-AD and HMDB-Violence, which challenge models with diverse action-based anomalies. They also present a novel method called Multi-Frame Anomaly Detection (MFAD) that incorporates deep video encoding features to capture long-range temporal dependencies and logistic regression to enhance the final score calculation. The experimental results show that MFAD outperforms existing methods on both simple and complex anomaly detection scenarios."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) The paper addresses the limitation of current benchmark datasets for video anomaly detection and proposes two new datasets that allow for the detection of complex action-based anomalies. This expands the scope of what constitutes an anomaly and encourages further research on more comprehensive anomaly types.\n(2) The proposed method, MFAD, simply incorporates deep video encoding features and logistic regression to effectively detect both simple and complex anomalies. The experimental results demonstrate the effectiveness of the method on benchmark datasets as well as the newly introduced datasets.\n(3) The paper is well-structured and clear. Based on the two datasets proposed in the paper, the method used performs better than existing methods."
            },
            "weaknesses": {
                "value": "(1) The paper lacks a more detailed description of the datasets HMDB-AD and HMDB-Violence. It would be beneficial to provide more information on the distribution of normal and abnormal activities, and any specific challenges or characteristics of the datasets.\n(2) The method proposed in this paper is more like a simple patchwork combination that lacks sound and rigorous theoretical support. Moreover, the paper lacks a more detailed and visual explanation of the proposed method.\n(3) The article lacks experimental validation of the effectiveness of the various components of the method. For example, the effect of redundant background information in deep image encodings was not verified.\n(4) The article also lacks a comprehensive analysis of the method's limitations, which would have facilitated a discussion of any potential challenges or failures. For example, the sub-optimal performance of the method proposed on the STC and Avenue datasets and the reasons for this should be analysed."
            },
            "questions": {
                "value": "1. How did you distinguish between normal and abnormal activity in multiple scenarios when constructing the two new datasets? What criteria were used?\n2. How did you extract the human pose estimation, object velocity and depth image coding, can you provide more details on these?\n3. How did you synthesise both few-frame and multi-frame features?\n4. What are the limitations or failure cases of the MFAD method?\n5. How did you verify the impact of each extracted feature on the results?\n6. What are the limitations or failure cases of the MFAD method? Why the proposed method is sub-optimal for experiments on the STC and Avenue datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698678505083,
        "cdate": 1698678505083,
        "tmdate": 1699636183692,
        "mdate": 1699636183692,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CysXj5mheY",
        "forum": "WnEnU2K3Rb",
        "replyto": "WnEnU2K3Rb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_y6mV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2475/Reviewer_y6mV"
        ],
        "content": {
            "summary": {
                "value": "The manuscript underscores the importance of Video Anomaly Detection (VAD) in surveillance systems. It criticizes the current focus on simple, single-frame anomalies in benchmark datasets and advocates for expanding the scope of VAD to intricate anomalies. The authors introduce two datasets, HMDB-AD and HMDB-Violence, to challenge models with diverse action-based anomalies, and present Multi-Frame Anomaly Detection (MFAD). MFAD builds upon the AI-VAD framework, incorporating single-frame and two-frame features and applying density estimation. To tackle complex multi-frame anomalies, deep video encoding, and logistic regression are added. Experimental results highlight limitations in existing models with new anomaly types, demonstrating MFAD's proficiency in both simple and complex anomaly detection scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths of the MFAD approach:\n\n++ Comprehensive Feature Extraction: MFAD extracts four diverse feature types, including object velocities, human pose estimations, deep image encodings, and deep video encodings, enabling a holistic analysis of video data.\n\n++ Adaptive Density Score Calculation: Using Gaussian Mixture Models (GMM) for velocity features and k-nearest neighbors (kNN) for other high-dimensional features, it adapts the density score calculation to the nature of the features, enhancing anomaly detection accuracy.\n\n++ Max Feature Aggregation: The addition of the 'max' feature, which aggregates maximum feature scores per frame, adds value to the approach, improving anomaly detection.\n\n++ Gaussian Smoothing: The application of Gaussian smoothing to anomaly scores reduces noise and provides more stable and interpretable results.\n\nOverall, MFAD's strengths lie in its feature diversity, multi-modal analysis, adaptive density scoring, effective feature fusion, supervised learning, and robust experimental design, making it a powerful method for detecting both simple and complex anomalies in video data."
            },
            "weaknesses": {
                "value": "Looking at the manuscript, weaknesses are provided below. \n\n-- Complexity: MFAD's multi-stage process and diverse feature extraction can make it computationally demanding and challenging to implement in resource-constrained environments.\n\n-- Model Specificity: Utilizing specific video foundation models may reduce adaptability to different datasets or domains.\n\n-- Not Real-Time: Computationally intensive and a requirement for separate training/testing data make real-time application challenging.\n\n-- Gaussian Smoothing Limitation: Applying Gaussian smoothing may not suit all anomaly patterns, potentially leading to information loss."
            },
            "questions": {
                "value": "There are just a couple of questions that I need clarification on!! \n\n--> How does MFAD handle the challenge of real-time video anomaly detection given its computational complexity? As I can see the author has provided the note for reproducibility, some insights would be helpful to understand the scope. \n--> Can MFAD adapt to different video datasets and domains effectively, or is it limited by its reliance on specific video foundation models?\n\nCurrently, I'm leaning towards accepting this work, if the Authors can provide some insights into the weakness & questions section, that would be helpful to understand the significant contribution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818562971,
        "cdate": 1698818562971,
        "tmdate": 1699636183594,
        "mdate": 1699636183594,
        "license": "CC BY 4.0",
        "version": 2
    }
]