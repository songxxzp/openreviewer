[
    {
        "id": "Gyo8Lffp4p",
        "forum": "G32oY4Vnm8",
        "replyto": "G32oY4Vnm8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_GXco"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_GXco"
        ],
        "content": {
            "summary": {
                "value": "This paper presents PTaRL, a model-agnostic method to enhance deep-learning methods for tabular data prediction. The method inserts a sound prototype learning step after the penultimate layer of any DNN to alleviate the issue of representation entanglement and localization. The results show improvement across several architectures and datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problems identified (representation entanglement and localization) and the results (including the ablation study) are convincing.\n- The various steps \u2014 the joint optimization of DNN representation, prototypes, and projection coordinate plus the two constraints \u2014 are intuitive. \n- The paper reads smoothly."
            },
            "weaknesses": {
                "value": "- The concepts of \u201cglobal data structure information\u201d and \u201csample location\u201d are not very clear, at least not as concretely demonstrated as entanglement and orthogonality."
            },
            "questions": {
                "value": "The whole purpose of using the prototype seems to be for capturing \u201cglobal data structure information\u201d so as to avoid \u201csample localization\u201d. However, after reading Section 4, I am still unclear what \u201cglobal data structure information\u201d really is. Could the authors provide a more explicit definition and description of it? Similarly for \u201csample location.\u201d\n\nI feel Figure 4 is a much better example of disentanglement than Figure 1, because I still see substantial overlap in the bottom row of Figure 1.\n\nI don\u2019t quite understand how Figure 5 shows diversification.\n\nI was wondering where the boosted performance sits in the literature as a whole. The paper shows DNN and DNN + PTaRL. Do these now match the performance of XGBoost and other state-of-the-art tree-based methods? How much better are they compared to older methods, such as kernel prototype classification and regression? Is it possible to apply PTaRL on different DNN depths to show the contribution of deep-learning representation vs the contribution of the prototype representation? I think knowing the answer to the first question (related to XGBoost) will be very useful. I can understand if the authors feel the other questions are more distracting than useful, since the paper has a focus on enhancing deep-learning approaches.\n\nOverall, the paper is quite well rounded. The problems, solutions, implementations, and results all work together well."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Reviewer_GXco",
                    "ICLR.cc/2024/Conference/Submission2154/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698718683576,
        "cdate": 1698718683576,
        "tmdate": 1700619337127,
        "mdate": 1700619337127,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zt97633uml",
        "forum": "G32oY4Vnm8",
        "replyto": "G32oY4Vnm8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_z5Xh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_z5Xh"
        ],
        "content": {
            "summary": {
                "value": "The existing deep tabular ML models suffer from the representation entanglement and localization. To address this, the authors explore a novel direction of applying prototype learning  framework. The proposed framework involves to construct prototype-based projection space and learn the disentangles representation around global data prototypes.\n\nThe proposed method contains two stages: prototype generating and prototype projecting. The former is to constructs global prototypes as the basis vectors of projection space for representation, and the latter is to project the data samples into projection space and keeps the core global data information via optimal transport. The authors show the efficiency of the proposed method with various benchmarks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The proposed approach is novel and the experimental results are impressive."
            },
            "weaknesses": {
                "value": "It would be great if the authors apply the proposed method to recent deep models for tabular representation, such as SAINT [1].\n\n[1] Saint: Improved neural networks for tabular data via row attention and contrastive pre-training, NeurIPS workshop 2022"
            },
            "questions": {
                "value": "I wonder if the authors believe that the proposed method can be applied to generative models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Reviewer_z5Xh"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831503830,
        "cdate": 1698831503830,
        "tmdate": 1699636148416,
        "mdate": 1699636148416,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZHCtPZD6vv",
        "forum": "G32oY4Vnm8",
        "replyto": "G32oY4Vnm8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_7NUi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2154/Reviewer_7NUi"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces several techniques to improve the performance of neural networks on tabular data. The study demonstrates that deep tabular models often face issues related to representation entanglement and the loss of global structure. To address these challenges, the paper proposes the construction of a prototype-based projection space with two carefully designed constraints aimed at decoupling the projected representations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The suggested representation learning pipeline can be integrated into various deep tabular models.\n- Figure 1 clearly illustrates that the phenomenon of representation entanglement has not been mitigated as the model capacity is gradually increased.\n- The primary concept for enhancing representation involves using weighted prototypes to approximate the original mapped features. This idea is indeed intriguing."
            },
            "weaknesses": {
                "value": "- The illustration (Fig. 2) does not clearly depict the overall pipeline; it still remains unclear.\n- More details of the optimization process could be provided."
            },
            "questions": {
                "value": "1. How is equation (4) optimized? Compared to the traditional OT problem, it includes \\theta_f as a variable to be optimized.\n2. Could you provide more technique details about the workflow of the PTARL algorithm (Algorithm 1)?\n3. The illustration (Fig. 2) could benefit from improvement as it currently lacks clarity in depicting the overall pipeline. For instance, there are two blocks labeled \"Hidden Representation\"; could you clarify the distinction between them? Additionally, the three sentences on the right side of the figure require further explanation for better understanding."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2154/Reviewer_7NUi",
                    "ICLR.cc/2024/Conference/Submission2154/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698836268944,
        "cdate": 1698836268944,
        "tmdate": 1700740180278,
        "mdate": 1700740180278,
        "license": "CC BY 4.0",
        "version": 2
    }
]