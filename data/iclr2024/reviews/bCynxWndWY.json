[
    {
        "id": "76RMdfpKqK",
        "forum": "bCynxWndWY",
        "replyto": "bCynxWndWY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_WvUe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_WvUe"
        ],
        "content": {
            "summary": {
                "value": "This paper revisits the problem of training decision trees under the constraint of differential privacy. In prior work, it was shown that random boosting was more effective than greedy approaches due to the extra privacy overhead incurred by using private data to make greedy selections. This paper shows that greedy approaches can be competitive with random boosting by making a series of improvements, including better composition using RDP, different utility functions, and Gaussian noise. Specifically, the paper highlights several cases where the greedy method can have an advantage: when features have interactions and when a low number of decision trees is needed. In general, it is shown greedy methods can give the best performance in the low number of tree regimes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- It is interesting to showcase settings where spending the additional privacy budget on node selection makes sense. \n- Shows a clear trade-off between greedy and random approaches and that greedy methods were underestimated previously.\n- Generally clear and well-written (with some typos).\n- Experiments on many datasets."
            },
            "weaknesses": {
                "value": "## Novelty\nThe main components are a combination of previously known approaches. Namely:\n- 4.1 uses Maddock et al.'s work\n- 4.2 uses the score function of Li et al.\n- 4.3 uses the same Gaussian mechanism approach as Maddock et al./Nori et al.\n- The composition appears to be very similar to Dong et al.'s work (see below for more details)\n\nThe experiments show that the combination of these approaches performs well. However, it needs to be made clear which components contributed to the success. An ablation study would be very insightful to show if, for example, it was simply the composition theorem that caused the greatest improvement or some other component. \n\nIf each component is not novel, then the study of all the components together is the contribution of this work. An ablation study would more rigorously study the effect of each component and give better insight into why previous work failed.\n\n## Composition Theorem\nThe relationship to prior work by Dong et al. needs to be clarified.\n- Nowhere in the Dong et al. paper is zCDP mentioned (after searching the pdf), so the derivation of the CDP bound plotted in the comparison needs to be justified.\n- The proof of Theorem 1 follows incredibly closely to the proof of Theorem 5 in Dong et al. Specifically, see proof of Lemma 7.3 for very similar expressions on page 35. Perhaps the authors can clarify this relationship as it seems they compared to Corollary 3.1 of Dong et al. in Figure 1 of the submission and not Theorem 5 of Dong et al. (which seems very similar if not identical to the result in this paper). \n\n## Evaluation limitations\n- Besides the suggested ablation study above, another missing component is varying epsilon. As far as I can tell, all evaluations were conducted at epsilon equals 1. I would suspect that with decreasing epsilon, the results would be much different as the greedy selection would tend to random selection, and then this method would once again be strictly outperformed by random boosting. Furthermore, increasing epsilon may increase the advantage of the greedy method. The privacy utility trade-off is an important aspect to study, and only studying a single epsilon gives a very limited view.\n\n- This work would benefit from a test for statistical significance. Most results had a high standard deviation; thus, deciding when a win is statistically significant is difficult. A hypothesis test or plotting confidence intervals would help to show more clearly when one technique outperforms another. Further, the ranking is somewhat misleading as it hides how close the techniques were to each other.\n\n- $1/n$ is too large for a delta parameter. It technically allows a trivial mechanism that publishes a single record of the database. The general rule of thumb is that $\\delta << 1/n$ [Dwork & Roth](https://www.nowpublishers.com/article/Details/TCS-042). I don't believe changing the delta would affect the overall conclusions of the paper, so I am willing to let it go, but I wanted to bring attention to it.\n\n- Figure 2 I could not find the number of runs and what the shaded area represents\n\n## Typos\nThis paper has numerous grammatical errors. I give a small subset of examples below:\n- Citations should be wrapped in parentheses to distinguish from text\n- Missing the word \"the\" in many cases (e.g. footnote three the sample Hessian)\n- Page 1: \"is a well tested\" -> \"are a well tested\".\n- Page 3: missing a prime. x and x' are the same after adding or removing.\n- Page 3: RDP definition \"M_1 satisfy\" -> \"M_1 satisfies\".\n- Page 4: by choosing fk+1 greedy at (k + 1)-th boosting rounds."
            },
            "questions": {
                "value": "Can the authors clarify the novelty of their work? Most importantly, can they clarify the relationship of the composition theorem with Dong et al.'s work?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Reviewer_WvUe"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698146979563,
        "cdate": 1698146979563,
        "tmdate": 1699636738771,
        "mdate": 1699636738771,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "umHhewHfhW",
        "forum": "bCynxWndWY",
        "replyto": "bCynxWndWY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_3J8a"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_3J8a"
        ],
        "content": {
            "summary": {
                "value": "The paper evaluates tree ensembles in the setting of differential privacy. Boosting methods with random splits and greedy splits were studied, and the empirical evaluation demonstrated a new perspective on applicability and performance of the most popular boosting methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A thorough review of related work was done. Key components of the proposed boosting algorithm were selected from best performing prior art models with additional modifications, and key properties were described with relevant references."
            },
            "weaknesses": {
                "value": "It was hard to separate novel parts of the work and existing components - for understanding exactly what contributes to the mentioned positive empirical evaluation. Because of this, it was unclear to what extent there is a novel contribution (a significance of modifications mentioned in equation 3 and theorem 1) and what part of the result can be attributed to a permutation of already known techniques."
            },
            "questions": {
                "value": "Is it possible to perform an ablation study (or are there already such results) by starting exactly with prior art (such as the Maddock et. al), and modifying one component at a time to evaluate a contribution of each proposed modification - to be able to emphasize the specific novel parts in the paper? (Tables 3 and 4 in the appendix refer to the components used when comparing to prior art, and there appear to be multiple modifications at once.)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Reviewer_3J8a"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834978737,
        "cdate": 1698834978737,
        "tmdate": 1699636738668,
        "mdate": 1699636738668,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SjUGPhODXG",
        "forum": "bCynxWndWY",
        "replyto": "bCynxWndWY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_QR2x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_QR2x"
        ],
        "content": {
            "summary": {
                "value": "This paper explores methods for differentially private decision trees. It introduces a method for greedy decision trees and, contra prior work, argues that greedy methods can be competitive with random methods.\n\nThe paper performs experiments on a number of data sets and goes into some detail analyzing in which settings different methods perform better."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Decision trees are a cornerstone of practical data analysis. The best DP versions of these methods are far from settled. I expect there is serious room for improvement and this work helps to fill some gaps. The question of greedy versus random methods is quite important.\n\nThe paper bridges theory and practice, aiming to bring strong analytical tools to improve practical algorithms. \n\nI appreciate the level of experimental analysis. Asking and answering questions like \"which method is best with few trees?\" is valuable to practitioners."
            },
            "weaknesses": {
                "value": "I feel there are three major issues that leave me with low confidence in the results. I must vote for rejection. I heartily encourage the authors to address these issues and resubmit to a different venue.\n\nFirst, the algorithm(s), privacy claims, and privacy proofs are not formally stated. This is a cause for serious concern, especially since one of the claimed contributions is the use of better privacy accounting methods. The reader cannot hope to replicate the experiments or verify that the algorithm is private.\n\nSecond: one of the central citations is to Maddock et al., who investigate private decision trees in a federated setting, so the data is decentralized. This submission does not appear to discuss this aspect of algorithm design. I am unsure if the proposed algorithm works in a federated setting and, if not, why the work of Maddock et al. is useful as the primary experimental comparison.\n\nThird, one of the ways the paper claims to improve over the work of Grislain and Gonzalvez (Sarus-XGB) and Li et al. (DP-Boost) is through \"improved privacy accounting.\" However, these prior approaches use pure DP, a significantly stronger privacy guarantee than that of the methods described here (which, as I gather from Section 6, is approximate DP). Switching to weaker privacy guarantees enables better composition analysis, but doesn't come for free. Without this discussion, readers may be misled."
            },
            "questions": {
                "value": "Can you give a complete description of the algorithm(s) you propose?\n\nWhat privacy guarantee(s) do they satisfy?\n\nDo these algorithms work in the federated setting that Maddock et al. consider?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Reviewer_QR2x"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698890594274,
        "cdate": 1698890594274,
        "tmdate": 1699636738551,
        "mdate": 1699636738551,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wrou6PBOTm",
        "forum": "bCynxWndWY",
        "replyto": "bCynxWndWY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_jsJy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6548/Reviewer_jsJy"
        ],
        "content": {
            "summary": {
                "value": "This paper challenges a wide observation that, under the differential privacy (DP) constraint, random boosting tree outperforms greedy boosting tree. It argues the greedy tree in previous studies was not optimized, and proposes to further optimize it by several simple tweaks including (i) applying Maddock et al. (2022) to split node, (ii) a regularized weighted scoring function, (iii) applying Gaussian mechanism instead of Laplacian to release noised data. In experiments, they show the improved DP boosting greedy tree performs better than random counterpart on simulated data, but performs worse on real world data sets in most cases."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed research question is interesting and significant. \n\n2. Overall the paper is well-presented."
            },
            "weaknesses": {
                "value": "[1] I find the point of this paper quite confusing: it challenges an observation, but its expeirmental results (Fig 3 & Tab 1) largely support the observation -- just like all previous studies. \n\n[2]  While the intuitive analysis on why greedy boosting tree may perform worse looks interesting, there is no formal or theorectical justification on it. Theorem 1 is loosely connected to the comparison between greedy tree and random tree. \n\n[3] Technical and theorectical novelties of the paper are limited. \n\n[4] Several mathematical statements are not clear, e.g., \n\n-- In Defintion 2, please clarify the definition of $D_{\\alpha}$ and neighboring sets. \n\n-- In Lemma 1, please clarify the definition of $RR$. \n\n-- In the proof of Lemma 1, please elaborate on how to derive the inequality in (5) using data processing inequality."
            },
            "questions": {
                "value": "From the current presentation, it is not clear whether this paper is the first one to challenge the comparison between DP random boosting tree and DP greedy boosting tree. It is also unclear what is the relation between this study and all previous studies that improve DP greedy boosting tree while using random boosting tree as baseline. Could authors clarify these points?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6548/Reviewer_jsJy"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698942478353,
        "cdate": 1698942478353,
        "tmdate": 1699636738447,
        "mdate": 1699636738447,
        "license": "CC BY 4.0",
        "version": 2
    }
]