[
    {
        "id": "YnccBnaePh",
        "forum": "A8Sqe4RZqF",
        "replyto": "A8Sqe4RZqF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_piq4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_piq4"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Robot-BERT (RoBERT), a method for building a general robot control policy for complex behaviors with minimal human involvement. Unlike traditional methods, RoBERT does not require human labels, high-quality behavior datasets, or accurate system model information. It is trained through Masked Action-Inverse-Inference (MAII), similar to Masked Language Modeling in BERT-like language models, making it suitable for zero-shot, multi-task, and keyframe-based robot control with minor architectural changes. Empirical studies demonstrate RoBERT's success in generating stable and flexible behaviors for various robot types in simulated environments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Interesting application of masked sequence models into robot trajectory modeling.\n- Thorough experimentation on different types of robots and tasks."
            },
            "weaknesses": {
                "value": "The presentation and writing of this paper makes it very difficult to assess the quality of this work.  There are incoherent sentences (eg: `By encouraging an agent to perform task in one direction, we are discouraging it from performing task in opposite direction. For example, by tweaking reward function to train a robot to teach dance smoothly, we\u2019re restricting its ability to serve as a counter-example for showing how un-smooth dances look like.`, `An intuitive idea here is as masks increasing, determinism of inverse dynamics would decrease and\nour setting would become a multi-modality Imitation Learning, as studied in Shafiullah et al. (2022).`), incorrect use of terminology (eg: `zero-shortly` (change to in a zero short manner), `ill-collected dataset` (change to noisy dataset)) and grammatical errors (eg: `unsupervise RL`) making it challenging to parse the paper. \nThe introduction of the paper is written in a manner that does not clearly explain the problem, and abruptly switches to listing the contributions. The methods section also lacks clarity as it is difficult to understand sections 3.3 and 3.4. Figure 1 also does not explain the method clearly as the inputs and the outputs of each phase are not shown clearly. Therefore, I would suggest that the authors rewrite certain sections of the paper to make it more understandable."
            },
            "questions": {
                "value": "- The paper claims that they use `the least amount of human labeling`,  but does not compare it to any other state of the art methods to prove so. \n- For training and evaluation purposes, why was the dataset split into 95-5% whereas typically people split it into 70-30% or 80-20%? Also, how was the dataset split to ensure no data leakage between the train and the test set?\n- Why are accuracy and precision used as the only metric? Why not report recall and F1 scores as well?\n- It is unclear how to interpret Figure 4."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Reviewer_piq4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1700/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698277925050,
        "cdate": 1698277925050,
        "tmdate": 1699636098468,
        "mdate": 1699636098468,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NP8R2KG2Bq",
        "forum": "A8Sqe4RZqF",
        "replyto": "A8Sqe4RZqF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_xJAs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_xJAs"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Robot-BERT (RoBERT), a method for building robot control policies without human effort. It is trained on datasets collected with unsupervised Reinforcement Learning methods and does not need human labels. It is trained via Masked Action-Inverse-Inference, and is aiming for keyframe-based robot control. Specifically, given the user-supplied state-only keyframe, the robot can achieve the targets with open loop control."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Experiments were conducted on three different robots.\nSource code and supplementary videos are provided to demonstrate the methods and results.\nThe approach is based on transformer-based large models."
            },
            "weaknesses": {
                "value": "The task seems easy to solve. Merely making the robot reach target states does not constitute general control, as this can be achieved with basic control techniques and without jittering observed in the supplementary videos. Moreover, for manipulation tasks using robot arms or dexterous hands, simply reaching target states is insufficient, as interactions with dynamic objects is more important and challenging. If the authors insist on exploring this direction, I recommend considering obstacle avoidance planning for robotic arms or social navigation; and exploring how to encode obstacles into the state to achieve target-reaching while avoiding obstacles."
            },
            "questions": {
                "value": "Additionally, I recommend not to use the entire field of \"ROBOTICS\" as a single section in the related work. It would be more effective to focus on specific sub-areas or topics within robotics that are directly relevant to the paper.\nUnsupervise RL should be Unsupervised RL."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Reviewer_xJAs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1700/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698799881329,
        "cdate": 1698799881329,
        "tmdate": 1699636098391,
        "mdate": 1699636098391,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pJqTnhJBJa",
        "forum": "A8Sqe4RZqF",
        "replyto": "A8Sqe4RZqF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_oyMc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1700/Reviewer_oyMc"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces ROBERT which leverages unsupervised data collection and Masked Action-Inverse-Inference (MAII) inspired by Masked Language Modeling to enable robot control without human labels or extensive behavior datasets. The approach demonstrates success in generating stable and flexible robot behaviors across various robot models in simulated environments. The paper also introduces a user-friendly keyframe control mechanism and highlights the multi-task capabilities of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper points out an important issue in this field, where existing works rely heavily on extensive amounts of human-labeled multimodal data or expensive experts dataset.\n- The research suggests that the fusion of unsupervised RL with masked sequence modeling holds potential for addressing this challenge."
            },
            "weaknesses": {
                "value": "- The contribution of this work is unclear and the paper lacks novelty, as the proposed method simply combines unsupervised RL dataset with masked modeling without introducing any unique techniques.\n- The motivation of adopting a bi-directional sequence modeling approach, akin to BERT-like methods, remains unclear in the context of the problem they are addressing.\n- The paper mentions a low-cost aspect without providing details on how this is achieved or its relevance to the main contribution.\n- The experiment section of the paper seems to be weak. It is not clear what the experiments aim to show, and there is an absence of any baseline comparisons. Presenting results solely for the proposed method without any comparative baselines seems weird given there are similar line of work such as [1, 2]. It would be better to include experimental results comparing the proposed method to other approaches to show the superiority of the suggested architecture or learning scheme.\n- The argument that the proposed method is superior to the state-of-the-art in general robot control is weakened by the fact that their experimental setup focuses on only simple tasks rather than complex tasks (see RT-2[3]). Given the experimental results the authors show, the claim of requiring the least amount of human effort for general robot control/decision-making sounds too strong even though it uses unsupervised dataset.\n\n[1] Philipp Wu et al., Masked Trajectory Models for Prediction, Representation, and Control. ICML, 2023.\\\n[2] Fangchen Liu et al., Masked Autoencoding for Scalable and Generalizable Decision Making. NeurIPS, 2022.\\\n[3] Anthony Brohan et al., RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. arXiv, 2023."
            },
            "questions": {
                "value": "- How does the approach of continuously changing the masking ratio randomly during training compare to the CL method? Can additional experimental results be provided to demonstrate this comparison?\n- It would be better if the authors add the experiment results that include comprehensive measurements of computational expenses, memory utilization, etc. to show that the proposed method is low-cost.\n- As mentioned earlier, it would be beneficial to include experimental results that show the superiority of the proposed approach by comparing it to baselines like MTM[1] and MaskDP[2], all trained with the same unsupervised RL dataset.\n- Can complex behaviors, such as interacting with objects, be learned solely from data collected through unsupervised RL? It would be beneficial to include experiments to demonstrate this, as there are significant doubts regarding the capability of learning truly meaningful and practical actions from an unsupervised RL dataset. The claim of this framework being suitable for general robot control remains questionable in terms of its ability to learn valuable actions with real-world relevance solely from an unsupervised RL dataset.\n- It is unclear for me about the authors insight about the specified reward function in introduction part. Isn\u2019t it good that the agent has a bias towards the goal when it is learning? Furthermore, as in multi-task RL, if we can specify appropriate reward functions for various tasks clearly to the agent, then the specified reward function itself does not pose a problem for learning multiple behaviors. It is a bit confusing for me regarding the intended argument. Is the main point here that learning multiple behaviors under a single specified reward function is not feasible?\n\n[1] Philipp Wu et al., Masked Trajectory Models for Prediction, Representation, and Control. ICML, 2023.\\\n[2] Fangchen Liu et al., Masked Autoencoding for Scalable and Generalizable Decision Making. NeurIPS, 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1700/Reviewer_oyMc"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1700/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800297251,
        "cdate": 1698800297251,
        "tmdate": 1699636098312,
        "mdate": 1699636098312,
        "license": "CC BY 4.0",
        "version": 2
    }
]