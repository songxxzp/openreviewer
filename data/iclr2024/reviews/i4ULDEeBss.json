[
    {
        "id": "nAcslL3oSk",
        "forum": "i4ULDEeBss",
        "replyto": "i4ULDEeBss",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework called RoleLLM to benchmark, elicit, and enhance the role-playing abilities LLM. It proposes a method to elicit role-playing abilities in closed-source LLMs such as GPT-4 using dialogue engineering and custom instructions. Also, this paper introduces the first benchmark and open-source dataset for role-playing."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper designs four stages for role playing: role profile construction, context-based instruction generation, role prompting using GPT, and role-conditioned instruction tuning\nThis paper proposes RoleBench, the first fine-grained benchmark and open-source dataset for role-playing."
            },
            "weaknesses": {
                "value": "This article has some issues with insufficient comprehensiveness in its evaluation. The performance of GPT-3.5 may be limited to evaluate these metrics given that GPT-4 is now commonly used for evaluating the results of weaker models. Lack of human evaluation to compare these role generation results."
            },
            "questions": {
                "value": "Why is RoleLLaMA's performance so much lower than RoleGPT? Could the author please provide some analysis?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "To learn certain characters may require the appropriate authorization."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3167/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR",
                    "ICLR.cc/2024/Conference/Submission3167/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827248878,
        "cdate": 1698827248878,
        "tmdate": 1700927228119,
        "mdate": 1700927228119,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "w5pPay6FEG",
        "forum": "i4ULDEeBss",
        "replyto": "i4ULDEeBss",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_mGAb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_mGAb"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces RoleLLM, a benchmark developed to enhance and evaluate the role-playing abilities of large language models (LLMs). RoleLLM encompasses the creation of profiles for 100 different roles, along with corresponding role-specific Q&A pairs and customized responses for imitating various speaking styles. These components were all generated by GPT-4 and are used as instructional tuning data. The authors trained and assessed several open-source LLMs, including RoleGPT (a version of GPT-4 tailored for in-context dialogue pairs), benchmarking their performance and offering valuable insights."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper presents a comprehensive and systematic framework for role-playing in LLMs.\n- The high-quality, instruction-tuning dataset and benchmark are notable contributions, useful for enhancing and evaluating the LLMs\u2019 capabilities in role-playing, speaking style imitation, response accuracy, and role-specific knowledge."
            },
            "weaknesses": {
                "value": "- A major limitation is that all responses and Q&A pairs are generated by GPT-4, creating a potential disconnect with real-world role-playing scenarios. Human evaluations are suggested to further verify the effectiveness of the dataset.\n- Concerns about data quality are evident. The review in Table 2 indicates relatively low accuracy in the generated responses, presumably due to incorrect answers in the RoleBench-general data collection.\n- The experimental results seem to just meet the minimal threshold for publication, implying a need for more extensive research or impactful findings."
            },
            "questions": {
                "value": "- For Table 2, I am curious about if give the right answer in the prompt and ask RoleGPT to generate the customized responses should increase the data quality.\n- This is a minor question I have: What is the reason behind using GPT-3.5 for evaluating RoleLLAMA versus GPT-4 for RoleGLM."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698921401678,
        "cdate": 1698921401678,
        "tmdate": 1699636264162,
        "mdate": 1699636264162,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IYuQAbL4yK",
        "forum": "i4ULDEeBss",
        "replyto": "i4ULDEeBss",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces RoleLLM, a role-playing framework for enhancing the role-playing abilities of language models. It presents RoleGPT, which elicits role-playing abilities through dialogue engineering, and Context-Instruct, which generates role-specific knowledge through context-based instruction generation. The paper also introduces RoleBench, a comprehensive dataset and benchmark for fine-grained role-playing. The contributions include demonstrating the effectiveness of dialogue engineering over prompt engineering, improving role-playing abilities using RoleBench, showcasing the generalization capabilities of RoleLLaMA, and highlighting the effectiveness of the system-instruction-based approach in role customization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper introduces RoleLLM, a new role-playing framework for large language models (LLMs) aimed at improving their role-playing skills through unique methods like role profiles and context-based instruction tuning. It details a thorough construction of these profiles and rigorous evaluations using GPT-based metrics and data techniques, ensuring a solid experimental foundation. \n2. The paper is clear and well-structured, with helpful visuals like Figure 1 to guide readers through the RoleLLM process. Its potential to enhance research in role-playing LLMs is significant, offering cost-effective and efficient strategies for model customization, as seen in the promising results of dialogue engineering and RoleBench assessments, and the adaptable generalization observed in RoleLLaMA.\n3. The paper's experimental design is thorough and robust, testing various aspects of role-playing in LLMs, including the effectiveness of dialogue engineering, role knowledge enhancement, and generalization capabilities of the developed models."
            },
            "weaknesses": {
                "value": "1. While the technical execution of fine-tuning LLMs to be better at role-playing is well done, the technical contributions are limited by its fine-tuning methods and traditional data augmentation methods. The use of traditional data augmentation techniques like Context-Instruct and RoleGPT, while useful, does not significantly advance the field beyond its current state. The reliance on GPT-generated question-answer pairs and dialogue engineering falls within well-explored paths in LLM research.\n2. The paper doesn't fully analyze or compare RoleLLaMA and RoleGLM with other role-playing LLMs. It'd help to have a deep dive into how RoleLLaMA and RoleGLM stack up against similar models, pointing out what's new and better about them. Including real-life examples or case studies where RoleLLaMA and RoleGLM outperform others in role-play would also make the case for the new framework stronger.\n3. The paper presents separate models for English and Chinese but does not extensively explore the challenges of cross-lingual and cross-cultural role-playing. Given the intricacies involved in linguistic and cultural nuances, a deeper analysis of model performance across different languages and cultural contexts is essential. Enhancing the paper with a more detailed examination of these aspects would solidify the models' effectiveness and applicability in a globally diverse setting.\n4. The paper currently lacks a thorough discussion on the ethical and societal implications of using role-playing LLMs. Considering the potential for misuse and the sensitive nature of role-playing (e.g., in mental health, education, or law enforcement), it is imperative to address ethical concerns, establish clear boundaries, and propose guidelines for responsible use. Integrating a comprehensive section on ethical considerations and safeguards would add significant value to the paper, making it more robust and socially responsible."
            },
            "questions": {
                "value": "I am skeptical about the quality evaluation for RoleBench. Do you consider any quantitative metrics? Moreover, adding some qualitative graphs would be helpful for demonstration. More specifically, if I understand this correctly, the ground truths are generated from LLMs, and their qualities need to be further scrutinized."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns",
                    "Yes, Potentially harmful insights, methodologies and applications"
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3167/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur",
                    "ICLR.cc/2024/Conference/Submission3167/Senior_Area_Chairs"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Constructing roles for LLMs could be dangerous, and ironically, computer scientists only want to invent the \"atom bomb\" using their technical skills without caring much about ethical issues. The construction of role profiles, a foundational aspect of the RoleLLM framework, may inadvertently introduce biases, especially since these profiles are manually curated. The selection and description of roles could be influenced by subjective interpretations, cultural biases, or limited perspectives. This concern is critical given the diverse and global applications of LLMs. To mitigate this, the authors need to consider a more systematic, extensive, and diverse methodology for role profile creation, possibly integrating crowd-sourced or expert-reviewed inputs to ensure a broader and more inclusive representation of roles."
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699243434727,
        "cdate": 1699243434727,
        "tmdate": 1699663373464,
        "mdate": 1699663373464,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RpIZDmfm7C",
        "forum": "i4ULDEeBss",
        "replyto": "i4ULDEeBss",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_HbAh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3167/Reviewer_HbAh"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework to benchmark, elicit, and enhance role-playing abilities in LLMs, including a character-level benchmark dataset RoleBench and role-playing LLMs, i.e., RoleLLaMA (English) and RoleGLM (Chinese). Experimental results show that these role-playing LLMs can achieve comparable results with GPT-4 equipped by role-specific prompts."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper first proposes a systematic instruction-tuning dataset for fine-grained role-playing, which may promote the development of this specific research direction.\n\n2. The LLMs trained on the role-playing instruction-tuning dataset show effective performance and good scaling properties."
            },
            "weaknesses": {
                "value": "1. This paper does not mention LLM-based character-level dialogue systems such as Character.AI, which are closely related to the proposed benchmark and models. I wonder: 1) the difference between Character.AI and RoleLLaMA / RoleGLM; 2) why the authors adopt GPT-4 to construct benchmark datasets instead of directly using Character.AI; 3) how Character.AI performs on the RoleBench compared with RoleLLaMA / RoleGLM.\n\n2. Nearly all the experimental results rely on ROUGE-based and GPT-based automatic metrics. However, ROUGE-based metrics only focus on the overlap between generated responses and reference responses, which may be not proper for open-ended dialogue tasks. GPT-based metrics are also shown to have various biases [1]. Thus, human evaluation should be added to make the experimental results more convincing. Also, I wonder why the authors choose different GPT models for evaluating RoleLLaMA / RoleGLM (i.e., GPT-3.5 for evaluating RoleLLaMA and GPT-4 for measuring RoleGLM). Existing works [1] have already shown that GPT-4 performs much better than GPT-3.5 in the evaluation of LLMs.\n\n[1] Large Language Models are not Fair Evaluators. arXiv 2023."
            },
            "questions": {
                "value": "I have included my questions in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699628038140,
        "cdate": 1699628038140,
        "tmdate": 1699636264043,
        "mdate": 1699636264043,
        "license": "CC BY 4.0",
        "version": 2
    }
]