[
    {
        "id": "tKgJwVtDVY",
        "forum": "uwJgCIKXJS",
        "replyto": "uwJgCIKXJS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_iSL5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_iSL5"
        ],
        "content": {
            "summary": {
                "value": "The paper provides linear versions of the Indexed Minimum Empirical Divergence (IMED) algorithm, that aims to solve the stochastic linear bandit problem. The paper introduces three versions of the linear IMED algorithm with different updating rules, and proves regret upper bounds. The paper provides proofs and some numerical studies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper learns from extension of Thompson sampling algorithm to linear bandits, adopts that idea, and uses the idea to extend IMED algorithm to linear bandit problems. Regret bounds that match those of LinUCB with OFUL\u2019s confidence bound are proved. This is a neat paper."
            },
            "weaknesses": {
                "value": "The paper's contribution should be insufficient for ICLR. The paper has done a decent application by extending to the linear setting for IMED algoritms. However, the algorithm design and supporting proofs are not novel, thereby having limited contribution toward the linear bandit literature. \n\nThe paper writes from page 5 to page 8 about their proof sketch. This part is not clearly written, and I am not sure what is the purpose of this part of the paper. \n\nThe paper's numerical study does not support the claims. The paper claims \"Compared to OFUL, LinIMED works more efficiently\" and \"Compared to SupLinUCB, ..., our empirical performance is better.\" The numerical study is too incomprehensive to make such claims."
            },
            "questions": {
                "value": "Why do the authors believe that their numerical study can support their claims? \n\nWhat is the purpose of page 5 to page 8 and what are the points that the authors want to make from this part?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1990/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698536590978,
        "cdate": 1698536590978,
        "tmdate": 1699636130881,
        "mdate": 1699636130881,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hBV2ekzP4d",
        "forum": "uwJgCIKXJS",
        "replyto": "uwJgCIKXJS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_FSvU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_FSvU"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes novel algorithms for solving the stochastic linear bandit problem based on the principle of Indexed Minimum Empirical Divergence (IMED). Three variants of the same approach are proposed (namely, LinIMED 1-2-3), differing mainly on managing the exploration-exploitation trade-off. Theoretical guarantees and empirical evaluations of the three approaches are presented."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper provides new solutions to the well-known stochastic linear bandit setting, building on top of a principle different from Thompson sampling or pure optimism (even though many elements are in common), possibly leading to improved empirical performances. Moreover, proving the theoretical guarantees of the proposed algorithms required a non-trivial technical effort."
            },
            "weaknesses": {
                "value": "1) Overall, I felt that the presentation was not always clear. I\u2019ll provide some examples:\n    - I would have divided the pseudocode for the three algorithms, avoiding reporting all of them in the same. An idea would be to just provide the pseudocode for one and the other in the appendix since they are very similar.\n    - The exploration term of the decision index is sometimes reported with a positive sign and a fraction inside the logarithm, and other times with a negative sign and a flipped logarithm argument. \n    - I feel that there\u2019s a contradiction when you say, first, that \u201c\u2026 we replace the optimized KL-divergence measure in IMED in Eqn. (1) with the squared gap between the sample mean of arm i and the arm with the maximum sample mean. This choice simplifies our analysis and does not adversely affect the regret bound.\u201d, but later, in the conclusions, you state \u201cIn the future, a fruitful direction of research is to analyze the effect of directly using the KL-divergence in Line 14 of Algorithm 1 instead of the estimated squared gap; we believe that in this case, the analysis would be more challenging, but the theoretical and empirical performances might be superior to our three LinIMED algorithms.\u201d\n\n2) Referring to the last point of the previous list, I think that this is a crucial thing about this paper: you state that you are providing \u201cnovel linear versions of the IMED algorithm\u201d but, in LinIMED, I cannot see any divergence, but rather a rough proxy defined by the empirical gap. I think that, in terms of performance, this would not drastically affect your results, while from a technical point of view, this would drastically harden the difficulty. However, from the IMED counterpart for linear bandits, one would expect to see the divergence principle in action. At the same time, here, I\u2019m not sure we can really talk of \u201cIndexed Minimum Empirical Divergence\u201d in a strict sense. I feel that addressing this point is a crucial task to strengthen the value of your work.\n\n3) Looking at the plots of your experimental campaign, it\u2019s hard to tell, for most of the time, if an algorithm is better than another. The fact is that most of the time the uncertainty bands around the average cumulative regrets are very much overlapped, leading us to no conclusion on whether an algorithm is effectively better than another in that experiment. I am trying to understand if this is a matter of how you computed that uncertainty or if there aren\u2019t really any statistically sound conclusions that can be drawn from there. I would ask you to clarify this point."
            },
            "questions": {
                "value": "Even though theorem proving is non-trivial from a technical point of view, I think that most of the key ideas there came from well-known results in this literature (see, e.g., proofs of theoretical guarantees for LinUCB). Can you highlight what are, in your opinion, the main technical novelties in the passages of your proofs?\n\nI am willing to revise my score if the authors can justify not using the true divergence instead of the estimated gap and if they can provide a satisfying answer to the previous question."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Reviewer_FSvU"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1990/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698577123190,
        "cdate": 1698577123190,
        "tmdate": 1699636130792,
        "mdate": 1699636130792,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ai7BcEnQNb",
        "forum": "uwJgCIKXJS",
        "replyto": "uwJgCIKXJS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_z91R"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_z91R"
        ],
        "content": {
            "summary": {
                "value": "This paper extends the Minimum Empirical Divergence algorithm to the linear bandit setting.  The authors provide three methods to do this and provide the regret guarantees for them. They show that the regret guarantees for the three algorithms are comparable to the other state-of-the-art algorithms for SLBs. They also show the efficacy of their method via empirical studies."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The work extends the MED framework to the linear bandit setting, closing the theoretical gap in the literature for SLBs.\n2) The regret guarantees shown are optimal (up to log terms).\n3) The numerical results justify their claims."
            },
            "weaknesses": {
                "value": "The main weakness of the work, in my opinion, lies in the contribution. I wish to know what were the main analytical changes faced in the extension of MED to LBs. It would be great if the authors provided some highlights on this in their final version because the main contribution of this work is theoretical. The experiments support their claims but do not drastically improve over LinUCB, which is the standard go-to for the SLB problem."
            },
            "questions": {
                "value": "1) \"OFUL involves a bilinear optimization, which is computationally expensive unless the confidence ellipsoid is a convex hull of a finite set.\"Can the authors please comment on this in detail, since the bilinear optimization has a closed form and the computation necessary is linear in K, (and O(d^3))? Am I missing something?\n\n2) Typo: T_i(t) = \\sum_{s=1}^{t\u22121}{A_t = a} in Sec 3.1, t-->s, a-->i.\n3) What were the main technical challenges that the authors faced while extending the analysis to the linear bandit setup? It would be nice to have a small subsection highlighting those."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1990/Reviewer_z91R"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1990/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730009340,
        "cdate": 1698730009340,
        "tmdate": 1699636130679,
        "mdate": 1699636130679,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8eYwvxtYbj",
        "forum": "uwJgCIKXJS",
        "replyto": "uwJgCIKXJS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_PVPY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1990/Reviewer_PVPY"
        ],
        "content": {
            "summary": {
                "value": "This paper studies how to apply the IMED algorithm for semi-bounded multi-armed bandits to the (oblivious and finite-armed) linear bandits setting. As a result, the authors proposed the LinIMED algorithm based on the original IMED algorithm and the confidence ellipsoid in (Abbasi-Yadkori et al., 2011). The authors proved its regret bound which was $\\widetilde O(d\\sqrt T) $ omitting $\\mathrm{poly}(\\log T)$ factors. The authors also presented experimental results based on synthetic data to demonstrate the advantage of LinIMED upon existing algorithms for linear bandits including OFUL and linear Thompson sampling."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. This is the first paper applying IMED to the linear bandits setting.\n2. The authors proved the regret bound matching the minimax optimal regret bound for infinite-armed linear bandits up to polylog factors.\n3. The authors presented experimental results for empirical comparison with existing algorithms."
            },
            "weaknesses": {
                "value": "1. The bound is not minimax optimal for finite-armed linear bandits. It has an $O(\\sqrt d)$ from optimal algorithms such as SupLinUCB (Chu et al., 2011).\n2. The most important assumption made by the IMED algorithm in (Honda and Takemura, 2015) was that the reward function could be semi-bounded, specifically it need not be bounded below. This distinguishes the IMED algorithm from the classical algorithms like (linear versions of) UCB. However, the authors made the assumption that the reward function was bounded."
            },
            "questions": {
                "value": "1. Did the authors make an assumption that $T \\ge O(d)$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1990/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698856861064,
        "cdate": 1698856861064,
        "tmdate": 1699636130597,
        "mdate": 1699636130597,
        "license": "CC BY 4.0",
        "version": 2
    }
]