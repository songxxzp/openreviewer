[
    {
        "id": "DSLqnuZPWa",
        "forum": "BpAxeHmQ94",
        "replyto": "BpAxeHmQ94",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_F4hf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_F4hf"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces randomized smoothing to cost-sensitive learning problems to develop a provable robust cost-sensitive learning framework. Empirical studies are conducted to show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Cost-sensitive learning is an essential task in the ML community, and considering how to obtain a robust model under such a context is meaningful."
            },
            "weaknesses": {
                "value": "The contributions of this paper are somewhat weak since some conclusions claimed in the main paper could be directly realized by Cohen et al. (2019). Furthermore, in Alg.1, where the $R_1$ comes from? In Cohen's paper, they also considered this in a binary classification case.\n\nAnother non-neglected limitation of this paper is that it can only process the binary cost-matrix problem. This is also a possible reason why the Cohen-R algorithm cannot perform well.\n\nAlso, the motivation of Sec.4.2 needs to be further added. \n- Why can Eq.(4) work well? Why must we do the optimization like this?\n- I noticed that $I_2$ also includes the cost-sensitive sample. But why the cost-sensitive samples included in $I_2$ is processed differently from I_3? \n- Moreover, the certified radii R_{c-s} would be greater than $0$ since the set $[m]$ includes $\\Omega_y$. Thus, why does $I_3$ exist $-\\gamma_2$\uff1f\n- Generally speaking, we usually do not obtain the exact value of g due to the expectation. Thus, in Eq.(4), how do you back-propagate $g(x)$?\n\nFinally, the experiment part is somewhat unconvincing. The authors should consider more of the latest randomizing smooth methods, such as [1,2].\n\nRef:\n- [1] Consistency regularization for certified robustness of smoothed classifiers, NeurIPS, 2020.\n- [2] Provably robust deep learning via adversarially trained smoothed classifiers, NeurIPS, 2019."
            },
            "questions": {
                "value": "See the Weakness part above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Reviewer_F4hf"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698290897577,
        "cdate": 1698290897577,
        "tmdate": 1699636301801,
        "mdate": 1699636301801,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pEloydAGpq",
        "forum": "BpAxeHmQ94",
        "replyto": "BpAxeHmQ94",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_i4At"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_i4At"
        ],
        "content": {
            "summary": {
                "value": "This paper studies provable adversarial robustness in the context of cost-sensitive learning. It applies randomized smoothing to obtain a certified radius where the classification cost is zero. In the cost-sensitive setting, a misclassification incurs a cost defined by an m x m matrix C, where m is the number of class labels. The entry C_{i, j} denotes the cost of misclassifying label i as j. The paper studies a special case of this matrix where all entries are 0 or 1. The traditional classification setting, where the misclassification cost is uniform, is captured by a matrix where all diagonal elements are 0, and all non-diagonal elements are 1. In the more general case, some off-diagonal entries could be 0, indicating no misclassification cost for the corresponding class. This offers the potential to increase the certified radius by permitting certain misclassifications, given that their associated cost is nil."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper studies provable robustness in a setting that has largely remained unexplored. The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1. Binary Cost Matrix: A 0/1 cost matrix may not be sufficient to capture real-world cost-sensitive ML tasks. The cost of misclassification would rarely be zero. Take the example mentioned in the second paragraph of the introduction. While misclassifying a benign tumor as malignant is less detrimental than the reverse, the cost of such a misclassification will not be zero. If so, one could simply label all tumors as malignant and achieve an overall classification cost of zero. However, such a classifier would not provide us with any valuable information.\n\n   It would be more impactful to design robustness certificates for a general cost matrix where the entries need not be 0/1. It might be possible to certify the expected misclassification cost by using the distribution of the cost under the smoothing noise. The following work on certifying the expected confidence of a neural network could be adapted for a general cost matrix:\n\n   Certifying Confidence via Randomized Smoothing, Kumar et al., NeurIPS 2020.\n\n2. Novelty: The robustness certificate designed in this work is a straightforward adaptation of Cohen et al.'s certificate [1]. The certificate in [1] takes the difference between two terms where the second term depends on p_b, the probability of the second most likely class. This paper redefines p_b as the probability of the most likely class in the set of class labels with cost 1.\u2028\n\n   [1] Certified Adversarial Robustness via Randomized Smoothing, Cohen et al., ICML 2019.\n\n3. Sample Complexity: The number of samples required for computing the proposed certificate is higher than that of the baseline certificate from [1]. It depends on the number of classes with cost 1. While this might be manageable for the small number of classes considered in the experiments (<= 10), scaling to a large number of classes, such as in ImageNet (1000 classes), would be difficult."
            },
            "questions": {
                "value": "1. What would be a practical application where a binary cost matrix would be sufficient? In most scenarios, the misclassification cost would take a range of different values.\n\n2. During inference, when the ground truth is unknown, how do we find the classes with cost 1? This set depends on the correct class label, which is not known during inference."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698535615846,
        "cdate": 1698535615846,
        "tmdate": 1699636301719,
        "mdate": 1699636301719,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nyg7a2IMpj",
        "forum": "BpAxeHmQ94",
        "replyto": "BpAxeHmQ94",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_oovB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_oovB"
        ],
        "content": {
            "summary": {
                "value": "This work proposed randomized smoothing certification for cost-sensitive learning, where misclassifying one class as another has different costs. The work provides some theorems and algorithms for certification. Experiments results on synthetic datasets (Cifar10 and imagenette) and a real-world medical dataset are also reported."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper studied an interesting problem, where misclassification to different classes will trigger different costs.\n2. The paper claims that this is the first work to apply randomized smoothing to cost-sensitive learning setting.\n3. The paper provides some theorems for deriving the robustness radius (thm 3.2) and shows the situations where cost-sensitive robust radius is strictly bigger than regular robust radius (thm 3.3).\n4. Experiments showed some improvements over the baseline methods."
            },
            "weaknesses": {
                "value": "1. Although providing theorem 3.2 for computing robust radius, the proof of this theorem is a straightforward generalization of Theorem 1 in [Cohen et al 2019], hence raising a novelty concern. Note that this limited novelty doesn't affect the reviewer's rating on this work.\n2. This method is designed to handle the cost-sensitive setting, for example, medical classification as the paper claimed. However, the improvement in medical setting is not as noticeable as in synthetic setting (Cifar10 and imagenette)."
            },
            "questions": {
                "value": "As mentioned in weakness 2, can the author perhaps explain why the proposed method has less improvement on HAM10k compared with Cifar10 and imagenette?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3485/Reviewer_oovB"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793877214,
        "cdate": 1698793877214,
        "tmdate": 1699636301644,
        "mdate": 1699636301644,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QEBhgmqfeG",
        "forum": "BpAxeHmQ94",
        "replyto": "BpAxeHmQ94",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_B2mS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3485/Reviewer_B2mS"
        ],
        "content": {
            "summary": {
                "value": "The paper delves into adversarially robust classifiers in cost-sensitive contexts, where adversarial transformations are assigned varying importance through a binary cost matrix. Many existing solutions either can't guarantee robustness or aren't scalable. This research leverages randomized smoothing, a method known for its scalability, to certify robustness in these cost-sensitive scenarios. The authors introduce a new metric, the cost-sensitive certified radius, and design an algorithm to train classifiers with this robustness in mind. Their approach is validated with experiments on both image datasets and a real-world medical dataset, achieving enhanced robustness without sacrificing accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well-written with a clear motivation.\n\n2. The topic is important."
            },
            "weaknesses": {
                "value": "1. The paper appears to be a straightforward adaptation of Cohen et al. [1] to a cost-sensitive context, limiting its novelty. Algorithm 1 seems to selectively ignore classes based on the cost matrix, and the training approach in Section 4.2 appears to be a variation of MACER. If my assessment is incorrect, I'd appreciate clarification in the rebuttal about the unique challenges faced when integrating randomized smoothing [1] and MACER into the cost-sensitive framework.\n\n2. The paper lacks comparisons with several key baselines [2,3,4]. It's essential to address these well-established methods, especially since SmoothMix reportedly outperforms MACER in [4].\n\n[1] Cohen et al., Certified Adversarial Robustness via Randomized Smoothing, ICML 2019\\\n[2] Salman et al., Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers, NeurIPS 2019\\\n[3] Jeong et al., Consistency Regularization for Certified Robustness of Smoothed Classifiers, NeurIPS 2020\\\n[4] Jeong et al., SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness, NeurIPS 2021"
            },
            "questions": {
                "value": "1. Refer to Weakness 1.\n\n2. Given the plethora of papers focused on refining the base classifier's training, why was MACER chosen as the foundation? Does MACER offer specific advantages for cost-sensitive training? If so, could you elucidate what aspects of MACER enhance its applicability to the cost-sensitive context?\n\n3. I observed that your method's distinction from MACER lies in its consideration of misclassified samples, indicated by $R_{c-s}<0$. You assert on Page 17 about achieving a superior balance between accuracy and cost-sensitive robustness. Can your enhanced MACER also boost the original certified robustness presented in [1]? Specifically, could you provide $Rob_{std}$ in Table 5? Such improvements might stem from optimizing misclassified samples and may not be inherently tied to cost-sensitive attributes."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830926935,
        "cdate": 1698830926935,
        "tmdate": 1699636301564,
        "mdate": 1699636301564,
        "license": "CC BY 4.0",
        "version": 2
    }
]