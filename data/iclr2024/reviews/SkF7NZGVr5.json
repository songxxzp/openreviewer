[
    {
        "id": "35PG9o9AyW",
        "forum": "SkF7NZGVr5",
        "replyto": "SkF7NZGVr5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_3UTT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_3UTT"
        ],
        "content": {
            "summary": {
                "value": "This work shows that the loss of curvature is correlated with the loss of plasticity"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea that the curvature relates to the plasticity phenomenon is novel and interesting. It is a plus because the curvature of the loss function is of central importance to deep learning theory. While I do like this work, I think there are aspects can be improved"
            },
            "weaknesses": {
                "value": "There are a few problems that are probably fixable:\n\n1. I find the current figures not sufficiently convincing. First of all, the srank is a normalized quantity, and therefore it cannot tell us the curvature of the loss. This is because the curvature is closely related to the absolute scale of the eigenvalues -- for a fixed sharpness of the local landscape, one can have an arbitrary srank and vice versa. Therefore, I am not convinced that the srank can be interpreted as \"curvature\" \n\n2. The figure are not clearly convincing. In particular, what the authors are trying to argue is that the batch error increase is correlated with srank decrease -- but there is no single figure that precisely shows this. The authors need to include a figure whose x-axis is the srank and the y axis is the batch error, and perform a rigorous correlation analysis to convince me\n\n3. I think it would be valuable to discuss the recent results in https://arxiv.org/abs/2309.16932 (mainly section 4.4). For example, the authors say that \"This suggests that loss of palsticity only occurs with the non-linear activations,\" which does not seem true in light of the result in the related work. Also, throughout, the authors suggest that L2 regularization can possibly mitigate the loss of plasticity, whereas the results in the above work shows that L2 reg. exacerbates it. The authors should explain the contradictions and why they occur\n\n\nAlso, I have a question:\n1. Why is the stable rank based on the singular values but not the eigenvalues? The singular values are only positive, but, in my opinion, the negative eigevalues in the Hesssian could play an important role here."
            },
            "questions": {
                "value": "See the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4057/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698217060850,
        "cdate": 1698217060850,
        "tmdate": 1699636369762,
        "mdate": 1699636369762,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fmYNY511wU",
        "forum": "SkF7NZGVr5",
        "replyto": "SkF7NZGVr5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_iEeG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_iEeG"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the rank of the network Hessian as an explanation of plasticity in neural networks, and conducts a series of empirical analyses to evaluate the utility of this explanation. It goes on to propose a regularizer which aims to minimize an approximation of the Wasserstein distance between the current distribution of per-layer weights and the initial distribution. This regularizer demonstrates improved stability and robustness to hyperparameters over related L2-based weight regularizers on the benchmarks studied."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper makes a solid effort to find a quantifiable property of networks which lose plasticity without accumulating dead units. While Lyle et al. (2023) allude to changes in the structure of the loss landscape which can occur in networks which lose plasticity in the absence of dormant neurons, prior work has not identified a cheap scalar quantity which indicates that this pathological curvature has arisen.\n- The paper evaluates its hypotheses and method on widely-used benchmarks in the study of plasticity loss.\n- The idea of studying the *rank* of the Hessian, as opposed to its maximal eigenvalue, is interesting and not something I have seen explored much in the literature.\n - The paper provides a nice illustration of the limitations of update norm to explain plasticity loss, in contrast to the observation of Abbas et al. that reduction in update norm often correlated with plasticity loss in networks which accumulate dead ReLU units.\n - The paper also highlights the importance of taking into account differences in the initial value in a performance metric after a task change when evaluating learning algorithms. In particular, what I presume to be higher loss spikes due to increased confidence in the network's predictions cause methods which allow the network to more effectively minimize its loss on the prior task can lead to spurious large initial values in the loss after a task change. Evaluation schemes which take an average of the loss over the training trajectory then overestimate the loss in plasticity of these methods.\n  - The study of the alignment between the Hessian principal components and the gradients could offer some potentially interesting insights into the evolution of the loss landscape.\n  - The proposed regularizer is sensible, reasonably cheap (only introducing a log(n) factor on top of standard weight decay) and seems to be highly effective."
            },
            "weaknesses": {
                "value": "- The paper doesn't evaluate across different architectures, and only considers extremely small MLPs. Given that prior work has noted that an intervention's efficacy often heavily depends on the architecture to which it is applied, it is important to evaluate an intervention on a range of architectures to get a full view of its robustness. \n- Saying that the curvature of the neural network is reduced because of a reduction in srank might go against existing notions of curvature in the literature on deep neural network training, which often characterize the curvature by the maximal Hessian eigenvalue. In particular, a reduction in srank of the features is often caused by the largest eigenvalue growing faster than the remainder. It is possible that a similar phenomenon is happening here, wherein the largest eigenvalue of the Hessian is growing faster than the other eigenvalues. A visualization of the eigenvalue distribution at the start vs at the end of training would be useful. I would be inclined to call a reduction in the srank an increase in the 'degeneracy' of the Hessian, rather than a reduction in curvature. \n- The rank of the Hessian with respect to the last two layers of the network is likely to be highly correlated with the rank of the penultimate feature layer. Figures 1 and 2, for example, show that the rankings given by the srank of the Hessian and the srank of the features largely agree with each other. Similar issues in the correlation between the feature srank and the error over time also emerge in the Hessian srank, for example the leaky-ReLU network in Figure 2, middle column. The evaluation of the srank of the features in Figure 1 appears to have either been performed with a very narrow network or a very small batch size, making it difficult to evaluate the significance of these measurements. I think the paper would benefit from a closer examination of the difference between the Hessian rank and the feature rank in these networks.\n- One of the biggest issues that emerges from the paper is the observation that the Hessian srank often exhibits similar inconsistencies to other quantities, like the srank of the features, which were used as justification to dismiss these quantities as good explanations of plasticity. For example, weight decay and regenerative regularization both exhibit similar Hessian srank, but weight decay exhibits greater plasticity loss in Figure 4.\n- The choice to study the rank of the Hessian, as opposed to the rank of the empirical NTK or the features, is not given sufficient motivation. Each of these quantities reveals something meaningful about the loss landscape, and it is not immediately obvious that the Hessian should be preferred over the other two.\n- While the proposed regularizer is reasonable, it feels very much orthogonal to the curvature of the network. The causal connection between preserving the distribution of the parameters and maintaining the rank of the hessian remains vague, and the benefits of the regularizer on the rank appear incidental.\n- Because of the limited set of evaluations, it is difficult to say whether the proposed regularizer will be useful in other contexts, where it may be necessary for the distribution of weights to shift in ways that increase the Wasserstein distance from initialization, or where the regularizer may slow down learning too much to be practical. It would be useful to evaluate on other datasets and to also show the learning curves; for example, the worse online learning results for the wasserstein regularization coupled with the better end-of-training results suggest that not only does the loss start out much higher, but that it stays higher than the other methods for a long time -- in other words, it is resulting in much slower learning."
            },
            "questions": {
                "value": "- I am skeptical of the results which seem to indicate that a linear network is able to attain near-0 error on MNIST. I have trained linear classifiers on this dataset in the past and don't recall seeing anything exceed 80-90% accuracy. I am also extremely surprised at the results which seem to indicate that a 3-layer, < 128-width **linear** MLP is able to attain zero training error on label-shuffled CIFAR-10. For example, even the larger networks studied by Zhang et al. in the classic paper \"Understanding deep learning requires rethinking generalization\" required dozens to hundreds of epochs to converge on random CIFAR-10 labels. I have a difficult time believing that a task sufficiently difficult for an ImageNet-calibre architecture to require Could the authors confirm that they are indeed able to obtain zero error on image classification datasets with a linear model?\n- How strong are the correlations between feature, gradient, and Hessian srank, and can the authors provide evidence that the Hessian srank is providing a meaningful notion of curvature or trainability not captured by the other two quantities?\n- The paper would benefit from evaluations in other architectures, and on tasks that cannot be solved by a linear model, to validate the utility of the proposed regularizer. In particular, how does the regularization method perform on tasks where linear networks fail? Does it generalize to convolutional networks / ResNets / sequence models?\n- Can the authors explain the settings noted in the \"weaknesses\" section where curvature appears to fail to explain plasticity in neural networks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4057/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698684758124,
        "cdate": 1698684758124,
        "tmdate": 1699636369683,
        "mdate": 1699636369683,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Poxji1nrrx",
        "forum": "SkF7NZGVr5",
        "replyto": "SkF7NZGVr5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_BAzs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_BAzs"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the loss of plasticity in learning algorithms, where they struggle to adapt to changing environments. While previous research linked this to factors like optimizer type, gradient norm, and neuron dormancy, this study introduces a novel perspective: loss of plasticity is tied to a decrease in curvature. Specifically, the authors highlight a correlation between the loss of plasticity and the reduced rank of the Hessian of the training objective at new task commencements. To combat this, the paper introduces a regularizer that retains weight distributions close to their initial setups, preserving curvature and ensuring better adaptability across successive tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper offers a novel perspective on the loss of plasticity by associating it with curvature in the optimization landscape. This approach deepens our understanding of plasticity and distinguishes this work from previous research.\n\nAt the core of the paper's approach is an examination of adaptability in curvature using the rank of the Hessian matrix. This focus on how task alterations affect curvature offers a detailed and precise metric, setting this work apart from broader methodologies in earlier studies. Moreover, the authors complement theoretical discussions with empirical evidence, bolstering the paper's credibility and relevance. While past research has suggested various metrics such as neuron dormancy, decrease in active units, feature rank, and weight norm to measure plasticity, the authors demonstrate that these metrics do not consistently track the loss of plasticity.\n\nFurthermore, this paper proposes a Wasserstein initialization regularizer. This not only mitigates the issues identified but also paves the way for the adaptability of learning algorithms."
            },
            "weaknesses": {
                "value": "This paper contains interesting ideas and promising experimental results. However, I do have several concerns regarding the completeness of this paper to comprehensively support their claims. Specifically:\n\nMetrics-Related Concerns:\n- The authors' decision to measure the partial blockwise of the last two layers raises questions. It's unclear why early layers are seemingly disregarded. Don't they play a significant role in the loss of plasticity?\n- For a comprehensive evaluation, it would be valuable if the authors could provide a layer-wise or partial block-wise Hessian rank for the experiments. Especially, I would like to check it out for the CIFAR-10 experiments, since it utilizes a deeper network than Mnist experiments.\n\nMethodological Concerns:\n- The choice of the Wasserstein distance measure as a regularizer adds complexity, especially when it comes to tuning for smaller sample sizes ($d$). Why not employ the simpler L2 regularization from the initial parameter? Does the norm of the neural network should be large enough to make accurate predictions for a large number of tasks?\n- It remains ambiguous how the Wasserstein distance regularizer directly contributes to increasing the rank of the Hessian matrix. The inclusion of theoretical evidence or explanations that tie these concepts together would strengthen the paper's methodological claims.\n\nExperimental Concerns:\n- The omission of experiments using permuted CIFAR-10 seems to be an oversight, given its relevance in evaluating plasticity.\n- A more rigorous comparison with related works is needed:\n  - A comparison with widely used techniques like dropout and data augmentation would be informative.\n  - A comparison w.r.t plasticity literature including CReLU activation [1], Layer Normalization [2], Last layer reset [3], or even combinations of these approaches [4].\n\n[1] Loss of Plasticity in Continual Deep Reinforcement Learning., Abbas et al., TMLR 2023.\n\n[2] Understanding plasticity in neural networks., Lyle et al., ICML 2023.\n\n[3] Primacy Bias in Deep Reinforcement Learning., Nikishin et al., ICML 2022.\n\n[4] Enhancing input and label plasticity for Sample Efficient Reinforcement Learning., Lee et al., NeurIPS 2023.\n\nI'm willing to increase the score if the authors address the outlined limitations."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4057/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4057/Reviewer_BAzs",
                    "ICLR.cc/2024/Conference/Submission4057/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4057/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721326958,
        "cdate": 1698721326958,
        "tmdate": 1700717377777,
        "mdate": 1700717377777,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3mYCrvf6Xk",
        "forum": "SkF7NZGVr5",
        "replyto": "SkF7NZGVr5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_sWyZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4057/Reviewer_sWyZ"
        ],
        "content": {
            "summary": {
                "value": "This paper posits a novel explanation for the loss of plasticity in neural networks, attributing it to the loss of curvature. The authors challenge existing explanations for the plasticity loss by providing counter examples and highlighting their inconsistencies. The plasticity loss, which refers to the phenomenon of neural networks losing their ability to learn from new experience, can be observed by increase in training error as the network learns. To measure the curvature, this paper exploited a partial blockwise neural network. Moreover, this paper suggests that a Wasserstein regularizer, which keeps the distribution of parameters close to their initialization, prevents the loss of plasticity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is addressing important problem. Motivation describing the inconsistency of existing explanations was straightforward.\n\n- The paper is clearly written and well structured. It was easy to follow and understand the authors\u2019 point.\n\n- It is interesting that the Wasserstein regularization effectively prevents the loss of plasticity."
            },
            "weaknesses": {
                "value": "[Significance of results] The presented arguments that existing explanations for the loss of plasticity are inconsistent seems to be insufficient. Although the proposed explanation related to the loss of curvature is intriguing, the authors should provide additional experiments (diverse model architectures and benchmarks) to argue that the proposed one is a consistent explanation for the plasticity loss. Moreover, it would be great if the authors could measure the consistency quantitatively.\n\n[Evaluation metric in continual learning setup] The paper seems to overlook an analysis on forgetting which is one of the most important criteria in the continual learning setup. It is recommended that the authors expand their discussions to encompass the concept of forgetting, in addition to delving deeper into plasticity.\n\n[Minor typo] In Appendix A bullet points 3 and 4, there are some missing symbols between two numbers (e.g., at the level of 2.6 2.7)."
            },
            "questions": {
                "value": "As mentioned in the weakness section, the significance of inconsistency in existing explanations is unclear. In Section 3 results, the rank of representation (top right of Figure 1) decreased, and the batch error increased when using tanh. As tanh is experiencing small decrease on the rank of representation, the batch error also showed relatively small increase. This seems to be a consistent explanation for the loss of plasticity. More explanations on this will strengthen the authors\u2019 argument.\n\nIn addition, why is Wasserstein regularization better than regenerative regularization? As mentioned in Section 5, the order statistics is defined as the difference between two regularizations. It would be beneficial for the readers if the authors can provide explanations regarding the substantial difference in the results presented in Figure 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4057/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698815862192,
        "cdate": 1698815862192,
        "tmdate": 1699636369531,
        "mdate": 1699636369531,
        "license": "CC BY 4.0",
        "version": 2
    }
]