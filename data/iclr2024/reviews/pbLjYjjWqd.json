[
    {
        "id": "pNvKNLi7tk",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_2J6K"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_2J6K"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses three challenges while fine-tuning LLM in federated learning (FL): (i) limited access to the LLM parameters, (ii) computational and storage costs for local clients, and (iii) communication costs between the server and the clients. Upon these challenges, the authors introduce Black-Box Tuning (BBT), a gradient-free approach. It optimizes the prompts via the CMA-ES optimizer for the local update and the global aggregation. To avoid overfitting, the authors propose a perturbation method that mixes up two sentences. The experiments cover three classification tasks and two state-of-the-art models (LLaMA and RoBERTa), and the results indicate the proposed method reduces the trainable parameters, computation overhead, and communication costs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It is a promising topic to discuss LLM in FL. This paper is well-written and points out the potential challenges when we fine-tune LLM in FL. \n2. The figures of the paper help the reader understand the work clearly. \n3. I appreciate the experiments adopting the state-of-the-art pretrained model LLaMA, which shows the method's broad coverage in terms of language models."
            },
            "weaknesses": {
                "value": "1. As mentioned by the authors, the clients have limited access to the entire model. I agree with this point, but the paper does not work it out. According to Eq. (1), the proposed method should attain the value of $f(\\cdot, \\cdot)$ to compute the loss function. I think there are only two approaches to the goal: (i) the clients upload the input and the output to the server, and the server computes and returns the loss to the clients; (ii) clients are allowed to use the model to get the loss. The first one breaches the principle requirements of FL, where the clients' data cannot be disclosed to any other parties, while the second one does not match the initial aims because the clients can load the entire model locally. \n2. In the experiments, I see the performance degradation between the gradient-based methods and FedBPT. The proposed FedBPT takes advantage of the computation overhead each round because it requires forward propagation only. However, I think the gradient-based methods will take fewer rounds to converge or perform better than FedBPT. As for their high communication overhead, I believe LoRA can solve the issue. \n3. Section 3 mentions two dimensions' values (i.e., $d$ and $D$) for the prompt. Intuitively, a longer prompt will perform better. The authors should discuss how these two values affect the model performance. \n4. Although Section 3 mentions this paper focuses on the classification task, I think it is too simple because we expect LLM to work on more complicated tasks such as question answering. Also, the datasets used in the experiment are not very challenging because they are binary classification or four-category tasks."
            },
            "questions": {
                "value": "Please address my concerns in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Reviewer_2J6K"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730004204,
        "cdate": 1698730004204,
        "tmdate": 1699636377606,
        "mdate": 1699636377606,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4xGlE15GBY",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_uWcP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_uWcP"
        ],
        "content": {
            "summary": {
                "value": "The paper studies black-box prompt tuning in the federated setting and proposes FedBPT. Specifically, FedBPT extends an existing approach BBT to the federated setting, which enables black-box prompt tuning in the centralized setting. Each client locally updates the prompt mapping vector and sends it to the server. The server averages the vectors and sends the global vector back to the clients for the training of the next round. FedBPT adopts a modified search step length and regularization by perturbing the input prompt."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The studied problem is important. With the fast development of LLMs, prompt tuning has been a popular research direction and how to enable it in the federated setting is emerging.\n\n2. The paper is well-written and easy to understand."
            },
            "weaknesses": {
                "value": "1. One concern is about the motivation of the paper. The paper assumes that LLMs can only provide API inference such as GPT-4. In such a case, the clients need to send the prompts to the service provider for inference. However, one important aspect of federated learning is privacy, and the data should not be transferred. Thus, the proposed approach is not feasible in the real world.\n\n2. Experiments miss some important baselines. Considering the vector z as a model, existing FL approaches such as FedProx [1] to solve non-IID data may be also applicable. Comparing these approaches should be added.\n[1] Federated optimization in heterogeneous networks\n\n3. Another concern is about the privacy risks of transferring vector z. I think the authors can present the learned prompts in the experiments and see the relationship between them and the training data. If the prompts contain information about the training data, transferring vector z may not be a feasible solution as every client can compute the prompt by $Az$."
            },
            "questions": {
                "value": "1. How to enable inference without transferring the data in the black-box setting?\n\n2. Can you demonstrate the learned prompts in the experiments?\n\n3. Can you add FL baselines on non-IID data by treating z as a model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807187801,
        "cdate": 1698807187801,
        "tmdate": 1699636377515,
        "mdate": 1699636377515,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bV4ZdAQ5dW",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_juc2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_juc2"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a federated prompt-tuning framework for large language models. The key difference in this framework is that it does not use gradient-based optimization methods such as SGD to optimize the trainable prompt parameters. Instead, it adopts a gradient-free optimization method, CMA-ES. In each training iteration, clients optimize the trainable parameters using the CMA-ES method and then upload these parameters to the server. The server does not aggregate these parameters directly, as in FedAvg. Instead, it uses these uploaded parameters to perform another round of CMA-ES updates. The updated parameters are treated as aggregated ones and are distributed among clients for the next iteration. Additionally, the paper proposes randomly masking a portion of the input text sequences to prevent prompts from overfitting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper provides a derivation of the step size related to the CMA-ES aggregation on the server side, making the method theoretically more reliable.\n\n2.\tThis method has fewer trainable parameters and lower communication costs than other prompt tuning methods.\n\n3.\tThe paper has a detailed introduction to gradient-free optimization, which makes the paper easy to follow."
            },
            "weaknesses": {
                "value": "1.\tA main concern is the time efficiency of this method since evolutionary algorithms are typically slower than SGD. If the paper uses the gradient-free optimization CMA-ES instead of SGD, that might result in not only increased time consumption but also heightened computational resource usage, subsequently slowing down the convergence rate. This paper should assess time efficiency and discuss the additional time overhead introduced by CMA-ES. \n\n2.\tAside from incorporating some existing methods, the primary innovation in this paper revolves around the aggregation of CMA-ES parameters within the framework of federated learning. Other components, such as gradient-free optimization or the utilization of sentence perturbation for preventing overfitting, are hard to label as innovative. Hence, the overall technical novelty of the article is limited. \n\n3.\tBaseline methods for prompt tuning in the experiments are overly basic and outdated. Comparisons should be made with more recent state-of-the-art approaches, such as LPT [1] and IDPG [2], which all claimed to perform better than vanilla prompt tuning.\n\n[1] Xiangyang Liu, Tianxiang Sun, Xuanjing Huang, and Xipeng Qiu. 2022c. Late prompt tuning: A late prompt could be better than many prompts. In Findings of the Association for Computational Linguistics: (EMNLP), pages 1325\u20131338. Association for Computational Linguistics.\n\n[2] Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, V.G.Vinod Vydiswaran, and Hao Ma. 2022. IDPG: An instance-dependent prompt generation method. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5507\u20135521."
            },
            "questions": {
                "value": "1.\tI noticed the authors emphasize that 'this approach eliminates the need for clients to access model parameters.' However, it seems that clients must have the capability to perform inference on their local devices to optimize CMA-ES parameters, which implies they do need to access model parameters.\n\n2.\tFrom Table 1, I noticed that FedAvg (fine-tuning all parameters) performs noticeably worse than the other two prompt tuning methods. Is there a specific reason for this? In most prompt-tuning literature, fine-tuning's performance is either close to or better than prompt tuning."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698997367787,
        "cdate": 1698997367787,
        "tmdate": 1699636377454,
        "mdate": 1699636377454,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rLsU162VXI",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_zMti"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_zMti"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed the FedBPT method which adopts CMA-ES to search for the optimal distribution of prompt and aggregates the collected local prompts in a sophisticated way. They also identified the overfitting issue caused by prompt tuning and applied the random masking techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper is overall well-presented, and the motivation is also clear. The three challenges solved by FedBPT are verified by statements or experiments. The idea of getting the optimal step length seems good in the context of CMA-ES."
            },
            "weaknesses": {
                "value": "My primary concern pertains to the relatively limited contributions of this paper. It appears somewhat incremental when compared to BPT, despite the identification and resolution of certain issues, including a plain aggregation and overfitting."
            },
            "questions": {
                "value": "1.\tI think the idea of applying BPT in FedBPT is direct and I have read the similar idea somewhere. So, it would be better to clarify the novelty and contributions of this submission?\n2.\tAuthors claimed that standard aggregation is not effective in Sec 4.3, but I did not see any justification about this point except for Fig.2. Please let me know if I missed it.\n3.\tFollowing 1, standard aggregation does not need to send $F^k(z)$ to server if I have correctly understood, while it is necessary in FedBPT to get the optimal step length. In this case, the information about local data is at more risks of being exposed as more information shared out. A clarification is needed here.\n4.\tSec 4.4 observed that most clients suffer from the dominant class issues. However, what is the loss for local clients when they are not well fitting across different classes? Also, is dominate class are \u201ceasy samples\u201d? \n5.\tFrom experiments, the improvement of random masking seems quite limited. If the dominate class issue is sever as shown in Fig.3, the improvement are expected to be large."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699072843792,
        "cdate": 1699072843792,
        "tmdate": 1699636377385,
        "mdate": 1699636377385,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "K86UlIapnV",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_2fPJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_2fPJ"
        ],
        "content": {
            "summary": {
                "value": "In this submission, the authors propose a novel federated learning (FL) framework named FedBPT to tackle the challenges when people want to fine-tune pre-trained language models (PLMs) via FL, including limited access to PLMs and unaffordable computation/storage/communication overhead. The proposed FedBPT utilizes black-box tunning (BBT) techniques to conduct the prompt tunning process, considering the prompt overfitting issue caused by non-IID data and the federated aggregation issues. Experiments are conducted on several benchmark datasets to show the effectiveness of FedBPT compared to both gradient-based baselines and gradient-free baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-written. The description of the proposed method is clear and detailed, making it easy to follow.\n2. The authors highlight the challenges when directly using the existing BBT techniques in FL, and further provide solutions to solve these challenges. Some empirical evidence is provided in the experiment section to validate the effectiveness of the provided solutions.\n3. The authors provide a theoretical analysis of the proposed method.\n4. The experiments are comprehensive. The authors conduct experiments with RoBERTa and Llama 2, and provide comparisons from the perspectives of model performance, communication cost, memory, and so on."
            },
            "weaknesses": {
                "value": "1. The comparisons in terms of computation costs between the proposed method and baselines are not clear and convincing. Compared to gradient-based methods, FedBPT needs fewer computation resources per iteration since it adopts a gradient-free technique, but it is still not clear the overall computation costs used for obtaining the optimal solution. It is important since the gradient-free technique might need more iterations for convergence. The authors should provide more experiments or discussions. \n2. The experimental results in Table 4 show that, even though 80% of the tokens are masked or replaced, the model trained on these ``noisy data'' outperforms that of vanilla BBT. The authors attribute such improvement to mitigating the overfitting issue. Such results are surprising (at least for me), and maybe the authors can provide more analysis or experiments. For example, the authors can replace FedAvg with other federated aggregation algorithms (e.g., FedProx[1]) that can also mitigate the overfitting issue caused by non-IID. \n\nRefs:  \n[1] Federated Optimization in Heterogeneous Networks. In MLSys, 2020."
            },
            "questions": {
                "value": "Please refer to the Weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699088966572,
        "cdate": 1699088966572,
        "tmdate": 1699636377310,
        "mdate": 1699636377310,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rkkql85v9B",
        "forum": "pbLjYjjWqd",
        "replyto": "pbLjYjjWqd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_aHU5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4124/Reviewer_aHU5"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Federated Black-box Prompt Tuning (FedBPT) as a solution to tackle several challenges associated with the application of Federated Learning (FL) for fine-tuning Pre-trained Language Models (PLM). These challenges include issues related to parameter access, high computational demands, and communication overhead. \nThe proposed framework mitigates these challenges by minimizing the exchange of variables through gradient-free optimization known as Black-Box Tuning. This approach optimizes the prompt without relying on back-propagation. A series of experiments are conducted to verify the framework's capacity to reduce communication and memory requirements while still achieving competitive performance levels."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The approach to address the overfitting problem is intriguing, particularly the use of random perturbation, which has proven effective in various domains.\n- The paper's organization is well-structured. The problem formulation and inference presented in the paper are clear, making it accessible for readers.\n- The techniques utilized within this framework demonstrate a level of innovation."
            },
            "weaknesses": {
                "value": "- Compared with gradient-based methods, FedBPT does significantly reduce communication overhead, but in the large-size LLama2 model, especially in the non_iid setting, its accuracy decline is still obvious. \n- In the ablation study, the author states that FedBPT is not sensitive to the population. However,  three population trials are not enough to prove this parameter insensitivity in my view. More population trials should be performed."
            },
            "questions": {
                "value": "Q1: What are the rectangle colors in Figure 3? It should be better to give an explanation in the caption.\nQ2: Random perturbation and controls the proportion of the perturbation are provided by generating a mask, my interesting is that the perturbation adding randomly or with semantic information? If this kind of perturbation is changed into words with opposite semantic information, for example, changing \"zero\" to \"some\" in Figure 4, can it have the same effect? Or produce other effects? \nQ3: From the experimental results, it can be seen that the simple manual prompt also produces a comparable effect to FedAvg. Can the authors' approach can be improved by a prompt generated by FedBPT or selected from its dataset instead of manually prompting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4124/Reviewer_aHU5"
                ]
            }
        },
        "number": 6,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4124/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699150939726,
        "cdate": 1699150939726,
        "tmdate": 1699636377237,
        "mdate": 1699636377237,
        "license": "CC BY 4.0",
        "version": 2
    }
]