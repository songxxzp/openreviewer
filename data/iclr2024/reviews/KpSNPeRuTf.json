[
    {
        "id": "k2hIINyqZm",
        "forum": "KpSNPeRuTf",
        "replyto": "KpSNPeRuTf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_MHr3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_MHr3"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a conditional sparse autoencoder to perform counterfactual inference on time series and images"
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper is well written in terms of language and organisation\n- The method attempts to tackle an important issue , that is counterfactuals in time series"
            },
            "weaknesses": {
                "value": "- The authors have missed a lot of related literature in counterfactuals of timeseries that they should be comparing, contrasting and benchmarking against. For example 3: \n\n    - Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations Seedat et al ICML 2022\n    - Causal Transformer for Estimating Counterfactual Outcomes, Melnychuk et al ICML 2022\n   - Non-parametric identifiability and sensitivity analysis of synthetic control models, Zeitler et al CLeaR 2023\n As a matter of fact the authors completely ignore the entirety of Synthetic Control literature and Epidemiology and Bio-Signals literature that has at its crux the estimation of counterfactual timeseries. \n\n- It is unclear how the proposed method performs the abduction and action step. The only information given is that the representation is sparse. Does this mean that the new counterfactual sample is just dictated by the conditioning factor? Does it include traversing the latent space ? \n\n- It is unclear what kind of causal guarantees the method offers. It appears that the only contribution is a sparsity constraint that is neither novel nor clear how it gives us any causal properties. \n\n- The image task is not properly motivated nor explained. The figure of different color hues is not clear what is the factual part and what is the counterfactual. \n\n- The introduction of sparsity to an autoencoder is not novel as it is well known in the community"
            },
            "questions": {
                "value": "- How does the proposed method compare in theory and practice with synthetic control, and other Neural network and transformer based methods for prediction of time series counterfactuals ? \n- How does the method actually guarantee any causal insights ? \n- How is the abduction and action performed in this method ? \n\n\n\nOverall I dont think this paper is ready yet for publication. Its contributions are not novel, lacking any clear and sound causal guarantees. The evaluation and comparison is insufficient"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8088/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697811322690,
        "cdate": 1697811322690,
        "tmdate": 1699637002011,
        "mdate": 1699637002011,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LPDJdsaH66",
        "forum": "KpSNPeRuTf",
        "replyto": "KpSNPeRuTf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_cmfR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_cmfR"
        ],
        "content": {
            "summary": {
                "value": "This paper adds an L1/L2 regularization term over the bottleneck latent variables to the regular Autoencoder loss, Eq. (2)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper conducts a comprehensive review of Generative Models for counterfactual prediction, and adds an L1/L2 regularization term over the bottleneck latent variables to the regular Autoencoder loss, Eq. (2)."
            },
            "weaknesses": {
                "value": "- The structure of this paper is confusing, leaving me uncertain about the author's intended message and purpose. \n\n- Novelty: The loss function of CSAE is $\\mathcal{L}_{\\mathrm{CSAE}}(\\mathbf{x})=|x-\\hat{x}|-\\lambda \\sum_i\\left|z_i\\right|$. Is that all? An L1/L2 regularization term? How does it perform counterfactual estimation and what is the counterfactual prediction objective?\n\n- Is Time Series Counterfactual the focus of this manuscript? Why did the authors spend a significant amount of space discussing content that is not directly related to it? It was not until the fourth paragraph that the topic was introduced.\n\n- The motivation of this paper is a bit confusing. What are the challenges in conducting Time Series counterfactuals? How do traditional Time Series methods approach this and what are their limitations? Why can an L1/L2 regularization term over the bottleneck latent variables implement Time Series Counterfactuals? What is the motivation behind this? The presentation should focus more on the core issues addressed in this paper. \n\n- Typos: \u201c\u2026 by jointly training and encoder \u2026 and a decoder \u2026\u201d \u2192 \u201c\u2026 by jointly training an encoder \u2026 and a decoder \u2026\u201d"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I suspect that this paper was generated solely by AI."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8088/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751800692,
        "cdate": 1698751800692,
        "tmdate": 1699637001892,
        "mdate": 1699637001892,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TDLxh9ZqN4",
        "forum": "KpSNPeRuTf",
        "replyto": "KpSNPeRuTf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_1arB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_1arB"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a conditional auto-encoder with sparsity constraints for counterfactual estimation and generation. The method is motivated for time-series data, but tested on both time-series and image data. Experimental comparisons were made to conditional VAE and, in the setting of time-series data, a LSTM."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Counterfactual estimates and generation are relatively under-explored in time-series data. The paper is thus tackling an important and worthy research question."
            },
            "weaknesses": {
                "value": "This work can be improved in several major areas:\n\n1. While the method is heavily situated within the context of counterfactual estimation and generation, the methodology itself is very marginally tied to causal inference. In fact, it is more related to disentanglement itself. Even for disentangling purpose \u2014 the use of sparsity constraint to minimize the information in the bottleneck is heuristic without any theoretical guarantee that z will not attempt to encode information about the conditioning/parent variable (and the success of which should largely depends on the regularization strength). Nothing in this seems to be addressing causal modeling (other than the conditioning), or addresses causal disentanglement at the presence of correlation.\n\n2. In all experimental settings, it is stated that there is no \u201cconfounding\u201d in the data and that the two factors (e.g., digit and hue) are independent. This is quite confusing \u2014 if two factors have causal relations, there is a high likelihood that they will appear correlated in the data, thus making naive disentanglement (assuming independent generative factors) difficult \u2014 In fact, this is the key challenge for most causal inference and generation work to address such \u201ccorrelation\u201d from observational data. If this correlation does not exist (which I interpret as the confounding as mentioned in the paper), such as estimating intervention effect from randonmized trial data, the the key challenge is gone. \n\n3. Similarly, while the paper was using time-series as a main motivation, pointing out that existing works that deal with images cannot be directly applied to time-series data, it was not pinpointed what exactly are the challenges associated with time-series counterfactuals, and how the presented method addresses them.\n\n4. The work is missing a large number of necessary baselines for comparison, including in time series data (such as RMSN [1], CRN [2], CausalTransformer [3]) and in static image data (causalGAN, causal-VAE, SCM-VAE, ICM-VAE, etc)\n\n[1] Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks\n[2] ESTIMATING COUNTERFACTUAL TREATMENT OUTCOMES OVER TIME THROUGH ADVERSARIALLY BALANCED REPRESENTATIONS\n[3] Causal Transformer for Estimating Counterfactual Outcomes"
            },
            "questions": {
                "value": "The contribution and rigor of the presented work are overall unclear to me. It\u2019d be helpful if the authors can address my major comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8088/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698874901579,
        "cdate": 1698874901579,
        "tmdate": 1699637001792,
        "mdate": 1699637001792,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IBUz757WOo",
        "forum": "KpSNPeRuTf",
        "replyto": "KpSNPeRuTf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_moAT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8088/Reviewer_moAT"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to use conditional sparse autoencoders (CSAE) instead of  conditional variational autoencoders (CVAE) for counterfactual estimation in the DSCM framework focused on timeseries problems. The authors compare the two methods on a synthetic, semi-synthetic and a proprietary timeseries dataset,   as well as coloured MNIST. The experiments indicate superior performance of the CSAE compared to the CSAE."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper tackles the important problem of counterfactual estimation for time-series problems and identifies performance drawbacks in currently used models."
            },
            "weaknesses": {
                "value": "The paper is a simple combination of the deep SCM framework with sparse autoencoders. The writing of the paper could use some editing as it's riddled with errors. Furthermore, section 3.1 very closely follows [1] while some of the metrics in 4.2 very closely follow [2], almost being a citation. Even thought the results look promising, the novelty is very limited and the experimental setup is too narrow to provide evidence of this method being suitable for general settings.\n\n[1] Pawlowski, Nick, Daniel Coelho de Castro, and Ben Glocker. \"Deep structural causal models for tractable counterfactual inference.\" Advances in Neural Information Processing Systems 33 (2020): 857-869.\n[2] Monteiro, Miguel, et al. \"Measuring axiomatic soundness of counterfactual image models.\" The Eleventh International Conference on Learning Representations. 2022."
            },
            "questions": {
                "value": "- The paper mentioned that methods are deterministically decoded, and as such does not use well defined probabilities as section 3 suggests. Is this wanted?\n- Why is the precision required for timeseries higher than for other counterfactuals?\n- The problems mentioned in the paper are already brought up in [2] (see the confounded data experiments) and have been tackled in e.g. [3]. How does this method compare?\n- Why does the probabilistic nature of CVAEs introduce additional errors?\n- The explanations of the metrics are hard to follow. It would be helpful to add equations here, especially for the \"Added variations\"\n- Whats the assumed causal graph for the experiments?\n\n[3] Kumar, Amar, et al. \"Debiasing Counterfactuals in the Presence of Spurious Correlations.\" Workshop on Clinical Image-Based Procedures. Cham: Springer Nature Switzerland, 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8088/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699310471339,
        "cdate": 1699310471339,
        "tmdate": 1699637001677,
        "mdate": 1699637001677,
        "license": "CC BY 4.0",
        "version": 2
    }
]