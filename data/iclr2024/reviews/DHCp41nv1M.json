[
    {
        "id": "Fdu0DJZrpw",
        "forum": "DHCp41nv1M",
        "replyto": "DHCp41nv1M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_dFYB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_dFYB"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of seeing dynamic scenes through scattering media. The authors propose a 3D convolution architecture that can take into account temporal correlation for the task of de-scattering the video sequence. Using a diffusion model prior regularizes the solution space of the inverse problem."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper tried to tackle a difficult problem using state-of-the-art generative AI approaches. They show that taking into account temporal correlations helps with the reconstruction of dynamic scenes undergoing scattering. They validate the approach as compared to a traditional TV approach and a 2D-based deep learning approach and show that using deep learning in video space improves the reconstruction quality."
            },
            "weaknesses": {
                "value": "The key issue and the reason I chose a rating of 2 for the presentation is the lack of contextualization for this work. While the authors do a good job comparing to some baselines like a TV method and a 2D approach the problem of seeing through scattering media has a long history, which this paper largely ignores. This problem arises in the context of de-hazing and underwater imaging (see e.g. Akkaynak et al and Berman et al below ). I also point out that the inverse problem is very similar to the DiffuserCam proposed by Antipa et al. Further works by Satat et al. Bar et al. Alterman et al. all looked into seeing through scattering and Bar et al. offer a simple model for speckle formation. Lastly, the discussion on speckles seem redundant as the paper reduces the model to a simple convolution with a gaussian kernel. This opens the discussion to a whole host of works done on blind and non-blind deconvolution. \n\nThe other major issue I have is that all the results and experiments assume a simple convolution model to generate data and then show the recovery based on that model. This means that there is no model mismatch at all. I would like the authors to expand on that.\n\nA minor point: the paper alternates between a differentiable model and a closed form model, which do not overlap. One can have a differential scattering-based model (e.g. Nimier-David, Merlin, et al. \"Mitsuba 2: A retargetable forward and inverse renderer.\" ACM Transactions on Graphics (TOG) 38.6 (2019): 1-17.) that is nonetheless a non-closed form model.\n\nSome relevant work that should be acknowledged and contextualized:\nSatat, Guy, Matthew Tancik, and Ramesh Raskar. \"Towards photography through realistic fog.\" 2018 IEEE International Conference on Computational Photography (ICCP). IEEE, 2018.\nAntipa, Nick, et al. \"DiffuserCam: lensless single-exposure 3D imaging.\" Optica 5.1 (2018): 1-9.\nBerman, Dana, and Shai Avidan. \"Non-local image dehazing.\" Proceedings of the IEEE conference on computer vision and pattern recognition 2016.\nAkkaynak, Derya, and Tali Treibitz. \"Sea-thru: A method for removing water from underwater images.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\nAlterman, Marina, et al. \"Imaging with local speckle intensity correlations: theory and practice.\" ACM Transactions on Graphics (TOG) 40.3 (2021): 1-22.\nBar, Chen, et al. \"Single scattering modeling of speckle correlation.\" 2021 IEEE International Conference on Computational Photography (ICCP). IEEE, 2021."
            },
            "questions": {
                "value": "See weaknesses. \nOverall, I think this is a sound paper. Nevertheless, my concerns are \na) lack of context and comparison with other state-of-the-art approaches that have shown good results in real-world hazy images.\nb) I would like the authors to elaborate on the lack of model mismatch by assuming a simple gaussian kernel and then recovering under this assumption. I'm not sure how to evaluate the figure in the appendix. I do not know if other, more physically realistic methods for rendering scattering effects might do much better."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7397/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7397/Reviewer_dFYB",
                    "ICLR.cc/2024/Conference/Submission7397/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7397/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698187547788,
        "cdate": 1698187547788,
        "tmdate": 1700505695914,
        "mdate": 1700505695914,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sYAlUgyY9V",
        "forum": "DHCp41nv1M",
        "replyto": "DHCp41nv1M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_AVri"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_AVri"
        ],
        "content": {
            "summary": {
                "value": "An original method is proposed to remove dynamic blur in a moving video by taking advantage of spatial and temporal correlations. The  approach consists in introducing temporal aspect in the 2-dimensional posterior sampling (DPS) approach, a similar extension allowing to extend Diffusion models as Video Diffusion Models (VDM). The proposed approach needs tha the diffusion layer is not to thick and that the scene is enlighten with a laser. Comparative experiments are proposed with convincing results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The possibility to take fully advantage of the spatial and temporal correlations is very interesting and useful. The proposed results are very convincing about the superiority of the proposed approach. A source code with example is provided."
            },
            "weaknesses": {
                "value": "The paper is well introduce and clearly explain but the derivations in appendix are quite hard to follow. It is not derivations but sketchs of derivations. A reference to a technical report with the derivations will be very useful."
            },
            "questions": {
                "value": "I was not able to find the description about the learning step in the paper. May you tell more about this important step ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7397/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698676935887,
        "cdate": 1698676935887,
        "tmdate": 1699636885949,
        "mdate": 1699636885949,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nOfMlxaDVb",
        "forum": "DHCp41nv1M",
        "replyto": "DHCp41nv1M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_nUZb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7397/Reviewer_nUZb"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes applying video diffusion models to the task of reconstructing video captured through scattering media. Specifically, this paper focuses on scenarios where the scattering is approximated by the so-called shower curtain effect, where the forward operator essentially reduces to a Gaussian blur kernel. The proposed method is based on posterior sampling given a pre-trained video diffusion model, supposedly containing prior knowledge of natural videos. The restoration of the original video is equivalent to doing a posterior sampling of the video diffusion model, conditioning on the blurry measurements. The evaluation of the proposed method is mainly done on two existing natural video datasets, and the scattering effect is simulated."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper tackles an important problem of imaging through scattering.\n- Incorporating diffusion models in the context of imaging through scattering is new."
            },
            "weaknesses": {
                "value": "- This paper only contains restoration results from **simulated** scattering. No successful restoration on any real-world scattering were demonstrated.\n- This paper only focuses on a naive special case of scattering, where the forward operator is trivially a Gaussian blur. Real-world scattering is much more complicated can requires the modeling of phase error caused by the scattering medium.\n- Ignoring the significance on the problem of optical scattering, the technical contribution on the algorithm side is very limited. The paper introduces minimal changes to existing approaches that apply the diffusion posterior sampling strategy on other inverse problem tasks.\n- This paper does not include literature review on the problem of imaging through optical scattering, and fails to cite recent papers that could give the readers a more complete perspective on the state-of-the-art, such as:\n  - Imaging with local speckle intensity correlations: theory and practice, ACM Transactions on Graphics, 2021\n  - Guidestar-free image-guided wavefront shaping, Science Advances, 2021\n  - Prior-free imaging unknown target through unknown scattering medium, Optics Express, 2022\n  - NeuWS: Neural wavefront shaping for guidestar-free imaging through static and dynamic scattering media, Science Advances, 2023."
            },
            "questions": {
                "value": "What's stopping the proposed method from successfully working on real-world scattering? Can the proposed framework handle more sophisticated forward model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7397/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7397/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7397/Reviewer_nUZb"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7397/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698711399282,
        "cdate": 1698711399282,
        "tmdate": 1700506871738,
        "mdate": 1700506871738,
        "license": "CC BY 4.0",
        "version": 2
    }
]