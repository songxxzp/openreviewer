[
    {
        "id": "nQcx6EtYpw",
        "forum": "NV6rn7j5p5",
        "replyto": "NV6rn7j5p5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_PP6U"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_PP6U"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the visibility evaluation of the content in the new generative search eigen empowered by the recent success of generative AI. This paper proposes some metrics to evaluate the visibility of the contents by a generative search engine. Based on the proposed metrics, the authors propose several suggestions to the content creators to improve their websites to increase the visibility of their content. The authors also prepare a benchmark dataset to evaluate the performance of the optimization they proposed in this paper and provide some simple analysis of the results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. A benchmark dataset is provided.\n\n2. Some evaluation metrics are proposed. \n\n3. Some SEO suggestions are provided."
            },
            "weaknesses": {
                "value": "1. The two-step experiment setting does not convince me of the evaluation. In the experiments, several sources are fetched from Google search first (Top 5), then the generative SO generates responses to the query. Based on this two-step setting, the visibility of the contents highly depends on the results returned by the traditional search eigen. \n\n2. The scope of this paper may not attract many researchers from the ICLR community since there are limited contributions to the learning and representation perspectives. \n\n3. The suggestions provided in this paper are straightforward without much deep insight. \n\n4. The related works are not well discussed. Also, the citation style in the paper is not professional."
            },
            "questions": {
                "value": "1. In the evaluation, after modifying the contents, do we re-run the whole experiments following a two steps settings? If so, how to determine the modifications contribute to which step?\n\n2. In the evaluation, following the two steps setting, how to determine the citation of each source?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8373/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8373/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8373/Reviewer_PP6U"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675134421,
        "cdate": 1698675134421,
        "tmdate": 1699637041568,
        "mdate": 1699637041568,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KW0dJbOoR1",
        "forum": "NV6rn7j5p5",
        "replyto": "NV6rn7j5p5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_DAsT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_DAsT"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a method to improve the visibility of websites in generative engines. The authors first compare the differences in visibility measurement methods between traditional search engines and generative engines and propose visibility measurement indicators suitable for generative engines. Next, the article introduces the specific methods of GEO. Experimental results verify the proposed GEO can significantly improve the visibility of websites in generative engines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper explores a new problem when LLMs are served as generative engines\u2014content creators lose their control of how the content is displayed, because the direct information provided by the generative engines reduces the invisibility of original content, which leads to economic losses for content creators.\n- This paper proposes Word Count metric and  Position-Adjusted Count metric for invisibility when using generative engines.\n- This paper proposes several methods to alleviate the invisibility problem, such as authoritative, statistics addition, etc. Experiments demonstrate their effectiveness."
            },
            "weaknesses": {
                "value": "- The paper is not organized well. The main text should exist independently, and the appendices should only supplement the main text. However, most of the results (e.g., various tables) of the main text are placed in the appendix.\n- This paper uses GPT-Eval to evaluate the subjective impression in Table 1. The difference of difference dimensions is trivial and even completely the same in the first case. It is doubted whether this measurement is really valid and sufficient to support the conclusions of this paper.\n- The invisibility problem is not clarified well. Traditional search engines retrieve content and rank them. If a user clicks content, then traffic comes to the website. Traffic monetization brings money to content creators. For generative engines, what does the improvement of visibility help specifically? Does the improvement of word count help the economy of content creators?"
            },
            "questions": {
                "value": "Please refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethical issues."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698893275305,
        "cdate": 1698893275305,
        "tmdate": 1699637041442,
        "mdate": 1699637041442,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6y2eMTud0i",
        "forum": "NV6rn7j5p5",
        "replyto": "NV6rn7j5p5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_Lvo2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8373/Reviewer_Lvo2"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces 'Generative Engine Optimization' which talks about how website creators can optimize their websites for visibility in Generative search results. It also proposes various visibility metrics that content/website creators can use to gauge their website's performance."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper addresses a very novel problem for the website creators which is how they can optimize their content in order to rank higher in the generative search results"
            },
            "weaknesses": {
                "value": "Some of the weaknesses of the paper are:\n1. The methodology is not thorough enough, I see mentions of functions g, rel in Section 4, but then they are not defined anywhere else.\n2. The mathematical equations are not well defined and/or are incomplete. Specifically, I don't really understand S_ci and where it is coming from - Is it the set of sentences citing c_i *within* the response or not? Also the mathematical intuition or logic for calculating Imp_wc(c_i,r) is not clear to me.\n3. How is the benchmark dataset 'GEO-Bench' generated is not very clear to me - i get the queries are sourced from 9 different places, but do we also include responses in this benchmark dataset?"
            },
            "questions": {
                "value": "1. How is the benchmark dataset 'GEO-Bench' generated is not very clear to me - i get the queries are sourced from 9 different places, but do we also include responses in this benchmark dataset?\n2. Mathematical intuition behind the defined metrics\n3. I'm not clear how the modified response r' is generated? Also what exactly are we trying to improve - the evaluation metric defines 'Improvement_si' as the relative improvement in impression of each source s_i -> what does this mean? What will we achieve by improving the impression of a source s_i if it is already present in the response r?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699266150276,
        "cdate": 1699266150276,
        "tmdate": 1699637041326,
        "mdate": 1699637041326,
        "license": "CC BY 4.0",
        "version": 2
    }
]