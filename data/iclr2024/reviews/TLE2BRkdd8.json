[
    {
        "id": "FEfVC03Fcz",
        "forum": "TLE2BRkdd8",
        "replyto": "TLE2BRkdd8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_LkRN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_LkRN"
        ],
        "content": {
            "summary": {
                "value": "Algorithmic recourse, which suggests actions to alter unfavorable outcomes in decision-making systems, faces challenges due to model updates. A new uncertainty quantification method is introduced to assess recourse robustness against model shifts, offering a theoretical upper bound for recourse invalidation. Additionally, a novel framework helps users balance implementation cost and robustness by generating model-agnostic recourses based on the derived invalidation rate bounds, with promising results on various datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The research problem make senses in realistic problems.\n2. The upper bound is agnostic w.r.t. prior distribution (e.g., Gaussian), thus offers a more flexible approach."
            },
            "weaknesses": {
                "value": "1. My main concern is on whether the studied problem is novel enough. I admit that the problem of designing a robust post-hoc explanation problem is important for dynamic decision systems. However, such topic is not your contribution, as similar researches have emerged in recent top conferences in 2 years. \n2. Hence, as your contribution offers a more cost-efficient or flexible approach, I think the novelty or importance of your work is not well present. As you referred to before, current robust CF methods cannot handle efficient cost and robustness at the same time. However, I do not see any theoretical analysis in your method section regarding. this clarification, as your method section focuses on deriving the bound. Meanwhile, I think that it is important to theoretically clarify how your contributed method can achieve more efficient and robust CF against previous methods. \n3. Besides, I also have some minor questions. \n- Your robustness stands on the conformity score function, which depicts the variation of the predictors. However, the word robustness usually refers to the variation of the underlying distribution, or data. Although the variation of predicted distributions can be regarded as another measure to quantify the model shift, it is not clear whether the underlying data shifts or just the model shifts (e.g., new fine-tuning approaches). \n- Another direction for your paper is to consider more sophisticated description of how the data changes, i.e., considering strategic adaptation raised by population's incentives and the resulting predictors. I really think that considering the model shift or data shift in general is meaningless, especially in the era of LLMs. Well pre-trained models with a large amount of data can easilly beats over tricks towards distribution shift or model generalization. Hence, only specific topics on model shift or data shift, i.e., strategic adaptation, are still meaningful."
            },
            "questions": {
                "value": "As seen in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698304475266,
        "cdate": 1698304475266,
        "tmdate": 1699636389260,
        "mdate": 1699636389260,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7UPROflRi6",
        "forum": "TLE2BRkdd8",
        "replyto": "TLE2BRkdd8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_rDRT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_rDRT"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to address the inconsistency in recourse generation: as predictive models often change over time, there is a concern about the reliability and robustness of the generated recommendations. The paper addresses this issue by proposing a method to generate model-agnostic recourses that are both robust to model shifts and have lower implementation costs. The challenges of measuring the robustness of a recourse under a shifted model and accommodating users' different tolerance levels for recourse invalidation are discussed. The paper introduces the concept of recourse invalidation rate and utilizes conformal predictive inference techniques to bound the invalidation rate. An extended alternating direction method of multipliers (ADMM) approach is proposed to efficiently find the minimal cost recourse that satisfies the invalidation rate constraint."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper studies an important problem in the literature, and it potential has high impact if carried out properly."
            },
            "weaknesses": {
                "value": "1. The authors do not clearly state the contributions of this paper in the introduction.\n2. The authors do not provide a justification for why their methods work. In many cases, the model parameters are shifted because the underlying distribution of the dataset is changed. It is thus unclear why having access to the $D_{train}$ and $D_{calib}$ set can solve this distributional shift problem when these two sets have no predictive power of the future distributions.\n3. The authors do not illustrate whether the bound $\\hat L$ and $\\hat U$ are practically sensible. I guess that $\\hat L$ is trivially (close to 1) and $\\hat U$ is conservative (much bigger than 1). I am not convinced that the construction of these values is informative and effective at dealing with model shifts.\n4. The authors should discuss the privacy concerns of their method because their approach requires access to the dataset.\n5. Section 4 is confusing to read. They contain mostly formulas with ad-hoc definitions of mathematical terms and have no discussion to provide insights/intuition.\n6.   The numerical experiments do not show strong dominance against DiRRAc."
            },
            "questions": {
                "value": "My feeling is that the authors are over-complicating the problem. How about a simpler approach as follows:\nStep 1: Get all empirical values of the score.\nStep 2: Construct a kernel density estimator\nStep 3: Formulate a robust version by perturbing the kernel density using some divergences or total variation.\n\nI guess that the above three step can generate the same effect as what the authors want to do in this paper. But it is more interpretable and easier to understand."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698651605129,
        "cdate": 1698651605129,
        "tmdate": 1699636389173,
        "mdate": 1699636389173,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ezSem5kJ4F",
        "forum": "TLE2BRkdd8",
        "replyto": "TLE2BRkdd8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_NqmB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_NqmB"
        ],
        "content": {
            "summary": {
                "value": "Algorithmic recourse is the process of offering users recommendations for actions they can take to receive a positive classification from a machine learning model after they have received a negative classification. The focus of this work is on designing robust recourses, i.e. recommendations for improvement which are robust to shifts in the underlying predictive model being used to make decisions. The authors propose an uncertainty quantification method to upper-bound the invalidation rate (i.e. the probability the offered recourse is no longer valid under model shift) for a given pre-computed recourse. \n\nUsing their proposed uncertainty quantification method (recourse invalidation rate), the authors design an algorithm to manage the trade-off between the cost of recourse (e.g. the \"effort\" required for a user to achieve this recourse) and the probability that the given recourse will be invalid under model shift. In particular for a user-specified invalidation rate, the algorithm aims to return a recourse with minimum cost such that the probability of the recourse being invalid is at most the user's given rate. The authors formulate this objective as a (non-convex) optimization problem, and numerically solve it using gradient-free optimization methods. \n\nThe authors empirically validate their recourse invalidation bounds and find that the average empirical bounds are always tighter than their theoretical counterparts, sometimes by a significant margin. They also empirically evaluate the performance of their proposed algorithm and find that it generates more robust recourse solutions which are often easier to implement when compared to existing methods for recourse."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "While the authors are not the first to study the robust algorithmic recourse problem, their results are novel within this space (to the best of my knowledge). In particular, their proposed uncertainty quantification method (recourse invalidation rate) is an intuitive measure of of uncertainty under model shifts, which does not require distributional assumptions on the feature space. \n\nThe numerical results are also a welcome addition to the submission. In particular, the comparison between the empirical and theoretical bounds was helpful for gauging how tight the bounds of Theorem 12 and Theorem 13 are. Additionally, the numerical comparison between Algorithm 2 and several baselines in real-world data showed that the authors' proposed method often outperforms the relevant baselines."
            },
            "weaknesses": {
                "value": "I found the writing of this submission somewhat challenging to understand. In particular, Section 4 (Recourse Invalidation Estimation for a Given Recourse) reads as a laundry list of propositions, theorems, and lemmas with various definitions sprinkled in between. It was unclear to me which parts are the salient features, and which parts are there to aid in the understanding of more important results. I also found the inclusion of the comparisons to previous work in this section to be odd, as Section 2 (Background and Related Work) appears to be a more appropriate place for such comparisons. If the submission is accepted, I encourage the authors to rewrite Section 3 in a way which is more concise and highlights important results. \n\nAnother weakness of the submission is the lack of any theoretical performance guarantees for Algorithm 2. (In fact, even the algorithm's runtime is not specified.) Even if theoretical performance guarantees cannot be obtained due to the non-convexity of the problem domain, it would have been nice to see a discussion on what exactly makes obtaining performance guarantees in this setting challenging. \n\nFinally, while not a major weakness, the authors' theoretical upper bounds on recourse invalidation are often significantly loose when compared to their empirical counterparts."
            },
            "questions": {
                "value": "What is the runtime of Algorithm 1?\n\nWhat is the runtime of Algorithm 2? \n\nDoes Algorithm 2 enjoy any non-trivial performance guarantees? In other words, is it possible to say something about the cost of the solution returned by Algorithm 2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Reviewer_NqmB"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698679837485,
        "cdate": 1698679837485,
        "tmdate": 1699636389076,
        "mdate": 1699636389076,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rlLSdZuwXt",
        "forum": "TLE2BRkdd8",
        "replyto": "TLE2BRkdd8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_C8WR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4220/Reviewer_C8WR"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new algorithmic recourse aiming for robustness against model shift. The method, named Probabilistic Invalidation-based Robust Recourse Generation (PiRR), is formulated with ideas from conformal prediction and solved with extended ADMM. The paper also proposes a new metric called invalidation rate, with two upper bounds. Then, three baseline recourse methods are evaluated demonstrate the power of these bounds. The effectiveness of PiRR is also compared against four other methods in term of the new metric."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper contributes a novel approach and formulation to the field.\n- Most of the paper is well-written, except for section 4."
            },
            "weaknesses": {
                "value": "- The paper is not following the conventional citing style.\n- The paper did not present an evaluation of PiRR in the traditional cost-validity trade-off performance. This makes it hard to put the method in context of the current landscape of the field.\n- Section 4 seems cramped and could be improved."
            },
            "questions": {
                "value": "- Assumption 3 seems too restrictive to be practical, since you need a bounded future perturbation. Can you elaborate on how is your formulation advantageous compared to previous works?\n- Can you clarify the utility for each upper bounds presented in Theorem 12 and 13? Why are both presented and included in the evaluation?\n- Based on section 2, the method in (Nguyen et al., 2022) seems to be highly related to this paper. Why was it left out from further discussion?\n- The updated version of (Pawelczyk et al., 2022) is (Pawelczyk et al., 2023).\n- Some other robust recourse baselines are listed below.\n\nReferences\n\nTuan-Duy Nguyen, Ngoc Bui, Duy Nguyen, Man-Chung Yue, and Viet Anh Nguyen. Robust bayesian recourse. In proc. Uncertainty in Artificial Intelligence, pp. 1498\u20131508, Eindhoven, Netherlands, Aug. 2022.\n\nMartin Pawelczyk, Teresa Datta, Johannes van-den Heuvel, Gjergji Kasneci, and Himabindu Lakkaraju. Algorithmic recourse in the face of noisy human responses. arXiv preprint arXiv:2203.06768, Oct. 2022.\n\nMartin Pawelczyk, Teresa Datta, Johannes van-den-Heuvel, Gjergji Kasneci and Himabindu Lakkaraju. \u201cProbabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse.\u201d International Conference on Learning Representations (2023).\n\nVictor Guyomard, Fran\u00e7oise Fessant, Thomas Guyet, Tassadit Bouadi, and Alexandre Termier. \"Generating robust counterfactual explanations.\"  ECML/PKDD (2023).\n\nJunqi Jiang, Jianglin Lan, Francesco Leofante, Antonio Rago, and Francesca Toni. \"Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation.\" arXiv preprint arXiv:2309.12545 (2023)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4220/Reviewer_C8WR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830014559,
        "cdate": 1698830014559,
        "tmdate": 1699636388940,
        "mdate": 1699636388940,
        "license": "CC BY 4.0",
        "version": 2
    }
]