[
    {
        "id": "bKJBB6BxDV",
        "forum": "XlfTLt0zvd",
        "replyto": "XlfTLt0zvd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_PGZe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_PGZe"
        ],
        "content": {
            "summary": {
                "value": "Authors proposed the multi-task framework based on the transformer architecture to efficiently capture the high-resolution information in facial landmark detection task. Query-aware memory module is newly introduced and the multi-layer additive residual regression module and Euler angles loss are proposed. Experiments on two public benchmarks show the effectiveness of the proposed method showing the SOTA results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "QAMem module looks sound and it is well presented in the Figure 2.\nMARR and Euler angles loss also look effective to tackle the targetted problem.\nEnglish and presentation are sufficiently good to understand the work."
            },
            "weaknesses": {
                "value": "Less qualitative results: only 1 dataset is used for qualitative results. More is required.\nEven though the authors insist that the proposed method is efficient; while there is no report for the time complexity in their results.\nIn ablation study, when comparing Euler+QA and MARR+QA, the accuracy improvement is quite limited. It is unclear the accuracy improvement was due to the components, or not.\nExplanations for some equations are rather blurry (for eqs 2 and 3)."
            },
            "questions": {
                "value": "There is less explanation for how to proceed the equations from 2 to 3. \nWhy in ablation study, the three combination only can improve the final accuracy, even though partial combination is not that effective?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742188161,
        "cdate": 1698742188161,
        "tmdate": 1699636540744,
        "mdate": 1699636540744,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Y5Ri9X41xq",
        "forum": "XlfTLt0zvd",
        "replyto": "XlfTLt0zvd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_zzMV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_zzMV"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a multi-task 3D face alignment framework based on a transformer. The objective is to overcome three main drawbacks of existing methods: (i) first, the 2D facial landmark detection task and the 3DMM parameters prediction task are parallelized in the form of two transformer branches. 3DMM parameters are regressed through Transformers, where the cross-attention mechanism is used to enhance the information communication among task-oriented queries and extracted feature maps in the designed decoder; (ii) A lightweight module named query-aware memory (QAMem) is proposed that makes up the accuracy loss from lower feature map resolutions. To enhance the robustness of the predicted landmarks, the average vertices coordinates of the training set are calculated, then a multi-layer additive residual regression (MARR) module is designed in the decoder to guide the detection under the reference of an average face model. (iii) A multi-information loss function is used to optimize the network."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The main contributions are:\n- A Transformer-based multi-task framework is proposed for 3D face alignment, using a multi-task structure. 3DMM parameters are regressed through Transformers, where the cross-attention mechanism achieves the information communication among different elements.\n- A Euler Angles Loss in introduced to the multi-information loss function for network optimization, which enhances the predictive ability in the case of atypical head poses."
            },
            "weaknesses": {
                "value": "- The title of the paper is not appropriate in my opinion. The title emphasizes a face alignment contribution, while the content focuses more on face landmarks detection. \n- Table 2 indicates results that are comparable to the state-of-the-art but for some cases do not improve on it. \n- Parameters of a 3DMM are regressed in this work. However, it is not clear how much the choice of the 3DMM impacts on the results. Did the authors try with different 3DMMs? \n- In the ablation study it is not clear the impact of the 3DMM on the results. \n- An analysis of the computational cost of the method in comparison with other solutions is missing. For landmarks detection the capacity of the approach to work in real time is important. Authors should clarify this point."
            },
            "questions": {
                "value": "Q1: The contribution of the used 3DMM on hte final results is not clear. Did the authors try with different 3DMMs? Can they show results using different 3DMMs?\nQ2: In the ablation study it is not clear the impact of the 3DMM on the results. \nQ3: Authors should discuss and illustrate the computational cost of the method in comparison with other solutions is missing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698754934664,
        "cdate": 1698754934664,
        "tmdate": 1699636540588,
        "mdate": 1699636540588,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "slTtXCnPvL",
        "forum": "XlfTLt0zvd",
        "replyto": "XlfTLt0zvd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_QjYA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_QjYA"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new method for 3D face landmarks detection. The contributions are:\n- The paper also jointly estimate 2D face landmarks. \n- The paper employs a DETR like approach and each estimated parameter is associated with a query embedding. This can help information communication in joint estimation of all the parameters. \n- The paper also proposes a module to improve the model efficiency using low resolution features. \n- The proposed method predicts residuals from the average face instead of directly predicting the original face. \n- And Euler Angles loss is proposed to improve the performance on atypical head poses. \n\nExperiments show the competitiveness of proposed method compared with baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The presentation of the paper is good.\n+ The use of query embeddings and cross attention can help information communication in joint estimation of all the parameters. And this is interesting and novel.\n+ Visual demos show the effectiveness of the proposed method in 3D pose and landmarks estimation."
            },
            "weaknesses": {
                "value": "- For the qualitative comparisons, only DAD-3DNet is compared with. From table 5, DAD-3DNet is already worse than the proposed method. While SynergyNet, which performs better than the proposed method, is not compared with in the visual demos.\n- section 3.2, the description about QA memory is not super clear. Does the proposed method use more features maps to trade for a lower resolution? What is the benefit in doing this?\n- Due to large variation of head poses and face shape, it might not be a good idea to compute the average face and predict the residuals.\n- The paper proposes a Euler Angles loss, but from figure 4, it requires an estimation of the Euler angles from predicted 3DMM parameters. Therefore another module needs to be introduced do the estimation. This module introduces additional errors and might not benefit the supervision for 3DMM parameters.\n- From table 3, the QA module seems not to improve the accuracy compared with baseline.\n- From table 5, the proposed method is not quantitatively better than SynergyNet 3DV 2021."
            },
            "questions": {
                "value": "- The paper first mentions \"memory\" in the second paragraph in section 3.1. But there is no context and explanation about it. What does memory mean? Which part does it correspond to in the network structure?\n- Can the authors give more explanation and proof about the QA module and its effectiveness? Does the module use more feature maps to trade for lower resolution?\n- From section 3.3, the paper uses multiple decoders. What are the decoders like? Why are multiple decoders used? Do they make it computationally less efficient? There are no explanation about the usage of multiple decoders. Maybe I miss something.\n- section 3.4.1, how are Euler angles estimated from 3DMM parameters? Is a neural network used here?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818777277,
        "cdate": 1698818777277,
        "tmdate": 1699636540501,
        "mdate": 1699636540501,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4od13g86tm",
        "forum": "XlfTLt0zvd",
        "replyto": "XlfTLt0zvd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an efficient multi-task transformer for 3D face alignment, self-attention and corss-attention mechanisims were sused to enhance information communication among different elements of the network. Query aware memory (QAMem) is also designed to remove dependence on high-resolution feature maps. Experiments on two public benchmarks show that the approach can achieve resonable peformance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The presentation is clear and easy to follow.\nThe experiments seem to be intensive and resonable results were achieved."
            },
            "weaknesses": {
                "value": "1) The contributions seem to be a combination of deep learning tricks like multi-task structure, QAMem module, MARR and Euler Angles Loss, the improvement of each module seems to be incremental and the combination of these incremental contributions, do not become a significant contribution.\n\n2) The pose estimation results on AFLW2000-3D dataset, shown in Table 2, don't support that the proposed approach achieve better performance than SOTA. Th MAE, pitch and roll of the proposed approach are not as good as SynergyNet published in 2021.\n\n3) The ablation study in Table 3 don't support the effeictiveness of proposed modules as well. For example, the performance of Cham Dist for Trans3DHead is not as good as the baseline.\n\nI have read the response from authors and the comments of other reviewers. Most of the reviews also questioned the experiments and the results, which does not seem to be convincingly better than sota approaches, so I keep my orginal ratings."
            },
            "questions": {
                "value": "Further discussion of the novelty of the work need to be elaborated, I don't thnk the contribution listed in the paper, make a good work for top conference like ICLR."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5361/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5361/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698850454941,
        "cdate": 1698850454941,
        "tmdate": 1700881961109,
        "mdate": 1700881961109,
        "license": "CC BY 4.0",
        "version": 2
    }
]