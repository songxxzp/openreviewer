[
    {
        "id": "rd4TA2bDpn",
        "forum": "p6hIAEHwSp",
        "replyto": "p6hIAEHwSp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_qyFE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_qyFE"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles improving the scalability of the problem of differentiable inductive logic programming, a task of\nlearning suitable logic programs from data. The authors say that previous ILP algorithms\nhave scalability issues. The paper proposes some techniques to improve scalability.\nThe paper experimentally evaluates the performance by comparing it with a baseline method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The scalability issues of differentiable ILP is an important topic. It prevents the method from being used in broader situations."
            },
            "weaknesses": {
                "value": "**The paper is very hard to follow.**\nThis paper is tough to follow. I have to confess that I cannot understand what is the key difference of the proposed\nmethod compared with existing differentiable ILP methods. \nThis is mainly because the paper does not provide many definitions and background knowledge needed to understand the paper.\n\nFor example, there is no explanation of the differentiable ILP task. Also, the task's input and output seem not explained.\nMoreover, there is no definition of first-order logic used in this paper.\nThe background section starts with explaining multi-hop reasoning as a problem on graphs. How are these graphs related to ILP?\nThe paper must clearly show how differentiable ILP relates to graph problems.\n\nWhat are the tree-like structures? I think the paper should give a formal definition of tree-like structures. \nWhat are the messages passed among graphs? Is a message a real-valued vector?\n\nIn summary, the paper might contain important ideas that might be useful for the ML community. However, the paper is almost \nimpossible to understand in its current form for many readers. Therefore, I suggest a major revision to improve its presentation.\n\n\n**Results of experimental evaluations are weak:**\nIn experiments, the paper compares the proposed method with a baseline. This section is weak because:\n- There are no explanations of the details of experimental settings.\n- The proposed method is compared with only one baseline method, and the reason why the paper compared with NLIL is unclear. I think the paper should compare with more baseline differentiable ILP methods.\n- Experimental results only report time and F1 scores. They seem insufficient to judge that the claim of the paper is correct."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Reviewer_qyFE"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8424/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698640068765,
        "cdate": 1698640068765,
        "tmdate": 1699637049732,
        "mdate": 1699637049732,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "y8OTHPqtg3",
        "forum": "p6hIAEHwSp",
        "replyto": "p6hIAEHwSp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_Y7bE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_Y7bE"
        ],
        "content": {
            "summary": {
                "value": "A new approach for performing ILP using neural network parameterization is proposed. The main contribution is an approach capable of learning a broader set of rules than what is currently possible with state-of-the-art neural ILP methods. The proposed method relies on evaluating/verifying SAT on tree-like FOL structures by adapting a factor-graph message passing approach similar to existing methods. The novel aspect is \u201cfolding\u201d which is to use this to learn more complex FOL structures by introducing constraints for merging similar structures. \n\nFurther, to learn using neural methods, each of the discrete operations in the evaluation and learning of FOL structures is encoded as a differentiable operation on a continuous tensor representation (similar to TensorLog). Experiments are performed on 3 datasets (one synthetic and 2 other standard ones) and comparisons with an existing state-of-the-art neural ILP method show promising results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Learning more complex structures from neural ILPs seems like a significant contribution\n- The idea of using constraints for merging to form complex structures from trees and encoding them with neural nets seems interesting"
            },
            "weaknesses": {
                "value": "- The experiments dot not adequately show the impact of the proposed approach. Specifically, there is a single synthetic example (community) on which the complex rule learning outcome is demonstrated. It seems like the other compared approach fails here. There are 2 other benchmarks, but it seems like the proposed approach is not necessary here. \n- The paper leverages existing approaches (e.g. TensorLog, message-passing, etc.) so it was hard to understand the novel contributions of the paper."
            },
            "questions": {
                "value": "Can there be a more comprehensive evaluation done to show that i) complex rules are required for real-world cases and ii) existing methods fail for such cases while the proposed method can effectively learn such rules.\n\nOne of the aspects shown in the experiments is also learning time. How do more complex structures affect this?\n\nIf the novel contributions were better highlighted it would be useful to evaluate significance of the proposed method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8424/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698689189302,
        "cdate": 1698689189302,
        "tmdate": 1699637049592,
        "mdate": 1699637049592,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BVeFRSAJ88",
        "forum": "p6hIAEHwSp",
        "replyto": "p6hIAEHwSp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_x87R"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_x87R"
        ],
        "content": {
            "summary": {
                "value": "This work describes an improvement over the ground breaking work of TensorLog; The work addresses the chain nature of TensorLog rules by enabling disjunctions. Other complex graphs are essentially transformed to trees.\n\nUnfortunately, the experimental work is weak. It largely remains to be seen whether the author's claiims are valid."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The extension proposed is interesting, and seems to have bee.n impllemented.."
            },
            "weaknesses": {
                "value": "- Lack of experimental support\n- As the authors mention, the message passing is an improvement on the same proposal for Tor TensorLog. Can you please further clarify your contribution in this?\n- Your graph folding algorithm should be better motivtated"
            },
            "questions": {
                "value": "Please, use the reference style correcttyl,*\n                                                                         \nYour graph folding algorithm seems a bit aggressive. I was hoping a bit more of motivatioan and more experiments. Did you consider comparing with TensorLog or one of the many available neurosymbolic systems,\n\nWhat is the difference between T and SAT/ Thanks!\n\nTitle: you use the word efficient.  but I cold not find either theoretical or experimental suppodl"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8424/Reviewer_x87R"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8424/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698697112712,
        "cdate": 1698697112712,
        "tmdate": 1699637049398,
        "mdate": 1699637049398,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OelUI9rb34",
        "forum": "p6hIAEHwSp",
        "replyto": "p6hIAEHwSp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_WLDK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8424/Reviewer_WLDK"
        ],
        "content": {
            "summary": {
                "value": "The paper extends ILP techniques that were previously limited for checking the satisfiability of longer chains of variables to cases where the variables form tree structures or even more general cases, which are then addressed by factoring the variable graph.\nThe method is illustrated in a few domains, and works faster than previous algorithms, and is also able to learn rules that could not have been learned with chain-based approaches, as is demonstrated on a new artificial dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This seems to be a reasonable step forward. The approach is described in sufficient detail and generality, so that an outsider can also understand the key ideas. The results show that it improves over previous work."
            },
            "weaknesses": {
                "value": "The idea of factoring the variables does not seem to be entirely new to me. I can't give a concrete reference, but I am quite certain I have seen that before, maybe in a slightly different context. In any case, the step forward does not seem to be substantial.\n\nAlso, the practical relevance is not clear to me. Apparently, the authors had to define an artificial dataset where they can show that the technique does what it is supposed to do, because many standard problems can be solved with chains. \n\nReferences in the paper are weird, the authors almost always use \"author (year)\", also in cases where \"(author year)\" would be appropriate.  The first reference in the bibliography is not correctly sorted in (presumably there is something wrong in the BibTex entry).  In general, the related work is not very exhaustive, missing, e.g., recent works such as POPPER. For Metagol, no reference is given (only a pointer to a github page). It is also preferable to cite the published versions of arxiv papers, not the arxiv papers themselves.\nIt is interesting that the authors only provide URLs to papers by Yang et al. Why? Either provide all URLs or none. \n\nA few typos, such as \"boolean\" -> \"Boolean\". or a comma starting a new line (2nd paragraph 4.4). A careful proof-read would certainly improve the paper (but it is generally quite readable)."
            },
            "questions": {
                "value": "In the 90s, family relations were toy problems for the then state-of-the-art ILP programs. How do your domains differ from what was used then? Are these large graphs from which these relations are learned? How large? How would classical algorithms such as Foil or Aleph do on such problems? \n\nAre there benchmark problems where trees or more general graphs are necessary, or are chains sufficient for most problems?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8424/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698873782188,
        "cdate": 1698873782188,
        "tmdate": 1699637049267,
        "mdate": 1699637049267,
        "license": "CC BY 4.0",
        "version": 2
    }
]