[
    {
        "id": "sxiawcrh8G",
        "forum": "TXvaWOBuAC",
        "replyto": "TXvaWOBuAC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_kKNE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_kKNE"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors have tackled the theoretical understanding of pruning DDNs as a canonical compression technique. In particular, the weights of the originally trained network and the corresponding pruned one are projected to a probabilistic latent space with the same dimension and KL divergence between the distributions of the projections is upper-bounded. In addition, some experiments have been conducted to support the theoretical claims."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "While almost all compression papers are super practical and do not provide any theoretical justification for why compressed networks have the same or even better generalization,  this paper tackles to theoretically establish an analytical framework for understanding the pruning of DNNs through the projection of weights into a probabilistic latent space. In my opinion, this is the strength of this paper."
            },
            "weaknesses": {
                "value": "1 - The English of this paper needs to be improved significantly.\n\n2 - Many statements and definitions are unnecessarily wordy and long, making reading and following the paper difficult. \n\n3 - What is the meaning of $\\mathcal{F}$ in the emprical risk minimization? I don't follow the notation used in equation (1). if $w_F$ denotes the whole set of weights, what is the meaning of the product between $Y$ and this term (loss is supposed to be a scalar value)? What kind of product is considered in the expression of $l(w)$? The same thing in Lemma 2 for the function $g$,\n\n4 - In the example on page 3, the authors have said that \"without loss of generality, assume hat ...\". Why should the covariance of the projected pruned weights be positive definite (all eigenvalues are strictly positive ?)? This is actually used in the experiment of section 5.2. \n\n5 - I understand this is a theoretical paper, but choosing only CIFAR10/100 datasets, experimenting in a controlled setup like a diagonal covariance matrix, and on the last layer, using only three architectures for a simple classification problem (no other tasks have been considered), and no experiments for other architectures (RNNs, Transformers, etc) is not completely convincing approach.\n\n6 - I am confused with the notion of iteration $t$ in definition 5, and the \"trained sparse network\" in the theorem 2, Lemma 2, etc.:\n\u00a0 \u00a0 \u00a0Typically, pruning is an iterative approach, meaning that when a trained network is pruned, it should be retrained again (or fine-tuned) to \n\u00a0 \u00a0 \u00a0get back its original performance, and the process may be repeated if further pruning is required. Is this the case for you? if so, what are the \n\u00a0 \u00a0 \u00a0conditions for the retraining/fine-tuning procedure? (i.e., what is the initialization for the pruned weights? What about many other hyper- \n\u00a0 \u00a0 \u00a0parameters values? From the experiment, it seems the authors have indeed fine-tuned the pruned network, but there is nothing about \n\u00a0 \u00a0 \u00a0it in the theoretical claims. In addition, does the cycle of prune-retrain/fine-tune happen only one time? \n\n7- The experiment section is quite confusing. In particular, the explanation of the plots, and legends are not consistent. There are many plots that make them hard to follow. I highly recommend showing 2 or 3 figures with super clear legends and explaining them neatly."
            },
            "questions": {
                "value": "Please see my comments in the \"weakness\" part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Reviewer_kKNE"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761699570,
        "cdate": 1698761699570,
        "tmdate": 1699636215916,
        "mdate": 1699636215916,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BTaPD8mTQf",
        "forum": "TXvaWOBuAC",
        "replyto": "TXvaWOBuAC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_EYVP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_EYVP"
        ],
        "content": {
            "summary": {
                "value": "The paper delves into the domain of deep neural networks with a specific focus on network pruning and its relationship with probabilistic distributions. The primary objective is to understand and explain the behavior of pruned networks both theoretically and empirically.\n\nThe paper introduces intricate mathematical derivations to explain the behavior of pruned networks. A notable highlight is the introduction and exploration of properties like AP2 and AP3, which are closely linked to the Kullback-Leibler (KL) divergence between certain distributions.\n\nThe authors establish a connection between network pruning techniques and probabilistic distributions. By utilizing the AP3 property, they explain the training convergence of a compressed network to an optimal sparsity level without compromising performance.\n\nThe research showcases a comparative analysis between AP2 and AP3 properties to discern which provides better differentiation among various pruning methods. The aim is to offer insights into the performance differences of these methods.\n\nEmpirical evidence is presented through experiments on popular architectures like ResNet50, AlexNet, and VGG16 across datasets such as CIFAR10 and CIFAR100. The results validate the theoretical predictions and provide practical insights into the behavior of pruned networks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper introduces novel concepts like the AP2 and AP3 properties, which aim to explain the behavior of pruned deep neural networks through a probabilistic lens.The connection between network pruning and probabilistic distributions, especially in the context of non-Bayesian networks, appears to be a fresh perspective in the domain.\n\nThe research provides a balanced mix of theoretical derivations and empirical validations. Mathematical foundations are rigorously laid out, and their implications are tested with real-world experiments. Experimental results on architectures like ResNet50, AlexNet, and VGG16 across datasets such as CIFAR10 and CIFAR100 lend credibility to the theoretical claims.\n\nThe paper is structured coherently with distinct sections for mathematical derivations, experimental results, related work, and technical configurations. The document effectively uses figures and graphical representations to aid understanding, especially in the experimental results section.\n\nNetwork pruning is a crucial area in deep learning, especially given the computational challenges of deploying large models. By providing insights into the behavior of pruned networks and their connection to probabilistic distributions, the paper addresses a significant aspect of model compression and optimization. The findings can potentially guide researchers and practitioners in better understanding and implementing pruning techniques for deep neural networks."
            },
            "weaknesses": {
                "value": "The focus on specific architectures (ResNet50, AlexNet, VGG16) may limit the general applicability of the findings. The behavior of the pruning methods on newer or different architectures remains unexplored.\n\nThe paper could benefit from a direct comparison with state-of-the-art pruning techniques in terms of performance, computational efficiency, and model robustness. This would give readers a clear benchmark on where the introduced methods stand relative to existing methods.\n\nThere is no discussion on the sensitivity of the proposed methods to hyperparameters. Understanding how sensitive the AP2 and AP3 properties are to changes in hyperparameters would be vital for practitioners looking to apply these methods.\n\nThere is no mention of the robustness of the pruning methods against adversarial attacks or their performance under distribution shifts. Given the increasing importance of model robustness, an assessment in these areas could significantly strengthen the paper."
            },
            "questions": {
                "value": "Could you provide direct empirical comparisons of the AP2 and AP3 properties against traditional pruning baselines? How do these new methods fare in terms of conventional metrics like accuracy, FLOPs reduction, and memory footprint?\n\nHave you tested the robustness of the pruned networks using AP2 and AP3 against adversarial attacks? Additionally, how do these pruned networks perform under distribution shifts or in out-of-distribution scenarios?\n\nYou mentioned deviations from expected results based on Lemma 2. Could you delve deeper into the causes of these discrepancies and potentially adjust the theoretical models to account for them?\n\nAre there plans to extend the experiments to a broader range of datasets and architectures? This would help in understanding the generalizability of your findings.\n\nCould you provide a detailed analysis of the resource efficiency of the proposed methods, especially in terms of training time, inference speed, and energy consumption?\n\nHow sensitive are the AP2 and AP3 properties to changes in hyperparameters? An analysis or discussion on this would be beneficial for practitioners aiming to implement these methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805852433,
        "cdate": 1698805852433,
        "tmdate": 1699636215787,
        "mdate": 1699636215787,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pJfKI2lpZ4",
        "forum": "TXvaWOBuAC",
        "replyto": "TXvaWOBuAC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_4kq3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_4kq3"
        ],
        "content": {
            "summary": {
                "value": "This paper attempts to interpret network pruning by employing a probabilistic latent space of DNN weights. Two projective patterns, AP2 and AP3, are introduced in elucidating the sparsity of weight metrices. Experiments with AlexNet, VGG16 and ResNet50 on Cifar10/100 validate the theoretical results of AP2 and AP3."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A theoretical explanation of model compression is a less explored research area. Research in this area would be beneficial to develop new model compress methods."
            },
            "weaknesses": {
                "value": "The major issue of the paper is writing. Frankly, I can\u2019t follow the argument since the problem formulation. More details are provide in the Questions section below."
            },
            "questions": {
                "value": "Is there any justification of Eq. (1)? Why can the loss be represented as a correlation between the weighted combination of the networks and the label? What is the definition of $w_F$, etc.?\n\nHow $w^{(l)} \\in R^{M^{l-1}\\times M^l}$ is mapped by $P: R^{n\\times M^l}$ to $R^n$?\n\n$\\tilde{w}^* = m^* \\odot w^*$? To my understanding, the optimal sparse $\\tilde{w}^*$ can be different to masked version of $w^*$. As the sparsity pattern changes, the optimal weights can be very different to optimal weights of a full model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698863553739,
        "cdate": 1698863553739,
        "tmdate": 1699636215713,
        "mdate": 1699636215713,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D6psKNRhJD",
        "forum": "TXvaWOBuAC",
        "replyto": "TXvaWOBuAC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_amvG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2734/Reviewer_amvG"
        ],
        "content": {
            "summary": {
                "value": "The authors investigate the correlations between parameter compression error and performance difference in neural networks and their pruned counterparts. The compression error is computed either through the squared Frobenius norm of the parameters' projection to another space (though the authors generally use identity projection), or mapping the parameters to a space of probability measures and computing the KL divergence."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The authors' choice of topic is a crucial one: Understanding why and when compression works is important not only for better compression methodology but for extracting insights with learning theoretical implications."
            },
            "weaknesses": {
                "value": "- The paper fails to make a distinguishable contribution to understanding why and when compression works. It does not live up to the term \"explaining\" in its title since it contains no arguments why or when compression should be applicable without harming performance. In my estimation the paper ends up correlating some probabilistic divergences with performance difference between original and pruned network, but even then 1- using the Frobenius norm of the parameters' difference seems to work better, 2- the mapping of parameters to probabilistic measures are not motivated in any systematic way.\n- The paper is inconsistent with its terminology and notation, and omits some fundamental information or concepts when making its case. I provide a more detailed, chronological list of the points that I found problematic."
            },
            "questions": {
                "value": "Here I present some questions and observations from the text that I found difficult to understand:\n- Pg. 1 onwards: I find the usage of \"probability space\" and related terms confusing throughout the paper. Here $\\mathcal{Z}$ is introduced as a \"probability space\" but I strongly suspect the authors mean the domain (state space) of the random variable $Z$. Similar for $\\tilde{Z}$.\n- Pg. 1: Neither in the beginning, nor anywhere the paper makes an explicit, mathematical definition of compression. Given the centrality of the notion for the paper, and the various ways in which it can be defined, I find this a very important shortcoming.\n- Pg. 2: What is a \"probabilistic space\"? If the intended meaning is probability space, more care should be taken for using the established terminology. If not, explicit definition is required.\n- Pg. 2: I find it extremely confusing that the authors use the same terminology for the parameter matrix and its vectorized version. This confusion goes beyond this point as well. E.g. although the authors state that they will proceed with the vectorized parameters, Definition 1 clearly refers to parameter matrix.\n- Pg. 2: In (1), why do the authors refer to a weighted combination of models in the model space? As far as I can see this construction never referred to again.\n- Pg. 2: What are the domains of $\\mathbf{X}$ and $Y$? \n- Pg. 2: I think the paper needs to justify that $\\tilde{w}^* = m^* \\odot w^*$, that the ideal compressed parameters are a masked version of the ideal uncompressed parameters. But given no explicit definition of compression/pruning has been presented, this is difficult to do here.\n- Pg. 2 Definition 2: What is $n$? Above the authors used $\\mathbb{R}^{M_{l-1}\\times M_l}$, why use a different notation now?\n- Pg. 2 Definition 2: What is a filter? Above $f^{(l)}$ has been explicitly introduced as a network layer. But in this definition $f^{(l)}$ is called a \"filter\" and the layers are referred to through scalar $l$. I think that for a paper with theoretical aspirations the notations and terminology are too chaotic.\n- Pg. 2: The paper refers to $\\omega^{(l)}$ as both vectors and \"parameter set\"s. What is a parameter set? Why is the naming for this term changing?\n- Pg. 2: \"$\\mathcal{Z}$ and $\\tilde{\\mathcal{Z}}$ are latent spaces that could overlap.\" Should these two spaces not be the same in order for KL divergence to be computable? What are we integrating over in Eq. 2, if not?\n- Pg. 4 Definition 5: Why is the probability space in the first sentence defined? Is it used in any way? Is $\\mathcal{F}$ the event space here, was this notation not reserved for the model space? I strongly suspect that the authors intended mapping is to a space of probability spaces defined on the same measurable space, with the state space being $\\mathcal{Z} = \\tilde{\\mathcal{Z}}$. If this is true, the definition strays far away from this purpose, and the use of terms such as \"probabilistic space\" adds to the confusion.\n- Pg. 5 Theorem 1: The theorem starts with a compressed training scheme. This is not introduced beforehand or afterwards.\n- Pg. 6: How are these models pre-trained?\n- Pg. 8: Given these results, do not the papers' findings boil down to suggesting using Frobenius norm of the original and pruned parmaeters difference for examining compression and performance? If so, is this not a very novel finding, and should be considered in light of previous results such as [1].\n\n[1] Y. Jiang*, B. Neyshabur*, H. Mobahi, D. Krishnan, and S. Bengio, \u201cFantastic Generalization Measures and Where to Find Them,\u201d presented at the International Conference on Learning Representations, Sep. 2019. Accessed: Aug. 05, 2020. [Online]. Available: https://openreview.net/forum?id=SJgIPJBFvH\n\n---\n\n### Note after Rebuttals\n\nI thank the authors for their feedback, which clarified a number of confusing points in the paper, as well as some details I missed. Unfortunately, my fundamental concerns regarding the contributions of the paper as well as their presentation still mostly remain, based on which I retain my recommendation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2734/Reviewer_amvG"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698930153021,
        "cdate": 1698930153021,
        "tmdate": 1700859586408,
        "mdate": 1700859586408,
        "license": "CC BY 4.0",
        "version": 2
    }
]