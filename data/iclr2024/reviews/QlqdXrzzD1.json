[
    {
        "id": "DEZ1J4jwX4",
        "forum": "QlqdXrzzD1",
        "replyto": "QlqdXrzzD1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_zjK7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_zjK7"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an Adaformer to dynamically extract features of different categories with diverse object sizes. To this end, it can adapt to LiDAR-based 3D SOT tasks for unified training. Albeit the idea is relatively common, it can achieve the target of unified training with performance improvement."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- It is the first work to unified train all categories on the 3D SOT task.\n- The proposed Adaformer can effectively learn adaptively ball region relative to different categories, which agrees with the motivation of this paper.\n- The paper is well-written."
            },
            "weaknesses": {
                "value": "- You should discuss relative works on your key idea (e.g., encoding shape- and size-changed geometric information). \n   Relative works include [a] (adaptive region learning), [b] (dynamic ball-query selection for size, dynamic foreground and background learning), [c], etc.\n\n   [a] Pyramid r-cnn: Towards better performance and adaptability for 3d object detection.\n\n   [b] DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection.\n\n   [c] RBGNet: Ray-Based Grouping for 3D Object Detection.\n\n- The comparison of latency should include other methods that have been reported, e.g., [c], [d], etc. In addition, the recent SOTA SOT methods should also be included.\n\n   [c] Beyond 3d siamese tracking: A motion-centric paradigm for 3d single object tracking in point clouds.\n\n   [d] Implicit and Efficient Point Cloud Completion for 3D Single Object Tracking.\n\n- Why not verify on Waymo dataset\uff1f\n\n- Can Adaformer be extended to general detection\uff1f\n\n- Can you conduct other statistical analysis to reveal diverse size of different categories to further support you motivation?"
            },
            "questions": {
                "value": "Please see the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Reviewer_zjK7"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2989/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697967184444,
        "cdate": 1697967184444,
        "tmdate": 1699636243542,
        "mdate": 1699636243542,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pFHa3YQuYr",
        "forum": "QlqdXrzzD1",
        "replyto": "QlqdXrzzD1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_vKoh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_vKoh"
        ],
        "content": {
            "summary": {
                "value": "Previous 3D single object tracking models are all category-specific, incurring redundant parameters. In this paper, the authors propose to unify the different categories in a single model. A novel point cloud representation learning network based on transformers, named AdaFormer, is proposed to encode the dynamically varying shape and size information from cross-category data in a unified manner. Moreover, the authors construct two unified models following previous Siamese and motion-centric paradigms to compare. Performance gains validate the effectiveness of proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The motivation is great, category-unified model designing is meaningful and significant to SOT task and trying to unify them is of novelty.\n2. The model achieves good performance on KITTI and nuScenes."
            },
            "weaknesses": {
                "value": "No obvious weakness from my perspective"
            },
            "questions": {
                "value": "Are there any inference speed and FLOPs comparison for proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2989/Reviewer_vKoh"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2989/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721662320,
        "cdate": 1698721662320,
        "tmdate": 1699636243460,
        "mdate": 1699636243460,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AyA4DiCRhr",
        "forum": "QlqdXrzzD1",
        "replyto": "QlqdXrzzD1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_5oVT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2989/Reviewer_5oVT"
        ],
        "content": {
            "summary": {
                "value": "Existing 3D single object tracking (SOT) approaches mainly focus on category-specific model training and evaluation. Inspired by general 2D SOT, this paper proposes to use category-unified model for 3D SOT. Specifically, the paper proposes a point set network named AdaFormer to encode geometric information of different object categories in a unified manner. To further boost the performance, the unified model inputs and learning objective are introduced to facilitate the learning of unified representation. To verify the effectiveness, two category-unified models SiamCUT and MoCUT based on Siamese and motion-centric 3D SOT paradigms are proposed. Experiments on KITTI and NuScenes datasets show that the proposed approaches gain much performance improvements over the baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper written&&organization is good, which is easy to follow.\n- I think the problem solved in this paper is valuable to the 3D SOT community, since current approaches mainly need to train multiple models corresponding to various training categories in the dataset in order to achieve higher performance. This paper shows competitive category-specific results by only learning a unified representation model (although I do not see the authors claim any training details about their unified training, e.g., training their models on all category samples on KITTI and then test it on category-specific KITTI).\n- The paper is technically sound, which solves the above problem progressively by proposing multiple modules."
            },
            "weaknesses": {
                "value": "- The proposed approach can track objects across all categories using a single network with shared parameters. But as I mentioned above, there is no training details about the unified training. Is the proposed only trained on the full KITTI and then test on it (the same for Nuscenes)? or the combination of KITTI and Nuscenes are used? Please all more illustration in the paper.\n- The main concern in this paper is about the lack of Waymo dataset evaluation and missing recent approaches for comparison. Please also include the latest references below for comparison, in order to better verify the effectiveness of the proposed approach.\n\n[1] Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking. ACCV 2022.\n[2] 3D Siamese Transformer Network for Single Object Tracking on Point Clouds. ECCV 2022.\n[3] CXTrack: Improving 3D Point Cloud Tracking with Contextual Information. CVPR 2023.\n[4] A Lightweight and Detector-Free 3D Single Object Tracker on Point Clouds. IEEE Transactions on Intelligent Transportation Systems. 2023."
            },
            "questions": {
                "value": "- The proposed approach can track objects across all categories using a single network with shared parameters. But as I mentioned above, there is no training details about the unified training. Is the proposed only trained on the full KITTI and then test on it (the same for Nuscenes)? or the combination of KITTI and Nuscenes are used? Please all more illustration in the paper.\n- The main concern in this paper is about the lack of Waymo dataset evaluation and missing recent approaches for comparison. Please also include the latest references below for comparison, in order to better verify the effectiveness of the proposed approach.\n\n[1] Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking. ACCV 2022.\n[2] 3D Siamese Transformer Network for Single Object Tracking on Point Clouds. ECCV 2022.\n[3] CXTrack: Improving 3D Point Cloud Tracking with Contextual Information. CVPR 2023.\n[4] A Lightweight and Detector-Free 3D Single Object Tracker on Point Clouds. IEEE Transactions on Intelligent Transportation Systems. 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2989/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698852054712,
        "cdate": 1698852054712,
        "tmdate": 1699636243395,
        "mdate": 1699636243395,
        "license": "CC BY 4.0",
        "version": 2
    }
]