[
    {
        "id": "RchCyvLhNR",
        "forum": "y886UXPEZ0",
        "replyto": "y886UXPEZ0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
        ],
        "content": {
            "summary": {
                "value": "The paper reveals that domain-specific pre-training greatly reduces LLMs'  prompting ability. The authors introduce a method to transform raw texts into comprehension tasks, aiming to enhance LLM's domain knowledge without sacrificing prompting skills. Experiment results show their 7B model is competitive with larger models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Interesting observation: Pre-training on domain-specific datasets leads to a decline in LLM's prompting ability.\n2. The proposed idea is straightforward, simple, and has the potential for broad applicability with clear motivation.\n3. Experimental findings indicate that domain-specific reading comprehension texts enhance the model's performance."
            },
            "weaknesses": {
                "value": "1. The novelty seems somewhat constrained, especially regarding the idea of incorporating reading comprehension tasks during the pre-training phase, which appears similar to the following paper:\nRECKONING: Reasoning through Dynamic Knowledge Encoding. \n2. The authors conducted experiments only on the 7B model. It's uncertain whether consistent results would be observed on larger-scale models, and it's unclear if the proposed method is effective on models after RLHF. (However, I think this weakness doesn't undermine the contribution.)"
            },
            "questions": {
                "value": "I'm confused why pre-training on domain-specific knowledge leads to a decrease in LLM's prompting ability. Could you clarify?\nEspecially in the explanation, does the term 'input-output patterns' pertain to limited data patterns or is it referring to something else?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2192/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2192/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727833040,
        "cdate": 1698727833040,
        "tmdate": 1699636153115,
        "mdate": 1699636153115,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aemorleVkC",
        "forum": "y886UXPEZ0",
        "replyto": "y886UXPEZ0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_qcCv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_qcCv"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to adapting LLMs via reading comprehension for QA. The authors conduct extensive experiments on various QA datasets. The results show the effectiveness of the proposed method. The paper is well written and the solution is clear."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors conduct extensive experiments on various QA datasets. The results show the effectiveness of the proposed method.\n2.  The paper is well written and the solution is clear."
            },
            "weaknesses": {
                "value": "1. I download the Supplementary Material and find that there are many missing files, such as codes and the full data sets. \n2. The implemtation details are not clear, such as GPU and memory size and  the parameters."
            },
            "questions": {
                "value": "1. I download the Supplementary Material and find that there are many missing files, such as codes and the full data sets. \n2. The implemtation details are not clear, such as GPU and memory size and  the parameters."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698758217393,
        "cdate": 1698758217393,
        "tmdate": 1699636153033,
        "mdate": 1699636153033,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wUDKm35EYA",
        "forum": "y886UXPEZ0",
        "replyto": "y886UXPEZ0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_aRRU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_aRRU"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on the investigating domain-adaptation pretraining method for LLMs, where they continued training on domain-specific corpora and found the approach hurts the LLMs' prompting ability. Thus, the author proposes to convert the corpora into reading comprehension texts to preserve the prompting performance. The experiments show the effectiveness of the method in three different domains (biomedicine, law, and finance)."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The proposed prompts are very effective, as showed with a significant zero-shot performance improvement across 3 domains, and the 7B model used in the experiment can outperform larger models (50B).\n- The paper is well-written. The author puts a comprehensive details on the experiments and analysis."
            },
            "weaknesses": {
                "value": "- Some ablation studies are essential to understand the effectiveness of the components (e.g., how the verbalizer affects the performance)\n- The baselines are not comparable to the results reported by the authors. E.g., GPT-J 6B. It will be great to have the AdaptLLM result on top of the baselines wherever the models are publicly available."
            },
            "questions": {
                "value": "- How did you choose the set of strings for the verbalizer?\n- Are there any analyses or findings on why the model performance improvement on domain \"law\" is the least? \n- Does the approach benefit another type of models? e.g., encoder-decoder model? or other decoder-only models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801197443,
        "cdate": 1698801197443,
        "tmdate": 1699636152958,
        "mdate": 1699636152958,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aH9NAcSiXe",
        "forum": "y886UXPEZ0",
        "replyto": "y886UXPEZ0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_Cte9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2192/Reviewer_Cte9"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an approach for continuing the pretraining of Large Language Models (LLMs) on domain-specific corpora. Initially, the authors find that conventional domain-adaptive pretraining enhances knowledge probing while detrimentally affecting the model's prompting ability. Subsequently, they propose transforming domain-specific documents into a reading-comprehension style format. In this format, certain sentences are altered via mining patterns to pose NLP tasks such as summarization and commonsense reasoning, accompanied by their respective answers. The experiments, spanning the biomedical, finance, and law domains, demonstrate that the proposed approach yields marginal improvements in the performance of LLMs on domain-specific tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed approach is straightforward yet effective in enhancing performance on domain-specific tasks, which has potential applicability to other models and domains.\n- The experiments include three representative domains and six mining tasks, which may have sufficient coverage in terms of domains and tasks.\n- The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "- In Table 4, the performance improvements appear marginal to me (3% in biomedicine, 4.8% in finance, and 4.3% in law). I am uncertain whether the benefits gained from using the proposed approach justify the effort required to transform corpora into reading comprehension texts.\n- The authors only use the LLaMA 7B model for verifying their proposed method. It remains unclear whether the approach is similarly effective for smaller and larger models."
            },
            "questions": {
                "value": "- Texts in corpora may possess their own document structure, and mining NLP tasks could potentially disrupt it, impacting readability and coherence. Have the authors manually verified whether their transformation is effective without compromising the integrity of the text?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698840959461,
        "cdate": 1698840959461,
        "tmdate": 1699636152878,
        "mdate": 1699636152878,
        "license": "CC BY 4.0",
        "version": 2
    }
]