[
    {
        "id": "2Xwb4xGdj0",
        "forum": "4SmhpF1nO4",
        "replyto": "4SmhpF1nO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_KYqz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_KYqz"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method for minority oversampling with autoencoders to tackle the class imbalance of tabular data. The proposed method trains an autoencoder with class-reweighted metric learning loss and filters the synthetic samples afterward. They conducted extensive experiments across 36 datasets and showed that the proposed method achieves competitive performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and easy to follow.\n- The proposed method is simple and achieves competitive results."
            },
            "weaknesses": {
                "value": "My major concern is that there are not enough ablation studies nor analysis of the proposed method:\n- Can authors provide some insights or ablation on why the Softmax loss is not directly applied to the original latent space but rather a linear-mapped space? What if using a non-linear mapping? How would the performance change if using larger or smaller weights for this loss?\n- The authors claim that Normalized Softmax loss performs the best. It would be more convincing and insightful if comparisons with other losses were provided.\n- Similarly, it would be great to also see the ablation of the class reweighting factors in Section 3.1.1, and the importance of the proposed oversampling in Section 3.2.1\n- What alternative thresholding strategy could be used in Section 3.2.2? Some comparison is needed to demonstrate the effectiveness of the proposed thresholding IMHO. Besides, it would be interesting to compare this with an oracle experiment, where the minority classifier is trained on a large amount of balanced data.\n\nOther concerns:\n- In my understanding, the proposed method can be used in broader scenarios. Why is the tabular data the scope of the paper? Is there any part of the method that is specifically designed for tabular data, or explores the structure of the data? \n- Is there a better way to rank the methods compared in Table 1? Imagine that we have methods A and B and two datasets,  A outperforms B with a large margin on one dataset but is outperformed by B on another dataset with a small margin, it will count as 1 best for each method, though in this case, A would be the preferred one."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698718334329,
        "cdate": 1698718334329,
        "tmdate": 1699636223326,
        "mdate": 1699636223326,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pFBFmiWj9X",
        "forum": "4SmhpF1nO4",
        "replyto": "4SmhpF1nO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_Uo1S"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_Uo1S"
        ],
        "content": {
            "summary": {
                "value": "The authors proposed Tabular Deep-SMOTE for class-imbalance mitigation in tabular datasets. The oversampling takes place in the latent space of an autoencoder trained in a supervised manner using metric-learning loss. Further, the authors introduce an importance-oversampling scheme that prioritizes oversampling near class domain boundaries. Lastly, to guarantee the quality of synthetic samples, they propose a synthetic sample filtering scheme based on the decision boundary of a pre-trained classifier."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Considers an important problem in the community."
            },
            "weaknesses": {
                "value": "While the authors have reviewed a fair amount of literature, a few significant works that are highly related are missing. For example, the methodology in [1] is very similar in spirit to what has been proposed.\n\nFurther, I have failed to understand why the authors limited the experiments only to tabular datasets. Is there something specific to the method that prevents the method from being applied to an image dataset? If not, then I would highly recommend and appreciate benchmarking using standard image datasets.\n\nMoreover, I suggest the usage of evaluation metrics best suited for imbalance learning as proposed in [2].\n\nThe authors do not report standard deviations of the performance evaluation. Therefore, it is not clear whether the performance boost is significant. For example, in thyroid_sick dataset the difference in performance w.r.t the runner-up method is 0.002.\n\nA severe limitation of the proposed method is that the datasets used for experimentation are a binary classification problem. So how will it perform in multi-class settings?\n\nBased on the discussion above, my initial opinion is borderline reject.\n\n1.\tMondal, Arnab Kumar, et al. \"Minority Oversampling for Imbalanced Data via Class-Preserving Regularized Auto-Encoders.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2023.\n2.\tMullick, Sankha Subhra, et al. \"Appropriateness of performance indices for imbalanced data classification: An analysis.\" Pattern Recognition 102 (2020): 107197."
            },
            "questions": {
                "value": "1. The paper describes the method as an algorithm without any justification on why should their design choices matter. One can think of establishing generalization bounds, as in [1]. \n\n1a. For instance, why should the imposition of a metric loss on the latent space lead to better oversampling (mathematically).\n\n1b. SMOTE and its variants are known to perform extremely badly in high-dimensions (due to their dependence on distance metrics). Therefore why should WeightedSMOTE be any good?\n\n2. The datasets used are very toy-like and not suited for practical scenarios. \n\n3. As described earlier, I don't understand why should the method be restricted to tabular data. \n\n4. The baselines used are obsolete. \n\n5. The writing is very cumbersome (not meticulous). \n\n6. Figure 3 is unreadable and frivolous in my opinion. \n\nIn summary,  this paper lacks novelty, has weak experiments, and has bad writing. It needs a lot of improvement before it can be considered in atop venue."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773704506,
        "cdate": 1698773704506,
        "tmdate": 1699636223248,
        "mdate": 1699636223248,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fLLPl26sLm",
        "forum": "4SmhpF1nO4",
        "replyto": "4SmhpF1nO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_RWeJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_RWeJ"
        ],
        "content": {
            "summary": {
                "value": "- This paper introduces a new oversampling method \u201cTabular Deep-SMOTE\u201d which    is applying autoencoder to SMOTE.\n- This paper shows experimentally superior AP and AUC score than other oversampling method by adopting three new methods : metric-learning loss, importance sampling in SMOTE , and filtering scheme."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Strengths:\n\n- Improved the performance by introducing new oversampling method."
            },
            "weaknesses": {
                "value": "Weaknesses:\n\n1. metric-learning loss : The paper uses a linear weight for each label, but it doesn't specify whether this weight is a learnable parameter or if it's defined differently. It seems to be a learnable parameter, but if that's the case, I'm not sure why this weight is helpful for distinguish the two classes.\n\n2. cosine similarity : In the latent space, the metric-learning loss is used to ensure good class separation. However, I wonder how well the cosine similarity works. It would be helpful if additional experimental results related to this are provided. Moreover, if the separation is done well by the cosie similarity, there might be no need to use SMOTE.\n\n3. Experiment : The author reviewed the methods of applying the autoencoder to SMOTE. It would be great if numerical results of these methods are listed in the experiments. Also in addition to the number of times the best performance was achieved, it would be helpful if the authors also provide the average ranking.\n\n4. Theoretical result : There is no theoretical justification of the proposed method. \n\n<Minor error>\n\n1. In Algorithm 1, it seems to be indexing the feature \"\". It would be beneficial to define it before using it. \n\n2. In Algorithm3, the weight seems smaller the closer it is to the major class. It may need correction. Also, adding k_neighbors or to the index doesn't look good. Although it might complicate things, it would be better to use clear definitions."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698802157665,
        "cdate": 1698802157665,
        "tmdate": 1699636223151,
        "mdate": 1699636223151,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oymyGQdObv",
        "forum": "4SmhpF1nO4",
        "replyto": "4SmhpF1nO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_iTrN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2806/Reviewer_iTrN"
        ],
        "content": {
            "summary": {
                "value": "The paper Tabular Deep-SMOTE proposes a new minority oversampling scheme for dealing with imbalanced data, consisting of three components: an auto-encoder trained including class-labels, a novel importance weighting scheme, and filtering synthetic samples using a baseline classifier.\nThe paper shows that TD-Smote improves over baseline approaches in aggregate using average ranks over datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper does a very careful analysis of the problem and runs extensive benchmarks with a variety of metrics and learners.\nThe paper is well-written and the discussion of the relevant literature is comprehensive. Including a GAN-based approach in addition to the traditional approaches is also laudable."
            },
            "weaknesses": {
                "value": "The very careful analysis presented in the paper seems to confirm my initial intuition, which is that oversampling does not help. Figure 3, Numeric Datasets shows that no oversampling is nearly identical (and most approaches are statistically indistinguishable). Figure 12 and 13 seem to reinforce this reading of the results.\nFigure 11 shows improved results in ranks (though all methods are statistically identical), though I would argue that the F1 score is not an appropriate score in this setting, and AUC or AP should be used.\nFor categorical datasets, there seems to be an advantage to oversampling, in particular TD-Smote (though again, statistically indistinguishable from no oversampling). It would be interesting to investigate why here oversampling seems to be much more helpful than in the numeric case. Unfortunately I did not find the SVM results or the AUC results for categorical and mixed datasets.\n\nAnother weakness is that there is no direct comparison against DEAGO and TAEI, which TD-SMOTE is claiming to improve over. While it's obviously not feasible to compare to all relevant methods, these two seem very close, and in particular the paper claims that adding the label to the autoencoder is useful, which is only shown in Table 9 - and which has a somewhat surprising -20% influence. This seems a very big difference given how close the methods are in general, and I'd love to understand the meaning of that number better.\n\nMinor issues:\nThe citation for ctgan should list NeurIPS as venue, I think."
            },
            "questions": {
                "value": "Can you explain the numbers in appendix M? Are these average relative changes? The influences seem quite big, given how close all the methods are and how close they often are to \"no oversampling\".\n\nWas there a particular reason not to include DAEGO and TAEI in the comparison?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698894297241,
        "cdate": 1698894297241,
        "tmdate": 1699636223091,
        "mdate": 1699636223091,
        "license": "CC BY 4.0",
        "version": 2
    }
]