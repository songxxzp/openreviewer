[
    {
        "id": "j6ybk5ikHJ",
        "forum": "CJnyR3M6Oh",
        "replyto": "CJnyR3M6Oh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_mRWy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_mRWy"
        ],
        "content": {
            "summary": {
                "value": "This paper researches the sparse representation learning in hyperbolic space. It defines the sparsity of one point geometrically in the Cartan-Hadamard manifold and avoids the difficulty of defining a unique coordinate system in a general manifold. In order to ensure sparsity, this paper introduces a novel sparse regularization term hyperbolic 1-norm for continuous optimization. Further, since the defined optimization problem becomes non-smooth because of the $\\ell_1$ norm, the existing Riemannian gradient descent method would oscillate around the sparse solutions on a non-smooth function, while the proposed hyperbolic iterative shrinkage-thresholding algorithm (HISTA) successfully avoids the oscillation issue. Finally, the numerical experiments prove that the proposed HISTA is effective and outperforms the existing hyperbolic-space-based representation learning methods with respect to space complexity and sparse representation quality."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) This paper defines the sparsity of a point geometrically in Cartan-Hadamard manifold, which is non-trivial in hyperbolic space.  \n(2) This paper introduces a novel sparse regularization term hyperbolic 1-norm on a Cartan-Hadamard with an origin and orthonormal bases, which is non-trivial in a coordinate system of hyperbolic space.  \n(3) This paper proposes the HISTA that avoids the oscillation issue that occurs in the existing Riemannian gradient descent method.  \n(4) Experimental results indicate that the proposed algorithm outperforms the existing method in terms of oscillation issue, space complexity, and sparse representation quality."
            },
            "weaknesses": {
                "value": "(1) The proposed method only works for Cartan-Hadamard manifolds.  \n(2) There is no convergence analysis for the proposed HISTA.  \n(3) Currently the applications of the proposed sparse learning method are kind of limited.  \n\nSome typos:  \nan CHMOO -> a CHMOO;  \nPage 9, $\\epsilon = 10^3$ -> $\\epsilon = 10^{-3}$;  \nPage 9, delete \"sufficient\" in Section 8 Limitation."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7200/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7200/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7200/Reviewer_mRWy"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7200/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698352587901,
        "cdate": 1698352587901,
        "tmdate": 1699636855097,
        "mdate": 1699636855097,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OC4wgnACY6",
        "forum": "CJnyR3M6Oh",
        "replyto": "CJnyR3M6Oh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_r35J"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_r35J"
        ],
        "content": {
            "summary": {
                "value": "This paper innovatively proposes a sparse learning scheme for hyperbolic representation learning. By defining sparseness and 1-norm via the Cartan-Hadamard manifold, this paper derives a novel hyperbolic iterative shrinkage-thresholding algorithm (HISTA) to obtain sparse representations. With theoretical analysis and experimental verification, HISTA successfully achieves geometrically uniform sparsity and avoids oscillation issues."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Ideas presented in this paper have novelty. Existing hyperbolic methods lack the complete statement of sparse learning.\n2. Theoretical analysis is organized and clear. Adequate definitions and remarks enhance the credibility of this paper.\n3. Limitations and future studies are given from different perspectives, showing the fundamental contributions of this paper in sparse hyperbolic learning."
            },
            "weaknesses": {
                "value": "1. There lacks a graphical presentation of experimental results in the main body. Please optimize the article architecture for better readability.\n2. Symbols denoted in this paper are ambiguous sometimes. For example, the italic upper letter T represents the tangent space in the preliminary section but represents the final iteration number in Algorithm 1. Please check the uniqueness of notations.\n3. Several mistakes.\na) Sections 2, 3, 7 and 8 are missed at the end of the introduction.\nb) Why Definition 2 and Example 2 start in new lines? They should be consistent with others.\nc) SHP mentioned in Definition 3 should be italic-bolded.\nd) There is an incorrect spelling of Poincar\\'e at the end of section 6."
            },
            "questions": {
                "value": "Please refer to the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7200/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698728043719,
        "cdate": 1698728043719,
        "tmdate": 1699636854988,
        "mdate": 1699636854988,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ROxdS7UyEM",
        "forum": "CJnyR3M6Oh",
        "replyto": "CJnyR3M6Oh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_kjo2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7200/Reviewer_kjo2"
        ],
        "content": {
            "summary": {
                "value": "The paper extends the sparsity regularization framework of Euclidean representations to more general manifolds of nonpositive curvature called Cartan-Hadamard manifold (CHM). CHMs include the Euclidean geometry and hyperbolic geometries. The main idea is to study the orthonormal basis of the tangent space at some point of the manifold and apply l0- or l1-norm regularization via differential geometry tools such as the logarithmic map. Since l1-norm regularization might not converge to sparse solutions in practice, the paper proposes to extend an iterative shrinkage-threshold algorithm to CHMs to solve this practical issue."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Sparsity is an important tool in machine learning to avoid overfitting but has mainly been studied in the Euclidean context. Hyperbolic representations have been shown to outperform Euclidean representations in low-dimensional space. This paper presents an elegant regularization framework to promote sparsity CHMs in general.\n\nThe paper is well-written and its motivation is clear. Since the Euclidean space is a CHM, the connection and extension to CHMs are well explained."
            },
            "weaknesses": {
                "value": "Although the paper proposes a way to promote sparsity in CHMs, the family of considered Riemannian manifolds is still limited (i.e. complete Riemannian of nonpositive curvature). The paper illustrates a nice example where l1-norm regularization can be extended to some Riemannian manifolds, but it assumes the existence of exponential and logarithmic maps whose closed-form is often unknown in practice. \n\n The practical use of the proposed framework in real world applications is also unclear. In particular, Figure 6 in the Appendix shows that no regularization at all is competitive with the proposed method in terms of accuracy (sometimes even better). This limits the practicality of the proposed approach. \n\nAnother limitation is that the paper considers nonparametric embeddings, not neural networks. Although sparsity has been studied for embeddings in the signal processing community, the sparsity criterion in machine learning often focuses on the output representation of linear or nonlinear models such as Support Vector Machines and Multiple Kernel Learning."
            },
            "questions": {
                "value": "Could you explain the practical relevance of the approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7200/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816632800,
        "cdate": 1698816632800,
        "tmdate": 1699636854877,
        "mdate": 1699636854877,
        "license": "CC BY 4.0",
        "version": 2
    }
]