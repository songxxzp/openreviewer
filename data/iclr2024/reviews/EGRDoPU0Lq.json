[
    {
        "id": "TrJRP7RhhO",
        "forum": "EGRDoPU0Lq",
        "replyto": "EGRDoPU0Lq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_bpWC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_bpWC"
        ],
        "content": {
            "summary": {
                "value": "This paper extends an existing method for explanation of linear models to RBF kernels. The authors show how to extract approximate explanations from this extension by minimising distances in the embedded space. Experiments on simulated and real data indicate that these explanations are substantially better than some existing state-of-the art generic explanation methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Interpretation of non-linear SVMs is a important and impactful problem, particularly in the science where the focus may be more on discovery than performance. This method is straight forward, efficient, and seemingly very effective."
            },
            "weaknesses": {
                "value": "There is no exploration of how difficult the problem of extracting a pattern through minimising the MSE is. It's stated that the optimisation is run three times, with the mean being used to summarise them. It would be interesting to explore the stability of the iteration more, as this is the critical part of the algorithm. It is also unclear if the mean is the best summary statistic as there may be multiple equally satisfactory explanations possible.\n\nOnly neuroimaging data is considered, both for simulations and the real world dataset. It would be interesting to know how this method scales with dimensionality, and if it still remains useful in p >> n scenarios."
            },
            "questions": {
                "value": "- Have high dimensional datasets been investigated?\n- It would be great to understand more the stability of the MSE optimisation, and if the mean is appropriate."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698365382774,
        "cdate": 1698365382774,
        "tmdate": 1699636222603,
        "mdate": 1699636222603,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XgLZkcYqW1",
        "forum": "EGRDoPU0Lq",
        "replyto": "EGRDoPU0Lq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_KvcN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_KvcN"
        ],
        "content": {
            "summary": {
                "value": "Needs more work.\n\nThe writing is really not presenting the paper under the most favorable light. I think that should this paper be accepted, which I do not recommend, an extensive rewrite is absolutely needed for the sake of the readers and the conference attendees.\nThere are too many vague statements and too many unclear sentences that make reading the paper too cumbersome.\n\nThe subject is narrow, the theoretical contribution is not exceptional, the experimental results are too terse.\nIn particular, the experiments are not varied enough to validate the method in general."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) Some experimental results are encouraging, in particular Figure 2C and the fact that the method proposed by the authors is much faster than the presented competitors.\n\n2) The method is relatively simple and well documented in Algorithm 1."
            },
            "weaknesses": {
                "value": "1) The impact is too narrow in my opinion and the technique not innovative enough.\n\n2) The experimental results are not diverse enough to really argue that the method is recommendable for general purpose XAI. The authors might want to have a deeper discussion about other kernels.\n\n3) The writing of the paper is too loose which is detrimental to the reader and the conference's audience. E.g. while XAI is a \"hot topic\" I would not use that language in an academic paper, specifically a paper with a very narrow focus application-wise."
            },
            "questions": {
                "value": "1) Could the authors please expand the experimental section to make it more convincing to the general XAI audience?\n\n2) Could the authors please deepen the discussion on other kernels and why they are not treated in the paper?\n\nThank you."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698808447848,
        "cdate": 1698808447848,
        "tmdate": 1699636222521,
        "mdate": 1699636222521,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yEU6hmBoq0",
        "forum": "EGRDoPU0Lq",
        "replyto": "EGRDoPU0Lq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_vJrk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_vJrk"
        ],
        "content": {
            "summary": {
                "value": "This paper concerns explainability in kernel methods, such as SVMs with RBF kernels.\nThe important problem of correlated noise typically leads to a confounded importance \"heatmap\".\nHaufe et al. (cited in the paper) solved the linear case, while the non-linear case has been looking for good ideas.  Here the authors propose to use the approximate linearity of latent space in kernel methods to de-noise the explanation using Haufe et al.'s method there.\n\nSimulation and benchmark cases are studied. In the simulation study where feature space ground truth is available, the proposed method outperforms relevant baselines. \nIn benchmark data where earlier analyses can be used as a proxy for ground truth, performance looks promising\n\nThe mathematical and algorithmic work is basic based on a straightforward application of kernel denoising by pre-imaging."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Simple and productive idea.\nStraightforward development of an algorithm with some additional minor heuristics (explained in the algorithm 1 box).\nExperimental results (including error estimates for the simulation study) supports the proposal.\nComputational cost is much less than baseline methods."
            },
            "weaknesses": {
                "value": "Much of the math is so basic that a simple reference would have been enough. The gained additional space could have been used to explore the role and significance of the assumptions and heuristics used to stabilize the solution.\n\nThe writing is not always so clear - could have benefitted from a writing assistant."
            },
            "questions": {
                "value": "Please address the role and significance of the assumptions (linearity of latent space) and heuristics (ensemble averaging). \n\nConsider running the manuscript with a writing assistant."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698940067768,
        "cdate": 1698940067768,
        "tmdate": 1699636222445,
        "mdate": 1699636222445,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6BjhU4pxuY",
        "forum": "EGRDoPU0Lq",
        "replyto": "EGRDoPU0Lq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_pU9a"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2799/Reviewer_pU9a"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new explainer of the kernel SVM under the framework of interpretable machine learning or XAI, which is an active research area. Haufe et al (2014) proposed an explainer for linear models based on a latent variable approach with applications in neuroimaging analysis. The approach is extended to kernel SVM in this paper. As shown in simulations and real applications, the proposed method gives more cogent explanations but also runs faster when compared with the popular explainers such as SHAP and LIME."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is working on a significant problem. The contribution is significant due to the improvement over the state-of-the-art explainers like LIME and SHAP."
            },
            "weaknesses": {
                "value": "1. The \"Experiment\" section requires more clarity. Simply mentioning that data generation utilizes a MATLAB toolbox isn't comprehensive. There's a need for details of the signal and noise pattern creation processes. It's important to highlight that the true data-generating model isn't linear, which underscores the preference for kernel SVM over its linear counterpart.\n2. While the emphasis on neuroimaging data is pertinent, its scope appears restricted. The proposed technique seems to be quite general. Could it be naturally integrated with other kernel methodologies, like kernel logistic regression, for instance? The support vectors in SVM might be instrumental in expediting explanation computation; however, this strategy might be equally effective for kernel logistic regression. Furthermore, adapting this method for conventional tabular data could be valuable. In such a scenario, the resulting explanation vector could serve as a metric for variable importance."
            },
            "questions": {
                "value": "In addition to the queries outlined in the \"Weakness\" section, there is another question. Is it true that the proposed method roughly gives the same result with a naive approach which simply gives the mapped data $\\phi(x)$, say by eigendecomposition, and directly applies the linear explainer proposed in Haufe et al (2014)? Even if the current proposal operates without the precise mapping of $\\phi(x)$, might we obtain a comparable outcome if $\\phi$ is discerned through a more rudimentary approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2799/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698990734390,
        "cdate": 1698990734390,
        "tmdate": 1699636222375,
        "mdate": 1699636222375,
        "license": "CC BY 4.0",
        "version": 2
    }
]