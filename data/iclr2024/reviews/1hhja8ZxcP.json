[
    {
        "id": "3PbMl6CZwT",
        "forum": "1hhja8ZxcP",
        "replyto": "1hhja8ZxcP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission216/Reviewer_1NQ6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission216/Reviewer_1NQ6"
        ],
        "content": {
            "summary": {
                "value": "The manuscript describes an application of the conditional diffusion model for the simulation of complex physical system, turbulent flows. The authors performed an extensive numerical studies using a range of solvers and a few different flow geometries. It is shown that overall the diffusion model outperforms supervised approaches."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors performed large-scale simulations and extensive numerical experiments to investigate the conditional diffusion model for the physics problems. The result seems to suggest an advantage of the diffusion model in physics simulations."
            },
            "weaknesses": {
                "value": "While it is interesting to see the capability of the diffusion model in learning physics problems, the study does not go beyond a relatively straightforward application of the conditional diffusion model, which does not align well with the scope of ICLR. The authors used simple evaluation metrics, which may miss important characteristics of physics problems."
            },
            "questions": {
                "value": "1. One of the most important characteristics of the physics problem is the conservation law. If not the mass conservation constraint, the computation becomes just a very simple matrix vector multiplications. What's the divergence-free error of the diffusion model and how it compares with the computational physics model?\n\n2. MSE error may not be the best metric to investigate the physics problem. For example, it will be helpful to compare the power spectrum to see if the nonlinear energy transfer is correctly represented in the diffusion model. For the turbulent problems considered, there are well defined metrics that give better representation of the physics. The authors need to compare those metrics, instead of simple MSE.\n\n3. What does it mean to have a posterior sampling? While the diffusion model can sample from the probability distribution, the problem itself is deterministic. It does not make a sense, simply because the diffusion model can generate a sample from a distribution, suddenly the authors arguing that they can sample from a posterior distribution when the problem setup is deterministic. If the authors consider the primitive variables as random variables, the problem formulation has also be properly stated and changed.\n\n4. Again from the comment 3, the paper lacks a proper problem formulation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission216/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698260318049,
        "cdate": 1698260318049,
        "tmdate": 1699635947085,
        "mdate": 1699635947085,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3O4syfBeFe",
        "forum": "1hhja8ZxcP",
        "replyto": "1hhja8ZxcP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission216/Reviewer_ySpT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission216/Reviewer_ySpT"
        ],
        "content": {
            "summary": {
                "value": "The authors introduced a method that trains diffusion models to capture the joint distribution of turbulent flow states over a few time steps, and apply conditioning at inference time to perform autoregressive rollouts. The authors compare the proposed method against models which are trained autoregressively using multiple flow examples and observed competitive accuracy and temporal stability characteristics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Paper is generally well written and not difficult to follow\n* Evaluation is done with meaningful benchmark methods; ablation studies are comprehensive\n* Proposed model is capable of generating probabilistic predictions, whereas most competitors are deterministic in nature\n* The proposed method does seem to result in good stability characteristics when rolled out for an extended period of time - an important challenge for many existing methods dealing with dynamical systems"
            },
            "weaknesses": {
                "value": "* The approach is not novel - it simply applies an existing way of conditioning diffusion model to do autoregressive rollouts of turbulent flow trajectories.\n* The presented benchmark is not fair in two ways\n    * Autoregressive diffusion sampling is very expensive, basically taking <the total number of denoising steps> times more (~20 in this case) compute than the U-Net model. A fair comparison would involve a U-Net either with larger capacity or integrated forward at finer time steps such that the compute cost is comparable.\n    * The authors do not show the results for \"rolling out in training\" as the primary baseline in the main text (it is instead presented as ablation studies in section C.5). However, it is well established (authors even include references supporting this) that this is the correct way of training autoregressive models. Indeed, the proposed ACDM does not have better performance compared to the models trained with such multi-step loss. Considering the significantly higher inference cost, it is hard to justify the value of the proposed method. The authors mentioned \"more hyperparameters\" and \"higher training cost\" as counter-arguments, but I do not think the former is a valid reason at all, and the latter is both weak and not supported by numbers comparison.\n* In the attached videos for the isotropic turbulence \"posterior_iso_samples_vort.mp4\", the samples showed visible flickering, i.e. some small-scaled features present in one frame noticeably go missing in the next. This seems to suggest that the conditioning scheme adopted may not lead to sufficient coherence between conditioned and sampled parts ($d$ and $c$). This is not reflected in any of the metrics presented.\n\nThese weaknesses are fundamental enough for me to not recommend a passing score."
            },
            "questions": {
                "value": "* It would be helpful to define LSiM somewhere besides including the reference.\n* Figure 4 is missing labels - which plots correspond to which test example?\n* I wasn't able to find spatial frequency analysis for the isotropic turbulence example? The rollouts look a bit smoother compared to the ground truth visually.\n* Appendix C.5 summary - what do you mean by \"significantly reducing the complexity of the learning task, instead of fundamentally increasing the models generalization ability\"? I cannot connect this statement with what is entailed by training rollouts beyond single step\n* Appendix C.6 Table 5 - the \"n1e-x\" subscripts looked really cryptic to me initially. Maybe just create a separate column to indicate the noise level?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission216/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission216/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission216/Reviewer_ySpT"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission216/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698466289973,
        "cdate": 1698466289973,
        "tmdate": 1699635946995,
        "mdate": 1699635946995,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PZ125dvbc6",
        "forum": "1hhja8ZxcP",
        "replyto": "1hhja8ZxcP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission216/Reviewer_wsiC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission216/Reviewer_wsiC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to apply conditional diffusion models to turbulence flow simulations. It demonstrates that diffusing the conditional inputs (i.e. the initial conditions of the simulation) aids performance as opposed to using the \"clean\" conditions for all diffusion steps.\nThe authors show that the resulting diffusion model attains good sample diversity and physical consistency, albeit at the expense of slower inference speed. It can also serve as an effective method for stabilizing long inference rollouts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Overall, I enjoyed reading this paper but think that switching the focus away from the conditional diffusion model (given the limited novelty and its limitations, see Weaknesses section) to a more general focus on comparing various approaches for data-driven physics simulations could be helpful to the reader so that the authors can focus on candidly analyzing and comparing the different methods, for which the current paper already provides a lot of interesting and valuable content. This is especially so given that the authors have had to come up with their own adaptations to use some interesting baselines such as the TF_VAE. Even if they don't perform well, it is very valuable to discuss them, as is done in this paper.\n\nList of strengths:\n- Diffusing/noising the conditional inputs is shown to be an effective way of improving the performance of the diffusion model. Albeit this is a small and simple design choice, it is not obvious, and it is good to have it documented for interested practitioners.\n- Several interesting observations and analyses are given in this paper, both regarding the proposed diffusion model and some of the baselines. For example, I enjoyed reading about the ablation of the number of diffusion steps and the training rollout and noise, as well as the shortcomings of the transformer-VAE.\n- Data-driven models for probabilistic physics simulation is an important and somewhat underexplored field, albeit see the weaknesses below for relevant related work that goes a bit beyond this work."
            },
            "weaknesses": {
                "value": "- The proposed autoregressive conditional diffusion model (ACDM) is a direct application of common diffusion models to turbulence simulation data. That is, except for proposing to diffuse the conditional inputs there are no methodological contributions.\n- Alternative methods to ACDM achieve comparable or even better benefits in terms of accuracy and rollout stability. In the paper, this is notably shown through the U-Net trained on multiple steps (i.e. m>2) or the U-Net where noise is injected into the training batches. This makes me uneasy when reading the abstract that claims *\"We show that this approach offers clear advantages in terms of rollout\nstability compared to other learned baselines\"*.\n- ACDM is extremely slow at inference time compared to the baselines (20x-100x slower almost). This is to be expected given that the baselines are single-forward pass models, but it should be made more clear by the authors when discussing the (dis-)advantages of the different baselines. E.g. in the last paragraph of the discussion and the summaries in the appendix, it is not fair to mention the disadvantages of the multi-step or training-noise U-Net baselines without noting the inference speed issue of ACDM. Especially for the training-noise baseline, I don't see any disadvantages compared to ACDM (except for potentially lower posterior sample quality. But this has not been shown here).\n- A recent work [1] already goes beyond this paper by adapting diffusion models to the same problem setting, lessening the inference speed issue of this paper, and addressing multiple of the outlooks/future work points given in the last paragraph of this paper. While it can be deemed as contemporaneous work, at least, it should be discussed in this paper. Of course, a direct comparison would be optimal, especially since the multi-step U-Net which performs similarly to ACDM in this paper is a baseline that is beaten by the method from [1].\n- It seems to me that some key hyperparameters unnecessarily deviate between ACMD and some baselines. This makes the significance of the results less clear. Notably, 1) ACDM uses two past timesteps as input (k=2), but many baselines only use one (k=1); 2) ACDM is trained with the Huber loss (which is a non-standard choice for diffusion models!) but all baselines use the MSE loss; 3) Number of training epochs varies wildly between models (e.g. 3100 for ACDM vs 1000 U-Net on Inc and Tra datasets). To me, these points seem very important to fix or require some explanation at least.\n- It is possible to sample multiple predictions from (most of) the baselines by perturbing the inputs. This is an important baseline to have for ACDM, and much more straightforward than the transformer-VAE idea. This should be tried at least for the training-noise U-Net (just keep the same variance for noising inference inputs).\n- It would be good to use benchmark datasets rather than creating new ones for the paper. E.g. see [2] which is used by [1] too, or [3]. This would make comparisons so much easier! Given the effort already spent on the current datasets of the paper (e.g. >5 days for some), will you open-source them?\n- ACDM introduces multiple new hyperparameters (e.g. R, diffusion schedule, etc.), so I would advise to not claim that introducing new hyperparameters is a problem of the baselines (e.g. last paragraph of the discussion), especially when said baselines are only introducing a single new HP.\n- I would advise toning down *\"Unlike the original DDPM, we achieve high-quality samples with as little as R = 20 diffusion\nsteps. We believe this stems from our strongly conditioned setting\"* a bit, given that you show that for some problems you need much more diffusion steps (e.g larger R seem to aid performance on the Iso dataset and it may not saturate at the largest R=500 that you tried, which also has the best LSiM).\n- The titles of the subplots in Fig. 4 are missing, so it is hard/impossible to tell what results correspond to which dataset.\n- Discussion of Fig. 6 in the main text should mention that some baselines perform very similarly, I think, on the frequency analysis (shown in Fig. 13 in the appendix)\n\n[1] Cachay, S.R., Zhao, B., James, H. and Yu, R., 2023. \"DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting\", NeurIPS\n\n[2] Otness, K., Gjoka, A., Bruna, J., Panozzo, D., Peherstorfer, B., Schneider, T. and Zorin, D., 2021. \"An extensible benchmark suite for learning to simulate physical systems\", NeurIPS Track on Datasets\n\n[3] Takamoto, M., Praditia, T., Leiteritz, R., MacKinlay, D., Alesiani, F., Pfl\u00fcger, D. and Niepert, M., 2022. \"PDEBench: An extensive benchmark for scientific machine learning\", NeurIPS"
            },
            "questions": {
                "value": "- Why not use CRPS as a metric for your probabilistic methods?\n- Do you use k=2 for all U-Net models?\n- In your figures showing multiple samples (e.g. Fig 5): Why is the third row separate from the first two? Why is the timestep not ordered by rows?\n- The hidden spaces of 56 (but even 112) for the FNO, and L=32 for the transformer models, seem pretty low to me?\n- How many diffusion steps do you train with?\n- Do you always use 5 samples from the probabilistic methods? \n- Why do you change your transformer adaptations TF_enc and TF_VAE in terms of encoder/decoder and residual prediction or not compared to TF_MGN?\n- Table 3 in the appendix: Can you please run the dashed variants? If not, why? ACDM_R10 on Iso seems like an especially interesting run to try to me.\n- What do you mean by *\"However, this is achieved by significantly reducing the complexity of the learning task, instead of fundamentally increasing the models generalization ability.\"*\n- Table 5 in the appendix: Any intuition on why perturbing the inputs with 1e-3 performs so badly? I would have expected a more or less smooth transition from 1e-2 -> 1e-3 -> 1e-4. Is there a bug maybe?\n- Can you provide visualizations of the multi-step and training-noise baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission216/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698796476123,
        "cdate": 1698796476123,
        "tmdate": 1699635946874,
        "mdate": 1699635946874,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mZVXucqilj",
        "forum": "1hhja8ZxcP",
        "replyto": "1hhja8ZxcP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission216/Reviewer_JT77"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission216/Reviewer_JT77"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes autoregressive conditional diffusion models (ACDMs) to simulate turbulent flow systems in an autoregressive rollout fashion. The model shows stability on long rollout horizon simulation. The proposed ACDM is further demonstrated to generate posterior samples that align closely with genuine physical dynamics in different fluid dynamics datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is well-written, and the presentation is clear. The related works are well examined, encompassing the key areas of interest regarding the use of conditional diffusion models for turbulent flow simulation, and the paper is correctly placed in the current literature. The proposed approach is straightforward and the authors provide several experiments (alongside well-appreciated source code) that make evaluation robust."
            },
            "weaknesses": {
                "value": "- The novelty is not much - the idea is almost a direct application of conditional diffusion models in autoregressive settings.\n- The inherent resolution at which a diffusion model generalizes is predefined during its training. This set resolution potentially restricts the model's flexibility, thereby impacting its practical utility and adaptability in diverse applications.\n- As depicted in Table 2, the enhancement in accuracy across the five datasets is marginal, with ACDM outperforming other models only on two datasets in terms of LSiM error. Moreover, it is unclear what is generally the best model from this result, given that except FNO, all models seem to obtain at least one best result across datasets.\n- Despite its acknowledgment of the limitations, the substantial computational cost of ACDM considerably undermines its practical utility. As state, the model can generate a solution in ~0.2 seconds; with 1000 time steps, this sums up to more than 3 minutes for a single trajectory against ~11 seconds for UNet. Therefore, it is hard to assess the Pareto-efficiency of the proposed method.\n- The organization of the paper would benefit from distinguishing between the preliminary and methodology sections; Section 3 is a mix of both and as such it is hard to distinguish the real contribution.\n- It would be useful to assess the performance on different datasets, such as from PDEBench [1], particularly in the 3D cases.\n- Stronger baselines could be chosen. For instance, graph neural networks have shown good performance in fluid dynamics such as [2]. Moreover, FNO variants such as AFNO have been shown to be powerful in large-scale real datasets [3].\n- [Minor] The explanation for Figure 4 is unclear. It appears that each subfigure lacks a title indicating the respective dataset name.\n\n---\n\n\n[1 ]Takamoto, Makoto, et al. \"PDEBench: An extensive benchmark for scientific machine learning.\" NeurIPS (2022).\n[2] Li, Zongyi, et al. \"Fourier neural operator with learned deformations for pdes on general geometries.\" arXiv preprint arXiv:2207.05209 (2022).\n[3]  Pathak, Jaideep, et al. \"Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators.\" arXiv preprint arXiv:2202.11214 (2022)."
            },
            "questions": {
                "value": "1. When the time step between two rollout steps is set to a fixed interval, how can we accurately capture the dynamics between these designated rollout steps?\n2. How would the model perform with real, possibly noisy data, such as the Black Sea and ScalarFlow datasets as in [1]?\n3. This is an additional question that does not influence the score (since the paper should be considered as \"concurrent work\"). How do you think your proposed model would fare against [2]?\n\n---\n\n[1 ] Lienen, Marten, and Stephan G\u00fcnnemann. \"Learning the dynamics of physical systems from sparse observations with finite element networks.\" ICLR 2022.\n[2] Lippe, Phillip, et al. \"Pde-refiner: Achieving accurate long rollouts with neural pde solvers.\" NeurIPS (2023)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission216/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835807588,
        "cdate": 1698835807588,
        "tmdate": 1699635946808,
        "mdate": 1699635946808,
        "license": "CC BY 4.0",
        "version": 2
    }
]