[
    {
        "id": "DNuSDSQ7Ai",
        "forum": "mnHpxTxnYg",
        "replyto": "mnHpxTxnYg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_rp3W"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_rp3W"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes black-box membership inference attacks against generative adversarial networks. It assumes that the attacker has access to the generated samples and the real distribution. The first attack is to train a classifier between the generated samples and the real samples and detect training samples if the predicted probability of being generated samples is larger than a threshold. The second attack detects training samples if the (relative) distance to generated samples is closer than a threshold. Experiments are conducted on an image dataset and a genomics dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* Overall, the paper is well-written in terms of clarity."
            },
            "weaknesses": {
                "value": "* The proposed methods lack novelty. Some of the key methods have already been proposed in prior work published 3 years ago.\n\n* The experiment results are not convincing enough.\n\n\nPlease see 'Questions' section for the details."
            },
            "questions": {
                "value": "The discussion of related work:\n* The introduction claims that \"Most existing work probing the privacy properties of GANs has typically focused on the \"white-box\" setting, where an adversary has access to the discriminator of the GAN, and is able to use standard techniques to conduct membership inference attacks based on the loss Chen et al. (2020); a notable exception is van Breugel et al. (2023a).\" However, black-box attacks have already been proposed in LOGAN (Hayes et al. 2018) and GAN-leaks (Chen et al. 2020).\n\nNovelty of the proposed approach:\nThe main approaches are almost the same as prior work published 3 years ago. In particular,\n* The proposed detector-based attack is the same as case 1 of the discriminative setting in Section 4.4 of LOGAN (Hayes et al. 2018).\n* The proposed one-way distance-based attack is the same as Section 5.2 of GAN-leaks (Chen et al. 2020)\n* The proposed two-way distance-based attack is the same as Section 5.2 + Section 5.6 of GAN-leaks (Chen et al. 2020).\nPlease correct me in the rebuttal if I misunderstood it.\n\nConcerns about the experiment results:\n* Many plots in Figure 1 and Figure 2 show that the proposed approaches can perform worse than random guesses in some settings (e.g., Figure 1a, 1b, 1d, 1e, 1f, 1g, 1j, 1k). Do you have explanations for that?\n* It claims that \"... ADIS consistently outperforms the Detector ...\". This is not the case in Figure 1j.\n* Because many of the lines in Figure 1 and 2 have significant overlap and the rankings of the methods are not consistent across the entire range of FPR, it would be more convincing to conduct the experiments multiple times and report the average and std of the scores.  \n\nOther minor issues:\n* Section 3: \"Generative Adversarial Network(GANs)\" should be \"Generative Adversarial Network (GANs)\"\n* Section 3: \"X_T ~ P\" should be \"X_T ~ P^n\" where n is the number of training samples.\n* Section 4.2: When expressing the generator reconstruction loss, the condition of R_L is mixed with G and X_G in different places. Please make the notation consistent.\n* Section 4.2: remove the extra period in the section title.\n* Figure 7a-7f: I doubt if we can conclude from these figures that the two point sets are close. Firstly, since only one viewpoint of the 3D plots is visualized,  it is impossible to know the exact location of each point. Moreover, in Figures 7b and 7d, most points from the \"real genome\" are not visible as they are covered by the points from the \"synthetic genome\".\n* Section 5.1: \"those results here .\" should be \"those results here.\"\n* Section 6: BigGAn should be BigGAN."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6837/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742164505,
        "cdate": 1698742164505,
        "tmdate": 1699636791523,
        "mdate": 1699636791523,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5V7OGA1CaY",
        "forum": "mnHpxTxnYg",
        "replyto": "mnHpxTxnYg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_bnwi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_bnwi"
        ],
        "content": {
            "summary": {
                "value": "This paper studies membership inference attacks against GAN in the black-box setting, where the adversary only has access to the generated synthetic data. The authors propose to leverage a detector trained to distinguish synthetic data from real data to predict membership. The efficacy of the proposed attack is empirically demonstrated on two genomic datasets and one image dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Membership inference attack against synthetic data is an underexplored but important research topic that has direct real-world applications, such as auditing private dataset release in the medical domain.\n\n- Connecting the distinguishability between GAN-generated samples and real samples to the distinguishability between member samples and non-member samples is a good insight.\n\n- The work evaluates privacy leakage by measuring TPRs at low FPRs, following Carlini et al., which is a very realistic setting.\n\n- Besides standard image datasets, the experiments considered genomic datasets which have direct privacy implications."
            },
            "weaknesses": {
                "value": "- The attack assumes that the adversary can get fresh samples from the same distribution as the underlying private data. However, it is unclear whether such an assumption is reasonable in practice.\n\n- Related to the above point, in real-world settings, oftentimes the adversary may only be able to get data samples from a slightly different distribution (e.g., to attack synthetic data released from one hospital, the adversary can only access data from another hospital). It is unclear how the proposed attack would perform under such distributional shifts. Some empirical results on this would be nice to have.\n\n- The performance improvements of the proposed methods aren\u2019t very significant compared to distance-based attacks and are not consistent across different settings. In many cases, distance-based attacks remain a very strong baseline (e.g., Fig1agij). In addition, the performance of the proposed attack seems to be very sensitive to the choice of architecture and dataset.\n\n- The crux of the proposed attack is the connection between inferring G vs. P and inferring T vs. P, which is justified by Theorem 1. However, the proof is based on an oversimplified assumption that G is a linear mixture of P and T and thus does not generalize.\n\n- The paper could benefit from a further round of proofreading to fix typos (e.g., that to random points -> than to, we trained average -> we average). Also, some notations in the Appendix are not consistent with the main paper (e.g., G = \u03b2P + (1 \u2212 \u03b2)T -> G = \u03b2T + (1 \u2212 \u03b2)D).\n\n- In Theorem 1, it seems that beta should be in (0, 1) instead of [0, 1].\n\n- In the proof of Lemma A.1, E_G[f(x)] should be 2TPR_M(f). Also, in the proof the Lipschitz constant is on the denominator which is not consistent with Eq. 1."
            },
            "questions": {
                "value": "1. How does the mode-collapse phenomenon of GAN motivate expressing G as a mixture of T and P?\n\n2. How would the proposed attack perform if P is shifted from T?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6837/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6837/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6837/Reviewer_bnwi"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6837/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812360831,
        "cdate": 1698812360831,
        "tmdate": 1699636791390,
        "mdate": 1699636791390,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jtpaSAH9zV",
        "forum": "mnHpxTxnYg",
        "replyto": "mnHpxTxnYg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_zbzo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_zbzo"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the privacy protection provided by data synthesis methods based on generative adversarial networks (GANs). More precisely, new of set of membership inference attacks (MIAs) is proposed that only assume a black-box access to synthetic samples produced by the generative model. These attacks are compared to existing state-of-the-art approaches on a thorough set of experiments and the results obtained demonstrate that they outperform previous methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The introduction clearly reviews the state-of-the-art of MIAs against synthetic data and the challenges associated with such attacks. \n\nOne of the main contribution of the paper is the proposition of two novel MIAs, one based on training a detector to differentiate between training examples and examples coming from the distribution and the other based on the difference of distance between a particular sample to other synthetic samples as well as to reference samples. Both attacks are well motivated theoretically.  \n\nExperiments have been conducted on genomic data with two different GAN-based synthetic data generations as well as by comparing to a diverse set of existing state-of-the-art MIAs. The results obtained clearly demonstrate that the proposed attacks outperform previous MIAs. In addition, the results obtained with ADIS demonstrate that augmenting the feature space with distance-based characteristics increases significantly the success of the attacks. \n\nAdditional experiments were also conducted on image dataset with a wide range of GAN-based approaches.  The results obtained while significantly different than for genomic data also demonstrate the efficiency of the proposed attacks."
            },
            "weaknesses": {
                "value": "The writing of the paper is ok but could be improved (see for instance below for a few typos). \n\nOverall, while the experiments conducted are very thorough, they should be complemented with at least one differentially-private data synthesis approach to assess in particular if such protection mechanism would impact the success of MIAs in a similar manner.\n\nA few typos/remarks :\n-\u00ab\u00a0why detectors can be approximately optimal membership inference attacks\u00a0\u00bb -> \u00ab\u00a0why detectors are approximate optimal membership inference attacks\n-The following reference is repeated twice : Boris van Breugel, Hao Sun, Zhaozhi Qian, and Mihaela van der Schaar. Membership inference attacks against synthetic data through overfitting detection, 2023b.\n-\u00ab\u00a0Rather than train\u00a0\u00bb -> \u00ab\u00a0Rather than training\u00a0\u00bb\n-\u00ab\u00a0Absent any additional information\u00a0\u00bb -> \u00ab\u00a0In the absence of any additional information\u00a0\u00bb\n-\u00ab\u00a0hamming\u00a0\u00bb -> \u00ab\u00a0Hamming\u00a0\u00bb\n-\u00ab\u00a0requires a further choice of distance metric\u00a0\u00bb -> \u00ab\u00a0requires further a choice of a distance metric\u00a0\u00bb\n-\u00ab\u00a0we only report those results here .\u00a0\u00bb -> \u00ab\u00a0we only report those results here.\u00a0\u00bb\n-\u00ab\u00a0features improved attack success\u00a0\u00bb -> \u00ab\u00a0features mproves the attack success\u00a0\u00bb\n-The following sentence is not complete : \u00ab\u00a0computation of reconstruction losses ??\u00a0\u00bb"
            },
            "questions": {
                "value": "The main question that I have is with respect on how protection measure such as differential privacy would impact the conclusions drawn from the experiments. It would be good if the authors could do additional experiments to evaluate this issue."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6837/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824447085,
        "cdate": 1698824447085,
        "tmdate": 1699636791272,
        "mdate": 1699636791272,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UvBRUvvhN6",
        "forum": "mnHpxTxnYg",
        "replyto": "mnHpxTxnYg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_QeZK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6837/Reviewer_QeZK"
        ],
        "content": {
            "summary": {
                "value": "The authors present several novel black box membership inference attacks against GANs. These attacks broadly fall under two buckets: i) Detector based (classifier based), ii) Distance based. The authors evaluate these attacks on several datasets and compare them with each other as well as comparable algorithms from other papers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The problem of black-box membership inference attacks against GANs is an interesting one. It is also probably the most practical and understudied form of membership inference attacks against GANs. \n2) The algorithms presented in the paper seem novel and advance the state of the art. \n3) The empirical evaluations of the algorithms are very reasonable and I particularly liked the choice of metrics."
            },
            "weaknesses": {
                "value": "1) The authors do not cite several relevant papers which have looked at black box membership inference attacks e.g. [1,2]\n2) Please include a more detailed explanation of the ADIS attack in the main paper since it is a novel contribution of this paper and has been used in the experiments.\n3) Figure 3 is cited in the main paper but is not a part of the main paper. Please at mention clearly that the figure is a part of the appendix and try to write the paper such that the appendix is purely optional reading. \n4) In theorem 4.1, why is it reasonable to assume that G is a convex combination of P and T? Please clarify/explain in the paper. \n5) In section 5.1, explain how the different train/test set sizes were chosen. Seems a little arbitrary. \n\n\n\n[1] Mukherjee, Sumit, et al. \"privGAN: Protecting GANs from membership inference attacks at low cost to utility.\" Proc. Priv. Enhancing Technol. 2021.3 (2021): 142-163.\n[2] Xu, Yixi, et al. \"Mace: A flexible framework for membership privacy estimation in generative models.\" arXiv preprint arXiv:2009.05683 (2020)."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6837/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698987435481,
        "cdate": 1698987435481,
        "tmdate": 1699636791157,
        "mdate": 1699636791157,
        "license": "CC BY 4.0",
        "version": 2
    }
]