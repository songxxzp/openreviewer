[
    {
        "id": "yLn1HYFw0a",
        "forum": "WO4BCqEyWc",
        "replyto": "WO4BCqEyWc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_Fj5t"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_Fj5t"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of recent self-supervised learning methods that they learn to be invariant to data augmentations, which may be harmful for some downstream tasks. To tackle this problem, this paper proposes to modify the projector by feeding the information about data augmentations together with the encoder outputs. Experimental results show the effectiveness of the proposed method in transfer learning on image datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Learning augmentation-aware representations is a timely topic.\n\n- The proposed idea is simple and ablation studies show how the design choices are made well."
            },
            "weaknesses": {
                "value": "- [Garrido et al.] would be one of the most recent work among prior works but missed in this paper.\n\n- The proposed method simply provides the additional information about augmentations together with the encoder outputs, and it is not clear how it helps to \"preserve more information about augmentations\" in representations. Figure 3 shows that injecting information of random augmentations results in reduced cosine similarities. This implies that the projector relies on the given information about augmentations, which is not directly related to the learned representations (the output of the encoder), i.e., learned representations do not have to be changed regardless of whether the projector relies on the additional information about augmentations or not. Any theoretical justification on the effect of the proposed method to the learned representations would be welcome.\n\n- The performance gain is overall minor and often it underperforms previous methods.\n\n- Why does MoCo-v2 in Table 1 contain only one performance of LooC? It looks quite not informative.\n\n- Why does MoCo-v3 in Table 1 miss the performance of \"AI by [Chavhan et al.],\" while the original paper presents its performance?\n\n- The reference section requires thorough proofreading, as there are many incomplete/inaccurate references. For example, the closest prior work by [Lee et al.] is published in NeurIPS'21, but its arXiv version is cited. Also, many references miss the name of the published venue.\n\n[Chavhan et al.] Amortised invariance learning for contrastive self-supervision. In ICLR, 2023.\n\n[Garrido et al.] Self-supervised learning of Split Invariant Equivariant representations. In ICML, 2023."
            },
            "questions": {
                "value": "Please address concerns in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3997/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698768575373,
        "cdate": 1698768575373,
        "tmdate": 1699636361897,
        "mdate": 1699636361897,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fyasPgwZjl",
        "forum": "WO4BCqEyWc",
        "replyto": "WO4BCqEyWc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_ad4G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_ad4G"
        ],
        "content": {
            "summary": {
                "value": "Self-supervised methods are known to learn representations invariant to augmentations applied during training. This can be problematic when features of such augmentations are important for downstream tasks. This work considers the important task of performing self-supervised learning without losing important semantic features in the data. To achieve this, CASSLE is proposed, a method which conditions the learned projection head on the augmentations of each view. The work demonstrates that this results in features which are still augmentation-aware."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The manuscript is well written and experiments are well picked to test the purported claims regarding sensitivity of learned features to augmentations applied during training.\n* CASSLE is simple and has demonstrated efficacy when training augmentation-based contrastive models. When compared to other methods that condition on augmentations applied during training, table 1 shows that CASSLE has superior performance across many datasets."
            },
            "weaknesses": {
                "value": "* Based on Table 7, the proposed method seems to less effective for SimSiam and BYOL compared to InfoNCE based methods. The manuscript currently claims that CASSLE is applicable to all joint-embedding architectures, but the current experimental results do not demonstrate this.\n* The experiments in 4.2 use the InfoNCE to evaluate augmentation-awareness, which is sensitive to the negative examples that are used. Instead of this, why not perform linear probing to predict the specific augmentation applied to an image? This would be a more direct measure of the augmentation-awareness.\n* The work does not address the large body of work surrounding \u201cfeature suppression\u201d, an important issue of contrastive models becoming invariant to features important for downstream tasks. I believe the work can be strengthened by including comparisons to methods proposed to address feature suppression [2], as well as evaluation on some feature suppression benchmarks [1].\n* Current experiments do not demonstrate the effectiveness of CASSLE with augmentation-free approaches to self-supervised learning. This limits the modalities in which it can be applied to those where augmentations can be selected a priori. \n\nMinor:\n* For Table 1, and other similar tables, could the authors add a column denoting mean improvement, taken over datasets, over the vanilla baseline to more easily compare each of the methods to CASSLE? It does not have to specifically be an additional column, but it would be nice to have an aggregate metric of performance in comparison to the baseline. \n* Some of the citations should be updated to include the full Author name (E.g., MoCo and SimSiam citations)\n\n\n[1] \"Intriguing Properties of Contrastive Losses,\u201d Chen et al., 2021\n\n[2] \u201cCan contrastive learning avoid shortcut solutions?,\u201d Robinson et al., 2021."
            },
            "questions": {
                "value": "* How does CASSLE relate to feature suppression [1] and shortcut solutions [2] in contrastive learning?\n* Table 4 indicates that many of the methods were trained with a batch size of 256. Can the authors clarify why this was set so low? In the SimCLR paper it is shown that contrastive methods perform much worse when trained with a smaller batch size. Does CASSLE scale to larger batch sizes? Does CASSLE still perform well with a large batch size?\n* Can CASSLE be applied to masked self-supervision? There seems to be a connection between CASSLE and the MAE, where the latter conditions on mask tokens to reconstruct masked patches.\n* Have the authors tried performing feature inversion like in [3]? It would be interesting to see if CASSLE results in inverted features that are more reconstructive of attributes like color compared to vanilla contrastive features.\n\n\n[1] \"Intriguing Properties of Contrastive Losses,\u201d Chen et al., 2021\n\n[2] \u201cCan contrastive learning avoid shortcut solutions?,\u201d Robinson et al., 2021.\n\n[3] \u201cWhat makes instance discrimination good for transfer learning?,\u201d Zhao et al., 2021."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Reviewer_ad4G"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3997/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797973614,
        "cdate": 1698797973614,
        "tmdate": 1700434992855,
        "mdate": 1700434992855,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2x26PcprSF",
        "forum": "WO4BCqEyWc",
        "replyto": "WO4BCqEyWc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_N37y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_N37y"
        ],
        "content": {
            "summary": {
                "value": "State-of-the-art approaches to self-supervised representation learning (SSL) optimize invariance-inducing objectives of representations to augmented views of an input observation, while preventing their collapse to a trivial solution. Effective optimization of these objectives reasonably results to information loss about the features excited by the augmentations in the representation space. These features, however, could be useful to maintain for some downstream prediction (potentially transfer learning) tasks. While the projector network is a common feature of these methods which mitigates this effect, the invariance still persists. The authors propose a simple intervention to typical SSL pipelines in order to further mitigate this effect: ***they suggest to condition the projector network with information about the particular augmentation used to derive a view of an observation***. Experiments on downstream transfer learning tasks with pretrained networks demonstrate an improvement in performance compared to baseline methods, targeted at the same issue. Analysis of representations and the projector demonstrate that augmentation information is indeed used and the method leads to more sensitivity to the variations induced by augmentations in earlier activations of the pretrained network. They also provide with ablation analyses of various implementation design choices."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The identified problem is known and significant for representation learning. The authors discuss fairly well the related literature and approaches to its solution.\n2. The idea is fairly novel, there have been some similar approaches that essentially \u201ccondition the projector network\u201d. Please, refer to Question 1.\n3. Nonetheless, their results generally convince that the detail is in the implementation level, rather than the conceptual.\n4. The paper is well-written and well-argumented.\n\nOverall, the paper convinces that conditioning the projector with augmentation information is a good direction towards creating more potent and transferable representations."
            },
            "weaknesses": {
                "value": "1. Experiments remain relatively small-scale in dataset and model size. Especially, it would have been interesting to examine the effect of conditioning as pretraining data becomes abundant.\n2. CASSLE performs better (compared to AugSelf) for contrastive methods and BarlowTwins than others, i.e. BYOL and SimSiam. A discussion on why this happens can be interesting.\n3. Semi-supervised (few-shot classification) results are competitive, but weaker.\n4. Experiments on object detection task demonstrate a marginal improvement.\n\n5. The paper does not report confidence intervals of their results.\n6. Citation and bibliography style needs serious editing. Sometimes \u201cet al.\u201d is retained in bibliography, journals/conferences/proceedings are frequently missing and style is generally inconsistent."
            },
            "questions": {
                "value": "1. Missing relevant approach to CASSLE is [1]. They provide with a method which can be perceived as a kind of conditioning to augmentation information.\n2. In *Related Work*, contrastive learning objectives usually refer to methods which prevent representational collapse by contrasting against negative pairs. Please clarify this distinction.\n3. In *Section 4.2*, an analysis of activation invariance is presented based on the InfoNCE loss. Which similarity function was used to compare earlier representations?\n4. In *Table 3*, how is the rank computed exactly?\n\n[1] Bhardwaj, Sangnie, et al. \"Steerable equivariant representation learning.\" arXiv preprint arXiv:2302.11349 (2023)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3997/Reviewer_N37y"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3997/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698815905710,
        "cdate": 1698815905710,
        "tmdate": 1699636361671,
        "mdate": 1699636361671,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Kxbr4bl8HO",
        "forum": "WO4BCqEyWc",
        "replyto": "WO4BCqEyWc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_hzhB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3997/Reviewer_hzhB"
        ],
        "content": {
            "summary": {
                "value": "Many self-supervised learning methods aim to learn augmentation-invariant representations. Such an approach could be harmful when a downstream task is sensitive to augmentation-aware information. To overcome this limitation of existing SSL methods, this paper proposes a simple yet effective approach that injects augmentation information (i.e., augmentation parameters) into the projection MLP used in the SSL framework. The approach shows superior performance over existing augmentation-aware information learning methods on ImageNet-100 experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper is generally well-written. It is easy to understand.\n- The idea is simple, intuitive, and seems to be widely applicable.\n- The proposed method, CASSLE, outperforms baselines (LooC, AugSelf, and AI) that also learn augmentation-aware information."
            },
            "weaknesses": {
                "value": "**(1) Lack of comparison with recent augmentation-free SSL methods.** \\\nRecently, there have been proposed many augmentation-free self-supervised learning methods, including data2vec [1-2], I-JEPA [3], and Masked Image Modeling (MIM) [4-5]. The augmentation-free SSL methods do not use augmentation, in other words, they aim to learn full information about original images, rather than learning augmentation-invariant representations. Also, since they are often better than MoCo-v2 and SimCLR in various benchmarks (e.g., linear evaluation, fine-tuning, scalability), the authors should compare the proposed method with the methods.\n\n[1] Baevski et al., data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language, ICML 2022 \\\n[2] Baevski et al., Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language, 2022 \\\n[3] Assran et al., Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture, ICCV 2023 \\\n[4] He et al., Masked Autoencoders Are Scalable Vision Learners, CVPR 2022 \\\n[5] Xie et al., SimMIM: a Simple Framework for Masked Image Modeling, CVPR 2022\n\n**(2) Experimental results are not convincing.** \\\nThe performance improvement of CASSLE over AugSelf is marginal.\n\n**(3) Lack of novelty.** \\\nI feel that the proposed method is neither novel nor interesting. First, the goal of this paper has been widely studied via augmentation-aware objectives (e.g., AugSelf) and augmentation-free SSL methods (e.g., I-JEPA). Also, it is hard to find a strong advantage of the proposed idea compared to AugSelf. In my opinion, the choice between injection and prediction cannot make meaningful novelty."
            },
            "questions": {
                "value": "Can the proposed method be applied to generative modeling like GAN training? It is worth noting that the main baseline, AugSelf, can be utilized for efficient GAN training [1].\n\n[1] Hou et al., Augmentation-Aware Self-Supervision for Data-Efficient GAN Training, NeurIPS 2023"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3997/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839957503,
        "cdate": 1698839957503,
        "tmdate": 1699636361574,
        "mdate": 1699636361574,
        "license": "CC BY 4.0",
        "version": 2
    }
]