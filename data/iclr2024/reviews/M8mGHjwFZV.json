[
    {
        "id": "mmKErHemSr",
        "forum": "M8mGHjwFZV",
        "replyto": "M8mGHjwFZV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_xG3Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_xG3Y"
        ],
        "content": {
            "summary": {
                "value": "The authors study the problem of optimizing a deep neural network without explicitly computing the gradient through backpropagation. This means that the gradient needs to be guessed. The main idea of the paper is that the gradients lie in a subspace that is lower than the size of the model, so the gradients should be guessed in this subspace. The authors show empirically that the gradient guesses obtained through this method are closer to the true gradient than previous methods, but they are biased estimators. They show that the performance of their methods improves with respect to previous methods, but it is still quite lower than using backprop. They argue that this is due to the bias in the gradient estimates and provide empirical evidence in support. Surprisingly, the authors also benchmark their method on the MLP mixer, and they obtain better performances than if they train with backprop.\n\nI lean toward rejection because [I elaborate on these three points in the Weaknesses section]:\n\n(P)resentation. The English is good and the paper starts well, but the presentation gets progressively poor and hard to follow. Especially toward the second part of the paper, there are disconnected paragraphs which it is hard to reconnect to the global story. Although the proposed concepts are not particularly hard, it takes more effort than necessary to understand how experiments are performed, and which evidence leads to what. Further, figures and tables could be much clearer than at the current state. \n\n(S)oundness. Much of the told story is based on reasonable arguments, confirmed by empirical evidence. Since the empirical evidence is the basis of the paper's message, it should be better substantiated than it currently is. This goes along with the presentation, which makes it hard to understand how experiments were performed (e.g. it seems that no hyperparameter tuning was done, and that the evidence is based on single runs), and therefore to understand whether the methodologies are sound. The MLP-mixer runs contain a strong message, and yet nothing is provided to make this evidence strong.\n\n(C)ontribution. A main selling point of the paper is not developed. This is, the good performance on the MLP mixer is just flashed and no attempt is done at analyzing it. This analysis is needed to make this finding consistent, and it would shed light on the argument presented by the authors, stating that it is the bias on the gradient that leads to low performances."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "STRENGTHS\n- The main idea of the paper, of reducing the dimensionality of the guessing space, is worth exploring. Although the results are not good nor fast nor general enough to replace backprop, it is still a step forward.\n\n- The gradient guesses are much more aligned to the true gradient than previous methods. This is an improvement with respect to previous methods.\n\n- Benchmarks on the MLP mixer show that in that case guessing the gradients is actually better than performing backprop. This is potentially very impactful, since it shows a (large-scale) case in which gradientless optimization matches backprop.\n\n- The authors argue that one can solve the lower performance problem by eliminating the bias in the gradient guesses. Therefore, there is hope that the current limitations of the method can be overcome."
            },
            "weaknesses": {
                "value": "(HYPERPARAMETERS) Was hyperparameter (HP) tuning performed (and how? e.g. based on which metrics) for all the models or only for those of figure 7? And even then, the displayed learning curves are only on the training set: was the tuning performed on the training set? How many times was each run repeated? I see no error bars, which would lead me to think only once. Do the models have a regularizer term (I guess not, because it would influence the shape of the gradient)? Also, I think that the same HPs were used for different methods, but I believe that the comparison should be performed on the optimal choice of HPs, since likely the HPs that are good for one dynamics are not necessarily good for another.\n\n(CODE) I could not find a statement saying that the authors provide their code, and would have liked to check it (at least to answer to some implementation questions which I was not able to find an answer to in the paper).\n\n(COMPARISONS) The comparisons between methods are shown for a fixed number of steps, but the sheer number of steps is not comparable among methods. Learning curves (accuracy and loss as a function of training time) should be provided at least in the appendix. Could it be for example that the $W^T$ method would often perform better if we only let it evolve longer? \n\n(MLP-MIXER)\nThe results on the MLP mixer are surprising to me. Why is the $W^T$ method performing worse with simple models, and all of a sudden it is doing better than backprop? Can the authors convince the reader that this is not a fluke? How many times were these runs repeated? Can the authors show the learning curves and describe in full detail the model training? Also, if the authors' argument on the bias is correct, then they should see that the gradient guesses on the MLP mixer have no bias, right? Why didn't the authors study this? This result can be very nice, but at the current state it feels incomplete.\n\n(TWO-REGIMES) From figure 1, there seem to be two regimes in the dynamics. At the very beginning of learning, the cosine similarity is much higher than throughout the rest of the run. Do we have an intuition for this? Later on, when measuring the effect of the bias, the authors do it after one epoch. But this is in the initial regime where the cosine similarity is high, and not in the more interesting regime (which starts immediately after) where the cosine similarity becomes stable throughout the run.\n\n(PRESENTATION-QUALITY)\nAlthough the manuscript is written in a good English language, the presentation is not clear. The presentation starts clear, but it becomes progressively more fragmented, and it becomes very hard to follow the flow.\n\nI list a series of additional specific points on the presentation:\n- The figures and tables are scattered anywhere in the text. For example, table 2 is referenced (before table 1) in page 5 but appears in page 9; or figure 1, which is referenced after figure 2, appears on page 2 but is only referenced on page 5.\n- Instead of \"Please refer to the supplementary section\" it would be nicer to know the exact section. Same thing when referencing a figure with multiple plots (e.g. write \"fig.4-left\", instead of just \"fig.4\")\n- Y-labels are always defined, but sometimes in the caption, sometimes in the title, and sometimes on the y axis. I think that it would be nice to at least always have them on the y axis. Likewise, my understanding is that the left column of table 2 is training data, while the right column is testing data, that could be written on the tables (it's only vaguely written in the caption). If find it nice to put (ours) on the methods proposed by the authors, and would also put it elsewhere, e.g. in the table of Fig.1.\n- Fig.1 Why are the curves of $W^T$ and activation perturbation missing on the left hand side plot?\n- The black curves on many sets of figure 3 are not visible. I have to go all the way to the table on page 9 to find out that they are hidden below the bounding box. \n- The self-sharpening is introduced as an effect but then it looks like it is a method, and then there is a discussion on SVD which it is not clear whether it was used for algorithmic or only descriptive purposes. I find the overall description confusing. In general, there I found no clear place where to find the definitions of the methods (except maybe for $W^T$, but it would be nice that all the methods be described consistently with one another)\n- The math of section 2.2 is simple, but I find the way it starts very confusing. The formulas clarified the text for me - it should be the opposite. Also, when mentioning that hypotheses are made, please specifically list which hypotheses.\n- The Visual prompt-tuning experiments in the appendix come out of the blue, and the short paragraph justifying it is not clear.\n- labels are cut (fig.7) and legends require zooming a lot\n- The term \"guess\" has a technical meaning in this paper, so I would use a couple of words to define it.\n- Symbols. E.g. the usage of the $\\top$ symbol is not consistent between Eq.5 and the following paragraph (and in general throughout the text). Or when the weights W1,...,Wk, it is left to the reader to understand these are matrices corresponding to each layer, and not all the weights of the model (so k is the number of layers, and not the number of weights). Or the expectation in equation 14 is over the guesses of the gradient, which is why it does not act on $\\nabla L$.\n- The acronym JVP is defined in the appendix but used in the main paper\n- It would be much easier if the numbered list at the beginning of section 3 corresponded with a number at the beginning of each sectin where those points are treated.\n- typo: there is a period missing at the end of section 3\n- typo: \"This bias is further in the next experiments and Section 4.\"\n- typo: linear combinations OF all the training example activations in the batch\n\n(BREADTH) Although I acknowledge that it is interesting to find alternatives to backprop even though they are not at the level of the state of the art, the current findings only apply to MLP models with ReLU activations, and are only based on heuristical arguments. Additionally, these methods are much (but how much?) slower than using backprop, and significantly worse. The current method relies on specific knowledge of the architectural details, so even if it was faster and better performing than backprop, it would still probably not be implemented."
            },
            "questions": {
                "value": "- For the related literature section: that learning happens in a tiny subspace was already known since years (https://arxiv.org/abs/1812.04754). Interestingly, this subspace is even smaller than the one used by the authors, so this can perhaps be used for further improvements of the proposed method.\n- The discussion section discusses open research lines. I would add some references.\n\n- I do not understand why the first term of Eq.11 can be ignored. Unless the weights are initialized in the origin (which is usually not the case), this term should be big\n\n- Why is self sharpening only used for the W:1024 models?\n\n- I would like to see a table of how long each of these methods (including backprop) take, per gradient guess, and also how many more epochs are needed to train (we need the training curves here)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698165346213,
        "cdate": 1698165346213,
        "tmdate": 1699636445805,
        "mdate": 1699636445805,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ri444TqYAb",
        "forum": "M8mGHjwFZV",
        "replyto": "M8mGHjwFZV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_Nqba"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_Nqba"
        ],
        "content": {
            "summary": {
                "value": "In this paper, in order to guess a better gradient (with less variances), the authors unfold the backpropagation and show that the gradient can be guessed in a much lower dimensional subspace and achieves better cosine similarity compared to the directional gradient. With the better-estimated gradient, they show that they can train a model with higher accuracy without backpropagation than previous methods and extend to cifar10 results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is easy to follow and the proposed method is intuitive. In addition, the empirical results are good compared to previous baselines. The idea is simple but effective."
            },
            "weaknesses": {
                "value": "How large is the largest model? Since the paper mentioned that the proposed method makes the training model with millions of parameters feasible, can we have some of these results?\n\nCan we apply the methods to convolution networks or transformers? Is that possible or easy?"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803933378,
        "cdate": 1698803933378,
        "tmdate": 1699636445724,
        "mdate": 1699636445724,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uO4uBSrZNl",
        "forum": "M8mGHjwFZV",
        "replyto": "M8mGHjwFZV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_58v1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_58v1"
        ],
        "content": {
            "summary": {
                "value": "The authors propose several improvements over random directional derivative approaches to approximate the gradient without back-propagation.  \n\nThese are based on considering the gradient calculation and leveraging properties of the components of this gradient calculation - to reduce the variance / make better random samples for parts of approximating the gradient.  E.g., instead of randomly sampling a direction, randomly sampling part of the gradient calculation with a specific structure and plugging in the rest of the formula to estimate the gradient, and generating the random samples in a particular way, e.g., from a subspace more likely to contain the true gradient / closer to the subspace of the true gradient.\n\nThey compare the proposed methods to baselines and a prior enhanced method, and show significant improvements across many architectures and several datasets, analyze and discuss the results and take-aways in detail."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-The ideas proposed to improve gradient approximation seem novel and are interesting - I feel they could be useful and motivate other work\n\n-The ideas are well motivated and introduced, and overall the paper is well-organized and flows nicely\n\n-Extensive experiment results are provided\n\n-Good discussion and analyses is provided including limitations"
            },
            "weaknesses": {
                "value": "I feel many of these weaknesses listed below could be addressed, and I would consider raising my score in that case.\n\n\n1) No discussion of broader related work.  I.e., the authors only mention specifically work on using the directional derivatives, but there is a much broader area of work on non-gradient learning for neural networks.  It would be best to point to this other work and situate this work in context of the broader work in this area (e.g., in a small related work section for example). \n\nFor example, one work in particular that comes to mind and is similar in spirit to use random directions, is using random perturbations.  Simultaneous perturbation stochastic approximation (SPSA) has been used, but similarly to improvements in this work and others for the directional derivative approach, a likelihood ratio approach has been proposed, which generates random samples from a more appropriate distribution.  I would be very interested to see a discussion of how the current work and focus area compares to this other work (especially since this work has shown potentially better results than the directional derivative approach).\nExample papers:\n- \"A New Likelihood Ratio Method for Training Artificial Neural Networks\" https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3318847\n- \"One Forward is Enough for Neural Network Training via Likelihood Ratio Method\" https://arxiv.org/abs/2305.08960 (posted earlier in the year as \"Training Neural Networks without Backpropagation: A Deeper Dive into the Likelihood Ratio Method\")\n\nThere are also other interesting approaches, such as:\n- \"The Forward-Forward Algorithm: Some Preliminary Investigations\" https://arxiv.org/abs/2212.13345\n- \"Evolution Strategies as a Scalable Alternative to Reinforcement Learning\" (more generally evolutionary algorithms) https://arxiv.org/abs/1703.03864\n\n\n\n\n2) There are some technical issues, missing details, and incorrect or unsubstantiated statements\n\n- this line in the intro makes no sense:\n\"...and proposes addressing it by augmenting the network supervised and unsupervised loss functions located near trainable parameters.\"\nwhat are you trying to say?\n\n- This is incorrect: \"Our second insight is that by the very nature of ReLU activations, \u2202ReLU(si)/\u2202si will typically be a sparse diagonal matrix, which will \u201czero out\u201d\"\ns_i is not a matrix, but a vector - so there is no way for the gradient with respect to s_i to be a diagonal matrix.  Furthermore, for what reason should we expect this to be sparse?  It's never stated.  In my experience, this depends on a lot of factors and is not necessarily the case.\n\n- \"our third insight is that W \u22a4 often effectively has low rank. \" - this is unsubstantiated - cite a reference or explain / prove why this is the case.\n\n- What is the \"activation perturbation baseline\" - it's shown in results and mentioned as a baseline but it's never explained what it is.\n\n- The \"self-sharpening\" method is not completely / clearly described / explained\n\n- Not all method results are reported in all experiments.  It seems only a subset of method results are shown in several cases, without explanation.  \n-- In particular, the prior work being compared to should be included in more experiments, e.g., in the detailed results of Table 2.\n\n\n3) writing could be cleaned up and improved..."
            },
            "questions": {
                "value": "Please also see the questions listed in \"weaknesses\" section.\n\nTypo: \"forward-more differentiation\" in Intro\n\nWhy not combine the 3 methods?  It's not completely clear that they are separate at first reading"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698886502087,
        "cdate": 1698886502087,
        "tmdate": 1699636445630,
        "mdate": 1699636445630,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "taZ6aHBs54",
        "forum": "M8mGHjwFZV",
        "replyto": "M8mGHjwFZV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_Gf7u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4653/Reviewer_Gf7u"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the problem of guessing gradients for forward automatic differentiation or \"forward gradients\" methods.\nThe main focus is to reduce the variance of the forward gradient estimator by generating guesses that possess provably better alignment with the true gradient.\nMost of the presented improvements are agnostic to data and depend only on the network structure, except for the activation mixing method, which indeed relies on the forward propagation of data samples in the model.\nThe paper is well-written, pedagogical, and the experiments are accompanied by theoretical insights.\nOverall, this is a very interesting investigation that should be valuable to research on optimization with forward gradient methods.\nThe experimental protocol is relevant, except for the choice of the model being evaluated, since its accuracy on standard classification benchmarks is extremely low.\n\nIt is worth noting that the authors acknowledge in the main body that their proposed improvements do not make forward gradient methods an alternative for standard backpropagation, and that further research is needed for such approaches to become competitive."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The experimental protocol is relevant, the theoretical insights are valuable, and the different experiments bring valuable knowledge about the practical training dynamics.\n2) The bias of the proposed methods is appropriately characterized, and its relation with respect to the drop in performance is appropriately showcased. In particular, the authors show that it is a crucial limiting factor for good performances, even in cases where the cosine similarity between the guess and the true gradient is high."
            },
            "weaknesses": {
                "value": "1) The test accuracies obtained with backpropagation in Table 2 are extremely low. The model clearly overfits the dataset, which is not surprising for an MLP.\n2) It is not clear from the text whether the self-sharpening phenomenon is a desirable property of the training dynamics. As far as I understand, it is not.\n\n[Minor comment]\n3) At the end of the paragraph \"Effect of bias on our methods\", the sentence \"This bias is further in the next experiments and Section 4.\" has a missing word.\n4) The second paragraph of \"SUMMARY AND DISCUSSION\" begins with \"another interesting future research...\" while this is the first research direction proposed. I would switch the order between the second and third paragraphs since the bias of this method has been identified as the main limiting factor."
            },
            "questions": {
                "value": "1) Could the authors replicate some of their experiments with another model that has an accuracy much closer to SOTA than chance level on these datasets?\nThis is particularly important for Table 2. The best accuracy for CIFAR10 is 53.5%. Similarly, it is 83.5% for SVHN. This is unacceptable for such a research paper. Not that the reviewer has some particular taste for some particular model, but it is impossible to adequately judge the practical relevance of these contributions if the accuracy is exactly half-way between SOTA and chance level. The SOTA for CIFAR10 is > 95% while chance level is 10% - your model is 53.5% which is very problematic. I am not saying that the proposed method should all yield > 90%, but it should be the case for the baseline (standard backpropagation).\n\n2) How is the 1-step effectiveness calculated? Has it been calculated for 1 mini-batch or is it the average for multiple training steps?\nIt would be nice to have a mathematical formula to understand what is at stake here.\n\n3) If the self-sharpening in the $W^{\\top}$ setting is due to the matrix $W$ becoming low rank, is the self-sharpening phenomenon a desirable thing because it leads to higher cosine similarity, or should someone avoid this dimensional collapse because it hampers generalization?\n\n4) An interesting alternative gradient guessing scheme is presented in [1] where a gradient from a small auxiliary classification network is used as a guess direction. It would be nice to be able to compare a purely structural bias such as proposed in the presented work, where the bias is strongly data-dependent. (The experimental settings are quite different, making a fair comparison difficult.)\n\n[1] - L. Fournier, S. Rivaud, E. Belilovsky, M. Eickenberg, E. Oyallon. ICML 2023. Can forward gradient match backpropagation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699110023033,
        "cdate": 1699110023033,
        "tmdate": 1699636445553,
        "mdate": 1699636445553,
        "license": "CC BY 4.0",
        "version": 2
    }
]