[
    {
        "id": "IZDpX8MPvH",
        "forum": "lpxcCD7WbQ",
        "replyto": "lpxcCD7WbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_d7DF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_d7DF"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a neuroscience-inspired method to enhance multi-task adapation in deep learning. In particular, it proposes stochastically co-modulating neurons' gains based on their task relevance in multi-task adaptation problem. The methodology involves mechanisms of stochastic comodulation and neural architectures design. Numerical experiments have been conducted in CelebA and CIFAR-100 datasets, where the experimental settings were slightly different. The experimental results demonstrate the effectiveness of the proposed method. The paper also investigates the mechanisms supporting this improvement by a range of visualizable analysis. Overall, the paper is an interesting attemptation in the adaptation in multi-task learning, while there remains some space to improve.\n\n# Post-rebuttal \nWhile I appreciate the authors for the responses and clarifications, they do not solve my concerns (e.g., no addtional experiments on ImageNet or CoCo). Therefore, I will keep my original recommendation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed stochastic comodulation method is simple and effective, as well as faster in convergence.\n\n2. The paper provides comprehensive and interesting analysis about the learned model properties (Figure 3-6).\n\n3. This work shed light on understanding stochasticity nature of neural representations in the brain."
            },
            "weaknesses": {
                "value": "1. While it is interesting to see a bio-inspired algorithm, I found the motivation is a bit hard to follow without the background knowledge about \"co-modulation\" in the brain. There is somehow a gap between the neuroscientific findings and the proposed deep learning methodology in this paper (I have not read the preset papers (Haimerl et al. 2019; 2022)). \n\n2. The novelty of this paper is unclear in presence of (Haimerl et al. 2022). See the questions below.\n\n3. The testbeds could be more extensive. See the questions below.\n\nMinor:\n- Colors in Figure 1, 2, 3,5 is not friendly to color-blind readers (especially red-green), consider using different marker/line styles instead.\n- Plot labels in Figure 5 are too small and hard to recognize on printed paper.\n- REPRODUCIBILITY STATEMENT: Pytorch -> PyTorch\n- Is there any reason that Haimerl et al. 2022 used the term \"co-modulation\" but this paper use \"comodulation\"?"
            },
            "questions": {
                "value": "1. The paper wrote \"We extend the model of stochastic comodulation presented in Haimerl et al. (2019; 2022) ...\". Could the authors explain in more details about the relationship between the current paper and (Haimerl et al. 2022), including methodology, task setting etc. ?\n\n2. I also wonder how the presented stochastic comodulation method perform on more challenging dataset such as ImageNet and COCO. Is there any reason that ImageNet was not tested? \n\n3. It might be interesting to investigate whether stochastic comodulation could mitigate the notorious catastropic forgetting problem in continual/lifelong learning, since deep learning AIs are known to be suffering much more from catastropic forgetting than biological agents. Do the authors have any prelimiary results or thoughts about this?\n\n4. What are the relation between the proposed methods and LoRA / control net, as these methods freeze the pretrained-model and conducts adaptation with additional network of fewer parameters?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3879/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3879/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3879/Reviewer_d7DF"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3879/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698659147640,
        "cdate": 1698659147640,
        "tmdate": 1700977664447,
        "mdate": 1700977664447,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UOkxmysOVh",
        "forum": "lpxcCD7WbQ",
        "replyto": "lpxcCD7WbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_iLtH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_iLtH"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces biologically inspired stochastic co-modulation as a way to modulate the context of a multi-task learning framework and improve performance. Neural networks are fine-tuned with stochastic modulation gains. The authors show an increase in performance compared to non-stochastic gains, and claim that the networks train more efficiently when stochastic co-modulation is present."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper connects recent work investigating context-dependent stochastic co-modulation in biology to the multi-task learning setting, showing that it can be beneficial as a way to fine-tune the network performance. This is generally of interest to both neuroscience audiences and machine learning practitioners. I also found the experiment on CIFAR-100 (training on the 20 superclasses and fine-tuning on the 100 classes) to be an interesting way to connect perceptual learning experiments in neuroscience. The authors also demonstrated a notable improvement using stochastic co-modulation compared to the other tested models, particularly in terms of the recall score."
            },
            "weaknesses": {
                "value": "1. **Clarity of writing** Overall, I found the writing of the paper quite hard to follow. A lot of ground is covered by their experiments, and the motivation is often unclear (for instance, explaining the two versions of the experiment described on page (6) for the \u201cImage Classification\u201d experiment). Additionally, in many places of the paper, there are ad-hoc observations that are not fully explained, for instance, in the footnote on page (5) or the explanation about \u201cnetwork weights overfitting too much on the training set\u201d on page (5). There are also terms that are not well defined, for instance when referring to the \u201creliability diagrams\u201d on page 7, where \u201creliability\u201d is not explained. These are just a few examples, and I encourage the authors to revise the text to make it more clear for the reader. \n2. **Experimental details seem ad-hoc** The training setup seems a little odd. As far as I can tell, for the CelebA experiment, the authors (1) took a pre-trained ImageNet backbone (2) trained the whole network on the full task (3) fine-tuned just the controller parameters. This makes it difficult to compare the \u201cefficiency\u201d of training because there are many stages involved. Can the controller not be trained at the same time as the encoder/decoder (and if so, is this due to training problems or due to some experimental design choices)?  \n3. **Evaluation Metrics** The sharp drop in Precision for the proposed stochastic comodulation is somewhat troubling, and the resulting explanation seems insufficient. Even if it is unintentional, it makes the metrics used for comparison seem somewhat designed to ensure that the comodulation model is listed as \u201cbest.\u201d"
            },
            "questions": {
                "value": "a. Is it typical to first train the entire network on all tasks and then fine-tune it on the same dataset? I am most familiar with work that fine-tunes for new tasks, so just clarifying whether this is a standard choice would be helpful. \n\nb. I\u2019m a bit confused by the sentence \u201cIn other words, when a network predicts class C with a probability of 0.4, the probability that the network is correct is 0.4.\u201d in the \u201cComodulation improves confidence calibration\u201d section on Page 7). Is there a typo? If not, could you explain this in more detail, as I don\u2019t understand how this could be correct as written. For instance, if Class C is only ever encountered <0.01% of the time then the network will be correct with a probability significantly less than 0.4, right? \n\nc. In Table 1, are the comparison \u201cstate of the art\u201d methods computed on models that were trained in the same environment that is used in this paper, or are these taken directly from the cited papers? This detail seems important to clarify, as there might be other underlying differences. \n\nd. Could the authors provide further explanation of the deterministic \u201cattention\u201d model? I could not find details of this in the paper. This seems particularly important to explain, given that it is one of the critical comparisons and does best on the \u201cPrecision\u201d metric. Is this attention just the controller without a stochastic element, and if not, why is something along those lines not a direct comparison? \n\ne. As a followup to (d), did the tuning of hyperparameters for training etc. for this \u201cattention\u201d model receive as much tweaking as the co-modulation comparison? It is a little puzzling to me that there is very little change in the representations after fine-tuning here, and so I wonder if it is the stochastic co-modulation that is actually helping, or if the \u201cattention\u201d case had hyperparameters that did not behave well with the training setup.  \n\nf. On page 4 there is the sentence \u201c...we only use stochasticity to compute the gain, but we use unperturbed representations for decision making.\u201d This doesn\u2019t make sense to me \u2013 isn\u2019t the gain perturbing the representations? Or is stochasticity somehow turned off during the testing (and only on during training?) \n\ne. Minor: there should be a comma in \u201crecall, precision and F1-score\u201d on page 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3879/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698779203392,
        "cdate": 1698779203392,
        "tmdate": 1699636346481,
        "mdate": 1699636346481,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UMflBIjT9N",
        "forum": "lpxcCD7WbQ",
        "replyto": "lpxcCD7WbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_cKzA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_cKzA"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel task adaptation technique for multi-task learning based on task-specific stochastic comodulation of neurons. The proposed approach modulates a pretrained backbone's (ResNet-18) response using iid gaussian noise ($m_t$) for stochasticity, combined with a learned representation of context information ($c_k$) and forwarded to an MLP decoder. For each downstream context $k$, the readout is obtained by scaling the decoder's activations using a context-dependent gain ($g_k$). The above described comodulation process repurposes the outputs from a strong pretrained backbone to be used for a variety of downstream tasks by identifying (and scaling) task-relevant neurons from the backbone. Results on Celeb-A and CIFAR-100 show the merits of comodulation in producing improved performance (as measured by F-score) and prediction confidence calibration. The authors also include analysis of comodulated network's internal representations to show that they learn semantically rich decoder and context representations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ This submission explores repurposing a pretrained backbone's representation with minimal finetuning and extra parameters to improve performance in diverse downstream contexts. This work is highly relevant in this era of strong pretrained visual backbones, and using their representations to perform multiple downstream tasks.\n+ The evaluations are quite rigorous with multiple random intializations of all models used to report variance in performance.\n+ Analysis of networks trained with comodulation using CIFAR-100 was really interesting, and it was impressive (although not clear why) that comodulation improves calibration of prediction confidence."
            },
            "weaknesses": {
                "value": "- The improvements produced by comodulation over attention seem quite marginal and tend to diminish as the number of pretraining epochs increases. It is true that as backbone size increases, pretraining becomes less of a viable option, but the small gains over attention regardless (with few pretraining epochs) makes the work less exciting.\n- I found the writing to be clear overall, but felt that the Methods section could be further revised for improving readability. E.g. (1) the reader isn't aware of what $h^{J}_t$ is the first time it appears at the bottom of page 3; (2) is $h^{J-1}_k$ in Eqn. 3 the output of the second encoder layer (i.e. $h^{l+1}_k$? (3) citations appear to be in the wrong format in a few places and needs to be corrected\n- Although the attention baseline is repeatedly evaluated in many parts of the paper, I couldn't find a mathematical description of this approach, adding which would improve the clarity of this work."
            },
            "questions": {
                "value": "Please refer to my weaknesses section above. Clarifying my questions and improving the readability of this work will help improve my rating of this submission."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3879/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698965442077,
        "cdate": 1698965442077,
        "tmdate": 1699636346418,
        "mdate": 1699636346418,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IrlXMmPme7",
        "forum": "lpxcCD7WbQ",
        "replyto": "lpxcCD7WbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_8Tjw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3879/Reviewer_8Tjw"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates stochastic modulation as a mechanism for adapting neural circuitry to task in large vision models. Motivation comes from biological neural networks' ability to modulate neural responses in a task-dependent manner, suggesting that this may be effective in artificial NNs and that trying it may shed light on biological NNs.\n\nThe method is centered on fine-tuning by comodulation. Extending on prior work, the method begins with a pretrained model (here, image models) and a pretrained controller that maps from task indication to task-dependent comodulation as context weights, which ideally magnify task-informative neurons while inhibiting task-irrelevant neurons. Furthermore, a stochastic modulator generates noise to apply to decoder activations. Models are trained on a primary task then tuned on a different but related task; at this point, only coupling weights change. \n\nExperiments are performed on CelebA (40 binary tasks, some as primary and some as secondary, each with the same input image distribution) and CIFAR-100 (one classification task into 20 superclasses, then a fine-tuning classification task into 100 classes). \n\nThe paper finds that comodulation enables convergence in far less training than in other multi-task learning-related fine-tuning methods, though with more tuning, deterministic attention (another mechanism inspired by enhancing certain neurons and suppressing others) performs similarly. Furthermore, the paper discusses that CIFAR-100, residual connections improve comodulation, comodulation shrinks decoder noise, and comodulation improves the model's confidence calibration.\n\nThe paper concludes that comodulation can help achieve SOTA results, faster training, and better calibration than deterministic gain modulation in some conditions. It is an open question which specific conditions this applies to. The paper argues that the results also demonstrate stochastic modulation to be a computationally viable candidate for contextual fine-tuning in an animal brain."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "#### Quality\n- Paper is well-motivated by biological systems and a natural problem for ML\n- Experimental setup is thorough. \n  - Particularly clever: training/fine-tuning division on CelebA vs. CIFAR-100 requiring two different types of shifts of distribution\n- Results are laid out and analyzed well. While the main claims are a bit disorganized, they are all backe dup and convincing, even if at a small scale. \n\n#### Clarity\nPaper is very well written. \n\n\n#### Originality\nNo originality concerns - paper is well-grounded within prior literature. \n\n\n#### Significance\nThe paper is contextualized well in both biology and ML literature, which can be difficult. The improvements on various datasets are nontrivial, and compete with similar types of work in ML. Experiments with the fine-tuning done on larger and more complex datasets would be good for sending a solid ML message, but this is already an interesting contribution."
            },
            "weaknesses": {
                "value": "#### Quality\n- Final results might need more grounding to actual neural data to claim that this paper has made stochastic modulation seem more like it might be used in the brain. \"Might be a computationally viable candidate\" is technically accurate, but the language still feels overall overstated with respect to how much these results mean for the actual brain. \n- While this may be a matter of my not knowing prior work, the mechanism isn't clearly anchored in prior work - even after the experiments section, there's only a vague sense of it. There is one exception, where in the methods section it's made clear what the methods are built off of - more of that might be helpful.\n\n#### Clarity\n- It really is hard to see in many of the figures why we should be excited about the differences in the curves. Annotating or zooming in to ground them quantitatively would help.\n- \"Deterministic gain increases\" and \"calibration of confidence\" are brought up in the intro but not defined until the methods/results, which is confusing. \n- Figure 1 should be connected to text earlier than Equation 1 - it's hard to understand what on the figure is referring to what in the paper. \n- Figure 1: unclear how the stochastic modulator originates and interacts with the decoder. The controller has task info embedded, but Fig 1 + text makes the stochastic modulator look both like it comes from the controller and like it's purely randomly sampled. Which is it? \n- Table 1 would benefit from far more annotation - it's a lot to take in right now, and the text only refers to it as a whole (or it refers to specifics that are hard to find and hold in memory). \n- Minor: the paper says the task is given as a one-hot, but the figure makes it seem like a binary representation of some kind.\n\n#### Significance\nTo some degree it's unclear which audience this paper is for - for neuroscientists, there's almost no quantitative grounding in neural data. That said, the paper seems primarily geared toward the ML community - here, more/larger-scale experimentation would help but the results do show clear and consistent improvement. I think this is a smaller but well-scoped paper that points to interesting further research along with making a contribution. \n\n\n#### Minor\nIn the \"network embeddings\" paragraph in page 5, the paper refers to fig 2D; I think it should refer to fig 2C."
            },
            "questions": {
                "value": "- How exactly is the stochastic modulator signal integrated into the decoder, and how is it generated? Does it come from the controller or a totally random sample? How does that reflect on Fig 1?\n- \"Maps individual tasks into the context weights\" - did you mean \"to\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3879/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699342150206,
        "cdate": 1699342150206,
        "tmdate": 1699636346337,
        "mdate": 1699636346337,
        "license": "CC BY 4.0",
        "version": 2
    }
]