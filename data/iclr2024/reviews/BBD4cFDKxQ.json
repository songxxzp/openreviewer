[
    {
        "id": "CWlQSjsneZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_3pzd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_3pzd"
        ],
        "forum": "BBD4cFDKxQ",
        "replyto": "BBD4cFDKxQ",
        "content": {
            "summary": {
                "value": "The paper proposes a new loss function for an outlier detection method based on adacos. The idea is to train an embedding space for an auxiliary classification task. The classifier learns class centroids and the distance to these centroids represent the logits fed into the cross entropy loss. In AdaCos, the loss is computed with respect to the cosine distance between the class centroid and the vector. In AdaProj, the authors propose to use the Euclidian distance of projections on the unit hypersphere instead. \nThe loss is evaluated within an existing outlier detection pipline on anomalous sound detection challenge data sets from the last year. The prposed method shows an improvement even though the gap is not extreme."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is clearly written even though some of the similarities to early works are not distinguished very clearly. The paper improves the state of the art with respect to the  DCASE challenge of 22 and 23 and demonstrates that the loss function can improve the performance on averge."
            },
            "weaknesses": {
                "value": "The paper's contribution is rather limited as mostly replaces the consine similarity with the very similar concept of the L2 distance of projections to the unit sphere. The justification of this step where rather cryptic and I could not distinguish the argument of AdaProj over AdaCos from arguments for the whole design of centroid-based embeddings for outlier detection. However, this was mostly proposed in already published works. \nThe impact  of the lemma to the proposed methond seems  also remained unclear to me. \nThe experimental evaluation and most part of the paper seem to be directed to improve thes DCASE challenge. Thus, the improvement might be interesting for this particular community. But in order to demonstrate that the proposed loss function is of general interest to the broader AI community, a more widespride set field of applications might be necessary.\n\nTo conclude, the contribution seems not very broad and the motivation of why it is a recognizable contribution to a broader stater-of-the-art in representation learning is insufficient."
            },
            "questions": {
                "value": "In lemma 2, you assume that x is part of the unit sphere as well as the subspace. Wouldn't this imply that the projection into both spaces must be x itself ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1177/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697213601741,
        "cdate": 1697213601741,
        "tmdate": 1699636044001,
        "mdate": 1699636044001,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C7s8nA2xRr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_RkC3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_RkC3"
        ],
        "forum": "BBD4cFDKxQ",
        "replyto": "BBD4cFDKxQ",
        "content": {
            "summary": {
                "value": "The paper addresses the challenge of semi-supervised sound anomaly detection, a critical task in machine condition monitoring. The authors introduce AdaProj, which utilizes an angular margin loss function. This loss function learns to project data onto class-specific subspaces rather than aiming to bring data as close as possible to their respective class centers."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "AdaPoj, the proposed method, demonstrates state-of-the-art performance as demonstrated by rigorous empirical evaluations on the DCASE2022 and DCASE2023 datasets."
            },
            "weaknesses": {
                "value": "1. The paper exhibits a notable lack of clarity in its presentation. The problem statement and underlying setting are not adequately explained, necessitating multiple readings to grasp the details. For instance, there is ambiguity concerning class definition within this context. Given that anomaly detection traditionally aligns with a one-class classification paradigm, the introduction of classes in this approach requires a more thorough explanation. Additionally, the distinction between datasets and their respective splits remains unclear. A clear definition of the distinctions between evaluation and development sets is crucial for comprehensive understanding. Presently, the manuscript falls short of readiness and would greatly benefit from substantial revisions, potentially utilizing the available spare pages to elaborate upon its nuances, especially given that the paper is 7.5 pages in length, well below the 9-page limit.\n\n2. My fundamental concern centers on the degree of incremental novelty this work contributes to. Specifically, the entire framework is constructed upon an existing ASD system introduced in past works. The primary alteration appears to be a subtle adjustment to the auxiliary objective. While the proposed AdaProj approach represents an intriguing extension, there is a need for a more detailed discussion regarding the substantial departure or enhancement it brings to the existing framework."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1177/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1177/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1177/Reviewer_RkC3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1177/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697460462909,
        "cdate": 1697460462909,
        "tmdate": 1699636043932,
        "mdate": 1699636043932,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6zV2mX3zoZ",
        "forum": "BBD4cFDKxQ",
        "replyto": "BBD4cFDKxQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_t49Z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_t49Z"
        ],
        "content": {
            "summary": {
                "value": "The paper appears to focus on a novel loss function called the AdaProj loss, which is designed to improve the performance of anomaly sound detection (ASD) systems. The AdaProj loss aims to enlarge the space of optimal solutions, allowing the network to learn less restrictive distributions of normal samples. This is expected to help differentiate between normal and anomalous data after training. The AdaProj loss measures the distance to class-specific subspaces during the training of the embedding model, rather than measuring the distance to a single or multiple centers as done for other angular margin losses. The paper compares the AdaProj loss with other loss functions, such as the AdaCos loss and sub-cluster AdaCos loss, on datasets like DCASE2022 and DCASE2023. The results suggest that the proposed AdaProj loss outperforms other losses, especially on the DCASE2023 dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The AdaProj loss introduces a new approach to learning embeddings for ASD systems, focusing on class-specific linear subspaces rather than single or multiple centers.\n2. The AdaProj loss demonstrates superior performance compared to other loss functions, especially on the DCASE2023 dataset.\n3. The paper provides lemmas and proofs to support the claims made about the AdaProj loss, adding depth to the research.\n4. The paper conducts a thorough comparison of the AdaProj loss with other existing loss functions, providing a comprehensive view of its advantages."
            },
            "weaknesses": {
                "value": "1. The paper seems to delve deep into mathematical formulations, which might make it challenging for readers without a strong mathematical background.\n2. The extracted summary does not provide a clear context or background on the significance of the problem being addressed, which might make it difficult for readers unfamiliar with ASD systems to grasp the paper's importance.\n3. The paper primarily focuses on the DCASE2022 and DCASE2023 datasets. Including more diverse datasets could have provided a more comprehensive evaluation.\n4. The summary does not mention any details about the network architectures or other hyperparameters used, which might be crucial for reproducibility."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1177/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698688317574,
        "cdate": 1698688317574,
        "tmdate": 1699636043866,
        "mdate": 1699636043866,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PTaTVygD8T",
        "forum": "BBD4cFDKxQ",
        "replyto": "BBD4cFDKxQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_PZSP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1177/Reviewer_PZSP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new loss term for semi-supervised anomaly detection. It is designed to learn a class-specific subspace to facilitate the detection process. Experiments are conducted on two datasets and the proposed loss function achieves the SOTA results on DCASE2023 dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Semi-supervised anomaly detection is typical yet valuable topic for general machine learning research. This paper keeps exploring this direction.\n2. Experiments on two datasets show the proposed loss outperforms other baselines."
            },
            "weaknesses": {
                "value": "1. Comparison methods are not recently published works, adding more recent one or two years publications helps to further support the loss effectiveness.\n2. The empirical results may need more analysis and discussion. Why the proposed loss works better than others? simply comparing the numerical performance cannot provide more intuition for a newly designed term.\n3. The whole draft needs a revision to be more informative. For example, the anomaly detection may need a figure illustration to show the detection results with corresponding discussion.\n4. Experiments on two datasets may not sufficient and the results are not consistently better than other baselines."
            },
            "questions": {
                "value": "Please refer to the weakness for details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1177/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763872548,
        "cdate": 1698763872548,
        "tmdate": 1699636043780,
        "mdate": 1699636043780,
        "license": "CC BY 4.0",
        "version": 2
    }
]