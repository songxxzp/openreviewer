[
    {
        "id": "H47Um3DWvB",
        "forum": "n7Sr8SW4bn",
        "replyto": "n7Sr8SW4bn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_AAng"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_AAng"
        ],
        "content": {
            "summary": {
                "value": "The authors utilize memory-augmented networks for summarizing graph streams into a fixed space. Given the compressed result and a specific edge (or a subset of edges), one can approximate the edge's weight. The neural network is first pre-trained on synthetic graph streams and later fine-tuned using a fraction of the input stream. When compared to sketching-based approaches, the suggested method shows a better approximation accuracy for a given compression size."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "S1. The overall design of the suggested proposed, particularly the use of memory-augmented networks for compressing graph streams, seems reasonable.\n\nS2. The introduced method exhibits significant improvements compared to sketching-based approaches.\n\nS3. The proposed successfully applies to billion-scale graphs, highlighting its practicality for real-world scenarios."
            },
            "weaknesses": {
                "value": "W1. The paper lacks a theoretical analysis of complexity and accuracy.\n\nW2. The presentation could be clearer. The insights and novelties of the addressing, decoding, and store operations could be specified.\n\nW3. The proposed method seems to only support weight-related queries, not graph algorithms like Dijkstra\u2019s.\n\nW4. While somewhat expected, the throughput of the proposed method is not as high as that of rule-based baseline methods."
            },
            "questions": {
                "value": "Q1. Can complex graph algorithms, like Dijkstra's, be executed using the summary? If they can, does it substantially impact the time complexity compared to executing the algorithms on the uncompressed graph?\n\nQ2.  Can you provide a more detailed explanation of how the MiGain term contributes? The present explanation seems too concise.\n\nQ3. What is the time complexity of the addressing, decoding, and store operations?\n\nQ4. The reported ARE and AAE seem quite large. What are their values when we use the mean as the estimate of all edge weights?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4699/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698711021884,
        "cdate": 1698711021884,
        "tmdate": 1699636451530,
        "mdate": 1699636451530,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FGSYhruypQ",
        "forum": "n7Sr8SW4bn",
        "replyto": "n7Sr8SW4bn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_GvCp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_GvCp"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a neural data structure for graph stream summarization, which has neatly designed modules (representation, addressing and decoding), as well as corresponding operations such as store and multiple types of queries. Experiments on Lkml and Enron datasets demonstrate the superiority of the designed approach compared to the SOTA TCM and GSS baselines."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper studies an interesting topic on using neural data structure for graph stream summarization, and designed the approach very neatly. In general, the presentation of the methodology is very clear and makes it easier to understand the nontrivial details.\n\n2. The training strategy is inspiring, following the paradigm of \"pre-training and fine-tuning\", and thus has two stages called larval phase and metamorphosis phase.\n\n3. Comprehensive experimental results demonstrate both the effectiveness of the method on different types of queries and throughputs."
            },
            "weaknesses": {
                "value": "1. Minor: A table of dataset statistics is suggested to make it more straightforward."
            },
            "questions": {
                "value": "1. In addition to throughput, is there any other metric to evaluate the efficiency of the method (e.g., query time)?\n2. How to balance between the parameter size and model accuracy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4699/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698829864415,
        "cdate": 1698829864415,
        "tmdate": 1699636451420,
        "mdate": 1699636451420,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Uq1I1JSMFU",
        "forum": "n7Sr8SW4bn",
        "replyto": "n7Sr8SW4bn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_wDZJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4699/Reviewer_wDZJ"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a Mayfly framework consisting of two stages (larval and metamorphosis) for summarizing graph streams. It is the first neural data structure for graph stream summarization. The Mayfly acquires basic summarization capabilities by learning from synthetic data and can be rapidly adapted to real graph streams. The Mayfly framework is agile and customizable, supporting a broad range of graph queries with lightweight information pathway configurations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1: The authors' integration of Mayfly with machine learning is interesting.\nS2: Well-written."
            },
            "weaknesses": {
                "value": "W1: It seems that this paper leans more towards an engineering-oriented research, and its technology appears to be quite fundamental. For instance, it utilizes techniques like meta-learning and follows the paradigm of pre-training and fine-tuning. In my view, there's very little innovation at the model level, which is the most fundamental reason for my minor rejection.\nW2: The authors' integration of graph streams with the Mayfly framework is indeed intriguing. However, from my perspective, it appears to be a fundamental application of pre-training and fine-tuning methods. I believe the authors should provide a clear explanation in the introduction or methodology section regarding why the Mayfly framework is particularly suitable for adapting to graph data streams.\nW3: While the authors propose the Mayfly framework with the aim of enhancing data stream processing efficiency, I did not see a clear experimental demonstration of its efficiency gains. In other words, I would appreciate a more tangible comparison between the Mayfly framework and the comparative algorithms in terms of actual runtime efficiency under the same spatial budget."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4699/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4699/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4699/Reviewer_wDZJ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4699/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698860223582,
        "cdate": 1698860223582,
        "tmdate": 1700694812866,
        "mdate": 1700694812866,
        "license": "CC BY 4.0",
        "version": 2
    }
]