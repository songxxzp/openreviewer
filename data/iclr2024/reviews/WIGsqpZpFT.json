[
    {
        "id": "NwgqOaTVEQ",
        "forum": "WIGsqpZpFT",
        "replyto": "WIGsqpZpFT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_mDPp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_mDPp"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the effect that LLMs\u2019 depth has on its performance on compositional genalization and language modeling tasks. To disentangle the effect of depth on performance from other factors, the authors fixed the total number of parameters of LLM by reducing the size of the transformer\u2019s feed-forward dimension (d_model) while increasing the layers of transformer. Experiments here showed that deeper LLMs result in better language modeling and compositional generalization up until when the LLM becomes too narrow when d_ff<d_model. The authors also conducted more experiments to show that the better compositional generalization by deeper LLMs is not simply due to better language modeling performance by using pretrained deeper LLMs that have similar perplexity than the shallower counterpart. Experiments are conducted on 3 model size classes, pretrained on C4 corpus and 4 compositional generalization tasks (COGS, COGS-vf, GeoQuery, English passivization)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+The paper\u2019s empirical findings contributes to the body of work that seek to better understand how to train LLMs most efficiently by choosing the best mix of model hyperparameters given a particular computational budget.\n\n+Experiments are designed well to disentangle possible confounders (language modeling performance etc).\n\n+The paper is generally well-written and easy to follow."
            },
            "weaknesses": {
                "value": "-The paper\u2019s core contributions centers around mostly confirming existing findings (e.g. Mueller et al. (2022) and Tay et al. (2021)) with empirical results that a bigger depth improves expressiveness of neural network or LLMs, limiting the impact of the work. Making it more obvious what is different from these prior work will help readers better appreciate the paper\u2019s contributions (e.g. in-depth analyses about why this occurs beyond empirical results on performance).  \n\n-The experiments focus only on compositional generalization and language modeling tasks while there is a plerotha of other tasks that can be used to evaluate LLMs\u2019 generalization capabilities."
            },
            "questions": {
                "value": "Can compositional generalization and language modeling tasks along stand to evaluate the generalization of the LLMs (or mostly only compositional generalization)? It would be helpful to discuss the different types of generalization if the paper is claiming generalization as a whole beyond compositional generalization."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6715/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698614948926,
        "cdate": 1698614948926,
        "tmdate": 1699636771934,
        "mdate": 1699636771934,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n1lGujiEWu",
        "forum": "WIGsqpZpFT",
        "replyto": "WIGsqpZpFT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_1ZSK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_1ZSK"
        ],
        "content": {
            "summary": {
                "value": "The paper provides a controlled study disentangling model depth from the width and total parameters. The results support the view that depth improves generalization in transformers, with diminishing returns past a shallow threshold. The paper makes a solid contribution to understanding model architecture choices for generalization. Overall, the paper makes a valuable contribution by investigating the impact of depth on the generalization ability of Transformer language models. However, addressing the following weaknesses would enhance the comprehensiveness and applicability of the research."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "By investigating the effect of depth on the model's generalization ability, the paper provides a valuable reference for improving and optimizing the design of language models."
            },
            "weaknesses": {
                "value": "1. Since the paper mainly verifies the effect of the Transformer\u2019s \u201cdepth\u201d on combinatorial generalization, the \"depth and width\" in the title of the paper is misleading.\n2. While the paper primarily investigates the effect of depth, the impact of width on generalization is not extensively explored. It would be beneficial to analyze the trade-offs between depth and width and how they interact in terms of model performance and generalization.\n3. The paper does not thoroughly discuss the computational implications of increasing depth or width in Transformer models. Considering the computational cost associated with deeper models, it would be useful to analyze the trade-off between improved generalization and increased computational requirements."
            },
            "questions": {
                "value": "1. Please double-check the reference format and standardize it.\n2. In the paper, you focus on the impact of depth on Transformer language model generalization, but the analysis of width is relatively limited. Can you provide further insights into the trade-offs between depth and width? How do these two factors interact in terms of model performance and generalization? It would be helpful to explore the joint effects of depth and width and their relative importance in achieving better generalization.\n3. You only conduct a single run for each experimental condition. Adding multiple runs would strengthen conclusions by quantifying uncertainty and ruling out run-specific fluctuations. Is it feasible to do multiple runs, even if a subset of conditions?\n4. Is there an optimal depth where returns diminish for all model sizes and domains? Or does optimal depth keep increasing with the model scale?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6715/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636631804,
        "cdate": 1698636631804,
        "tmdate": 1699636771823,
        "mdate": 1699636771823,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xce1dtsydJ",
        "forum": "WIGsqpZpFT",
        "replyto": "WIGsqpZpFT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_yaYa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_yaYa"
        ],
        "content": {
            "summary": {
                "value": "The paper empirically studied the impact of increasing depth and width on the model's out-of-distribution generalization performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper provides some interesting experiment results which might be useful for future research."
            },
            "weaknesses": {
                "value": "1. The result is a bit too straightforward with only experiment results. More theoretical analysis on the difference between increasing depth and width on out-of-distribution generalization is required for a paper on venues such as ICLR.\n2. Why do the authors choose to focus on decoder-only models? What can be the difference between encoder-decoder models and decoder-only models on the impact from different depths and widths?"
            },
            "questions": {
                "value": "Please see the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Reviewer_yaYa"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6715/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827344879,
        "cdate": 1698827344879,
        "tmdate": 1699636771669,
        "mdate": 1699636771669,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dkf2SOlWGa",
        "forum": "WIGsqpZpFT",
        "replyto": "WIGsqpZpFT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_ZnHf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6715/Reviewer_ZnHf"
        ],
        "content": {
            "summary": {
                "value": "This paper  studies how performance for \"compositional generalization\" in Transformers varies as a function of depth. Its main twist is to pay careful attention in keeping the number of parameters constant. Hence, when augmenting depth, it is reducing width accordingly. This is done for 3 different number of parameters.\nInspecting the results, my take-aways are the following: performance _does_ systematically get better with deeper models as long as they don\u2019t become so narrow so as to have a width that requires reducing input dimensionality. This said, depths=3-6 look largely enough for all practical purposes, and the main way to get better performance is just to increase the number of parameters, which matches usual knowledge."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper asks a clear question: how does performance vary as a function of depth vs width for a given and fixed number of parameters for transformer based architectures on LM.\nThe paper provides a very clear and rigorous treatment of this question, also providing relevant literature and areas of further investigations.\nI particularly like one of the final questions that is asked about \"alternative approaches to controlling for total size\". Universal transformers are quite an extreme way to go, with all layers sharing the same weights. Maybe you could find some alternative way, for instance by repeating blocks of layers instead of just one. Likewise, I wonder about hypernetworks. They could be used to fill out huge networks, but then constraining the number of parameters.\n\nAll in all, I think the paper may be interesting to some persons, at least as a reference on that precise question it is asking.\n\nI think the paper is just as good as it gets to answer this question for any person that could be interested in the topic. For this, my pick is it should be accepted."
            },
            "weaknesses": {
                "value": "- Applicability of the study is arguable a bit weak and I would say that it mostly would serve as a reference for what is usually considered common knowledge without any rigorous treatment: \"for a given parameter budget, pick depth over width\".\n- It remains extremely clear from this paper that beyond very small depth (as soon as we get 3~ layers), performance doesn\u2019t really go up with depth alone: the way to go is just to add more parameters.\n- As a practitioner, I would be interested by the following question: what about if my budget is not really in terms of number of paremeters, but rather in compute power or memory? Do you see the same thing happening that one should pick depth?\n- p8: \"when studying the the impact\""
            },
            "questions": {
                "value": "I am not sure about the questions I should ask, since the paper really looks pretty clear to me. I guess it\u2019s more about what\u2019s next. Personally I didn\u2019t find the 3rd and 4th limitations very illuminating, but liked the 2nd."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6715/Reviewer_ZnHf"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6715/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699041818189,
        "cdate": 1699041818189,
        "tmdate": 1699636771546,
        "mdate": 1699636771546,
        "license": "CC BY 4.0",
        "version": 2
    }
]