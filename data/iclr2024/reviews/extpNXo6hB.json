[
    {
        "id": "2jhKYpeIhe",
        "forum": "extpNXo6hB",
        "replyto": "extpNXo6hB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_UgSj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_UgSj"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the author present SweetDreamer, a text-to-3D generation model. They address the limitations of existing 2D diffusion models by aligning the 2D geometric priors with well-defined 3D shapes from a 3D dataset. To resolve the multi-view inconsistency, SweetDreamer incorporates fine-tuning a pre-trained diffusion model to produce view-specific coordinate maps of canonically oriented 3D objects. Then these aligned geometric priors are integrated into different text-to-image pipelines to generate geometry and appearance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem addressed in this paper is a realistic problem that current diffusion models struggle to handle effectively.\n\n2. The incorporation of 3D geometric priors into the generation process is a compelling and intriguing approach."
            },
            "weaknesses": {
                "value": "1. The novelty of this paper is kind of incremental. Most components (such as Stable Diffusion, loss functions) of the proposed method come from previous works, lacking technical novelty.\n\n2. The quantitative results are not satisfying. The evaluation scores reported in Table 1 only show the performance of inconsistency. Did the author compare with other methods by use of other metrics (e.g., R-Precision in DreamFusion)? \n\n3. A simple baseline is missing. Have the authors considered directly replacing the original SDS loss with the aligned geometric SDS loss and calculated the inconsistencies in Table 1?\n\n4. The ablation discussion is absent."
            },
            "questions": {
                "value": "Please see Weaknesses.\n\nOther questions:\n\n1. How long does the fine-tuning for a stable diffusion model take?\n2. How does the efficiency (inference time) of this model compare to other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3384/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3384/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3384/Reviewer_UgSj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698642069709,
        "cdate": 1698642069709,
        "tmdate": 1699636289226,
        "mdate": 1699636289226,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LBLB7hvLdS",
        "forum": "extpNXo6hB",
        "replyto": "extpNXo6hB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_uDHT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_uDHT"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes SweetDreamer, a new solution to the multi-face Janus problem encountered in the text-to-3D generation pipeline. The core strategy revolves around integrating a Canonical Coordinates Map (CCM) SDS loss. SweetDreamer fin-tunes the Stable Diffusion model to predict Canonical Coordinates Maps (CCM) on the Objaverse dataset, offering Aligned Geometric Priors (AGP). Furthermore, the authors incorporated camera information into the diffusion model. Both quantitative and qualitative assessments show that SweetDreamer successfully mitigates the issues of geometry and appearance inconsistency."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of introducing view-conditioned information into 2D foundation models like Stable Diffusion to address the multi-face problem is sound. By fine-tuning the 2D diffusion model to predict the Canonical Coordinates Map, it gains an inherent understanding of the basic viewpoint of an object, thus providing additional aligned geometric priors for the text-to-3D pipeline. Additionally, the inclusion of camera information to speed up convergence is a reasonable choice.\n2. Human evaluation results indeed validate that SweetDreamer alleviates the multi-faced problem. Furthermore, a user study accentuates SweetDreamer's superiority over previous methods.\n3. The presentation is clear and easy to follow. The author gives a thoughtful analysis of the multi-face problem, including \u201cthe geometry inconsistency is the key problem compared with appearance inconsistency\u201d."
            },
            "weaknesses": {
                "value": "1. There are no ablation studies in this paper. For example, the author claims that the SDS loss from the Canonical Coordinates Map can avoid overfitting the 3D training data. However, there are no experiments to support this idea. Moreover, all the design choices in this paper including how to inject the camera information into the diffusion model are not ablated. \n2. In fact, introducing a view-dependent SDS loss to tackle the multi-face issue has been proven in Zero-123 and Magic-123, which use a view-aware SDS loss to generate a 3D object. SweetDreamer uses a Canonical Coordinates Map SDS loss rather than RGB SDS loss, the novelty and technique contribution is limited.\n3. SweetDreamer uses Objaverse data to fine-tune the Stable Diffusion model to predict the Canonical Coordinates Map. However, defining a canonical coordinate system uniformly across diverse categories is challenging. The authors' choice to whittle down the Objaverse dataset from 800k to 270k, in effect, results in significant data attrition. When compared with techniques that fine-tune based on multi-view images, this could constrain the method's generalizability."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698776153135,
        "cdate": 1698776153135,
        "tmdate": 1699636289128,
        "mdate": 1699636289128,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FYxaxqHtla",
        "forum": "extpNXo6hB",
        "replyto": "extpNXo6hB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_nptq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_nptq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes aligned geometric priors (AGP) to address the multiview inconsistency problem in diffusion models. In detail, the method finetunes a pre-trained 2D diffusion model to generate viewpoint-specific coarse geometric maps of canonically oriented\n3D objects to ensure 3D awareness. Qualitative experiments and human evaluation results show great geometry consistency of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed aligned geometric priors (AGP) show effectiveness in improving multiview consistency.\n\n2. The qualitative results show good consistency compared with other methods.\n\n3. The paper is well-written and the core contributions are clear."
            },
            "weaknesses": {
                "value": "1. Using Canonical Coordinates Map (CCM) in diffusion model to preserve 3D consistency is one of the core contributions of this paper. However, this coordinate map representation is not something new, and the advantage of using CCM instead of a depth map, normal map, or point cloud is not clear. Experiments to show the superiority of such representation are desired.\n\n2. The experiments have some weaknesses. Only 80 results from 80 text prompts are generated using each method. The results can be noisy based on the small amount of data.\n\n3. The definition of \"3D consistency\" in the quantitative experiment is vague (\"e.g., multiple heads, hands, or legs\"). For example, when the generated object is blurred, or does not have the concept of \"head, hand, leg\" (e.g., building), or some part of the generated object is twisted but not duplicated or missing, how can we determine the 3D consistency is correct or not?\n\n4. It is better to also report the appearance or texture quality measurements, even though this paper mainly focuses on improving the 3D consistency. It can show whether (and if yes, to what extent) the proposed method will influence the appearance or texture quality of the generated objects.\n\n5. The method is based on the assumption that all objects within the same category adhere to a canonical orientation in the training data. However, Objaverse does not align the zero poses of the objects. It is interesting to see whether only using a smaller subset, where objects have a canonical orientation, can lead to better results or not."
            },
            "questions": {
                "value": "1. The questions in the Weaknesses section.\n\n2. \"Ours (NeRF-based full) using DeeFloyd IF first and then Stable Diffusion\". How is it implemented in detail? What is the method (Ours (NeRF-based)) used in user study (NeRF-based IF or NeRF-based full)?\n\n3. How are $\\lambda^{ori}$ and $\\lambda^{align}$ chosen?\n\n4. The user study interface can be shown in the appendix (How did the interface show users to \"consider only the 3D consistency\"? How are the users chosen? Do they have the concept of 3D consistency?)\n\nI will consider raising the rating if the authors can respond to the weaknesses and questions well in the rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3384/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3384/Reviewer_nptq",
                    "ICLR.cc/2024/Conference/Submission3384/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816806542,
        "cdate": 1698816806542,
        "tmdate": 1700765366550,
        "mdate": 1700765366550,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7nQm6nXU8g",
        "forum": "extpNXo6hB",
        "replyto": "extpNXo6hB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_Q6rV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3384/Reviewer_Q6rV"
        ],
        "content": {
            "summary": {
                "value": "Text-to-3D is now a very very hot topic, starting from Dreamfushion. Nowadays, there are already many works which demonstrate very good quality of results. However, existing methods undergo a severe issue: the SD lacks view information of the 3D objects, making \"multi-face\" issues are usually caused. This work presented Canonical Coordinates Map as a geometric representation and train a geometric-aligned prior resorting to the recent public 3D dataset-Objaverse. The results are of very high quality."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- First, the results are of very high quality. \n- The paper writing is good and the motivation is strong. \n- The proposed method is novel."
            },
            "weaknesses": {
                "value": "- My major concern is about the necessity of the proposed CCM. It seems CCM is one of the geometric prior representation. I am curious what will happen if we replace CCM by just using normal map or depth map as a geometric representation? More specifically, an extra experiment is needed: using objaverse to train a normal/depth map (instead of CCM) generative model and also include camera condition.  \n- My another question is: if objaverse is used to finetune SD for CCM generation, will the generalization ability be decreased? As objaverse is lacking diversity especially on complicated scenarios. More discussions are encouraged.\n- In Fig 1, it seems the normal map owns many bumps, what are the details about the normal rendering?\n- It is said in the implementation details \"a significant portion of the 3d objects in canonical orientation and a few misoriented\". The authors mentioned it will not affect the results. I think more detailed explanations are needed, for example, what does it mean about mis-oriented? how many objects are mis-oriented\uff1f if the mis-oriented cases are corrected manually,  will the performance be improved further?"
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698897726681,
        "cdate": 1698897726681,
        "tmdate": 1699636288968,
        "mdate": 1699636288968,
        "license": "CC BY 4.0",
        "version": 2
    }
]