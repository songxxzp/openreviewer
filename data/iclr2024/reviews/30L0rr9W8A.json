[
    {
        "id": "I5S9bMSeAn",
        "forum": "30L0rr9W8A",
        "replyto": "30L0rr9W8A",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_ciJn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_ciJn"
        ],
        "content": {
            "summary": {
                "value": "The authors propose to learn a control barrier function in the latent space via an auto-encoder.  The system dynamics is learned by directly regressing over the gradient. The CBF is learned following the common loss setup in the CBF learning literature. The safe policy is learned by distillation from the CBF-QP result where the QP layer is differentiable following Brandon Amos's work. The proposed method is verified on a few tasks including car and quadrotor obstacle avoidance. The author also combined the latent CBF with an existing learned driving agent and achieved improvement in the Carla simulator."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The simulation experiment results are strong, \n2. The paper is generally well-written, easy to follow\n3. The idea of learning a CBF in the latent space is new"
            },
            "weaknesses": {
                "value": "1. I don't get why learning a CBF in the latent space is more advantageous than learning in the original state space, and there is no comparison to show the benefit.\n2. There lacks necessary theoretical \"book-keeping\" results to ensure that the latent CBF is well-defined and the theories for the original CBF can carry over.\n3. The training process is not explained clearly, I'm confused about the training details, e.g. how is the auto-encoder trained?"
            },
            "questions": {
                "value": "1. \"Domain adaptation for the encoder ensuring the latent space that the latent space is always relevant and can contain features necessary for the barrier function\", please remove the first \"the latent space\"\n\n2. For equation (2), please specify the norm used.\n\n3. How do you guarantee the injectiveness of the encoder, i.e., each point x got mapped to a unique z? \n\n4. I don't think one can simply define a barrier function on z and apply the original CBF theory without any care. For example, assuming that z has a higher dimension than x (which is probably true), all z that are mapped from an x live on a manifold. The original CBF theory is built on assumptions that involve openness and compactness of certain sets, which may be violated here. For one, the image of the safe set in the latent space may even be disconnected when the original safe set is connected or the other way around.\n\n5. I find the dynamics learning problem very weird, it seems that the assumption is that you can observe \\dot{x} directly, yet the dynamics is unknown. This is almost never the case in practice as gradient observation is very noisy. The authors may consider a discrete-time CBF setting for practicality.\n\n6. As mentioned above, please provide more details on the training process, is the training end to end, if not, how many steps and which components are fixed, which are being trained in each step?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9335/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698215883305,
        "cdate": 1698215883305,
        "tmdate": 1699637175056,
        "mdate": 1699637175056,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oYoEoJ2S5o",
        "forum": "30L0rr9W8A",
        "replyto": "30L0rr9W8A",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_ERPL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_ERPL"
        ],
        "content": {
            "summary": {
                "value": "This work uses autoencoder to learn latent space within which the dynamics and CBF are well-defined and proposes an algorithm for learning dynamics/CBF and an optimal policy together; which is applied to some practical tasks showing advantages."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. For some experiments, it is shown that the proposed algorithm successfully learn CBF approximately with autoencoder architectures.\n2. Algorithms are simple enough."
            },
            "weaknesses": {
                "value": "1. There are some mathematically no rigorous or strange writings; e.g., page 3 top \u201care both in R^D\u201d should be \u201care both in the Euclidean space R^D\u201d or so.  Also, B(z, theta_B) should be continuously differentiable?  And B(z, theta_B) should be on R^d x parameter space (or theta_B could be given\u2026?)?  Eq 16 is a bit strange; z in Z_safe within dataset?\n2.  If you assume the dynamics is over the observation space (or learned latent space), it has all the information about the state; so I get the idea that the authors are trying to do encoding to get latent state, the work is not dealing with the partial observability case.  Abstract and introduction are misleading (no access to \u201call states\u201d may imply that we have partial observability).\nAnd it is mathematically just CBF (not LatentCBF or so).\n3.  CBF is useful for giving theoretical guarantees of safety.  Although adding encoding/decoding layers for practical purpose, it adds little insights about the theoretical concept of CBF."
            },
            "questions": {
                "value": "1. What is the systematic and robust choice of policy_adapt?  If the whole algorithm, including the learning of CBF, is robust, I believe the work becomes solid.  For now, it seems a bit ad-hoc, which hinders the benefits of practical applications (as I mentioned, the focus of this work is practical scaling to image space etc. rather than theoretical insights.  So each choice of parameters, exploration policies etc. should be made clear and robust."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Reviewer_ERPL"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9335/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698479355348,
        "cdate": 1698479355348,
        "tmdate": 1699637174953,
        "mdate": 1699637174953,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DARmu36SkK",
        "forum": "30L0rr9W8A",
        "replyto": "30L0rr9W8A",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_pAha"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_pAha"
        ],
        "content": {
            "summary": {
                "value": "Traditional control methods for enforcing set-invariant safety involve the construction of a scalar functional such as a CBF to ensure projection to safe controls. With the advent of learning, several models that were used in generating safe controls have been replaced with learned models such as neural nets. For example, several papers learn a neural CBF while others try to fit a NN to both CBF and unknown dynamics. Here, the authors endeavor to relax the assumption of a known system/robot state. Rather, only a high-dimensional observation such as an image is known. The projection to latent space is performed using an auto-encoder to generate a latent representation. This representation is a proxy for the state and the CBF/dynamics is learnt over the representation. To learn the CBF, an appropriate loss function to separate safe and unsafe trajectories is used. The latent representation is learned end-to-end with an appropriate auto-encoder loss. The dynamics is also modeled with a neural net and learned during an exploration phase. Experimental validations are performed on several benchmarks common in CBF literature such as the quadrotor and kinematic car dynamics. Additional validation is performed using the CARLA simulator."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The novelty is clear and is a good fit for this venue.\n\n2) The experimental results and comparisons are good. The result in CARLA shows some additional effort on the authors' side.\n\n3) The presentation and the figures in this paper are excellent and demonstrate the results clearly.\n\n4) The specific use of Lipschitz neural networks and Bjorck layers is interesting."
            },
            "weaknesses": {
                "value": "Some of the weaknesses in terms of significance of the results and related questions are listed here.\n\n1) While it seems good to assume no knowledge of any aspect of the dynamics/environment, the solution can retain some structural aspects of the dynamics/environment. The approach here is to learn everything as a black box.  In contrast, this paper ( https://arxiv.org/pdf/2203.02401.pdf  ) uses whatever ego-state information is available as proxy intermediate losses while training end-to-end. That might be a more realistic scenario where we have some partial information available.\n\n2) It would be interesting for me to understand if the training is stable. In terms of the training, it would be nice to see learning curves and error bars as to how robust and repeatable the training is. \n\n3) Some of the appeal of classical control is the existence of provable guarantees especially when it comes to safety (even though those guarantees come with strings attached). While ensuring a self-driving car is safe, we are not happy if the car is safe $x\\\\%$ of the time. We are looking for something stronger. In this context, apart from the percentage of time the system is unsafe, it would be nice to understand how much the deviation from the safe boundary is. \n\n4) Safety is not guaranteed during the exploration phase"
            },
            "questions": {
                "value": "1) \u201cThe major limitation is that the typical definition of a barrier function requires state information that is not generally available in real-world scenarios.\u201d - Usually some partial state information is available so the premise is not perfectly true.\n\n2) When the CBF is learnt using a soft loss function, it is not for theoretical purposes a strict CBF. Rather, it is an approximate neural CBF.  Is there any way of overcoming this limitation such as using verification?\n\n3) For the baseline comparison, is the state-assumed to be known or estimated with a different neural module. More clearly, is the main difference between the current method and baselines mainly end-to-end learning? \n\n4) It is interesting that LCBF uses fewer episodes for learning. Is it because all components of the state are not relevant to safety and thus need not be learnt in the latent state?\n\n5) Will the method work if $\\pi^{optimal}$ changes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9335/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698530139504,
        "cdate": 1698530139504,
        "tmdate": 1699637174845,
        "mdate": 1699637174845,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eWWzTDgdO0",
        "forum": "30L0rr9W8A",
        "replyto": "30L0rr9W8A",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_5PWg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9335/Reviewer_5PWg"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the problem of safe data-driven control using neural networks when access to the state is unavailable. Observations (not necessarily the true states) are embedded in a latent space using a Lipschitz autoencoder. Using this latent representation of the dynamics, a QP-CLF based approach is used to design a safe controller in the latent space, by learning the dynamics in latent space, the controller and the barrier certificate. The safe and unsafe sets themselves are not explicitly defined; rather, they are annotated in the data using a simple formulation (eq 15). The empirical evaluation shows that the proposed approach achieves performance comparable to the state of the art."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper has the following strengths.\n\n* The idea of embedding the dynamics in a latent space, and performing the safe control optimization therein is an interesting one, as it enables learning of the dynamics as well as the safe controller. \n* In this formulation, neither the safe set nor the dynamics need to be specified and can be learned from data."
            },
            "weaknesses": {
                "value": "The paper has several weaknesses.\n* The discussion about safety and barrier certificates feels rushed. Safety, as defined in [1],[2], is always with respect to safe and unsafe sets. The barrier certificate conditions given in equations (4)-(5) should hold on the interior of the safe set (see, for instance, equations (4), (7) in [1]). \n* There are no discussions about guarantees that the closed-loop trajectories in the latent space will satisfy safety constraints in the canonical space (i.e. the space X from which trajectory data is initially drawn from).\n* Similarly, the learning problem should be more clearly stated - what is the dataset in question, what are the functions we are learning, and what is the loss function? \n* There is very limited discussion as to why Lipschitz autoencoders are necessary. In section 3.3, it's stated that this choice was made owing to [1], which requires the barrier certificate $B(z)$ to be Lipschitz. This is a little imprecise, as all the theorems in [1] only require that the barrier certificate (and the various functions, such as the state-dependent Hessian $H(x)$ used in the QP) be locally lipschitz. \n* There is limited discussion about other data-driven control methods, including reinforcement learning, kernel methods, gaussian processes, etc. What are the particular advantages of using potentially costly neural policies over other methods?\n* It is unclear what the authors mean with the third contribution - could that be clarified? It is not discussed anywhere else in the paper. \n\n\n\n\n\n\n[1]  *Control barrier function based\nquadratic programs for safety critical systems.* Ames et al, 2016. \n\n[2] *A framework for worst-case and stochastic safety verification using barrier certificates*. Prajna and Rantzer, 2007."
            },
            "questions": {
                "value": "I ask that the authors please address the points raised in the 'Weaknesses' section. Additionallly, I have the following questions for clarification.\n\n* It's stated in the paper that this work is motivated (at least in part) by the fact that the true state may not be accessible. This problem can be thought of as a variant of output feedback control, which has a rich history. Can you comment on the similarities and differences between this work, and other work that addresses the problem of data-driven output feedback control? \n* Following the previous question, can one think of the latent-space embedding as a form of neural observer? If not, why not? \n* Is it possible to formally analyze the performance of the closed-loop trajectories once they are decoded? For instance, is it possible to analyze the probability that the closed-loop trajectories are safe?\n* Is there a practical advantage of using this technique in real-world scenarios? In particular, can you comment on the cost of inference using this neural network-based approach, to other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9335/Reviewer_5PWg"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9335/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698613988063,
        "cdate": 1698613988063,
        "tmdate": 1699637174739,
        "mdate": 1699637174739,
        "license": "CC BY 4.0",
        "version": 2
    }
]