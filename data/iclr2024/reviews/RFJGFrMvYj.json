[
    {
        "id": "oDAZr6drwf",
        "forum": "RFJGFrMvYj",
        "replyto": "RFJGFrMvYj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_nTLn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_nTLn"
        ],
        "content": {
            "summary": {
                "value": "This paper leverages VQGAN to generate an initial image based on text and segment map guidance, followed by refinement using a diffusion model. The authors claim that this  algorithm enhances controllability while upholding image quality."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The proposed algorithm suggests the potential of harnessing multiple pre-trained models to achieve superior generation results."
            },
            "weaknesses": {
                "value": "This paper is not yet publication-ready. The proposed algorithm appears to be a fusion of two pre-trained models, lacking a demonstration of its non-triviality. Furthermore, the experiments fail to establish its superiority over existing competitors."
            },
            "questions": {
                "value": "1. Why is the inclusion of VQGAN necessary in the pipeline? Could the classifier guidance be directly applied to the diffusion model without VQGAN?\n\n2. How to select the coefficients in Eq. (2)?\n\n3. What accounts for the notably larger variance observed in Table 1 when using the proposed method?\n\n4. The paper would benefit from additional details, including the time and memory requirements for generation and an analysis of each component's contribution through ablation studies."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697619509270,
        "cdate": 1697619509270,
        "tmdate": 1699636791712,
        "mdate": 1699636791712,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uzqmgwfC2k",
        "forum": "RFJGFrMvYj",
        "replyto": "RFJGFrMvYj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_UDgM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_UDgM"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a two-step method for image generation.\n\nFirst, it uses a trained model to create a controlled image.\n\nNext, a diffusion model gives the final image.\n\nThe method is simple but makes sense."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method seems to work.\n\nThe paper is easy to understand.\n\nThe steps are clear."
            },
            "weaknesses": {
                "value": "The method lacks of novelty. Seriously.\n\nIt misses some important related works, e.g., SceneComposer: Any-Level Semantic Image Synthesis, CVPR 2023.\n\nFigures, like Fig. 2, need more details.\n\nMore example images are needed."
            },
            "questions": {
                "value": "Please add FID or CLIP scores for comparison.\n\nThe paper needs more work before it's ready.\n\nBetter figures and more examples will help."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Please review and mention more related works."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Reviewer_UDgM"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697975179377,
        "cdate": 1697975179377,
        "tmdate": 1699636791543,
        "mdate": 1699636791543,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3EBqyvxwKS",
        "forum": "RFJGFrMvYj",
        "replyto": "RFJGFrMvYj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_pNhh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_pNhh"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a two-stage framework to generate controlled images. Specially, the first stage generates a controlled image and second stage for producing final output."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "None"
            },
            "weaknesses": {
                "value": "This paper is too rough and does not meet the standards of top-tier conferences."
            },
            "questions": {
                "value": "This paper is too rough and does not meet the standards of top-tier conferences."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Reviewer_pNhh"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824037910,
        "cdate": 1698824037910,
        "tmdate": 1699636791404,
        "mdate": 1699636791404,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "t7MpTjJ1bl",
        "forum": "RFJGFrMvYj",
        "replyto": "RFJGFrMvYj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_anks"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6839/Reviewer_anks"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a two-stage method to combine controllability and high quality in image generation. In the first stage, the authors utilize pre-trained VQGAN and segmentation models for precise layout control. In the second stage, they feed the generated image to a  diffusion model for a enhanced high-quality result."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Compared to previous one-stage methods, this method divides controllable generation into two steps."
            },
            "weaknesses": {
                "value": "- The motivation of this article is not clear. I hope the author can explain: 1) Why is the controllable generation divided into two steps? 2) Why use VQGAN for the generation model of the first step? 3) What are the advantages of the pretrained model? I see that the first step also requires loss optimization, which will also cause a training burden.\n- The paper does not validate the effectiveness of the proposed method. 1) The final generated results do not align with the segmentation map, which makes me question the controllability of the method. 2) The method does not compare with ControlNet and T2I-adapter, which are state-of-the-art methods in controllable generation. 3) The authors did not choose indicators related to image quality in the experiments. 4) The authors did not verify the effectiveness of each part (including loss designs) of the designed framework separately.\n- This paper is hard to read. The writing needs to be polished."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6839/Reviewer_anks"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698854963530,
        "cdate": 1698854963530,
        "tmdate": 1699636791272,
        "mdate": 1699636791272,
        "license": "CC BY 4.0",
        "version": 2
    }
]