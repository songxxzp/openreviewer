[
    {
        "id": "PqxJlYp4BQ",
        "forum": "WoP9veDwUp",
        "replyto": "WoP9veDwUp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_idd4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_idd4"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the 'task overlap' problem, which enlarges the variance for posterior parameter estimate in GBML. A new approach, LAVA is proposed to alleviate this issue."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. This work identifies the task overlapping issue for GBML.\n\nS2. To overcome the challenge of task overlapping, this work proposes a Hessian aided task adaption, and further employs Laplace approximation, variance reduction, as well as stabilized Hessian for efficiently solving it."
            },
            "weaknesses": {
                "value": "W1. Task overlapping needs more examples. Because this is the core to this work, it is beneficial to provide more real-world examples Current sinusoidal example appears to be oversimplified and not convincing enough.\n\nW2. This work can benefit from additional experiments in real-world scenarios. It seems that on the only real-world dataset, omnioush, the proposed algorithm is not the most competitive."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697984641505,
        "cdate": 1697984641505,
        "tmdate": 1699636604664,
        "mdate": 1699636604664,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gzP9rS7hk3",
        "forum": "WoP9veDwUp",
        "replyto": "WoP9veDwUp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_ciAP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_ciAP"
        ],
        "content": {
            "summary": {
                "value": "The authors characterized task overlap for GBML, and proposed a solution to address high variance in GBML, which reduced the variance of the gradient estimate by weighing each support point individually by the variance of its posterior over the parameters."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea is of task-overlap is good, which is demonstrated in Figure 1.\n\nThe idea of aggregating of parameters is good and new.\n\nThe experiments on the toy example, sine function regression, contain good discussion about the variance reduction."
            },
            "weaknesses": {
                "value": "**The presentation can be further strengthened.**\n\n* The notation keeps changing, which is very unclear. Please make notation clear and consistent.\n* The type of reference, eg. in-text reference, needs to be checked.\n* Eq 1. is not clear. It is better to rewrite the objective.\n\n**Please reconsider the assumptions and Proposition 1.**\n* Eq 3. is unclear, as $D_{\\tau}^{Q}$ is just one realisation of $D_{\\tau}$. It seems that the authors miss another expectation there given that the authors claim that the uncertainty comes from data points.\n* Meanwhile, the authors claim that $D$ is a collection of all tasks, is it finite or countable infinite? Are there any uncertainty in the generating process of tasks themselves?\n* In theory, it is even difficult to have a local solution of MAML's objective. To ensure it, we often need additional assumptions. The assumption 1 and the paragraph underneath do not make sense from a theoretical aspect though the authors try to provide some theory. \n* The definition of $h_\\psi$ on page 5 is problematic as covariance needs to be positive semi-definite.\n* I do not understand why the authors need to have Proposition 1 if it is a well-known result.\n\n\n\n\n**From the experiments in Appendix, it seems that the method does not work well on mini-ImageNet.**"
            },
            "questions": {
                "value": "Why does the proposed method perform worse than MAML on mini-ImageNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698605634673,
        "cdate": 1698605634673,
        "tmdate": 1699636604573,
        "mdate": 1699636604573,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4lsQfq0qp1",
        "forum": "WoP9veDwUp",
        "replyto": "WoP9veDwUp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_mLEP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_mLEP"
        ],
        "content": {
            "summary": {
                "value": "The paper considers improving gradient-based meta-learning from the perspective of approximate bayesian inference. Here the authors show that vanilla MAML\u2019s adaption can be seen as aggregating Gaussian-approximated posterior distribution over each support example with the same covariance matrix. Instead of using the same covariance, the authors apply Laplace approximation so that different support examples have its own covariance matrix (which is the Hessian of the example\u2019s negalive log-likelihood). The proposed method LAVA then uses the Hessian-weighted individual-example-adapted parameters as the final adapted model parameters. The authors show that this new approach reduces the variance of the parameter estimates. Experimentally, results are shown over 3 few-shot regression tasks which demonstrate the performance advantage of LAVA over existing meta-learning methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of aggregating individual example\u2019s posterior distribution in the context of meta-learning is to my knowledge novel.\n- The connection between MAML (which the authors argue treats each example\u2019s posterior covariance as equal) and LAVA (which allows Laplace approximation in individual example\u2019s posterior) is novel and insightful."
            },
            "weaknesses": {
                "value": "Although I find the paper\u2019s proposed idea interesting,  I find the choice of technical language, explanation, and the experimental results a bit lacking in its current form for publication:\n\n- **Method is computationally too expensive**.\n    - Despite the authors performing an analysis in Figure 6 and 7 showing the time cost of 1 inner step of LAVA is comparable to 6 inner steps of CAVIA, it is important to note that this relationship depends on (and should be linear to) the dimensionality of the adaptable parameter space of LAVA, as the Hessian computation takes $O(d)$ backprops where $d$ is the dimension of $\\theta$.  If we choose the number of adaptable parameters to be larger (for example, 100 context parameters in the image classification task in the original CAVIA paper), the computation and time cost of LAVA would be much greater than CAVIA.\n    - Given the worse computation requirement of LAVA compared to CAVIA and MAML, I believe it is necessary for the authors to further discuss and investigate possible techniques for computation savings. For example, instead of computing and storing the Hessian, it is conceivable to use techniques such as 1) only performing Hessian vector products (which only takes constant back props to compute) and 2) using conjugate gradients to approximately find the (inverse Hessian, vector) product. I believe these explorations are necessary for the scaling of the proposed method, as I don't believe purely scaling up the non-adaptable parameters while keeping the number of adaptable parameters to a very small number (e.g. $<10$) can provide sufficient performance in the case of LAVA on real world problems.\n- **Evaluating on problems with higher inherent dimensions** The three few-shot experiments are all internally parameterized by a small number of parameters ($<10$), which might make it appropriate consider LAVA which could adapt a correspondingly small number of context parameters. However, for real world parameters, the inherent problem dimensions could be much higher or unknown. (One experiment setup that more closely captures this property is the image completion task used in CAVIA.) The current experiments in the paper haven't demonstrated the ability of LAVA to handle such problems.\n- **Evaluating on another model architecture.** All the three few-shot experiments are performed using the same 3 layer 64 hidden unit MLP architecture. It is useful to also demonstrate that the proposed method can perform well for other architectures (different computation blocks, depths, and widths).\n- **Comparing gradient-based meta-learning methods under the same number of inner-problem backprops used**. In the experiment section, the authors have reported performances of different baseline gradient-based meta-learning methods. However, it\u2019s not clear to me whether all these methods are restricted to using 1 inner steps (the same as LAVA). If so, I want to highlight that LAVA\u2019s single inner adaptation update step requires number of backprops proportional to the adaptable parameter dimension, while the other methods only need 1 backprop per single inner adaptation step. Thus, for fairness, the authors should also allow the other baseline methods to use the same number of backprops by allowing them to take more inner adaptation steps (preferably during meta-training, at least during meta-test). This might improve the performances of some of the baseline methods.\n- **Unsatisfying explanation on the lack of performance on Mini-imagenet**. In Table 4 in the Appendix, the authors compare LAVA with other meta-learning methods on Mini-Imagenet (arguably the most commonly used few-shot meta-learning benchmark) and find the performance to be worse than many other methods. The authors give an explanation that the few-shot classification classification are inherently discrete problems that do not suffer as extensively from the task overlap. However, this claim seems incorrect to me, as observing a single image, label pair from a few-shot classification task is also insufficient to determine what the rest of the classes are in the task. Thus there is also task overlap according to the authors\u2019 definition. Besides, it\u2019s only unclear how the discreteness of the labels would play a role in this, as the learning parameters $\\theta$ are in a continuous space.\n- **choice of technical language**\n    - **Assumption 1**. It is a bit unclear how to define the optimal $\\theta_{\\tau}^*$. To my understanding, the right-hand side of Equation (6) should not guarantee to be the best possible $\\theta$ in the space $\\Theta$ for the task $\\tau$. Instead, it makes more sense use $\\theta_{\\tau}^*$ to denote the one-step gradient adapted model parameters over an infinite number of support examples sampled from the task $\\tau$. (In fact this is what has been shown in Appendix A.2). However, if more than one gradient steps are taken, the unbiasedness (and thus Assumption 1) would no longer be true.\n    - **Assumption 2**. The notation $f_\\tau(x)$ is defined without exactly specifying what its output means until Assumption 2. Besides, in the interpretation of Assumption 2, the authors mention an alternative formulation is that the conditional task-distribution have a non-zero \u201ccovariance\u201d. However, I believe this terminology should be changed to \u201chaving a non-singleton distribution support\u201d.\n- **Equation 9 is incorrect without additional assumptions**. We notice that the single-example posterior terms on the right hand side is each proportional to product of the example likelihood and the prior $\\propto p(y_i \\mid x, \\theta) p(\\theta)$. Hence the product on the right hand side of Equation 9 would be proportional to the product of $N$ prior probabilities $p(\\theta)^N$. In contrast, the left hand side of Equation 9 is still proportional to only $p(\\theta)$, making the prior weighted more heavily on the right hand side of (9). A way to fix this is to introduce the uniform prior assumption earlier than Equation (9) instead of after.\n- **The explanation of the variance reduction is a bit lacking**. Equation (12) formulates a variance reduction problem. However, the current writing misses the connection to its use of Assumption (1) which would imply that the estimators $Z$ under different values of $\\{W_i\\}$ would have the same expectation. Without clearly specifying this, the variance reduction problem seems out of place and unmotivated."
            },
            "questions": {
                "value": "- On page 5, it was mentioned that \u201cConsequently, it is possible to shape the posterior distribution $p(\\theta | x, y)$ to be normal\u201d. It\u2019s not clear to me how this would be possible for general neural network predictive models. Can the authors further explain this?\n- How many context parameters (adaptable inner loop parameters) are used in the MiniImagenet experiment? How long would the training take compared to other methods on this application?\n- Why are the dotted prior curves sometimes different for the same column in Figure 5 in the Appendix?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5760/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5760/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5760/Reviewer_mLEP"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698607538010,
        "cdate": 1698607538010,
        "tmdate": 1699636604456,
        "mdate": 1699636604456,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IJC8b6fHEm",
        "forum": "WoP9veDwUp",
        "replyto": "WoP9veDwUp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_gPmV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5760/Reviewer_gPmV"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new gradient-based meta-learning algorithm that is able to decrease the variance of the learned parameters. Taking a Bayesian perspective, it weights each of the support data points by the variance of the posterior that it induces over the parameters, approximated using a Laplace Approximations. Experiments show improvements in meta-learning ODEs w/o substantially increasing computation time, but is inconclusive for a real-world physics simulation problem."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "# Originality and significance #\n\nAs far as I know, this paper is the first application of the Laplace Approximation to GBML. The results are promising, so I think this work would be relevant to the community.\n\n# Clarity #\n\nThe paper is written very clearly and is straightforward to understand. The authors explain some of the assumptions made.\n\n# Quality #\n\nThe proposed algorithm is simple and straightforward, with approximate (but incomplete) mathematical backing.  A good diversity of problems and baselines are used in the experiments, and the experimental results are promising."
            },
            "weaknesses": {
                "value": "1. The experiments do not contain ablations in certain axes. The problem dimensionality is varied, but the model dimension (the network architecture) is not.\n2. The assumptions of the algorithm is not clear. The variance calculation implicitly assumes that $\\theta_0$ is deterministic, but is that reasonable given that it depends on previous parameter updates (which are not deterministic)?"
            },
            "questions": {
                "value": "1. The standard errors for the Omnipush results are large compared to the differences in algorithms' performances. Have you tried increasing the number of trials to reduce it?\n2. How do the results vary when the model architecture varies, e.g. when the number of parameters in the neural network increases?\n3. Is there a proof of the claim made in the first paragraph of page 5?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699051240535,
        "cdate": 1699051240535,
        "tmdate": 1699636604353,
        "mdate": 1699636604353,
        "license": "CC BY 4.0",
        "version": 2
    }
]