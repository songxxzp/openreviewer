[
    {
        "id": "gc2J5Wo73S",
        "forum": "gp5dPMBzMH",
        "replyto": "gp5dPMBzMH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_6hGH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_6hGH"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a model named BELT-2 for multi-task EEG-to-Language decoding.  In particular, a discrete conformed is used to convert EEG  into EEG embeddings. Combined with a soft query prompt, the Querying Discrete Conformer (Q-Conformer) enables the multi-task mechanism. The EEG embedding is aligned with BPE tokens and fed to LLM such as T5. The experiment is conducted on an open-source ZuCo dataset to show the effectiveness of BELT-2."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of utilizing the powerful representation ability of LLM for EEG decoding is interesting."
            },
            "weaknesses": {
                "value": "* a) Many of the training details are unclear, which makes it very hard to understand the working mechanism of the proposed BELT-2. I will elaborate in the question section.\n\n* b) The training of the Q-Conformer is based on seven different loss terms \u03bb1(L_cm + L_cb) + \u03bb2 * L_recon + \u03bb3 * L_div + \u03bb4 * L_bpe + \u03bb5 L_neg + \u03bb6 * L_tr with a list of balancing coefficients of [1, 1, 0.001, 10, 0.001, 10]. Training a discrete encoder (Conformer in this case) like VQ-VAE along with the downstream (translation in this case) is not common. From my experience, balancing the reconstruction quality and the code quality itself while training the VQVAE is already a hard task. Thus, I would very much like to know how this model would perform without the quantization and reconstruction. That is to remove L_cm, L_cb, L_recon, and L_div and only use the Conformer as an EEG encoder. Ideally, an ablation study on these loss terms and corresponding curves during training would help the readers understand the different components of BELT-2.\n\n* c) The experimental setting of word-level modeling is questionable. For a regular sentiment classification task, a continuous EEG signal is used as input, yet this work only extracts EEG segments based on eye tracking. Naively speaking, sentiment-related information does not necessarily exist only when the subject is looking at words. Or else, there might be a delay of the reaction in the brain upon reading. Is this considered while aligning the word and EEG?\n\n* d) The word-level modeling seems too artificial to fit the word embedding format to LLM. Sequence-to-sequence modeling would be more interesting and practical. \n\n* e) Speculative Augmentation takes k=15 other copies of the Conformer, which is both computationally and memory expensive.  An ablation on K should also be provided."
            },
            "questions": {
                "value": "* a) The training details of the Q-Conformer is only provided in the appendix but nowhere to be mentioned in the main text. The authors should not use the appendix as additional pages to the paper.\n\n* b) What is the vocabulary used during training the EEG-language alignment? Is it the vocabulary of the ZuCo dataset or the vocabulary of the LLM (T5) ?\n\n* c) It is also not clear what loss function is used to train the multi-task query and which part of the network is updated. Is it the context transformer or the query prompts?\n\n* d) It is not clear why BPE is adopted. What would happen if the contrastive loss is used without BPE, meaning use whole word tokens?\n\n* e) When combining Q-Conformer with  LLM using continuous virtual prompts, how is it trained exactly?  These are not even mentioned in the appendix.\n\nI would like to raise my rating with my concerns and questions addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2330/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698239098391,
        "cdate": 1698239098391,
        "tmdate": 1699636165597,
        "mdate": 1699636165597,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XcYhC4i3JS",
        "forum": "gp5dPMBzMH",
        "replyto": "gp5dPMBzMH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_CXNw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_CXNw"
        ],
        "content": {
            "summary": {
                "value": "The manuscript presents BELT-2, a novel multi-task model that bridges the capabilities of large language models with human brain dynamics, focusing on enhancing the encoding and decoding of EEG signals. With its BPE-level EEG-language alignment and multi-task training, BELT-2 marks a significant breakthrough in EEG decoding. The paper boasts impressive results in multiple tasks, such as EEG-to-Text Translation, EEG Sentiment Classification, and EEG-to-Text Summarization. Notably, the BELT-2 model outperforms the state-of-the-art in several benchmarks, demonstrating its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The manuscript is well composed, with a clear structure and logical flow, enhancing the reader's understanding and engagement.\n2. The experiments are comprehensive. The detailed comparisons to state-of-the-art methods across various tasks, complemented by thorough ablation studies, add significant depth and robustness to the paper's findings."
            },
            "weaknesses": {
                "value": "1. Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to some ambiguity in interpretation. I would recommend the authors to elucidate this procedure in greater detail. Specifically, it would be insightful to understand whether the spatial arrangement of the EEG sensors played any role in this process.\n\n2. The manuscript introduces BELT-2 as a progression from the prior BELT-1 model. However, the discussion and distinction between the two models are somewhat scanty, especially given their apparent similarities. It would be of immense value if the authors could elaborate on the design improvements made in BELT-2 over BELT-1. A focused discussion highlighting the specific enhancements and their contribution to the performance improvements, as showcased in Table 1 and Table 4, would add depth to the paper.\n\n3. A few inconsistencies are observed in the formatting of the tables, which might be distracting for readers. I'd kindly suggest revisiting and refining the table presentation to ensure a consistent and polished format.\n\n4. In Figure 4 and Section 2.4, there is a mention of utilizing the mediate layer coding as 'EEG prompts'. The concept, as presented, leaves some gaps in understanding, primarily because its introduction and visualization seem absent or not explicitly labeled in the preceding figures and method sections. It would enhance coherence and clarity if the authors could revisit Figures 2 and/or 3 and annotate the specific parts illustrating this mediate layer coding."
            },
            "questions": {
                "value": "In the section detailing the experimental setup, the authors introduced the dataset split. Was this split done on a cross-subject basis or just cross-training samples? Given the well-documented variations in EEG signals across different individuals, understanding this aspect is crucial. Will inter-individual variations impact the EEG-to-Language translation performance of the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Reviewer_CXNw",
                    "ICLR.cc/2024/Conference/Submission2330/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2330/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747479296,
        "cdate": 1698747479296,
        "tmdate": 1700727868065,
        "mdate": 1700727868065,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QAFeUaxVk7",
        "forum": "gp5dPMBzMH",
        "replyto": "gp5dPMBzMH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_KLkP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_KLkP"
        ],
        "content": {
            "summary": {
                "value": "This paper presents BELT-2 which learns to perform many EEG-to-language tasks in a multitask setting. Specifically, EEG-to-text, summarization, and classification are learned simultaneously. The architecture consists of an encoder, which is pre-trained with a reconstruction loss. Then, during training time, all objectives for all tasks are optimized for simultaneously. The model can choose to tailor its representations per task, conditioned on a query vector that is also passed as input per task. The authors find that both pre-training and multi-task learning improve performance over the baseline."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Significance: for the tasks considered, the results represent a substantial improvement over existing work\n- Novelty: There is novelty in the application to the EEG domain\n- It's unclear whether BPE-level contrastive learning is a novel method, or novel in the sense that this is the first time that it has been applied to the EEG domain. Could the authors clarify? If it's novel to the field, then this would be a plus for the paper"
            },
            "weaknesses": {
                "value": "- The broader application to the field of machine learning is limited. The key takeaway seems to be the effectiveness of multi-task learning.\n- It seems the main difference between BELT and BELT-2 is the addition of multi-task learning. If this is the case, then the technical advancement may be on the modest side. Although, I would not say this is a large weakness."
            },
            "questions": {
                "value": "- The last sentence on the first paragraph of page 1 says that previous methods have not achieved a \"general bridging between brain signals and languages.\" Can you say more precisely what this means? Does \"general bridging\" refer to the multi-task setting? Is that the main difference between BELT and BELT-2? \n- I have a question about the input to the conformer. Page 3 says that the input is created by \"segmenting the raw EEG waveform signal into windows using eye-tracking information.\" Are the segments of uniform length? If so, then why is the eye-tracking information necessary? If not, then does some sort of truncation or down-sampling occur?\n- I have a question about the multi-task query described on page 4. It says that \"we could easily extend the Q-conformer to a new downstream task by initializing a new set of query tokens to extract information related to the new task, obviating the need for training an entirely new model.\" But is this really a saving in time? Wouldn't the same amount of time be needed to train the new set of query tokens, even if you start with the existing model weights?\n- In section 2.4, it says that \"During the EEG representation learning stage, the Q-Conformer extracts, task-specific information from the EEG input signals.\" But this doesn't seem to be the case? Is Figure 2 left meant to depict the representation learning stage? If so, why aren't there any task-specific terms in the objective function?\n\n## small things\n- Figure 2 -- the captions for (upper right) and (bottom right) are switched\n- To get forward quotes, use `` in latex\n- page 8 typo: \"briding\" --> \"bridging\"\n- typo: the speculative augmentation ablation is Figure 5, not Table 5"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2330/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699424756503,
        "cdate": 1699424756503,
        "tmdate": 1699636165442,
        "mdate": 1699636165442,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VwDIIP5B2z",
        "forum": "gp5dPMBzMH",
        "replyto": "gp5dPMBzMH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_8fpS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_8fpS"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces BELT-2, a multi-task model specifically designed to enhance both EEG signal encoding and decoding performance. BELT-2 incorporates byte pair encoding (BPE)-level EEG-language alignment and seamlessly integrates multi-task training and decoding within the EEG domain."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "a)\tIt\u2019s the first work of multi-task brain decoding by bridging the Q-Conformer EEG encoder and LLMs. \nb)\tIt outperforms the baseline models, demonstrating superior performance."
            },
            "weaknesses": {
                "value": "a)\tThe interaction of all the components in Equation 2 is unclear, and it remains uncertain whether the introduction of certain hyperparameters is necessary.\nb)\tThe organization of the logit structure in the paper appears somewhat disordered, exemplified by an error in the figure caption of Figure 2. I would recommend swapping the content in the upper right and bottom right sections of the figure. Furthermore, the explanation of loss functions on Page 3 does not align consistently with Equation 2.\nc)\tLack of Clarity: The description of \"Multi-task Query\" in the paper is unclear. It is not clear how the query prompt is trained and whether a new task requires complete retraining. Furthermore, there is a lack of clarity regarding how the Frequency domain EEG embedding e is transformed into continuous EEG tokens h, i.e., the learning process of the conformer model E(.), and how it is subsequently transformed into word-level EEG representations.\nd)\tLack of Specificity: If EEG representations are employed using a contrastive learning approach, the method proposed in Section 2.3 appears to be a conventional operation.\ne)\tUnclear Ablation Experiments: The paper does not provide a clear description of the ablation experiments, particularly the absence of ablation on BPE-level Contrastive learning and key components of Formula 2."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Reviewer_8fpS"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2330/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699469390047,
        "cdate": 1699469390047,
        "tmdate": 1700705593544,
        "mdate": 1700705593544,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rEqj5Vkgn5",
        "forum": "gp5dPMBzMH",
        "replyto": "gp5dPMBzMH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_psny"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2330/Reviewer_psny"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel multi-task model, called BELT-2, to enhance both encoding and decoding performance from EEG signals. The experimental results conducted have shown the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The idea of the proposed method to bridge the Q-Conformer EEG encoder and LLMs seems interesting.  \n- The application to EEG data seems novel.\n- The proposed method outperforms some state-of-the-art methods for various tasks.\n- The paper is clear and well-structured."
            },
            "weaknesses": {
                "value": "- The discussion on the difference between BELT and BELT-2 is not sufficient.\n- Some details related to the training and the loss function are not provided."
            },
            "questions": {
                "value": "It is suggested to highlight the difference between BELT and BELT-2, and to provide more precision on the training details and the loss function."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2330/Reviewer_psny"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2330/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699945365981,
        "cdate": 1699945365981,
        "tmdate": 1699945365981,
        "mdate": 1699945365981,
        "license": "CC BY 4.0",
        "version": 2
    }
]