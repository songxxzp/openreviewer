[
    {
        "id": "MRWu2ceUDp",
        "forum": "aEGUT3OGCW",
        "replyto": "aEGUT3OGCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_QPLU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_QPLU"
        ],
        "content": {
            "summary": {
                "value": "This paper talks about on how to add robustness in VIT models, something which was guaranteed in VGG and ResNet. \nThey achieved this using a set patter of modifying last layers of VIT model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* Great theoretical backing for their proof.\n* Mentions initial hypothesis what they are trying to achieve using this task. This is a great way to start any research problem."
            },
            "weaknesses": {
                "value": "* I fail to see lot of practical sense from this paper.\n* Adding some pictorial references to the idea might be able to help readers to grasp the idea completely."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698419409426,
        "cdate": 1698419409426,
        "tmdate": 1699637111015,
        "mdate": 1699637111015,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "w2TBJ6xpho",
        "forum": "aEGUT3OGCW",
        "replyto": "aEGUT3OGCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_ub3F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_ub3F"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a method for provable repair the correction of classification outputs using Vision Transformers on a specified set of images with certain guarantees and with limited degradation of performance (drawdown) on the initial training set. The proposed provable repair method claims that suitable modification of the final fully-connected layer of a vision transformer is sufficient to achieve these goals. Specifically, the paper builds on provable repair methods proposed for DNNs, like MMDNN and APRNN, that, while they cannot be fully implemented in the case of vision transformers (ViTs) due to the presence of self-similarity modules, they can be applied to the last fully-connected layer of ViTs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well written and easy to read. The main ideas behind the proposed method are clearly exposed and their relation to previous work is presented. Based on concepts introduced in the MMDNN and ARPNN works, a modification of the last layers weights is performed by defining a linear programming problem for satisfying the required constrains. To improve the efficiency of the method, the problem is limited only to the class labels contained in the given repair set. Additionally, fine-tuning of the final layer is also applied in an alternating way, to further improve generalization and limit drawdown."
            },
            "weaknesses": {
                "value": "The contribution is somewhat limited, as the main idea is based on similar approaches applied for DNNs, such as MMDNN (Goldberger et al., 2020) and APRNN (Tao et al., 2023). Nevertheless, these methods have been suitably modified for their application in the context of ViTs. \n\nSome aspects of the evaluation could be improved. For example, it is mentioned that standard LP-based repair of the last layer could not be considered due to scalability issues. While this is a major limitation of this baseline, it would be interesting to provide some results on a dataset with a reduced number of categories that would make this comparison possible. Also, another aspect that would be interesting to consider in the ablative study is the performance of the proposed method for large values of K. Is there a maximum K value in practice and, if yes, how can this limit be estimated in practice?"
            },
            "questions": {
                "value": "As stated above, is there a maximum K value inpractice? If yes, is it easy to estimate it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8836/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699274282142,
        "cdate": 1699274282142,
        "tmdate": 1699637110898,
        "mdate": 1699637110898,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WS4tTkq9M9",
        "forum": "aEGUT3OGCW",
        "replyto": "aEGUT3OGCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_CCeY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8836/Reviewer_CCeY"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for provable repair of neural networks by modifying only the weights of the last linear layers so as to maximise the classification accuracy on the repair set. This problem can be cast as a linear program (LP), as previously done in the literature. The novelty of this work that sparsity is taken into account when solving this LP."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed method can exploit the sparsity in the LP (given that the number of labels in the repair set remains small). The results on ViT are quite good."
            },
            "weaknesses": {
                "value": "1. The authors claim that their method has \"provable correctness guarantees\" (all images in the repair set will be classified correctly post-repair), which is of course not true because the final accuracy deepens on the repair set and the capacity of the last layer. (Take the ImageNet training set as the repair set for example, can the method guarantee a 100% accuracy? Obviously not.) This incorrect claim seems to come from a misconception regarding the algorithm, as discussed below in the next point.\n\n2. There's a fundamental algorithmic issue. \"Since FTall only terminates once all inputs are classified correctly, it is a provable repair approach.\" (at the end of section 2), and \"If there is no solution to the LP, the loop continues. Otherwise, the repaired Vision Transformer is returned.\" (at the end of page 5): the authors claim that their algorithm terminates when all the images are correctly classified. The question is: Is it guarantee to terminate?\n\n3. Some other claims are also questionable. For example, \"PRoViT scales to thousands of images\": this depends on the number of classes present in the repair set. For example, if there's only a single class, then this claim becomes uninteresting. \n\n4. Are you sure that the optimization problems in Equations (2) and (3) are linear programs? In addition, please avoid using \"Theorem\" for everything. For example, Theorems 2 and 4 should be stated as remarks, in my opinion. (And perhaps the other ones should be labeled with Proposition instead of Theorem.)\n\n5. Most importantly, the proposed method has nothing to do with vision transformers. It is largely based on existing works, the optimization problem is the same, only the resolution has been improved by taking into account sparsity. And it also works for any models other than ViT (as long as they has a linear layer at the end, which is the case for all common architectures). It happens to work well for ViTs, but there was absolutely no explanation for this phenomenon, and ViTs were also not the motivation for the design of the method, so the title and the framing of this paper seem to use ViTs only to attract attention."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8836/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8836/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8836/Reviewer_CCeY"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8836/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699662423662,
        "cdate": 1699662423662,
        "tmdate": 1699662423662,
        "mdate": 1699662423662,
        "license": "CC BY 4.0",
        "version": 2
    }
]