[
    {
        "id": "DqHOkNqjdT",
        "forum": "o3BxOLoxm1",
        "replyto": "o3BxOLoxm1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_smw4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_smw4"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Manifold Preserving Guided Diffusion(MPGD), a framework that leverages the manifold hypothesis to enhance conditional generation tasks. By guiding the diffusion process using the underlying manifold structure, it achieves better sample quality and faster inference. The authors propose novel training-free methods applicable to both pixel and latent space models, demonstrating improved sample quality and inference speed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The problem that traditional training-free guidance fails to guarantee the interfered results located in the manifold is quite interesting. This seems to exist in a wide range of existing approaches. Beisides, the proposed method is training-free, simple, efficient and easy to be implemented."
            },
            "weaknesses": {
                "value": "- Although the problem to be addressed looks quite fundamental and the presented approach is quite general, the experiments look quite limited. It only contains a restoration task, a face-id transferring task and a style guidance task, which is quite narrow considering that the proposed method is applicable to a lot of editing tasks. Besides, the paper repetitively uses several cases in both the manuscript and the appendix, which looks a bit boring. \n\n- The results of style guidance look not that appealing. \n\n- If possible, user study would make the experimental part stronger. \n\n- There are some typos, e.g., in Eq. 2 (\\alpha_t --> \\alpha_{t-1}) and Fig. 14 (bitterfly --> butterfly)."
            },
            "questions": {
                "value": "Please address my concerns or correct me if there is anything wrong in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Reviewer_smw4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4319/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698683095244,
        "cdate": 1698683095244,
        "tmdate": 1700701775988,
        "mdate": 1700701775988,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PTHWcRS7k7",
        "forum": "o3BxOLoxm1",
        "replyto": "o3BxOLoxm1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_mY9K"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_mY9K"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a guided diffusion model based on manifold preserving. The basic idea is to insert the manifold constraint into the pre-trained diffusion model, by gradient-descent projection of the estimated clean image onto the manifold tangent space. The manifold constraint is implemented by the gradient descent of auto-encoder w.r.t. the estimated clean image. The paper presented theorems for the manifold preserving. The experiments mainly show that the proposed approach achieves high-quality generated image while having 3.8 times speed-up."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The idea of imposing data manifold on the diffusion model using auto-encoder is an interesting idea.\n\n(2) The paper presented sufficient proof for the manifold constraints.\n\n(3) The generated images are overall good, especially with higher generation speed."
            },
            "weaknesses": {
                "value": "1. The paper claimed that the proposed MPGD can generate images with 3.8 times speed up compared with the baseline. The main paper should give more details on why it can speed up with the same number of iterations?\n\n2.  The theoretical analysis on the auto-encoder in theorem 2 says that the gradient of auto-encoder lies on the tangent space of manifold. The analysis relies on the linear manifold hypothesis. Is this assumption realistic for real image set, and how to understand that the image manifold is linear?\n\n3.  In the experiments for super-resolution, there are several methods using diffusion model for image super-resolution or other restoration methods, e.g., Denoising diffusion null-space model, etc. How about the comparisons with these Sota diffusion-based image inverse models?\n\n4. The paper mentioned multi-step optimizations in the manifold projection. How does the number of iterations affect the conditional generation results in quality measures?"
            },
            "questions": {
                "value": "Please refer to the weakness for my questions, mainly on the insufficient experimental justifications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4319/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698717269277,
        "cdate": 1698717269277,
        "tmdate": 1699636400621,
        "mdate": 1699636400621,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ke4wlF2SF4",
        "forum": "o3BxOLoxm1",
        "replyto": "o3BxOLoxm1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_obSn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_obSn"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel way of generating conditional samples from unconditional diffusion models without additional fine-tuning. The method is based on modifying the DDIM sampling algorithm by performing gradient steps on the $x_0$ estimate with an off-the-shelf \"clean-image\" classifier."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors propose a novel and flexible way to utilize the priors of large diffusion models in conditional generation tasks. The main advantage is the ability to use any off-the-shelf classifier to provide guidance, which previously relied on expensive, slow procedures that required multiple optimization steps during sampling."
            },
            "weaknesses": {
                "value": "- The experiments do not clearly demonstrate the idea of guiding the sampling process with an off-the-shelf network. In all three experiments, a reference image is used to guide the sampling. The projection to the manifold in these cases is shown to successfully guide the diffusion towards an image in the reference image neighborhood.  However, it is not clear how that would work in the case where the guidance is given by a more general differentiable loss $L$. This raises the question of whether the proposed method is applicable in cases other than the limited set of inverse problems presented, where the guidance may be less informative. An example would be an $L$ that measures the log-likelihood of an attribute in the image (e.g. blonde hair). \n\n- The qualitative results in Figure 6 raise questions about the diversity of the samples drawn. The generated images shown, are almost all identical and deviate from the distribution of images in the original CelebA dataset (i.e. the colors are completely unnatural). The baseline also performs badly but the distribution seems closer to the original $p(x)$ that the model learned.\n\n- The related works section should be in the main paper. This is necessary to draw clear distinctions between the existing works and the proposed approach and highlight what the authors' main contributions are."
            },
            "questions": {
                "value": "- Could the authors clarify what the $L$ function that is used in the different experiments is?\n\n- Can the authors showcase their method on an experiment that is not based on sampling with a reference image? Is this a limitation of their method or can it be generalized to other formulations of $L$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Reviewer_obSn",
                    "ICLR.cc/2024/Conference/Submission4319/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4319/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698852984494,
        "cdate": 1698852984494,
        "tmdate": 1700498634737,
        "mdate": 1700498634737,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YthDf2lHpw",
        "forum": "o3BxOLoxm1",
        "replyto": "o3BxOLoxm1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_Yt4g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4319/Reviewer_Yt4g"
        ],
        "content": {
            "summary": {
                "value": "The paper applies the manifold hypothesis to enhance the control in unconditional diffusion models. One key finding from the paper is that the guidance term in the diffusion process can potentially have a detrimental effect on the evaluation of the score function. In other words, it can cause deviations from the data manifold and lead to the generation of unrealistic images. To address this issue, the paper suggests a solution where the guidance gradient of clean samples is projected onto the tangent space of the manifold using an autoencoder, allowing the model to stay closer to the manifold."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper presents a versatile idea that can be integrated with existing methods. This approach offers a balance between efficiency and quality, showcasing lower overhead compared to baselines, while also demonstrating improved quality and faster inference speed.\n- The paper provides valuable insights, and these insights are effectively supported by experiments, as in Section 3.\n- The development of the method in Section 4 is presented in a clear and accessible manner. The logical flow and explanations make it easy for readers to follow the methodology.\n- The paper demonstrates thoroughness in its presentation of baselines for experiments in both the pixel space and latent space. The dataset choices are reasonable, coupled with compelling figures and metrics, enhances the persuasiveness of the results."
            },
            "weaknesses": {
                "value": "I don't see major weaknesses in the paper, it is cohesive and well-rounded.\n\n- While the paper appropriately utilizes KID as a less biased metric, it could benefit from including FID (Fr\u00e9chet Inception Distance) as a more widely recognized and standardized metric for related work comparison. The absence of FID makes it challenging for readers to assess the method's performance in relation to existing or future approaches.\n- The paper misses the opportunity to provide insight into failure cases when it comes to text-guided generation. This is particularly important given its widespread use in the community."
            },
            "questions": {
                "value": "- What is the method's guidance consistency in comparison to DDIM?\n- Is there any behavior change in the classifier-free guidance scale for text in the style guided experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4319/Reviewer_Yt4g"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4319/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698879087055,
        "cdate": 1698879087055,
        "tmdate": 1699636400472,
        "mdate": 1699636400472,
        "license": "CC BY 4.0",
        "version": 2
    }
]