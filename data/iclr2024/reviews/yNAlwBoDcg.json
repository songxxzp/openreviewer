[
    {
        "id": "eFcljUvK4f",
        "forum": "yNAlwBoDcg",
        "replyto": "yNAlwBoDcg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_CJku"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_CJku"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes SPLITZ, a new approach for training neural networks with certifiable robustness guarantees by exploiting both Lipschitz continuity and randomized smoothing (RS). The key idea is to split the neural network into two parts, the first part would have constrained Lipschitz constants, while the latter layers are smoothed by randomized smoothing. The authors claim that this new method has the advantages of both certified approaches (Lipschitz continuity and RS) in a single framework.  The authors provide a theoretical analysis to compute the robustness radius for SPLITZ classifiers and demonstrate the effectiveness of SPLITZ with experiments on MNIST, CIFAR, and ImageNet."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This idea is interesting, and given that Lipschitz continuity and randomized smoothing are two well-established methods for certifiable robustness, it is interesting to work toward a unification of the two approaches."
            },
            "weaknesses": {
                "value": "**Major weakness: I believe the paper to be flawed**\n\n- The results on CIFAR10 show an increase of 21.9 points of certified robustness for eps = 1 with the L2 norm compared to the state of the art. This increase is extremely high and, in my opinion, suspicious. I took the time to check the code and it seems that the authors normalize the inputs of the model. The authors mention this in Appendix E.2 DETAILS OF DATASETS. \n\nAfter a review of the code, it seems that the authors use a function called `get_architecture` to initialize the model, this function is defined as:\n\n```\ndef get_architecture(arch: str, dataset: str) -> torch.nn.Module:\n     \"\"\" Return a neural network (with random weights)\n\n    :param arch: the architecture - should be in the ARCHITECTURES list above\n    :param dataset: the dataset - should be in the datasets.DATASETS list\n    :return: a Pytorch module\n    \"\"\"\n    if arch == \"resnet50\" and dataset == \"imagenet\":\n        model = resnet50(pretrained=False).cuda()\n    elif arch == \"cifar_resnet20\":\n        model = resnet_cifar(depth=20, num_classes=10).cuda()\n    elif arch == \"cifar_resnet110\":\n        model = resnet_cifar(depth=110, num_classes=10).cuda()\n    elif arch == \"mnist_lenet\":\n        model = lenet().cuda()\n    normalize_layer = get_normalize_layer(dataset)\n    return torch.nn.Sequential(normalize_layer, model)\n```\n and the `get_normalize_layer` function is:\n\n```\ndef get_normalize_layer(dataset: str) -> torch.nn.Module:\n    \"\"\"Return the dataset's normalization layer\"\"\"\n    if dataset == \"imagenet\":\n        return NormalizeLayer(_IMAGENET_MEAN, _IMAGENET_STDDEV)\n    elif dataset == \"cifar10\":\n        return NormalizeLayer(_CIFAR10_MEAN, _CIFAR10_STDDEV)\n    elif dataset == \"mnist\":\n        return NormalizeLayer(_MNIST_MEAN, _MNIST_STDDEV)\n\n_IMAGENET_MEAN = [0.485, 0.456, 0.406]\n_IMAGENET_STDDEV = [0.229, 0.224, 0.225]\n\n_CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]\n_CIFAR10_STDDEV = [0.2023, 0.1994, 0.2010]\n\n_MNIST_MEAN = [0.1307]\n_MNIST_STDDEV = [0.3081]\n```\n\nIf that's the case, the certified radius should be scaled accordingly, for example, if CIFAR10 images are scaled with \n```\n_CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]\n```\nthen if I'm not mistaken, the certified radius should be divided by `1/min(_CIFAR10_STDDEV) \u2248 5.0`. This would explain the very high certified robustness of CIFAR10.\n\n- Regarding the results on ImagetNet, the results are not better but on par with the state-of-the-art DDS approach (Carlini et al. 2023). This again is surprising given that the authors use a simple ResNet50 while Carlini et al. 2023 have used a combined model (diffusion + ViT classifier BEiT large model) with +800M parameters. Again, the normalization problem could explain this discrepancy. \n\n**Other comments:**\n- The proposed approach has already been investigated in the preprint [1]. \n- The authors do not seem to be aware of a large body of work on Lipschitz networks. The sentence \"Lipschitz constrained training is often only feasible for smaller (few layers) neural networks\" is false. The work of Meunier et al. [2] successfully trained a 1000-layer Lipschitz network by constraining all layers to have a Lipschitz equal to 1. Furthermore, there are many papers that the authors did not acknowledge, the sentence: \"The main challenge is that accurate estimation of Lipschitz constants becomes infeasible for larger networks, and upper bounds become loose, leading to empty bounds on the certified radius.\" is true, but 1-Lipshitz networks actually solve this problem see [2, 3, 4, 5, 6].\n- Using MNIST to demonstrate an adversarial robustness approach is not convincing to me due to the nature of the dataset (toy dataset). \n\n[1] Zeng et al. Certified Defense via Latent Space Randomized Smoothing with Orthogonal Encoders  \n[2] Meunier et al., A Dynamical System Perspective for Lipschitz Neural Networks ICML 2022  \n[3] Araujo et al., A Unified Algebraic Perspective on Lipschitz Neural Networks, ICLR 2023  \n[4] Trockman et al., Orthogonalizing Convolutional Layers with the Cayley Transform, ICLR 2021  \n[5] Singla et al, Skew Orthogonal Convolutions, ICML 2021  \n[6] Prach et al., Almost-Orthogonal Layers for Efficient General-Purpose Lipschitz Networks, ECCV 2022"
            },
            "questions": {
                "value": "Can the authors comment on the normalization issue?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Reviewer_CJku"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698246152414,
        "cdate": 1698246152414,
        "tmdate": 1700620962367,
        "mdate": 1700620962367,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sSLyNsrDD0",
        "forum": "yNAlwBoDcg",
        "replyto": "yNAlwBoDcg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_3vvt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_3vvt"
        ],
        "content": {
            "summary": {
                "value": "The authors present a novel algorithm to obtain certified robustness with high probability (in the sense of randomized smoothing), named SPLITZ. By combining local Lipschitz regularization in the first layer(s) with randomized smoothing in the latent space, the authors improve on the state-of-the-art by a sizeable margin on MNIST and CIFAR-10."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The idea behind the proposed approach is novel and conceptually simple/intuitive: to the best of my knowledge, this is the first work combining Lipschitz-based certified training schemes with randomized smoothing. \nThe paper is mostly well-written, with a clear presentation of the required technical background (sometimes in the appendix) and of the main technical building blocks of SPLITZ.\nWhat stands out the most, though, is the experimental section, showing that SPLITZ outperforms previous approaches (even those using additional data) by a significant margin on both MNIST and CIFAR-10, with the performance improvement increasing with the perturbation radius."
            },
            "weaknesses": {
                "value": "To my mind, the main weakness of the work lies in the introduction of a fair number of hyper-parameters (train-time $\\gamma$, $\\theta$, $\\lambda$), which will inevitably increase the overall runtime overhead of the proposed approach. Analogously, it would be nice to see a detailed analysis of the overhead incurred by the optimization over $\\gamma$ (remark 1).\n\nIn addition, I think that the presentation itself could be somewhat improved in a couple of instances. For instance, the authors repeatedly state that certified training is either randomized smoothing or Lipschitz-based methods, somewhat ignoring the family of methods that train against network relaxations (for instance, IBP, CROWN-IBP, and more recent works such as SABR, TAPS, CC/MTL-IBP, etc.): these methods do not have an explicit Lipschitz estimation. Analogously, it is claimed that a large certified radius is equivalent to a small Lipschitz constant, but such is a sufficient rather than necessary condition for robustness. There is a formatting issue in page 8, where the body of the text and the caption become hard to visually separate.\nFurthermore, some sections are not entirely self-contained: for instance, the paragraph before equation (9) does not explain how LB/UBs are contained, and defers to the appendix important details of the Lipschitz part of the training."
            },
            "questions": {
                "value": "Could the authors provide an indication of the overhead of running SPLITZ (including the hyper-parameter tuning process) with respect to the reported baselines?\n\nThe authors refer to $\\theta$ as a \"learnable\" parameter: do you mean tunable hyper-parameter? If so, why does not $\\lambda$ suffice? \n\nJudging from \"dataset configuration\", it would feel like SPLITZ is quite sensitive to the $\\lambda$ schedule. How was this tuned?\n\nResults on MNIST and CIFAR-10 are remarkable. However, how do the authors explain the fact that performance improvements (if any) upon the baselines are significantly smaller on ImageNet?\n\nIt would be interesting to hear the authors' opinion as to why the effect of the splitting location on performance increases witht $\\sigma$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698603607153,
        "cdate": 1698603607153,
        "tmdate": 1699636076308,
        "mdate": 1699636076308,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Qi13YXcSvd",
        "forum": "yNAlwBoDcg",
        "replyto": "yNAlwBoDcg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_jHmH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_jHmH"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel technique for achieving certified adversarial robustness by combining the principles of Lipschitz bounded networks with randomized smoothing. The approach involves partitioning a neural network into two components, where the first is bounded by a local Lipschitz constraint, and the second is robustified through randomized smoothing. The authors present a training procedure designed to reinforce the respective parts\u2014ensuring Lipschitz continuity in the former and noise resilience in the latter. This allows the model to outperform state-of-the-art L2 certificates for image classification. \n\nThe proposed method has been evaluated on image datasets MNIST, CIFAR-10, and ImageNet. It consistently outperforms the state of the art on MNIST and CIFAR-10 datasets. However, on the ImageNet dataset, it only outperforms the state-of-the-art methods that do not use additional data for some of the certified radii. It does not quite outperform the method that uses additional data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The ideas in the paper are articulated with clarity and are easy to follow.\n2. The paper proposes a novel technique that combines two established methods with considerable efficacy.\n3. Along with theoretical robustness guarantees, it proposes a training procedure to optimize the robustness criteria (Lipschitzness for the first part and robustness to random noise for the second) needed for this method.\n4. It outperforms state-of-the-art techniques of certified robustness for MNIST and CIFAR-10 Image classification datasets."
            },
            "weaknesses": {
                "value": "1. The method does not consistently outperform existing approaches for ImageNet. Specifically, it does not perform as well as DDS, which leverages additional data to improve robustness.\n\nDespite this, the improvement for smaller datasets is noteworthy. Keeping this in mind, I am leaning toward accepting this paper."
            },
            "questions": {
                "value": "Could this technique be adapted to incorporate additional training data (like DDS) to improve its performance on large-scale datasets like ImageNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1475/Reviewer_jHmH"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698779980399,
        "cdate": 1698779980399,
        "tmdate": 1700702238958,
        "mdate": 1700702238958,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6nqX9ADxH6",
        "forum": "yNAlwBoDcg",
        "replyto": "yNAlwBoDcg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_jeFQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1475/Reviewer_jeFQ"
        ],
        "content": {
            "summary": {
                "value": "This paper combines Lipschitz networks with randomized smoothing (RS) to develop the SPLITZ method which splits a classifier into two halves, constrain the Lipschitz constant of the first half, and smooth the second half via randomization. The motivation is that many standard deep networks exhibit heterogeneity in Lipschitz constants across layers, and the proposed method is capable of exploiting this heterogeneity while improving scalability of RS. Training methods and related robustness theory are developed. Numerical results are presented to show that the proposed method achieves good results on MNIST, CIFAR-10 and ImageNet datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed method is more scalable than RS.\n\n2. The idea of exploiting heterogeneity in Lipschitz constants across layers is interesting.\n\n3. Numerical study is quite comprehensive."
            },
            "weaknesses": {
                "value": "1. The idea of combining Lipschitz networks and RS may not be that original. In general, Lipschitz training is not the only way to restrict the Lipschitz constant of networks. One can enforce various network structures so a prescribed Lipschitz constant is ensured. The following paper which appeared in 2021 combines orthogonal Lipschitz layers with RS:\n\nHuimin Zeng, Jiahao Su, and Furong Huang. Certified defense via latent space randomized smoothing with orthogonal encoders. arXiv2021.\n\nTherefore, on the conceptual level, the paper may not be that novel. Btw, the above paper should be cited. \n\n2. The advantage of the proposed method over DDS is not that convincing. I mean, from Table 3, it seems that DDS is better for smaller perturbations?\n\n3. When talking about constraining the Lipschitz constant of networks, the authors mainly focus on Lipschitz training and ignore a large body of works that use prescribed network structures to constrain the Lipschitz constants. The following list of papers is relevant and should be discussed:\n\nTakeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. ICLR, 2018.\n\nQiyang Li, Saminul Haque, Cem Anil, James Lucas, Roger B Grosse, and Joern-Henrik Jacobsen. Preventing gradient attenuation in lipschitz constrained convolutional networks. NeurIPS, 2019.\n\nAsher Trockman and J Zico Kolter. Orthogonalizing convolutional layers with the cayley transform. ICLR, 2021\n\nSahil Singla and Soheil Feizi. Skew orthogonal convolutions. ICML, 2021.\n\nTan Yu, Jun Li, Yunfeng Cai, and Ping Li. Constructing orthogonal convolutions in an explicit manner. ICLR 2022.\n\nLaurent Meunier, Blaise Delattre, Alexandre Araujo, and Alexandre Allauzen. A dynamical system perspective for lipschitz neural networks. ICML 2022.\n\nBernd Prach and Christoph H Lampert. Almost-orthogonal layers for efficient general-purpose lipschitz networks. ECCV 2022.\n\nXiaojun Xu, Linyi Li, and Bo Li. Lot: Layer-wise orthogonal training on improving l2 certified robustness. NeurIPS 2022.\n\nAlexandre Araujo, Aaron Havens, Blaise Delattre, Alexandre Allauzen, and Bin Hu. A unified algebraic perspective on lipschitz neural networks. ICLR 2023.\n\nRuigang Wang, and Ian Manchester. Direct parameterization of lipschitz-bounded deep networks. ICML 2023.\n\n**A big question:Why do not use the above Lipschitz networks for the first half and then integrate RS with the second half? How to compare such a network parameterization approach with the proposed method?**"
            },
            "questions": {
                "value": "1. The idea of combining Lipschitz networks and RS may not be that new. Can the authors be more specific about the unique conceptual novelty of this paper?\n\n2.  From Table 3, it seems that DDS is better for smaller perturbations? Is it possible to make the proposed method achieve better results than DDS even for small perturbations?\n\n3. As mentioned above, there is a large body of literature on parameterizing networks in certain ways to enforce Lipschitz constraints. Why do not use the above Lipschitz networks for the first half and then integrate RS with the second half? How to compare such a network parameterization approach with the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699292518649,
        "cdate": 1699292518649,
        "tmdate": 1699636076149,
        "mdate": 1699636076149,
        "license": "CC BY 4.0",
        "version": 2
    }
]