[
    {
        "id": "axhaPXESGy",
        "forum": "WhgB5sispV",
        "replyto": "WhgB5sispV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission321/Reviewer_8jaG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission321/Reviewer_8jaG"
        ],
        "content": {
            "summary": {
                "value": "This work is on dynamic scene representation and rendering.\nThe authors extend Gaussian Splatting to dynamic scenes by extending the 3D Gaussian formulation with $t$, along with 4D spherindrical harmonics.\nExperiments are conducted on Plenoptic Video and D-NeRF dataset and demonstrate the effectiveness of the proposed method: more realistic and faster.\nAnalysis shows that some primitive underlying 3D movement can be captured."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The extension of 3D Gaussian for dynamic scenes. It allows using 3D Gaussian to render dynamic scenes realistically.\n2. Overall the paper is clearly written and well explained in the motivation, design and implementation.\n3. Superior results compared to very recent SOTA methods include K-Planes, HexPlanes. Higher realism and speed."
            },
            "weaknesses": {
                "value": "* Concerns Regarding Novelty:\n   - The enhanced speed and realism seem to be primarily attributed to the power of Gaussian splatting, rather than the novel modules introduced.\n   - The implementation of 4D spherical harmonics appears to offer only a marginal improvement, as evidenced by the mere +0.2 PSNR increase in Table 3.\n   - The inclusion of time (t) in addition to spatial dimensions $(x,y,z)$ in the Gaussian model appears to be a straightforward extension, akin to extending TensoRF\u2019s triplanes to K-planes.\n* Modeling Concerns: \n   - I have reservations about the authors\u2019 approach of modeling the 4D Gaussian by treating space (xyz) and time (t) equally. This seems to suggest that each Gaussian fades in, peaked at $\\mu_t$ and out, as indicated by the term $p$ in Equations 4 and 10. This is not grounded in physical reality, where Gaussians are expected to move through space rather than appearing and disappearing abruptly.\n  - Consequently, I think this extension mainly increases the model\u2019s capacity to incorporate time and I question whether the proposed approach can yield consistent results in more complex scenarios (e.g., higher moving speeds, sparse observations).\n\n\nThat being said, I think there are more effective ways to extend 3D Gaussian splatting for dynamics with a more accurate and physically-grounded representation. Nevertheless, I still consider this work to be above the bar in this field, providing some insights for the community."
            },
            "questions": {
                "value": "I know these are concurrent work (one even come after ICLR submission deadline). It would be admired if you can add in the final version about comparison to the following two works on extending Gaussian splatting for dynamic scenes.  I have no conflict of interests to these works.\n1. 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering. https://arxiv.org/pdf/2310.08528.pdf\n2. Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis  https://arxiv.org/pdf/2308.09713.pdf\n\nBesides, it would be appreciated if you can apply the proposed method on any urban scenes (e.g. KITTI, Waymo dataset). These are the more challenging and common dynamic scenes in real world."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Reviewer_8jaG"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission321/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698613339980,
        "cdate": 1698613339980,
        "tmdate": 1699635958683,
        "mdate": 1699635958683,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sDyBhWkRRQ",
        "forum": "WhgB5sispV",
        "replyto": "WhgB5sispV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission321/Reviewer_1bTN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission321/Reviewer_1bTN"
        ],
        "content": {
            "summary": {
                "value": "This paper generalizes the 3D Gaussian splitting to 4D. The key contribution is a 4D Gaussian-based representation for dynamic rendering. Unlike intuitively modeling the 4D as canonical 3D + deformations, this paper inserts many 4D bubbles into 4D space-time and jointly assembles the dynamic scenes. \n\nInterestingly, when using full rotational 4D Gaussians, to render a specific time, one just needs to slice the 4D distribution and then do standard 3D Gaussian EWA. The skew in 4D also leads to time-dependent center changing, which leads to local scene flow.\n\nThe proposed representation is tested with the dynamic rendering task on D-NeRF and DyNeRF datasets and shown to be effective. With the power of splitting, the proposed representation achieves high inference FPS."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- It\u2019s interesting to use local 4D Gaussians to represent full 4D functions instead of using explicit flow plus 3D Gaussian.\n- The introduction of full 4D covariance and the usage of the time-dependent harmonics of appearance is effective.\n- The flow extracted from the time-dependent center sliced from 4D Gaussians makes this 4D function approximation more reasonable because it may locally capture correspondence, which introduces the smoothness into the 4D approximation."
            },
            "weaknesses": {
                "value": "- One key weakness the reviewer is curious about is the number of Gaussians in the proposed representation when the video grows longer. And how long does each 4D Gaussian cover in time? If the 4D Gaussians, like the 3D static one, only have local support in time, then the memory or storage consumption may be huge, preventing applying such representation to long videos or streaming.\n- To help the readers understand the 4D Gaussians, one 2D/1D slice + time visualization may be helpful.\n- The LPIPS is not reported in the table while most dynamic rendering does.\n- Although the local flows as I write in the strengths are interesting, the reviewer is wondering how can these local correspondences generalize to global and long-term ones. It\u2019s unclear whether such 4D mixture models can capture long-term tracking."
            },
            "questions": {
                "value": "Pelase see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission321/Reviewer_1bTN"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission321/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698697692810,
        "cdate": 1698697692810,
        "tmdate": 1699635958596,
        "mdate": 1699635958596,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wmD2iRvFAl",
        "forum": "WhgB5sispV",
        "replyto": "WhgB5sispV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission321/Reviewer_XBJp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission321/Reviewer_XBJp"
        ],
        "content": {
            "summary": {
                "value": "This submission introduces a 4D spatial-temporal representation (3D for space and 1D for time) based on Gaussian principles to model dynamic 3D scenes. This representation is a principled extension of the 3D Gaussian representation used in Gaussian Splatting for static scenes. With the 4D Gaussian representation, the states of 3D Gaussians at specific time instances become slices of the 4D function, enabling their rasterization into video frames for forward image rendering and scene reconstruction. The submission demonstrates that by modeling the interplay between space and time, implemented as a non-block-diagonal 4D covariance matrix, we can improve the modeling and reconstruction of dynamic scenes. The paper illustrates that with only the reconstruction loss and no additional regularizations, the 4D Gaussian-based representation achieves superior performance compared to state-of-the-art methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+The proposed 4D Gaussian based representation to model the spatial-temporal field is a very principled extension of the 3D GS method. As a result, the fitting process is robust - no need to introduce additional regularization terms or optimization strategy to make sure the optimization will converge.\n\n+The scene reconstruction using the representation achieves SOTA performance with only reconstruction loss across all experiments.  No manually designed regularization term is needed. This shows the effectiveness of the 4D representation. \n\n+The 4D densification and pruning operations in spacetime can be derived naturally by extending from 3D. As shown in the submission, those operations improve the performance on modeling scene motions\n\n+The paper is well written with consistent and accurate notations, thus easy to follow and grasp."
            },
            "weaknesses": {
                "value": "- more discussion needed for key advantage of the proposed model:\nAlthough in Sec 3.2 and Tab.3, the authors mentioned the benefit of making space and time dependent by allowing non-block diagonal 4D covariance matrix for modeling motions,  it is not easily seen why the performance increase (full version vs \"No-4DRot\"). The visualization of temporal slices of the fitted 4D Gaussian could be helpful to demonstrate how the corresponding 3D Gaussian across frames models motions\n\n- more discussion on design choice needed:\nThe 4D SH function is also a function of time t, will it also explain the temporal appearance change (eg. motion)? if so, it is explaining the properties we did not intend it to (we use it for view-dependency), and it may interact with other optimized variables such as 4D rotation to explain the motion, will it lead to ambiguity and affect the performance of dynamic modeling ?"
            },
            "questions": {
                "value": "1. The number of 4D Gaussians might be huge (millions in 3D GS paper), given that one more temporal dimension in addition to 3D space as in 3D GS. Can the author address that, since that might be one limitation of the Gaussian based representation?\n\n2. Are the 4D means of the Gaussians also being optimized? If so, the 4D means can also introduce displacements to 3D Gaussians. In other words, both 4D mean offsets, and 4D rotation can lead to displacements. Will this introduce ambiguity to explain the scene flow field?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission321/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814327704,
        "cdate": 1698814327704,
        "tmdate": 1699635958488,
        "mdate": 1699635958488,
        "license": "CC BY 4.0",
        "version": 2
    }
]