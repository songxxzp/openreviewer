[
    {
        "id": "6q372dlc97",
        "forum": "YVQkVnS1XK",
        "replyto": "YVQkVnS1XK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_Cwsn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_Cwsn"
        ],
        "content": {
            "summary": {
                "value": "In this paper, a robustness dataset and metrics are proposed to bridge the gap between academia and industry. But the paper is not well organized. The illustration of the proposed metrics and experiment setting are not clear. Besides, the dataset should be evaluated with more state-of-the-art methods."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tAn explainable AD dataset XIMAGENET-12 is generated to s to bridge the gap between academia and industry. The XIMAGENET-12 dataset possesses various annotation categories, relatively high image information quality, and public availability.\n\n2.\tA model robustness score formal schema is proposed to evaluate the model\u2019s robustness."
            },
            "weaknesses": {
                "value": "1.\tThe paper is not well organized. The Section4 our robustness score framework should be in front of the Section3 Experiment.\n\n2.\tThe dataset should be evaluated with the state-of-the-art backbone. The lasted model is ViT proposed in 2020 in your paper only in Ex3. The figures are to big and not well typesetted.\n\n3.\tThe formulation of the proposed robustness score is confused. The difference of the first two equations are not illustrated, such as C and C\u2019.\n\n4.\tLack of illustration that how the dataset can bridge the gap between academia and industry\n\n5.\tLack of result evaluation for Ex2 and Ex3. And in Ex2, it seems you should cite Tab.2 instead of Fig2 in Section3.3.\n\n6.\tThe evaluation metrics are not explained in the experiments\n\n7.\tThe evaluation of the proposed robustness score should be in the main body not in the appendix."
            },
            "questions": {
                "value": "1.\tWhat\u2019s the meaning of the evaluation metrics in Table1, Table2.\n\n2.\tIn Results on Transformer-based methods. Blur Background has more influence than Blur Object images. What\u2019s the reason?\n\n3.\tMany results in appendix seems to be redundant. They are not mentioned in the main body or the appendix, such as Fig3, Fig8\n\n4.\tSome typos: \n\na)\tthe first GenAI in contribution1 is needless.\n\nb)\tin Ex2, it seems you should cite Tab.2 instead of Fig2 in Section3.3."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7250/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698666894211,
        "cdate": 1698666894211,
        "tmdate": 1699636864150,
        "mdate": 1699636864150,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tSYFFRWB7c",
        "forum": "YVQkVnS1XK",
        "replyto": "YVQkVnS1XK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_eyGx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_eyGx"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces XIMAGENET-12, a new benchmark dataset for evaluating model robustness in explainable AI settings. The dataset contains over 200K images across 12 ImageNet categories with manual pixel-level annotations. It covers 6 scenarios like blurring, color changes, and generated backgrounds to simulate real-world variations. The authors propose a robustness score based on accuracy variance across scenarios and classes. Through experiments on classification, detection, and segmentation models, they find that introducing generated backgrounds causes significant performance drops. The key contributions are:\n1. XIMAGENET-12, a large-scale robustness benchmark with pixel labels and simulated scenarios.\n2. A robustness scoring method based on accuracy variance.\n3. Analysis showing transformer and CNN models are sensitive to generated backgrounds."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The dataset provides plenty of semantic annotation, which is useful for robustness research on segmentation task.\n2. The scenarios are diverse and simulate practically relevant issues like blurring.\n3. The robustness score provides a simple metric for model evaluation and comparison."
            },
            "weaknesses": {
                "value": "1. More details could be provided on the data annotation process and quality control.\n2. The robustness score could be evaluated more thoroughly as a metric.\n3. The writing quality could be improved in some areas for clarity and concision.\n4. Ablation studies compared to other datasets are limited.\n5. This benchmark seems like a two-task benchmark, only for segmentation and classification."
            },
            "questions": {
                "value": "This article uses a large number of synthetic images, and there is a gap between natural images and synthetic images. Are the training and conclusions on synthetic images useful for real-world scenarios and nature images?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7250/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668382206,
        "cdate": 1698668382206,
        "tmdate": 1699636864048,
        "mdate": 1699636864048,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DrKvimbtcT",
        "forum": "YVQkVnS1XK",
        "replyto": "YVQkVnS1XK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_WJcw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7250/Reviewer_WJcw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a dataset for measure the robustness of vision models, the dataset covers 12 categories from ImageNet, and with manual labeling of the segmentation mask, 6 scenarios with different background are introduce to test the robustness of vision models. Experiments show some what a performance degradation of state-of-the-art vision models on the proposed benchmark."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. I think the P value in the evaluation is a good point.\n2. Testing images with different background indeed is a challenging scenario for vision models."
            },
            "weaknesses": {
                "value": "1. The presentation of paper is not clear, the paper did not even give the name of the 12 selected categories.\n2. The paper claims that the proposed dataset bridge the gap between academia and industry anomaly detection models, but from the current text, it is hard to see the relationship of the proposed benchmark to anomaly detection.\n3. It seems that the images is taken from the ImageNet training set (since each categories have 1300 images which is the number of images in the training set for each class), how these training set images can be used for evaluating the performance of models that have already been trained on ImageNet?\n4. It is very hard to parse the main results of the evaluation."
            },
            "questions": {
                "value": "1. Is that images from the ImageNet training set? If so, what is the rationale that these images can be used to test models that have already trained on it?\n2. Please summarize the main results or conclusions of the evaluation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7250/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698915024404,
        "cdate": 1698915024404,
        "tmdate": 1699636863951,
        "mdate": 1699636863951,
        "license": "CC BY 4.0",
        "version": 2
    }
]