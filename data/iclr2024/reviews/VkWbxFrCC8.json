[
    {
        "id": "DZri1qpsQ8",
        "forum": "VkWbxFrCC8",
        "replyto": "VkWbxFrCC8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_DDkv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_DDkv"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces RECOMBINER, an extension of the previous COMBINER implicit neural representation method for achieving neural compression. The new work includes a few model variations from the original COMBINER, including 1) a model parameter reparametrization, 2) the inclusion of positional encodings, and 3) a patch processing mechanism to handle large images. For these new model complexities, the paper also proposes an altered training procedure for fitting the parameters and the variational model. The paper considers numerical experiments for image, audio, video, and protein data. On image data, the proposed method outperforms VAE-based alternatives at low bitrates. On audio data, the proposed method outperforms the compared methods. On video data, the proposed method outperforms H.264/H.265 when H.264/H.265 are not in quality mode. The paper also validates its changes with ablation experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper proposes a series of changes in COMBINER that result in good improvements to performance on all tasks where there is data for both methods (RECOMBINER and COMBINER were not compared for video and protein data).\n2. The paper looks a large variety of tasks - most compression papers would only focus on one of these tasks.\n3. The mathematics for the reparametrization are presented clearly and intuitively.\n4. The patch-level processing for high-resolution data is a particularly welcome modification for image compression."
            },
            "weaknesses": {
                "value": "I am waffling on this paper a little bit largely due to the comparisons. Some of the tasks seem a little bit selective in terms of baselines. I raise a few points below.\n\n1. Despite the improvements, overall INRs continue lag behind performance of competing methods on 3 out of 4 tasks.\n2. INR performance comes at a compute cost penalty. This would be particularly large in the case of the video and image codec comparisons.\n3. Errors for the protein data seem quite large, and I don't think the benefit of rate control is particularly useful for this setting. The paper presents RECOMBINER as an option here, but when the rate is lower than the competing methods, the error approaches the machine resolution. RECOMBINER only matches competitor compression performance at high rates.\n4. Many neural methods for compression (particularly for audio) rely on perceptual compression rather than rate-distortion as is experimented with in the present paper. The paper does not consider how RECOMBINER could be adapted to become a perceptual codec.\n5. Older image compression methods are used as baselines. The handcrafted baseline of choice is now VTM, and the baseline neural image compression is ELIC (He, 2022).\n\nHe, Dailan, et al. \"Elic: Efficient learned image compression with unevenly grouped space-channel contextual adaptive coding.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "1. Do you think there is a mechanism where RECOMBINER could be adapted to a perceptual codec?\n2. Did you consider other neural audio compression methods? Encodec (Defossez, 2022) is one of particular note.\n3. How are Fourier embeddings computed for protein and video data?\n\nD\u00e9fossez, Alexandre, et al. \"High fidelity neural audio compression.\" arXiv preprint arXiv:2210.13438 (2022)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Reviewer_DDkv"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698714014926,
        "cdate": 1698714014926,
        "tmdate": 1700513609929,
        "mdate": 1700513609929,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6lNab7QIj9",
        "forum": "VkWbxFrCC8",
        "replyto": "VkWbxFrCC8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_TTUk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_TTUk"
        ],
        "content": {
            "summary": {
                "value": "This paper improves the most recent implicit neural representation (INR) compression method, called the COMBINER, and proposes a robust and enhanced COMBINER, thus named as RECOMBINER. The enhancements are mainly from the layer-wise block diagonal matrix in factorised Gaussian assumptions to increase the flexibility of overfitting data, additional positional embedding to address the local patterns, as well as the hierarchical model to compress high-resolution images. Experimental results verify the effectiveness of this improved COMBINER method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper improves the existing COMBINER method, with robust and enhanced performances on data compression. The improvements are reasonably established, upon the stringent factorised Gaussian assumption as proposed in the original COMBINER method. A block-wise diagonal method does much help during training and inferencing.\n2. This paper proposes the hierarchical strategy to accommodate the compression for high-resolution images. The optimisation is supported by minimising the upper bound when splitting into patches.\n3. Experimental results have verified the effectiveness of the proposed RECOMBINER method. Although not beating the state-of-the-art VAE based methods, I still value this work to be a promising alternative direction for learnt data compression."
            },
            "weaknesses": {
                "value": "1. The quality of this paper needs to be comprehensively improved, whereby many typos exist. For example, \"have a neural network memorize the data (Stanley, 2007) and encode the network weights instead.\".\n2. For the linear reparameterization module, why A^[l] is updated during the training stage? Also the authors claim that the block-wise diagonal matrix operates as good as the full covariance matrix. Is any verification on this, from either theoretically or emperically?\n3. For the learnt positional embeddings, I am a bit confused on using additional position cues. Since x_i also includes the coordinate information, why using z_i helps to address the global representation challenge?"
            },
            "questions": {
                "value": "Please see my weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699029463328,
        "cdate": 1699029463328,
        "tmdate": 1699636209527,
        "mdate": 1699636209527,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iwe3oyruWg",
        "forum": "VkWbxFrCC8",
        "replyto": "VkWbxFrCC8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_oN2Z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2684/Reviewer_oN2Z"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes three additional techniques that can be used to improve COMBINER, an INR-based modality-agnostic data compression framework. (1) Linear Reparameterization: One places Gaussian factorized priors on the latent codes, instead of the weight parameters themselves. (2) Learnable Positional Encodings: One generates positional encoding from some lower-dimensional learnable latent code, which is mapped to the full-dimensional space through upsampling and convolution. (3) Hierarchical Bayesian modeling on patchified data: One divides the data into patches and models it with hierarchical Bayesian approach. These changes make the modified version (called RECOMBINER) achieve the performance comparable to SOTA codecs and a competing INR-based approach (VC-INR)."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The performance gain over the previous attempt in this direction (i.e., COMBINER) is indeed very impressive. The innovations introduced in this paper seems to make the combiner-like approach a competitive paradigm for INR-based data compression.\n- All three proposed modifications are technically well-designed and well-motivated. Especially, the hierarchical Bayes approach in section 3.3 looks quite clear and intuitive.\n- The writing is very clear. The paper is one of the most easy-to-read papers among all papers I read in the past several months.\n- The empirical validation is quite extensive, covering image/video/audio to protein structures.\n- Appendix E, which describes the things that didn't work, is very useful and a good academic practice."
            },
            "weaknesses": {
                "value": "- **R-D tradeoff on image.** While it is definitely good to see that recombiner outperforms combiner, the performance does not clearly outperform VC-INR, an even older baseline. I do not see this as a very big drawback, but this observation makes it quite questionable whether combiner-like approach has any great potential in the long run.\n\n- **Comparison on audio/video.** I wonder how the RECOMBINER compare with VC-INR and COIN++ on audio/video datasets. The paper says that it does not compare with these baselines, because \"the works use different data splits.\" I do not think this is a good excuse to not compare with these baselines. It seems evident that recombiner outperforms combiner, but in the end, we would like to understand whether the combiner-like approach is indeed a useful framework, when compared with other INR-based paradigms (and furthermore, VAE-based ones).\n\n- **Limited range of bitrate in comparison---problems in extending to higher bitrates?.** Comparing with baselines, the range of bitrates considered is considerably smaller. For Kodak, VC-INR compares on the bitrate up to 3.5, while this work only considers up to 1.2. For videos, the range is again up to 1.2, while VC-INR does it to over 4. The same for the audio. I wonder why the authors made this choice. Does this mean that recombiner has difficulties in training in high bpp regime?\n\n- **(minor) Practicality.** Not a big issue for a research-in-progress, but the long encoding/decoding time is a severe practical limitation (appendix d.4). I wonder how these computational costs compare with the baselines; it would be a great help if authors could give an explicit head-to-head comparison with combiner, coin++, and vc-inr.\n\n- **(minor) Limited Impact of Technical Contributions.** Given the lukewarm performance gain over competing paradigms, it would be great if the proposed technical innovations are very novel or have a wider applicability to other fields of machine learning. I am not sure if this is the case; the linear reparameterization and learned positional encodings are either not very new or highly specialized to the context of recombiner. I do appreciate the technicality of the hierarchical Bayes part, but some components are somewhat mysterious to me (the strange importance of random permutation) and the idea may not have a wider impact outside this specific context.\n\n- (minor) the last row of the legend in figure 5c is wrongly ordered?"
            },
            "questions": {
                "value": "In addition to the requests in \"weaknesses,\" I have one more question:\n- The figure 5c is very interesting, in the sense that using the tricks without random permutation is almost the worst among all choices (brown). Do you have any explanation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2684/Reviewer_oN2Z"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699113919112,
        "cdate": 1699113919112,
        "tmdate": 1700742204262,
        "mdate": 1700742204262,
        "license": "CC BY 4.0",
        "version": 2
    }
]