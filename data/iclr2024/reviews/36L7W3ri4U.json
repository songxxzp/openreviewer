[
    {
        "id": "PYdg7hZzBO",
        "forum": "36L7W3ri4U",
        "replyto": "36L7W3ri4U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7062/Reviewer_ycpS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7062/Reviewer_ycpS"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the convergence properties of q-replicator dynamics in continuous-time potential games. Potential games are a special class of general-sum games in which player utilities can be represented by a potential function. q-replicator dynamics are a class of learning dynamics which take a hyperparameter $q$ as input. If $q=0$ gradient descent is recovered, if $q=1$ replicator dynamics are recovered, and if $q=2$ log-barrier dynamics are recovered. The authors show that q-replicator dynamics converge pointwise to Nash equilibria in a subclass of potential games called Perfectly-Regular Potential Games (PRPGs), which capture almost all finite potential games. \n\nHaving established this result, the authors are interested in analyzing which equilibria are converged to when all players in a game employ q-replicator dynamics. Their main metric of performance is the average price of anarchy (APoA), which measures the price of anarchy, on average, with respect to a uniformly random initialization of the q-replicator dynamics. The authors' main theoretical contributions come in the setting of 2-by-2 PRPGs. In particular, they find that the APoA of running gradient descent is higher than the APoA of running replicator dynamics in 2-by-2 PRPGs if and only if the payoff-dominant equilibrium is also risk-dominant. Here, the \"payoff-dominant\" equilibrium refers to the equilibrium with the highest utility, and an equilibrium is \"risk-dominant\" if it is unilaterally optimal against the uniform distribution of the rest of the agents. \n\nThe authors compliment their theoretical results in 2-by-2 PRPGs with numerical simulations in higher dimensions. They find that, in line with their theoretical results in 2-by-2 games, gradient descent outperforms the replicator dynamics in all diagonal games (i.e. games in which the only non-zero elements of the payoff matrix are along the diagonal). Throughout the submission, the authors provide proof sketches and intuition for their results."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The problem of analyzing the convergence guarantees of learning algorithms in games is not a novel problem, but is of great interest to the game theory community. Additionally, obtaining results in this area has traditionally been challenging. While the authors restrict themselves to a subclass of two-by-two potential games, the authors' results are novel and their analysis helps shed some light on this important issue by comparing the convergence properties of gradient descent and replicator dynamics, two canonical algorithms for learning in games. I found the paper to be well-written, and I appreciated the authors' efforts to provide intuition for their results and why they cannot be easily extended beyond the two-by-two setting they consider. The numerical simulations in settings beyond two-by-two games are also a strength, as they help shed light on this problem in a more general setting, despite the issues with extending the authors' theoretical results."
            },
            "weaknesses": {
                "value": "One weakness is the restriction to the setting of 2-by-2 Perfectly-Regular Potential Games. However given the challenge of analyzing the convergence dynamics of learning algorithms in games, this is not a large weakness."
            },
            "questions": {
                "value": "Why focus on metrics which measure performance with respect to random initialization instead of other methods of initialization, e.g. initializing to the uniform distribution over actions as is canonical in the literature on learning in games?\n\nDo you have any insights on how your results would carry over to the discrete-time setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Reviewer_ycpS"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7062/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698621779279,
        "cdate": 1698621779279,
        "tmdate": 1699636831404,
        "mdate": 1699636831404,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "R7UbfC64jj",
        "forum": "36L7W3ri4U",
        "replyto": "36L7W3ri4U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7062/Reviewer_xUnV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7062/Reviewer_xUnV"
        ],
        "content": {
            "summary": {
                "value": "A long line of work in algorithmic game theory has sought to bound the difference between selfish outcomes and socially optimal outcomes. However, these ``Price of Anarchy\" (PoA) bounds hold in a worst-case sense, and need not faithfully represent the real-world performance of concrete dynamics. This work considers the average-case PoA (APoA) of a large family of dynamics, namely Q-Replicator dynamics, in potential games. The main contributions of this work are threefold: first, it is shown that almost all potential games are such that Q-replicator dynamics initialized on any interior point converges to a (finite set of) Nash equilibrium. In particular, this makes average-case notions of PoA almost always well-defined. In the case of 2x2 games, this paper provides a complete characterization of the regions of attraction for different equilibria. The main applications are to exactly characterize in which 2x2 games gradient descent dynamics has a better APoA than replicator dynamics, and moreover, bound the APoA of gradient descent when the payoff- and risk-dominant Nash equilibria coincide. Finally, preliminary empirical evidence is given to suggest that certain generalizations of the results are possible."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The conceptual questions addressed by this work are quite interesting. On a technical level, the analysis provides a nontrivial extension of existing work on the performance of these dynamics. The paper is itself quite well-written and the results are supplemented with empirical evaluations that validate the results and suggest intriguing future directions."
            },
            "weaknesses": {
                "value": "The theoretical results, while very nontrivial, currently only hold for 2x2 games, and it is not clear conceptually or technically what an appropriate generalization would be. The paper could benefit from a bit more discussion about the technical differences with prior work (i.e. that of Panageas and Piliouras [EC'16])."
            },
            "questions": {
                "value": "Recommendation: While I only have a passing familiarity with this line of work, my general impression is that work has very interesting conceptual takeaways. While there is some concern about how general these findings are and the extent to which they might generalize, my current belief is that this work makes interesting progress on the quality of important learning outcomes that would be of interest to the community. For now, I am leaving my score as a 6, but I could increase it in light of other reviewer comments/discussion of the technical novelty compared to Panageas and Piliouras [EC'16].\n\nComments:\n\n---The conceptual goal of providing more refined PoA guarantees for concrete dynamics is a very interesting direction that deserves further study, in my opinion. \n\n---While this work does give good discussion on how the current paper extends the original results of Panageas and Piliouras, it may be worth providing a short discussion on the technical differences that allow these extensions. This would also help convince the reader of the novelty of these results.\n\n---As mentioned above, the main weakness is that the concrete theoretical results on APoA are localized to 2x2 games. It isn't entirely clear what an appropriate generalization would look like with more agents and larger action spaces, and of course, one imagines that the technical analysis quickly becomes intractable. But progress on these questions has to start somewhere and my current impression is that this paper indeed takes steps towards these aims that would be of value to the community."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7062/Reviewer_xUnV"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7062/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807269800,
        "cdate": 1698807269800,
        "tmdate": 1699636831189,
        "mdate": 1699636831189,
        "license": "CC BY 4.0",
        "version": 2
    }
]