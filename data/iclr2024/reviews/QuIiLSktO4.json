[
    {
        "id": "IkgIEtN4z6",
        "forum": "QuIiLSktO4",
        "replyto": "QuIiLSktO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_utqC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_utqC"
        ],
        "content": {
            "summary": {
                "value": "This paper considers online caching and metrical task systems (MTS) in the popular algorithms with predictions framework.  Following recent related work due to Im et al. 2022, they consider reducing the number of predictions utilized by the algorithm.  This paper differs from that one in two respects:\n - This paper considers action predictions as introduced by Antoniadis et al. which are different from the usual notion of \"next-arrival-time\" predictions as used by Lykouris and Vassilvitskii 2021, Rohatgi 2020, and Im et al. 2022.\n- In addition to considering bounded number of predictions as in Im et al. 2022, they also propose studying well-separated queries to the predictions.  In this setting there is a lower bound on the number of time steps between queries to the predictions.  This is motivated by settings where we may not be able to immediately query the prediction.\n\nThe main theoretical results are as follows:\n- An algorithm for caching with robustness $O(\\log k)$, smoothness $O(f^{-1}(\\eta / OPT))$ and using at most $O(log k)OPT$ queries to predictions.  $f$ is an increasing function with some restrictions.  Examples of the relationship for different $f$'s are described.\n- A lower bound of $f(\\ln k) OPT$ queries to the predictor for any algorithm that is $f(\\eta)$ smooth.\n- For MTS, the authors study well-separated queries that arrive once every $a$ steps and give an algorithm with cost $O(a)(OPT + 2\\eta)$ and give a nearly tight lower bound.\n\nTo complement these, several experiments using datasets that have been utilized in prior work are carried out, comparing the proposed algorithm to the algorithms proposed in several prior works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Developing algorithms which make use of predictions economically is an interesting question that has arisen recently\n- The result for caching gives a nice way of quantifying the trade-off between number of predictions and smoothness through the function $f$, although it is a little more difficult to interpret than say the result in Im et al. 2022.\n- The experimental results are promising"
            },
            "weaknesses": {
                "value": "- The writing and grammar needs improvement at certain points (see below for more specific comments)."
            },
            "questions": {
                "value": "### Major Questions and Comments\n\n- The motivation for well-separated queries is settings in which the waiting for the query to be produced may take a number of time steps to produce.  Have you considered a setting where the prediction queries are explicitly delayed?  For example, based on the state of the algorithm at time $t$, we make a query to the predictor, but the result does not arrive until time $t+a$.  So predicted information is directly more costly in the sense that it may no longer be \"fresh\" or as useful when we receive it.\n- For MTS, you are unable to give a bound on the number of predictions that scales with $OPT$ since the adversary can scale the instance to make $OPT$ arbitrarily small.  Can the absolute number of predictions be bounded?  For example is it possible to use $o(T)$ queries to the predictions for this setting, or is this impossible similar to the lower bound in Theorem 1.4?\n\n\n### Minor Comments\n - First page, third paragraph - \"Online nature of ...\" -> \"The online nature of ...\"\n - Second page, second new paragraph - \"Using method of Blum and Burch ...\" -> \"Using the method of Blum and Burch...\"\n - Several places - In case of caching ...\" -> \"In the case of caching\"\n - Please make general improvements to the grammar.\n - Page 6, first paragraph - \"$f(i) \\leq 2^j - 1$\" - should this be $f(i) \\leq 2^i - 1$?  I don't see $j$ defined nearby...\n - For the synthetic noise a log-normal distribution is used.  I believe you meant the parameters for this distribution are $\\mu = 0$ and $\\sigma \\in [0,50]$.  The mean of a log-normal distribution cannot be 0...\n - In the captions for Figures 1 and 2, please clarify if the standard deviation reported is for the competitive ratio averaged over many trials (and not the noise for the synthetic predictions), and how many trials were used for this average if so."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5029/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698436150128,
        "cdate": 1698436150128,
        "tmdate": 1699636492038,
        "mdate": 1699636492038,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "S0kwcY6mBd",
        "forum": "QuIiLSktO4",
        "replyto": "QuIiLSktO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_bwNg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_bwNg"
        ],
        "content": {
            "summary": {
                "value": "This paper studies online algorithms for caching (and more generally MTS) with predictions. The considered prediction is \u201caction prediction\u201d, which tells what (the ideally optimal) algorithm does. The goal here is not only to achieve a good prediction error vs competitive ratio tradeoff, but also to use fewer predictions, through queries to the action prediction.\n\nThe results look very general and strong. The main results are about caching with size k. It shows for a large class of functions f, the algorithm uses f(log k) * OPT predictions, achieves consistency 1, robustness O(log k) and smoothness O(f^{-1}(\\eta / OPT)), where \\eta is the number of wrongly predicted actions. Furthermore, these bounds are also justified by nearly matching lower bounds.\n\nTechnically, the caching algorithm first tries to follow the prediction, and if the prediction \u201clooks bad\u201d, it switches to a modified Marking algorithm to preserve the robustness. But to preserve consistency, this modified Marking is run for only O(k) distinct requests and will switch back to follow the prediction again. This algorithm is intuitive, but the analysis is very involved, especially to deal with the randomness of the Marking algorithm and to control the number of predictions used.\n\nFor the MTS problem, it does not make much sense to aim for a query complexity bound like f(\\cdot) OPT, and the paper turns to put a constraint that the algorithm can only make a query every $a$ steps, where $a$ is some parameter. This also makes the techniques very different from the caching algorithm."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- I\u2019m impressed by the results and techniques.\n\n- The paper is very clearly written, and the comparison to previous works is adequate.\n\n- This paper has a very comprehensive discussion of how to potentially implement the predictor and the ways to tune the algorithm for better practical performance \u2014 I find this very helpful."
            },
            "weaknesses": {
                "value": "- The MTS part does not seem to connect well enough to the rest of the paper which mainly focuses on caching; especially I cannot see the tight relation in terms of algorithms/techniques.\n\n- The experiments only show a marginal advantage over baselines on real datasets."
            },
            "questions": {
                "value": "- In Section 1.1, it is not clear enough what \\eta means without reading later parts of the paper, particularly what it means by \u201ctotal error\u201d (mentioned in the first paragraph of Section 1.1). Some intuitive explanations would be helpful. Furthermore, it may look like the meaning of \\eta is different between Theorem 1.1 and Theorem 1.3, and this should be clarified, too. (By the way, this is not clearly discussed even in Section 2.1.)\n\n- Theorem 1.2: \\eta is not quantified; I guess we should say \u201cfor every \\eta > 0\u201d?\n\n- In Section 2.2, it is assumed that the predictor is trying to simulate Belady. Is this without loss of generality?\n\n- In Algorithm 2, is $S$ a set or a sequence? I don\u2019t find S = [ xxx ] a standard notation. Also, S[I] does not look standard, either.\n\n- In Algorithm 2, line 4, is this to define $F$?\n\n- In Algorithm 2, line 4, how is p chosen?\n\n- In Algorithm 2, I find additional whitespace before \u201c;\u201d in lines 6 - 8.\n\n- Section 3, it\u2019s better to give some \u201ccomment\u201d in the algorithm (or somewhere in the main text) to describe what F and S stand for.\n\n- Page 6, there\u2019s a paragraph about \u201cimplementation suggestions\u201d. This paragraph is not directly related to the proof of the main theorem, so it is slightly out of context. Maybe move it to the end of the section, or somewhere in the experiments section?\n\n- Page 7, 2nd paragraph. What is G_{i, I+1} exactly? In particular, what does \u201cgap\u201d mean? I\u2019m not even sure if this is a number or a subset when I first read it.\n\n- Page 7, 2nd paragraph. What do you mean by \u201cperiod\u201d X? Maybe you simply say X is a sequence of requests.\n\n- I tried to read the proof of Lemma 3.3, but I didn\u2019t find a clear place for \u201cRobust_f uses at most f(log k) predictions\u201d. Where is it? Also, does this bound depend on the randomness?\n\n\n- Section 5, for the synthetic predictions, why do we consider the log-normal distribution?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5029/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698506081333,
        "cdate": 1698506081333,
        "tmdate": 1699636491954,
        "mdate": 1699636491954,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BxZT3EQCRs",
        "forum": "QuIiLSktO4",
        "replyto": "QuIiLSktO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_NjU5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_NjU5"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the online caching problem and the metrical task system problem which admits online caching as a special case. In the online caching problem, we are given a cache of fixed capacity $k$ and a sequence of online arriving elements, and want to design an online algorithm that decides which elements to keep in the cache and which ones to evict when the cache becomes full. The goal is to minimize the number of cache misses, which occur when an arriving element is not present in the cache. In the metrical task system problem, we are given a metric space $M$ of states and an initial state $x_0\\in M$. At each time step $t$, we receive a cost function $\\ell_t: M \\rightarrow R^+ \\cup \\set{0, \\infty }$ and need to decide which state to move to. When moving to a state $x_t\\in M$, we have to pay $\\ell_t(x_t) + d(x_{t-1},x_t)$. The goal is to minimize the total payment. To see that online caching is its special case, we can view the elements kept in the cache as the state in a metric space. \n\nThe two problems are considered in the learning-augmented setting, where we can access imperfect predictions about the future.  More precisely, the authors assume that at any time $t$, if they query a predictor, the predictor returns a prediction $\\hat{s}_t$ of the state that the optimal solution (or a good approximation solution) moves to. Since the prediction is imperfect, they define the prediction error $\\eta$ to be the moving distance between the predicted state and the real optimal state. The authors show that for online caching,  there exists an algorithm that achieves $1$-consistency, $O(\\log k)$-robustness, and $O(f^{-1}(\\eta /OPT))$-smoothness within a query complexity at most $f(\\log k)OPT$, where function $f( \\cdot )$ is an increasing convex function with $f(0)=0$ and $f(i)\\leq 2^i-1$ $\\forall i\\geq 0$. For metrical task system, the authors show that there exists an algorithm that achieves a cost at most $O(a) \\cdot (OPT+2\\eta)$ by making a query each $a$ time step. The smoothness lower bounds are further provided in the paper to show the optimality of their results. Finally, the proposed algorithms are evaluated empirically."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This is a technically solid paper. Online caching and MTS are very classical and important problems in online optimization, and can capture many real-world applications. The paper advances in the direction of augmenting online algorithms by restricted learning. The two problems are good targets since the existence of a robust framework for them alleviates the concern about robustness. The authors show non-trivial trade-offs between the query complexity and the smoothness, which may influence future work in the field of learning-augmented algorithms."
            },
            "weaknesses": {
                "value": "One weakness is that the action prediction setting still looks a little bit weird. To me, particularly in online caching, predicting the next arrival time of the current element makes more sense and is more learnable. It seems hard to learn the optimal actions from historical data in practice. But I understand that this is a setting proposed in the previous work, and the local information predictions (e.g. next arrival time) may not help in the restricted-learning setting."
            },
            "questions": {
                "value": "(1) The key algorithmic idea for algorithm 1 is built on observation 2.1 that Belady is somehow stable. If the predictor simulates other unstable algorithms, is there any non-trivial smoothness bound?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5029/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5029/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5029/Reviewer_NjU5"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5029/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698570613039,
        "cdate": 1698570613039,
        "tmdate": 1699636491840,
        "mdate": 1699636491840,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fgdZnA2Ltn",
        "forum": "QuIiLSktO4",
        "replyto": "QuIiLSktO4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_dLjd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5029/Reviewer_dLjd"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of Metrical Task Systems (MTS) under the prediction setting. In the classical MTS problem, the algorithm starts from an initial state (or a point in a metrical space), and the adversary releases a cost function at each time step. After seeing the cost function, the algorithm needs to make a decision at each time: either stay in the same state or move to another state, which is possibly cheap, but some extra moving costs will be charged. In the prediction setting, the algorithm accesses a prediction on future information. In this paper, the prediction is considered the next stage of an optimal algorithm. Unlike other prediction papers, this work investigates how the number of predictions affects the algorithm.\n\nThe main contribution of this work is a learning-augmented framework achieves a good trade-off between the smoothness ratio and the number of predictions. For the Caching problem, this framework achieves a nearly optimal tradeoff. The authors also show that such a framework works for the general MTS problem. Besides this, this work also extends the framework for the setting where the prediction can also be obtained by at least a time step. Finally, the authors verify their algorithm in some datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths:\n\n1. The paper is well-written and well-structured. I appreciate that the authors provide sufficient intuitions on appropriate places, which significantly improves the readability of the paper.\n2. I particularly like the model where the prediction cannot be obtained by at least some fixed time step. This idea seems new and can capture many applications in practice.\n3. The technical contribution is solid. Although the high-level picture of the proposed algorithm follows a typical framework in a learning-augmented area, the algorithm contains sufficient new ideas and analysis."
            },
            "weaknesses": {
                "value": "Weaknesses:\n\nI don't see any major weaknesses in the paper. My main concern is that due to its technical nature, one would really be required to check all proofs for correctness. I am unfortunately not able to do that due to the time limit for reviewing. I only checked a few lemmas and I believe they are correct. If all proofs are correct, then I think this is a good paper."
            },
            "questions": {
                "value": "I don't have any specific questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5029/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698586982900,
        "cdate": 1698586982900,
        "tmdate": 1699636491735,
        "mdate": 1699636491735,
        "license": "CC BY 4.0",
        "version": 2
    }
]