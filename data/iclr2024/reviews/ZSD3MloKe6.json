[
    {
        "id": "LNiYzPz6Ub",
        "forum": "ZSD3MloKe6",
        "replyto": "ZSD3MloKe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_zG28"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_zG28"
        ],
        "content": {
            "summary": {
                "value": "To address the issue of exposure bias, this paper proposes a sampling method called the Time-Shift Sampler. Specifically, this method is based on the observation that within a window of size w around the time step t, there exists a better time step ts that corresponds to a closer match between the variance of the true samples and the predicted samples xt. Moreover, the feasibility of this method is theoretically validated by the authors. To validate the effectiveness of the proposed method, extensive experiments are conducted on multiple models and datasets, and the results strongly demonstrate its efficacy. Importantly, compared to other relevant papers addressing exposure bias, this article offers the advantage of not requiring retraining and incurring minimal additional costs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper investigate an important problem which ignored by previous works, dubbed exposure bias, and propose an interesting method to remedy it.\n2. The analysis for the exposure bias problem helps to understand the proposed method, Time-Shift Sampler.\n3. Time-Shift Sampler does not require fine-tune the pre-trained diffusion models and incurs minimal additional costs, while effectively mitigating exposure bias. \n4. Moreover, Time-Shift Sampler enables to combine with various diffusion model, which demonstrates a good scalability."
            },
            "weaknesses": {
                "value": "1. Due to the conditions imposed by the theoretical derivation, amost 10% sampling time can not be simply ignored.\n2. As mentioned 'seamlessly integrated to existing sampling algorithms', how about the performance combined with the DPM-solver [1], DEIS [2].\n3. In my humble opinion, the analysis of the exposure bias problem is empirically not theoretically as mentioned in the 'contribution'.\n4. There is no obvious advantage over the recent training-free sampling method.\n\n[1] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu. DPM-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. Advances in Neural Information Processing Systems, 35:5775\u20135787, 2022.\n[2]  Q. Zhang and Y. Chen. Fast sampling of diffusion models with exponential integrator. International Conference on Learning Representations, 2023."
            },
            "questions": {
                "value": "1. Can this method combine with other training-free sampling methods, such as DPM-sovler, DEIS?\n2. How is the performance on ImageNet?\n3. Is there exits a analytical solution for the window size?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Reviewer_zG28",
                    "ICLR.cc/2024/Conference/Submission6453/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6453/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698500173714,
        "cdate": 1698500173714,
        "tmdate": 1700537545008,
        "mdate": 1700537545008,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u2iGZZCzTC",
        "forum": "ZSD3MloKe6",
        "replyto": "ZSD3MloKe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_rQd1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_rQd1"
        ],
        "content": {
            "summary": {
                "value": "This paper examines the exposure bias of diffusion models and proposes a straightforward and efficient method to address it. The study presents clear experiments and motivation to elucidate both the exposure bias phenomenon and its solution."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper analyzes the exposure bias of diffusion models, presenting clear visual results and detailed analysis.\n2. This paper presents a simple, effective, and training-free solution for exposure bias.\n3. The proposed solution can be applied to both DDPM-like and DDIM-like methods, providing potential benefits for future acceleration work."
            },
            "weaknesses": {
                "value": "The selection of window sizes and cutoff values is primarily based on limited experience."
            },
            "questions": {
                "value": "How can we design a more effective strategy for selecting window sizes and cutoff values when dealing with random datasets and image sizes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Reviewer_rQd1"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6453/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698756157955,
        "cdate": 1698756157955,
        "tmdate": 1699636721170,
        "mdate": 1699636721170,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "txAyq64SVK",
        "forum": "ZSD3MloKe6",
        "replyto": "ZSD3MloKe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_YoEn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_YoEn"
        ],
        "content": {
            "summary": {
                "value": "This work studies the problem of exposure bias in diffusion models and proposes a training-free method to mitigate exposure bias during sampling. The paper first reasons why mitigating exposure bias in diffusion models could result in improved sampling by empirically demonstrating the accumulation of error at different time steps. To this end, a quantity $C(x_t, t)$, called input couple for trained DPM, is used to capture the discrepancy between ground truth and network predictions. The core idea is that there might be an alternate time step $t_s$ that might align better with the next state $\\hat{x}_{t-1}$  predicted by the network. This assumption is empirically demonstrated for different datasets and for different choices of time steps. \n\nIn order to find this alternate optimal time step $t_s$, this work derives the variance of this optimal tilmestep. This can then be used to empirically determine $t_s$ on-the-fly during sampling. This step can be seamlessly integrated into existing sampling methods like DDIM, DDPM, and PNDM. Further, this does not require any fine-tuning or training of diffusion models. However, this comes at the cost of some minor additional overhead in terms of sampling time. Overall, this method gives consistent improvements over baselines of DDIM, DDPM and PNDM in terms of FID scores."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method for alleviating exposure bias is training-free unlike previously proposed methods.\n2. The proposed method results in consistent improved performance in terms of FID score compared to baselines of DDIM, DDPM, and PNDM sampling (See Table 1), as well as prior works like ADM-IP.\n3. The primary contribution of this work which is empirical demonstration of the fact that correction of exposure bias can be done without retraining diffusion models is valuable."
            },
            "weaknesses": {
                "value": "1. The proposed method is training-free but introduces minor overhead in sampling time of diffusion models. Further, as the number of sampling steps increases, the method seems to be sensitive to the choice of hyperparameters like window size. At smaller number of sampling steps, the method is also a bit sensitive to cutoff time. (See Section 5.4)\n2. The writing needs improvement as it is currently a bit ambiguous at certain places. (See 1. and 2. In questions below for further details). For instance, plotting details for Figure 3 are unclear from the appendix. Similarly, it is unclear to me how $var(x_{t-1})$ is computed in line 9 of Algorithm 3. The overall clarity of this paper will greatly improve if these paragraphs are rewritten by adding additional details. Similarly, mathematical expressions should be added at multiple places along with text for improved clarity. For instance, Figure 2, writing $var(x_t)$ is more informative than simply writing $x_t$ for the label of y-axis. In Figure 3, the mathematical form of error can be included instead of labelling y-axis as error.  \n3. Certain parts of derivation of proof of Theorem 3.1 need further explanation. The proof assumes that for an image P, and pixels $p_i, p_j \\in P$, $p_i \\perp p_j$ if $i \\neq j$ which is usually not true in practice as neighboring pixels in image usually have high correlation. It also assumes that each pixel in image $P$ follows distribution $\\mathcal{N}(\\mu_i, \\sigma)$, but later it claims that $\\mu_i$ is the mean of the distribution of $\\hat{x}_{t-1}$ which looks incorrect as the mean of the latter distribution is a vector/tensor (as it is an image) while $\\mu_i$ is a scalar as it is mean of pixel values."
            },
            "questions": {
                "value": "1. The explanation of details for plotting Figure 3 is unclear from the description given in Appendix B. Perhaps writing mathematical equations might make the idea more concise and clear. Also, for the purpose of rebuttal, could the authors include this expression here, or alternately provide an explanation of what the figure indicates? It is unclear to me why the error computation for this figure is split into two different stages. Any intuition/reasoning behind choosing the methodology of computing errors in Figure 3 is appreciated.\n2. In DDPM sampling, we use line 4 in algorithm 2 to get the next sample $x_{t-1}$.  It is unclear to me how this $x_{t-1}$ is used to compute $var(x_{t-1})$ in line 9 of Algorithm 3. We cannot use the analytic closed form of variance as it won\u2019t have errors/exposure bias from prediction in network. Thus it needs to be sample variance. In that case, to compute $var(x_{t-1})$, is $z \\sim N(0, I)$ sampled multiple times and then sample $var(x_{t-1})$ computed? As other terms for sampling $x_{t-1}$ are fixed for a given $x_t$ (Line 4 in Algorithm 2), isn\u2019t $z$ the only source of variance in this case? How many samples of $x_{t-1}$ are needed to get a reasonable estimate of this sample variance? Is it possible to add these details in the text that explains the algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6453/Reviewer_YoEn"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6453/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698786256335,
        "cdate": 1698786256335,
        "tmdate": 1700616816797,
        "mdate": 1700616816797,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SQyP2daZFP",
        "forum": "ZSD3MloKe6",
        "replyto": "ZSD3MloKe6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_8DgG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6453/Reviewer_8DgG"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to select a suitable timestep for next step instead decreasing it as in most diffusion model sampling algorithms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-written and organized.\n\n2. The analysis are sufficient and the findings in section 3. are interesting. \n\n3. According to the tables, the FIDs are improved with different baseline samplers. It is also good to see that the sampling time is not increased significantly as shown in figure 6."
            },
            "weaknesses": {
                "value": "1.  Other metric should also be included, such as precision and recall. Is there any reason why text-to-image performances are not added? It would be better if authors could include such results as the task is one of most important tasks of diffusion model. \n\n2. Could you also visualize the selecte timestep trajectory?  It also would better to have more analysis on the selected timesteps and around which timesteps are mostly important."
            },
            "questions": {
                "value": "as above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6453/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699181022540,
        "cdate": 1699181022540,
        "tmdate": 1699636720929,
        "mdate": 1699636720929,
        "license": "CC BY 4.0",
        "version": 2
    }
]