[
    {
        "id": "tupdi7LSza",
        "forum": "L7LwHpjMTQ",
        "replyto": "L7LwHpjMTQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6786/Reviewer_ry4r"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6786/Reviewer_ry4r"
        ],
        "content": {
            "summary": {
                "value": "This paper casts the problem of estimating high dimensional neural networks mappings as selecting an unknown Reproducible Kernel Hilbert Space (RKHS) using the optimal solution of a multi-task multiple kernel learning (MTMKL) optimization problem. Under the setting where both number of covariates and the number of candidate kernels increase with the sample size, the authors show an optimal statistical rate of the MTMKL classifier. The proposed method is successfully applied to embeddings of medical imaging data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Casting the high dimensional neural networks optimization problem as multi-task multiple learning optimization problem\n- Thorough theoretical analysis of the optimal estimator"
            },
            "weaknesses": {
                "value": "- CLIP is not considered in the experiments! This paper should not be sold as CLIP modelling but as a method that use inner-product based objective.\n- Claim that there were no prior theoretical work on multi-task multiple kernel learning. There are multiple work on the subject (this is an old topic) including theoretical analysis. See (Micchelli, C., & Pontil, M. (2004). Kernels for Multi--task Learning. Advances in neural information processing systems, 17.)"
            },
            "questions": {
                "value": "- I have a big concern about the title of the paper. I do not see why the results in the paper are only specialized to CLIP models instead of general estimating functionals of high dimensional (features embeddings) inner products. In the experimental section, CLIP is barely used! Some embeddings are just extracted. I think if the paper is around CLIP as Multi-task multiple kernel, there should be a whole study on the architecture of CLIP, which to me seems to be a big task. Could the authors please elaborate more on this as this is really confusing to me about the real contribution of the paper? \n-It is mentioned in the Related literature that no theoretical analysis of MKL has been conductied in the multi-task setting. Could the authors justify that as there is a big literature on the subject. For instance: See (Micchelli, C., & Pontil, M. (2004). Kernels for Multi--task Learning. Advances in neural information processing systems, 17.) which has not been cited/analysed. There are other related works. Could the authors elaborate on this?\n- In the experiments section (section 7.2), the authors do not specify which embeddings are used (are they CLIP embeddings?), justifying again my concerns of why CLIP as a motivation of the paper? If so, more detailed experiments should be performed using CLIP embeddings for large-scale image recognition problem (this is a big literature to be considered).\n\n\n------- After rebuttal ---------------------\nThe work conducted by the authors during the rebuttal phase convinced me to raise my score. My original concern was that the paper was focused on proposing a new way of training CLIP-like models but the experimental sections did not compare with respect to the traditional way of training CLIP. The authors have done this comparison in the rebuttal phase and have shown improvements of their MTMK approach over CLIP, and promised to revise the paper to include that as one of the message of the paper by including it as an algorithm for training CLIP."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6786/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6786/Reviewer_ry4r"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698419200631,
        "cdate": 1698419200631,
        "tmdate": 1700647052186,
        "mdate": 1700647052186,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Dpti1yPSLq",
        "forum": "L7LwHpjMTQ",
        "replyto": "L7LwHpjMTQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6786/Reviewer_F8DR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6786/Reviewer_F8DR"
        ],
        "content": {
            "summary": {
                "value": "The paper tries to achieve better understanding and analysis of CLIP using reproducing kernel Hilbert spaces (RKHS). CLIP uses a contrastive loss on mapping of input text and image datasets. The paper argues that the objective function of CLIP can be expressed by using kernels in an RKHS. Then the paper proposes to find the best RKHS that maximizes the contrastive loss of CLIP."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Interpreting the training CLIP as a kernel learning problem is interesting. Due to characteristics of kernel functions analyzing kernel-based models is tractable. This perspective offers a promising avenue for enhancing the understanding of CLIP, a fundamental and widely adopted model.\n2. The paper conducted experiments on real datasets to support the theoretical analysis."
            },
            "weaknesses": {
                "value": "1. It seems that the goal of the paper is to give readers of better understanding on how to train a better CLIP model. It is more common that neural network models are employed. However, I did not find any discussion in the paper that if their analysis provides some intuition on how  train a better CLIP. Therefore, the contribution of this paper is not super clear to me.\n2. The methods used in this paper is too heuristics. In case of using neural networks, deep neural network models can be interpreted as NTK using some heuristics while in order to train the contrastive loss using kernel learning, the paper performs some relaxations in the objective function.\n3. Experimental section can be improved by adding more datasets and baselines."
            },
            "questions": {
                "value": "Please see weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839137316,
        "cdate": 1698839137316,
        "tmdate": 1699636783618,
        "mdate": 1699636783618,
        "license": "CC BY 4.0",
        "version": 2
    }
]