[
    {
        "id": "drLuQrOF8X",
        "forum": "sNWQUTkDmA",
        "replyto": "sNWQUTkDmA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_VvVc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_VvVc"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method to compute a \"feature vector\" in transformers for a given task."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method requires no labeled training data, in contrast to other similarly motivated methods like probing."
            },
            "weaknesses": {
                "value": "I find the paper quite opaque. The paper should directly give a formal definition of an \"observable\", state how it is used/useful, and show how it is computed. Instead, the paper gives a long narrative of several motivations in words. The theorem about how the layer norm doesn't substantially the direction of feature vectors seems pretty specific to the narrative here; it is hard to see much general value out of the context. \n\nI'm not very knowledgeable in the area of gender bias analysis so I'm not qualified to make comments on the value of the experiments. But given my lack of confidence on the value of the technical part, it is hard for me to see the value of the experiments either."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4345/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698754130240,
        "cdate": 1698754130240,
        "tmdate": 1699636405087,
        "mdate": 1699636405087,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UtJyKXb5HZ",
        "forum": "sNWQUTkDmA",
        "replyto": "sNWQUTkDmA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_Gf3o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_Gf3o"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method called Observable Propagation (ObProp) to identify feature vectors in large language models. Because of the success of LLMs, interpreting what their intermediate layers learn has turned out to be an emerging topic. The authors propose that linear transforms of language model logits, which they call observables, can be captured approximately via feature vectors that can be computed by a simple forward model through the model.\n\nIn more detail, the basic idea is to define an abstract vector called observable n and feature vector y, such that the inequality n.f(x) = y.x is satisfied for a non-linearity f (an intermediate layer of the LLM). This inequality cannot be exact but the authors propose to compute an approximation by approximating each neural non-linearity by its gradient (Taylor approximation) and each attention mechanism by the attention weights (which are assumed to be constants). This lets them learn a feature vector y for each observable n.\n\nThe authors propose that studying the norms of such vectors and looking at their correlation (a coupling coefficient) will suggest us more about the observables. Simple experiments using GPT-Neo-1.3B suggest that such learnt feature vectors for the gendered pronounds prediction weakly match the ones recovered by looking at logit differences (via path patching). Additional experiments on occupational gender bias predicts that LLMs do exhibit gender-occupation bias."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Mechanistic interpretability is an important research direction and the authors propose a simple method towards this research direction which does not rely on large-scale compute or data.\n\n- Their experiments, including App. H, suggest that the ObProp algorithm does seem to recover meaningful interpretation of various attention heads that occur in the model, which could then be analyzed more rigorously using more powerful methods."
            },
            "weaknesses": {
                "value": "- This method seems like an oversimplification of the architecture of an LLM. The ObProp algorithm propagates through the layers by approximating almost all non-linearities by their first-order gradients.\n\n- Moreover, the work abstracts out QK circuits in LLMs, i.e. the attention scores are treated as constants and not as non-linearities, therefore the problem is oversimplified and I'm not sure the theorems shown are necessarily that insightful. As the authors note, their method ObProp does not capture the action of induction heads.\n\n- Theorem 1 proposes that layer norms do not affect the feature vectors, by showing that the expected cosine similarity is close to 0. However, in this theorem, the activations and observables x, n are chosen to Gaussian with mean 0 and covariance I. What's the point of this assumption? And how do the authors conclude that the theorem 1, as stated with these distributions, implies their claim about layer norm for general activations?\n\n- Related to the above, why did the authors look at uniform distributions on the sphere in theorem 2? Even if the vectors have bounded norm, why do the authors assume uniformity?"
            },
            "questions": {
                "value": "Some questions were raised above.\n\n- Typo in the equation in 2.2 and below, score has both 1 and 2 subscripts."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4345/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4345/Reviewer_Gf3o",
                    "ICLR.cc/2024/Conference/Submission4345/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4345/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801161699,
        "cdate": 1698801161699,
        "tmdate": 1700544094379,
        "mdate": 1700544094379,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "e0mqINsuGt",
        "forum": "sNWQUTkDmA",
        "replyto": "sNWQUTkDmA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_DiKb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4345/Reviewer_DiKb"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method ObsProb  to better understand which parts (paths) of neural networks in neural networks contribute to which predictions. The idea is to start with a linear functional on the logits layer and then give some (approximate) mathematical arguments as to how this can be propagated down the network. \n\nEmpirically the authors do a case study with gender bias. They show that the n_subj (he/she) and n_obj (her/him) feature vectors derived from ObsProb have high cosine similarities for 4 heads and these cosine similarities are vary high. This indicates that according to the authors' approach, the same underlying features of the network are being used for these predictions. Moreover, the authors find a similar result with n_{bias} (which is an observable for occupational bias).  They find a particular path for n_{subj} has a very high correlation with that of n_{bias}."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Interpretability is complex and challenging for LLMs. Being able to understand how different predictions are made my similar parts of the model could be very useful. The authors' results are around gender and occupational bias using their approach are insightful."
            },
            "weaknesses": {
                "value": "The empirical evaluation is largely a case study and doesn't feel rigorous. It would be more convincing to have a more quantitative evaluation across more types of observables compared to a baseline, along with the case study.\n\nNit: It would be good to define the term \"unembedding matrix\"."
            },
            "questions": {
                "value": "My main concerns with the approach are around rigorous evaluation as discussed above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4345/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699210896424,
        "cdate": 1699210896424,
        "tmdate": 1699636404927,
        "mdate": 1699636404927,
        "license": "CC BY 4.0",
        "version": 2
    }
]