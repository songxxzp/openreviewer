[
    {
        "id": "n1ZzjKvmpS",
        "forum": "Ge7ZqrKG9t",
        "replyto": "Ge7ZqrKG9t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on modeling the mathematical reasoning process within LLMs. The authors propose a novel framework named Planner-Reasoner-Executor-Reflector (PRER) and implement two MathAgents within this framework, i.e., MathAgent-M and MathAgent-H, to tackle complicated mathematical problems. The experimental results verify that the two agents significantly improve the reasoning accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed PRER is a general framework whose idea of decomposing mathematical reasoning process is rational. Besides, the architecture of the paper is clear to read.\n2. This framework can be implemented with different LLMs and in different grains. The motivation of describing LLMs\u2019 and human-like behaviors is reasonable, and the corresponding technique makes sense.\n3. The accuracy improvements on datasets MiniF2F and MATH are significant."
            },
            "weaknesses": {
                "value": "1. It\u2019s necessary to give an \\emph{overall} introduction of its idea. What I mean is not the description of the workflow of Planner-Reasoner-Executor-Reflector framework. What I am concerned about is the reason of formalizing the actions as \u201cinfer\u201d\u3001\u201ccalculate\u201d and so on (Details could be referred to question 1 below). Besides, this paper presents several modules realized by prompting LLM, without a clear introduction to the internal logic and reasons for model design. \n2. Some details lack enough descriptions or explanations, bringing difficulty in reproducing the proposed framework. Details could be referred to questions 2-4 below.\nPlease see the detailed questions below, which should be answered and addressed."
            },
            "questions": {
                "value": "1. How do the authors define the actions of different modules? For example, why does the \u201cMathematical\u201d class in MathAgent-H only contain \u201cassociate\u201d and \u201cconstruct\u201d? What is the behind idea of designing them? Are there other actions that should be considered? \n2. According to the paper, the actions of MathAgent-M is a subset of MathAgent-H's. Therefore, what is the necessity of proposing MathAgent-M independently from the perspective of technique? Besides, as described in Table 1, the \"Infer\" action in MathAgent-M has different meaning with the \"infer\" in MathAgent-H. The authors state that the action in MathAgent-H is more aligned with human actions. However, the description of \"infer\" in MathAgent-M, i.e., \"Infer new rationales using deduction methods\" can also be viewed as an action in human cognition.\n3. What is the meaning of m^1_n, m^2_n in Eqs.(2),(3) in section 2.2. They lack descriptions or explanations.\n4. In Eq.(3), why is t_n (i.e., topology of the inference) an output, not an input, and even if t_n is obtained, what is it useful for subsequent reasoning? Because t_n does not appear in Eq.(4) or other equations.\n5. According to Figure 3, \u201cinfer\u201d and \u201ccalculate\u201d occupy the most important part for MathAgent-M and MathAgent-H, respectively. It's a little weird for me due to the following reasons. First, as the authors have stated, MathAgent-H is more aligned with human actions. However, the statistics reveal that the human-like actions (e.g., \"induce\", \"rethink\") take up a very small proportion in MathAgent-H's reasoning process, contradictory with the motivation of designing MathAgent-H. Second, why \"infer\" takes up such a small proportion in MathAgent-H? Intuitively, since the testset are the same, \"infer\" should also be the prominent action in MathAgent-H, since it's more relevant to mathematical reasoning. On the contrary, \"calculate\" in MathAgent-H is indeed a computation action, which intuitively should not have such a high frequency.\n6. There exist some other works that also decompose the mathematical reasoning into several steps (e.g., Tree of Thought [1]) and adopt a generate-then-verify paradigm (e.g., [2,3]). The authors need to give more illustrations of how this work is distinctive, explain the differences with other similar works, and incorporate them in experiments.\n[1] Yao S, Yu D, Zhao J, et al. Tree of thoughts: Deliberate problem solving with large language models[J]. arXiv preprint arXiv:2305.10601, 2023.\n[2] Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, and John Jumper. Accelerating large language model decoding with speculative sampling. arXiv preprint arXiv:2302.01318, 2023.\n[3] Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative decoding. In International Conference on Machine Learning, pages 19274\u201319286. PMLR, 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698692232363,
        "cdate": 1698692232363,
        "tmdate": 1699636101564,
        "mdate": 1699636101564,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "brNgSdGSxu",
        "forum": "Ge7ZqrKG9t",
        "replyto": "Ge7ZqrKG9t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
        ],
        "content": {
            "summary": {
                "value": "The paper tackles improving the mathematical reasoning capability of LLMs by proposing a set of modular decomposition actions. These actions range from infer, associate, observe, disprove, etc. All the actions are simulated by LLMs with few shot prompts. With the help of these actions, the paper shows a strong performance improvement on MATH and MiniF2F datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper attempts to systematically break down various useful actions in mathematical reasoning. The design is interesting.\n\nThe performance gain from prompting the LLM with proposed actions is quite significant especially on MiniF2F datasets, where it solves 20% IMO problems that are not solved before."
            },
            "weaknesses": {
                "value": "The paper is not very well-written with many of the equations not explained clearly. The authors should provide more clarifications on these.\n\nThe design of various actions seem heavily engineered and the overall algorithm quite complicated. (See Algorithm 2) I wonder if the authors could break down the effect of various actions and only identify a few that contribute to the performance improvement the most. This is especially important since according to Figure 3, majority of the actions are \"calculate\"."
            },
            "questions": {
                "value": "1. What does this sentence mean: \"whereas the MATH dataset does not offer final answers for reasoning\"? I am very certain MATH datasets have ground truth reasoning steps and final answers.\n\n2. What actions are truly necessary in improving the reasoning performance of LLM? Can the authors perform more thorough ablation?\n\n3. Given the strong MiniF2F performance with MathAgent-H on IMO problems, can the authors provide a few generated proofs for those problems? Also, I was not able to find the prompts associated with MiniF2F.\n\n4. Figure A1: where is (c)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723576911,
        "cdate": 1698723576911,
        "tmdate": 1699636101458,
        "mdate": 1699636101458,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5Ch5FfPOM2",
        "forum": "Ge7ZqrKG9t",
        "replyto": "Ge7ZqrKG9t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_WFXS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_WFXS"
        ],
        "content": {
            "summary": {
                "value": "The paper delves into the challenges LLMs face when solving intricate mathematical problems. To address these challenges, the authors introduce an agent-based zero-shot framework named Planner-Reasoner-Executor-Reflector (PRER) and two MathAgents, MathAgent-M and MathAgent-H. Experiments on miniF2F and MATH datasets show that the proposed approach significantly outperforms GPT-4, especially for level-5 problems of the MATH dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well written and easy to follow.\n2. The work pushed the state-of-the-art results on two datasets including MATH which seems to be a challenging dataset even for larger language models.\n3. The implementation two MathAgents is innovative and shows promise in addressing the challenges LLMs face in mathematical reasoning."
            },
            "weaknesses": {
                "value": "1. Although the paper demonstrates advancements over GPT-4, it fails to specify the average model calls needed for each question within the PRER framework. This omission raises concerns about potential high costs. If the cost is, hypothetically, k times, would it still surpass k majority-voting? It would be advantageous to incorporate such an experiment. With succinct prompts, GPT-4 can outperform MathAgent-M on the MATH dataset. For instance, PHP achieves a score of 53.9.\n2. The experiments are centered on particular datasets (miniF2F and MATH), both of which solely encompass abstract mathematical language. The efficacy of the proposed technique on other mathematical problem-solving datasets remains uncertain, especially concerning word problems akin to those in GSM8K. Such word problems can also be complex and may require more domain knowledge.\n3. The paper's proposition of an approach that can \u201csystematically decompose and model the solving process of complex mathematical reasoning\u201d seems unsubstantiated with neither theoretical nor empirical backing. While using prompts to tailor LLM into a specialized expert is a prevalent strategy, the model doesn't acquire any fresh insights. Furthermore, there's an absence of empirical evidence emphasizing the significance or need for Executors."
            },
            "questions": {
                "value": "The paper introduces a technique to augment LLMs' aptitude in mathematical reasoning through an agent-based framework. Although the findings are encouraging, questions remain about the method's adaptability and the absence of exhaustive comparisons with alternative techniques.\n\n**Correctness:** 3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n**Technical Novelty And Significance:** 3: The contributions are significant and novel, but there are areas that could be further explored or clarified.\n\n**Empirical Novelty And Significance:** 3: The empirical contributions are significant, but the paper could benefit from a broader range of experiments and comparisons."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698738190764,
        "cdate": 1698738190764,
        "tmdate": 1699636101372,
        "mdate": 1699636101372,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lZTbTUFxWg",
        "forum": "Ge7ZqrKG9t",
        "replyto": "Ge7ZqrKG9t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
        ],
        "content": {
            "summary": {
                "value": "In this work the authors develop a general agent-based framework, called Planner-Reasoner-Executor-Reflector (PRER), to model the problem solving process in mathematical reasoning (MR).\nA feature of the proposed framework is that it only relies on LLMs, with no calls to external theorem provers.\nThe proposed approach is evaluated experimentally."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1) The experimental evaluation is rather thorough, the proposed approach is compared with several different frameworks.\n\n2) The related literature is discussed in some detail, but it only mentions briefly related approaches that leverage on theorem-provers. Also, the paper does not discuss why avoiding the use of theorem-provers entirely."
            },
            "weaknesses": {
                "value": "1) The authors say that \"to the best of our knowledge, systematical decomposition and meticulous\nmodeling of complex mathematical solving process have not been explored.\" However, there are a few pages on decomposition for mathematical reasoning, also cited by the authors themselves. Consider, for instance,\n\n- Xueliang Zhao, Wenda Li, and Lingpeng Kong. Decomposing the enigma: Subgoal-based demonstration learning for formal theorem proving. arXiv preprint arXiv:2305.16366, 2023.\n\n- Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.\n\n- Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601, 2023.\n\nand related:\n\n- Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks, 2023.\n\n2) Equation 1 is not entirely clear. It seems akin to the notion of deduction in logical systems, but its meaning is not formally specified. E.g., what is the meaning of symbol \"|-\"?\n\n3) The different components of the proposed framework (planner, reasoner, executor, reflector) are presented rather in a hurry, in less than one page, by means of Equations (1) to (5), which are not explained in much detail either, especially as for the role of the different logical functions. Consider: \"Planner\nincludes an addition function, preprocessing, to decompose the original problem into the form of (X, y).\"\nWe don't get any more information about preprocessing in the paper.\n\n4) As the authors themselves discuss limitations in the conclusions, \"the current prompts are manually\ncrafted, heavily reliant on experts.\"\nThis might not be the most promising way forward."
            },
            "questions": {
                "value": "It is not entirely clear to me why two different agents, MathAgent-M and MathAgent-H, are required. What is the rationale for this choice?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1727/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1727/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698753317523,
        "cdate": 1698753317523,
        "tmdate": 1699636101304,
        "mdate": 1699636101304,
        "license": "CC BY 4.0",
        "version": 2
    }
]