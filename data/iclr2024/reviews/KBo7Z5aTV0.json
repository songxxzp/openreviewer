[
    {
        "id": "W7zQ69EcJh",
        "forum": "KBo7Z5aTV0",
        "replyto": "KBo7Z5aTV0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_GSD6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_GSD6"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a  pixel learning framework for semantic segmentation. Intra-image, inter-image, inter-domain pixels variances are considered in this framework. The framework is elaborate, which consists of four components, i.e., Multiple Resolution Feature Extraction, Pixel Level Sub-Domain Partition, Adaptive Prototype Generation, and Drift Pixels Alignment. The motivation of this paper is interesting. The experimental results demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) Pixel variance is important in semantic segmentation. This paper proposed a new solution. \n\n(2) This framework is flexible, it is quite easily to perform different semantic segmentation tasks.\n\n(3) The performance is good."
            },
            "weaknesses": {
                "value": "(1) The authors did not report the results on higher resolution images, is that because too many pixels should be considered?\n\n(2) In semantic segmentation, contextual information is quite important to assign a class label to a pixel.  But this paper discards the context in some extent. Is this reasonable?\n\n(3) Pixel-level contrastive learning is widely used in unsupervised semantic segmentation, both local and global relations are considered. In these methods, global pixel features are usually store in a memory bank.  The differences with these method should be given in detail.\n\n(4) In Table 1, the proposed method performs worse with 1/8 and 1/4 than 1/30. The authors should explain this.\n\n(5) In addition of intra-image, inter-image pixel relations, this method also considers the inter-domain one, but this is not presented in abstract."
            },
            "questions": {
                "value": "see the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5500/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668765912,
        "cdate": 1698668765912,
        "tmdate": 1699636562752,
        "mdate": 1699636562752,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jzuGWjSZV9",
        "forum": "KBo7Z5aTV0",
        "replyto": "KBo7Z5aTV0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_YSzS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_YSzS"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce the pixel learning scheme by treating each image as a local distribution of pixels. The PiXL framework, which segregates pixels within a given local distribution into sub-domains: joint pixels and drift pixels, is proposed. Then, the PiXL employs an asymmetric alignment approach to align drift pixels with the joint pixels, effectively addressing pixel-level variance in a\ndivide-and-conquer manner. Extensive experiments confirm PiXL\u2019s performance, especially demonstrating promising results in\nlabel-scarce settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper  proposes a novel pixel learning scheme to dive semantic segmentation models into the pixel level by treating an image as a distribution of pixels. This advocates addressing pixel-level variance to enhance the segmentation model\u2019s per-pixel recognition capability.\nThe strengths are as follows:\n1. This paper proposed PiXL, a pure pixel-level learning framework that executes pixel-level intra- and inter-distribution (image) alignment within the context of pixel learning. \n2. Extensive quantitative and qualitative experiments in various settings of semantic segmentation confirm the effectiveness of PiXL, demonstrating the feasibility and superiority of the pixel learning scheme, which deserves further exploration.\n3. The writing is clear and well-reading."
            },
            "weaknesses": {
                "value": "The weakness are as follows:\n1. Some description is not very clear. For example, in equation 4, \"PiXL determines the threshold ...\", how to determine the threshold is not presented. why \" that pixel partitioning is performed separately...considering the entropy gap across images.\"?\n2. \"PiXL employs entropy as the criteria to segregate the pixel features in g into joint pixels and drift\npixels.\" how to compute the entropy?\n3. the paper validate the effectiveness on HRDA model, but if the proposed methods can be applied to general semantic segmentation methods is not verified.\n4. In table 3, the proposed method cannot show state-of-the-art performance compared with other methods. The authors should prove its effectiveness."
            },
            "questions": {
                "value": "The questions are summarised with weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5500/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698734768338,
        "cdate": 1698734768338,
        "tmdate": 1699636562637,
        "mdate": 1699636562637,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7R7gahWBMy",
        "forum": "KBo7Z5aTV0",
        "replyto": "KBo7Z5aTV0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_nhEN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_nhEN"
        ],
        "content": {
            "summary": {
                "value": "This paper takes pixel-level distribution (local distribution) into consideration, and proposed Pixel Level Sub-Domain Partition Module (PSP), Adaptive Prototype Generation Module (APG); Drift Pixels Alignment Module(DPA) modules, the effectiveness of which is proved in ablation study.\nFirst, the PSP module divides all features (with multiscale feature extraction) into Joint pixel features and Drift Pixel features based on the entropy of each segmentation pixels corresponding to each pixel feature. For Joint ones, they use APG to generate local feature prototypes based on their semantic classes, while the Drift ones would be pulled by the prototypes extracted from APG using info NCE loss. \nThe prototypes from APG is the mean value of pixel features which belongs to Joint pixel features in two samples. From which, the paper argues that can get intra-image and inner-image information.\nFinally, the effectiveness of these module is proved in unsupervised domain adaptation, semi-supervised semantic segmentation together with fully-supervised semantic segmentation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is well-written and nicely organized.\n2. Extensive experiments have been conducted and a number of quantitative and qualitative results are shown, demonstrating the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. The method seems incremental. The paper generates class prototype from two image features and push or pull image features based on these prototypes. Their novelty lies in the partition of joint features and drifted features, the selection of high resolution feature prototypes and low resolution prototypes, which seems to be triky."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5500/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763097666,
        "cdate": 1698763097666,
        "tmdate": 1699636562451,
        "mdate": 1699636562451,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mLRA7cvZer",
        "forum": "KBo7Z5aTV0",
        "replyto": "KBo7Z5aTV0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_L3L6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5500/Reviewer_L3L6"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes  a pixel-level learning framework, PiXL, for semantic segmentation. The framework consists of a pixel partition module,  a prototype generation and selection module, and a pixel alignment module. The pixel partition module separate pixels features into joint and   drift pixels based on their entropy. The prototype generation module is to select the most meaningful pixels. The pixel aligment module adopts contrastive learning to align pixel features intra and inter-distribution. The effectiveness of proposed framework and components are experimentally validated on three public datasets: GTA5, SYNTHIA, and Cityscapes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of investigating semantic segmentation from pixel feature distribution perspective is novel.\n2. The proposed pixel learning framework and its components are technically solid and innovative.\n3. The motivation and the underlying principles of designing the framework and each components are clearly presented and explained, so that it is easy to follow the work.\n4. The experiments are extensive and solid."
            },
            "weaknesses": {
                "value": "The experiment results of the proposed results are not much better than previous works."
            },
            "questions": {
                "value": "no"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5500/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699107862788,
        "cdate": 1699107862788,
        "tmdate": 1699636562324,
        "mdate": 1699636562324,
        "license": "CC BY 4.0",
        "version": 2
    }
]