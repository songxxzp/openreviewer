[
    {
        "id": "ZOKena5wDL",
        "forum": "WrEFIbrVg9",
        "replyto": "WrEFIbrVg9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_mgFR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_mgFR"
        ],
        "content": {
            "summary": {
                "value": "This paper analyzes the benefit of weight averaging (specifically, Polyak-Ruppert averaging) in private optimization. Specifically, it considers the strongly/general convex + smooth setting along with *Hessian smoothness* albeit only w.r.t. the optimum (i.e., Condition 3). Under these assumptions, it is shown that the (non-asymptotic) convergence bound of the Polyak-Ruppert averaging scheme is better than that of the last iterate with suitable step-size choices. Some small-scale experiments are shown to corroborate the theoretical findings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Solid theoretical analysis showing the improvement offered by the averaged iterate over the last iterate in private optimization. I'm not up to speed on all of the recent papers in private optimization, but as far as I know, there are no results like the ones in this paper showing the benefits of weight averaging in private optimization. The paper just makes the cut for me because of this."
            },
            "weaknesses": {
                "value": "**1.** *The presentation of the theoretical results needs to be improved and simplified*. For e.g., Theorem 4 is very hard to parse and overloaded with too many symbols. I'd recommend deferring the full versions to the Appendix and presenting abridged versions in the main paper having only the important terms. Also, I'd have liked to see a remark or something *explicitly* comparing the dependence of the convergence bounds of the averaged iterate and last iterate w.r.t. $n$ *together* (and therefore, explaining why the averaged iterate does better) rather than leaving it to the reader.\n\n**2.** Looking at Theorem 4, there is a term of $||\\theta_0 - \\theta^{\\ast}||^4$ whereas in Theorem 3, there is just $||\\theta_0 - \\theta^{\\ast}||^2$. If our initialization is very far from the optimum, this may make the averaged iterate have worse convergence than the last iterate. This point should be discussed in the paper.\n\n**3.** I understand that this is a theoretical paper and so I don't want to complain too much about the scale of the experiments, but for this proposal to be more convincing and practically useful, the authors should consider performing some larger experiments -- beyond linear/logistic regression and definitely with larger $d$.\n\n**4.** It'd be nice to also provide some intuitive explanation of why averaging helps instead of just math.\n\n**Suggestion:** The expectation notation is a bit non-standard; $\\mathbb{E}[.]$ is more standard."
            },
            "questions": {
                "value": "**1.** Is Condition 3 being used in Theorem 3? I don't see any $C_1$ term in Theorem 3.\n\n**2.** Why are there $E\\big(||\\theta_0 - \\theta^{\\ast}||^2\\big)$ and $E\\big(||\\theta_0 - \\theta^{\\ast}||^4\\big)$ terms in the results? These are deterministic, right? Or are you taking expectation w.r.t. something else here?\n\n**3.** What are the constants $C_{3,0}$ and $C_{4,0}$ in Theorem 4? Overall this theorem needs to be simplified and cleaned up as I mentioned in Weaknesses.\n\n**4.** Can the results be extended to regular $(\\varepsilon,\\delta)$-DP? Or is there a reason the authors are considering GDP?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6671/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698205431666,
        "cdate": 1698205431666,
        "tmdate": 1699636763809,
        "mdate": 1699636763809,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WpSvW6SNzc",
        "forum": "WrEFIbrVg9",
        "replyto": "WrEFIbrVg9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_o6Sb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_o6Sb"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the non-asymptotic analysis of the convergence of the DP-SGD (Differentially Private Stochastic Gradient Descent) algorithm and its variants. The authors analyze the convergence of the DP-SGD algorithm and provide practical guidelines on the effect of various hyperparameters such as step size, parameter dimensions, and privacy budgets on convergence rates. The paper provides theoretical bounds on the expected distance between the estimators and the global optimum for strongly convex loss functions. For non-strongly convex functions, the paper analyzes the difference between the loss incurred by the estimators and the optimal loss."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strength:\n1.\tThe paper provides a comprehensive understanding of the convergence behavior of DP-SGD and to help practitioners choose appropriate hyperparameters for their specific use cases.\n\n2.\tThe paper contains fine analysis for both strongly convex case and non-strongly convex case."
            },
            "weaknesses": {
                "value": "Weakness:\n1.\tThe paper does not provide any lower bounds so it is hard to evaluate the tightness of results. \n\n2.\tThis paper lacks comprehensive comparisons to prior works. There are many works on stochastic gradient descent on local differential privacy guarantee. For example, Algorithm 4 in Wang, Teng, et al. \"Local differential privacy for data collection and analysis.\" Neurocomputing 426 (2021): 114-133 and Algorithm 1 in Liu, Ruixuan, et al. \"Fedsel: Federated sgd under local differential privacy with top-k dimension selection.\" Database Systems for Advanced Applications: 25th International Conference, DASFAA 2020, Jeju, South Korea, September 24\u201327, 2020, Proceedings, Part I 25. Springer International Publishing, 2020.  From my point of view, this is not the first work on LDP-SGD, and therefore a comprehensive comparison is expected in this paper. I suggest the author adding a table including previous results and this work. Also, the upper bounds in the paper are unnecessarily long, for simplicity and better rendering I suggest keeping the leading asymptotic term.\n\n3.\tThe technical contribution is relatively weak as I could not find sufficient novelty in the proofing techniques.\n\n4.\tThe presentation of this work could be enhanced. Specifically, it appears there may be an issue with the visibility of equations 3 and 4, which I presume are the upper bounds in Theorems 3 and 4. This could potentially be a result of a compiling error."
            },
            "questions": {
                "value": "1.\tThere is an obvious typo in the proof. On page 1 of supplementary material, \u201cFor the second term of (1), by Condition ??, we have\u2026\u201d, here Condition ?? should be Condition 2.\n2.\tWhy the authors particularly favor Polyak-Ruppert averaging estimator in the theoretical analysis? It would also be interesting to see the results of many other variants of SGD that give better performance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6671/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698703692824,
        "cdate": 1698703692824,
        "tmdate": 1699636763690,
        "mdate": 1699636763690,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QNs1qtcU5o",
        "forum": "WrEFIbrVg9",
        "replyto": "WrEFIbrVg9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_8zUa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_8zUa"
        ],
        "content": {
            "summary": {
                "value": "This paper provides the convergence result of sgd for lipschitz functions under the local differential privacy, both for the strongly convex setting and the non-convex setting."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper provides detailed proofs of their theoretical results, with several numerical simulations."
            },
            "weaknesses": {
                "value": "1. I think authors may not provide a good explaination on their motivation on using GDP instead of classical LDP notation, see also Question 1.\n\n2. Both the results and proof techniques in this paper are similar to those in [1] in the non-private setting. It appears that the introduction of additional Gaussian noise does not pose significant challenges to the analysis. However, the authors do not explicitly compare their paper to [1] or other non-private research in both the proof and result sections.\n\n[1] Moulines & Bach, Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning, 2011"
            },
            "questions": {
                "value": "I have several questions on the paper's motivation and theoretical results:\n\n1. Why did the authors choose to employ GDP notation rather than LDP in the paper? As far as my understanding goes, GDP's primary advantage is its tighter composition guarantee. However, within the context of this paper, where each user's data passes through the algorithm only once, the notion of composition does not apply. Consequently, I am struggling to understand the underlying motivation and advantages of adopting GDP notation.\n\n2. Concerning the theoretical results when $\\alpha = 1$: In the convergence rate section of Remark 1, the authors assert that \"For a scenario where $\\alpha = 1$, convergence of the LDP-SGD estimator $\\theta_n$ is not assured.\" Nevertheless, based on my knowledge, at least in the strongly convex setting, the convergence analysis of LDP-SGD with a step size $\\theta_i = O(1/i)$ seems to be readily attainable by adapting the proof provided in [1]. Have I possibly overlooked any technical complexities?\n\n[1] Alexander Rakhlin, Ohad Shamir, Karthik Sridharan, \"Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization,\" 2011."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6671/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6671/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6671/Reviewer_8zUa"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6671/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698752011261,
        "cdate": 1698752011261,
        "tmdate": 1699636763563,
        "mdate": 1699636763563,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZuvUEuHRfv",
        "forum": "WrEFIbrVg9",
        "replyto": "WrEFIbrVg9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_MP3i"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6671/Reviewer_MP3i"
        ],
        "content": {
            "summary": {
                "value": "The paper claims to perform a comprehensive non-asymptotic analysis of the convergence guarantee of the DP-SGD algorithm. Rightfully so, if this is done correctly, it provides guidelines to the practitioner how to best choose various hyperparameters if we aim to achieve certain convergence rates. Considering that hyperparameter tuning is one of the important problem, such a study is definitely worth pursuing."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strength of the paper is to perform the tedious calculation to show the non-asymptotic analysis on the convergence rate."
            },
            "weaknesses": {
                "value": "While the major motivation of the paper is to provide a guideline to practitioners as to how they should choose hyperparameters, I really (like really) do not see how one can figure out these hyperparameters from the expression they have in the theorem statement. I find it extremely hard to parse their theorem statements. One benefit of asymptotic analysis is that it makes expression a bit easier to parse. If the authors do insist on writing the exact non-asymptotic bounds, then I would suggest they work a bit more on making the expression simpler. Having experience with practitioners, I can guarantee that no one would take their theorem and try to work out hyperparameters from it, at least not analytically. Nesterov-Nemerivoski's results are not influenced because they give an asymptotic bound, but because they give simple to state bounds, and in reality, they are not that far from what you get in practice for certain loss functions.\n\nI also find the assumption on assumption on Hessian a bit too much. \n\nThe paper has several typos. One glaring one is citing the same set of authors on page 2 (second paragraph). Another one that comes to my mind is the missing cross reference on the first page of the supplementary material. The one that really annoyed me is the references in the Remarks. It does not take a lot of effort to write Theorem 3 instead of (3). However, it shows the lack of diligence the authors put in writing their paper."
            },
            "questions": {
                "value": "None. Please read the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6671/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698883156657,
        "cdate": 1698883156657,
        "tmdate": 1699636763437,
        "mdate": 1699636763437,
        "license": "CC BY 4.0",
        "version": 2
    }
]