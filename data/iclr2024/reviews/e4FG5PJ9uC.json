[
    {
        "id": "topUyGblnL",
        "forum": "e4FG5PJ9uC",
        "replyto": "e4FG5PJ9uC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_QSZk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_QSZk"
        ],
        "content": {
            "summary": {
                "value": "This work focuses on solving the weighted least squares problem for image quality distance in full-reference image quality assessment. Inspired by lossless compression, this work proposes the Autoregressive Similarity Index (LASI), which obtains perceptual embeddings by calculating a weighted sum of the causal neighborhood subset of pixel values to predict the current pixel value. The performance of the data-free LASI is comparable to that of supervised methods such as LPIPS and unsupervised methods like PIM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe LASI metric is designed in a simple yet solid manner. Full-reference Image Quality Assessment (FR IQA) can be approached from the perspective of lossless compression and the semantic information within the neighborhood of pixels.\n2.\tThe experiments of JND\uff0c2AFC and MAD are very detailed and the explanations are very clear."
            },
            "weaknesses": {
                "value": "1. The experimental dataset consists only BAPPS. \n2. An ablation study is missing for the causal neighborhood and non-causal neighborhood, as semantic understanding relies on contextual relationships around pixels or regions."
            },
            "questions": {
                "value": "1. The sentence in the section 4.1 \u2018\u2019Our method relies on self-supervision (at inference-time) to learn a representation for each pixel that captures global perceptual semantics of the image. The underlying assumption is that, given a representation vector for some pixel, it must successfully predict the value of other pixels in the image in order to capture useful semantics of the image\u2019s structure.\u201d But the relationship of the perceptual embedding in FR-IQA and the semantic extraction is confused in this work. Because many previous methods also use semantic features extracted by pre-trained models on high-level classification tasks to calculate perceptual distance. Is there any difference between this semantic feature and the embedding derived by Eq 1 in this work?\n2. Since the LASI is designed on the semantic extraction in the images\u2019 structure, so the correlation of the prediction task and perceptual task is good, which is a little obvious.  \n4. Perhaps LASI can only measure perceptual distance at patch level, and will it be useful for high-resolution images? \n5. An ablation study is missing for the causal neighborhood and non-causal neighborhood, as semantic understanding relies on contextual relationships around pixels or regions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Reviewer_QSZk"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698758882807,
        "cdate": 1698758882807,
        "tmdate": 1700720685257,
        "mdate": 1700720685257,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2yPbZ9RNYT",
        "forum": "e4FG5PJ9uC",
        "replyto": "e4FG5PJ9uC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_8dYU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_8dYU"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new perceptual metric that requires no training data nor DNN features. In particular, taking inspiration from psychology finding that visual working memory compresses visual stimuli, the proposed method, named Linear Autoregressive Similarity Index (LASI), compresses a visual stimuli during inference."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper introduces a new perceptual metric that requires no training data or DNN features.\n\n- The paper is clearly written and easy to follow."
            },
            "weaknesses": {
                "value": "- The paper claims to have competitive performance, compared with LPIPS method. But, 11% difference in SR in Table 1 seems rather high.\n\n- The paper claims that the advantage of the proposed method is that it requires no training data or DNN features. But, the method requires computations at inference time. Considering that once training is done, DNN-feature based methods do not require much of extra computations (hence the cost is amortized) while the proposed method requires extra computations, is requiring training data or DNN features really a bad thing?\n\n- All experiments are performed with 64x64 resolution, which seem rather small. Is the proposed method effective for larger images, compared to other works? Is the choice of $N$ the size of neighborhood robust against the image size? It seems $N$ needs to be tuned for each image resolution, which can be critical, since images can come in at various sizes.\n\n- The paper claims that the method can be combined with LPIPS but I cannot find the experimental results on this. Does the combination actually bring improvements?"
            },
            "questions": {
                "value": "Written in the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Reviewer_8dYU"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839973792,
        "cdate": 1698839973792,
        "tmdate": 1700735930580,
        "mdate": 1700735930580,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "a66I2On7yD",
        "forum": "e4FG5PJ9uC",
        "replyto": "e4FG5PJ9uC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_WqhQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2943/Reviewer_WqhQ"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on generating perceptual embedding of an image, without using any training data. The paper also introduces and proposes a distance metric called LASI. The author goes on to compare the proposed method's performance with existing methods such as LPIPS and others."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper looks to solve an important problem in the domain of computer vision which is to qualify the quality of embedding generated which matches with its perceptual quality, without using any training dataset. \n- Conducts evaluation on the BAPPS dataset with other metrics such as LPIPS, PIM, and MS-SSIM.\n- Achieves comparative and better results in some cases compared to current state-of-art methods.\n- A good amount of side experiment details are shown to better verify the claims presented in the paper.\n-The paper for the most part of it well organized without any obvious typos and a writing structure that is easy to follow."
            },
            "weaknesses": {
                "value": "- There is minimal discussion about the failure cases using the proposed method. Would be great to have some qualitative results and the probable reason we are seeing the results as we see it.\n- Authors fails to discuss adequately why in some cases other metrics (such as PIM) excel compared to the LASI metric."
            },
            "questions": {
                "value": "1. In the results presented in Table:1, why does MS-SSIM outdo the author's proposed method for the BAPPS-JND task.. whereas it outperforms it for the BAPPS-2AFC task?\n2. As mentioned in the weakness section, it is imperative that authors present more details qualitative and quantitative about the failure cases seen using the LASI method proposed in the paper.\n3. In Section 5.3: \"....Results indicate LASI can find failure points for LPIPS and vice-versa......\" Can authors elaborate on this point ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2943/Reviewer_WqhQ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699473843339,
        "cdate": 1699473843339,
        "tmdate": 1699636237891,
        "mdate": 1699636237891,
        "license": "CC BY 4.0",
        "version": 2
    }
]