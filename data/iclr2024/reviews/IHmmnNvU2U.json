[
    {
        "id": "IRfBhim8U0",
        "forum": "IHmmnNvU2U",
        "replyto": "IHmmnNvU2U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_nCje"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_nCje"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel domain generalization method, Weighted Risk Invariance (WRI) to learn invariant features across different domains. By considering a linear causal setting, given several assumptions, the authors theoretically show that WRI provides an invariant predictor. They next introduce an empirical algorithm WRI, in which the model parameters and the density of the invariant feature distribution are jointly learned in an alternating minimization scheme. Experimental results on both synthetic (ColoredMNIST) and real-world (DomainBed) data show that WRI provides better performance in both classification and out-of-distribution (OOD) detection compared to two relevant baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written and easy to follow. The idea of introducing a Weighted Risk Invariance (WRI) approach to learn invariant features in domain generalization is interesting and novel. I appreciate the authors' effort to provide a theoretical guarantee of the satisfaction of the weighted risk invariance of their method. In addition, the empirical results of the paper demonstrate the benefits of the proposed WRI compared to two relevant approaches."
            },
            "weaknesses": {
                "value": "While I am aware that developing a fully theoretically sound domain generalization method is currently a big challenge in the community, my major concern is the main technical contributions of the paper. In particular,\n\n1. The key idea of the proposed relies on the assumption (depicted in a causal graph in Fig. 2) that the observed feature $X$ can be decomposed by $X_{inv}$ and $X_{spu}$ without any details or explicit explanations (in the method and also in the implementation of the algorithm) about the way to extract the invariant feature $X_{inv}$ from $X$. To obtain the key factor $X_{inv}$, one often has to apply a causal discovery algorithm [A], which is relatively complicated and time-consuming. \n\n2.  The definition of an invariant predictor (in Defn. 1) is not well-defined. Indeed, the invariance of the conditional distribution $p_e(f(X)|X_{inv})$ is not equivalent to the condition $f(X)=f(X_{inv})$. Furthermore, the domain invariant presentation in a general domain generalization should be based on the conditional distribution of the label given the input feature, i.e., $p_e(Y|g(X))$ with $g$ is a presentation mapping, not the predictor $f$. \n\n3. Though I did not have time to verify the proof of Proposition 1, I am still not convinced the result that the invariance of the predictor $f$ leads to the weighted invariance (Defn. 2). In addition, could you please clarify the real meaning of the definition of the weighted invariance (Defn. 2), also the way to verify that property?  I also would like to see the comments from other reviewers on this.\n\n4.  The experimental results of the paper are supportive, but not very convincing. In particular, it seems that the proposed WRI can only beat the related baselines (IRM and VREx) on the synthetic dataset (MNIST), while on the real-world dataset Domainbed, their performance is much similar, and WRI's even could not beat the naive ERM approach. \n\n[A]. @article{nogueira2022methods,\n  title={Methods and tools for causal discovery and causal inference},\n  author={Nogueira, Ana Rita and Pugnana, Andrea and Ruggieri, Salvatore and Pedreschi, Dino and Gama, Jo{\\~a}o},\n  journal={Wiley interdisciplinary reviews: data mining and knowledge discovery},\n  volume={12},\n  number={2},\n  pages={e1449},\n  year={2022},\n  publisher={Wiley Online Library}\n}"
            },
            "questions": {
                "value": "Please see my comments/questions in the Weaknesses part above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723598552,
        "cdate": 1698723598552,
        "tmdate": 1699636706982,
        "mdate": 1699636706982,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5dSxnfJ8DW",
        "forum": "IHmmnNvU2U",
        "replyto": "IHmmnNvU2U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_G5hc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_G5hc"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce a novel approach to deal with out-of-distribution generalization, particularly when invariant features are subjected to covariate shift. The method emphasizes the utilization of the weighted risk between diverse environments to ensure an invariant predictor. The authors provide theoretical guarantees for the identification of invariant features in linear data-generation processes. Empirical results on various datasets demonstrate the effectiveness of the proposed methodology."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Addressing out-of-distribution generalization is of paramount importance, given its wide applications.\n2. The invariance regularizer, grounded in weighted risks, is both theoretically sound and interesting.\n3. The paper is well-organized."
            },
            "weaknesses": {
                "value": "1. The authors assert that REx is limited to the homoskedastic setting, whereas their method can accommodate the heteroskedastic setting. However, the definitions appear to pertain to disparate scenarios. In the REx literature, homoskedasticity is tied to noise variance discrepancies across different $X$, while heteroskedasticity in this work relates to covariate shifts in invariant features. The rationale behind REx's inability to address the heteroskedastic covariate shift is not lucid. Moreover, the proposed WRI seems incapable of addressing the conventional heteroskedastic scenario, as varying noise variance for $Y$ across environments would render the weighted risk inconsistent across environments.\n2. The \"Comparison to IRM\" section is unclear. A formal proof delineating the superiority of WRI over IRM would enhance clarity. Integrating the REx loss in Figure 4 might also be beneficial.\n3. The implementation details are somewhat unclear. The reason behind employing an alternating minimization process, as opposed to direct optimization of Equation (9), is not explicit. Furthermore, ensuring the identification of invariant features via Equation (9) seems challenging. Notably, the final term in Equation (9) gravitates towards $d(x) \\rightarrow P_e(x)$, inclining towards a dependency on all features. Furthermore, it is unclear whether the second term of Equation (9) also contains other trivial solutions (like the all zero solution mentioned by the author).\n4. The omission of critical baselines, such as SWAD [1] and MIRA [2], potentially diminishes the empirical significance of the proposed technique. The authors' assertion in the appendix that non-causally motivated methods can occasionally outperform causally-based methods in domain generalization tasks appears to undermine the essence of leveraging causality-based techniques in this realm.\n5. In the \"OOD detection performance of our learned densities\" section, there is an absence of detailed explanation regarding the modified CMNIST test split incorporating mirrored digits.\n6. The discussion would benefit from a more extensive review of related work addressing covariate-shift generalization, e.g., [3][4].\n\n\n[1] Cha, Junbum, et al. \"Swad: Domain generalization by seeking flat minima.\" Advances in Neural Information Processing Systems 34 (2021): 22405-22418.\n\n[2] Arpit, Devansh, et al. \"Ensemble of averages: Improving model selection and boosting performance in domain generalization.\" Advances in Neural Information Processing Systems 35 (2022): 8265-8277.\n\n[3] Xu, Renzhe, et al. \"A theoretical analysis on independence-driven importance weighting for covariate-shift generalization.\" International Conference on Machine Learning. PMLR, 2022.\n\n[4] Duchi, John, Tatsunori Hashimoto, and Hongseok Namkoong. \"Distributionally robust losses for latent covariate mixtures.\" Operations Research 71.2 (2023): 649-664."
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767626146,
        "cdate": 1698767626146,
        "tmdate": 1699636706847,
        "mdate": 1699636706847,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "r9qMgO93vq",
        "forum": "IHmmnNvU2U",
        "replyto": "IHmmnNvU2U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_924Z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_924Z"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed Weighted Risk Invariance (WRI), a new optimization formulation for the OOD generalization problem. Particularly, the paper claims WRI to be able to recover invariant predictor even in the case of heteroskedastic covariate shift. The claim is justified theoretically under a linear causal setting. The paper also proposes a practical algorithm to solve modified WRI in the practical regime by alternating between learning the model parameters and the density of the invariant distribution. The experiments show outperforming results compared to other causally motivated methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is generally well written and easy to follow.\n- The proposal is well formulated, novel, and non-trivial.\n- Essential claims are theoretically justified for the linear causal setting.\n- Experimental settings are detailed."
            },
            "weaknesses": {
                "value": "Although the paper is interesting, I am having the following issue/concerns:\n- The introduction and comparison to (V)REx and IRM are separated, posing some difficulty in reading.\n- The usage of density estimates in OOD detection are not detailed but only a brief description in section 4.\n- No argument is provided for the non-linear case, even though the experiments on DomainBed does not follow the linear regime.\n- Lacking analysis on the difference between WRI and the practical objective."
            },
            "questions": {
                "value": "My main concerns are the final two points above, since without addressing them, the experiments are divorced from the first half. I am happy to adjust my score if the author can address these concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6384/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6384/Reviewer_924Z",
                    "ICLR.cc/2024/Conference/Submission6384/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825146664,
        "cdate": 1698825146664,
        "tmdate": 1700708052021,
        "mdate": 1700708052021,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jRNDwTCPKJ",
        "forum": "IHmmnNvU2U",
        "replyto": "IHmmnNvU2U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_qV1P"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6384/Reviewer_qV1P"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel problem formulation called \u201cWeighted Risk Invariance\u201d for domain-invariant feature learning in domain generalization. Under the given causal model and a given a set of input environments, the goal of domain-invariant feature learning is to recover a domain invariant predictor, which ensures that the model is robust to distribution shifts in new environments by only relying on invariant features. However, this can be challenging when covariate shift occurs in the invariant features themselves - which requires accounting for the distributions of the potentially shifted invariant feature. This is achieved via the proposed notion of \u201cWeighted\u201d risk invariance, which can be solved by reweighting the ERM loss function with the marginal density of the invariant features. Further, a practical objective is proposed to ensure that this objective recovers non trivial solutions,  enforced via a negative log penalty term which discourages small density estimates. These claims are thoroughly supported with experiments on both synthetic and real life datasets - achieving competitive performance with previous baselines such as IRM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, the paper is well written, well motivated and easy to follow. More specifically: \n1. The paper studies an important issue under a causal model where the invariant features themselves can shift across the observed train (and future test) environments. The proposed formulation of weighted risk invariance seems novel, and is more general / flexible setting to study domain invariance, going beyond the typically studied causal models.\n2. The paper is clear and concise - the problem is motivated very well via appropriate illustrations which make it easier for the reader to understand the importance of this work. For example, the comparison with IRM on Page 6 is interesting. Similarly, the experiments on the new proposed MNIST versions is also an interesting setup."
            },
            "weaknesses": {
                "value": "Please see below:\n1. While the paper does a good job of motivating the problem and showing results on synthetic setups, my main concern is reg. the experiments on real life datasets: that it is unclear whether a conclusion can be made. When does the proposed method work v/s when does it not, when it comes to real life datasets? Is there any reason behind these observations? What can one infer?\n2. Following up on the previous point, could the authors explain when might such a phenomenon occur in a real life dataset more explicitly? Perhaps a real life intuition would help.\n\nSee more questions / suggestions in the next question."
            },
            "questions": {
                "value": "Questions:\n1. Is there any assumption on the support of the invariant features? Is this why the practical objective has been proposed over the original formulation?\n2. Is there any guidance for the reader on when this method should and should not be used, given a dataset?\n\nSuggestions:\n1. It might be a good idea to include a summary of all experimental results in a visual format e.g. plot so that the results are easier to read through. \n2. It would be nice to visualize the new proposed colored MNIST example via an illustration to understand the setting used in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6384/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6384/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6384/Reviewer_qV1P"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6384/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699031905303,
        "cdate": 1699031905303,
        "tmdate": 1699636706552,
        "mdate": 1699636706552,
        "license": "CC BY 4.0",
        "version": 2
    }
]