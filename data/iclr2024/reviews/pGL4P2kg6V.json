[
    {
        "id": "668l6DI49J",
        "forum": "pGL4P2kg6V",
        "replyto": "pGL4P2kg6V",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_6BcB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_6BcB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a class incremental learning algorithm based on incrementally growing concept bottlenecks. It uses CLIP-dissect to identify neurons responsible for certain concepts and uses GPT to generate relevant concepts for a given class label. It freezes the part of the network that is responsible for previously learned concepts and adds new concepts for new classes. Lastly, the network maps from concepts to classes like in Concept Bottleneck Models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Using interpretable concepts as middle points to guide through incremental class learning is an interesting idea.\n- Using pretrained models (backbone, CLIP, GPT) to assist continual learning is a novelty.\n- Experimental results show that the proposed method is superior to other continual learning algorithms."
            },
            "weaknesses": {
                "value": "- Since the paper utilize a pretrained backbone, there is not much difference between the proposed method and the baselines. Moreover, it is unclear whether the gain comes from its continual learning ability or just the concept bottleneck. It would be good to see whether the proposed GPT+Concept Bottleneck procedure works well for a non-incremental learning setting.\n- The paper is most related to DEN, but there is no comparison to the method. The paper could be compared to DEN by having the same pretrained backbone network with additional two layers learned by DEN instead of incremental concept bottlenecks.\n- The paper lacks clarity on the GPT concept generation and filtering procedure. It would be helpful to give examples on what the concepts are (move some figures from Appendix to main text). It is also important to share the text prompts used to generate concepts."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699127146378,
        "cdate": 1699127146378,
        "tmdate": 1699636468030,
        "mdate": 1699636468030,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zp5pW6l2Y9",
        "forum": "pGL4P2kg6V",
        "replyto": "pGL4P2kg6V",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_zdWA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_zdWA"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a framework using CLIP Dissect to alleviate catastrophic forgetting in continual learning by controlling concepts. A neuron is denoted as a \u201cconcept unit\u201d if it activates highly, and is hence highly correlated with, a human-understandable concept. These concepts are architecturally added, frozen and reused in subsequent tasks. A continual extension to concept bottleneck models is also presented, which builds on top of Label Free-CBMs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Neuron-level interpretability used for continual learning is an underexplored direction. The paper builds upon several existing works like CLIP Dissect and LF CBMs, using them in a continual setting. The notion of concept evolution was quite interesting. Additionally, the background and related work sections are covered well. I also appreciate the detailed experimental studies presented in the Appendix."
            },
            "weaknesses": {
                "value": "**Scalability** \nThere is no analysis provided on the order of the number concepts added to Ct for new tasks. This would affect how scalable the method is, especially as it is mentioned that repeated concepts in subsequent tasks are added to the concept set as well.\n\n**Motivation**\nThe method does not seem to necessitate having interpretable concepts to alleviate catastrophic forgetting. The same thing could have been carried out on the classification layer itself using a vision-language aligned model and backbone. To be more specific, the entire dissection and subnetwork search process could have been performed directly on the classes. How are concepts or rather interpretability in general helping here? The paper seems to be attempting to address two different albeit related things, although the motivation for doing so is not very clear.\n\n**Formulation**\n* By design, it appears that the proposed method can only be used for CNN models and not transformer architectures. It would be nice to see how the proposed work can be more contemporary in its application.\n* In the freeze-all variant, it is possible that classes in newer tasks may be based on concepts that were available earlier. How would the model learn these associations if the weights for old tasks are not allowed to change?\n\n**Experiments**\n* The paper shows experiments on relatively small datasets. Related to my point on scalability, I would like to see some results on larger scale datasets.\n* The baselines for CL are not contemporary \u2013 there have been several state-of-the-art baselines for CL in the last 2 years, which are not considered. Additionally, no existing continual interpretable baselines have been included like ICICLE (ICCV 2023). (While I understand that the ICCV conference happened after the ICLR deadline, this work was available on arXiv since March 2023, https://arxiv.org/abs/2303.07811)\n* I would also like to see some analysis on other vision-language aligned models like FLAVA.\n* It would have been nice to see some discussion on subnetworks beyond Sec 3. How big were the learned subnetworks? How many weights were actually frozen on the different datasets?\n\n**Presentation**\nThe writing is unclear in a few places. For example: \n* \u201cit\u2019s not considering classification accuracy of CBM in continual learning setting, which is different than our goal.\u201d (pg 5) and \u201cthe Concept Controller strategy follows the similar idea as CC\u2019s in step 4\u201d (pg 6). It is difficult to understand what is trying to be conveyed in these sentences. \n* In Fig 3, it is not clear whether the network is from top to bottom or the other way, since there are no arrows. This makes it hard to understand the two schemes.\n* In Sec 3, the paper states that the subnetwork is frozen. In Sec 4, it states that the concepts are frozen. Is a concept a neuron or a sub-network? This is unclear. \n* Since the main premise of this work is on concepts and their subsequent use of interpretability, it would have been nice to see results such as Figures 6 and 7 in the main paper. The primary results in the main paper are all standard CL metrics. Note that Tables 3 (and 8 in the Appendix) only studies the concept consistency \u2013 it does not study interpretability."
            },
            "questions": {
                "value": "1. On expanding the concept set in successive tasks, it is stated that existing concepts are also added to the current concept set as they could capture a different context. Please clarify how this context is captured.\n2. How does the freezing strategy of concept controller account for old concepts occurring in new classes?\n3. How does the framework scale to large datasets?\n4. Other than the fact that a neuron-level interpretable model is being used, is such a model even necessary to the problem the paper attempts to address? As the same purpose could be served by using any VL-aligned model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699247761708,
        "cdate": 1699247761708,
        "tmdate": 1699636467947,
        "mdate": 1699636467947,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lmTsxiruwi",
        "forum": "pGL4P2kg6V",
        "replyto": "pGL4P2kg6V",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_Hm1u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4845/Reviewer_Hm1u"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a continual learning pipeline with quite a few modules (such as dissection-based continual training and concept bottleneck). The training also contains multiple steps. The final empirical results showcase its benefits compared to buffer-free continual learning methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is clearlly written and generally easy to follow.\n\n- The idea of introducing concept bottlenecks to continual learning is interesting and worth exploring.\n\n- The experimental results look good on the benchmark datasets."
            },
            "weaknesses": {
                "value": "- I find the proposed method quite complex and ad-hoc in general. The dissection-based continual training is interesting, but it is eseentially to incorporate the dissection into [1].\n\n- The introduction of label-free concept bottleneck to the proposed framework makes it even more complex and also difficult to find which part actually contributes to the performance gain. Therefore, an ablation study has to be performed. What if we combine label-free concept bottleneck to DER directly. How does it perform? The paper needs to study each added module carefully and show its advantages.\n\n- The motivation to design such a complex system is weak. The usage of label-free concept bottleneck will introduce additional information from GPT-3, which is questionable. One can easily achieve good performance if you use store the text label and perform zero-shot classification on continual learning dataset (which can easilly outperform your results). Even if you use label-free concept bottlenecks, the addtional text information is still leaked to your model. I am not sure whether this is still a fair comparison.\n\n\n\n[1] Der: Dynamically expandable representation for class incremental learning, CVPR 2021"
            },
            "questions": {
                "value": "See the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699248705053,
        "cdate": 1699248705053,
        "tmdate": 1699636467881,
        "mdate": 1699636467881,
        "license": "CC BY 4.0",
        "version": 2
    }
]