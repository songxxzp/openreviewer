[
    {
        "id": "YUQ4gdEVHu",
        "forum": "WkIsvAqoxA",
        "replyto": "WkIsvAqoxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission505/Reviewer_qsqM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission505/Reviewer_qsqM"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a diffusion-based layout generation model utilizing transformers. It removes the autoencoder layer typically used in a diffusion model for layout/image generation and directly operates on the layout input space. The proposed two model variants (Dolfin and Dolfin-AR) empirically improves performance across various metrics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is clearly written and easy to follow. \n2. The proposed models notably improve quantitative results against generative layout benchmarks."
            },
            "weaknesses": {
                "value": "1. The main difference with previous models is by operating directly on the input space of layouts (the coordinates and corresponding class labels) instead of processing the layouts with VAE/dedicated modules. However the reasons for the brought-in performance gains are not sufficiently justified.  \n2. \"enhancing transparency and interoperability\" is overclaimed since it is a property of the standard diffusion process itself. \n3. From the paper presentation it is not clear what are the modifications to the original DiT transformer other than omitting a category input."
            },
            "questions": {
                "value": "1. Why is operating on the original layout space better, especially when processing such data with dedicated neural modules is quite standard ? e.g. other than mentioned related works also standard in other generative models such as [1]. Could it be that the training data is insufficient? \n2. Please check the metric arrow directions in Table 3, 4, 5.\n3. In Fig.6, the generated samples exhibit some obvious unnaturalness (e.g. blue frames, bottom left, the window lines). Similar patterns exist in Fig.13. Is it because of insufficient training ? Could you compare it with PLay? \n\n[1] GLIGEN: Open-Set Grounded Text-to-Image Generation"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698477193014,
        "cdate": 1698477193014,
        "tmdate": 1699635977050,
        "mdate": 1699635977050,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iZ6r6yCMlB",
        "forum": "WkIsvAqoxA",
        "replyto": "WkIsvAqoxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission505/Reviewer_SyW2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission505/Reviewer_SyW2"
        ],
        "content": {
            "summary": {
                "value": "Diffusion Layout Transformers without Autoencoder (Dolfin) is proposed, with an efficient bi-directional (non-causal joint) sequence representation. An autoregressive diffusion model (Dolfin-AR) is also proposed to capture rich semantic correlations for the neighboring objects. The method is validated on 2D layout generation and line segment generation tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- not requiring the autoencoder layer in the diffusion model\n- autoregressive diffusion model to capture the rich semantic correlation between objects/items\n- experiment on generating geometric structures beyond layout, such as line segments"
            },
            "weaknesses": {
                "value": "- not using auto encoder is not a new idea, Imagen model is processing directly on pixels\n- there is no intuition on why auot-regressive design leads to better semantic correlation, although this is observed from experiments\n- not many baselines comparison for the line segment generation"
            },
            "questions": {
                "value": "- explain the intuition of the advantage of auot-regressive design\n- compare with image diffusion results for line generation, line representation can be obtained followed by a line detector\n- each object in a layout is represented by a 4 \u00d7 4 tensor, why we need 4 entires for the entire layout width/height? Once it's normalized, is that always -1/1?\n- in Algorithm 1 and 2, is it better to use a different index than \"t\" in the for loop? The for loop index has different meaning than the diffusion step t."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698520008886,
        "cdate": 1698520008886,
        "tmdate": 1699635976981,
        "mdate": 1699635976981,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AEInTzfRbi",
        "forum": "WkIsvAqoxA",
        "replyto": "WkIsvAqoxA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission505/Reviewer_eh4o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission505/Reviewer_eh4o"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces \"Dolfin,\" a generative model that uses a transformer-based diffusion process for layout generation. The proposed method directly applies on the input space of the geometric objects. The method benefits from bi-directional representation and consists of two versions, the non-auto regressive version that process all tokens simultaneously and the auto-regressive version that predicts each token sequentially. The authors provided experiments on RICO and PublayNet datasets for layout generation task as well as additional experiments on Line Segments Generation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is detailed and easy to follow.\n\nAdditional experiments on line segment generation can be useful to consider along with the other tasks."
            },
            "weaknesses": {
                "value": "The paper offers potential value to the community. However, concerns regarding its novelty and the robustness of its experimental evaluations need to be addressed for it to be ready for publication.\n\nNovelty: The core proposition of the paper, which involves the utilization of the input coordinate space for layout design generation through continuous diffusion models, is not entirely novel. Similar approaches have been discussed in prior works such as [1, 2].\n\nExperiments and Comparison: The experiments presented currently lack comprehensiveness. The results in Table 1 do not facilitate a fair comparison between the proposed method and existing methods. Although Tables 2 and 3 provide more data points, they restrict their focus to MaxIoU and Alignment scores. Furthermore, the results suggest that the proposed method underperforms compared to the baselines. This underscores the need for a more in-depth analysis and comparison.\n\n\n[1] LEGO-Net: Learning Regular Rearrangements of Objects in Rooms, CVPR 2023\n[2] HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising, CVPR 2023"
            },
            "questions": {
                "value": "Considering the large batch sizes which are used in the experiments (10k and 6k) compared to the conventional batch sizes up to 2048, adding a table on the effect of the batch size on the final result can be very insightful.\n\nI couldn't find any direct comparison on pros and cons of the Dolfin and Dolfin-AR. It is better if you also add both versions to other tables as well."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698801433397,
        "cdate": 1698801433397,
        "tmdate": 1699635976898,
        "mdate": 1699635976898,
        "license": "CC BY 4.0",
        "version": 2
    }
]