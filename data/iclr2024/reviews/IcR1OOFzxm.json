[
    {
        "id": "EUmAsCpJ4e",
        "forum": "IcR1OOFzxm",
        "replyto": "IcR1OOFzxm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_TA5q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_TA5q"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes RAISE, Rule AbstractIon and SElection model for generative abstract reasoning. In particular, the model is evaluated on Raven's Progressive Matrices. To solve a Raven problem, the model first encodes the context images and samples the latent rule for different latent concepts and generates the answer. On both RAVEN and I-RAVEN, the model shows improved performance while being generative, and also the model enables arbitrary panel generation and odd-one-out problem testing."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The best generative solution I'm aware of for solving the abstract reasoning problem, while problem structure has been taken into the design. To the best of my knowledge, previously similar performance is only attained by discriminative models and this is the first of the generative model to achieve similar performance. The authors have also tested the model on different setups, and the results are good enough.\n\nThe authors have shown sufficient experiments to show the meaningfulness of the latents: by varying the latents, they could get desired image results.\n\nWhile the problem formulation follows the conventional approach, the problem decomposition makes sense and is intuitive."
            },
            "weaknesses": {
                "value": "The formulation for conditional generation is rather standard. While it is not exactly the same as conditional VAE, the derivation follows the same principles and the tweaks are only made due to the structured inference prior employed in modeling.\n\nIn general, I don't think the comparison is completely fair compared to other baselines, as some of the baselines only use the ground truth answers. While RAISE only uses the rule annotations, grounding of rules to corresponding hidden concepts is also implicitly encoded in the matrix. So supervisory signals could actually be backpropagated to the attribute / concept part. Besides, in evaluation, I do note that PrAE and ALANS are only trained on a specific split whereas RAISE are trained on more than one, and that is at least twice the data.\n\nOne thing I'm not particularly sure is how is the answer selected in RAISE. When you generate the answer, how do you pick the candidate from the given set? PrAE and ALANS actually only generate the hidden latents and compare in the latent space. Do you compare in the pixel space? Do you think comparing in the hidden space would help further improve performance of RAISE?"
            },
            "questions": {
                "value": "Check above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6119/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834902316,
        "cdate": 1698834902316,
        "tmdate": 1699636662247,
        "mdate": 1699636662247,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FW1h5KPaJj",
        "forum": "IcR1OOFzxm",
        "replyto": "IcR1OOFzxm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_qkwH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_qkwH"
        ],
        "content": {
            "summary": {
                "value": "A new model -- RAISE has been proposed by the authors for RAVENs. The model contains several components, such as an image encoder, two variation autoencoder, and a global knowledge set. This model first extracted image features and then used these features to generate answers by a conditional generative process. The proposed model was evaluated through experiments on RAVEN and I-RAVEN datasets and showed better performance than other generative-based methods. Ablation studies showed the proposed RAISE can better handle the selection in arbitrary positions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is generally well-written and the main idea is easy to follow.\n\n2. The authors proposed a new generative model -- RAISE that can explicitly encode rule-related information. It will be more useful to construct interpretable machine learning algorithms in this community.\n\n3. The authors showed that their RAISE can perform better than previous generative methods, and is also on par with some of the existing selection-based methods.\n\n4. The authors also analyze the proposed models with different experiments."
            },
            "weaknesses": {
                "value": "1. The authors fail to convince me, why we need to generate answers in arbitrary positions ? I am eager to see what is the advantage of generating an arbitrary position over generating the right-bottom answer, not only the final performance, but also the rationale or the motivation behind this design.\n\n2. Whether the model shown in App is used in all configurations or not?\n\n3. Too many hyper-parameters should be tuned.\n\n4. Experiments are not enough. I suggest using PGM-Neutral, PGM-Interpolation and PGM-Extrapolaton to confirm the effectiveness of RAISE.\n\n5. The authors also should clearly state why to use rule annotations, but not the answer images. Which indeed violates the RPM question. \n\nOverall, it is a borderline paper"
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6119/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698836683033,
        "cdate": 1698836683033,
        "tmdate": 1699636662139,
        "mdate": 1699636662139,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VahTwBgmZp",
        "forum": "IcR1OOFzxm",
        "replyto": "IcR1OOFzxm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_w266"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_w266"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a conditional generative model for Raven progressive matrices. It is trained from images, encoding each image into a set of C Gaussian latents, which can be decoded back to images, while also learning a set of K rules governing how a target image is composed (given its position in the grid and what the inferred progressive rule is). It is trained through an ELBO loss with some partial auxiliary rule supervision.\n\nIt shows clear advantages compared to existing baselines, both in terms of actual accuracy, but also in flexibility, as it can generate images in arbitrary cells of the RPM.\n\nOverall, the generative model is rather straightforwardly designed, albeit feels rather specific to RPM problems, hence this is addressing a very specific problem and significance might be limited. I also have a few reservations about some baselines (in particular the Transformer one)."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is very clear, presents the problem well, and the math is clear and easy to follow. Figure 1 is very helpful to unpack the generative process, and overall I feel like it made all its choices clear. I could find nearly all details I needed about the implementational details (see questions below)\n2. Experiments are comprehensive and well executed, with a good choice of baselines (I am not an expert in RPM however)\n3. From results shown in Figure 2, I think it\u2019s fair to say that it \u201csolves\u201d PGM quite effectively, but an expert might be able to comment better on the complexity of this problem for current SOTA."
            },
            "weaknesses": {
                "value": "1. This is a generative model designed specifically for RPM, and it is unclear how one would leverage this work or its findings in any other context.\n2. It is equally a \u201cstraightforward\u201d application of an ELBO-based generative process. It is well executed, but not surprising and I did not find particularly interesting pieces of technical/insightful choices throughout the paper.\n3. It is unfortunate that some amount of rule annotation is still used. It oscillates between amounts (5% for non-grids, 20% for O_IG and 100% for 2x2 and 3x3 grids), but I was wondering what the performance would have been with 0% supervision, as this seems like the \u201coptimal\u201d solution target for RPMs."
            },
            "questions": {
                "value": "1. Do you have any suggestions for what one can learn from your model that can be generalized away from the RPM setting? Any specific insights / technical novelty compared to previous works?\n2. Most decisions were extremely clear, but it was not that well explained how candidate answer selection was performed (Section 4.1 and 4.2)\n   1. Do you generate a sample x_t and compare to the x_candidates in pixel space?\n   2. Do you generate a z_t and compare g^enc(x_candidates)?\n   3. Do you instead do a likelihood test?\n3. Finding values for C and K required going into the Appendix (C=8, K=4), and their choice wasn\u2019t discussed.\n   1. How sensitive is the model to varying C or K?\n   2. How were these chosen? How adapted to the number of attributes and real rule numbers do they have to be? I\u2019m aware they are different, but how sensitive is it e.g. can you use K=100?\n4. The Transformer baseline lacked details, even in Appendix C.3.\n   1. Which encoder did you use? Was it a discrete representation? Transformers behave much better on VQ-like latents.\n   2. I somehow expected it to do better, e.g. if attributes were provided instead of pixels, isn\u2019t a Transformer a pretty strong baseline?\n5. How needed was the rule supervision?\n   1. Do you have numbers when you drop this to 0?\n6. Nits/typos:\n   1. It would have helped to explicitly write that r^c takes values between 1 and K.\n   2. \\mu_T^c -> \\mu_t^c in (4)\n   3. z_T^c -> z_t^c in (6)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6119/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698869031156,
        "cdate": 1698869031156,
        "tmdate": 1699636662010,
        "mdate": 1699636662010,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Q4xfHI1M1B",
        "forum": "IcR1OOFzxm",
        "replyto": "IcR1OOFzxm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_5rkm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6119/Reviewer_5rkm"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel method (RAISE) for solving Raven's Progressive Matrices (RPM) abstract visual reasoning problems. RAISE is a deep latent variable model, that learns the underlying rules in an RPM problem as latent variables and then uses the learned rules to conditionally (based on the context rows/columns present in one problem) generate the target image. The authors show that this leads to strong results for standard RPM reasoning tasks, generalizes better to more esoteric tasks (like answer selection at random locations). The visualization of latent concepts also shows that the latent variables are able to reasonably capture the atomic rules underlying the reasoning problem."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The motivation of building a generative solver versus a selective one to avoid shortcuts in discriminative reasoning task is very valid and has been highlighted in prior literature [1, 2]. I commend the authors for trying to solve the harder problem in RPM reasoning: mapping the underlying data generative process.  \n* The RAISE model is very well thought our and describe in the paper. The modelling choices make sense for the few-shot style reasoning tasks in RPM problems. Also see weaknesses regarding the motivation and usability in a broader context.\n\n\n**References** \n\n1. Hu, S., Ma, Y., Liu, X., Wei, Y. and Bai, S., 2021, May. Stratified rule-aware network for abstract visual reasoning. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 2, pp. 1567-1574).\n2. Geirhos, R., Jacobsen, J.H., Michaelis, C., Zemel, R., Brendel, W., Bethge, M. and Wichmann, F.A., 2020. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2(11), pp.665-673."
            },
            "weaknesses": {
                "value": "* In Sec 1. Introduction: \"It has been suggested that Bayesian inference with shared latent concepts can explain the emergence of in-context learning in LLMs, which is the foundation of few-shot reasoning in tasks like RPM tests.\" This premise has several logical leaps which the authors don't explain. For example, Chan et al [1] showed that the nature of training data for natural language enables few-shot reasoning from in-context learning. This does not hold for RPM reasoning tasks - the data distribution does not have the same long tailed and co-occurence properties as natural language. Similarly, Bayesian inference of shared latent concepts being able to explain in-content learning is just one lens of explainability for this empirical phenomenon, and there can be other lenses which are purely frequentist (e.g. the one showed by Chan et al). Overall, the motivation derived for RAISE from this statement is very loose and falls apart on deeper inspection.\n\n* My chief concern witht this paper, and the overall idea behind structuring latent representations and re-combining them at inference is how scalable is it beyond toy problems like RPMs? The bottleneck with DLVMs like RAISE is two-fold: learnability (e.g. authors re-use encoder parameters between generative and inference process) and reliance on human knowledge to design the graphical model. RPMs have a very limited rule set, and the visual abstraction process is vastly simpler than human scenes. These reasons why existing concept learning methods that rely on similar modelling and inference have not been able to scale to harder visual reasoning problems are yet to be solved.  \n\n* In Sec 3.1 \"Previous studies have emphasized the role of abstract object representations in the abstract reasoning of infants, which is similar to the idea of object-centric representation learners that decompose complex scenes into object representations. Both views reflect the compositionality of human cognition (Lake et al., 2011).\" I don't know if the human analogy to concept learning should drive artificial concept learning agents, particularly because the underlying constraints (inductive biases?) on human and artificial systems are vastly different. A much more recent work from Lake et al [2] shows that neural network based reasoning combined with a meta learning objective can solve similar systematic generalization problems. I would also refer the authors to the discussion section of the paper for a much more nuanced discussion on Bayesian vs Neural approaches to learning systematicity. For a similar treatment of systematic reasoning by learning the underlying rule structure and routing at inference but from a purely neural treatment, I would refer the authors to [3] which also reports strong results on RPM style reasoning tasks.\n\n**References** \n\n1. Chan S, Santoro A, Lampinen A, Wang J, Singh A, Richemond P, McClelland J, Hill F. Data distributional properties drive emergent in-context learning in transformers. Advances in Neural Information Processing Systems. 2022 Dec 6;35:18878-91.\n2. Lake, B.M. and Baroni, M., 2023. Human-like systematic generalization through a meta-learning neural network. Nature, pp.1-7.\n3. Rahaman, N., Gondal, M.W., Joshi, S., Gehler, P., Bengio, Y., Locatello, F. and Sch\u00f6lkopf, B., 2021. Dynamic inference with neural interpreters. Advances in Neural Information Processing Systems, 34, pp.10985-10998."
            },
            "questions": {
                "value": "I don't have particular questions regarding the paper: I think it is a good paper, and the authors achieve what they set out to do in the introduction. My main concern is whether this is the right thing to do, especially for more \"real-world\" reasoning problems where the cardinality of the rule set is exponentially larger. I think the paper would benefit from the authors providing a more comprehensive discussion on Bayesian vs Neural concept learning since their current motivation on building a DLVM is not very convincing. \n\nMinor question: In Sec 5. \"Too much noise will make a problem have a large number of solutions (e.g., PGM (Barrett et al., 2018)), such data may not be proper for validating the generative reasoning ability of models\" I am not exactly sure what the authors mean by \"a problem have a large number of solutions\" - does this refer to potentially many rule compositions satisfying the bottom-right answer selction in RPMs."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6119/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699031014542,
        "cdate": 1699031014542,
        "tmdate": 1699636661908,
        "mdate": 1699636661908,
        "license": "CC BY 4.0",
        "version": 2
    }
]