[
    {
        "id": "io6ubqf4E7",
        "forum": "AqaFgmH87p",
        "replyto": "AqaFgmH87p",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_fLMf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_fLMf"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses recent advancements in differentially private (DP) deep learning, focusing on large vision and language models with millions to billions of parameters. The authors find that different group-wise clipping styles offer an accuracy-memory trade-off. While all-layer clipping is commonly used and provides better accuracy, it requires more memory compared to group-wise clipping. The paper formalizes this trade-off through convergence theory and complexity analysis. Importantly, it demonstrates that the accuracy gap between group-wise and all-layer clipping decreases with larger models, while the memory advantage of group-wise clipping remains, allowing DP optimization of large models with high accuracy and low peak memory usage."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper addresses an important aspect of DP deep learning, namely gradient clipping, which is crucial for privacy-preserving training of large models. It thoroughly explored the design space of group-wise clipping styles for various learning tasks.\n\nEmpirical Experiments: The paper includes a good set of experiments to support its claims."
            },
            "weaknesses": {
                "value": "**Motivation of Group-Wise Clipping**: In the abstract, the paper claims The paper lacks a clear and strong motivation for why group-wise clipping is a necessary or valuable alternative to all-layer clipping as **all group-wise clipping enjoy almost the same training speed as the standard non-DP optimization**. Meanwhile the memory cost does not differentiate too much across various grouping choices, either (see Table 3 and Figure 5).\n\n**Confusing measures**: There are several terms used across the paper, e.g., time complexity, training speed, memory cost. The paper should define them clearly whether they are theoretically or empirically computed. If empirically, the training speed and the memory cost are jointly affected by the setup of the batch size, model size and the model architecture. Book-keeping technique would store the backward gradients on the output of each operation, the same as storing the activations, which may have memory problem when the batch size is large. \n\nAs a following weak point, the paper does not talk about the implementation detail and wall-clock training speed comparison.  This is because the non-uniform grouping is complex to implement and the wall-clock training speed is the ultimate measure for different choices.\nThe cost of searching the best non-uniform grouping is not counted.\n\n**Relevance of Theory**: The theoretical analysis may not provide sufficient insights into practical scenarios. The upper bound gets sub-linearly (sqrt) worse as the number of the groups increases, which is not reflected in real experiments. Theorem 2 is a bit trivial and does not convey much information related with the target of the paper. \n\n\n**Experiments presentation**: The experiments are cherry picked in the main text. It seems that the results of the paper are not as good as the result of He et al. 2022 in Appendix C, which are excluded from the main text. Moreover, all the experiments consider the fine-tuning setting, which is not clearly stated in the main text. There lack training scratch experiments for full comparison."
            },
            "questions": {
                "value": "Questions about the experiment results.  In Table 3, the memory cost increases as you increases the number of groups for QNLI RoBERTa-base. This contradicts with theory analysis and all other experiments. Can the authors explain why this happens?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Privacy, security and safety"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The paper studies how to protect the privacy of dataset when training with large models. It explores new algorithms/methods for the privacy protection."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698919856875,
        "cdate": 1698919856875,
        "tmdate": 1699636356427,
        "mdate": 1699636356427,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rjwJXPZLvu",
        "forum": "AqaFgmH87p",
        "replyto": "AqaFgmH87p",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_yntr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_yntr"
        ],
        "content": {
            "summary": {
                "value": "This paper studies group-wise clipping for optimization under differential privacy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The issues discussed in this article regarding optimization under DP are timely and critical. The performance loss caused by DP necessitates urgent solutions for these problems."
            },
            "weaknesses": {
                "value": "The paper lacks novelty as the proposed clipping method is an extension of the existing Book-Keeping\ntechnique Bu et al. (2022c). Furthermore, the convergence analysis relies on smoothness assumptions.\n\nI also disagree with the authors' perspective that \"Differentially private (DP) optimization of deep learning models has enjoyed amazing accuracy and rigorous guarantees against privacy risks.\" From my knowledge, accuracy loss remains a significant obstacle, which is also the problem this paper aims to address."
            },
            "questions": {
                "value": "Are there any hyperparameters that need to be tuned for the proposed clipping methods? If so, do these adjustments come at an additional privacy cost? Has the paper reported these associated costs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699073603222,
        "cdate": 1699073603222,
        "tmdate": 1699636356352,
        "mdate": 1699636356352,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ANNaQteFQx",
        "forum": "AqaFgmH87p",
        "replyto": "AqaFgmH87p",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_nK9w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_nK9w"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the group-wise clipping approach in DP, and gives analysis on its convergence and its algorithmic relation to back-propagation. The authors also analyze the system wise metrics such as peak memory profile usage. Empirical results are given on GPT2 and ViT models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper provides detailed analysis to the group-wise clipping technique in DP domain, some of the conclusions are interesting to this field.\n* The authors give both insights from theory and system perspectives.\n* The authors also set up new baseline results, which could potentially be a good reference for further work in this space."
            },
            "weaknesses": {
                "value": "* From the peak memory profile results, i.e. Table 3 and Figure 5, it looks like the peak memory usages for different boundaries are pretty close (in general less than 2 GB). I'm not sure how much this can lead to faster training and larger batch sizes. For example, what is the new batch size that can be used, and how much speed up we gain? Some real-world numbers here could be beneficial.\n* From Theorem 1, it looks like the AUTO algorithm obtains the same convergence speed compared to the standard SGD. However, the standard SGD does not require per-sample gradient to be symmetric about the oracle gradient as shown in Assumption 4.3. I wonder if this is critical for AUTO to get on-par convergence speed to SGD? What will the convergence rate be like without such assumption?\n* In the paper, the authors object to the conclusion of https://arxiv.org/pdf/2212.01539.pdf with a self-designed group-wise clipping algorithm for faster training speed. However, I don't see too much evidence supporting this. Could you show a convergence curve?"
            },
            "questions": {
                "value": "Please refer to the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699207881468,
        "cdate": 1699207881468,
        "tmdate": 1699636356276,
        "mdate": 1699636356276,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YmVDzuEr8W",
        "forum": "AqaFgmH87p",
        "replyto": "AqaFgmH87p",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_RBj1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3955/Reviewer_RBj1"
        ],
        "content": {
            "summary": {
                "value": "Recent advances in differentially private deep learning have improved accuracy, memory efficiency, and training speed for large models. This paper focuses on per-sample gradient clipping methods in DP optimization. It finds that different clipping styles have similar time complexity but trade off accuracy and memory usage. All-layer clipping offers better accuracy but requires more memory than group-wise clipping. As models grow larger, the accuracy gap narrows, while the memory advantage of group-wise clipping remains, making it suitable for efficient DP optimization of large models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ It's an interesting paper that leverages memory-accuracy tradeoff of group-wise dp optimization with different granularity. \n+ The key observation about dS doesn't depend on dW so that the computational time doesn't depend on m provides great ml-sys type of insights. \n+ The ViT experiments on Cifar100 is convincing."
            },
            "weaknesses": {
                "value": "- The presentation needs some work. The paper contains multiple contributions and a lot prior work / settings, which was clear in the introduction, but very confusing in later sections. For example, I was very confused about the equal time efficiency part because authors wrote this contribution directly so I thought that was the previous design. Specifically, if this is the contribution, I would sign-post it at the beginning of section 3 what are the conventional wisdom and why a simple analysis on computational dependency graph (you don't need dW to derive dS) would do the work. It requires many passes of reading and reasoning to get the point. \n - The presentation of experiment section is poor. Also ImageNet is mentioned at the beginning but the experiments don't have it? In addition, cifar10/100 (better imagenet) are convincing Image baselines, but why using E2E dataset in the last experiment 1) it is not popular for decoder only model 2) you didn't benchmark the peak memory for gpt. Also I understand you benchmarked peak memory before, but table 5 and 6 better have acc and peak mem side by side."
            },
            "questions": {
                "value": "I'm curious in authors' view, is this 1-2 GB memory difference significant? Or in another word, is this an important tradeoff worth studying to begin with?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3955/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699245082035,
        "cdate": 1699245082035,
        "tmdate": 1699636356202,
        "mdate": 1699636356202,
        "license": "CC BY 4.0",
        "version": 2
    }
]