[
    {
        "id": "Du0TdvvOla",
        "forum": "GrRZz9qqJp",
        "replyto": "GrRZz9qqJp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_oRYb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_oRYb"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the underlying mechanism of the masked language model. Similar to the situations in contrastive learning, the authors propose to explain the success via the spectral clustering framework and establish the underlying clustering structure in the natural data is the key. The only difference is that pairs are from human heuristic in contrastive learning (i.e., pairs of data after augmentation), whereas here the pairs are from the natural data (i.e., a token and the surrounding data). The authors also provide some empirical evidence that validates their result."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- They extend the theory of spectral contrastive learning to the masked language model domain, which is a meaningful generalization of the original theory.\n- The paper is well-written and the experimental details are stated clearly."
            },
            "weaknesses": {
                "value": "- The theory is largely the same as the original spectral contrastive learning paper despite different definitions of positive pairs. There seems to be a lack of theoretical innovation despite mainly being a theory paper.\n- The experiments are largely on vision data. Would be great to include more experiments on language domain which is where masked token prediction is widely used.\n- There's a lack of explanation of why the clustering structure appears in the first place."
            },
            "questions": {
                "value": "- Do you have any intuition on how much the inductive bias comes into play? Since the tokens of different locations are largely treated as different tasks in the spectral contrastive learning theory, it seems like there must be some inductive bias that makes the representations similar across different places."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698463187447,
        "cdate": 1698463187447,
        "tmdate": 1699636243088,
        "mdate": 1699636243088,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UKw5JUX5NJ",
        "forum": "GrRZz9qqJp",
        "replyto": "GrRZz9qqJp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_rQ46"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_rQ46"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a theoretical framework for understanding mask models and establishes the connections between mask models and spectral contrastive learning. Based on that, the paper explains some important designs in mask models. Empirically, the authors verify their assumptions and theoretical analysis (e.g., the choices of mask ratios, batch normalization, and backbone architecture are important in MAE models) on real-world datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The theoretical analysis of mask models is important and under-explored. The connection between mask models and contrastive learning is interesting."
            },
            "weaknesses": {
                "value": "1. Based on the theoretical analysis in Section 4, the objective of mask models is equivalent to the spectral contrastive loss. However, I think there exists an obvious difference, i.e., the adjacent matrix in contrastive learning represents the probability that two samples can be selected as a positive pair while that in mask models represents the input similarity of two samples. And the discussions in this paper about that are not enough. For example, I do not think the models can learn meaningful representations if we select positive pairs in contrastive learning based on the input similarity. \n2. I think there are too many detailed proofs in Section 4 and it is hard to capture the main messages derived in the Theorems.\n3. I note that the theoretical analysis assumes the encode-decoder architecture is equivalent to the encoder in contrastive learning. However, in downstream tasks, we usually only use the encoder $f$. Is it possible to theoretically analyze the downstream performance?\n4. The experiments in this paper verify the theoretical analysis. However, is it possible to provide new insights to further increase the performance of mask models based on the analysis?\n5. $N$ denotes different meanings in the proofs of Theorem 4.3 and Lemma 4.6."
            },
            "questions": {
                "value": "see my comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698568517803,
        "cdate": 1698568517803,
        "tmdate": 1699636242991,
        "mdate": 1699636242991,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wneDrszcOk",
        "forum": "GrRZz9qqJp",
        "replyto": "GrRZz9qqJp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_wnEL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_wnEL"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a theoretical framework for understanding the working mechanism of masked image modeling (MIM). Specifically, this paper connects MIM with spectral clustering, through which MIM is viewed as a token-level contrastive learning. This view explains several intriguing empirical questions: 1) varying optimal masking ratios across domains, 2) the large performance gap between linear probing and fine-tuning, and 3) the interaction between MIM and model architectures."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem, understanding performant deep learning techniques from a theoretical perspective, provides insights into harnessing existing frameworks and developing novel approaches for practitioners. This work gives intuitions to certain behaviors of MIM as listed in the summary."
            },
            "weaknesses": {
                "value": "\u2022 The contributions over prior work are not fully discussed. For instance, the connection between spectral clustering and contrastive learning has already been studied in [1], whereas this paper is not discussed in the paper. In my opinion, there is a significant overlap between the messages (e.g., masking ratios), which largely weakens the current work's contribution.\n\n\u2022 This paper lacks substance in theory. The major theory in this paper connects MIM and contrastive learning, which has already been given in [1]. Moreover, the remarks relating theory to MIM behaviors (i.e., Section 5) are somehow either too sloppy or straightforward. For instance, I don't see the logical connection between the number of clusters and the number of attention heads in line 256-257. I would appreciate either mathematical illustrations or more rigorous explanations for statements like this. \n\n\u2022  I find the experimental section highly underwhelming for a paper aiming to understand empirical behaviors. The results regarding MAE (Section 6.3 and 6.4) are already well known (finetuning > linear probing) and can be totally expected (more attention heads -> higher performance). They do not directly substantiate and are not specific to the theoretical insights.\n\n[1] https://arxiv.org/abs/2210.08344\n\nSome typos:\n\nline 38: \"..\"\n\nline 153: \"are utilize\""
            },
            "questions": {
                "value": "I would like to learn about the authors' response to the weaknesses listed above, which may give me a clearer perspective on the paper's contribution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Reviewer_wnEL"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698759655859,
        "cdate": 1698759655859,
        "tmdate": 1699636242905,
        "mdate": 1699636242905,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QqePa1ldjw",
        "forum": "GrRZz9qqJp",
        "replyto": "GrRZz9qqJp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_zZgx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2984/Reviewer_zZgx"
        ],
        "content": {
            "summary": {
                "value": "This paper conducts a theoretical study of masked image modeling (MIM) that relates the masked image modeling objective to a type of contrastive loss.  The theory shows that training a model to reconstruct the masked image patches is equivalent to minimizing a \"token-wise\" contrastive loss defined over the image patches.\n\nIn regular spectral contrastive loss, the adjacency matrix is based on similarity from external knowledge (e.g., certain data augmentations should result in similar representations). In this case, the adjacency matrix is based on the inner products between low-rank patch approximations in pixel space."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Attempts to relate mask-reconstruction pretraining (typically thought of more as a generative pretraining method than a contrastive one) with contrastive losses, for which a number of theoretical results are known.\n\n- The theory suggests intuitive ways of setting parameter choices for masked pretraining (Section 5)."
            },
            "weaknesses": {
                "value": "- Possibly interesting results obscured by poor presentation. For example:\n\n    - why is the input $X$ in the minimizations (1)/(5)? I thought the input was typically a random set of patches. Clearly the min over $X$ can typically be obtained by setting $X = X_0$. The MAE paper does not optimize over the input patches.\n    - The token mixing layer definition is unclear and seems out of place. What does it mean to mix features on the patch level? Not defined here in a self-contained way.\n\n    -  The construction in Section 4 is very unclear. What's the graph $G$? What are the nodes---patches? How are patches defined? How many possible patches are there? How is the rank $r$ defined?\n\n    - How should I think about this adjacency matrix? Why is the inner product between low-rank patch approximations in pixel space the right way of thinking about patch similarity?\n\n    - L158-159: _\"Given the corresponding normalized adjacency matrix A, optimizing mask modeling is equivalent to optimize the following loss on classification downstream tasks\"_\n\n        Why \"downstream tasks\"? This looks like a pretraining loss.\n    - There are numerous typos and grammatical errors throughout.\n\n- The title seems like overselling. \"Mask Models are Token Level Contrastive Learners\" makes it sound like it also applies to BERT-style masking in NLP, but the motivation, assumptions, and details all heavily focus on the image modeling case. It should be clear that it's about masked *image* models\n\n- Missing several relevant references, e.g. [1], [2]. The latter analysis is general and seems like it might apply to the masked modeling case as well.\n\n- The predictions in Section 5 on the correct way of setting parameters like the masking ratio are not tested here empirically, and they rely on several untested assumptions (such as that $rank(g(f(X))$ is a constant proportional to the number of visible patches).\n\n\n- The earlier theory does not explain the results in Section 5/6 on token mixing layers and batch normalization. There is no rigorous statement that connects back to Sections 3 and 4 showing that e.g. batch normalization layers will improve linear probing performance.\n\n[1] Wei, Colin, Sang Michael Xie, and Tengyu Ma. \"Why do pretrained language models help in downstream tasks? an analysis of head and prompt tuning.\" Advances in Neural Information Processing Systems 34 (2021): 16158-16170.\n\n[2] Balestriero, Randall, and Yann LeCun. \"Contrastive and non-contrastive self-supervised learning recover global and local spectral embedding methods.\" Advances in Neural Information Processing Systems 35 (2022): 26671-26685."
            },
            "questions": {
                "value": "(see above questions about presentation)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2984/Reviewer_zZgx"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698879508055,
        "cdate": 1698879508055,
        "tmdate": 1699636242831,
        "mdate": 1699636242831,
        "license": "CC BY 4.0",
        "version": 2
    }
]