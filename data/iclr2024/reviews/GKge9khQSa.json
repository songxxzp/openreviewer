[
    {
        "id": "CzNDV3OYok",
        "forum": "GKge9khQSa",
        "replyto": "GKge9khQSa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission80/Reviewer_b5bi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission80/Reviewer_b5bi"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a dynamic method that integrates token pruning and pooling (merging) to reduce the FLOPs and execution time of vision transformers. The authors note that as the layers become deeper, the significance of image tokens grows increasingly distinct. Consequently, applying token pruning in deeper layers and pooling in shallow ones should yield benefits. This adaptable strategy can function effectively without modification and delivers enhanced performance after fine-tuning. The central contribution of the paper lies in its validation of this adaptive approach, which effectively addresses inattentive redundancy and duplicative redundancy across different layers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The motivation for redundancy and duplicative redundancy should be handled differently across different layers is clear.\n- Well-written and easy to follow.\n- This method can work off-the-shell without finetuning."
            },
            "weaknesses": {
                "value": "- Lack of discussion and comparison with the highly related work \"joint Token Pruning & Squeezing (TPS) \"[1], whose method is doing the pruning and pooling(squeezing/merging) at the same time in a non-adaptive way, which should be a good and important baseline for this adaptive strategy. \n- In the small network series such as Deit-S, the performance is 0.3% behind TPS[1] in a comparable FLOPS budget, I think the performance should be higher to justify the benefit of the adaptive strategy. It would be nice if the author would give more analysis about this case.\n- Lack of experiments of hybrid ViT such as PVT[2]. I think it would make the method more impactful if it is applicable to hybrid ViT(include regular spatial conv) beyond vanilla ViTs.\n\n[1] https://arxiv.org/abs/2304.10716\n[2] https://arxiv.org/abs/2102.12122"
            },
            "questions": {
                "value": "- The adaptive pruning and pooling strategy is the key contribution of this method. I think the author should make the \"adaptive\" point more convincing, such as comparing other non-adaptive pruning and pooling methods(pruning and pooling at the same time), or comparing the naive non-adaptive baseline(pruning only before layer x and pooling only after layer x, layer x is a fixed parameter such as half or two-thirds of the depth.\n- I think more metrics other than the \"variance\" of the distribution of importance score of image tokens should be considered. Since variance is shift-invariant and absolute value of the score is not considered. The absolute value of the score distribution should be somehow helpful to the choice of pooling or merging.\n- See weakness 3, how to make this method work on hybrid ViT(including regular spatial conv) and what's the improvement?\n- How to make this method work on dense prediction tasks such as segmentation and what's the performance?\n- Is it a possible case where pooling at the early stage and pruning at the final stage?\n- What's the performance if the adaptive policy is reversed? (change pooling to pruning and pruning to pooling)\n\n[1] https://arxiv.org/abs/2304.10716"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission80/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698402995872,
        "cdate": 1698402995872,
        "tmdate": 1699635932727,
        "mdate": 1699635932727,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6U8W8MKAft",
        "forum": "GKge9khQSa",
        "replyto": "GKge9khQSa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission80/Reviewer_Egiv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission80/Reviewer_Egiv"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose to reduce computation load of ViT by adaptive token pruning and pooling. Base on the token distribution, they tackle inattentive and duplicative redundancy by an adaptively selection of token pruning or token pooling policy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1 How to achieve accuracy-computation balance is a critical problem for ViT.\n\n2 The propsoed method seems to be sound.\n\n3 The paper is written well."
            },
            "weaknesses": {
                "value": "1 The novelty is relatively limited. The token pruning or token pooling has been widely investigated in the literature [DynamicViT, Evo-ViT, Self-Slim ViT, etc]. The adaptive design used in the paper is simply the combination of both  pruning and pooling without much insightful modifications.\n\n2 The results are actually comparable with the state of the art methods, with a little improvement. As shown in Table 1, the proposed method is actually comparable to Evo-ViT,  in terms of all the DeiT model settings. Similarly, it shows the marginal performance improvement, compared with EViT-LV-S. All of these indicate that, the effectiveness of the proposed design is not quite convincing."
            },
            "questions": {
                "value": "Please see weakness for reference. Bascially, there are two main concerns.\n1 The combination of pruning and pooling is not quite novel, considering that a number of similar compression methods have been developped in the literature.\n2 The exepriments do not show the effectiveness of the proposed design, with a marignal improvement."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission80/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698464526275,
        "cdate": 1698464526275,
        "tmdate": 1699635932655,
        "mdate": 1699635932655,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "d32S8vuK4z",
        "forum": "GKge9khQSa",
        "replyto": "GKge9khQSa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission80/Reviewer_SM9c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission80/Reviewer_SM9c"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to accelerate by token pruning and pooling, and its experiments show some improvement on throughput."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strength of this paper is easy following. The figures help a lot for understanding the story. The experiments are good even though not better compared with some  recent papers."
            },
            "weaknesses": {
                "value": "The weakness of this paper are as follows:\n1. The inference is hard to implement to be really act as what the authors have claimed. I do not think the throughputs are experimental numbers but theoretical numbers.  This is the common issue for adaptive token pruning methods, such as A-ViT. I think in practical this paper is useless, not only not decreasing the real computation cost but increasing the cost. I do not think the codes would be released for inference. \n2. The results are not promising. In recent CVPR2023, there are several new works that achieved better results than this one. For example, Making Vision Transformers Efficient From a Token Sparsification View. \n3. Further finetuning based on pretrained models is not fair comparisons."
            },
            "questions": {
                "value": "1. Can you share the inference codes? \n2. Can you share the codes for throughputs calculation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission80/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698633517864,
        "cdate": 1698633517864,
        "tmdate": 1699635932555,
        "mdate": 1699635932555,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3D9OsHBvAp",
        "forum": "GKge9khQSa",
        "replyto": "GKge9khQSa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission80/Reviewer_zbfa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission80/Reviewer_zbfa"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed to integrate both token pruning and token pooling techniques into vision transformers to perform model compression, and input-adaptively deciding different token compression policies for different layers, without additional trainable parameters. The compression results look promising."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed method is simple yet effective, without additional trainable parameters, and can be easily incorporated into the standard transformer block.\n2. The results demonstrate a better accuracy-compression ratio trade-off than the previous methods."
            },
            "weaknesses": {
                "value": "1. Missing a pretty relevant reference: Unified Vision Transformer Compression.  ICLR 2022 Please cite and compare with it on Deit-S, Deit-B, and Deit-Tiny. \n2. The backbones used in the paper are Deit and LV-VIT. How about the Swin-Transformer, which also already has a patch merging module for each stage of blocks? I am curious about the generalization of the proposed mechanism in this kind of structure and its performance."
            },
            "questions": {
                "value": "The target compression ratio seems to be hard to directly and accurately map to each layer's reduction percentage contributed by token pooling and token pruning. How to balance the K threshold in pruning and pooling and how to choose the decision threshold to match a user-given compression ratio? Please clarify it in more detail."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission80/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698855640094,
        "cdate": 1698855640094,
        "tmdate": 1699635932474,
        "mdate": 1699635932474,
        "license": "CC BY 4.0",
        "version": 2
    }
]