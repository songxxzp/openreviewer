[
    {
        "id": "Mz8XGj9exf",
        "forum": "0rXGGYNVAw",
        "replyto": "0rXGGYNVAw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_wvyK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_wvyK"
        ],
        "content": {
            "summary": {
                "value": "Federated learning has been mainly utilized for relatively shallow neural nets. The authors show that increasing depth can significantly worsen performance even for iid client data. However, they also found--perhaps counter-intuitively--that increasing width improves performance, so they argue that overfitting is not the reason. They attribute this degradation in performance to the accumulation of divergent terms in back propagation due to client dissimilarities."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The authors give guidelines on how to improve models in federated learning.\n- They run various experiments and try to prove the divergence accumulation phenomenon."
            },
            "weaknesses": {
                "value": "Various claims and steps in this paper are flawed. For example, it is not surprising that increasing width increases performance. The problem is that increasing depth is decreasing performance in your case, which is something that need to be investigated in depth and demonstrated with careful experiments because it is against the strongest point of \"deep\" learning and its common wisdom.\n\nAnother thing is that federated learning can be reduced to SGD in the simplest setting (one local step, iid clients, etc.), so theoretically, the divergence that might have been introduced could be from local training for more than one step. However, this has never been discussed in the paper, except the fact that the local epochs are set to 8 (which is a lot by the way). Finally, the authors explicitly mention client dissimilarity, yet they assume iid clients, which makes the authors objectives from this paper slightly unclear.\n\nHere are some other comments:\n1. The authors assume that the clients data are identically distributed, but proceed to show that they are not. Equation (6) assumes that the difference between clients data is a linear term, which is simply not often the case for non-iid clients. Most data-augmentations are non-linear, for example.\n2. In assumption 1 and 2, the stochasticity of the difference of gradients comes from the data distribution, so saying that the error is independent from the intermediate calculations Z and H--from which the error itself is eventually calculated--is very hard to believe.\n3. Assumptions and Theorems should be formatted correctly.\n4. Observations 1 and 2 are the same.\n5. Divergence measure in Fig. 3 is not clear. What does it stand for? Which direction is better?\n6. Modeling data diversity with a Gaussian noise is simply wrong. In fact, Gaussian noise is sometimes added to the data to improve model's stability/generalization.\n7. The authors did not use any of the well-known federated datasets (e.g. LEAF datasets) and did not specify how the data is partitioned into the clients.\n8. The conducted experiments are the same with different models. The authors need to provide more detailed experiments in order to demonstrate that this phenomenon is truly caused by the depth of neural nets (see questions below).\n9. Lemma 1 is simply saying that a linear function a linear combination of epsilon produces a different linear combination of epsilon, which is trivial. No need for independence as well. Same thing with Lemma 2."
            },
            "questions": {
                "value": "- Did you use batch normalization? This is very important.\n- What optimizer did you use?\n- Can you run an experiment that demonstrates increasing divergence as you increase depth, and the relationship between divergence and depth for a set of fixed widths? Use a simple net like: linear -> relu -> linear -> relu -> ... and make sure to normalize your divergence measure with respect to the depth.\n- Can you share anonymous source code?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Reviewer_wvyK"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6994/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697756859929,
        "cdate": 1697756859929,
        "tmdate": 1699636818646,
        "mdate": 1699636818646,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cZ1BHhJ26E",
        "forum": "0rXGGYNVAw",
        "replyto": "0rXGGYNVAw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_pCdo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_pCdo"
        ],
        "content": {
            "summary": {
                "value": "The authors observe that deeper models in the context of FL often face challenges in achieving convergence, resulting in a degradation of performance. They provide technical guidelines for improving the performance of FL on deeper models and demonstrate through experiments that these methods have a remarkable impact in reducing divergence, resulting in significantly greater enhancements in FL performance compared to centralized learning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written and easy to follow. The paper focuses specifically on the challenge of applying federated learning to deeper neural networks, which is an important problem."
            },
            "weaknesses": {
                "value": "The analysis of divergence accumulation is primarily based on a simplified linear layer with an activation function. However, since the authors conducted experiments using ResNet, it would be more appropriate for them to provide the analysis based on the residual module. Additionally, the process of deriving the entire formula lacks clarity and is challenging to comprehend."
            },
            "questions": {
                "value": "1. Why does the accuracy of CL also decrease as the model becomes deeper in Figure 1?\n\n2. Please provide a more detailed explanation of Equation (6) and clarify the meaning of $\\epsilon_i$. Additionally, explain why $\\epsilon_i$ is defined as shown below Equation (10). There is a typographical error in Theorem 1.\n\n3. How was Assumption 1 derived, and why is $E[\\epsilon_i]=0$?\n\n4. Neural Architecture Search (NAS) [1] could be a more suitable tool to replace the proposed guidelines as it can automatically adjust the width and depth of the model. Inspired by NAS, several works have introduced advanced Auto Data Augmentation (ADA) methods, such as AutoAugment [2], to automatically search for data augmentation policies for different tasks. The authors should further discuss these methods for future research.\n\n[1] He X, Zhao K, Chu X. AutoML: A survey of the state-of-the-art[J]. Knowledge-Based Systems, 2021, 212: 106622.\n[2] Cubuk E D, Zoph B, Mane D, et al. Autoaugment: Learning augmentation policies from data[J]. arXiv preprint arXiv:1805.09501, 2018."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "null"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Reviewer_pCdo"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6994/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697878929239,
        "cdate": 1697878929239,
        "tmdate": 1699636818513,
        "mdate": 1699636818513,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Az2bUz3dSj",
        "forum": "0rXGGYNVAw",
        "replyto": "0rXGGYNVAw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_w79q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6994/Reviewer_w79q"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the model depth in federated learning and identifies 'divergence accumulation', supported by both theoretical derivations and empirical evidence. The authors propose several technical guidelines and perform evaluations on three public datasets to show their effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper investigates an interesting topic.\n- The introduction well presents the motivation.\n- The overall study design is easy to follow.\n- The authors try to provide both theoretical and empirical evaluations on the divergence accumulation."
            },
            "weaknesses": {
                "value": "- Observations in Fig 2(a) may not be accurate. divergence of deep layers also tends to increase and converge if the model is trained more than 40 rounds.\n- Given \\epsilon_i with Z, the assumption 2 that assumes \\epsilon_i is dependent with Z and H may not hold.\n- The theorem of divergence accumulation only proves linear layers. It has no consideration for other important layers in modern deep neural networks,e.g., convolutional layers and normalization layers.\n- The proposed theorem does not show specific properties related to FL. It is also reasonable for centralized learning.\n- The empirical evaluation is too toy; an 8-layer CNN is not a \u2018deep model\u2019. Evaluations using a real deep model (e.g., networks with overall 100 layers) are expected.\n- The experimental design cannot fully validate the uniqueness of divergence accumulation in FL. Both CL and FL suffer from divergence accumulation.\n- Some experiment details are not clear, E.g., the total training rounds, and data split. Given the observation in Fig.2 (a), models may not converge given only 40 rounds, and this may lead to a wrong observation.\n- The experiment settings are not consistent. Tables 1 and 2 use different backbones, which is weird.\n- The observation of using smaller receptive fields may not be true given the original input size is small (64x64)."
            },
            "questions": {
                "value": "- Local data within each client is small. It is easy to imagine that local training with limited data cannot present better performance than centralized training. What are the results if we increase the local client data to the same amount as the centralized one? If this observation still exists, it means the divergence would be specifically related to the FL training paradigm rather than short of data.\n- In Fig.2(a), layer #23 and #42 show similar divergence, which may not well fit the divergence accumulation theorem. Any explanations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6994/Reviewer_w79q"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6994/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698312191748,
        "cdate": 1698312191748,
        "tmdate": 1699636818395,
        "mdate": 1699636818395,
        "license": "CC BY 4.0",
        "version": 2
    }
]