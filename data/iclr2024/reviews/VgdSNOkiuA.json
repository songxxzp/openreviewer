[
    {
        "id": "MuetFUL0P7",
        "forum": "VgdSNOkiuA",
        "replyto": "VgdSNOkiuA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_63XR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_63XR"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an adaptive approach to using LLMs that may switch between\ndifferent LLMs, change prompting, and decompose the problem based on the\nobserved performance of initial or partial solutions. The authors describe their\nframework and evaluate it empirically."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well written and explores an interesting idea."
            },
            "weaknesses": {
                "value": "Details of it are unclear. In particular the decomposition seems to rely on\nmanually defined granularities, i.e. a given problem cannot be decomposed\nautomatically. This imposes a significant burden on the user. The results of the\nempirical evaluation seem to suggest that this decomposition is often crucial to\nachieving good performance; this should be discussed in more detail."
            },
            "questions": {
                "value": "As a user, how would I decide how to decompose, how many levels are needed, and what the\nlevels represent?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698689637231,
        "cdate": 1698689637231,
        "tmdate": 1699636280941,
        "mdate": 1699636280941,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tV6UdPhpf8",
        "forum": "VgdSNOkiuA",
        "replyto": "VgdSNOkiuA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_5Pco"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_5Pco"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an adaptive LLM solver method that iterates through different methods to arrive at a solution. Adaptive solver first checks if a given solution is accurate before trying different adaptations.  The adaptations are model, prompting and decomposition granularity. Experiments show how the different adaptations affect performance on various reasoning datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Originality: The idea of the framework introduced is unique for its flexibility. Most papers focus on trying to improve one of the given adaptations while the adaptive solver takes a different approach. \n- Significance: Searching or solving for the best way to approach a particular question is an important line of work, especially given the high cost of API and variety of inputs.\n- The paper is well presented. In particular, the conclusions from the analysis and experiments are easy to find."
            },
            "weaknesses": {
                "value": "- There are a limited number of options for the solver and the method requires a lot of pre-processing (to write the in-context examples) for the prompting method. \n- The implementation is not as novel as the original idea. To the best of my understanding, the solver goes through different methods and chooses the best one. A significant improvement would come from making the solver more dynamic and based on the solution. Works that combine planning and LLMs are quite relevant.*\n- The paper mentions that the number of solving rounds does not increase much but there is no discussion of the increase in inference time. Trying different approaches until a certain number of iterations has passed or some metric is satisfied will increase the inference time significantly. This could be problematic for real-time applications. \n\n\n*Relevant papers: \n- Wang, Lei, et al. \"Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models.\" arXiv preprint arXiv:2305.04091 (2023).\n- Hao, Shibo, et al. \"Reasoning with language model is planning with world model.\" arXiv preprint arXiv:2305.14992 (2023)."
            },
            "questions": {
                "value": "- For the Decomposition Granularity Adaptation experiment, what model is used? GPT-3.5? Is there a way to compare this with GPT-4?\n- How is Decomposition Granularity different from prompting? From Figure 1, c and d look quite similar. \n- Were there experiments using a larger solver list? From Table 1, each of the 3 solvers has the best performance in at least one of the datasets. \n- Results clearly depend on what is in the solver. Is there a way to choose what methods to put into a given solver? \n- How did inference time change per types of adaptations?  \n- How were in-context examples chosen?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Reviewer_5Pco"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698713821302,
        "cdate": 1698713821302,
        "tmdate": 1699636280868,
        "mdate": 1699636280868,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OYsI2HCMYy",
        "forum": "VgdSNOkiuA",
        "replyto": "VgdSNOkiuA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_uCwU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_uCwU"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an approach for combining multiple different strategies in order to solve problems using LLMs. This is akin to portfolio selection since there is generally no \"one-size-fits-all\" approach to solving problems. In order to do so, the authors propose the adaptive-solver (AS) framework for LLMs. \n\nAS consists of three different adaptation strategies, (a) Model adaptation where the LLM models are changed from cheaper to more advanced albeit expensive models, (b) Prompting method adaptation wherein different prompting methods are utilized for problems, and finally decomposition granularity adaptation that tailors the decomposition granularity of prompts from coarse to finer.\n\nAn adaptation module consists of a portfolio of such solvers and the authors use an evaluation module with a consistency metric to determine the evaluation criteria for switching solvers. The authors then provide an empirical evaluation of their approach and perform several ablations of each of the modules."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper is generally well-written (even though the empirical could have been organized a bit better) and the ideas are expressed clearly\n\n2) The idea of having a portfolio of such selection strategies makes sense since empirically it is known that there is usually not a single approach that can outperform others"
            },
            "weaknesses": {
                "value": "The paper is quite interesting but it seems that the empirical evaluation section is (a) bit hard to follow, and more importantly (b) the results only show a marginal improvement over baselines.\n\na) The paper only improves over baselines by a nominal ~3% (Table 1). This does not seem very significant to me and is further exacerbated by the fact that different, hand-coded variations of AS are needed to outperform the baselines as such.\n\nb) The paper claims that AS can cut down on API costs but a cost analysis vs baselines is not provided. Table 2 only provides cost analysis vs using two versions of GPT but does not include overall costs for the entire pipeline.\n\nc) Similarly, Table 3 only shows marginal improvements for the decomposition granularity ablation. \n\nOverall, the ablations are interesting but the process seems overly hand-coded with not enough improvements over the baselines. (Even the strategies for choosing solvers is driven by expert-knowledge). For example, how many times was strategy 1 (choose the last solver in the list) selected in your evaluation. Such information is missing in the main paper."
            },
            "questions": {
                "value": "Id like to thank the authors for their extensive experiments. I've listed my questions below. I hope that the authors can resolve my queries.\n\n1. Could you please comment on (b) and provide a reason as to why overall costs for the entire pipeline are not included in the paper.\n\n2. Currently, it feels like most of the experiments are ablations. I would have preferred to have seen results with a general AS solver list and a more comprehensive comparison with baselines.\n\n3. I can understand the reason for the ablations but is there any reason as to why all baselines were not tried on for all datasets? For example, Table 2 only uses ZeroCoT for prompting and only the model adaptation is explained. I think that the overall efficacy of the pipeline can only be clearly determined when the pipeline is used everywhere and not selectively applied to different datasets. I appreciate the authors trying to reduce the # of variables but this only made the evaluation more confusing for me."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3313/Reviewer_uCwU"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698787141463,
        "cdate": 1698787141463,
        "tmdate": 1699636280797,
        "mdate": 1699636280797,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IHpbqy9S00",
        "forum": "VgdSNOkiuA",
        "replyto": "VgdSNOkiuA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_xp3G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3313/Reviewer_xp3G"
        ],
        "content": {
            "summary": {
                "value": "This paper presents and demonstrates a simple algorithm for achieving a better cost-accuracy trade-off for reasoning tasks with LLMs. The high-level idea is to construct a cascade using different models, prompts, and/or granularities of decomposition. A crucial element is the ability to evaluate whether a solution is likely to be correct, which is achieved using the consistency of multiple samples at some non-zero temperature. The method is evaluated on a collection of reasoning datasets, and is shown to achieve a significant reduction in cost, sometimes even achieving an increase in accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Baselines and components are all highly recent (2022-2023).\n1. Considers three different types of solver adaptation. Judicious choice of solvers in experiments.\n1. Significant reductions in cost achieved. For those employing LLMs, it is useful to be aware of the efficacy of a cascade using the consistency check.\n1. Ablative studies are well designed and well presented."
            },
            "weaknesses": {
                "value": "1. Little technical novelty - mostly an empirical study.\n1. It seems like the temperature could have a significant impact on the consistency check, however there was no study of the effect of varying temperature.\n1. It would be useful to present the ROC curve (FPR-FNR tradeoff) of the consistency check for each solver, ideally at a range of temperatures.\n1. While Figure 3b shows which of the 3 decomposition prompts was used, it would be useful to know how many solvers were tried for each experiment, and how often the cascade \"dropped through\" to the final solver.\n1. It would be good to include a discussion of determining an optimal cascade (perhaps assuming that the errors of different models are independent) per budget for a given dataset.\n\nSuggestions (no need to address):\n1. For a scientific context, I would tone down some of the grandiose language (\"this innovative method represents a significant step in dynamic strategy selection\", \"holding vast implications for the realm of artificial intelligence\").\n1. Personally, I don't like the use of the word \"solver\" for the current purpose. Possible alternatives: tactic, strategy, protocol."
            },
            "questions": {
                "value": "Mainly just address weaknesses listed above. Additional questions:\n\n1. Which model does each method use in Table 1? Could include this in the caption.\n1. It's unfortunate that OpenAI's pricing affects the \"cost saving\"; changes in pricing will change the results. Is there any way around this? Is it possible to obtain flops (or kWh, but that too is technology dependent)? Otherwise at least note that this uses pricing as at [date]."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699406587988,
        "cdate": 1699406587988,
        "tmdate": 1699636280735,
        "mdate": 1699636280735,
        "license": "CC BY 4.0",
        "version": 2
    }
]