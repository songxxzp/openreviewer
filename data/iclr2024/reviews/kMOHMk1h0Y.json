[
    {
        "id": "0THFyOo2gd",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_ggkq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_ggkq"
        ],
        "forum": "kMOHMk1h0Y",
        "replyto": "kMOHMk1h0Y",
        "content": {
            "summary": {
                "value": "1. This paper investigates the problem of learnt video compression based on implicit neural representations (INR).  \n2. A global embedding is introduced, which is shared by all frames and optimized through backpropagation.  \n3. This global embedding is fed to the decoder together with the frame index, without the need of encoder.   \n4. The proposed GNeRV outperforms HiNeRV and achieves SOTA RD performance over multiple datasets like UVG and MCL-JCV.  \n5. A progressive residual coding pipeline is incorporated, leading to more efficient multi-bitrate encoding and better multi-bitrate RD performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "strengths:\n\nOverall, this is a solid paper.  \nThe method and experiment are all clearly explained.   \nMost previous works are compared properly with multiple datasets.  \nTo my knowledge, the global embedding proposed in this paper is novel in this INR for video compression field.   \nThe RD performance is better than previous SOTA."
            },
            "weaknesses": {
                "value": "weakness:\n\nThe contribution part should be improved to better explain the main contributions of this paper such as the significance of the RD improvement and multi-bitrate compression. Currently there are only two bullets. \n\nIntroducing and optimizing the global latent is quite related to the explicit bit allocation framework proposed in Xu, T., Gao, H., Gao, C., Wang, Y., He, D., Pi, J., ... & Zhang, Y. Q. (2023, July). Bit allocation using optimization. In International Conference on Machine Learning (pp. 38377-38399). PMLR. In my understanding, GNeRV can be considered as implicit bit allocation using optimization. Please discuss this in the revised version to help readers build deeper understandings regarding this field. \n\nMore visualizations should be provided to compare with previous works."
            },
            "questions": {
                "value": "Please refer to the weakness part. And:\n\nIn Table 2, why the complexity of DNeRV and HiNeRV are not reported? Also, the FPS of x264 abd x265 should be provided for better comparison. \n\nIn Table 1, why HiNeRV, x264, x265 are not reported?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3417/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697447856842,
        "cdate": 1697447856842,
        "tmdate": 1699636293395,
        "mdate": 1699636293395,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2kgqWvm0aS",
        "forum": "kMOHMk1h0Y",
        "replyto": "kMOHMk1h0Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_nVh1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_nVh1"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a progressive approach to implicit neural representation compression for videos. It proposes a global embedding, obtained by an MLP, for representing the time/frame index joint with a global representation for the video frame content. Learning the progressive representation is obtained by training the GNeRV for residuals of multiple stages. The results are interestingly good for high-bitrate case in comparison to other INR-based approaches."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is fairly well-written and easy to follow.\n- Training a INR that is handling multiple rates using a single representation is interesting and novel angle in this paper.\n- The results are conclusive and supporting the hypothesis.\n- The ablation studies are sufficient to demonstrate the contribution of various components and steps of the method."
            },
            "weaknesses": {
                "value": "- While conventional video codecs are tested, the results for other neural approaches are missing. That could improve the paper in terms of conducted experiments."
            },
            "questions": {
                "value": "- Why for different size of models and increased MACs the FPS of proposed method is constant and even improves? This could be a nice addition in discussions about the proposed method.\n- Figure 3 could be improved by having training and inference pipeline better clarified.\n- Is there a particular reason for not reporting the other neural based video coding approaches?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3417/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698693587117,
        "cdate": 1698693587117,
        "tmdate": 1699636293305,
        "mdate": 1699636293305,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pqPPKRo1rY",
        "forum": "kMOHMk1h0Y",
        "replyto": "kMOHMk1h0Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_vfx3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_vfx3"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel implicit neural representation model for video compression. Unlike HNeRV (CVPR 2023), the proposed method doesn't require an encoder module for embedding extraction for each frame. Instead, it directly optimizes one global embedding for an entire video and adapts it for different frames using the proposed distribution shift branch with temporal index as input. Additionally, the authors introduce a progressive training strategy, enabling multiple rates to be achieved based on multiple stages of residual information fitting. Experimental results on Bunny, UVG dataset, and MCL-JCV dataset demonstrate superior performance compared to other methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and easy to follow.\n- The study features extensive experiments and achieves superior results."
            },
            "weaknesses": {
                "value": "- How are the variable compression rates controlled using the proposed progressive pipeline? We know it is feasible to achieve this using the 'respective' approach. Further clarification would be beneficial.\n- The objective function combines MSE and SSIM, however, all quantitative results are reported in terms of PSNR. Typically, for optimal performance on each metric, it is advisable to use only the corresponding one. Please clarify its motivation, and include the comparison in terms of SSIM.\n- While HiNeRV outperforms h265, it performs significantly worse compared to h265 in this context. The authors should clarify the details of the experimental setting."
            },
            "questions": {
                "value": "My main concern pertains to the novelty of the proposed approach. The distribution shift branch appears to employ a technique same as to COIN++. Although the proposed method targets video compression while COIN++ focuses on dataset compression, the reliance on the distribution shift is crucial for me. I think similar performance could be achieved by employing a grid input (as in HiNeRV) with distribution shift, instead of using a global embedding, which is the main contribution emphasized by the authors."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3417/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3417/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3417/Reviewer_vfx3"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3417/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698755333878,
        "cdate": 1698755333878,
        "tmdate": 1699636293202,
        "mdate": 1699636293202,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "x95aLmlIYX",
        "forum": "kMOHMk1h0Y",
        "replyto": "kMOHMk1h0Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_qKqs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3417/Reviewer_qKqs"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a new video representation and compression technique built upon Implicit Neural Representation (INR). Along with giving time index as input and RGB format as output, the authors propose the GNeRV technique which gives a global representation shared amongst all frames. A tensor based embedding structure is introduced whose shape is determined by a hyperparameter and video\u2019s resolution. Time information is used at each block\u2019s input and positionally encoded data is applied to measure shift. A progressive pipeline is used to eventually form a high-bitrate model. In detailed ablation study is conducted to evaluated each components significance. Extensive experiments have been conducted to compare with other state of the art video compression models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Novel compression techniques have been applied - progressive pipeline and quantization  \n2. In-depth ablation studies have been conducted to compare various aspects of the model. Extensive experimentation has been conducted on several aspects of their own pipeline and compared with other state-of-the-art models."
            },
            "weaknesses": {
                "value": "1. \u201cThe input of the network is time index t, and the output is the reconstructed image of frame t\u201d - Why is t used as a parameter for both?\n2. Is there a variance observed in the PSNR values across different runs?\n3. Residual information is defined before using it in the introduction\n4. Figure -  X_G in the figure is not defined. The description of the figure could be better. There are symbols that are not self-explanatory and need to refer to various different sections to get a better understanding of the model architecture. It would be great if we can mark several components of the architecture as named in the sections in the figure. \n5. Writing improvements - There are several terms whose definition is missing or have been used loosely like header layer."
            },
            "questions": {
                "value": "1. How much overhead does residual computation cause, especially for long-form videos?\n2. \" Since all frames share one global embedding, this structure accounts for less than 1% of the total number of parameters in the model,\nsaving the parametric quantities for later convolution networks\", is this true for all the different hyperparameter settings used in the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3417/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823319614,
        "cdate": 1698823319614,
        "tmdate": 1699636293109,
        "mdate": 1699636293109,
        "license": "CC BY 4.0",
        "version": 2
    }
]