[
    {
        "id": "aio8v0FUxr",
        "forum": "aOnUe8ah7j",
        "replyto": "aOnUe8ah7j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_q1T8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_q1T8"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method for symbol segmentation in architectural floorplans. The method is based on representing each graphical primitive as a point with a set of features and thus, relying on Point Transformer for feature extraction. Then, an adaptation of Mask2Former is used to segment and classify the symbols in the floorplan. Some specific components are introduced to adress the specificity of graphical primitives in architectural drawings. Experimental validation is performed by applying the method to a standard floorplan dataset, comparing with state-of-the-art and conducting several ablation studies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of relying on a point representation of graphical primitives seems novel and makes sense in this context since symbols in architectural drawings are composed of graphical primitives. Then, using the combination of PointTransformer and Mask2Former is also a novel approach in this context that seems suitable for capturing the interaction between graphical primitives for symbol segmentation. \n- Experimental results on a standard dataset report better performance than state-of-the-art methods. A detailed ablation study shows the contribution of the different modules of the proposed framework."
            },
            "weaknesses": {
                "value": "Perhaps I missunderstood something, but I do not see the motivation of symbol segmentation in CAD drawings. As far as I understand CAD drawings should already contain information about the symbols included in the floorplan and where they are located. \n\nIn the description of the method and the experiments there are several points that are confusing or not well explained:\n- In equation (2) I understand that l_k is the distance between v_1 and v_2. Then, what about circles and ellipses? How is the lengh computed? And for arcs, this definition does not account for the curvature. Two arcs with very different curvature can have the same representation.\n- In equation (3), it is not clear how the neighbourhood M(p_i) is defined. Do adjacent points mean connected primitives? Or primitives inside a certain distance? Which is exactly the difference with A(p_i) defined later in section 3.3 (given that the threshold used in section 3.3 is just one pixel). In this sense, the role of the ACM module is not very clear. \n- It is not clear the motivation of the KNN interpolation described in section 3.5. As far as I understand, since points correspond to graphical primitives, interpolation of neighboring points could lead to losing information of specific primitives and I am not sure that makes sense merging different primitives into a new one. \n- Related to the previous point, It is not clear how it is performed downsamplind and upsampling in the Point Transformer. The same as in the original Point Transformer? \n- In equation (12) it is not clear what is e_i and L(e_i).\n- In the experiments, which is the difference between Semantic and Panoptic Symbol Segmentation? Why in table 1 (semantic segmentation) the evaluation measure is F1? How are F1 and wF1 defined in this context?"
            },
            "questions": {
                "value": "See above in Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1614/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744737509,
        "cdate": 1698744737509,
        "tmdate": 1699636089792,
        "mdate": 1699636089792,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3WiyPAEUIL",
        "forum": "aOnUe8ah7j",
        "replyto": "aOnUe8ah7j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_AtGi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_AtGi"
        ],
        "content": {
            "summary": {
                "value": "This paper, titled SymPoint, advocates for representing a symbol as a point and extends the previous methodology to encompass a broader range of symbol properties. The Point Transformer serves as the foundational feature extraction tool. Mask attention and a contrastive connectivity learning mechanism are integrated into the panoptic symbol spotting task, aiming to cultivate rich features that can effectively differentiate between graphic primitives. The PQ performance has been elevated from the previous method to a novel tier, as delineated in the experimental section."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "With the advancements in point cloud processing and the Transformer architecture, the authors suggest leveraging these powerful backbones from other domains and adapting them to address the challenge of panoptic symbol spotting.\nA suite of techniques, encompassing vector graphics representations, Point Transformers, Masked Attention, Contrastive Connection Learning, and KNN Interpolation, has been integrated into the targeted task.\nExperimental outcomes reveal that SymPoint significantly outperforms existing methods, exhibiting a considerable advantage in Semantic Symbol Spotting, Instance Symbol Spotting, and Panoptic Symbol Spotting."
            },
            "weaknesses": {
                "value": "- A primary concern from the reviewer centers on the paper's predominant reliance on existing methodologies to address the issue. Specifically, in Sec3.1 (From Symbol to Point), many parameterizations echo those found in FloorplanCAD, albeit this paper seeks to enhance the diversity of encoded features. The point-based representation in Sec 3.2 directly employs the Point Transformer, reminiscent of CADTransformer. Both Contrastive Connection Learning (Sec3.4) and KNN Interpolation (Sec3.5) have been thoroughly examined in other scholarly works. While the \"Attention with Connection Module\" presents as novel to the reviewer, it would be beneficial to undertake a comprehensive review to discern if analogous concepts have been previous literature.\n- In Table 4, where the benchmark approach registers a PQ of 73.1, could you detail the design of how this baseline method is formulated?\n- In Table 4, it appears the newly introduced \"ACM\" module inadvertently undermines performance. Could the authors shed light on the causative factors behind this decline?\n- Again, referencing Table 4, the KInter technique emerges as a salient contributor to performance enhancement. Could the authors offer a more clear explanation and visualization? It might also be worthwhile to highlight this module within the methods section.\n- As the proposed framework incorporate a bunch of techniques for a specific application, did you submit the code for reviewing?"
            },
            "questions": {
                "value": "See the raised concens in Weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1614/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777729440,
        "cdate": 1698777729440,
        "tmdate": 1699636089700,
        "mdate": 1699636089700,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QG70pyNIRX",
        "forum": "aOnUe8ah7j",
        "replyto": "aOnUe8ah7j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_u21w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1614/Reviewer_u21w"
        ],
        "content": {
            "summary": {
                "value": "In this paper, a method for symbol spotting from CAD vector graphics (VG), called SymPoint, is proposed. SymPoint treats graphic primitives as a set of 2D points. Two strategies, attention with connection module (ACM) and contrastive connection learning (CCL), are devised to better utilize the local connection information of primitives and enhance their discriminability."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The main idea and technical detailed are clearly presented."
            },
            "weaknesses": {
                "value": "1. The originality and technical contribution of this work is quite limited. Point Transformer, Mask2Former and InfoNCE are all well-established methods or models.\n2. The potential application range of the proposed method can be narrow (CAD vector graphics), because it is unclear whether the idea and techniques presented in this work can be extend ed to other tasks."
            },
            "questions": {
                "value": "The authors should explain and verify the originality and technical contribution of the proposed method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1614/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831965792,
        "cdate": 1698831965792,
        "tmdate": 1699636089632,
        "mdate": 1699636089632,
        "license": "CC BY 4.0",
        "version": 2
    }
]