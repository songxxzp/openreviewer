[
    {
        "id": "WLP2KMEDMV",
        "forum": "f6BIRu23ow",
        "replyto": "f6BIRu23ow",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_Qnji"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_Qnji"
        ],
        "content": {
            "summary": {
                "value": "This work introduces the TriSAM method, which is a zero-shot 3D segmentation method named TriSAM that relies on the Segment Anything Model (well-known as SAM). The framework can segment objects in an image given a point or bounding box as input. The designed framework is designed to segment blood vessels, hence the work proposes to integrate a multi-seed training strategy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Significance: The paper focuses on a very relevant problem that, to date, still remains unsolved.\n- originality: The idea of combining a tracking approach with SAM sounds novel."
            },
            "weaknesses": {
                "value": "Clarity: The paper misses to provide precise details about how the method works. While the overall outline of the steps within TriSAM are very clear, how each of them are designed and formalized is not well explained in the paper. \nQuality: There are aspects of the paper (see questions) that are not well justified. The experimental results do not consider state of the art methods on vessel segmentation (e.g. [1-3] to illustrate just a few examples), including some that reduce the annotation effort (see [2]). \n\n\n[1] Livne, Michelle, et al. \"A U-Net deep learning framework for high-performance vessel segmentation in patients with cerebrovascular disease.\" Frontiers in neuroscience 13 (2019): 97.\n[2] Dang, Vien Ngoc, et al. \"Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation.\" Medical Image Analysis 75 (2022): 102263\n[3] Tetteh, Giles, et al. \"Deepvesselnet: Vessel segmentation, centerline prediction, and bifurcation detection in 3-d angiographic volumes.\" Frontiers in Neuroscience 14 (2020): 1285."
            },
            "questions": {
                "value": "- What do the authors mean by this sentence \" Moreover, imaging the whole mouse brain using VEM technology is under planning\"? \n- How are turning points detected?\n- How is the tracking approach integrated with SAM?\n- How is the model trained? The zero-shot aspect does not come across clear\n- The paper states that : \"By choosing the best plane during tracking, the shape and size will not change dramatically\". This seems like a flawed argument. Across neighboring slides, the vessels should not dramatically change of size but progressively. However, as the brain vessels are tortuous, the change of shape can always occur."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Reviewer_Qnji"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2087/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698599391410,
        "cdate": 1698599391410,
        "tmdate": 1700750699372,
        "mdate": 1700750699372,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Z0DxWVqMFb",
        "forum": "f6BIRu23ow",
        "replyto": "f6BIRu23ow",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_BJ42"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_BJ42"
        ],
        "content": {
            "summary": {
                "value": "This paper presents the BvEM benchmark that provides Volume Electron Microscopy (VEM) image volumes from adult mice, macaque, and humans. Also, this proposes a zero-shot cortical blood vessel segmentation method, called TriSAM, which consists of Tri-Plane selection, SAM-based tracking, and recursive redirection. By choosing the best plane for tacking, this method enables effective long-term 3D blood vessel segmentation. The proposed method is demonstrated on the BvEM benchmark and shows superiority over the comparative methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper proposes a new dataset, BvEM, which contains VEM images and their blood vessel segmentation labels verified by the experts. \n- The proposed method extends the work of the Segment Anything Model (SAM) to 3D vessel segmentation, which addresses the problem of requiring large amounts of annotated training data.\n- For SAM-based tracking, the authors select seeds in which the shape and size do not have dynamic changes by looking into three different planes.\n- The proposed method is verified on the proposed benchmark dataset and achieves higher performance than the comparative methods."
            },
            "weaknesses": {
                "value": "- In the proposed method, the initial seed generation and triplane selection seem to be quite heuristic in that the selections depend on the threshold.\n- The dynamics of the planes are not investigated in detail. The shape and size may be different along the images.\n- There are many learning-based blood vessel segmentation methods, but only 3D UNet is used as a comparative method. The other Color Thresholding and SAM+IoU Tracking methods are not deep learning-based methods.\n- There is a lack of description of why the proposed method adopts the SAM approach."
            },
            "questions": {
                "value": "- How the threshold for each initial seed selection and plane selection is determined? It seems difficult to find the optical threshold manually. Also, how are segmentation results different according to the threshold?\n- Please discuss about the dynamic changes along the images for tracking blood vessels.\n- Is the proposed TriSAM SOTA even when compared to the supervised image segmentation methods such as nnUNET?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Reviewer_BJ42"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2087/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698802672515,
        "cdate": 1698802672515,
        "tmdate": 1699636141038,
        "mdate": 1699636141038,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nksZXeY2It",
        "forum": "f6BIRu23ow",
        "replyto": "f6BIRu23ow",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_NUw2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2087/Reviewer_NUw2"
        ],
        "content": {
            "summary": {
                "value": "The proposed TriSAM is based on the multi-seed tracking framework, which leverage specific image planes for tracking, while employing others to detect possible turning points. This framework is a combination of Tri-Plane selection, SAM-driven tracking, and recursive redirection. Evaluated on the proposed BvEM dataset, the proposed TriSAM is able to achieve long-term 3D blood vessel segmentation without the need for model training or fine-tuning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. A new benchmark of BvEM is introduced for blood vessel segmentation in volume electron microscopy images.\n2. The proposed TriSAM works effectively and is able to achieve zero-shot 3D blood vessel segmentation.\n3. The paper is well written and clearly organized."
            },
            "weaknesses": {
                "value": "1. The proposed method is more like an engineering implementation than a scientific research. It consists of four steps: Initial seed generation, Tri-plane selection, SAM-based tracking, and recursive redirection. Even though the rationale is simple, it works effectively.\n\n2. The lack of comparison with sota VEM segmentation methods. The discussion of existing VEM segmentation methods are quited limited, more discussion should be provided to facilitate the understanding of existing researches. The proposed method might be compared with more SOTA zero-shot segmentation methods.\n\n3. How to determine the threshold in Tri-Plane selection and SAM-based tracking? Do we need to change the value of threshold when applied to other data sets?"
            },
            "questions": {
                "value": "1.  The existing VEM segmentation methods might be discussed in detail. What is the difference between the proposed method and existing works?\n\n2. The threshold plays a vital role in the SAM-based tracking and recursive redirection. An ablation study of threshold could be provided to determine the influence of different values of threshold."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2087/Reviewer_NUw2"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2087/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809243298,
        "cdate": 1698809243298,
        "tmdate": 1699636140946,
        "mdate": 1699636140946,
        "license": "CC BY 4.0",
        "version": 2
    }
]