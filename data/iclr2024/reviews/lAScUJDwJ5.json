[
    {
        "id": "1AVObQfwTj",
        "forum": "lAScUJDwJ5",
        "replyto": "lAScUJDwJ5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_9oym"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_9oym"
        ],
        "content": {
            "summary": {
                "value": "Targeting dealing with reconstructed image that of low-quality or the anomaly is fine-grained, this paper proposes POUTA, where the discriminative network analysis the features of the reconstructive network, and leverages a coarse-to-fine process. The experiments on MVTec AD, VisA and DAGM dataset show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1.\tThe architecture is clear, and the motivation sounds reasonable.\n2.\tExperiments show the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1.\tThis paper is lacking important references from the anomaly detection literature. The primary claim made by the authors is that they approach anomaly detection at the feature level rather than the conventional image-level distinction to locate anomalies. However, feature-level reconstruction has already been explored extensively in the literature, including UniAD [a] and its subsequent studies. In these works, the approach of abstaining from reconstructing data at the image level and not using a discriminative network has already been applied. This discrepancy conflicts with the authors' description and literature review.\n2.\tThe ablation studies are carried out on the relatively straightforward MVTec dataset, where the baseline method already achieves an AUC of 98.4%, rendering the comparisons somewhat inconclusive. A more robust evaluation should be conducted on a more challenging dataset like VisA to assess the contributions of each module effectively. Furthermore, the designs of both FCM and HSG appear to be incremental and lack novelty.\n3.\tThis study appears to be outdated, given that there are existing anomaly detection methods that achieve exceptionally high performance on isolated tasks (e.g., 100% AUC on half of the classes in the MVTec dataset). Many recent studies focus on examining how methods perform under a universal model (using a single model for all classes) [a] or in zero-/few-shot settings, such as [b]. It is important to assess how the proposed method performs in these settings as well.\n4.\tThe paper suffers from issues in its writing. It proves challenging to grasp the content, even after multiple readings.\n\n[a] You et al. \"A Unified Model for Multi-class Anomaly Detection.\" NeurIPS 2022. \n\n[b] Jeong et al. \"WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation.\" CVPR 2022."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2554/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697950723714,
        "cdate": 1697950723714,
        "tmdate": 1699636191980,
        "mdate": 1699636191980,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fsbeRVYQPN",
        "forum": "lAScUJDwJ5",
        "replyto": "lAScUJDwJ5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_iu96"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_iu96"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the undesired failure in anomaly/defect detection. It claims that the image-level difference analysis cannot dealing with the low-quality reconstructed abnormal image and the fine-grained anomaly detection. It is discovered that the features in reconstructive network contains more accurate information about anomaly than the image-level difference. Inspired by this, this paper constructs self-supervised proxy task with synthetic anomaly as segmentation supervision, and designs a serial of subnetworks to adopt feature-level difference analysis. The experimental results outperform existing works or achieve comparable performance, demonstrating the effectiveness of this method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper is well-organized and the motivation is explicit.\n\n- The multi-level feature difference analysis is proved more effective for both detection and localization task. And the evaluation on industry defect detection provides insight into limited discriminant of image-level information.\n\n- Comparing discriminative networks with image-level inputs, the parameters and computational cost are lower without additional feature encoder, a.k.a. produce-once-utilize-twice."
            },
            "weaknesses": {
                "value": "The major concern with this paper lies in the limited novelty. Despite the feature-level inputs, using discriminative network to identify synthetic anomaly is not new to me. Some similar works exist. For example, the overall framework can be considered as an incremental improvement of DR\u00c6M (Zavrtanik et al., 2021a).\n\nSome claims may not be supported well, e.g., \"the discriminative network cannot obtain the difference between the original and reconstructed image with image-level information. And the feature-level information contains more accurate information about the anomaly.\" Considering the information flow in the reconstruction process, abnormal image contains more anomaly information than the features produced by following encoder, and the normal-like decoded image should also discard more anomaly information. That is, ideally, image-level inputs should be more discriminative.\n\nAs mentioned above, I wonder if there is any intuitive explanation as to why DR\u00c6M with more discriminative information cannot be optimized as well as POUTA."
            },
            "questions": {
                "value": "As mentioned in the \"weaknesses\" part, I suggest the authors to address my concerns and illustrate the novelty of the proposed work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2554/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698381726509,
        "cdate": 1698381726509,
        "tmdate": 1699636191892,
        "mdate": 1699636191892,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pXaoYpwQo3",
        "forum": "lAScUJDwJ5",
        "replyto": "lAScUJDwJ5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_QRqr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2554/Reviewer_QRqr"
        ],
        "content": {
            "summary": {
                "value": "A method for visual anomaly detection and localization is presented. First an auto-encoder network is trained that reconstructs an input. The multi-scale features from the encoders and decoders are then processed by a discriminative network that combines them in a coarse-to-fine fashion and predicts an anomaly map and anomaly score."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The work is conceptually similar to previous works in this area like DRAEM. However, instead of comparing pixel-level differences, the authors use features from both the encoding and decoding portions of the reconstructive auto-encoder. This is a simple but sound idea. Results on all the datasets tested are quite good."
            },
            "weaknesses": {
                "value": "1. The writing is a bit unbalanced: some exposition (especially in Sec. 1, Introduction) can be condensed considerably. On the other hand, some portions lack sufficient technical details. For instance, \n\n    a. What is the architecture of the MSS module? I understand the loss functions used to train it, but there seems to be no description of its architecture. \n\n    b. Further, can the authors please provide additional details about the training regimen? I'm assuming that for each MVTec/DAGM category, a separate set of weights is learnt? Is the whole pipeline (reconstructive network + FCM + HSG + MSS) trained jointly? Or is the reconstructive network trained first, and then the remaining modules (FCM + HSG + MSS) trained from the features of the pre-trained autoencoder?\n\n2. Finally, comparison to non-reconstruction-based approaches is missing. These constitute an important class of methods in the visual anomaly detection domain, and there are several such methods that give state-of-the-art results, a couple of which are listed below:\n    - Roth, K., Pemula, L., Zepeda, J., Sch\u00f6lkopf, B., Brox, T. and Gehler, P., 2022. Towards total recall in industrial anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\n    - Defard, T., Setkov, A., Loesch, A. and Audigier, R., 2021, January. Padim: a patch distribution modeling framework for anomaly detection and localization. In International Conference on Pattern Recognition."
            },
            "questions": {
                "value": "1. Are the maps $M_{p(i)}$ and $M_p$ heatmaps or binary segmentation maps? Also, I'm assuming that all the $M_{p(i)}$ are resized to the resolution of the ground-truth maps?\n2. The losses $L_{pre}$ and $L_{MSS}$ are very similar in formulation; one is applied to features from all levels, while the other is applied to final predicted map. Are both really needed? What is the impact of using only one instead of both?\n3. How were the values for various parameters ($\\lambda_i, i= 1\\dots, 4$; $\\gamma$; $\\alpha_t$; etc.) in the \"Implementation details\" chosen? Was it empirically?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2554/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699057989321,
        "cdate": 1699057989321,
        "tmdate": 1699636191832,
        "mdate": 1699636191832,
        "license": "CC BY 4.0",
        "version": 2
    }
]