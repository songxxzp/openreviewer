[
    {
        "id": "7iX5TaB8Tt",
        "forum": "WTJv0L5QLX",
        "replyto": "WTJv0L5QLX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_C4jg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_C4jg"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a geometrical analysis of the forward and backward dynamics associated to Variance Exploding-SDE diffusion models. In particular, authors compare the sampling and denoising trajectories, investigating their quasi-linearity and the fact that both move monotonically from their starting point to their final one. \n\nThe authors investigate how the output of the denoiser (obtained via reparametrization of the score) converges to a solution with low FID score much faster than the corresponding sampling trajectory. The authors proceed to discuss the relationship between higher order schemes and the denoising trajectory (Section 4) and the connection to mean shift (Section 5). Finally, the authors discuss the deviation of the ideal and parametric score, linking its behaviour to generalization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The paper's geometrical analysis of the forward and backward dynamics associated with Variance Exploding-SDE diffusion models is interesting and adds a new dimension to the understanding of these models. This type of analysis can be crucial for developing a deeper understanding of the underlying mechanisms of SDE-based models and their behavior during the sampling and denoising processes. Such insights can potentially inform the design of more efficient or accurate diffusion models in the future.\n\n* Despite the focus on the VE-SDE case, the paper provides a detailed analysis of the sampling and denoising trajectories. The investigation into the quasi-linearity of these trajectories and their monotonic progression from start to finish is an interesting observation.\n\n* Overall, the article is well written."
            },
            "weaknesses": {
                "value": "* One major concern is that the authors focus only on the VE case (although they mention that a similar analysis applies to a variance preserving SDE). While interesting, such limitation reduces generality of the claims. Some of the numerical observations might simply be artifacts of the considered SDE class, and do not provide information about diffusion models in general. Moreover, I find the different sections to be somehow disconnected; in certain cases some results are presented as original, while to the best of my understanding, they are restating known literature results. Finally, the connection to a \u201cgeometrical perspective\u201d is very weak.\n\n* Recall Observation 1: \u201cThe sampling trajectory is almost straight while the denoising trajectory is bent\u201d. As explicitly mentioned in Proposition 2, the norm of the corrupted data will be much greater than the clean data. On the other hand, the denoising trajectory will have (by construction) a roughly constant norm at each step. Then observation 1 is almost trivial. Is it still valid for other SDEs? If not, what information is the proposition offer to the reader? Similar considerations apply for Observation 2. Also, I would advise the authors to rescale Fig 2b (maybe logarithmic y axes), since in the \u201cregion of interest\u201d(small diffusion steps) it is very difficult to compare top and bottom subplots.\n\n* Observation 3 is equivalent to the following rephrasing: \u201cthe output of a denoiser has better FID score than its input\u201d. This is trivially true, and once again provides very limited insight into the geometry of diffusions. One interesting technique is related to the computation of the FID score using the JUMP scheme, but it seems that the technique provides limited benefit for values of FID which are competitive.\n\n* Section 4 discusses how second order schemes use in their numerical implementation approximations of the second order time derivative of the sampling process. This is exactly how second order numerical \nschemes are derived. Then, what is the take home message of this Section?\n\n* Proposition 4 is a known result from [Karras 2022], in particular Eq. (57) in the Appendix. The authors should explicitly mention this. I would also suggest to rephrase \u201conce a diffusion model has converged to the optimum...\u201d. At first I was confused about whether the authors were referring to convergence to the final \nsampling point or convergence of the parameters of the score network (I assume the authors are referring to the latter).\n\n* The content of Section 6 concerns the study of score deviation from its ideal value. Also in this case, the authors do not to compare their results with the work by Karras, 2022, where it is stated (see their \nSection 5, page 9):\n\u201cInspecting the per-$\\sigma$ loss after training (blue and orange curves) reveals that a significant reduction is possible only at intermediate noise levels; at very low levels, it is both difficult and irrelevant to discern the vanishingly small noise component, whereas at high levels the training targets are always dissimilar from the correct answer that approaches dataset average\u201d\nHow is this different from the claim in your article: \u201c the deviation between the learned denoising output  and its optimal counterpart behaves differently in three successive regions...\u201d?\n\n* Finally, while the content of Section 6 is technically correct, I fail to see the geometrical perspective in the findings (is the l2 distance the only geometrical metric to consider?)"
            },
            "questions": {
                "value": "* Given that the study focuses exclusively on Variance Exploding-SDE (VE-SDE) models, how do the authors anticipate their findings would generalize to other types of SDEs, such as Variance Preserving-SDEs (VP-SDEs)? Could the geometrical insights and behavior of trajectories observed in this study be applicable or significantly different for other SDE formulations?\n\n* The review on the weaknesses above points out that the connection to a \"geometrical perspectives\" seems weak in some sections. Could the authors elaborate on how they define and utilize geometrical analysis within the context of this study, particularly how it pertains to understanding the dynamics of diffusion models?\n\n* Regarding Observation 3, where it's noted that the output of a denoiser generally has a better FID score than its input, could the authors discuss any unexpected or non-trivial implications of this finding, particularly in how it might influence the design or optimization of future diffusion models?\n\n* Proposition 4 appears to overlap significantly with findings from [Karras 2022]. Could the authors clarify what distinct contribution this proposition makes beyond the existing literature? Additionally, how do their findings in Section 6 diverge from or confirm the observations made in [Karras 2022] regarding score deviation at various noise levels?\n\n* Could you please help in clarifying what are the novel contributions of Section 4, with respect to the discussion on second order schemes? Could the authors highlight how their analysis of these schemes contributes new understanding or practical advancements in the field of diffusion models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698352754809,
        "cdate": 1698352754809,
        "tmdate": 1699636905595,
        "mdate": 1699636905595,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VuMk06Wx0f",
        "forum": "WTJv0L5QLX",
        "replyto": "WTJv0L5QLX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_dBDN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_dBDN"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to study the variance-exploding diffusion models used for generative modeling. It contains some propositions, lemmas, and a theorem stating some theoretical properties of the diffusion models. These results characterize the behavior of the denoising and sampling trajectories. They are often written in a sloppy manner and most of them, in my opinion, concern some simple facts that do not need to be stated as propositions. \n\nThe paper also contains some observations, based on empirical experiments on image datasets that are often used in the literature on generative modeling. These observations are mostly some simple claims that are not poorly justified. In my opinion, their practical usefulness is limited. Some precise remarks are provided below, but let me simply quote here Observation 4 \"The learned score is well-matched to the optimal score in the large-noise region, otherwise they may diverge or almost coincide depending on different regions.\" Basically, this observation tells us that in the small-noise region, which is the main region of interest, one cannot say much about the fit of the optimal score with the learned score."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1) The paper deals with an interesting problem, that of generative modeling using exploding-variance diffusion models. \n2) To the best of my knowledge, Theorem 1 is new.  \n3) Experimental results are of some interest."
            },
            "weaknesses": {
                "value": "1) Mathematical writing is sloppy. \n2) The observations are not sufficiently well justified, and their impact is limited. \n3) Some of the mathematical results are trivial. \n\nMore specific remarks:\n\nSection 2 : \n\n- There is an ambiguity between distribution and density function. Given the formula of the score function used, for instance, in (2), $p_t$ denotes the probability density function with respect to the Lebesgue measure. Then, it is written that $p_0 = p_d$ is the empirical data distribution. This is unclear to me. The empirical data distribution does not admit a density wrt to the Lebesgue measure. I guess $p_d$ is not the empirical data distribution, but the density of the \u201ctheoretical\u201d distribution of a data point.\n \n- It is worth defining the precise meanings of $p_d$ and $p_n$ in the beginning of Section 2\n- Eq 1 & 2, $dx$ should be replaced by $dx_t$\n- Eq 3: this part is unclear for several reasons. First, it is not defined what is $\\theta$, what is $\\sigma$ and what is $r$? Second, the least squares problem should necessarily involve a minimization; it is not specified wrt to which quantity the minimization should be done. Third, what is the output of the least-squares problem and how it is related to the score?\n- Proposition 1 can hardly be considered as a mathematical statement. Is it possible to formulate it in the conventional forme: let $r_{\\theta}$  be \u2026 and $\\tilde x$ be the output of a one-step Euler scheme \u2026, then \u2026 ? Without exaggeration, with the current formulation I do not understand the claim of the proposition.\n- From a mathematical point of view, the first claim of Prop 2 is not well formulated. Indeed, the quantity on the left-hand side is random, which means that the meaning of the convergence hidden in big-O notation should be made clear. Regarding the proof of this proposition presented in the appendix,  \n  * Eq 44 has no mathematical meaning. One cannot write $a = b \\pm c$. \n  * Eq 45 is wrong  \nI believe what the authors try to do in this proposition can be done in a clean way\nusing Talagrand\u2019s Gaussian concentration inequality.\n\nSection 3 : \n- Observation 1 is poorly justified. The fact that the distance between the 10 points of the trajectory and the straight line connecting the first point to the last point of the set is smaller than 20 does not necessarily imply that the continuous-time path these points are sampled from is a line. It might very well be a spiral around a line or any other curve.  \nThere is a well known method in statistical data analysis for measuring how close a point cloud is to a line. It is called PCA and suggests to look at the spectrum of the correlation matrix. It would be more relevant to justify the closeness to a line by such a method, based on more than a dozen of points.  \n- Observation 2: it is not quite clear to me what the authors call \u201cmove monotonically\u201d. Since the justification of observation 2 seems to be the blue curve of fig 2 (b), I guess the meaning of monotonicity here is to be understood as the monotonicity of the function that maps t to the distance between z(t) and z(0), where z is either the x or r. \n- Observation 3, and Fig 3: I am not sure that the denoising trajectory converges faster than the sampling trajectory does. The speed of convergence is the derivative of the curve (the slope), which seems to be stronger for the sampling trajectory than for the denoising trajectory."
            },
            "questions": {
                "value": "I have no questions for the authors. My suggestions are listed above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698620620475,
        "cdate": 1698620620475,
        "tmdate": 1699636905489,
        "mdate": 1699636905489,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2eR7tm65oJ",
        "forum": "WTJv0L5QLX",
        "replyto": "WTJv0L5QLX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_SvFU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_SvFU"
        ],
        "content": {
            "summary": {
                "value": "This paper examined the geometric properties of the sampling trajectory and the denoising trajectory, along an ODE-based sampling process, EDM. The observed properties are summarized as following:\n\n1. The sampling trajectory is almost straight while the denoising trajectory is bent.\n\n2. Both trajectories monotonically move from the initial points to final points in expectation.\n\n3. The denoising trajectory converges faster than the sampling trajectory in terms of visual quality, FID and sample likelihood.\n\n4. The learned score is well-matched to the optimal score in the large-noise region, otherwise they may diverge or almost coincide depending on different regions.\n\nBased on the observations, the authors proposed that\n\n1. an ODE-jump sampler, which jumps from the sampling trajectory to the denoising trajectory in the last step, can achieve FID improvement/reduce NFEs.\n\n2. a series of second-order sampler can be reduced to a second-order Taylor polynomial approximation of the sampling trajectory and various finite differences of derivative of the denoising trajectory. \n\nAt the end of the paper, the optimal denoising output was analyzed and related to annealed mean shift."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper combines lots of analytical and experimental evidences to support the geometric understanding of the sampling trajectory and the denoising trajectory in EDM."
            },
            "weaknesses": {
                "value": "1. Lack of novelty. Most of the results/techniques have been observed/used in other papers."
            },
            "questions": {
                "value": "1. How are section 4 and 5 related to the geometric properties of the two trajectories? I don't quite understand why it is essential to include  Section 4 in the paper.\n\n2. For the ODE-jump solver, can we actually prove the improvement theoretically?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7498/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7498/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7498/Reviewer_SvFU"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727608068,
        "cdate": 1698727608068,
        "tmdate": 1699636905356,
        "mdate": 1699636905356,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PwI8hk4b5L",
        "forum": "WTJv0L5QLX",
        "replyto": "WTJv0L5QLX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_fQGm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7498/Reviewer_fQGm"
        ],
        "content": {
            "summary": {
                "value": "This work explores ODE-based sampling from variance exploding diffusion models from a geometric perspective. In particular, the relationship between the sampling trajectory and the denoising trajectory is investigated. Several small propositions and observations are made which link existing fast ODE solvers and ODE-based sampling to the mean-shift algorithm."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Very clear exposition and intuitive geometric explanation for some interesting observations on ODE-based sampling of VE diffusion models\n- Simple yet effective theory linking mean-shift algorithms to diffusion models which I have not seen before.\n- Theory is supported by empirical evidence in large-scale diffusion models."
            },
            "weaknesses": {
                "value": "- My main issue with this work is that it is unclear exactly how to use these theoretical insights and observations to improve diffusion models and diffusion model sampling. While it is interesting to link mean-shift algorithms to diffusion models it is not shown how this link leads to improved sampling. Similarly, while all the fast ODE solvers are shown to be related, it is unclear how to use this for better sampling.\n- Theory is all quite simple (though useful), and is not particularly novel.\n- I have seen the jump trick used in practice fairly often, and do not think this is a particularly novel insight. For example in RFDiffusion this trick is used [1]. Though I doubt this is the origin of this trick.\n\nOverall I lean towards rejection, but could be convinced by a small amount of actionable insight, given the clear exposition and intuitive geometric figures. However, I note I do not have full knowledge of the novelty of this with regard to related work in this space. \n\n[1] Joseph L. Watson, David Juergens, Nathaniel R. Bennett, Brian L. Trippe, Jason Yim, Helen E. Eisenach, Woody Ahern, Andrew J. Borst, Robert J. Ragotte, Lukas F. Milles, Basile I. M. Wicky, Nikita Hanikel, Samuel J. Pellock, Alexis Courbet, William Sheffler, Jue Wang, Preetham Venkatesh, Isaac Sappington, Susana V\u00e1zquez Torres, Anna Lauko, Valentin De Bortoli, Emile Mathieu, Regina Barzilay, Tommi S. Jaakkola, Frank DiMaio, Minkyung Baek, David Baker. Broadly applicable and accurate protein design by integrating structure prediction networks and diffusion generative models. Science 2023."
            },
            "questions": {
                "value": "Comments:\n\nProp 2 could use an \u201cand\u201d before the limit. \n\n> We mostly take unconditional generation on CIFAR-10 as an example to demonstrate our observations.\n\nIs this true? I don\u2019t see this from the figures."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807964461,
        "cdate": 1698807964461,
        "tmdate": 1699636905221,
        "mdate": 1699636905221,
        "license": "CC BY 4.0",
        "version": 2
    }
]