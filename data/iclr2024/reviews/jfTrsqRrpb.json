[
    {
        "id": "sZxOXR3X9j",
        "forum": "jfTrsqRrpb",
        "replyto": "jfTrsqRrpb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_bvBC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_bvBC"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the limitations of top-down instance segmentation architectures in open-world scenarios, where predefined closed-world taxonomies may not be sufficient. To overcome this challenge, the authors propose a novel approach called Bottom-Up and Top-Down Open-world Segmentation (UDOS).\n\nUDOS combines classical bottom-up segmentation methods within a top-down learning framework. It utilizes a top-down network trained with weak supervision derived from class-agnostic bottom-up segmentation to predict object parts. These part-masks are then refined through affinity-based grouping to generate precise instance-level segmentations.\n\nThe key advantage of UDOS is its ability to balance the efficiency of top-down architectures with the capacity to handle unseen categories by leveraging bottom-up supervision. By incorporating both approaches, UDOS achieves superior performance over state-of-the-art methods in cross-category and cross-dataset transfer tasks. The authors validate their approach on challenging datasets such as MS-COCO, LVIS, ADE20k, UVO, and OpenImages."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper demonstrates a high level of originality in several aspects. Firstly, it introduces the concept of combining classical bottom-up segmentation methods with a top-down learning framework to address the limitations of predefined taxonomies in open-world scenarios.\n\n+ The use of weak supervision derived from class-agnostic bottom-up segmentation to predict object parts contributes to the originality of the proposed method."
            },
            "weaknesses": {
                "value": "- While the Multiscale Combinatorial Grouping (MCG) approach was proposed in 2016, it might be beneficial to consider the use of more recent methods, such as the Segmentation Attention Module (SAM), to enhance the generation of higher-quality masks for this problem. The integration of SAM into the existing framework could potentially improve the performance and accuracy of mask generation.\n\n- In order to provide a comprehensive evaluation of the proposed approach, it would be valuable to compare it with relevant open-world panoptic segmentation techniques, such as ODISE (Open-vocabulary DIffusion-based panoptic SEgmentation). The inclusion of a comparative analysis with ODISE would enable a thorough assessment of the strengths and weaknesses of the proposed method and offer insights into its effectiveness in handling open-world scenarios."
            },
            "questions": {
                "value": "Please refer to paper Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2753/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698044354555,
        "cdate": 1698044354555,
        "tmdate": 1699636217940,
        "mdate": 1699636217940,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ligVzKmnB9",
        "forum": "jfTrsqRrpb",
        "replyto": "jfTrsqRrpb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_QToW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_QToW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes bottom-Up and top-Down Open-world Segmentation (UDOS), a novel approach that combines classical bottom-up segmentation methods within a top-down learning framework."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This method is reasonable and novel. Combining bottom-up and top-down is an interesting idea."
            },
            "weaknesses": {
                "value": "1. This paper generate candidate object regions through unsupervised segmentation methods. However, it cannot be guaranteed that these unsupervised methods can generate object regions that cover all regions. Especially when the number of categories increases, I question the performance of the unsupervised segmentation methods. The author should provide :1) the specific performance of the unsupervised segmentation methods, 2) experimental comparison with existing methods when categories are more, like COCO to LVIS.\n2. The author should provide more result metrics with previous methods. For example, LDET also provides AP, AR10. The author should provide related performance comparisons to provide more comprehensive results.\n3. [A] also proproses a CLN (region proposal generation algorithm). What's about performance comparision with this work.\n4. What's about the details about Refinement module? I feel that this is all about previous methods, no matter the objectness ranking and inference.\n\n[A] Detecting everything in the open world: Towards universal object detection. CVPR 2023"
            },
            "questions": {
                "value": "Please refer to the weakness part. I will adjust the rating based on the author's feedback."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Reviewer_QToW"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2753/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698753635099,
        "cdate": 1698753635099,
        "tmdate": 1699636217854,
        "mdate": 1699636217854,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hcrW3djYrJ",
        "forum": "jfTrsqRrpb",
        "replyto": "jfTrsqRrpb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_Rvq9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_Rvq9"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed the UDOS for open-world instance segmentation that combines bottom-up unsupervised grouping with top-down learning. This model designed a grouping module and refinement method to achieve SOTA performance on multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The group-parts-to-whole strategy for segmentation is interesting. \nExperiments on multiples datasets verify the effectiveness of the proposed methods.\nThe paper writing and organization are good and clear."
            },
            "weaknesses": {
                "value": "Question: \n1. Is there any time-consuming experiments on the cluster in the grouping module? Because the similarity is calculated two-by-two.\n2. I am interested in the AP performance if adding the classification head in cross-datasets and cross-category setting. I know the task is category-free and different from open-vocabulary segmentation task, but I wander the segmentation performance with higher recall.\n3. As we know, the segment anything (SAM[1]) has high generalizability in category-free segmentation task. It is a foundation model pretrained in many data, but its zero-shot ability is strong without fine-tune in specific datasets in category-free segmentation task, so I think the comparison is necessary. Can this have higher recall that SAM? If not, please discuss on the contribution.\n4. Why exclude part masks from U that overlap with any ground truth mask in S with an IoU greater than 0.9? Please discuss on it with experiments.\n5. How about the grouping result on these situations: two same-category instances are close (or overlap), two instance with similar color, two hierarchical categories (e.g. clothes and person).\n[1] Segment Anything, ICCV2023."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2753/Reviewer_Rvq9"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2753/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837691521,
        "cdate": 1698837691521,
        "tmdate": 1699636217774,
        "mdate": 1699636217774,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Y767YqrrHN",
        "forum": "jfTrsqRrpb",
        "replyto": "jfTrsqRrpb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_jfRf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2753/Reviewer_jfRf"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a top-down bottom-up approach for open-set instance segmentation. The bottom-up segmentation module is used to predict object parts, and then the authors use a clustering/group method to assemble parts into objects.  The main point that the authors try to argue is that, this bottom-up module somehow fits well in the open-world (open-set) instance segmentation scenario."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "originality: The approach involves quite a few components. To me the authors build a quite complex system and it's unclear to me what the motivation and which component is the main reason which contributes to the good performance.\n\nquality: borderline\n\nclarity: The idea is clear and the paper is easy to follow\n\nsignificance: The task per se is quite important. However I do not think the system presented in this paper is good enough to have an impact on open-world instance segmentation."
            },
            "weaknesses": {
                "value": "1) The bottom-up module is quite complex, involving a few components. I do see the authors did ablation experiments to justify some design choices, it is not clear why  part-segmentation and grouping work better than other baseline approaches.  Part-segmentation + grouping appeared in the literature long time ago and researchers abandoned this idea.  Current experiments in this paper do not convince me that this is actually a better idea for open-world segmentation.  A simple baseline will be to train a class-agnostic instance segmentation using, e.g. COCO annotations.  Papers already showed that a  class-agnostic model works better for open-world problems.\n\n2) The compared methods are very old. For example, authors choose Mask RCNN and MCG as the baseline methods. These two methods are very old. The authors will need to consider recent methods. Even for top-down methods, Mask2former etc. will be a much better choice. I see that the authors might argue that the proposed method can use any other top-down method to replace Mask RCNN. But still why choose MaskRCNN in the first place. Using a more recent method will make the experiment results more convincing."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2753/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698929354124,
        "cdate": 1698929354124,
        "tmdate": 1699636217713,
        "mdate": 1699636217713,
        "license": "CC BY 4.0",
        "version": 2
    }
]