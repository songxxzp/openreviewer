[
    {
        "id": "EQvIty6vp7",
        "forum": "GKING3cAaf",
        "replyto": "GKING3cAaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_SWdN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_SWdN"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the efficient design of language models with the limit of computation resources. It proposes to optimize the entropy of transformer decoders with the extra consideration of decoder depth and takes a fast way to achieve it. Experiments are done on 12 zero-shot tasks, and compared with OPTs, Pythia, GPT-2, and Cerebras-GPT."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper investigates an important and interesting problem, the efficient and expressive design of transformer language models.\n* The proposed method is simple and does not cost much, which can be done on the CPU within minutes."
            },
            "weaknesses": {
                "value": "* In 3.2, the paper incorporates the depth constraints into the entropy-driven design, which looks empirical. \n  * First, the paper thinks entropy can express expressiveness but the depth would hurt the effectiveness, and makes them a trade-off in Eq. 4. However, I think the expressiveness and effectiveness may include each other, which means the expressiveness of a model can indicate its effectiveness. \n  * Second, the paper argues that the depth-width ratio can play an important role and give a hyper-parameter \\beta to control it. However, I do not see much explanation about revising Eq. 2 to Eq. 4, and the choice of \\beta value. For example, why choose 1/16 as the \\beta value, and why make the ratio a multiplication factor in Eq. 4. More explanation is preferred.\n\n* The experiments in this paper are not very solid. \n  * First, the paper shall compare other methods for efficient model design like classic zero-shot NAS techniques in the main table. I see three figures about their training, but I think the concrete accuracy performance across tasks should be given in the main table. Also, the paper can compare with some classic zero-shot NAS techniques, which have been studied much in computer vision tasks. I understand the authors\u2019 claim that they also need a little GPU support while this method does not. However, as this method needs large-scale pre-training, I do not think the little cost of zero-shot NAS really matters. Thus, the paper needs a more detailed comparison with other techniques to illustrate the superiority. \n  * Second, the paper only works on very small models, which can not make me convinced of the effectiveness of the proposed method. As you can think, there are many techniques to largely affect the performance of small models. I understand that pre-training can cost much, but maybe the authors can operate on some pre-trained models, apply the search method, and do a little training, which will not cost much.\n* Can the authors give some concrete examples of the searched architectures, which might help us better understand the method design and motivate others?"
            },
            "questions": {
                "value": "Please check the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Reviewer_SWdN"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7730/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698529989522,
        "cdate": 1698529989522,
        "tmdate": 1699636943147,
        "mdate": 1699636943147,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YRB6HqxoXl",
        "forum": "GKING3cAaf",
        "replyto": "GKING3cAaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_BhDx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_BhDx"
        ],
        "content": {
            "summary": {
                "value": "This work develop a Neural Architecture Search method for transformers to be deployed on mobile devices. The method estimates the entropy of the initial transformer architecture and the maximum entropy architecture is search with an evolutionary algorithm. Once selected the architecture is pretrained and compared against other models on zero-shot tasks.\n\nRecommendation: I will start with a relatively low score tuntil the authors convince me that I can trust their evaluation. I am happy to increase my score if the authors explain why their experimental setup is comparable to the baselines in their work. I raise my score further if the authors provide a scaling analysis of larger models, or justify why such small models are interesting compared to models that are closer to 2 GB in size."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- strong correlations (0.86) between entropy measure and perplexity for many models trained from scratch compared to 0.77 for other methods\n- extensive evaluation and ablations\n- novel entropy approach for NAS"
            },
            "weaknesses": {
                "value": "- Experimental setups not comparable. OPT uses less tokens; Pythia (and Cerebras-GPT?) uses a batch size of 1024 sequences for faster training (at the loss of performance); Merino uses a batch sizes of 512 (slower training, but better performance)\n- The models are relatively small even for mobile devices. Since one could take a relatively large model, quantize it, and put it on a mobile device, this raises the question what the scaling behavior of the entropy method is. Does it scale to 1.3B? To 2.7B? I think any model under 2 GB is still pretty manageable for modern mobile devices and performance for such models is relevant."
            },
            "questions": {
                "value": "- How can FLOPs differ so much when the parameters are similar? Does it mean parameter sharing can be on/off for individual transformer blocks?\n- How much does the architecture change for a particular FLOPs target if you draw a new random seed (different initial weights) for the optimization procedure?\n- It seems you used a smaller batch size for training than Pythia did. Do you think that the evaluations with Pythia are still valid?\n- Why did you optimize for those particular FLOPs and parameter counts?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7730/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698704630728,
        "cdate": 1698704630728,
        "tmdate": 1699636943016,
        "mdate": 1699636943016,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jkG0aWySBR",
        "forum": "GKING3cAaf",
        "replyto": "GKING3cAaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_e1q5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_e1q5"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a way to find a small size model which supposedly when trained from scratch can achieve similar performance as full-size model. This attribute is particularly useful for obtaining models from small devices."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Well written\n2. The research direction is interesting."
            },
            "weaknesses": {
                "value": "1. The motivating theory sounds a bit weird to me.\n2. Experiments are not convincing."
            },
            "questions": {
                "value": "1. The paper keeps saying it's a data-independent method, which sounds odds to me as usually entropy is related to the certain distribution so it shouldn't be data-independent. But indeed their entropy definition (They seem to quote from previous works which I didn't check the correctness) is data-independent. That makes me confused. My question is, shouldn't a model's generalization capability depends on the difficulty of the task? It simply cannot be data-independent. \n\nIn particular, if I have a dataset which is nothing but a random permutation of certain corpus. And then I split it into train/test so in this case the train/test distribution are the same but the task itself is impossible. In the motivating theory, the model should still generalize. Without a reasonable clarification on this, I think the paper should be rejected.\n\n2. Since the model size is not large, I believe the paper should point out what's the performance difference between the approximation and the optimal solution. In this scale, the computational cost is not that high and we'd like to see the performance difference between approximated ones and non-approximated ones. That is,\n\n2-a: What if I do full SVD instead of approximated one, the performance difference?\n2-b: What if I solve the easy optimization problem by brute-force method on certain fine-grained grids, what's the performance difference?\n\n\n3. I don't know why when comparing to the NAS approaches, it uses 1b dataset. LM task itself as a judgement doesn't make sense to me. I'd like to see the essentially tasks from Table 2 compared when evaluating NAS."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7730/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698706833630,
        "cdate": 1698706833630,
        "tmdate": 1699636942892,
        "mdate": 1699636942892,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hlGld7ENc9",
        "forum": "GKING3cAaf",
        "replyto": "GKING3cAaf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_iksc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7730/Reviewer_iksc"
        ],
        "content": {
            "summary": {
                "value": "The authors propose an entropy-driven framework to achieve designing the efficient generative language models in resource constraint scenarios. Specifically, the authors leverage entropy to measure the effectiveness of deep neural networks based on previous methods, with consideration in the hardness to train a over-deep networks. An optimal efficient model designing strategy could be achieved by the proposed search process."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed method achieve to find a solution for efficient transformers design, which solves an important topic.\n2. The paper is well written, by clearly introducing the background information and the novel ideas."
            },
            "weaknesses": {
                "value": "1. The main concern I have is the experiment scale is too small. The larget model the proposed method used has 64M parameters, and the largest pre-trained model for comparison is OPT-350m. It's hard to make any conclusion when the overall performance is low. It would be better if the authors could provide the result on larger scale experiments.\n2. I'm curious about the search result and some conclusion. It would be better if authors could provide some insights about the general rule for efficient model architecture design. (For example, perhaps deeper layers should have wider network designs.)"
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7730/Reviewer_iksc"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7730/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699556644153,
        "cdate": 1699556644153,
        "tmdate": 1699636942798,
        "mdate": 1699636942798,
        "license": "CC BY 4.0",
        "version": 2
    }
]