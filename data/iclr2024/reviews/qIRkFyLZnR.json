[
    {
        "id": "XxYtKnDcqD",
        "forum": "qIRkFyLZnR",
        "replyto": "qIRkFyLZnR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_p4nt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_p4nt"
        ],
        "content": {
            "summary": {
                "value": "This paper consider offline robust RL for linear MDP with linear function approximation. The work is the first to consider this setting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The setting is interesting and novel, especially with function approximation for robust RL. \n2. The extension part makes the results more general."
            },
            "weaknesses": {
                "value": "1. I don't get the method in the work, how do you tackle the uncertainty from the dataset? Like in the tabular setting (Shi & Chi, 2022) and previous offline RL works, a penalty term is subtracted for those less visited states. How do you handle it in your method?\n2. The result seems not too surprising to me. The work is under the linear MDP setting, and the uncertainty set is defined w.r.t. $\\psi$. This setting is a little bit easy to me, as many nice properties hold under it, like the completeness of the linear function class."
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1966/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698261144582,
        "cdate": 1698261144582,
        "tmdate": 1699636128003,
        "mdate": 1699636128003,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pyYfCa9rd8",
        "forum": "qIRkFyLZnR",
        "replyto": "qIRkFyLZnR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_GkC9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_GkC9"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to combine the linear MDP with $d$-rectangular uncertainty set to admit linear function approximation for offline distributionally robust RL. Their proposed algorithms incorporate the linear function approximation and have finite-sample suboptimality bounds. The numerical experiment further show the performances."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This work proposes a novel setting incorporating linear MDP with $d$-rectangular assumption, in which the state-action value function admits linear representation. This is also the first attempt to investigate finite-sample sample complexities for offline distributionally robust RL with linear function approximation."
            },
            "weaknesses": {
                "value": "There are severe errors in this paper. The writing is not clear, some parts of the paper are hard to follow. The theoretical results are questionable."
            },
            "questions": {
                "value": "1. The part around equation (5) is hard to follow. It seems that a simple clip of the estimator from below can prevent the 'approach infinity and damage estimation' problem. I don't see the necessity of using value shift, and don't see how it contributed to the 'improved theoretical results' as claimed in the abstract. \n2. For the uniformly well-explored dataset assumption, the authors state that it is adopted in Jin et al. (2021); Duan et al. (2019) and Xie et al. (2021). Can you specify respectively in which assumptions/theorems they use the uniformly well-explored dataset assumption? Moreover, in the proof of Th 5.2, in the end there is a term like this, $\\Vert\\sum_{i=1}^d\\phi_i(s,a)\\bf{1}_i\\Vert$, which is unique in your setting. But the assumption is in the form of $E[\\phi(s_h,a_h)\\phi(s_h,a_h)^{\\top}]$. The proof is omitted by claiming using similar steps in the proof of Corollar 4.6 in Jin et al. (2021). More details should be provided to show the correctness of this assumption.\n3. For assumption 4.4, as far as I know, Zhou et al. (2021b), Panaganti & Kalathil (2022) didn't use this assumption. Actually, assumption 4.4 states that the optimizer $\\beta_{h,i}^*$ is lower bounded for any function $V$, this assumption cannot be true even with small uncertainty level $\\rho$. Specifically, in proposition 2 of Hu and Hong (2013), we have $\\beta^*=0$ if and only if $\\kappa:=P(X=essinf X)>0$ and $\\log\\kappa+\\delta\\geq 0$. If X is a constant, then $\\kappa=1$ and $\\log\\kappa+\\delta\\geq 0$ for any $\\delta$, in which case $\\beta^*$ can be zero. On the other hand, we should choose $\\rho$ based on practical need, rather always a small value. Even if it is small, it still cannot guarantee that assumption. \n4. Blanchet et al. (2023) also studied the same setting. They proved a $O(d^2H^2/\\sqrt{N})$ order suboptimality bound. While in your work,  you proved suboptimality bounds of $d^{1/2}H^2/\\sqrt{N}$ and $d^{3/2}H^2/N^{1/2}$. Why your results are $d^{3/2}$ and $d^{1/2}$ better, respectively? \n5. On page 8, it seems to me that section 5.2 of model misspecification comes out of no where. There is no model and formulation here, such as what is that uncertainty set for the non-linear transition kernel. In proof, the authors simply bound the inf of two uncertainty sets like as follows:\n$$\\inf_{P_{h+1} \\in \\mathcal{P_{h+1}}}E_{P_{h+1}}[V_{h+1}]-\\inf_{P_{h+1} \\in \\tilde{\\mathcal{P}}}E_{P_{h+1}}[V_{h+1}] \\leq (H-h)\\xi.$$ I don't think this is correct. Please provide with more argument.\n\n\n\nTypos and lack of clarification:\n1. At the beginning of page 2, distributional (DR) robust RL.\n2. At the beginning of page 3, the definition of value function and Q-function are wrong. NO definition of $N$, $d$, $\\delta$.\n3. Misuse of RLS as RTS in page 4.\n4. On page 2, how you define 'weak data conditions'. Is there a strong data condition counterpart? In the statement of open problem, what is the 'weak' data coverage conditions, weaker compared to what?\n5. Should $\\phi(s,a)\\geq 0$, which is necessary in the definition of $d$-rectangularity. The current definition in linear MDP cannot ensure that."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1966/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1966/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1966/Reviewer_GkC9"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1966/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698606262660,
        "cdate": 1698606262660,
        "tmdate": 1699906720010,
        "mdate": 1699906720010,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fbYJbUocI0",
        "forum": "qIRkFyLZnR",
        "replyto": "qIRkFyLZnR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_WFAe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_WFAe"
        ],
        "content": {
            "summary": {
                "value": "This paper studies distributionally robust offline linear soft state aggregation MDP under d-rectangularity condition with a KL distance to measure the probability distance. It gives an example why the $(s,a)$-rectangularity condition is not suitable for such problem and well motivates the use of d-rectangularity set. The paper proposed a value iteration method to solve the problem and demonstrate sub-optimality gap under the well-explored regime, the partly explored regime, and the misspecification regime. Numerical results demonstrates the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper provides a full story from the motivation, problem setting, algorithm design, complexity analysis, and several extensions to cover different regimes in practices. Certain tricks like value shift technique are used to bypass challenges in estimations, which can be of independent interests."
            },
            "weaknesses": {
                "value": "This is overall a strong paper. \n\nIn terms of presentation, the notation system is very complicated that one can easily get lost, which is also common for distributionally robust RL paper. \n\nIn terms of novelty, the motivation and settings are new. However, the components of algorithm design seem to be standard except for the estimation trick. Not a big matter given the more realistic setting. \n\nIn terms of result, Yin et al 2022 has improved complexity bound in the non-robust setting, which has been available for more than a year. According to the conjecture of the authors, they should be able to achieve optimal dependency in H as well. The authors are welcomed to add this to the camera-ready version."
            },
            "questions": {
                "value": "1. I suppose $\\psi_{h,i}(s)$ represents the $i$-th coordinate of $\\psi_{h}(s)$? Can the author explain why $\\psi$ satisfies the second equation in Definition 2.1?\n\n2. Page 2 line 2, it should be \"offline distributionally robust (DR) RL\". \n\n3. Robustness by definition already means being pessimistic. I wonder what is the different of pessimistic and robustness in the algorithm PDRVI-L?\n\n4. Does the technique and result extend to infinite horizon discounted MDP and why?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1966/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700578110,
        "cdate": 1698700578110,
        "tmdate": 1699636127835,
        "mdate": 1699636127835,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SPGS45Xhlm",
        "forum": "qIRkFyLZnR",
        "replyto": "qIRkFyLZnR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_T9sS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_T9sS"
        ],
        "content": {
            "summary": {
                "value": "This work targets the problem of handling model distribution shifts in offline RL problems, especially in the case that the environment is modeled in a linear function approximation way. This is an interesting problem since most of the existing works for this problem are in tabular settings. Targeting two history dataset quality: well-explored or weaker coverage, it proposed a robust algorithm DRVI-L, as long as the non-asymptotic sample complexity guarantees for it. In addition, this work conducted experiments to evaluate the performance of DRVI-L with comparisons to existing robust RL algorithms and non-robust counterparts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The topic of offline robust RL with linear function approximation is very interesting and in a pressing need.\n2. It provides a framework to target this problem by introducing proper assumption (Soft State Aggregation) and designing new algorithms based on this setting.\n3. The algorithm has been tested in experiments and shows competitive results compared to existing algorithms."
            },
            "weaknesses": {
                "value": "1. There exist many confusing notations or not proper abuse of notations. For example, $R^{rob} (\\pi, P) $ is abbreviated as $R(\\pi, P)$, which actually already represents the non-robust expected return, which causes some confusion about the notation $R$ later. More are listed later in details.\n2. The technical correctness is not clear to the reviewer since the Lemma E.2 in Appendix seems not correct. The reason is that: firstly, in Lemma E.1, there exists some transition kernel $P\\_{exist} \\in \\mathcal{P}\\_1$ (denoted as $P_{1,h}^*$ in the paper) that can leads to the equality in (14). However, this applying $P_{1,h}^*$ also defined in a  $\\arg\\min$ notion below (13). I guess actually $P_{1,h}^*$ is just some transition kernel in $\\mathcal{P}_{1}$ but not in a $\\arg\\min$ notion. Then applying Lemma E.1 to Lemma E.2 won't leads to the results that this work claims. Since Lemma E.1 and E.2 are essential part in the proof, it makes the technical correctness doubtful for the reviewer."
            },
            "questions": {
                "value": "1. As mentioned, what does the notation $P_{1,h}^*$ and $P_{2,h}^*$ mean in the proof of Lemma E.1, it has been re-defined at least twice.\n2. The expectation over $P_{1,\\pi}^*$ in Lemma E.1 is not clear. At each time step $h$, the expectation is determined by  $P_{1,h,\\pi}^*$ according to the reviewer's understanding. Carefully polishing the notation and presentation will be very helpful for the reader to check and follow the proof.\n2. What does $P^*$ mean in the proof of Lemma E.2, which has not been mentioned?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1966/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698709247234,
        "cdate": 1698709247234,
        "tmdate": 1699636127765,
        "mdate": 1699636127765,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "T5lSsvGpsq",
        "forum": "qIRkFyLZnR",
        "replyto": "qIRkFyLZnR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_EUgk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1966/Reviewer_EUgk"
        ],
        "content": {
            "summary": {
                "value": "This paper considers offline RL in a training-test model mismatch. They consider linear MDP model and provide robustness guarantees using distributional robust optimization under two settings of offline data: well=explored data and weakly-explored data. They provide sample complexity for robust offline RL for each of the settings of the offline data coverage."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The sample complexity looks reasonable."
            },
            "weaknesses": {
                "value": "The problem setting is limited\n* What if $D$ is not KL? What motivates $D$ to be KL in practice? \n* How do we know $\\rho$ in practice? What if we misspecified $\\rho$? \n* In what problems when this kind of model mismatch actually happen? Is there any motivating real example?"
            },
            "questions": {
                "value": "Please see my questions above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1966/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698802977516,
        "cdate": 1698802977516,
        "tmdate": 1699636127677,
        "mdate": 1699636127677,
        "license": "CC BY 4.0",
        "version": 2
    }
]