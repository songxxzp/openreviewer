[
    {
        "id": "cm8ykwwI0y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_vrrL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_vrrL"
        ],
        "forum": "6J7WG1jyog",
        "replyto": "6J7WG1jyog",
        "content": {
            "summary": {
                "value": "The authors mainly did continue training/SFT/RLAIF to LLM to further improve LLM in Arabic. From my perspective, the main issue the authors want to solve is cultural difference. Training on specific language sources helps solve the cultural difference."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors organize the paper clearly and describe in details on how to tune an LLM to work better on a specific language Arabic. From the evaluation, tuning improves metrics on both human and auto evaluations."
            },
            "weaknesses": {
                "value": "I think the main weakness is novelty. Though novel application should be also considered an contribution, I do not think the paper provides many insights on LLM in Arabic. It seems to just follow the common techniques continue training/SFT/RLAIF."
            },
            "questions": {
                "value": "What insight can I get from the paper? Does the paper just follow continue training/SFT/RLAIF to make LLM work on Arabic?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697350502399,
        "cdate": 1697350502399,
        "tmdate": 1699637089595,
        "mdate": 1699637089595,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qzS5qBWX8e",
        "forum": "6J7WG1jyog",
        "replyto": "6J7WG1jyog",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_P1tY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_P1tY"
        ],
        "content": {
            "summary": {
                "value": "Current LLMs have shown good performance on English but fail to align with local values and cultural norms in non-English environments. This paper introduces a packaged solution to localize LLMs to the Arabic language. First, they conduct an incremental pre-training on Arabic data. Then, they fine-tune Arabic natural questions and instructions related to Arab. Next, they employ a reward model trained on data with local culture and values. \n\nThe authors evaluate their model on different benchmarks, i.e., instruction-following benchmark, NLU benchmark, knowledge benchmark and culture localization benchmark. The model achieves SOTA performance among open Arabic LLMs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis paper is well-written and easy to follow.\n2.\tLocalization on specific culture is an important topic in LLMs.\n3.\tThis paper mentioned Arabic-related dataset and models, which can be useful for the people in related fields."
            },
            "weaknesses": {
                "value": "1.\tThe theoretical and technical contributions are poor. This paper is more like a engineering report to introduce how to localize a public LLM on Arabic, illustrating the operation and dataset during pre-training, instruction tunning and RLHF stage. All the methods are well-known. The findings are intuitive, using localize data to pre-train, instruction tuning and training RLHF can be helpful for better localization. It seems more suitable for an empirical NLP conference rather than a learning conference.\n2.\tThe newly introduced Arabic Cultural and Value Alignment benchmark is not novel. Previous work [1] also introduce a benchmark to measure the culture bias in Arabic LLMs. It seems the authors didn\u2019t mention and cite this paper.\n3.\tThe analyses are insufficient. I will be more excited to see a comprehensive and systematic evaluation on the contribution of different operation, i.e., pre-training, instruction tuning and RLHF, on different evaluation perspective, such as instruction-following, knowledge accuracy, culture alignment, etc. \n\n[1] Having Beer after Prayer? Measuring Cultural Bias in Large Language Models, https://arxiv.org/abs/2305.14456"
            },
            "questions": {
                "value": "1.\tCan you clarify your technical or theoretical contribution? Any novel method or new understanding about the previous method?\n2.\tCan you provide a comprehensive and systematic evaluation on the contribution of different operation, i.e., pre-training, instruction tuning and RLHF, on different evaluation perspective, such as instruction-following, knowledge accuracy, culture alignment, etc?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698893016997,
        "cdate": 1698893016997,
        "tmdate": 1699637089491,
        "mdate": 1699637089491,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2pdheArqie",
        "forum": "6J7WG1jyog",
        "replyto": "6J7WG1jyog",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_CfmQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8690/Reviewer_CfmQ"
        ],
        "content": {
            "summary": {
                "value": "This paper describes the building and evaluation of an LLM finetuned for the Arabic language and Arabic culture (referred to as localization). The work starts with a strong Llama2 model and does continued pre-training on a modest amount of English and Arabic data, supervised finetuning and RLAIF to obtain Arabic LLMs with improved instruction following capabilities, factual understanding and Arabic cultural sensitivity. AceGPT shows significant improvement over Jais (another Arabic), and is competitive with ChatGPT. The paper contributes a new benchmark ACVA for studying cultural alignment of language models. Localization/cultural alignment is a strong theme in the paper."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Pre-training with Arabic data seems to improve performance on MMLU and ACVA benchmarks, proving the utility of native language data.\n* An interesting analysis of preference for certain cultural contexts in Language model responses. A dataset for studying cultural alignment the same has been created, which is a novel and useful contribution. \n* Better performance than JAIS, comparable to ChaptGPT.\n* Ablation studies show the utility of pre-training with Arabic data and RLAIF (which improves both instruction following and localization)"
            },
            "weaknesses": {
                "value": "* While the paper makes an interesting contribution to an improved Arabic LLM, it does little to advance the study of building/adapting LLMs for non-English languages. Most of the methods are well known. A few studies can help draw broader lessons on the localization of LLMs: \n    * How much pre-training data is required? What is the best data balance between English and other languages? \n    * Does the English performance get impacted due to the finetuning?\n    * How objective is the ACVA benchmark? Different annotators (even amongst Arabic annotators) themselves might have different viewpoints on Arabic culture. On  subjective questions, what is the inter-annotator agreement on the answers?\n\n* Evaluation using automatically translated datasets can be problematic (MMLU and EXAM). \n  * Some human judgment on translation quality should be provided to understand the quality of the benchmark.\n  * You could consider other translation models: GPT4 vs NLLB or any available Arabic-specific NMT model that might be better than GPT4."
            },
            "questions": {
                "value": "* Please add more details about JAIS, which is the competing model, and should be included for readability. A discussion on why ACEGPT is better. Jais is trained with much more Arabic data, but a lot less English data (compared to the backbone Llama model that ACEGPT uses). yes, AceGPT has better performance than JAIS \u2013 which takes the approach of training from scratch and uses far less English data than  Llama2.\n* ACVA dataset: The dataset and its construction can be described better to better understand them.  \n     * You could put some examples of the ACVA tes test set (questions as well as responses (both yes and no) (there is a single example in E.4, but in Arabic). Multiple examples (both yes/no) with English translations would be very useful.\n     * You could add some examples of the prompt for ACVA dataset generation.\n* For all tasks, can you add the base/SFT/RLAIF model results? Would be useful for comparison and understanding impact. \n* Section 4.3.1: There seems to be little difference in the reward between \u2018yes\u2019 and \u2018no\u2019 answers \u2013 yet the model seems to improve on Arabic cultural alignment. Is it just due to the fact that the last stage of finetuning consumed Arabic Quora data? If an additional SFT training was done on just the Arabic Quora data, would that have had the same impact as RLAIF?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698896887663,
        "cdate": 1698896887663,
        "tmdate": 1699637089395,
        "mdate": 1699637089395,
        "license": "CC BY 4.0",
        "version": 2
    }
]