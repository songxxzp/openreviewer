[
    {
        "id": "RVvbjENNzF",
        "forum": "Tusy7IlWWw",
        "replyto": "Tusy7IlWWw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_4joa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_4joa"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose an augmentation technique for SSL methods, capable of extracting styles from in-batch or external datasets and transferring them to other images. This process effectively diversifies the styles of the original images. Additionally, the authors emphasize the necessity of preserving the semantic information of pre-training data. They introduce an intermediate stylized image to prevent substantial alteration of its semantic content. The authors report significant improvements compared to baselines, underscoring the efficacy of the proposed augmentation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The introduction of style augmentation is novel and holds promise for integration with other SSL methods.\n\n2. The proposed method markedly enhances the performance of the baseline.\n\n3. The paper is well-structured and effectively presented."
            },
            "weaknesses": {
                "value": "1. While the 2% improvement for MoCo V2 is noteworthy, the generalizability of the proposed augmentation technique necessitates evaluation across various methods, such as BYOL and SimSiam. \n\n2. To evaluate the representation quality, more downstream experiments are needed. The authors should consider expanding their experiments such as object detection and segmentation.\n\n3. The concept of controlling augmentation to preserve semantic information is not new. It's crucial for the authors to position their work within the context of existing literature.\n\n[1] Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biase. NeurIPS 2020.\n[2] Improving Transferability of Representations via Augmentation-Aware Self-Supervision. NeurIPS 2021.\n[3] RSA: Reducing Semantic Shift from Aggressive Augmentations for Self-supervised Learning. NeurIPS 2022."
            },
            "questions": {
                "value": "1. The enhancements observed during fine-tuning are not as pronounced as those in linear probing. Could the authors elucidate the factors contributing to this disparity?\n\n2. Have the authors employed strong augmentations during the linear probing phase? Typically, in settings of SimCLR and MoCo V2, only week augmentations are utilized. It would be help present the linear probing results on ImageNet-1K without strong augmentations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3499/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698020264875,
        "cdate": 1698020264875,
        "tmdate": 1699636303092,
        "mdate": 1699636303092,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2qe1p2tM7u",
        "forum": "Tusy7IlWWw",
        "replyto": "Tusy7IlWWw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_ifUN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_ifUN"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel data augmentation technique called SASSL (Style Augmentations for Self Supervised Learning) based on Neural Style Transfer. SASSL decouples semantic and stylistic attributes in images and applies transformations exclusively to the style while preserving content, generating diverse augmented samples that better retain their semantic properties. Experimental results demonstrate that SASSL improves classification performance on ImageNet and transfer learning performance on diverse datasets compared to existing methods. The paper also provides an overview of self-supervised learning, contrastive learning, style transfer, and texture synthesis, discussing the challenges and limitations of existing methods in these areas. The contributions of this paper include the introduction of the SASSL data augmentation technique, which effectively combines neural style transfer with self-supervised learning, and the demonstration of its benefits in improving classification and transfer learning performance.Their proposed augmentation improves downstream task performance by 2.09% top-1 accuracy on imagenet dataset and improves linear probing performance by up to 3.75% and fine-tuning by up to 1% on transfer learning on five diverse datasets. The paper also highlights the potential for future extensions of SASSL to other self-supervised learning methods and encoder architectures."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "In terms of originality, the paper introduces a novel data augmentation technique called SASSL that combines existing ideas like neural style transfer with self-supervised learning to increase robustness and have better transferability. This approach of decoupling semantic and stylistic attributes in images and applying transformations exclusively to the style while preserving content is unique and innovative. It offers a fresh perspective on data augmentation in self-supervised learning and provides a new way to generate diverse augmented samples while retaining semantic properties.\nThe quality of the paper is evident in the thorough experimental evaluation conducted. The authors compare SASSL with existing methods and demonstrate its effectiveness in improving classification performance on ImageNet and transfer learning performance on diverse datasets. The experimental results are well-presented and provide strong evidence for the benefits of SASSL.\nClarity is another strength of the paper. They explain the motivation behind SASSL and the technical details of the approach in a clear and concise manner. The paper is well-structured and easy to follow, making it accessible to readers.\nIn terms of significance, the paper makes a valuable contribution to the field of self-supervised learning and data augmentation. By introducing SASSL, the authors address the challenge of preserving semantic information while applying style transformations, which is crucial for generating augmented samples that retain their original content. The improved classification and transfer learning performance achieved by SASSL highlight its potential for enhancing the generalization capabilities of learned representations. This has implications for various downstream tasks and can lead to more robust and accurate machine learning models.\nOverall, the paper demonstrates originality, quality, clarity, and significance in its approach to data augmentation in self-supervised learning. It introduces a novel technique, presents the information clearly, and contributes to the advancement of the field."
            },
            "weaknesses": {
                "value": "One major concern is the lack of a detailed discussion about relevant data augmentation strategies, especially those manipulating image textures like [1]. Regarding the experiments, no existing data augmentation algorithm is compared against SASSL. \n\nAnother potential weakness of the paper is the lack of a comprehensive ablation study to analyze the effect of the number of layers in the stylization network on the performance. Conducting such an ablation study would provide deeper insights into the strengths and limitations of SASSL and help guide future improvements. \nAdditionally, the paper could provide more insights into the computational efficiency of the SASSL technique and comparison with other existing methods that also leverage style transfer for data augmentation. This would provide a clearer understanding of the computational requirement and unique contributions and advantages of SASSL compared to previous approaches.\n\n[1] ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. (ICLR\u201919)."
            },
            "questions": {
                "value": "What is the need for incorporating blending and pixel interpolation ? Is it purely for experimental purposes ? What is their significance in the proposed SASSL technique?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3499/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698766535082,
        "cdate": 1698766535082,
        "tmdate": 1699636303020,
        "mdate": 1699636303020,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7hDJw2F7in",
        "forum": "Tusy7IlWWw",
        "replyto": "Tusy7IlWWw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_ZUu3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_ZUu3"
        ],
        "content": {
            "summary": {
                "value": "This paper mainly discussed a self supervised data augmentation, here is the summary:  \nAuthors propose SASSL, a data augmentation technique based on Neural Style Transfer that\nnaturally preserves semantic information while varying stylistic information (Section 4).\nIn addition to that, authors have empirically demonstrated an improved downstream task performance by incorporating our\nmethod into MoCo v2, without additional hyperparameter tuning. We report more than 2% top-1\naccuracy improvement on the challenging ImageNet dataset (Section 5.1).\nAuthors claimed our augmentation method learns more robust representations by measuring their transfer learning capabilities on five diverse datasets. SASSL improves linear probing performance\nby up to 3.75% and fine-tuning by up to 1% on out-of-distribution tasks (Section 5.2).\nAuthors observed that balancing stylization using representation blending and image interpolation performs best, and adding external style datasets for transfer can improve performance (Section 5.3).\n\nIn general, supervised learning have been demonstrated a possible way to make data augmentation, this paper just made some contribution to this point."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I think neural transfer is a spot point in this paper. In self supervised learning and especially when this topic comes across with the field of data augmentation, it is necessary to raise way to capture the distribution of high dimensional data."
            },
            "weaknesses": {
                "value": "The downstream task is only about classification. Maybe it can happen to be successful."
            },
            "questions": {
                "value": "Can you or did you do some other downstream task to demonstrate the success of data augmentation (e.g. object detection?)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3499/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698889057718,
        "cdate": 1698889057718,
        "tmdate": 1699636302948,
        "mdate": 1699636302948,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QVUdTrjg7k",
        "forum": "Tusy7IlWWw",
        "replyto": "Tusy7IlWWw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_PzRD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3499/Reviewer_PzRD"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes SASSL (Style Augmentations for Self-Supervised Learning) to enhance the data augmentation strategies in SSL. SASSL applies neural style transfer to input images and take the stylized images as the augmented samples for SSL training. Experiments on SSL and transfer learning have been conducted to evaluate the proposed approach. SASSL outperforms original MoCo v2 by 2% on top-1 classification accuracy on the ImageNet dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Experiments on both SSL and transfer learning have been conducted to evaluate the proposed method. The method performs better than the original MoCO v2 on ImageNet SSL. \n\n2. The proposed is easy to understand."
            },
            "weaknesses": {
                "value": "1. The paper shows limited technical novelties. It adopts the commonly used NST method CSN for SSL data augmentation, where both CSN and SimCLR have been widely used in existing literature. Although the authors claimed that this is the first work to adopt NST for SSL, I assume this method of a simple combination of two well-known methods does not bring much inspiration to the community. In addition, similar ideas have been explored in early literature [r1, r2].\n\n2. The proposed idea (NST for SSL data augmentation) is only evaluated on CSN of NST and SimCLR of SSL. More different trials, such as adaptive instance normalization (AdaIN) of NST and more SSL frameworks should be evaluated to demonstrate the effectiveness of this idea. Furthermore, why would you call the normalization method as CSN? This method was noted as Conditional Instance Normalization (CIN) in original paper, and this notion CIN has been widely used in current NST literature.\n\n3. Table 2 shows that not all style datasets can outperform the original MoCo V2 for Retinopathy and DTD. The optimal style dataset also varies across different target datasets. The choice of style dataset would be a problem.\n\n4. Table 3 shows that the proposed method would even harm the performance when interpolation weight $\\beta=1$ that represents a full exploit of stylized image. A manual selection of $\\alpha$ and $\\beta$ are required, for instance $\\alpha, \\beta \\in [0.1, 0.3]$ in this paper. It's not clear how the authors determined this range. This range may also have to be customized for different datasets, limiting the practical usage of the method.\n\n5. It lacks insights into why NST works well for SSL data augmentation. Figures 2 and 3 do not provide sufficiently informative clues. They could probably be put into the appendix. The authors are encouraged to show more evidence of improvements (other than the performance improvement) brought by NST for SSL tasks. For instance in my mind, may we visualize the neuron activations before and after NST to investigate the effect of NST on SSL backbones?\n\n6. The notations in this paper are somewhat confusing. 1) $\\beta^{(k)}$ denotes the trainable function in conditional style normalization, while $\\beta$ denotes the interpolation factor of content and style images in Eq. 11. The authors should reconsider the notations for either of them; 2) Should $f$ be $h$ in Eq. 2? 3) In Eq. 7 $\\mathcal{T}$ is a stylization network, while in Eq. 1 $\\mathcal{T}$ denotes all possible augmentations.\n\n[r1] Zheng, Xu, et al. \"Stada: Style transfer as data augmentation.\" arXiv preprint arXiv:1909.01056 (2019).\n\n[r2] Jackson, Philip TG, et al. \"Style augmentation: data augmentation via style randomization.\" CVPR workshops. Vol. 6. 2019."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3499/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3499/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3499/Reviewer_PzRD"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3499/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698896107814,
        "cdate": 1698896107814,
        "tmdate": 1699636302882,
        "mdate": 1699636302882,
        "license": "CC BY 4.0",
        "version": 2
    }
]