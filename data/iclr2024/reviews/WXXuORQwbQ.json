[
    {
        "id": "pDfRQefCEN",
        "forum": "WXXuORQwbQ",
        "replyto": "WXXuORQwbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the use of sparse tensors to represent human-scene interaction data. Given a dense tensor input the authors proposed to learn multiple sparse masks. Sparse tensors are created by multiplying the learned masks and the dense input tensor. The sparse masks have a pre-defined fixed sparsity. The authors reused existing dense architecture but converted its dense operations into sparse ones.\nThe paper shows two applications: contact prediction and scene generation"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The input dimensionality in human-scene interaction is rightfully large. Using sparse input for this task is novel and technically sound.\n- The paper is easy to read.\n- Human-scene interaction is an interesting and important problem."
            },
            "weaknesses": {
                "value": "- The novelty is limited to sparsifying the input for the human-scene interaction. Using sparse inputs by itself is not new, but it has not been studied for this task before.\n- In Figure 6 and Table 4. It seems the model gets worse when using 50 or 10 masks which is strange.Why would using 3 masks be better than 10 or 50 masks? Why would it be even better than using the full dense tensor?\n- The paper attributes the COO representation to \"Choy 2020\". The COO format is much older than that. \n- Figure 4 is hard to see. Human bodies are too small."
            },
            "questions": {
                "value": "- The method is basically learning mesh subsampling. I wonder about how the method compares to classic subsampling methods.\n- Did the masking learn any interesting patterns? like which vertices are more relevant for which pose?\n- I understand that the method can be faster than POSA, but why would it be more accurate?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697659961359,
        "cdate": 1697659961359,
        "tmdate": 1699636086907,
        "mdate": 1699636086907,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8uSmj6JFrT",
        "forum": "WXXuORQwbQ",
        "replyto": "WXXuORQwbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
        ],
        "content": {
            "summary": {
                "value": "Instead of focusing on optimizing the model architecture, the authors proposed a novel way to enhance the human-scene interaction research from the view of representation. \nIt is revealed that the input for human-scene interaction is usually of high dimension, which limits the inference speed and effectiveness of the models.\nSparse Mask Representation is thus proposed, exploring the sparsity of the inputs.\nRigorous experiments are conducted on tasks related to contact prediction and scene synthesis.\nResults show the effectiveness of the proposed sparse encoding."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors show that introducing sparse encoding is an effective technique for the improvement of Human-Scene Interaction tasks.\nImpressive inference acceleration and model compression are achieved with the proposed method.\nCompetitive results are shown compared to previous efforts."
            },
            "weaknesses": {
                "value": "The current version appears to be an application of the Choy, 2020 citation. Clarification on the contribution beyond this should be provided.\n\nAs mentioned, the acceleration could be attributed to two factors. First, a sparse body mesh with 90% fewer vertices is used. Second, the sparse network works. Ablation should be conducted on the sparse mesh only and the sparse network only."
            },
            "questions": {
                "value": "Please refer to the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698575931631,
        "cdate": 1698575931631,
        "tmdate": 1699636086840,
        "mdate": 1699636086840,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fic0uhiR8c",
        "forum": "WXXuORQwbQ",
        "replyto": "WXXuORQwbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel approach called Sparse Mask Representation (SMR) to effectively handle the complex and sparse input data in human-scene interaction. Unlike previous methods that focused on lightweight models or quantization, SMR uses sparse masks to select important information from the input, reducing computational cost. Experimental results demonstrate its superior performance in contact prediction and scene synthesis tasks, with significantly faster inference speed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is skillfully written, ensuring ease of comprehension for the reader. It introduces a seemingly straightforward yet remarkably effective solution to the complex issue of human contact prediction in 3D environments. The authors have undertaken a thorough set of experiments, clearly demonstrating the superior performance of their approach. Furthermore, they have meticulously examined the related work, providing a comprehensive comparison with existing literature across multiple datasets."
            },
            "weaknesses": {
                "value": "I find the paper to be well-written, and the authors have conducted thorough experiments to demonstrate the effectiveness of their approach. The only potential area for improvement lies in providing more detailed explanations on how the sparse masks are defined, especially in the context of task dependency. This would further enhance the clarity and depth of the paper."
            },
            "questions": {
                "value": "Are the sparse masks randomly generated, meaning do the 0 and 1 values occur at random locations? Or are the masks specifically tailored to the task at hand?\n\nHow does your approach handle fine-grained contacts, such as situations where the tips of the fingers come into contact with other objects?\n\nAdditionally, could you elaborate on how your approach addresses videos?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A",
                    "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793054127,
        "cdate": 1698793054127,
        "tmdate": 1700995787974,
        "mdate": 1700995787974,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hNoJ9XArEe",
        "forum": "WXXuORQwbQ",
        "replyto": "WXXuORQwbQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_fpDr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1581/Reviewer_fpDr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new representation for human-scene interaction task. The authors suggest to inject sparsity in the input space rather than designing lightweight model, model pruning or quantization which were used by previous methods. By enforcing input sparsity, the method is simple and effective in benefitting both the accuracy and inference time."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Proposed approach is very simple but effective. The design choices made by the authors are intuitive and make sense. \n* The experiments and analysis are quite comprehensive and provides insights for the method. \n* Discussion is fairly done and includes a number of limitations and future directions. Overall it is a well written research paper."
            },
            "weaknesses": {
                "value": "* Methodology is incremental and not much novelty by itself."
            },
            "questions": {
                "value": "I can see that from Figure 6. it shows optimal performance for k = 3 mask with 90% sparsity, but there is no clear pattern or correlation between sparsity ratio vs accuracy. Could authors give an explanation on this trend?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818244487,
        "cdate": 1698818244487,
        "tmdate": 1699636086700,
        "mdate": 1699636086700,
        "license": "CC BY 4.0",
        "version": 2
    }
]