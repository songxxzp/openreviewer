[
    {
        "id": "eZiNyIhuHz",
        "forum": "lm7MRcsFiS",
        "replyto": "lm7MRcsFiS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_nnoZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_nnoZ"
        ],
        "content": {
            "summary": {
                "value": "This work proposed Ring-A-Bell, a model-agnostic red-teaming tool for T2I diffusion models, which serves as a prompt-based concept testing framework that generates problematic prompts to red-team T2I diffusion models with safety mechanisms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall this paper proposed a practical and intersting offline method in generating problematic prompts for 'safe models'. The experiments are very convincing and concrete."
            },
            "weaknesses": {
                "value": "Please see the questions."
            },
            "questions": {
                "value": "There are a bunch of notation issues. I list some of them below:\n1. What is $\\rho$ in (2)? I cannot find it in the main paper.\n2. What is the training parameter of (2)? Is it $\\widetilde c$?\n3. Are there brackets in (3)\n4. Should $\\tilde{\\mathbf{P}}_{cont}$ be a function of $c$ or $\\hat c$?\n\nQuestion about experiments:\n1. How to tell whether the percentage of nudity is greater than 50%? The output propobility? Please be rigorous."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5834/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5834/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5834/Reviewer_nnoZ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5834/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698631619265,
        "cdate": 1698631619265,
        "tmdate": 1699636616123,
        "mdate": 1699636616123,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WmXFRT04ZC",
        "forum": "lm7MRcsFiS",
        "replyto": "lm7MRcsFiS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_nmRw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_nmRw"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the safety of text-to-image models. The paper proposes a model-agnostic attack to evade safety mechanisms and generate sensitive and inappropriate images. The proposed work is evaluated on online services to explore their safety risks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper investigates red-teaming text-to-image models, which is a critical topic for generative AI safety.\n2. The proposed method is validated on four T2I online services.\n3. The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1. The model-agnostic design of the proposed framework is not convincing. The entire design is based on an offline CLIP model and is irrelevant to the online services. This design implicitly assumes that the framework that applies to the offline CLIP model can be transferable and effective for online services. What if the online services use a more robust text encoder? In addition, one of the contributions, claimed by the paper, is that Ring-A-Bell is \u201cbased solely on either the CLIP model or general text encoders.\u201d However, in the evaluation, only the CLIP model is evaluated. It would be great to see if the proposed work can be extended to other and more recent text encoders.\n2. The paper only compares the proposed framework with QF-Attack, which is insufficient. Many recent works are encouraged to be investigated [1-4]. In addition, although P4D is designed for offline attacks, it would be great to consider P4D as a baseline to compare the performance gap between online and offline attacks.\n3. The paper aims to evade the safety mechanism of online diffusion models. However, the paper only considers concept removal defenses. For an online service, an easy and effective way is to develop a detector to identify inappropriate images. For example, the service provider could build a detector (e.g., NudeNet detector used in the evaluation) to detect nudity in the images. The proposed framework that mainly focuses on the text domain may not be effective. \n\n[1] Qu, Yiting, Xinyue Shen, Xinlei He, Michael Backes, Savvas Zannettou, and Yang Zhang. \"Unsafe diffusion: On the generation of unsafe images and hateful memes from text-to-image models.\" ACM CCS 2023.\n[2] Mehrabi, Ninareh, Palash Goyal, Christophe Dupuy, Qian Hu, Shalini Ghosh, Richard Zemel, Kai-Wei Chang, Aram Galstyan, and Rahul Gupta. \"Flirt: Feedback loop in-context red teaming.\" arXiv preprint arXiv:2308.04265 (2023).\n[3] Rando, Javier, Daniel Paleka, David Lindner, Lennart Heim, and Florian Tram\u00e8r. \"Red-teaming the stable diffusion safety filter.\" arXiv preprint arXiv:2210.04610 (2022).\n[4] Yang, Yuchen, Bo Hui, Haolin Yuan, Neil Gong, and Yinzhi Cao. \"SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters.\" arXiv preprint arXiv:2305.12082 (2023)."
            },
            "questions": {
                "value": "Please clarify the model-agnostic design and explain why it is effective for online services."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5834/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727783050,
        "cdate": 1698727783050,
        "tmdate": 1699636616014,
        "mdate": 1699636616014,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D0sw232Dad",
        "forum": "lm7MRcsFiS",
        "replyto": "lm7MRcsFiS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_WiiG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_WiiG"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the effectiveness of safety mechanisms for text-to-image (T2I) diffusion models. It proposes a model-agnostic evaluation tool called Ring-A-Bell, which can assess the reliability of deployed safety mechanisms without prior knowledge of the target model. The tool performs concept extraction to identify problematic prompts and generates inappropriate content to evaluate the safety measures. The paper empirically validates the method by testing online services and various concept removal methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ significance: this paper reveals the importance of adversarial evaluation of the current concept removal works. Moreover, it performs its attack in a practical black-box way, which expands its evaluation scale to commercial APIs. How to evaluate the black-box commercial APIs is of great importance since they are powerful and more easily accessible by common people. \n\n+ quality: this paper takes a comprehensive inspect into the safety robustness of commercial APIs and also state-of-the-art concept removal methods, which demonstrates the efficacy of their method."
            },
            "weaknesses": {
                "value": "- their attack is easy to be filtered or removed by advanced NLP techniques such as large language model, since they perform token-level optimization on the prompt and the output is usually random combinations of tokens. large language model can purify the prompt by removing the semantically unclear part of the prompt.\n\n- the token level optimization is uninterpretable and cannot provide insights into how to defend against such attacks."
            },
            "questions": {
                "value": "- the ablation study of interference among modification, prompt dilution, and Ring-A-Bell: in Figure 2 and 3, the shown prompt contains the three types of texts. 1) is the whole prompt generated by Ring-A-Bell, or you combine the three types of attacks together for final output? how to discriminate the type of texts such as modification, prompt dilution, and Ring-A-Bell? 2) which type of text is essential to evade the safety filter of diffusion models or defeat the concept removal methods? \n\n- the ESD config is missing in Table 2 since it has multiple variants, whose concept removal effect is different from each other.\n\n- why K=16 is the final config? is there experiment result about smaller K?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5834/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698914840759,
        "cdate": 1698914840759,
        "tmdate": 1699636615921,
        "mdate": 1699636615921,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7lDtEbgxWZ",
        "forum": "lm7MRcsFiS",
        "replyto": "lm7MRcsFiS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_UevV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5834/Reviewer_UevV"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a model-agnostic red-teaming tool, Ring-A-Bell, for the evaluation of text-to-image (T2I) diffusion models\u2019 safety mechanisms. In the first stage, this concept retrieval algorithm would perform concept extraction by learning the difference between the embeddings of prompts with/ without the target concept (e.g., violence). With the extracted concept, the algorithm utilises genetic algorithms to produce problematic prompts to test the reliability of online T2I diffusion models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe main idea of the algorithms is clearly demonstrated with figures and examples. The motivation of the paper is clearly explained by analyzing the drawbacks of the current model-specific attack algorithms.\n\n2.\tExtensive experiments are well-designed to show the efficiency of Ring-A-Bell in generating problematic prompts in the field of nudity and violence. The evaluation is reasonable with the NudeNet detector. The results are clearly shown with quantitative tables and well-processed images to demonstrate the ability of Ring-A-Bell as a red-teaming tool."
            },
            "weaknesses": {
                "value": "1. The related work should include the introduction of the concept removal methods, such as the Safe Latent Diffusion mentioned in the paper.\n\n2. In the concept extraction stage, the selection/ generation of the prompt pairs, which are semantically similar but different from the target concept, is not clearly specified. Producing high-quality prompt pairs requires extensive specialized knowledge. This can affect the effectiveness of the algorithm and increase the difficulty of reproduction.\n\n3. The generation of p \u0303_cont is simply by a linear combination of the embedding of P and extracted empirical representation c \u0302, which needs further justification. The definition of \u2018target prompt P\u2019 is not specified.\n\n4. The ablation study is not properly implemented. For example, it might be better to demonstrate the performance of the algorithm with and without discrete optimization.\n\n5. The algorithm strongly emphasizes that the text encoder is the CLIP model. It might be better to test on other text encoders."
            },
            "questions": {
                "value": "see the above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5834/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699015691639,
        "cdate": 1699015691639,
        "tmdate": 1699636615813,
        "mdate": 1699636615813,
        "license": "CC BY 4.0",
        "version": 2
    }
]