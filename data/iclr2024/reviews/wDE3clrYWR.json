[
    {
        "id": "qpzGlERIy7",
        "forum": "wDE3clrYWR",
        "replyto": "wDE3clrYWR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_9yfn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_9yfn"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the Memory Metropolis (MeMe) algorithm, integrating neural networks with simulated annealing (SA) to optimize combinatorial problems on 2D binary grids. By leveraging a unique class of network architecture termed \"template networks,\" the method directs convergence towards states of structurally clustered patterns. This approach challenges conventional practices by intentionally violating the Markov property and is applied to nanophotonic inverse design, highlighting its potential in finding clustered design patterns."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The introduction of \"template networks\" and the Memory Metropolis approach presents a fresh perspective in the realm of optimization.\n\n* Combining elements from Markov Chain Monte Carlo optimization, neural networks, and reinforcement learning is interesting."
            },
            "weaknesses": {
                "value": "* The technical contribution is not strong. The proposal is generally mired in complexity which may make it inaccessible for readers not deeply familiar with all the integrated disciplines. Intentionally violating the Markov property without substantial justification is concerning. Further evidence or theoretical underpinnings are needed to support this decision.\n\n* Rewriting for clarity can make the paper more accessible to a broader audience.\n\n* The method of reward maximization and the process of determining detrimental actions is not explained in depth.\n\n* Abstract is too lengthy\n\n* The conclusion should reiterate the major findings, their implications, and potential future work in a more detailed manner."
            },
            "questions": {
                "value": "* A detailed side-by-side comparison with existing SA and regularized SA methodologies is required.\n\n* Delving deeper into the reasons for violating the Markov property and the potential implications can make the proposal more convincing.\n\n* Authors are suggested to discuss the broader applicability of the MeMe algorithm, beyond the specific case study presented.\n\n* The paper doesn't clarify whether the approach is generalizable outside of the specific domain it was applied to."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3402/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3402/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3402/Reviewer_9yfn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740065012,
        "cdate": 1698740065012,
        "tmdate": 1700735806475,
        "mdate": 1700735806475,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iUHX813lfa",
        "forum": "wDE3clrYWR",
        "replyto": "wDE3clrYWR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_SEFL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_SEFL"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel MCMC algorithm Memory Metropolis (MeMe), to tackle the combinatorial optimization problem in the context nanophotonic inverse design. The problem involves finding specially constrained patterns on a binary grid, with applications in creating high-performance devices for nanophotonic integrated circuits. MeMe involves the use of a neural network to build transition proposal distributions in Simulated Annealing (SA). The key contribution is 'template networks', a new class of network architectures designed to learn a template for constructing a proposal distribution for state transitions. MeMe violates the Markovian property as it uses past states to craft transition proposals. The template network is trained on the evaluation results of intermediate states of a single optimization run, which results in an architecture that does not require an input layer. Additional inductive biases are incorporated in the form of layers with limited local connectivity, which encourages the emergence of structural clusters. This biases the target distribution towards cluster formation. MeMe is also linked to deep RL, where the optimization objective of the Metropolis algorithm is viewed as a reward maximization problem. The policy is constructed using the discrepancy between the template and the current state, allowing the template network to find high-reward template-patterns. MeMe is evaluated empirically via application to combinatorial optimization in nanophotonic inverse design where it demonstrates significant improvements over standard SA."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper studies the interesting problem appearing in the context of nanophotonic inverse design. The problem is described and formalized clearly, well motivated and presents a unique interesting challenge for machine learning approaches. This isn't the first instantiation of using sampling approaches for combinatorial optimization but is quite well executed. \n* MeMe leverages advances from deep learning in the form of the template networks to craft effective proposal distributions within simulated annealing to model the biased target distribution to get high scoring candidates. \n* The experiments on the nanophotonic design task is described in ample detail and thoroughly analysed."
            },
            "weaknesses": {
                "value": "* A major weakness in my opinion is that it is unclear how much of the method is generally applicable to other problem settings. It appears that the design of the template networks requires quite a bit careful engineering and domain knowledge and can be potentially challenging on other tasks. The paper's narrow focus on a specific application also makes it somewhat poorly positioned for the audience at ICLR, even though the domain is introduced appropriately. I encourage the authors to consider alternative venues where the particular application is a focus. \n* Another major shortcoming is the lack of baselines - the authors only compare the apporach to simulated annealing but it would be good to have other baselines for instance some standard RL methods like PPO."
            },
            "questions": {
                "value": "* Can you provide more details on the computational cost of MeMe? How does it scale with the problem size?\n* There is a potential issue of overfitting in the training of the template network? If so, how is it addressed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698901841601,
        "cdate": 1698901841601,
        "tmdate": 1699636291317,
        "mdate": 1699636291317,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NhB97vaZCC",
        "forum": "wDE3clrYWR",
        "replyto": "wDE3clrYWR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_UWqi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3402/Reviewer_UWqi"
        ],
        "content": {
            "summary": {
                "value": "The paper suggests a combination of neural network-based approach and deep RL to the problem of combinatorial optimization with the simulated annealing algorithm. The proposed algorithm utilizes the RL approach to construct the proposal particles in the modification of Metropolis-Hastings scheme. The authors also provide a results on physical simulations demonstrating the efficiency of their approach compared to the vanilla simulated annealing scheme."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The topic of combining RL with discrete optimization is challenging, and the experimental results of the submission are spectacular, especially in the term of quite large problem dimension."
            },
            "weaknesses": {
                "value": "The relation of the proposed algorithm to the RL setting is not clearly explained in the current submission. Current submission lacks the detailed MDP description with the tuple of state space, action space, and reward, and the reward description for the particular optimization problem. The writing of section 3, and especially section 3.1 is hard to follow. The choice of extremely discounted RL problem (with $\\gamma = 0$) is also rather questionable for an empirical paper, and requires additional experimental verification. Moreover, there already were papers, e.g. [Beloborodov et al, 2020], [Mills et al, 2020], which already provided a framework for treating SA as an MDP and applied RL for solving it. That is why, I suggest the authors to better indicate the novelty of their approach.\n\n[Beloborodov et al, 2020] Beloborodov, D., Ulanov, A. E., Foerster, J. N., Whiteson, S., & Lvovsky, A. I. (2020). Reinforcement learning enhanced quantum-inspired algorithm for combinatorial optimization. Machine Learning: Science and Technology, 2(2), 025009.\n[Mills et al, 2020] Mills, Kyle, Pooya Ronagh, and Isaac Tamblyn. \"Finding the ground state of spin Hamiltonians with reinforcement learning.\" Nature Machine Intelligence 2.9 (2020): 509-517."
            },
            "questions": {
                "value": "I would suggest the authors to add more structure to the current version of section 3, adding more details on how the considered problem falls into the RL formalism. \n\nMoreover, I would like the authors to elaborate the novelty of their suggested algorithm. For example, RL approach to simulated annealing  was recently considered, e.g. in [Correia et al, 2023], and references therein. Thus I would suggest the authors to better highlight the novelty of their approach compared to the ones discussed in the previous papers.\n\nReferences:\n[Correia et al, 2023] Correia, Alvaro HC, Daniel E. Worrall, and Roberto Bondesan. \"Neural simulated annealing.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2023. \n[Beloborodov et al, 2020] Beloborodov, D., Ulanov, A. E., Foerster, J. N., Whiteson, S., & Lvovsky, A. I. (2020). Reinforcement learning enhanced quantum-inspired algorithm for combinatorial optimization. Machine Learning: Science and Technology, 2(2), 025009.\n[Mills et al, 2020] Mills, Kyle, Pooya Ronagh, and Isaac Tamblyn. \"Finding the ground state of spin Hamiltonians with reinforcement learning.\" Nature Machine Intelligence 2.9 (2020): 509-517."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699452438782,
        "cdate": 1699452438782,
        "tmdate": 1699636291258,
        "mdate": 1699636291258,
        "license": "CC BY 4.0",
        "version": 2
    }
]