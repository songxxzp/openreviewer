[
    {
        "id": "tFZZUVkFhW",
        "forum": "ESmvnmZ9fT",
        "replyto": "ESmvnmZ9fT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_BVY4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_BVY4"
        ],
        "content": {
            "summary": {
                "value": "The paper outlines an improved method for novel view synthesis and 3D scene reconstruction named Single Stage Convolutional Radiance Fields (SCoRF). SCoRF proposes to overcome existing limitations of Neural Radiance Fields (NeRF) by proposing a single-stage paradigm that jointly learns the relative position, colors, and densities of 3D rays using a Convolutional Neural Network (CNN). The authors also introduce an innovative adaptive position optimization loss function to enhance learning. Experimental results are presented, showing that SCoRF outperforms existing state-of-the-art methods in terms of photorealism and computational efficiency."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is original in its proposal of SCoRF, combining convolutional blocks with fully connected layers in a single-stage architecture to optimize complex scenes. The inclusion of an adaptive position optimization loss further strengthens the unique approach. \nIn terms of quality, the methodology appears well-developed and justified, with meticulous attention to detail in the experimental setup. \nThe paper is also highly significant as it addresses key limitations in existing NeRF-based approaches, opening up the potential for various applications in computer vision and computational photography. \nThe writing is clear, with relevant figures and tables to aid understanding, making the complex topic accessible to a wider audience in the field."
            },
            "weaknesses": {
                "value": "The visual results in Fig. 4 are worse than NeRF, especially in the highly reflective regions.\nConversely, although the paper indicates that the proposed SCoRF is computationally efficient, quantitative metrics such as training time or inference speed are not provided, weakening the argument.\nThe proposed method cannot be integrated with explicit voxel-based methods. Please correct me if  I am wrong."
            },
            "questions": {
                "value": "- Can the authors provide some metrics on the training and inference time of the proposed method?\n- Could the authors comment on how to integrate the proposed convolutional sampling strategy with existing explicit representations such as voxel, hash, or 3D Gaussians?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Reviewer_BVY4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5091/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698211268132,
        "cdate": 1698211268132,
        "tmdate": 1700661454380,
        "mdate": 1700661454380,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "joOVRgiG5K",
        "forum": "ESmvnmZ9fT",
        "replyto": "ESmvnmZ9fT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_eE9q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_eE9q"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a single-stage convolutional pipeline to replace the two-stage sampling strategies in the original nerf. The paper proposes a network with convolutions, which take the encoding positions and directions as input, and estimate the positional related values. These positional related values works like the distance between two sampled point in the standard volume rendering equations. The experiment shows competitive performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis method proposes to replace the time/memory consuming hierarchical sampling strategy with a single-stage convolutional pipeline, which is a reasonable motivation.\n2.\tThe experiment shows competitive performance in terms of image equality."
            },
            "weaknesses": {
                "value": "1.\tThe paper claims the problems of the original nerf including:\n\na)\t\u201crequire considerable training data and resources\u201d\n\nb)\t\u201ccomputational cost and time\u201d\n\nc)\t\u201cmany rays do not contain valid and pivotal point\u201d\n\nd)\t\u201cMLP-base NeRF are particularly inefficient\u201d\n\nAnd this method is proposed to solve these problems by a single-stage convolutional framework.\n\nHowever, from my view, none of these problems are solved according to the presentation of this paper. First, the number of the parameter of this method is almost the same with NeRF according to Table 3. Second, the speed of the method is not compared. Third, the input points of the method are sampled the same with coarse NeRF, so the input points of this method also \u201cmany rays do not contain valid and pivotal point\u201d, right?\n\n2.\tMore visual results are needed to show the performance of the method. Videos are critical to prove the effectiveness of the method in NVS area.\n\n3.\tThis method lacks interpretability. The equation 5 violate the theory of volume render (change the distance between two samples to some value estimate by the network). How would you explain this equation, or how would this equation work?"
            },
            "questions": {
                "value": "1.\tI notice that the loss (6) is proposed to ensure ascendant values. But is it really ascendant during the test?\n2.\tHow would you explain the generalization ability from training views to test views of this method? Since the network takes rays as input and the test rays are not available during the training stage, how would this network render reasonable test images?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Reviewer_eE9q"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5091/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698679110224,
        "cdate": 1698679110224,
        "tmdate": 1699636500094,
        "mdate": 1699636500094,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8LyG3yQ4lr",
        "forum": "ESmvnmZ9fT",
        "replyto": "ESmvnmZ9fT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_DEzN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5091/Reviewer_DEzN"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method to improve NeRF rendering quality by predicting new 3D point samples along camera rays. The main idea is to apply an 1D convolution over point positions and ray directions and predict a set of new 3D positions for volumetric rendering."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of exploring local relationship among 3D point samples along a ray is interesting."
            },
            "weaknesses": {
                "value": "**A. Technical-wise issues**\n1. Contribution 1 claims \u201cconsiderably reducing overfitting\u201d, which does not have any evidence showing in the experiment section.\n2. Not sure I understand the 2nd last sentence \u201cthey suffer from limitations in applying to many photorealistic view synthesis areas\u201d at the end of section 3.1?\n3. Section 3.2 title is about \u201csingle stage convolutional NeRF\u201d but the entire section does not explain how the \u201csingle stage convolutional\u201d is conducted. The only sentence vaguely express this idea is \u201cwe devise a network generating S position-related values {t_i}\u2026\u201d, whereas the majority of this section is about how to handle/avoid {t_i} not being monotonic increase. There should be at least a math formulation to show how the convolution is done, I.e. input and output.\n4. The draft spends almost a page (page 5) on getting {t_i} to be monotonic increase, while it could be resolved with some implementation tricks. For example, predicting {$\\Delta$t_i} instead of predicting {t_i} directly.\n5. Table 2a, why is the real dataset down-sampled to 504x378? The photo-realistic rendering performance would be more meaningful at higher resolutions.\n6. It seems like Table 3 tries to show that the proposed method provides better PSNR while having less network parameters comparing to previous methods. In this case, there are several baselines missing, for example TensoRF and K-planes.\n7. It seems like Table 4 tries to show the NVS performance under various number of point samples along a ray. First, this result would be more clear in a graph. Second, it needs to be compared with other baselines. How do other methods perform when the number of point samples drop?\n\n---\n**B. Presentation-wise issues**\n1. Figure 1 and Figure 2 should have more caption text. Currently Fig. 1 has no legend and it\u2019s unclear about what\u2019s the idea the figure would like to convey (I kind of understand it after staring it for long time). Also the entire paper is about applying an 1D convolution, which should be highlighted in figure 2.\n2. Figure 5, the depth map of the proposed method looks so different from others. I suspect it\u2019s a scaling or visualisation range issue?"
            },
            "questions": {
                "value": "See weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5091/Reviewer_DEzN"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5091/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698704511390,
        "cdate": 1698704511390,
        "tmdate": 1699636500004,
        "mdate": 1699636500004,
        "license": "CC BY 4.0",
        "version": 2
    }
]