[
    {
        "id": "zQqNLFb6ad",
        "forum": "HexshmBu0P",
        "replyto": "HexshmBu0P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_7nbF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_7nbF"
        ],
        "content": {
            "summary": {
                "value": "The paper provides an empirical study on watermarking for deep diffusion models (DMs). The authors propose a simple yet effective pipeline to embed watermark information into generated contents and DMs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper is well-written and the methodology is explained clearly. The authors have also provided a comprehensive explanation of their research with supportive visualizations.\n2.\tThe proposed watermarking pipelines are efficient and robust against some common distortions, which could have practical implications."
            },
            "weaknesses": {
                "value": "1.\tThe paper does not discuss how the proposed watermarking pipelines handle adversarial attacks or deliberate attempts to remove or modify the watermark. For example, finetune latent diffusion models with trigger prompt \u201c[V]\u201d again to remove the watermark.\n2.\tIn unconditional or class-conditional generation, the watermark string is fixed. Injecting a new watermark string requires training a new model from scratch, which is time-consuming.\n3.\tThe average PSNR (Peak Signal-to-Noise Ratio) presented in Table 1 is below 30 dB. In contrast, the majority of watermarking schemes typically achieve satisfactory visual quality when the PSNR is above 40 dB."
            },
            "questions": {
                "value": "1.\tThe training strategies for unconditional or class-conditional generation could potentially be optimized to minimize its cost.\n2.\tThe robustness could be further demonstrated by considering additional post-processing operations, such as JPEG compression under varying quality factors.\n\nPlease refer to the following paper: Fernandez P, Couairon G, J\u00e9gou H, et al. The stable signature: Rooting watermarks in latent diffusion models[J]. ICCV2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5103/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698588116815,
        "cdate": 1698588116815,
        "tmdate": 1699636502082,
        "mdate": 1699636502082,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XJLNvFVG7H",
        "forum": "HexshmBu0P",
        "replyto": "HexshmBu0P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_zWgb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_zWgb"
        ],
        "content": {
            "summary": {
                "value": "While the use of watermarking for copyright protection and content monitoring is a well-established approach, its application in the context of DMs is relatively unexplored. The work proposes a comprehensive analysis and a practical recipe (including two frameworks) for effectively watermarking cutting-edge DMs, such as Stable Diffusion. The suggested approach involves adapting conventional watermarking techniques to accommodate the unique characteristics of DM-generated content, providing a foundational guide for future research in this domain."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strengths lie in the following aspects:\n1) Originality: this work attempts to introduce watermark techniques into the generative neural network domain (diffusion model), which watermarks the neural model.\n2) Clarity: the work was well-written and easy to follow. The organization of this work is satisfactory.\n3) Results: the authors conducted extensive experiments to validate the effectiveness of the proposed methods."
            },
            "weaknesses": {
                "value": "The weaknesses can be identified in the following aspects:\n\n1) Methodology: While the proposed framework is indeed well-explored in discriminative learning tasks, its technical contribution appears somewhat limited. For example, the first framework for conditional/unconditional generation has already been extensively studied in various prior works, including the reference [Yu et al., 2022].\n\n2) Experiments: Despite the comprehensive nature of the conducted experiments, some crucial experiments were not included. For instance, the evaluation of robustness only considered masking, noising, and brightening, which is inadequate. Please refer to the subsequent questions for further details.\n\n3) The quality of the watermarked images is not entirely satisfactory, as the average PSNRs fall below 30dB, indicating a significant impact of the watermark embedding on the original generative models.\n\n[Yu et al. 2022] Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, and Mario Fritz. Artificial fingerprinting for generative models: Rooting deepfake attribution in training data. In IEEE International Conference on Computer Vision (ICCV), 2021."
            },
            "questions": {
                "value": "Some concerns need to be addressed:\n1) Concerning the first framework, the authors proposed the incorporation of a watermark bit string into the training dataset. The experimental results validated the effectiveness of this approach. I concur with this strategy. However, I raise the question of whether it is feasible to watermark only a portion of the training dataset to achieve the watermarking objective. For example, is it feasible to watermark only 30% or 50% of the samples?\n\n2) Regarding the second framework, in the design of the trigger prompt, the authors recommended using the uncommon identifier '[V]' as input. Should other rare identifiers, such as '!M~', be considered as well? Will the conclusions drawn from these considerations remain unaffected?\n\n3) Regarding the experiments, when assessing the resilience of the watermarked images, only three types of distortions, namely masking, noising, and brightening, were taken into account. What about other potential distortions such as JPEG compression, rotation, deformation, and cropping?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Reviewer_zWgb"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5103/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698596561547,
        "cdate": 1698596561547,
        "tmdate": 1699636501977,
        "mdate": 1699636501977,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RnGhWk9aSb",
        "forum": "HexshmBu0P",
        "replyto": "HexshmBu0P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_wQee"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5103/Reviewer_wQee"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes watermarking techniques for diffusion models to address legal challenges in copyright protection and generated content detection. It details two watermarking pipelines for different DM types and provides practical guidelines for implementation, balancing image quality with watermark robustness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper addresses a highly relevant contemporary issue.\n2. The experiments are thoroughly and rigorously executed.\n3. The manuscript is well-crafted, presenting its arguments in a clear sequence.\n\n\nSuggestions:\n1. Consider relocating some of the visual elements to the appendix.\n2. Shortening the captions of figures may enhance their readability.\n3. It may be beneficial for the authors to concentrate on a single methodology to provide a more focused exploration of the subject matter."
            },
            "weaknesses": {
                "value": "1. Copyright scenario is not clear. Is the copyright protection for model owner or for user who downloaded? \n2. Detecting generated contents is also not clear. Are the authors proposing method for detecting generated content? If so, where is the related experiments?\n3. Watermarking Stable Diffusion using Dreambooth has less novelty. The Dreamfusion itself is designed for training personalized concept to use it for Stable Diffusion's rich representation. In this sense, the authors change the personalized concept to watermark images. \n\n1. The manuscript could benefit from a clearer delineation of the copyright scenario. It would be helpful to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model.\n\n2. The section on detecting generated content could use further clarification. If that is the case, could you please direct me to the experiments that validate this approach?\n\n3. The approach to watermarking Stable Diffusion via Dreambooth may appear to have limited novelty since Dreamfusion is inherently capable of training personalized concepts for Stable Diffusion. It seems that this method lies in the adaptation of personalized concepts into watermark images."
            },
            "questions": {
                "value": "1. Regarding the watermarking process in Stable Diffusion, could you elucidate on the protocol if a caption such as \"A photo of QR code\" were provided? Is there a safeguard in place to prevent inadvertent leakage of the watermark under such circumstances?\n\n2. Could you specify the lower bound of the bit-wise accuracy for the watermarking technique? Such a metric would be instrumental in assessing the robustness of the approach."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5103/Reviewer_wQee"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5103/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698778799089,
        "cdate": 1698778799089,
        "tmdate": 1700673679090,
        "mdate": 1700673679090,
        "license": "CC BY 4.0",
        "version": 2
    }
]