[
    {
        "id": "Ri6JLItXln",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_B95a"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_B95a"
        ],
        "forum": "D1w3huGGpu",
        "replyto": "D1w3huGGpu",
        "content": {
            "summary": {
                "value": "This paper targets on developing agents for compositional generalization to novel combinations of observation and action spaces by using COIN architecture."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The target of this paper on generalization (specifically compositional generalization) is a key area in machine learning.\n2. A modular approach to compositional combinations of observation and action spaces seems a good fit and appropriate approach.\n3. Experiments show improvement over various COIN baselines."
            },
            "weaknesses": {
                "value": "1. This paper seems to be solely an application of COIN architecture in the setting of compositional combinations of observation and action spaces. It is not clear what novelty or technical contribution it has.\n2. The experiments are mainly on COIN architecture. No comparison with other approaches. It is hard to assess the effectiveness of this method."
            },
            "questions": {
                "value": "1. Why is there no comparison with non-COIN approaches?\n2. What is the novelty of this paper? It seems to be simply an application of COIN architecture on compositional combinations of observation and action spaces."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697150322744,
        "cdate": 1697150322744,
        "tmdate": 1699636929520,
        "mdate": 1699636929520,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GFgabLHSn0",
        "forum": "D1w3huGGpu",
        "replyto": "D1w3huGGpu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_Pm6p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_Pm6p"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to use end-to-end modular architectures to achieve compositional generalization to unseen combinations of observation\nand action spaces. It requires individual encoding and action modules for each observation and action space, with a single controller connecting them shared across different spaces. The paper constructs an synthetic environment with compositional structure and show through extensive experiments that the proposed method enables generalization to unseen combinations of observation and action spaces."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ Originality:\n\nThe paper proposes an effective design for compositional generalization of the agent's observation and action spaces. While modular architectures are well known in previous works, the presented work is novel in a sense that it is a successful demonstration that modular design can be effectively used for compositional generalization.\n\n+ Quality & Clarity:\n\nThe paper is well-written. Experiment designs are clean and comprehensive in general. The presentation is well-organized and easy to follow.\n\n+ Significance:\n\nThe presented work can be potentially beneficial for generalist agent design."
            },
            "weaknesses": {
                "value": "- Significance:\n\nIt would be great if noisy real-world data or more complex visual data is included in the testing scenario. It is unclear for now whether this design is robust enough to deal with the not-that-clean data regime."
            },
            "questions": {
                "value": "i) Could the authors provide insights or discussions about why the proposed method performs worse in the instruction space of `Sort by Property`? Is there a class of tasks that the proposed method fail to handle?\n\nii) For the `HARD HOLDOUTS` set-up, will the performance further improve if there are more easy combinations available for training? Are there any other possible solutions to address the easy-to-hard transfer problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed.",
                    "Yes, Potentially harmful insights, methodologies and applications"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Reviewer_Pm6p"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823931794,
        "cdate": 1698823931794,
        "tmdate": 1699636929415,
        "mdate": 1699636929415,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VRog1Rkn4l",
        "forum": "D1w3huGGpu",
        "replyto": "D1w3huGGpu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_h2vj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_h2vj"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a dataset and a system for compositional generalization to novel observation spaces, action spaces, and tasks using end-to-end modular architectures. These architectures divide the task into specialized differentiable modules for encoding observations and predicting actions; and they are connected. The authors create a controlled environment for testing. Experiments show that the modular approach allows agents to generalize to unseen combinations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper presented an modular approach towards compositional generalization, which is an important field and is definitely relevant to the theme of the conference. The sections defining the model and describing the experiments are well-structured, effectively conveying the core concepts and findings of the paper."
            },
            "weaknesses": {
                "value": "The main weakness of the paper is its limited contribution.\n\nOn the dataset aspect, it's a bit unclear what's new in this dataset. So the proposed dataset is based on a 2D grid world, with some 3D rendering. I do not see significant differences between this setting and Minigrid (https://github.com/Farama-Foundation/Minigrid), and many works have been built on Minigrid. For example, Minigrid also contains different observation spaces (symbolic vs. image), and there are also works that use text descriptions too. It also contains instruction-level compositionality. Another example in robotics is CompoSuite: A Compositional Reinforcement Learning Benchmark https://arxiv.org/pdf/2207.04136.pdf\n\nOn the model aspect, I don't see significant differences between this paper and other papers that use (most times pretrained) LLMs for decision-making. For example, https://arxiv.org/pdf/2202.01771.pdf they have studied different encodings of the input too. Its also similar to GATO, except that GATO does not use \"modules for encoding observations\". Another example in robotics is Modular Lifelong Reinforcement Learning via Neural Composition https://openreview.net/pdf?id=5XmLzdslFNN\n\nFindings. I think the findings of the paper are not completely new. Many aspects of it have been demonstrated in many works, mostly in more realistic settings such as robot manipulation. For example, GATO also demonstrated how it could learn new tasks faster based on other pretrained tasks. And again, the results here are only demonstrated in a very synthetic setting, it is very unclear how these findings can be generalized to realistic learning settings (e.g., multitask learning for robotics)."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7644/Reviewer_h2vj"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698890530216,
        "cdate": 1698890530216,
        "tmdate": 1701064543552,
        "mdate": 1701064543552,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qs88y1Xaef",
        "forum": "D1w3huGGpu",
        "replyto": "D1w3huGGpu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_n2i7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7644/Reviewer_n2i7"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Compositional Interfaces (COIN) architectures, the end-to-end modular architectures for compositional generalization to unseen combinations of observation and action spaces in embodied agent settings.\nDifferentiable modules in COIN handle observation encoding and action prediction.\nEach observation or action space has a module, but the controller is shared.\nThe environment with compositional structure is developed to investigate the architecture.\nAn environment instance is generated by combining observation, action, and instruction space.\nThe experiments show COIN enables compositional generalization and transfer learning. It generalizes to unseen combinations, and novel observation modalities can be quickly integrated."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem of compositional generalization for embodied agent settings is important.\n\n- The paper also developed a flexible compositional environment.\n\n- It uses end-to-end training and does not require a special training scheme.\n\n- The experiments support the ability of COIN for compositional generalization and transfer learning."
            },
            "weaknesses": {
                "value": "There are concerns that the task and the architecture do not cover general cases of compositional generalization in embodied agent tasks.\n\n(1) **Disentangled inputs:**\nIt handles disentangled inputs since the observation, action, and instruction space are separately provided, but it does not address more general entangled inputs.\n\n(2) **Types of combinations:**\nThere can be more possible compositional generalization problems, such as novel combinations of shape and color in observation.\n\n(3) **Given component IDs:**\nThe IDs of observation and action spaces are provided for each sample to select modules. They can be hidden in more general cases.\n\nHere are some other concerns.\n\n(4) The agent is trained with imitation learning, while another widely used algorithm is reinforcement learning.\n\n(5) In the experiment, the environment is small and synthetic. It also lacks strong baselines of existing embodied agent algorithms."
            },
            "questions": {
                "value": "Please refer to the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699278842707,
        "cdate": 1699278842707,
        "tmdate": 1699636929172,
        "mdate": 1699636929172,
        "license": "CC BY 4.0",
        "version": 2
    }
]