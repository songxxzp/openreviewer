[
    {
        "id": "XUrmOMqHzo",
        "forum": "PhJUd3mbhP",
        "replyto": "PhJUd3mbhP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
        ],
        "content": {
            "summary": {
                "value": "AutoAgents is a framework for orchestrating multiple specialized\nagents dynamically to form AI teams tailored to different tasks. It\ndivides the process into a Drafting Stage and an Execution Stage,\nallowing agents to collaborate effectively."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This study provides a valuable clarification of its position,\nespecially in the context of LLM-based Agent frameworks. In comparison\nto AgentVerse and SSP, this research stands out by highlighting the\nsignificance of Self-Refinement agents and Collaborative Refinement\nAction as key differentiators."
            },
            "weaknesses": {
                "value": "The paper is perceived as having low readability and insufficient\nreproducibility. The reviewer kindly requests a more granular\ndescription of the methodology that enables readers to implement the\nprocedures step by step. For instance, while Table 1 is highly\nbeneficial for positioning this research within the LLM-based Agent\nframework, in comparison to AgentVerse and SSP, it distinctly\nhighlights the significance of Self-Refinement agents and\nCollaborative Refinement Action. Nevertheless, the two points\nmentioned above are not clearly articulated in Section 3.2, \"EXECUTION\nSTAGE.\" They are mentioned in the text and Figure 2, but their\npresentation as steps is absent, making it challenging for readers to\ncomprehend and evaluate reproducibility.\n\nThe evaluation in the experiments lacks qualitative insights. In the\nexperiments, it remains unclear how the introduction of\nSelf-Refinement agents and Collaborative Refinement Action has led to\ndifferential outcomes compared to SSP, and what specific effects these\ntwo points have had. While accuracy has undeniably improved, it is\nessential to qualitatively demonstrate how these two aspects have\ncontributed to the observed results.\n\nThere are concerns regarding the reproducibility of the\nexperiments. It is unclear whether the CASE STUDY has been practically\nrealized or if it serves as an imagined example for\napplication.\n\n\nThe paper lacks an ablation study to assess the impact of modifying or\nomitting certain components within the system, particularly in the\nDraft and Execution phases where multiple agents are involved, such as\nAgent Observer, Plan Observer, Researcher, Planner, Writer, Character\nDeveloper, and others. This study could help elucidate the\nsignificance of each component and its contribution to the overall\nsystem.  Furthermore, the absence of an ablation study regarding\nShort-term memory, Long-term memory, and Dynamic memory raises\nconcerns. Investigating the effects of altering or removing these\nmemory components could provide valuable insights into their\nrespective roles and importance within the framework.  Overall,\nconducting such ablation studies would enhance the paper's depth and\nprovide a more comprehensive understanding of the system's inner\nworkings and the role of its individual components."
            },
            "questions": {
                "value": "Could you provide a more detailed, step-by-step description of the\nSelf-Refinement agents and Collaborative Refinement Action in Section\n3.2, \"EXECUTION STAGE,\" to enhance readability and reproducibility?\n\nCan you offer qualitative insights to elucidate how the introduction\nof Self-Refinement agents and Collaborative Refinement Action has\ninfluenced the experiment results, particularly in comparison to SSP,\nto help readers better understand the effects of these elements?\n\nPlease note that further clarification on the practical realization of\nthe CASE STUDY would be valuable to address concerns about\nreproducibility.\n\nIs there an opportunity for conducting ablation studies to investigate\nthe importance of individual components in both the Draft and\nExecution phases, as well as the Short-term memory, Long-term memory,\nand Dynamic memory components in Knowledge Sharing Mechanism? Such\nstudies could help clarify the significance and roles of these\ncomponents in the framework.\n\nThese three elements - the number of agents, self-refinement, and\nCollaborative Refinement Action - are key characteristics of this\nstudy from Table 1. Can you please explain why the OPEN-ENDED QUESTION\nANSWER and The Trivia Creative Writing tasks are well-suited for\nassessing the impact of these factors?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698542926792,
        "cdate": 1698542926792,
        "tmdate": 1699635934330,
        "mdate": 1699635934330,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KUTJW9Ftwy",
        "forum": "PhJUd3mbhP",
        "replyto": "PhJUd3mbhP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
        ],
        "content": {
            "summary": {
                "value": "This paper propose AutoAgents, a framework to generate multiple agents and let them cooperate to solve different problems. The framework consists of the draft stage and the execution stage. The draft stage uses 3 predefined agents to cooperatively produce an agent list and an execution plan for a specific problem. The execution stage uses the proposed expert agents to execute the plan and solve the problem. Experiments on two benchmark show the effectiveness of the proposed framework."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Clear presentation of high-level idea: the overall framework and process is clearly presented through well-drawn figures like Fig. 1 and 2.\n- Strong reproducibility: the author provides source code and the temperature of LLM is set to 0, which makes it easy to reproduce the result in the paper."
            },
            "weaknesses": {
                "value": "- Limited novelty: according to Table 1, the main difference between the proposed framework and other existing methods like Social Simulacra, Epidemic Modeling, SSP, and AgentVerse is that this work uses self-refinement and collaborative refinement. This difference is more of a prompting technique and has already been used in many existing works like [1, 2, 3]\n- Unclear presentation of detailed techniques: though the high-level idea is well-presented, the details of many technique are unclear. For example, how to determine when and which agents should engage in collaborative refinement? This is the main differnce from other methods but there is very little detailed description. More questions are in the Question part.\n- Insufficient evaluation: \n    1. Lack of baselines: Table 1 lists 12 existing frameworks, but none is used as baseline in task 1, and only 1 is used in task 2. Comparisons with existing methods are needed to show the effectiveness of the proposed methods.\n\n    2. Lack of ablation study: there is no quantitive ablations on different components of the framework like self-refinement, collaborative refinement, etc.\n\n    3. Unfair comparisons and potential problem in metric: in task 1, it is unfair to compare AutoAgents using GPT-4 with ChatGPT and Vicunna-13B. In task 2, the metric only considers the QA quality, how about the quality of the story around the given topic?\n\nReference:\n\n[1] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023.\n\n[2] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. Critic: Large language models can self-correct with tool-interactive critiquing, 2023.\n\n[3] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022."
            },
            "questions": {
                "value": "Detailed techniques:\n\n1. Section 3.1 Plan Generation: why plan genreation is parallel to agent generation? If the agent list has not been generated, how is it possible to \"entail a clear identification of agent\" for each step?\n\n2. Section 3.2 Action Observer: how does the Action Observer interact and communicate with other agents to act as the tasks manager and how is this process determined? When will the Action Observer adapt the execution plan.\n\n3. Section 3.2 Collaborative Refinement: how to determine when and which agents should engage in collaborative refinement?\n\n4. Section 3.2 Knowledge Sharing Mechanism: how to determine what knowledge is shared and who to share with?\n\nExperiments:\n\n5. Compare with more baselines in Table 1 for both task 1 and task 2, especially multi-agent frameworks like Social Simulacra, Epidemic Modeling, SSP, and AgentVerse.\n\n6. Unfair comparisons in Section 4.1: fair comparisons would be AutoAgents using ChatGPT v.s. ChatGPT and AutoAgents using Vicuna-13B v.s. Vicuna-13B.\n\n7. Metric problem in Section 4.2: the trivia creative writing task has two subtask: (a) craft a coherent story around a given topic (2) answer N questions. The current metric only evaluate the result of subtask (b), there need another metric for subtask (a).\n\n8. Ablation study: uantitive ablation results on different components of the framework. For example, remove self-refinement, collaborative refinement, different Observers, etc."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698746150240,
        "cdate": 1698746150240,
        "tmdate": 1700577997012,
        "mdate": 1700577997012,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CZlayiAqtq",
        "forum": "PhJUd3mbhP",
        "replyto": "PhJUd3mbhP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a framework for automatically synthesizing collaborative specialized agents. AutoAgents mimics the collaborative process of human teams by decomposing tasks into drafting and execution phases and delegating different subtasks to different agents. AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Finally, the experimental and empirical evaluation on various benchmarks validates the advantages of AutoAgents."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThis paper presents a framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks.\n2.\tThe paper is technically sound and the research question is clear. \n3.\tThe contribution of the paper is relevant for LLM-based multi-agent collaboration. The results of this paper is interesting and significant in automatic agent generation. The proposed AutoAgents framework generates more coherent and accurate solutions than the existing multi-agent methods."
            },
            "weaknesses": {
                "value": "1.\tHow the proposed AutoAgents framework expands the scope of collaborative applications and reduces the consumption of resources should be elaborated. \n2.\tThe authors do not explain how to determine the number of agents in the section of the framework for automatic agent generation.\n3.\tThe section about automatic agent generation is too tedious to introduce too much related works\n4.\tIn addition to ChatGPT, Vicuna-13B and GPT4 in Table 2, it has not enough recent models to further show the superiority of the proposed framework-AutoAgents in open-ended question answer task in the experimental part.\n5.\tIn the experimental part, the performance on N=10 is better than N=5 in trivia creative writing task, but there is no explanations."
            },
            "questions": {
                "value": "1.\tDuring the execution stage, why the authors adopt the vertical communication paradigm, which assigns different responsibilities to agents according to their roles. \n2.\tThe authors present results for the Open-ended Question Answer task and the Trivia Creative Writing task to evaluate the framework effectiveness. What if the Question Answer task is not open-ended? Does the proposed framework AutoAgents still work?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698822027003,
        "cdate": 1698822027003,
        "tmdate": 1699635934136,
        "mdate": 1699635934136,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XZLGgAbXIr",
        "forum": "PhJUd3mbhP",
        "replyto": "PhJUd3mbhP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes AutoAgents, a framework to generate and coordinate multiple specialised agents with distinct roles to construct an AI team to accomplish specialised tasks. The process comprises two stages: Drafting and Execution. The drafting stage involves Planner, Agent Observer, and Plan Observer agents discussing to generate the agent team and an execution plan, which is executed by the generated agents in the execution stage. The authors evaluated the performance of AutoAgents against a few existing solutions in the Open-ended Question-answering and Trivia Creative Writing task, and results show that AutoAgents performs better against the tested baselines. They performed a qualitative evaluation in a task requiring AutoAgents to generate the Tetris game."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of dynamically generating agents who play different roles to solve team tasks is interesting and useful. I found the idea to be novel. It is easy for the reader to get a good overview of the idea of AutoAgents. However, there was a need to look at supplementary materials to understand aspects of what the different predefined roles were supposed to do. The visuals helped me understand the idea better. The background was sufficient, in my opinion, and well-written. This discussion and Table 1 made the contributions clear."
            },
            "weaknesses": {
                "value": "Section 3:\nFor the agent generation, the motivation for the format of the Prompt P is unclear. Additionally, when we look at the supplementary material, the specific elements of the prompt are not explained -- are these taken from existing works?\n\nOthers:\nI also found details that needed to be included in a few other sections, such as the self-refinement process. Furthermore, I had questions about specific choices of parameters during the evaluations. I have included my questions in the next part to capture the specific places where I needed more information.\n\nMinor typos:\nPage 2: effectiveness of AutoAgents. [we] also conduct\nPage 7: at = lt \u222a pt \u222a ot, [where lt,] where lt denotes"
            },
            "questions": {
                "value": "1) What motivated the design of the prompt elements for the predefined agents? Did you consider alternatives, or did existing works inspire these?\n2) How were the roles, skills, and actions decided for the specific tasks? Were they injected in the prompt, or did the Planner agent generate them?\n3) For the self-refinement process, what was the source of the thoughts, i.e., who decided what thoughts to include and why?\n4) Regarding knowledge sharing, did you experiment with each agent using different types, or were these predefined onset?\n5) How did you decide to use the number of discussions in the two stages to 3 and 5, respectively (page 7)?\n6) In multiple places, the agents' discussions may be stopped after some predefined threshold if the agents do not reach a consensus (e.g. during collaborative refinement, page 7). How often did this happen, and if the team did process, what is the quality of the outcome?\n7) In the Open-ended Q&A, the authors mention recruiting volunteers, but no more details are provided about how, whether ethics approval was sought, etc. Could the authors please provide more details on this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "In the Open-ended Q&A, the authors mention recruiting volunteers, but no more details are provided about how, whether ethics approval was sought, etc."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk",
                    "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698909690899,
        "cdate": 1698909690899,
        "tmdate": 1700736503888,
        "mdate": 1700736503888,
        "license": "CC BY 4.0",
        "version": 2
    }
]