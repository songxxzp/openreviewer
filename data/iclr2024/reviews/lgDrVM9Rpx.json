[
    {
        "id": "ul7QJ7Wkk9",
        "forum": "lgDrVM9Rpx",
        "replyto": "lgDrVM9Rpx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_6mPa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_6mPa"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel online rasterized HDMapping algorithm P-MapNet and focuses on exploiting priors in both SDMap and HDMap to get rid of the current reliance on expensive HDMaps for autonomous vehicles. The authors propose two novel designs within P-MapNet: a multi-head cross-attention-based SDMap prior module to settle the problem of SDMap misalignment and a ViT-style HDMap prior refinement module pre-trained on the masked-autoencoder methodology. In the experiments, P-MapNet is evaluated on both the NuScenes, where it achieves a 13.4% improvement in mIOU at the range of 240m * 60m, and Argoverse2 dataset, where it increases by 9.36 mAP compared to the baseline method demonstrating the effectiveness of its far-seeing solution for online HDMap construction and localization challenges in autonomous driving scenarios via both SDMap and HDMap priors."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This work provides a detailed explanation of a two-phase OSM data-based rasterized SDMap generation method, contributing to the advancement of research on SDMap utilization.\n\n2. The main quantitative evaluations are performed on widely-used public datasets, namely NuScenes and Argoverse2, highlighting the salient performance improvement achieved by P-MapNet.\n\n3. The proposed design is thoroughly evaluated through a comprehensive set of ablations investigating the SDMap fusion methods. These ablations demonstrate the design merits of the proposed approach."
            },
            "weaknesses": {
                "value": "1. The paper emphasizes the limitation of relying on HDMaps for autonomous vehicles to operate outside regions with this infrastructure, yet it relies heavily on HDMap priors to refine outputs and address issues such as broken and unnecessarily curved results. Additionally, the approach of generating HDMap with prior information from HDMap seems counterintuitive and unreasonable.\n\n2. The paper falls short of providing the results under the setting of camera-only modality and combining both SDMap prior and HDMap prior modules. This omission raises concerns about the true impact of HDMap priors on the overall performance.\n\n3. In terms of vectorization baseline results, the authors only reproduce HDMapNet under their new settings on the NuScenes dataset, without conducting a comparison with other state-of-the-art methods, both vectorized and rasterized-to-vectorized. This limits the thoroughness of the performance evaluation."
            },
            "questions": {
                "value": "1. Could you please explain the reasons for selecting rasterized representation and employing post-processing for vectorized results instead of directly using a vectorized network? In Section 2.1, you mentioned the limitations of methods relying solely on onboard sensors, but it is not clear how this relates to the chosen representation. Additionally, you mentioned that your network is designed in a BEV dense prediction manner and the structured output space of BEV HDMap cannot be guaranteed. Given these factors, why not use the vectorized representation directly, which naturally addresses the problem and eliminates the need for additional MAE pretraining methodology?\n\n2. Can you provide a demonstration of why online generation of HDMap is necessary when given HDMap, and explain the relatively low increase in performance when HDMap priors are added?\n\n3. Can you report the results under the camera-only modality and when both SDMap prior and HDMap prior modules are combined, to accurately reflect the genuine influence of HDMap priors?\n\n4. Can you reproduce the results of more recent state-of-the-art methods in the new long-range settings to compare their performance with the vectorized results? This comparison should include, but not be limited to, VectorMapNet (mentioned but not compared with), MapTR, MapVR (which also perform rasterized-to-vectorized conversion), and PivotNet.\n\n5. In relation to Table 2, could you explain the significant decrease in frames per second (FPS) and how this might impact downstream or practical applications?\n\n6. Your SDMap Prior Module aligns misaligned SDMap with BEV features using multi-head cross-attention. However, what if there are localization errors present in the BEV features, which is a common occurrence in both camera-only and camera+lidar models?\n\nMinor issues:\nIn your summary of contributions, \"artefacts\" should be corrected to \"artifacts.\"\nRegarding your summary of contributions, I am confused about the example of \"P-MapNet is a far-seeing solution.\" Could you clarify what it is specifically used for?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3411/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3411/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3411/Reviewer_6mPa"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698673605881,
        "cdate": 1698673605881,
        "tmdate": 1699636292678,
        "mdate": 1699636292678,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DjwyarcpdB",
        "forum": "lgDrVM9Rpx",
        "replyto": "lgDrVM9Rpx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_mZgt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_mZgt"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new approach called P-MapNet for far-seeing HD-Map generation. The proposed P-MapNet exploits the priors from SD-Map and HD-Map for long-distance HD-Map. This paper first generates SD-Map for nuScenes and Argoverse datasets and then presents the P-MapNet framework which is based on BEV and contains the SD-Map prior module and the HD-Map prior module. The HD maps are predicted by the segmentation head. The experiments can show the proposed method is effective, especially for long-range HD map prediction."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper presents a new HD map framework named P-MapNet aims for long-range HD map construction.\n2. This paper builds the SD map for two datasets based on OpenStreetMap.\n3. The proposed framework P-MapNet adopts the coarse SD-map prior and the fine-grained HD-map prior for far-seeing map construction.\n4. The proposed P-MapNet obtains significant results compared to HDMapNet."
            },
            "weaknesses": {
                "value": "1. The experiments lack the comparisons with recent works, e.g., [1][2][3]. The baseline of HDMapNet is too old and weak.\n2. The idea of building long-distance HD maps has been explored in previous works [4,5], the authors should clearly state the difference and the superiority of the proposed framework.\n3. The proposed approach involves a large computation burden and  has lower inference speeds\n4. The authors evaluate the proposed framework on the benchmark with the max range of 240x60 while I'm concerned about the superiority of the proposed framework compared to the methods trained with the same range. In addition, I'm concerned about whether the proposed method has a limited range, and what the range is when SD maps do not work.\n5. The experiments about the downsampling factors of the SD map.\n6. Experimental results about P-MapNet(S+H) without lidar.\n7. In Sec.4.3, it's unclear how the initial maps are used in the mask image modelling and how the maps are refined during inference.\n\n[1] Liao et.al. MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction. ICLR 2023.\n[2] Liu et.al. VectorMapNet: End-to-end Vectorized HD Map Learning. ICML 2023.\n[3] Ding et.al. PivotNet: Vectorized Pivot Learning for End-to-end HD Map Construction. ICCV 2023.\n[4] Xiong et.al. Neural Map Prior for Autonomous Driving. CVPR 2023."
            },
            "questions": {
                "value": "1. I'm concerned about whether the proposed framework can be applied to vectorized methods, such as MapTR[1], though this paper tries to vectorize the map through post-processing.\n\n[1] Liao et.al. MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction. ICLR 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698863017705,
        "cdate": 1698863017705,
        "tmdate": 1699636292598,
        "mdate": 1699636292598,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GzsvjooTj3",
        "forum": "lgDrVM9Rpx",
        "replyto": "lgDrVM9Rpx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_8h86"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_8h86"
        ],
        "content": {
            "summary": {
                "value": "This draft improves the accuracy of the online map construction task by introducing prior information from SDMap and HDMap. It uses surround images and point cloud data as input to obtain BEV (Bird's Eye View) features, and then utilizes attention mechanism to extract corresponding features from SDMap to generate better bev feature. It further ensures the continuity of segmentation results by using a pre-trained HDMap model based on MAE. The utilization of these two priors significantly enhances the accuracy of map construction."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The introduction of prior information of SDMap significantly improves the map accuracy at both short range and long range.\n2. The highlight is the use of pretraining model based on MAE to ensure the continuity of segmentation result.\n3. The ablation experiments in this article are quite comprehensive."
            },
            "weaknesses": {
                "value": "1. If a vectorization modeling approach is used, there might not be such discontinuities in results. This article should conduct further experiments to validate this matter.\n2. The metrics of vectorization results should be compared with vectorized modeling methods.\n3. The mask proportion of MAE should undergo some ablation experiments.\n4. The benefits brought by the prior information of HDMap are too small.\n5. There are some data inaccuracies in mIoU in Table 2."
            },
            "questions": {
                "value": "What data should be used to train this MAE-based ViT?  And and would the model overfit if all the data is utilized?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698974638459,
        "cdate": 1698974638459,
        "tmdate": 1699636292522,
        "mdate": 1699636292522,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cpRNHRiYOd",
        "forum": "lgDrVM9Rpx",
        "replyto": "lgDrVM9Rpx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_Je8q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3411/Reviewer_Je8q"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to incorporate map priors, including priors both in SDMap and HDMap, to improve the performance of HDMap generation. Weakly aligned SDMap priors are extracted and encoded as an alternative conditioning branch. A masked autoencoder pretraining on nuscenes is utilized to refine the HDMap. Extensive experiments demonstrate the effectiveness of propose method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper is well structured. The presentation is clear and easy to understand.\n2.\tThe novelty of the paper is good, The designs are motivated well and intuitive is good.\n3.\tMAE was used to improve the performance of map construction.\n4.\tThe experiments are extensive, although some necessary experiments are missing."
            },
            "weaknesses": {
                "value": "1.\tThe benchmark is not compared reasonable. Comparison with recent advance works is needed.\n2.\tSome parts of the proposed method is not clarified clearly, such as the HDMap Refinement Module.\n3.\tThe performance of run time is not competitive.\n4.\tUtilizing pretrained MAE as second-stage refinement is interesting. However, its generalization as a pretrained model is more worthy of exploration."
            },
            "questions": {
                "value": "1.\tIt is reasonable to compare with recent works with advance performance (e.g. [1], [2])\n2.\tSome parts of the proposed method is not clarified clearly, such as the HDMap Refinement Module. Please introduce more details about it. How can it refine the initial predictions with absent sidewalks and broken lane lines? Are there any insights?\n3.\tThe performance of run time seems not competitive. Please explain about that.\n4.\tUtilizing pretrained MAE as second-stage refinement is interesting. However, its generalization as a pretrained model is more worthy of exploration. The reviewer wonder how it works when it come to other dataset, e.g., pretrained on nuscenes while inferenced on Ago.\nPlease explain my concerns and modify the manuscript according to the negatives. If all my concerns are well addressed, I will raise my score.\n[1] Liao B, Chen S, Wang X, et al. Maptr: Structured modeling and learning for online vectorized hd map construction[J]. arXiv preprint arXiv:2208.14437, 2022.\n[2] Liao B, Chen S, Zhang Y, et al. Maptrv2: An end-to-end framework for online vectorized hd map construction[J]. arXiv preprint arXiv:2308.05736, 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699264593990,
        "cdate": 1699264593990,
        "tmdate": 1699636292385,
        "mdate": 1699636292385,
        "license": "CC BY 4.0",
        "version": 2
    }
]