[
    {
        "id": "H3gZO2loH4",
        "forum": "N8UGyR3HTI",
        "replyto": "N8UGyR3HTI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_KgTt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_KgTt"
        ],
        "content": {
            "summary": {
                "value": "This paper studied regression learning with noisy labels, which is a seldom explored but important problem for machine learning. To address the problem, this paper proposed a novel noise-robust method by performing sample selection via a characteristic that data points similar in the feature space are likely to have similar labels. In addition, a neighborhood jittering regularization is used to improve the robustness. Experimental results confirmed the superiority of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The studied problem is highly valuable in real-world applications while seldom explored. This work used noisy regression benchmarks from various domains, which fully demonstrated the application potential of the proposed method.\n2. The proposed method is a reasonable solution that makes use of the orderly relationships within the label and feature spaces.\n3. The discussions and ablation analyses are thorough, making the effectiveness of the proposed method convincing."
            },
            "weaknesses": {
                "value": "1. Some important baselines are missing. For example, [1] is a nice baseline for regression learning with noisy labels. [2] performed bounding box correction by minimizing the discrepancy between two classifiers. Besides, I think there are some other works in noise-robust object detection that consider regression learning with noisy labels.\n2. Some highly related references in noisy label learning are missing. For example, the transition matrix methods [3-5], and the hybrid methods [6,7].\n3. The description of the proposed algorithm procedure and the experiment setting can be introduced more clearly. I have some questions and suggestions: 1) Are the prediction-based or representation-based sample selections used together in the proposed method? If not, when to use the prediction-based sample selection, and when to representation-based one? 2)  How to inject symmetric label noise in regression labels? 3) The pseudo-code of the proposed algorithm will help a lot for the readers who want to understand the detailed design.\n\n\n[1] Superloss: A generic loss for robust curriculum learning. NeurIPS 2020\n\n[2] Towards noise-resistant object detection with noisy annotations. arXiv 2020\n\n[3] Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. NeurIPS 2020\n\n[4] Part-dependent Label Noise: Towards Instance-dependent Label Noise. NeurIPS 2020\n\n[5] Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning. NeurIPS 2022\n\n[6] Selective-Supervised Contrastive Learning with Noisy Labels. CVPR 2022\n\n[7] Ngc: A unified framework for learning with open-world noisy data. ICCV 2021"
            },
            "questions": {
                "value": "I think this work is a nice work if the authors can address my concerns above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3113/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698174946962,
        "cdate": 1698174946962,
        "tmdate": 1699636257926,
        "mdate": 1699636257926,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m5rMHMPv3t",
        "forum": "N8UGyR3HTI",
        "replyto": "N8UGyR3HTI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_yzhv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_yzhv"
        ],
        "content": {
            "summary": {
                "value": "The paper presents FragSel, a method for improving regression methods in the presence of noisy labels. This method uses a simple technique to learn better representations by training over maximally distance subsets, and the authors shown strong performance on an array of standard benchmarks for label noise."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The overall communication is clear and straightforward, and the framing of the paper is evident and easy to understand throughout.\n- The presented method FragSel is novel yet relatively simple, leading to an effective method for improving regression in the context of label noise that is straightforward to reproduce.\n- The evaluation section is quite thorough, using a wide variety of benchmarks, noise methods, and evaluation metrics to assess the quality of their method."
            },
            "weaknesses": {
                "value": "- No real concerns are present, though I am not particularly well-versed in the literature on this topic so it is hard for me to assess if this work is sufficiently different from previous works."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Reviewer_yzhv"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3113/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698733241348,
        "cdate": 1698733241348,
        "tmdate": 1699636257845,
        "mdate": 1699636257845,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wEO9VkEQlx",
        "forum": "N8UGyR3HTI",
        "replyto": "N8UGyR3HTI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_PSFZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_PSFZ"
        ],
        "content": {
            "summary": {
                "value": "This papaer solves the problem of noisy label for regression task. It focuses on sample selection methodologies. It solves noisy label regression more well by (1) pairing samples with contrastive features, (2) considering neighbor agreement, and (3) neighborhood jittering. Additionally, this paper suggests new benchmark dataset for noisy label regression."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Curate a new benchmark dataset for regression task, and evaluate current benchmarks. \n- Apply graph structure to find the constasting pairs of dataset.\n- Suggest a new metric called Error Residual Ratio (ERR)."
            },
            "weaknesses": {
                "value": "- Figure 1 is hard to understand. It includes too much information that has not yet been explained.\n- I think it is already quite well known that samples with similar features tend to exhibit similar labels, and many studies have assumes that properties; the validity of Semi supervised learning, pseudo labeling stems from this assumption. Therefore, I think that the novelty of this paper may be limited from several previous sample selection based methods, since I think the method proposed in this paper is the combinations of the previous studies (suggested in the classification task).\n- I cannot understand yet why the method the authors suggests fits especially for the regression task. Can't it be applied to classification task?"
            },
            "questions": {
                "value": "- It is known that data points with similar features tend to exhibit similar label values. However, including noisy labeled data samples, it corrupts these similarity the model learns because the model tries to fit all data samples, which is also the problem of learning noisy data. Therefore, for managing noisy data, can we use the similar feature-similar label property as it is? Or should we use additional tricks for managing the problem? \n- Why should we select samples with framentation? (empirically, okay. Any theoretical idea?)\n- Number of fragmentation would matter...\n- Selecting the clean subset of the data, I think some bias can be included (e.g. maybe samples whose features are severely biased to one class will be easily sampled, and if samples are located between two fragments, it may not be selected although it is clean.). Can we mitigate it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3113/Reviewer_PSFZ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3113/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820823569,
        "cdate": 1698820823569,
        "tmdate": 1699636257736,
        "mdate": 1699636257736,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "trpBe3cOPL",
        "forum": "N8UGyR3HTI",
        "replyto": "N8UGyR3HTI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_3QwR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3113/Reviewer_3QwR"
        ],
        "content": {
            "summary": {
                "value": "Built upon the assumption that samples with similar labels tend to share relevant features, the authors propose a novel framework to model regression data collectively. They achieve this by transforming the data into disjoint yet contrasting fragmentation pairs, which utilize a mixture of neighboring fragments to identify noisy labels. This identification is carried out through an agreement among neighbors within both the prediction and representation spaces. Experimental results, demonstrated on four benchmark datasets, underscore the efficacy of the proposed framework in handling synthetic label noise."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) The exploration of the problem concerning noisy-labeled regression is both intriguing and practically significant.\n\n(2) The proposed method organizes data samples into clusters and capitalizes on neighborhood information, which is well-grounded for identifying noisy labels.\n\n(3) Tailored for noisy regression labels, the authors introduce a new metric called Error Residual Ratio for evaluating selected or refurbished samples.\n\n(4) Empirical efforts showcased the effectiveness of the proposed method, as well as evaluated the performance of certain baseline methods (previously applied in robust classification tasks) in addressing noisy label regression."
            },
            "weaknesses": {
                "value": "(1) The presentation could be further improved to help readers capture the proposed method. [please refer to Questions Q1, Q2]\n\n(2) When checking the empirical performances of the proposed method (FragSel-R v.s. FragSel-D), it seems that the role of classification-based feature extractor has much larger effect on the performance than the regression based method. And the performance of FragSel-R is not consistently better than baselines."
            },
            "questions": {
                "value": "(Q1) Is there a rationale behind the authors' choice to split fragments based on equal length rather than equal size? For instance, considering the age distribution of heart disease, it may be less common in children, resulting in fewer cases. Would splitting the data in intervals of 0-10, 10-20, etc., be suitable given such disparities?\n\n(Q2) In step 2 of the proposed contrastive fragmentation algorithm, for completing the graph, could authors explain a bit more about the whole process, i.e., why the edge weight is decided by the distance between the closest samples of the two fragments, instead of the distance between two centroids.\n\n(Q3) Regarding the performance of FragSel-R,-D, it seems that the classification-based feature extractor has much better effect than the regression based method. And the performance of FragSel-R is not consistently better than baselines.\n\n(Q4) In Appendix Figures 7 and 8, visualizing the baseline performance, i.e., F=1 (without employing FragSel), alongside the other results could provide a more direct understanding of how the number of fragments impacts performance. This comparison could offer more insightful conclusions.\n\n(Q5) While the authors assert that the sole hyperparameters of the framework are the number of fragments (F), the parameter K utilized for KNN-based prediction, and the extent of jittering applied for regularization, the influence of each on the results presented in Table 1 remains unclear. Could the authors provide additional insight into how these hyperparameters affect the outcomes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3113/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698966330008,
        "cdate": 1698966330008,
        "tmdate": 1699636257638,
        "mdate": 1699636257638,
        "license": "CC BY 4.0",
        "version": 2
    }
]