[
    {
        "id": "cfLdLKcVJP",
        "forum": "ATFPZbSZia",
        "replyto": "ATFPZbSZia",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_5Kts"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_5Kts"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a novel convolutional neural network for end-to-end 3D lane detection. First, the approach splits BEV features into vertical and horizontal groups along the channel dimension. Then, group convolution is applied to both vertical and horizontal groups to extract further features. During the training phase, the authors propose a SOM strategy to match ground truth and predictions. Finally, 3D lanes are detected by performing row-wise classification. Notably, this method achieves state-of-the-art performance in the 3D lane detection task on 3 benchmarks, OpenLane, Once-3DLanes, and OpenLane-Huawei."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Idea seems fundamentally sound.\n2. Spliting BEV feature for vertical and horizontal lane detection would be valuable, espeically when model is deployed on an edge device.\n3. Paper is well written and very easy to read."
            },
            "weaknesses": {
                "value": "1. Simply dividing each group into N outputs limited the max output lane number of the model.\n2. SOM strategy is simple yet effect, details are not well explained or even missing, eg. the matching cost definition."
            },
            "questions": {
                "value": "1. It is unclear what will happen when both the vertical and horizontal heads match the ground truth (GT). The paper does not provide a clear explanation or analysis of this scenario.\n2. The paper does not address how to ensure stable predictions. It raises concerns about the possibility of different heads predicting the same lane at different time and one of them is not the optimal prediction. \n3. Can not find the matching cost definition or loss functions in Section 3.4."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Reviewer_5Kts"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1158/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698048980599,
        "cdate": 1698048980599,
        "tmdate": 1699636042245,
        "mdate": 1699636042245,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KGTq1kHzYP",
        "forum": "ATFPZbSZia",
        "replyto": "ATFPZbSZia",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_dGoq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_dGoq"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a end-to-end 3D lane detection from a single image. The proposed model is based on technical contributions: (1) a splitting strategy that build several groups of features to represent a line, (2) two groups of heads to recognize, in the bird-eye-view (BEV), horizontal and vertical lines. The resulting model is evaluated on three public benchmarks and outperform existing models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is nicely written and easy to read. The main contribution, to my point of view, consists in splitting the BEV features into two groups of candidates: horizontal candidates and vertical candidates. Each group has 6 heads to predict existence confidence, visibility, category, row-wise classification index, x-axis offset, and z-axis offset. Since the proposed model splits the group of candidates in horizontal and vertical, the authors proposed an adapted technic called single-win one-to-one matching (SOM) to match each candidate with the training labels."
            },
            "weaknesses": {
                "value": "In the experimental part, GROUPLANE is evaluated on three datasets. The selected baseline model is PersFormer (described as the best published model). Can you give details on this choice? Regarding the benchmark webpage, it seems that the best 2022 model is 58% F1 score and that PersFormer is currently ranked 9. The resulting figure 2 is not fair and should be changed with new models.\nMoreover, can you add the two following references (ranked 1 and 2) from ICCV2023: \nLATR: 3D Lane Detection from Monocular Images with Transformer\nPETRv2: A Unified Framework for 3D Perception from Multi-Camera Images\n\nIn the ablation study, the authors compare the Horitontal/Vertical grouping strategy with only a vertical strategy. The proposed strategy increases about 5% the F1 score. It should be interesting to give information on the horizontal/vertical ratio of lines of the dataset. Moreover, it could be interesting to split the results into vertical/horizontal lines."
            },
            "questions": {
                "value": "Can you give details on the choice of PersFormer as the baseline for figure 2 and table 3?\nCan you give information on the horizontal/vertical ratio of lines of the dataset used for table 6?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1158/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698653564844,
        "cdate": 1698653564844,
        "tmdate": 1699636042167,
        "mdate": 1699636042167,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EvzhV2lSAH",
        "forum": "ATFPZbSZia",
        "replyto": "ATFPZbSZia",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_RkdN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1158/Reviewer_RkdN"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces anchor-based 3D lane detection utilizing channel-wise grouping features. Additionally, the authors propose a single-win one-to-one matching method that associates a grid belonging to vertical or horizontal lanes. The detection heads predict the existence, visibility, row index, lane category, and offset of lane points to grid centers. The paper provides extensive experimental results, demonstrating high performance on various lane detection benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Provide test results on various datasets and achieved high performances."
            },
            "weaknesses": {
                "value": "- The ultra-fast deep lane detection method has already introduced a hybrid anchor-based lane detection that predicts row-and-column anchors corresponding to lanes.\n- It is interesting to note that Table 1 and Table 2 exhibit inconsistent results when using different backbone models. It would be nicer if the authors further investigated this issue.\n\nZ. Qin, P. Zhang and X. Li, \"Ultra Fast Deep Lane Detection With Hybrid Anchor Driven Ordinal Classification,\" in IEEE TPAMI, 2022."
            },
            "questions": {
                "value": "."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1158/Reviewer_RkdN"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1158/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777213140,
        "cdate": 1698777213140,
        "tmdate": 1699636042077,
        "mdate": 1699636042077,
        "license": "CC BY 4.0",
        "version": 2
    }
]