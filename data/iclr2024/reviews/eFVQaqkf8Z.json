[
    {
        "id": "6e0YBIVyjJ",
        "forum": "eFVQaqkf8Z",
        "replyto": "eFVQaqkf8Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_7KS5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_7KS5"
        ],
        "content": {
            "summary": {
                "value": "The standard linear SVM fails in the classification of the XOR problem.  To resolve this problem, the authors proposed a new paradigm, equality separation. Additionally, they integrated the idea of equality separation into the neural network and applied the proposed method to supervised anomaly detection tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The authors studied the VC dimension of the proposed equality separation. The idea of equality separation can also be applied in the neural network.\n* The authors introduced the notion of closing numbers to quantify the difficulty of forming a closed decision boundary."
            },
            "weaknesses": {
                "value": "* Many times, I got overwhelmed and distracted by the narration and the layout of the manuscript. For examples,\n  * The sentence \"Equality separators use the distance from a learnt hyperplane as the classification metric\" is confusing: A distance is measured between two objects, but here the authors only mention one object, i.e., the learnt hyperplane.\n  * I feel the authors spent too much tutorial-like narration for VC dimension, closing number, and locality, in the main manuscript. In particular, what is the purpose of the over-detailed VC dimension? What useful information can we conclude in this section? Did the authors want to use the VC dimension to give some theoretical bound of generalization errors?\n  * In section 2.2, it is difficult to follow the mixed descriptions. The authors may use bullet points to describe case-by-case and use some plots to support the narration, if necessary.\n  * In section 3, the popped sentence \"The utility of equality separators becomes evident in AD setting\" is confusing since there is no particular interpretation of the utility of the equality separator in Anomaly Detection in the previous section after the introduction. As for the \"Anomaly detection\" in the introduction, it looks more like related works, maybe the authors could consider moving that part into Section 3.\n\n* For the equality separator, what is the necessity of this proposed method? \n  * Even though linear SVM fails to solve the XOR classification while equality separator can, why do not use kernel SVMs?\n  * In Figure 3(e), what if the unseen classes fall into the purple region but are far away from the brown points? Will they be classified as brown classes when using $\\epsilon$-error separator?  What if the brown class is surrounded by the blue class which consists of several cohorts? In this case, does $\\epsilon$-error separator work?\n  * When considering the toy example in Figure 3, the authors also use the kernel to improve the shallow equality separator. Does this imply that the proposed equality separator (even though it is simple and linear) in general is not proper without kernel or activation?\n\n* The decision of  $\\epsilon$-error separator depends on the value of $\\epsilon$, but I cannot see any discussion on the choice or computation for the value of  $\\epsilon$.\n\n* Since the paper is titled \"in Anomaly Detection\", it should contain more well-established anomaly detection benchmarks (http://odds.cs.stonybrook.edu)\n\n* There is no discussion on Deep One-Class Classification [1] or a comparison with it. This related work also targets anomaly detection by forming a circle boundary to the normal classes.\n\n* Is that possible to graphically show the closed decision boundaries on other examples formed by the proposed method? \n\n[1] Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel M\u00fcller, Marius Kloft Proceedings of the 35th International Conference on Machine Learning, PMLR 80:4393-4402, 2018."
            },
            "questions": {
                "value": "* Multiple minor issues:\n  * Line 1, Page 3: do you mean $\\mathbb{R}^+\\cup\\{0\\}$?\n  * Theorem 2.3.: separators $\\mathcal{H}$ \"in\" Def.\n  * Corollary 2.4: do you mean $\\mathcal{H}_\\epsilon$?\n\n* \"modeling a halfspace separator \u2026. with an equality separator requires non-linearity like ReLU\":  could the authors explain more about how the ReLU reflects the modeling for a halfspace with an equality separator?\n\n* \"equality separators yield a different optimal hyperplane compared to SVMs in binary classification\": could the authors articulate the \"optimality\" here?\n\n* \"where equality separation is more conservative in classifying the positive brown class\": What do you mean by \"more conservative\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698423765604,
        "cdate": 1698423765604,
        "tmdate": 1699637012426,
        "mdate": 1699637012426,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Cs01kXvZNe",
        "forum": "eFVQaqkf8Z",
        "replyto": "eFVQaqkf8Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_NTiL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_NTiL"
        ],
        "content": {
            "summary": {
                "value": "The authors explore the space of halfspace separator. In this manuscript they explore the equality separator. Instead of dividing the space into two halves, all instances that fall on the hyperplane (or are near to it) are part of one class while the rest belong to the other class. The others then calculate the VC dimension of this equality separator. Furthermore, they also introduce the bump activation function to be used in NNs which is a smoothed version of the equality separator. They propose using this separator for anomaly detection. Finally, they show the efficacy of the proposed method in the experimental section."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed equality separator is very interesting. Even though for epsilon-separator is related to SVMs there is still other novel aspects to this. Furthermore the theoretical analysis shown here for VC dimension shows the advantage of the proposed method over regular linear separators.\n2. The results for anomaly detection is promising specially on the synthetic data set.\n3. The paper is very well written. All required information is provided in a clear manner and explained properly."
            },
            "weaknesses": {
                "value": "1. As mentioned above, the anomaly detection results in this paper are promising. However, the gain on the NSL-KDD dataset is not always positive. This limits the application of the proposed method.\n2. The authors performed thorough experiments on the NSL-KDD dataset. However, further datasets should also be included in the experimentation to show the efficacy of the proposed method."
            },
            "questions": {
                "value": "1. This is related to concern regarding weakness 1. What are the authors intuition regarding the equality separator not always outperforming the other baseline methods for NSL-KDD.\n2. I noticed that in Table 3, for DOS, HS-NS result is in bold. Why is that? I though ES-NS performs the best here?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698798567706,
        "cdate": 1698798567706,
        "tmdate": 1699637012290,
        "mdate": 1699637012290,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tvPqmXS2dK",
        "forum": "eFVQaqkf8Z",
        "replyto": "eFVQaqkf8Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_FBaF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8167/Reviewer_FBaF"
        ],
        "content": {
            "summary": {
                "value": "This work discusses a novel approach to linearly classify the XOR problem, challenging the conventional wisdom that it cannot be done with linear methods. The authors propose \"equality separation\" as an alternative to traditional halfspace separation, adapting the SVM objective to distinguish data within or outside the margin. They integrate this classifier into neural network pipelines, highlighting its potential for anomaly detection and demonstrating its effectiveness in supervised anomaly detection experiments, including detecting both seen and unseen anomalies."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The introduction of an 'equality separator' to address the XOR problem is indeed an intriguing and innovative concept.\n- The introductory section is well-structured and easily comprehensible, complemented by the informative Figure 1.\n- All the theoretical assertions are substantiated with precise definitions and rigorous proofs."
            },
            "weaknesses": {
                "value": "- In order to enhance the accessibility and comprehensibility of the content, it would be advisable to incorporate critical discussions and analyses that are currently relegated to the appendix into the main body of the manuscript.\n- The proposed design has exclusively undergone experimentation on toy datasets or relatively straightforward real-world datasets. Consequently, there is uncertainty surrounding the effectiveness of the proposed method when confronted with more intricate, real-world datasets."
            },
            "questions": {
                "value": "- Is this network design extensible to more intricate datasets, such as image data?\n- Isn't there a gradient vanishing problem with that bump activation design when the layers of the neural network are deep?\n- What are the advantages of doubling the VC dimension in contemporary neural network architecture?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8167/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698865630391,
        "cdate": 1698865630391,
        "tmdate": 1699637012176,
        "mdate": 1699637012176,
        "license": "CC BY 4.0",
        "version": 2
    }
]