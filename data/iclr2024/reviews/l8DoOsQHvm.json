[
    {
        "id": "P3rEa1TB70",
        "forum": "l8DoOsQHvm",
        "replyto": "l8DoOsQHvm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_BuUw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_BuUw"
        ],
        "content": {
            "summary": {
                "value": "This manuscript addresses the problem of scene flow estimation from point clouds. A weight-sharing\naggregation (WSA) module and a deformation degree (DD) module are proposed to implement implicit rigidity constraints. The resulting algorithm has been evaluated on FlyingThings3D and the KITTI dataset without occlusion."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The manuscript is overall well written and easy to follow.\n2. The proposed method shows good performance on FlyingThings3D and the KITTI dataset\nwithout occlusion.\n3. The proposed WSA and DD modules are implemented on both PointPWC-Net and\nBi-PointFlowNet and show a performance improvement."
            },
            "weaknesses": {
                "value": "1. Important related works are missing. This work is not the first to implement rigidity\nconstraints to scene flow estimation. See references below.\n2. What happens if the objects are deformable, e.g. pedestrians. Does the method perform worse?\nIt would be good if there was a visual comparison / analysis for such circumstances.\n3. How is Eq(7) inferred? Obviously, Eq(7) holds true if f_e() is a linear\nfunction. However, there are usually non-linearities in deep neural networks and Eq(7) needs to be shown.\n4. After the upsampling layer, the coordinates and the features are updated. How is the\nconcatenation with the downsampled features done given the new coordinates?\n5. The evaluation is done on Flyingthings3D and KITTI following the preprocessing in\nHPLFlowNet. However, in this setting the occlusion points are removed, which is usually\nnot the case in the real world. How does the proposed method work following the\npreprocessing in FlowNet3D with occlusions? And how does it work on a larger scale\nautonomous driving dataset such as Waym-Open (https://waymo.com/open/data/motion/)?\n6. The deformation degree module seems to show a marginal improvement.\n\nReferences:\n\nTeed Z, Deng J. Raft-3d: Scene flow using rigid-motion embeddings[C]//CVPR2021.\n\nDong G, Zhang Y, Li H, et al. Exploiting rigidity constraints for lidar scene flow estimation\n[C]//CVPR 2022.\n\nLi R, Zhang C, Lin G, et al. Rigidflow: Self-supervised scene flow learning on point clouds\nby local rigidity prior[C]//CVPR2022."
            },
            "questions": {
                "value": "1. What is the novelty / difference in relation to the references given above?\n\n2.-5. Please refer to weaknesses 2.-5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5613/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698655777959,
        "cdate": 1698655777959,
        "tmdate": 1699636579627,
        "mdate": 1699636579627,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eClbt5CBcA",
        "forum": "l8DoOsQHvm",
        "replyto": "l8DoOsQHvm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_YnNz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_YnNz"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a weight-sharing aggregation based scene flow estimation network. A weight-sharing aggregation module is proposed to utilize the aggregated weights of point coordinates to aggregate the scene flow and point features for scene flow and feature upsampling. It aims to implicitly encode the rigidity constraints into the upsampling stage. Then a deformation degree module is proposed to preserve the local geometric structures between the source point clouds and the warped target point clouds. Extensive experiments on synthetic FlyingThings3D and real KITTI datasets demonstrate its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1)\tDifferent from that the methods that can explicitly encode the rigidity constraints based on the segmented objects and rigid pose estimation, the proposed method can implicitly encode the rigidity constraints into the upsampling stage with sharing weights. \n(2)\tThe experiments show the  superiority of the proposed method."
            },
            "weaknesses": {
                "value": "(1)\tThis paper claims that scene flow and point coordinates can be aggregated with the sharing weights. But I am confused about the operation on aggregating features with the same weights. I suggest that authors could conduct the experiments on upsampling the point features with different aggregated weights. Will the performance decrease a lot with different parameters?\n(2)\tThe authors should verify that the generated scene flow via weight-sharing aggregation really conforms to the rigid constraints.\n(3)\tSome important details are missing and the descriptions are unclear. For example, this apper lacks a description of how to obtain the aggregated weights. And what does \u201cMN\u201d mean? Does it correspond to the feature pyramid in Section 3.4?\n(4)\tThe ablation study on \u201cDD\u201d module shows that it brings the network a very weak improvement.\n(5)\tThe experimental section lacks the complexity analysis of the proposed method. Please list the inference time and FLOPs of compared methods."
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5613/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735026925,
        "cdate": 1698735026925,
        "tmdate": 1699636579505,
        "mdate": 1699636579505,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m82HU3nyGw",
        "forum": "l8DoOsQHvm",
        "replyto": "l8DoOsQHvm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_gEsZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5613/Reviewer_gEsZ"
        ],
        "content": {
            "summary": {
                "value": "The paper studies scene flow estimation from point clouds, with emphasizing implicit rigidity constraints. Following the design of PointPWC-Net, the core of this approach lies in two primary components: a weight-sharing aggregation method and a deformation degree module. While the former leverages identical weights for the fusion of point coordinates, scene flow, and features to implicitly establish rigidity constraints, the latter emphasizes the preservation of local structures of rigid objects during the scene flow estimation process. \n\nThis paper showcases the efficacy of the resultant network, WSAFlowNet, by benchmarking its performance against the popular FlyingThings3D and KITTI datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Overall, the writing of the manuscript is mostly clear and easy to follow. The authors provided various mathematical and experimental evidence to support the feasibility and effectiveness of their approach.\n- In feature abstraction, the proposed weight-sharing aggregation module enforces rigidity constraints by using identical weights for aggregating point coordinates, scene flow, and features, without requiring explicit pose estimation or 3D object segmentation.\n- The proposed deformation degree module reasonably enhances the local structure consistency by measuring the deformation degree of local structure between reference and warped points, with a KNN.\n- Both proposed modules are properly ablated, which provides convincing signals with analysis."
            },
            "weaknesses": {
                "value": "- Based on the ablations in Table 2, the gain from the deformation degree module looks minor. Indeed the two proposed modules work well in tandem, but more analysis and experimental evidence are needed to verify the necessity of the DD module for maintaining local rigid structure invariance.\n- Relevant comparisons on the computation cost of different approaches could be useful for evaluating the practicality of the proposed model for the scene flow estimation task.\n- No potential limitations or drawbacks of the proposed method are discussed. Also, failure cases need to be showcased and analyzed if any. Here the paper seems to focus too much on the advantages of the presented method and does not always give the whole picture.\n- I'm not super familiar with recent SOTA methods on scene flow estimation from point clouds, so might be biased on this one: the generalization capability of the proposed model was demonstrated by evaluating on KITTI without finetuning, but it would be more convincing to demonstrate comparisons on more recent real-world point cloud data from autonomous driving datasets, such as nuScenes, Argoverse, and Waymo open dataset."
            },
            "questions": {
                "value": "Please check the suggestions in the Weakness section above to further strengthen the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5613/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698838606716,
        "cdate": 1698838606716,
        "tmdate": 1699636579376,
        "mdate": 1699636579376,
        "license": "CC BY 4.0",
        "version": 2
    }
]