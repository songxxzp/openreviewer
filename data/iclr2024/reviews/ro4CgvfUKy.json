[
    {
        "id": "xl8tfAlcki",
        "forum": "ro4CgvfUKy",
        "replyto": "ro4CgvfUKy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_cWdJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_cWdJ"
        ],
        "content": {
            "summary": {
                "value": "In this manuscript the authors present a method to segment images by adding noise to the latent of a (variational) autoencoder and clustering based on the differences between reconstructions in pixel space. In a couple of controlled experiments on grouping stimuli, this method shows the groupings that are shown by humans."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "It is an interesting observation that autoencoder objectives alone lead to a representation that separates objects in a similar way as grouping experiments in humans suggest. Also, I think it is an interesting hypothesis that noise at higher levels is translated into correlated noise at lower levels that supports segmentations into objects. The authors present their novel set of gestalt tests that test for the expected grouping results explicitly while being properly image computable."
            },
            "weaknesses": {
                "value": "I am not convinced by this paper for three reasons:\n\nFirst, the main evaluation is done on a self made grouping stimulus set, which trains the network quite explicitly to produce the grouping made by human observers as the intended objects are exactly the groups that vary separately in the stimulus generation, by switching color together for example. While this is clearly not direct supervision, it does create a statistical structure that strongly favours the representation of object centred dimensions while there are no variations within objects or over the whole scene. This makes it a lot less surprising that auto encoders find dimensions that create correlations within objects.\n\nSecond, the authors emphasise noise strongly in their arguments and go to some length to explain how iid noise might emphasise the local PCs around the stimulus. While I do not think these arguments are technically incorrect, I think they are besides the point. The main step to make this technique work seems to be the shape of the derivative of the decoder around the stimulus. The decoder seems to create correlated changes in the parts that belong to the same object, which yields high similarity for those pixels. It is interesting that this effect is strong enough that few samples are sufficient to separate objects successfully, but in principle any way of estimating this derivative should work. As the noise size here corresponds to the typical delta used to compute the approximate derivative, it is also not surprising that small noise works well. The interesting part is that the derivative creates correlated changes for each object, not that this can be estimated based on noise samples.\n\nThird, I think the connection to human or biological vision is weaker than suggested by the authors. In biological vision we need a segmentation of the internal layer representations, not of the pixels in the image. This requires that the encoder and decoder are in some way related that allows us to connect our noise reconstructions and the encoding elements. Additionally, we would need a biologically plausible clustering algorithm that is based on the found similarities in the noise. Both are not present in the model presented here. Thus, substantial revisions would be necessary to transform the method proposed here into a biologically plausible method for object segmentation."
            },
            "questions": {
                "value": "Perhaps my questions highlight that this manuscript seems not ideally placed at a machine learning conference:\n- I would like to understand how the authors imagine the noise based segmentation to work in biological vision: How does the autoencoder model map to the brain? And what evidence is there that anything like this might actually happen in the brain?\n- Does this work in any way for natural scenes? Testing this on existing autoencoders for natural scenes could avoid my concerns about the training data being very targeted to create the patterns observed in humans.\n- And what about comparisons to alternative methods? Do other methods for segmentation or grouping get the gestalt tests wrong?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Reviewer_cWdJ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791209316,
        "cdate": 1698791209316,
        "tmdate": 1700688972745,
        "mdate": 1700688972745,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tQFPrczjvM",
        "forum": "ro4CgvfUKy",
        "replyto": "ro4CgvfUKy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_9tYc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_9tYc"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new unsupervised object discovery technique based on variational autoencoders with noise injected to the latent representation. The authors propose an unsupervised object segmentation algorithm that works by computing the difference between reconstructions of an input image from noisy latent representations followed by pixel-wise clustering. The proposed approach is tested on unsupervised perceptual grouping performance on the Good Gestalt (GG) dataset that the authors propose in this submission as well. Quantitative evaluation performed on the GG dataset shows promising evidence of Latent Noise Segmentation discovering objects while being trained on unsupervised image reconstruction. Further analyses on the sensitivity of LNS to latent noise parameters helps better understand the working of VAEs equipped with latent noise segmentation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Very intriguing to see emergent perceptual grouping from ANNs trained on unsupervised image reconstruction objectives. Super interesting perspective that latent neuronal noise could lead to learning good gestalt priors.\n+ The approach is very straightforward and easy to understand. I think this simplicity is a big strength of the proposed work.\n+ Good Gestalt datasets are also a nice addition to the contributions from this work, I hope this benchmark can serve as a good way to measure perceptual grouping abilities of models in the community. \n+ I like the additional analyses performed on understanding how latent noise parameters affects emergent grouping."
            },
            "weaknesses": {
                "value": "- The focus of the paper feels a bit narrow in terms of the architecture / learning objective. Is there something special about VAEs trained with ELBO + LNS that makes them develop emergent grouping, or does LNS generalize across architectural choices and learning rules (say, diffusion-based or adversarial generative models)? Adding a discussion on this would add more value to the submission\n- I feel that GG's difficulty could be significantly improved by adding more distractors and/or noise to the background of images. Although the current emergence of grouping looks interesting, I would be even more surprised if the model is learning to discount background noise in its presence, i.e., currently the dataset makes figure-ground organization too simple by providing a largely low-frequency background and I believe GG can be solved merely by using simple rules on low-level feature detectors. \n- The authors have covered a variety of unsupervised object discovery approaches such as Slot Attention, Complex-valued autoencoders in related work but have not performed a direct comparison to these baselines in their reported experiments. This makes the paper weaker due to the absence of relevant baselines other than the VAE-based ones currently reported in this version of the paper.\n\nOverall, the strengths of this work marginally outweigh the weaknesses mentioned above, I would be inclined to further improving my score provided the authors convincingly rebut my concerns about this work."
            },
            "questions": {
                "value": "- Can the authors please comment on whether they experimented with harder versions of GG? Here are a few potential options: (1) Change the size of the square/circle between train and test splits for Kanisza Squares, Closure, Continuity, (2) Use different rotations (without overlap between train and test splits) of the Kanisza squares / Closure squares, (3) Use different colors / textures as backgrounds in all tasks. Any modification of the dataset in the spirit of the modifications suggested here will further strengthen the message that simple low-level statistics don't drive the emergence of perceptual grouping.\n- Adding stronger baselines such as the ones the authors have mentioned in related work will help improve my score further."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797529099,
        "cdate": 1698797529099,
        "tmdate": 1699636862871,
        "mdate": 1699636862871,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "j71w36y9gv",
        "forum": "ro4CgvfUKy",
        "replyto": "ro4CgvfUKy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_ipWu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_ipWu"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates noise in feature space as a means of segmenting images. Several datasets of simple artificial images are developed for this work, each of which is designed to test whether the method exhibits a different Gestalt property. Autoencoders are used to produce latent representations. Small independent noise is repeatedly added to the latent representations. Differences are calculated between pairs of noisy outputs to produce pixel-wise vectors of differences. These vectors are clustered to produce a segmentation. This often results in Gestalt-like segmentations, e.g. segmentation of Kanizsa squares from background."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The dataset is a nice contribution, particularly the test set with expected segmentations for images that are expected to elicit various Gestalt phenomena. \n\nThe segmentation method is novel (as far as I know) and creative."
            },
            "weaknesses": {
                "value": "The abstract claims that the results show, \u201cpotential benefit of neural noise in the visual system\u201d and the paper repeatedly claims to study the ecologically plausibility of the method. Noise is certainly prevalent in biological vision, but I'm not convinced that there is a substantial connection between this method and biology. Issues include: 1) reliance of the method on small-amplitude noise, whereas spiking noise is closer to Poisson; 2) use of agglomerative clustering; 3) lack of comparison with neural data; 4) need for specialized training datasets to produce Gestalt phenomena; 5) poor performance on natural images. \n\nIf the goal is to explain something about biological visual systems, I think much clearer links to biology are needed. It seems to me that this would require substantial changes to the model and/or much more detailed justification of multiple model elements. \n\nTo elaborate on point 4 above, the method seems to rely on the design of the training datasets to work properly. For example, to segment Kanizsa squares, an autoencoder is first trained on stimuli that show the squares in a different color than the background color. This kind of dependence is claimed explicitly in the appendix: \u201cIf p1 and p2 are pixels belonging to the same object, the way the dataset is generated \u2026 dictates that the training samples projected onto the pixel value space will only stretch in a direction where there exists a strict linear ratio between the values of the two objects.\u201d Humans don't require such specialized training to experience Gestalt perception.  \n\nTo elaborate on point 5 above, the method is not meant to be practical, but its low practicality is also a concern for biological plausibility. It is not extensively tested on natural or otherwise practical images but in addition to the Gestalt dataset images, it was tested on celebrity faces and the paper claims that the method \u201coften finds a semantically meaningful segmentation of face-hair-background\u201d. However, examination of the results (Appendix A.3) shows that the results are generally poor. According to Table 1, even in these artificial circumstances, the model only outperforms the control in 4/6 cases. The control is the same model with noise applied to the output rather than to the latent representation. It could be interesting to also contrast with established strong segmentation methods, particularly if this method agreed with humans in conditions where others don\u2019t. However, some promise of strong performance would be needed in an convincing model of human vision."
            },
            "questions": {
                "value": "What size are the GG datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812211614,
        "cdate": 1698812211614,
        "tmdate": 1699636862762,
        "mdate": 1699636862762,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "z3hOttR9Hs",
        "forum": "ro4CgvfUKy",
        "replyto": "ro4CgvfUKy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_zkrR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_zkrR"
        ],
        "content": {
            "summary": {
                "value": "The authors demonstrate that segmentation and grouping features emerge unsupervisedly by injecting iid noise in the latent space of VAE and AE. They show this by designing a simple algorithm that compute relative differences of reconstructed images from latent code corrupted by noise on top of which they stack et simple clustering algorithm. In addition, the author have built a large dataset consisting of different grouping/segmentation tasks corresponding to various Gestalt aspects of perception such as closure, continuity, proximity, etc."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- well-grounded in the vision science field, enough references\n- the idea is well motivated by the search of a role for neural noise and tested in artificial neural network\n- the performances of the proposed method are extensively tested on a relevant dataset that is build for this purpose (that one counts twice)\n- comparison of VAE and AE is provided together with a control of the idea of adding noise in the latent space\n- amount of added noise and step required in the algorithm are also evaluated"
            },
            "weaknesses": {
                "value": "**Minor weaknesses** \n- The role of the post-processing step is not evaluated : does agglomerative clustering play a big role ? There are other standard clustering methods that could be tested.\n- Even if it's not designed for the segmentation of natural images and if it's likely to not perform very well compared to SOTA algorithms it is worth testing it. I have in mind a recent paper (Vacher et al 2022) in which deep neural network features are evaluated for segmenting natural images.\n- Latent space of VAE are known to enable appealing morphing between natural images (by linearly interpolating the latent code) so I am wondering what would be the segmentation related uncertainty that could be obtained with this method ... I guess this would require a more involved post-processing step.\n- Other neural network architectures are not tested (GANs, Normalizing flows, ...) \n\n**Minor remark**\n- In table 1, bold should be used for every best performing model, eg also for Continuity and Gradient Occ.\n\n\nRefs : \n- Vacher, J., Launay, C., & Coen-Cagli, R. (2022). Flexibly regularized mixture models and application to image segmentation. Neural Networks, 149, 107-123.\n\n\n**Post-response update**\nI thank the authors for their response and considering it together with the other reviews, I am increasing my score so that it is now a clear accept."
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Reviewer_zkrR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699019521086,
        "cdate": 1699019521086,
        "tmdate": 1700504238831,
        "mdate": 1700504238831,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pTcpg2JIlQ",
        "forum": "ro4CgvfUKy",
        "replyto": "ro4CgvfUKy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_DELR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7243/Reviewer_DELR"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the role of neural noise in the formation of perceptual groups. They show how one can obtain segmentation maps from a (V)AE simply through the injection of noise in the latent space, without any supervision on a segmentation task. Concretely, N noisy versions of a latent vector are passed through the decoder to result in N slightly different outputs. The difference maps between two consecutive outputs are then turned into one segmentation map using a clustering algorithm. The paper posits that the reason this process reveals perceptual groups in a scene is because pixels belonging to the same group tend to co-vary. Indeed, an experiment using a novel dataset, Good Gestalt, reveals cognitively viable segmentation maps that seem to obey the Gestalt laws. The appendix also includes an experiment on natural images (CelebA). In the paper's conclusion, neural noise is put forward as a potential mechanism for perceptual grouping."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Asking how perceptual grouping may occur without explicit supervision is important considering how many modern models rely on such supervision, whereas our own visual system arguably handles it differently. Moreover, I think the papers takes an interesting and fresh take on it by studying how noise might in fact be beneficial to visually separate objects. \n\nThe extent of the analyses (mathematical accounts, extra results on CelebA, noise sensitivity analysis) etc. is impressive. More than once I wrote down something I intended to inquire about, only to see that exact question already addressed a bit further down the paper.\n\nIt's a well-prepared manuscript, written with care."
            },
            "weaknesses": {
                "value": "The potential weaknesses I have spotted could very well rather be unclarities, so I'll save it for the \"Questions\" section."
            },
            "questions": {
                "value": "1)\nI'm unclear on the extent to which Latent Noise Segmentation is a method to reveal the perceptual groups already formed inside the network through some mechanism or another, versus a mechanism that gives rise to perceptual groups in its own right. Is the hypothesis that LNS is a way of \"doing\" segmentation or is it a way to \"show\" the result of segmentation, if that makes sense?\n\n2)\nThe training samples in the GG dataset often combine two Gestalt cues. For example, in Proximity, the parts closest to each other are also similar in color. Was that crucial to the results? Would the segmentations maps no longer obey the law of Proximity if there was no color cue during training?\n\nIn Section 2, does pretraining refer to training on GG before doing the noise injection, or was there any pretraining on natural images? If so, it would be interesting to see segmentation maps for GG test images before training on GG train images. Would it group by continuity just by learning from natural statistics, for example?\n\nI think it might be worthwhile to show examples of VAE outputs without noise (i.e., the actual reconstructions, not the segmentation maps). If it groups the pixels of the Kanizsa squares together supposedly \"perceives\" the square, does it output its illusionary contours? \n\n3) \n\"Time steps\" is used to refer to the number of noisy samples needed for a segmentation map. Does it bear any relation with actual time in the human visual system? \n\n4) \nThe paper refers to ecological validity and biological plausibility, but I'd love to see a little more elaboration on how exactly a biological visual system would potentially carry out the operations suggested here (e.g., how can we picture the 'clustering' being done)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7243/Reviewer_DELR"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7243/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699137079106,
        "cdate": 1699137079106,
        "tmdate": 1699636862513,
        "mdate": 1699636862513,
        "license": "CC BY 4.0",
        "version": 2
    }
]