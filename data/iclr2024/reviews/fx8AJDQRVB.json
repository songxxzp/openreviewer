[
    {
        "id": "w7efArFU3X",
        "forum": "fx8AJDQRVB",
        "replyto": "fx8AJDQRVB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_uAFu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_uAFu"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel latent-diffusion-based framework for image super-resolution. Experiments achieve state-of-the-art of x4 and x8 super-resolution among the latest competing diffusion-based SR models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Quantitative and qualitative results all reveal the superiority of the proposed model compared to the latest diffusion-based models."
            },
            "weaknesses": {
                "value": "1.\tThe point of compensating for the information loss in the autoencoder is interesting, but the novelty is limited. The newly proposed components are weak in cohesion and continuity in solving the information loss problem of the AE space and information compression. \n2.\tThe purpose of SS-MoE seems not to be designed specifically for information loss, i.e., the motivation is not clearly written in the paper. Though the performance can be slightly upgraded with the component, the parameters are multiple times larger than the model without the component (according to Table 6 and Table 3, and the paper didn\u2019t show the parameter increase of each component). There may be other efficient designs with the increased parameters of SS-MoE.\n3.\tMissing comparisons with some new baselines: DiffIR [1], DIffBIR [2], ResShift [3]\n\n[1] Diffir: Efficient diffusion model for image restoration. \n[2] DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior. \n[3] Resshift: Efficient diffusion model for image super-resolution by residual shifting."
            },
            "questions": {
                "value": "Please explain in detail the motivation of SS-MoE. Others please refer to the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Reviewer_uAFu"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698322036455,
        "cdate": 1698322036455,
        "tmdate": 1699636637655,
        "mdate": 1699636637655,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rt0ohxHmYg",
        "forum": "fx8AJDQRVB",
        "replyto": "fx8AJDQRVB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_krWG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_krWG"
        ],
        "content": {
            "summary": {
                "value": "This paper summarizes two issues in using the diffusion model to address image super-resolution, namely distortion caused by the compression of latent space and the huge computational cost. This work proposes a frequency compensation module to enhance\nthe frequency components and use Sample-Space Mixture of Experts (SS-MoE) to improve the capacity of the SR model. The visual results provided in the paper appear to have clearer details compared to other methods, and it also demonstrates certain advantages in some quantitative metrics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper provides a comprehensive and clear analysis and summary of the current methods and issues in super-resolution."
            },
            "weaknesses": {
                "value": "1. The results in the paper do not stand out significantly when compared to other methods, and they are not the best in terms of the metrics, making it challenging to demonstrate the superiority of this method over other super-resolution methods.\n2. The reason for designing SS-MoE in this way is not explicitly explained. Initially, multiple MoEs were designed to separately handle different noise sources. However, during inference, an averaging step is performed to parameterize the weights, which conflicts with the original motivation.\n3. In the experimental ablation study of FCD, the results show variations in the metrics, with some being high and others low. This inconsistency in the results makes it difficult to determine whether the approach used in the paper is the best one.\n4. There are several typographical errors in this paper. I recommend conducting a more thorough proofreading."
            },
            "questions": {
                "value": "Refer to weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5968/Reviewer_krWG"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636588459,
        "cdate": 1698636588459,
        "tmdate": 1699636637560,
        "mdate": 1699636637560,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YpUFp8RJu2",
        "forum": "fx8AJDQRVB",
        "replyto": "fx8AJDQRVB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_MvoB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_MvoB"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed a new diffusion-based SR approach, the authors propose a sample-space mixture of experts strategy to improve the sampling quality and propose a frequency compensation module to reduce high-frequency reonstruction distortion."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The author introduce sampling-space MOE to improve the image quality of diffusion-based SR, and provide detailed ablation experiments to validate the effectiveness of the adopted strategy.\n2) The authors propose a frequency loss to emphasize high-frequency distortion.\n3) The authors validated the proposed method on several benchmark datasets."
            },
            "weaknesses": {
                "value": "1) The novelty of this paper is not significant. The major framework and the major modifications were proposed in other works and the authors just combine these method to establish a new method. Using the MOE strategy to enhance sampling quality and introduce high-frequency loss to enhance SR results are straight-forward operations and the authors just combine the two methods without any modification.\n2) To evaluate photo-realistic SR, it is highly suggested to conduct subjective evaluation to compare different methods.\n3) Based on Table 1, the advantage of the proposed method over the competing approaches are not significant.\n4) The authors utilized 5 or 6 metrics to evaluate different methods, but did not discuss the results carefully. The numbers in Table 5 can not clearly validate the effectiveness of the proposed FFL and AFF-Net."
            },
            "questions": {
                "value": "Please refer to the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671396783,
        "cdate": 1698671396783,
        "tmdate": 1699636637450,
        "mdate": 1699636637450,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tiyqLqCC4W",
        "forum": "fx8AJDQRVB",
        "replyto": "fx8AJDQRVB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_dphS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5968/Reviewer_dphS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Sampling-Space MoE to enlarge the diffusion model without necessitating a substantial increase in training and inference resources. To address the issue of information loss caused by the latent representation of the diffusion model, the author further presents a frequency-compensated decoder to refine the details of super-resolution images. Experimental results on both Blind and Non-Blind SR datasets demonstrate that the proposed method obtain good performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Appealing visual results are obtained with the proposed method.\n2. The paper is well-written and organized, making it easy to understand the proposed framework and its contributions."
            },
            "weaknesses": {
                "value": "1. Ablation studies lack qualitative results, and the results in Table 5 do not offer strong evidence for the effectiveness of the proposed FCD.\n2.The visual results are sometimes good but with severe hallucination, and quantitative results are not always good on LPIPS and NIQE (These two metrics are generally more convincing in real image restoration).\n3. Since the compared methods including GAN-based methods and Diffuison-based method, it is insufficient to evaluate these methods only based on restoration metrics. The author should also make a comparison on model complexity, inference speed, and GPU usage."
            },
            "questions": {
                "value": "see the Weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698681944030,
        "cdate": 1698681944030,
        "tmdate": 1699636637336,
        "mdate": 1699636637336,
        "license": "CC BY 4.0",
        "version": 2
    }
]