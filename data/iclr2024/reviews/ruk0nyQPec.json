[
    {
        "id": "oAgsJ2LjSC",
        "forum": "ruk0nyQPec",
        "replyto": "ruk0nyQPec",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_mHsD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_mHsD"
        ],
        "content": {
            "summary": {
                "value": "The methodology presented in the paper attempts to address current concerns regarding language technology, namely its reliance on copyrighted data. The authors propose a new corpus, the 228B-token Open Licence Corpus (OLC) comprising texts with various permissive licenses. Additionally, they show that since OLC is less broad in content than its alternatives that do not eschew copyrighted text, training a language model solely on this results in comparably low performance.\n\nIn order to benefit from using copyrighted texts, the authors propose to use their language model trained on OLC in conjunction with a datastore containing copyrighted text. They test two distinct retrieval methods, k-nearest neighbours (KNN) and retrieval-in-context (RIC) for returning tokens (in the case of KNN) or text blocks (in the case of RIC) from the datastore. They find that by using KNN-based retrieval they can achieve performance close to Pythia, a language model trained on non-permissive data across 14 domains on perplexity and 10 downstream tasks.\n\nSILO models such as the one proposed by the authors are conducive to both identifying the pieces of copyrighted texts contributing to a given decision, as well as removing such texts, complying with concepts like fair use and GDPR."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Overall: The paper is fairly clearly written, it addresses a very important and current problem in the application of language technology, and carries out extensive analyses. It also compares performance of the proposed method across a large number of domains and tasks.\n\nSoundness: There are still some costs associated with inference time and performance when using SILO models as opposed to using \u201cclassical\u201d models trained on a range of permissive and non-permissive texts. However, the methodology proposed by the authors seems like a viable method of mitigating the very current problem of the use of copyrighted or otherwise protected corpora in language technology.\n\nContribution: The authors create OLC, a diverse pretraining corpus made up of permissive texts. Additionally, they train a language model on this corpus. They also present a large number of analyses untangling the impact of various factors relating to domain overlap and retrieval methods, among all."
            },
            "weaknesses": {
                "value": "Overall: Some of the tables are difficult to read, as mentioned, adding some highlights to help compare the performance would have been helpful. Additionally, in the case of Table 3, the percentages included are confusing. Are the minuses referring to the advantage (or lack thereof) when compared with Pythia? If yes, why do we get -100% when the result is the same across SILO and Pythia?\n\nPresentation: The content is mostly presented clearly. However, it would have helped to have some examples at least in the appendix or a more descriptive figure illustrating KNN and RIC-based retrieval to make it somewhat easier to understand. Otherwise, some of the denser tables would have benefitted from adding highlights (underline or bold text) to important scores to lead the eye."
            },
            "questions": {
                "value": "I have no questions, but please make sure that you improve clarity when it comes to presenting your results. Also, I think being a bit more explicit in how retrieval works at inference time in practice could improve the paper and match its otherwise accessible tone."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747805925,
        "cdate": 1698747805925,
        "tmdate": 1699636396174,
        "mdate": 1699636396174,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Rb7DZBBhdR",
        "forum": "ruk0nyQPec",
        "replyto": "ruk0nyQPec",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_P6ek"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_P6ek"
        ],
        "content": {
            "summary": {
                "value": "This paper verifies the feasibility of decomposing data into high-risk and low-risk categories to ensure the legality of LLMs. Low-risk data is employed during the pretraining phase, whereas high-risk data can be integrated during inference by utilizing in-context retrieval augmentation or kNN-LM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* This paper introduces a paradigm aimed at ensuring the legality of data used in LLMs, with the potential to significantly impact related research areas such as LLM privacy and security.\n* It conducts a comparative analysis of two approaches for incorporating high-risk data into LLMs during the inference process, offering valuable insights into their effectiveness.\n* The paper also introduces a dataset that can support further research in this line of investigation."
            },
            "weaknesses": {
                "value": "* This paper primarily focuses on evaluating the zero-shot performance of SILO. Given that pretrained LLMs usually serve as base models for instruction-tuning or task fine-tuning, understanding the extent of SILO's influence on these processes is of significant importance. However, this is not explored in this paper.\n* In the evaluation of SILO, this paper primarily relies on PPL as a metric, although it does carry out experiments on text classification tasks. A more comprehensive assessment across various settings, a broader range of tasks, and in terms of multiple aspects (such as helpfulness and harmfulness) could offer a deeper and more insightful understanding of SILO's performance."
            },
            "questions": {
                "value": "In the paper, the authors claim that \"Pythia ... is trained with a similar amount of compute (data size and model parameters).\" What are the exact computational costs when training SILO and Pythia?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698813097872,
        "cdate": 1698813097872,
        "tmdate": 1699636396088,
        "mdate": 1699636396088,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4p3O05jZ4q",
        "forum": "ruk0nyQPec",
        "replyto": "ruk0nyQPec",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_X9LU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_X9LU"
        ],
        "content": {
            "summary": {
                "value": "This research delves into the potential of developing technologies tailored to manage legal risks associated with the controversial issue of training Language Models (LMs) on copyrighted data. The authors introduce SILO, developed by:\n\n1. Training a parametric LM on low-risk texts (e.g., copyright-expired books).\n2. Enhancing the LM with high-risk texts (e.g., copyrighted books) stored in a nonparametric datastore, accessed only during inference.\n\nAt its core, SILO leverages the kNN-LM retrieval method (k-nearest neighbors LM by Khandelwal et al., 2020)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The motivation behind this study is commendable, as it addresses the pressing concern over the legality of training materials for LMs.\n* SILO's methodology offers an effective solution to the identified problem, as demonstrated by both its theoretical framework and experimental outcomes. Its adaptability in integrating various corpora is a significant advantage.\n* Compared to alternative techniques, like post-hoc training data attribution or attempts to neutralize specific training samples' effects, this method provides robust assurances and scalability."
            },
            "weaknesses": {
                "value": "* Technological innovation is a slight drawback since the study primarily builds upon the kNN-LM framework by Khandelwal et al., 2020. However, this is somewhat mitigated by the strategic application of the technology to a pertinent issue, backed by thorough analysis and experimentation.\n\n* As per Table 16, the runtime speed remains a notable challenge for kNN-LM. Future work should explore innovative technological solutions to address this limitation."
            },
            "questions": {
                "value": "Please briefly respond to the two weaknesses I listed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698909073261,
        "cdate": 1698909073261,
        "tmdate": 1699636396018,
        "mdate": 1699636396018,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BcsZfliTtf",
        "forum": "ruk0nyQPec",
        "replyto": "ruk0nyQPec",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_cDVV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4283/Reviewer_cDVV"
        ],
        "content": {
            "summary": {
                "value": "The premise of this study is that some data that is legally challenging to be included during pretraining of a LLM. In this study the authors investigate whether such data can instead be used just as augmentation during inference while the LLM is only trained on uncritical data. The augmentation during inference is either achieved with the knn-LM approach or by simply adding BM25 retrieved text in the context. They investigate the effectiveness of this approach on a few zero-shot text classification benchmarks, and by measuring perplexity on text sources of various domains. They can show that a model only trained on legally safe data performs worse and adding the augmentation during inference can reduce the gap to a model that has seen such data during pretraining."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The premise hinges on the currently hotly debated issue of legal implications of using legally critical data for pretraining, and assumes that using such data in pretraining would be undesirable. They investigate the option to make it easy to remove critical data unambiguously from the inference of the model, which could enable using such data until it has to be removed.\n\nThe general quality and clarity of the paper is good, i.e. the presentation is well thought out and good to follow."
            },
            "weaknesses": {
                "value": "The general idea the paper presents is straight-forward, relevant and interesting, yet I am not convinced if it asks the right questions and measures the right things. \n\nWhen data is taken away during pretraining and is only added during inference, then the first question I have is on which tasks does this matter and has a larger impact and on which tasks does it not matter. The suite of text-classification benchmarks are too simplistic to give us any relevant insights into the effect this might have. \n\nThe perplexity analysis is not too insightful, as we won't know how that will influence any of the benchmarks that might be relevant to a particular use-case. An increase in perplexity is expected under domain-shift and also that adding the inference augmentation will reduce it, so its not clear what the take-away for the reader should be (its good to have that in the appendix, but we know that knn-LM and RIC do work).\n\nAs a strong paper, I would have liked to see the potential advantages to be contrasted more with the current challenges, i.e. the paper leaves the run-time and various adjustments to make the approach feasible in the appendix, and focuses the main paper on selling the approach as a potential solution, yet realistically its far away from that."
            },
            "questions": {
                "value": "- Even with using open licence data, isn't there is still a risk, that IP from others might be infringed?\n- It didn't become clear to me why the paper focuses on the different licences PD,SW and BY, as it doesn't have any significance in the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698980821715,
        "cdate": 1698980821715,
        "tmdate": 1699636395923,
        "mdate": 1699636395923,
        "license": "CC BY 4.0",
        "version": 2
    }
]