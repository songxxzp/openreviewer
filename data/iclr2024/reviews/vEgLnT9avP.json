[
    {
        "id": "yFCvRumejf",
        "forum": "vEgLnT9avP",
        "replyto": "vEgLnT9avP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_2iPY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_2iPY"
        ],
        "content": {
            "summary": {
                "value": "This paper first points out that the presence of strongly connected sub-graphs may severely restrict information flow in common GNN architectures. Then, it introduces the concept of multi-scale consistency, which can fit both the node-level and graph-level scenarios. In light of this, the authors introduce ResolvNet, a flexible graph neural network based on the mathematical concept of resolvents. Finally, it conducts some experiments to evaluate the proposed method, showing that the proposed method outperforms state-of-the-art baselines on several tasks across multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tIt provides some theorical support for the proposed model.\n2.\tIt tests on several widely-used datasets, and the proposed method can sometimes beat the existing methods.\n3.\tThe authors provide their codes."
            },
            "weaknesses": {
                "value": "1.\tSOTA baselines are largely ignored. On three famous datasets Cora, Citeseer and Pubmed, there are only two baselines are considered (in Table 1). Few baselines (like GCNII and GraphMAE2), which after 2022, are considered. As far as I know, GCNII (which is open source) can beat the proposed method on Cora and Pubmed. Moreover, even this, the proposed method cannot get the best performance in Table 3.\n2.\tThe work is some kind of hard to follow. Although providing lots of theories will enhance the paper, the readability is also should be considered.\n3.\tSome grammatical errors, like 1) satisfied by poular graph -> \u201cpopular\u201d; 2) severly restricts - > \u201cseverely\u201d. 3) degree occuring -> \u201coccurring\u201d"
            },
            "questions": {
                "value": "1.\tWhy the reported results cannot beat SOTA baselines (like GCNII) in Table 1?\n2.\tHow many hyper-parameters are there in your method? If the proposed method contains too many hyper-parameters, it will be hard to reproduce.\n3.\tSee the weakness in the \u201c*Weaknesses\u201d part.\n4.\tThe work can be largely improved by enhancing its experiments and fixing gram errors."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4788/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698645418713,
        "cdate": 1698645418713,
        "tmdate": 1699636461339,
        "mdate": 1699636461339,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1BOSUa2BTI",
        "forum": "vEgLnT9avP",
        "replyto": "vEgLnT9avP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_ZGZ9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_ZGZ9"
        ],
        "content": {
            "summary": {
                "value": "This paper study multi-scale consistency (distinct graphs describing the same object at different resolutions should be assigned similar feature vectors) of node representation in graph neural network, which is indeed an important topic that is less well explored. \n\nThe authors show existing GNN method lack of multi-scale consistency, then they propose ResolvNet to solve this issue. Experiment shows improvement on GNN performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper study multi-scale consistency (distinct graphs describing the same object at different resolutions should be assigned similar feature vectors) of node representation in graph neural network, which is indeed an important topic that is less well explored. \n\n2. This paper provide a very clear definition on multi-scale consistency in Definition 2.1, and explain in great details (using both figures, text, and examples) to help readers understand why it is important.\n\n3. The proposed method capture the intuition of multi-scale consistency."
            },
            "weaknesses": {
                "value": "1. Experiment dataset is small. This is potentially because the proposed method has very high complexity due to matrix inverse (see feed-forward rule in paragraph **The ResolvNet Layer**. The authors need to conduct experiment on larger datasets (e.g., OGBN) and report complexity in terms of FLOP/Wall-clock time.\n\n2. Part of the discription is not very clear, please refer to Questions."
            },
            "questions": {
                "value": "1. I understand the definition of $G_\\text{high}$ and $G_\\text{reg}$, but I am very clear how two split an original graph into this two graph. This is related to Definiton 2.1.\n\n2. Please elaborate on \"we would have a Lipschitz continuity relation that allows to bound the difference in generated feature vector in terms of a judiciously chosen distance\". This is the sentense above Eq. 1. I don't understand why."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4788/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698731827664,
        "cdate": 1698731827664,
        "tmdate": 1699636461241,
        "mdate": 1699636461241,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "W4ii2MLlCa",
        "forum": "vEgLnT9avP",
        "replyto": "vEgLnT9avP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_MwCo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_MwCo"
        ],
        "content": {
            "summary": {
                "value": "This paper points out a problem in graph neural networks where certain strongly connected parts, like cliques, can limit the spread of information in the graph. To solve this, the authors introduce the idea of multi-scale consistency. This means keeping a connected way of spreading information even if the connection density in the graph changes for the node level tasks. For the graph level tasks, it means graphs generated from the same ground truth, which are at different resolutions,  should be assigned similar feature vectors. The research shows that many popular GNN designs don't have this feature. To fix this, the authors of this work propose ResolvNet, a new Spectral-based GNN design based on a math concept called resolvents. By applying resolvent of the Laplacian, \tResolvNet is able to have the same effect of projecting the dense connected components in the original graph to a coarsened graph, then efficiently propagating information and finally projecting the embedding back to the original graph node level. Authors have theoretically proved that the proposed method is able to consistently integrate multiple connectivity scales occurring within graphs. Also , extensive experiments have shown that ResolvNet has multi-scale consistency and does better than other baselines in many tasks using various datasets. It is also shown that the proposed method is more stable than the baselines under different resolution scales."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "*Originality*: The paper identifies a novel issue in graph neural networks and introduces an effective framework, ResolvNet, to address it. This represents a significant and innovative contribution to the field.\n\n*Quality*: The investigative experiments and primary results presented in the paper are persuasive. Supported by solid theoretical proofs, this work stands out as a high-quality piece of research.\n\n*Clarity*: The paper is exceptionally well-organized. Its straightforward and lucid presentation of both the problem and the proposed solution allows readers to grasp the content quickly and comprehensively.\n\n*Significance*: By highlighting a new issue and offering an effective framework to tackle it, this work holds substantial impact potential for the broader community."
            },
            "weaknesses": {
                "value": "*Insufficient Analysis*: The paper could benefit from more extensive ablation studies and parameter analyses. Understanding how variations in parameters like $\\omega$ and $k$, as defined in the ResolvNet Layer, impact the final results would provide deeper insights.\n\n*Complexity of Concepts*: The concept of \"resolvents\" is not a commonly understood mathematical idea. Providing more explanations, along with practical application cases, would greatly aid readers in grasping this concept and its significance in the proposed framework.\t\n\nMinor issue:\n\n*Notation Introduction*: The paper occasionally lacks a comprehensive introduction to certain notations. For instance, the notation $T$ in section 3.2 is introduced without adequate context or explanation."
            },
            "questions": {
                "value": "The datasets utilized in this study are primarily small to medium-sized. How would ResolvNet perform in terms of accuracy and computational time when applied to larger datasets?\n\nHow do learnable filters as polynomials in resolvents achieve similar effects of up-projection operator and down-projection operator. It may need more illustrations and explanations for this in Sec 3.2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4788/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698782961968,
        "cdate": 1698782961968,
        "tmdate": 1699636461162,
        "mdate": 1699636461162,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5d230zsJDQ",
        "forum": "vEgLnT9avP",
        "replyto": "vEgLnT9avP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_nd7U"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4788/Reviewer_nd7U"
        ],
        "content": {
            "summary": {
                "value": "The paper considers graphs with two scales, one in which nodes are strongly connected into clique-like communities and a another scale in which the connections are weaker and uniform over the graph. A distinction is based between the two communities based on spectral analysis: the second eigenvalue of the first scale is much higher than all the eigenvalues of the second scale. The idea of resolvents is proposed to deal with such graphs and two types of filters, type-0 and type-1 are defined to propagate information in a GNN. The ideas are validated empirically. It is shown that the proposed method works well on graphs with high homophily."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of separating a network into multiple scales is nice. The problem is well defined and motivated\n\nThe use of resolvents to design filters is novel. A theory is developed to justify the methods.\n\nThe experimental results show the usefulness of the method."
            },
            "weaknesses": {
                "value": "1. It would be good if the authors could demonstrate the performance of their methods on synthetically generated graphs, say using stochastic block models. That would allow all parameters to be controlled.\n\n2. It is not clearly defined how the two kinds of filters are combined: does a node learn which filter to use?\n\n3. There are some other obvious baselines with which the authors could compare their methods: \na. Apply pooling to learn the clusters (say using diffpool, gpool, eigenpooling among others) and then use a generic GNN on the coarsened graph.\nb. Separate the two networks using Gaussian Mixture Models, have two different GNNs for the two scales, and combine the two representations for node/graph prediction.\n\n4. The abstract is not clear, especially the sentence: At the graph level, multi-scale ..\" The last sentence also seems to make bolder claims than what the experiments show."
            },
            "questions": {
                "value": "Please look at the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4788/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698880625463,
        "cdate": 1698880625463,
        "tmdate": 1699636461094,
        "mdate": 1699636461094,
        "license": "CC BY 4.0",
        "version": 2
    }
]