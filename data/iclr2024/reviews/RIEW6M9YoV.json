[
    {
        "id": "zEGhSuvsp0",
        "forum": "RIEW6M9YoV",
        "replyto": "RIEW6M9YoV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_XLS2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_XLS2"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on generating graphs from a target distribution, which is a vital task in several areas like drug discovery and social network analysis. The paper introduces a new framework termed as \"Hierarchical Graph Generation with K^2\u2212Tree\" (HGGT). This model (1) uses a K^2\u2212Tree representation, which was originally designed for lossless graph compression, enabling a compact graph representation while also capturing the hierarchical structure of the graph. (2) Incorporates pruning, flattening, and tokenization processes in the K^2\u2212Tree representation. (3) Introduces a Transformer-based architecture, optimized for generating sequences by using a specialized tree positional encoding scheme."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper's emphasis on hierarchically capturing graph structures using K^2\u2212Tree is technically sound. Hierarchies are crucial for many real-world graphs, and K^2\u2212Tree, with its inherent structure, naturally offers this advantage.\n\n2. The introduction of pruning, flattening, and tokenization processes aims to achieve a compact representation. This can lead to both storage and computational efficiencies, which are pivotal when dealing with large-scale graph data."
            },
            "weaknesses": {
                "value": "1. I have doubts about the motivation, which is not strong enough to drive the development of such work. \n\n2. Related work missing, such as [1, 2]\n\n3. The paper doesn't detail the computational resources required, which raises concerns about its practicality for very large graphs.\n\n4. Tokenization can sometimes lead to loss of information, and without details, it's uncertain how this impacts the overall graph representation.\n\n[1] Kong, Lingkai, et al. \"Autoregressive Diffusion Model for Graph Generation.\" (2023).\n\n[2] Chen, Xiaohui, et al. \"Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling.\" (2023)"
            },
            "questions": {
                "value": "See weakness, I'd like to raise my score if concern is addressed"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Reviewer_XLS2"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698521555418,
        "cdate": 1698521555418,
        "tmdate": 1699636401958,
        "mdate": 1699636401958,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JldT93F1Sm",
        "forum": "RIEW6M9YoV",
        "replyto": "RIEW6M9YoV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_K9N3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_K9N3"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new graph generative model which capitalizes on the $K^2-$tree representation, a  representation of graphs that is more compact than the adjacency matrix. The $K^2-$tree representation is transformed into a sequence and then a Transformer-based architecture is employed which predicts one token at a time based on the previously generated sequence. The Transformer is also equipped with positional encodings that take into account the structure of the tree. The proposed model is trained on synthetic and real-world datasets. The results indicate that in most cases, the generated graphs better preserve graph properties than the baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed model shows strong empirical performance over previous baselines on both synthetic and real-world datasets. Thus, HGGT could be a useful addition to the list of graph generative models.\n\n- The $K^2-$tree representation seems interesting and the proposed model has some novelty. Even though there are previous works that have proposed autoregressive models for graph generation, in my view the main components of HGGT are different from those of previous works.\n\n- The model supports node and edge features, while the results reported in Figure 7 suggest that HGGT is much more efficient than competing models."
            },
            "weaknesses": {
                "value": "- The paper claims that the employed representation is hierarchical, however, I do not fully agree with this claim. In case a hierarchical community structure is present in the graph, a hierarchical representation is supposed to capture this community structure. However, the proposed $K^2-$tree representation would not necessarily capture this (since it depends on the node ordering). On the other hand, the hierarchical clustering algorithm would produce a proper hierarchical representation. I thus think that this claim needs rephrasing to avoid misunderstanding.\n\n- The proposed model is conceptually similar to GRAN [1] which sequentially generates blocks of nodes and associated edges. A detailed discussion of how HGGT differs from GRAN is missing from the paper.\n\n- One of my main concerns with this work is that it is not clearly explained in the paper why the proposed model significantly outperforms the baselines. This is not the first autoregressive model for graph generation, and previous models also came up with different schemes to reduce the time and space complexity (such as BFS ordering and generation of blocks of the adjacency matrix in [2] and [1], respectively). Thus, I would not expect such a significant difference in performance between HGGT and those previous models. I would like the authors to comment on this.\n\n- In Table 2, we can observe that the novelty of the generated molecules is low compared to those of the baselines (mainly on QM9). I would expect the authors to provide some explanation or intuitions about why the proposed model fails to produce novel graphs.\n\n- In section 5.2, it is mentioned that \"Each metric is measured between the 10,000 generated samples and the test set\". I do not think that this is actually true. If I am not wrong the validity and the uniqueness have nothing to do with the samples of the test set. Furthermore, the Frechet ChemNet Distance and the novelty are commonly computed by comparing the generated samples against those of the training set and not those of the test set.\n\n[1] Liao, R., Li, Y., Song, Y., Wang, S., Hamilton, W. L., Duvenaud, D., Urtasun, R., & Zemel, R. \"Efficient graph generation with graph recurrent attention networks\". In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 4255-4265, 2019.\\\n[2] You, J., Ying, R., Ren, X., Hamilton, W., & Leskovec, J. \"Graphrnn: Generating realistic graphs with deep auto-regressive models\". Proceedings of the 35th International Conference on Machine Learning, pp. 5708-5717, 2018."
            },
            "questions": {
                "value": "In p.5, why $K^2$ elements are not enough and $K(K + 1)/2$ more elements are added, thus increasing the vocabulary size for each token?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698620614730,
        "cdate": 1698620614730,
        "tmdate": 1699636401858,
        "mdate": 1699636401858,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u4TTrh9jWw",
        "forum": "RIEW6M9YoV",
        "replyto": "RIEW6M9YoV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_JeGt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_JeGt"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a new graph generative model Hierarchical Graph Generation with $K^2$\u2013Tree (HGGT). $K^2$-tree is a lossless graph representation and the authors compress it by pruning, flattening and tokenizing operations such that it fits to Transformer with $K^2$-tree positional encoding for graph generation. The effectiveness and efficiency of HGGT are evaluated on six datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The approach of combining $K^2$-tree compressed representation with Transformer is new.\n\n(2) The performance of HGGT is superior to the SOTA baselines on most datasets."
            },
            "weaknesses": {
                "value": "(1) The performance of HGGT (Table 2) is not so satisfactory for molecular graph generation which is probably the most important application of this graph generative model.\n\n(2) It lacks the worst case time complexity analysis for the algorithms."
            },
            "questions": {
                "value": "(1) Why is the performance of HGGT on molecular datasets not so good as that on the generic graph datasets? It seems that HGGT achieves the worst score on three metrics of the two molecular benchmarks (Uniqueness on QM9 and Novelty on both).\n\n(1) What are the time complexities of Algorithms 1-4 and HGGT?\n\n(2) Is the $K^2$-representation still lossless after pruning, flattening and tokenization? I guess yes, but is there a simple proof for this?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Reviewer_JeGt"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698686553536,
        "cdate": 1698686553536,
        "tmdate": 1699636401726,
        "mdate": 1699636401726,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CJ5QXoo1aR",
        "forum": "RIEW6M9YoV",
        "replyto": "RIEW6M9YoV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_Nzff"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4327/Reviewer_Nzff"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel algorithm to generate graphs based upon $K^2$-tree representation. One of the positive sides of $K^2$-tree representation lays in the fact that it ensures the compactness of the obtained representation without losing the hierarchical information from the nodes and edges in the original graph. After having described how $K^2$-tree representation works, the authors outline the generation algorithm built upon it. Specifically, the algorithm prunes redundant nodes from the representation (e.g., given its symmetrical nature); the, it flattens and tokenizes the pruned $K^2$-tree; finally, it exploits a Transformer architecture to generate the new graph through positional encoding. Results on various graph learning tasks and domains against other state-of-the-art graph generation solutions outline the efficacy of the proposed approach. The evaluation is complemented through an extensive ablation study which further validates the goodness of the algorithm."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The paper is well-written and easy-to-follow.\n+ The proposed algorithm is simple but effective.\n+ The proposed algorithm is also able to generate featured graphs (e.g., molecular structures which come with features on graph edges).\n+ The experimental analysis is extensive and supports the efficacy of the proposed solution.\n+ The code is released at review time."
            },
            "weaknesses": {
                "value": "- To the best of my knowledge, I cannot see any specific weakness."
            },
            "questions": {
                "value": "* Could it be possible to adopt the proposed graph generation algorithm to create graphs with specific topological properties (e.g., node degree or clustering coefficient)?\n\n**After the rebuttal.** The rebuttal answered all questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4327/Reviewer_Nzff",
                    "ICLR.cc/2024/Conference/Submission4327/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4327/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699258954343,
        "cdate": 1699258954343,
        "tmdate": 1700651532865,
        "mdate": 1700651532865,
        "license": "CC BY 4.0",
        "version": 2
    }
]