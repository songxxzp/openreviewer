[
    {
        "id": "qLMA3kvoB5",
        "forum": "9zpOUsOvLM",
        "replyto": "9zpOUsOvLM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission963/Reviewer_S9nw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission963/Reviewer_S9nw"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors develop a model called Topology-Invariant Pooling (TIP) to improve the pooling process in graph neural network. The model is motivated by their observation that filtration process in persistent homology aligns with the graph pooling process, thus if the reduced graphs share similar topological information with the original graph, the pool process will be efficient. They characterize the topology of the graphs by using persistent homology and design a corresponding topological loss term to guide the graph pooling. They have incorporated the TIP model into a collection of graph pooling methods. The results are very promising."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The key innovation of the paper is the design a topology-based pooling process. Different from previous pooling process when preserving the cluster/community structure is the main focus, the TIP model is to maintain the topological similarities in terms of persistent homology information, during the graph pooling process."
            },
            "weaknesses": {
                "value": "Even though the authors claim that \u201cThe core of PH is the computation of filtration\u201d, they have not provided a convincing argument of their choice of Forman-Ricci curvature as the filtration parameter. The notations in the paper is confusing and need to be improved."
            },
            "questions": {
                "value": "1)The authors use Forman-Ricci curvature as the filtration parameter and their reason is that it \u201cincorporates edge weights and graph clusters to better capture the topological features of the coarsened graphs\u201d. In fact, Forman-Ricci curvature is one type of discrete Ricci curvature models. The other discrete Ricci curvature model is Ollivier-Ricci curvature (thus it may be better to call it Forman-Ricci curvature instead of Forman curvature).  Essentially, all these discrete Ricci curvature models only characterize the \u201clocal\u201d geometric information of the graph or simplicial complex. It is not sure why the authors choose to use it as the filtration parameter.\n\n2)The authors state that \u201cThe core of PH is the computation of filtration, which presents a challenging task due to its complexity\u201d. What is the meaning of \u201ccomputation of filtration\u201d? Is it to design a proper filtration parameter, to construct a series of simplicial complexes from the filtration process, or to calculate the persistence of homological generator from the filtration process?\n\n3)Some notations in the paper are very confusing. For instance, Page 3, $V={(i, x_v)}_{v\\in 1:n}$, why the notation {i} is needed?; $X\\in R^{n*d}$, I guess $d$ is the dimension of the node vector? \n\n4)Page 4, for the \u201csequence of nested subgraphs\u201d, the subindex is from 0 to n, this implies that nodes are added into the filtration process one by one, which is clearly not the case. To avoid the confusion, it is better to use a different way of notations.\n\n5)Page 5, in equation (5), the operation of min and max is in terms of what? If it is for the elements of the matrix, the min(A^l) will result in a number (scale). \n\n6)Page 5, in equation (6), note that \u201cD_1\u201d is defined to be \u201cph()\u201d, but in page 4, \u201cph()\u201d is defined to be collections of  \u201cD_0\u201d, \u201cD_1\u201d, etc. Further, $A^l$ is defined as the Hadamard product of $A^l$ and $D_1[1]- D_1[0]$. Here $A^l$ is a matrix and  $D_1[1]- D_1[0]$ is a vector. They may have very different dimensions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698463278585,
        "cdate": 1698463278585,
        "tmdate": 1699636022318,
        "mdate": 1699636022318,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RBFNBSZNpu",
        "forum": "9zpOUsOvLM",
        "replyto": "9zpOUsOvLM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission963/Reviewer_r2G4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission963/Reviewer_r2G4"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses an important problem, graph pooling, which is a key component of GNNs for graph classification tasks. The authors aim to integrate topological structural information from graphs into the pooling process. They introduce the Topology-Invariant Pooling model, demonstrating significant improvements compared to conventional pooling methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea keeping the topology information during pooling process is novel, and it can address one of the issues in GNNs in graph classification tasks.\n2. The results in benchmark datasets are very good."
            },
            "weaknesses": {
                "value": "1. While the concept is quite promising, the implementation falls short in terms of its strength. The authors have attempted to utilize persistent homology to maintain consistent topological information during the pooling process; however, the approach they propose doesn't align with their intended outcome. To achieve their objective, the integration of persistent homology should be fundamentally different.\n\n2. The theorem is a bit irrelevant here as the existence of a filtration function in this context does not mean much for practical purposes.\n\n3. For classification results, it would provide more valuable insights into the performance of the proposed model if the authors compared it with State-of-the-Art (SOTA) GNN results rather than basic models. This approach would offer a more meaningful assessment of the model's capabilities.\n\n===============\n\nMore specific concerns:\n\n4. Use of PH is a bit problematic here. You are using sublevel filtration with a node function as far as I see. Since you are using single filtration, edge weights have no importance here. Therefore, the concepts of resampling and persistence injection, which involve varying the edge weights, may not align well with the method's underlying principles.\n\n5. When employing sublevel filtration with a filtering function 'f,' it's crucial to recognize that the resulting persistence diagram does not reflect the topology of the graph itself. Instead, it depicts the evolution of topological features within the subgraphs (complexes) defined by the filtering function. As a result, the persistence diagram consists of tuples of values from your filtering function.\nIn the context of graph coarsening, the primary objective is to reduce the graph's size while preserving its coarse topological structure. The sublevel filtration applied to the original graph is irrelevant to this goal and holds no significance in this specific context.\n\n6. Including dataset statistics would enhance the exposition."
            },
            "questions": {
                "value": "This is more of a remark than a question. The notion of introducing topological information into the pooling process is intriguing, but it does present a certain contradiction. The original graph may possess numerous topological features, yet the objective of graph pooling is to transition to a smaller, more compact graph. As a result, expecting the coarsened graph to retain similar topological information from the original one is not very meaningful, especially when using PH with sublevel filtration.\n\nOne potential solution in pursuit of this goal involves using TDA to guide the graph pooling process. However, this approach often demands a completely different filtration type, such as the Vietoris-Rips (or power) filtration, which can be computationally expensive. Balancing the desire for topological preservation with the computational cost remains a significant challenge in this context."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission963/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission963/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission963/Reviewer_r2G4"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698513062604,
        "cdate": 1698513062604,
        "tmdate": 1699636022241,
        "mdate": 1699636022241,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7H4aILzSMs",
        "forum": "9zpOUsOvLM",
        "replyto": "9zpOUsOvLM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission963/Reviewer_adEb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission963/Reviewer_adEb"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new graph coarsening method based on persistent homology, aiming to preserve the topology of the coarsened graph. In particular, it adds the topological loss between the coarsened graph and the original graph into the graph pooling loss function. Experiments on several benchmarks show its effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Using persistent homology to enhance graph coarsening is new to the best of my knowledge. \n\nThe proposed model manages to effectively preserve the topological information, as suggested by the empirical validations."
            },
            "weaknesses": {
                "value": "1. My biggest concern is that it is unclear why we need to preserve the mentioned topological information, e.g., the 1-th Betti Number (number of cycles) during graph coarsening. For example, in a molecule graph, a benzene ring can be represented by a 6-cycle (a cycle with 6 nodes), and thus can be captured by PH. The cycle can be coarsened to a point, which is reasonable since it will preserve the structural information. However, it will lead to a change in the 1-th Betti Number.\n\n2. Another highly related question is the unclear illustration of Figure 1. What is the chosen filtration of PH in Figure 1(a) and Figure 1(b)? If the filtration is the color of the nodes, then the nodes with the same color should appear or disappear at the same time. In addition, in Figure 1(c), which graph does the diagram correspond to, and which cycle/connected component does each persistence point corresponds to? Furthermore, from my perspective, Figure 1(b) denotes that we can use a graph pooing function to capture the change of the PH information since the correspondence is stable regardless of different datasets. In other words, we do not need additional efforts to preserve the mentioned topological information.\n\n3. In the experiment part, since TU datasets are suffering from high standard deviation, I recommend adding more popular benchmarks such as ZINC and the OGB datasets. In addition, the running time should be reported on different benchmarks."
            },
            "questions": {
                "value": "See Weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698586461416,
        "cdate": 1698586461416,
        "tmdate": 1699636022156,
        "mdate": 1699636022156,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EWjCYIGp2B",
        "forum": "9zpOUsOvLM",
        "replyto": "9zpOUsOvLM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission963/Reviewer_XtaZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission963/Reviewer_XtaZ"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a PH-based pooling layer called TIP (topology-invariant pooling). The proposed approach resamples graph connections (after soft-cluster assignments) and scales edge weights with persistence information (from 1-dim persistence diagrams). In addition, TIP applies a new loss that enforces topology-preservation based on multiple vectorizations of the 1-dim diagrams. Experiments on 3 synthetic and 7 real-world datasets aim to show the efficacy of TIP when combined with well-known pooling methods (DiffPool, MinCutPool, and DMoNPool) and GNNs."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- To my knowledge, this is the first paper to leverage PH for graph pooling;\n- The proposed method is simple and can be easily integrated (as pooling method) into several GNNs."
            },
            "weaknesses": {
                "value": "- [Theory] Theorem 1 states that distinguishing graphs based on 1-dimensional persistence diagrams is more expressive than 1-WL. **I believe this is false**. For instance, let $G$ and $G'$ be two graphs comprising one and two isolated nodes, respectively. The 1-dimensional diagrams for these graphs are identical (and empty) for any filtration function. However, 1-WL distinguishes graphs with different numbers of nodes. In addition, since the paper leverages filtration functions on node features, for graphs that share the same single feature vector (or same color), 1-dim diagrams cannot go beyond Betti-1, which is clearly less expressive than 1-WL. \n\n- [Methodology] Since 1-dim persistence diagrams have limited persistence (the death times are identical), it seems the proposal mainly relies on cycle-preserving pooling (do the authors agree?). At a conceptual level, I am not convinced that this design choice is a desideratum for general-purpose graph pooling and/or graph classification tasks. Overall, I found the motivation for adopting only 1-dimensional PD weak;\n\n- [Experiments] Due to the lack of a strong/principled motivation, I would expect to see more empirical evidence to support the proposed method. The paper only considers TU Datasets, and therefore does not exploit recent efforts (e.g., OGB) to strengthen the evaluation of GNNs. Moreover, except for the Enzymes dataset, the empirical gains do not look significant (with differences in mean accuracies usually within one std, overall) compared to pooling-free approaches. Lastly, the ablation study should consider other datasets and pooling layers."
            },
            "questions": {
                "value": "1. Could you elaborate on how PH coarsens graphs (as in Figure 1)?\n2. Do the persistence ratios in Fig. 1(b) include 0-dim persistence diagrams? If so, it seems misleading to use Fig(b) as a motivation and only exploit 1-dimensional PH information for pooling. \n3. Does the proposed method apply multiple filtration functions? If so, how are the 1-dimensional persistence diagrams processed (or combined)? \n4. The paper says: \"PH cannot directly extract meaningful topological features from A\". Can't we apply edge-level learned filtration functions, where the nested sequence of subgraphs is obtained according to the filtration values at each edge?\n5. I believe it would be helpful to see examples of (1-dim) persistence diagrams before and after applying TIP. For instance, I am curious to see the diagrams for the ring and grid2d datasets.\n6. In the introduction, the paper says 'in addition to concatenating vectorized PH diagram as supplementary features, ...\" However, the methodology section doesn't mention these additional features. Is the proposed approach also using 0-dim persistence information as additional node features (like in TOGL)?\n7. Is TIP isomorphism invariant?\n8. In section 4, the paper uses vectorized 1-dim diagrams to measure topological similarity. However, Fig. 5 shows learning curves using the Wasserstein distance. I was confused. The same happens with the filtration functions --- Forman curvature vs. learnable filtration function --- it seems the former is only used for evaluation purposes (table 1). These choices should be clarified.\n\n\nMinor comments and suggestions:\n- Page 3: $V=\\\\{i, x_v\\\\}$ $\\rightarrow$ $V=\\\\{v, x_v\\\\}$;\n- Page 3: Highlight that the GNN in Eq. (2) is not the same as the one in Eq. (4); \n- Page 3/4: Filtration functions are defined as $f: \\mathcal{G} \\rightarrow \\mathbb{R}$. However, later in the same paragraph, it appears as $f(x_v)$. We can also find $f(e)$. Please be precise here.  \n- Page 4: What would be the case (3) \"all other edges will be paired with the maximum value of the filtration\"? Each edge either creates a cycle (case 1) or not (case 2), no?!\n- In Eq. (6), computing the Hadarmard product between $A (n \\times n)$ and $(\\mathcal{D}_1[1] - \\mathcal{D}_1[0]) (m \\times 1)$ might be problematic. I suggest being more precise.\n- In Eq. (7), the variable $t$ should appear on the right-hand side of $h_t = \\text{transform}(D_1)$.\n- What do you mean by persistent sub-topology?\n- Give more details about the Forman curvature used as the filtration function.\n- The caption of Fig. (6) says: \"a pair of isomorphic graphs that cannot distinguished by 1-WL but can be distinguished by TIP\". It is not clear what the paper wants to convey here (including the plot and the caption)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission963/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698848062133,
        "cdate": 1698848062133,
        "tmdate": 1699636022066,
        "mdate": 1699636022066,
        "license": "CC BY 4.0",
        "version": 2
    }
]