[
    {
        "id": "fZvPZOINzN",
        "forum": "kBTzlxM2J1",
        "replyto": "kBTzlxM2J1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed a solution on how to extract rules from the DRUM model that are faithful, i.e., both complete and sound. The authors provided extensive analysis on the correctness of the proposed algorithm and demonstrate the benefits of their algorithm with some experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The rule learning problem, in particular, the problem of how to obtain a high-quality set of rules, that the authors are exploring is a critical problem. \n+ The authors present a detailed theoretical analysis of how to derive faithful rules from DRUM model, which is quite impressive"
            },
            "weaknesses": {
                "value": "+ I have some concerns about the motivation of the proposed method. It is not clear to me why faithfulness is an important metric for rule learning. What kind of benefits can we obtain for the rule learning problem if the rules can respect faithfulness, e.g., say better generalizability? The authors may need more effort to justify this. One motivating example might be helpful for readers to understand this.\n+ I also feel that the proposed solution is too specific. It is only applicable to the DRUM model rather than the general rule learning model, which may limit the applicability of the proposed method in general settings. \n+ The overall presentation may need to be improved. I feel that the authors have a lot of technical content to present. However, putting all of them together without appropriate illustrations makes it hard for readers to digest. One suggestion would be using some running examples to intuitively explain the meaning of the notations and equations rather than just leaving them in the paper. Even the prior work such as DRUM paper or Neural ILP paper, there are a lot of visualizations that help users understand the intuitions of the proposed method.\n+ I feel that the experimental evaluations are also concerning. The authors only focus on evaluating the performance of the proposed methods. However, no appropriate evaluations (except some simple case studies) are conducted for the faithfulness part, e.g., how many rules from the vanilla DRUM model violate the faithfulness criterion and what is the bad effect of including those rules?"
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4188/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ",
                    "ICLR.cc/2024/Conference/Submission4188/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698273203540,
        "cdate": 1698273203540,
        "tmdate": 1700340278236,
        "mdate": 1700340278236,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DGozCnByel",
        "forum": "kBTzlxM2J1",
        "replyto": "kBTzlxM2J1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_BVyG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_BVyG"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses the growing interest in extracting understandable rules from machine learning models that work with knowledge graphs. These models are used for various tasks like knowledge graph completion, node classification, question answering, and recommendation. However, many of these rule extraction methods lack formal guarantees, which can be a problem when applying these rules in critical or legally required situations. The paper focuses on the DRUM model, a variant of the NEURAL-LP model, which has shown good practical performance. The paper explores whether the rules derived from DRUM are sound and complete, meaning they provide reliable results. The authors propose a new algorithm to ensure both soundness and completeness in the extracted rules. This algorithm, while effective, may be less efficient in practice. They also suggest adding constraints to DRUM models to facilitate rule extraction, even if it reduces their expressive power. The paper points out that DRUM and NEURAL-LP models have technical differences, making it necessary to examine the guarantees separately for DRUM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Good paper interesting, with good ideas and good experiments."
            },
            "weaknesses": {
                "value": "it seems that a lot of citations are missing, please add them and discuss them\n\nhttps://arxiv.org/pdf/2301.09559.pdf\nLearning Interpretable Rules for Scalable Data Representation and Classification\nFINRule: Feature Interactive Neural Rule Learning\nhttps://arxiv.org/pdf/2309.09638.pdf"
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698573856915,
        "cdate": 1698573856915,
        "tmdate": 1699636385280,
        "mdate": 1699636385280,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gjiyO39gFH",
        "forum": "kBTzlxM2J1",
        "replyto": "kBTzlxM2J1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_Crqq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_Crqq"
        ],
        "content": {
            "summary": {
                "value": "The paper adapts a study that was previously conducted for extracting rules from the Neural-LP model (which is a neural model for reasoning about knowledge graphs) to DRUM, an alternative architecture for the same task. This adaptation is not entirely trivial, as the authors motivate well, so that this can be considered an original contribution. They also show that, in analogy to the previous work, the extracted rules are not necessarily faithful, and can be unsound or incomplete. An expensive alternative is also proposed as a remedy."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper seems to be well formalized and contain sufficiently interesting improvements over the state-of-the-art. The evaluation is on a standard benchmark task. The introduction is quite accessible, but after that I was quickly lost."
            },
            "weaknesses": {
                "value": "I am not sufficiently familiar with this area in order to judge whether the contribution of this work is sufficiently deep for publication, whether the shown results are actually correct, or whether the performed evaluation on this set of benchmark sets is a standard procedure in this area.\nWhat I can judge, however, is that the paper is a) very well written in the sense that a stringent formal presentation is chosen, but also b) not written for an audience outside this immediate community, and the authors also do not make any attempt to make their work more accessible. If you do not know any of the prior works, in particular DRUM, you are lost. I could, e.g., easily follow the terse formal description of Datalog, because I am familiar with that. With the similarly formal presentation of DRUM I was completely lost. I now know what parts this system has, but not what they are used for. I know that path-counting is part of the method, but I don't know what paths are counted, and why this has any significance. \nI think the paper is a very nice illustration of the fact that shorter explanations are not necessarily more interpretable. \n\nMinor stuff:\nThe formalization of the paper seems to be very stringent, the references are not (lower case abbreviations such as gnn, all conference names abbreviated (I don't know all of them), weird references to things like ICML volume 227 or ISWC volume 13489, backslashes in URLs, etc."
            },
            "questions": {
                "value": "I'm not really familiar with this task, but this seems to be quite a heavy machinery for extracting family relations. In Inductive Logic Programming these are only toy examples. Are there no better tasks for showcasing what you can do?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698785722261,
        "cdate": 1698785722261,
        "tmdate": 1699636385208,
        "mdate": 1699636385208,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KJ0Vg8STib",
        "forum": "kBTzlxM2J1",
        "replyto": "kBTzlxM2J1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
        ],
        "content": {
            "summary": {
                "value": "In the abstract, the authors describe the problem that they are solving as  \"methods for extracting interpretable rules from ML\nmodels trained to solve a wide range of tasks over knowledge graphs (KGs), such as KG completion, node classification, question answering and recommendation.\" and talk about how \"Many such approaches, however, lack formal guarantees establishing the precise\nrelationship between the model and the extracted rules, and this lack of assurance becomes especially problematic when the extracted rules are applied in safety critical contexts or to ensure compliance with legal requirements\"\n\nWhile the work described in the paper seems reasonable, this does not quite seem to match the claim in the abstract. As best as I can tell,\nthe techniques in the paper do not deal with classification / question answering / recommendations. Further, it is not obvious (either from the description of the technique or the experimental results) that they provide assurances around the \"precise relationship between the model and the extracted rules\" (while there might be soundness, completeness does not seem to result)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The results seem interesting for knowledge graph completion problems."
            },
            "weaknesses": {
                "value": "It was not obvious how this applies for general ML problems, particularly those around question answering. It was not clear how the algorithm might perform for classification/recommendation systems."
            },
            "questions": {
                "value": "It was not obvious how this applies for general ML problems, particularly those around question answering. It was not clear how the algorithm might perform for classification/recommendation systems."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810730625,
        "cdate": 1698810730625,
        "tmdate": 1699636385107,
        "mdate": 1699636385107,
        "license": "CC BY 4.0",
        "version": 2
    }
]