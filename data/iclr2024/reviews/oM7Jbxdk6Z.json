[
    {
        "id": "nMnOEKHWcY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_3A6t"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_3A6t"
        ],
        "forum": "oM7Jbxdk6Z",
        "replyto": "oM7Jbxdk6Z",
        "content": {
            "summary": {
                "value": "This paper seeks to understand the inherent connection between 2D and 3D representations, capturing the essential structural attributes of molecules through atomic-relation level multimodal pretraining techniques. \nIn this process, the authors initially combine atom relations from various modalities into a single cohesive matrix for combined encoding, and subsequently retrieve specific information for both 2D and 3D structures separately."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Learning the qualified representation of molecules is important for various downstream tasks.\n2. To the best of my knowledge, this is the first work that aligns atom-level representation for 2D and 3D representations of molecules."
            },
            "weaknesses": {
                "value": "1. As highlighted by the authors, earlier studies typically aligned different modalities at a broader molecule level, potentially hindering the capture of detailed molecular structures. Initially, when considering atom-level depictions of a molecule, our focus might be on the atom-level rather than the atomic-relation level. For instance, we might design a model that determines 3D atom coordinates based on a 2D molecular graph. What's the rationale behind emphasizing atomic-relation level multi-modal pretraining? It would be beneficial to provide a thorough reasoning in the methodology section and draw empirical comparisons in the experiments.\n\n2. The experimental findings appear to be underwhelming. MoleBlend's performance, as shown in Tables 1 and 2, doesn't seem to fare well against prior studies."
            },
            "questions": {
                "value": "Provided above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Reviewer_3A6t",
                    "ICLR.cc/2024/Conference/Submission4139/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4139/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697212364630,
        "cdate": 1697212364630,
        "tmdate": 1700753332136,
        "mdate": 1700753332136,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xzf6XJZSNi",
        "forum": "oM7Jbxdk6Z",
        "replyto": "oM7Jbxdk6Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_w2xw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_w2xw"
        ],
        "content": {
            "summary": {
                "value": "The authors proposed to align molecule 2D and 3D modalities at the atomic-relation level and introduce MOLEBLEND. This multimodal molecular pretraining method explicitly utilizes the intrinsic correlations between 2D and 3D representations in pertaining. Extensive evaluation demonstrates that MOLEBLEND achieves state-of-the-art performance over diverse 2D and 3D tasks, verifying the effectiveness of relation-level alignment."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to understand.\n2. The authors conducted extensive experiments on both 2D and 3D molecule tasks and showed their good performance."
            },
            "weaknesses": {
                "value": "1. The authors did not discuss the training time cost of different pretraining methods.\n2. A series of pertaining baselines are missed in related works and comparisons. For example:\n\n[1] Xu M, Wang H, Ni B, et al. Self-supervised graph-level representation learning with local and global structure. ICML 21.  \n[2] Zhang Z, Liu Q, Wang H, et al. Motif-based graph self-supervised learning for molecular property prediction. NeurIPS 21.  \n[3] Zaidi S, Schaarschmidt M, Martens J, et al. Pre-training via denoising for molecular property prediction. ICLR 23.  \n\n3. The theoretical analysis is good. However, could the authors provide more insights into why MOLBLEND overperforms existing methods theoretically?\n\n4. How does the different choice of encodings for 2D/3D modalities influence the pretaining?"
            },
            "questions": {
                "value": "Please see the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Reviewer_w2xw"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4139/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698418565283,
        "cdate": 1698418565283,
        "tmdate": 1699636379400,
        "mdate": 1699636379400,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hB3Pb5HJCI",
        "forum": "oM7Jbxdk6Z",
        "replyto": "oM7Jbxdk6Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_TmmD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_TmmD"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes MolBlend, a method that explores the intrinsic alignment between 2D and 3D for molecule pretraining. MolBlend aims to conduct the 2D-3D pretraining based on the atom relations, which is finer-grained than previous works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The key idea is clear and straightforward: to use the attention module to help augment the 2D-3D atom-relation for molecule pretraining.\n- The theoretical proof is interesting."
            },
            "weaknesses": {
                "value": "- The motivations are not clearly claimed or supported.\n    - For instance, on Page 2, the authors say that they \u201cobserve that although appearing visually distinct \u2026 are intrinsically equivalent as they are essentially different manifestations of the same atoms and their relationships\u201d. What does \u201cequivalent\u201d mean here? A lot of 2D-3D pretraining methods start by saying such two modalities are complementary to each other.\n    - Additionally, on Page 2, what is the motivation to feed both modalities as one unified data structure to one single model in MoleBlend?\n\n- Notations are misleading in Sec 3.1.\n    - Why is $R_{spd}$ required? Because they can be derived from $R_{edge}$?\n    - For Eq 1, the notation should be $R_{2D3D,S}$ (with S in the subscript).\n    - Is $R_{2D3D}$ the masked version of $R_{spd}, R_{edge}, and R_{distance}$?\n\n- Other minor comments:\n    - The title can be further improved, especially that what modalities are considered is not explicit.\n    - The distance modeling is invariant. A more advanced equivariant model is preferred here.\n    - It would be better to explicitly add a column in the result tables on what backbone models are pretrained/comparing.\n    - The citation of 3D InfoGraph is wrong. Please fix it.\n\nI will consider raising the score once the authors answer/fix these comments."
            },
            "questions": {
                "value": "- I am confused about the Fig 1.b. Does this mean the input can be either 2D or 3D, and the output can be both 2D and 3D?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4139/Reviewer_TmmD"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4139/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698716126874,
        "cdate": 1698716126874,
        "tmdate": 1700486035509,
        "mdate": 1700486035509,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bnKGSvn6Ch",
        "forum": "oM7Jbxdk6Z",
        "replyto": "oM7Jbxdk6Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_XaRC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4139/Reviewer_XaRC"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a molecular representation learning method that fusing the information from both 2D and 3D molecule structures. A unified relation matrix is constructed to describe the relationships between each pair of atoms, so that both 2D and 3D information can be injected into the matrix for fusion. For the 2D structure, based the bonds between atoms, shortest path and edge type information can be calculated for each entry of the relation matrix, and for the 3D structure, the entry can records the 3D Euclidean distance between atoms. The 2D and 3D information are blended in one relation matrix and a Transformer backbone is trained to recover the full information."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of using a relation matrix to unify the 2D and 3D information for molecular representation learning is novel.\n2. Theoretical analysis provide more insights to the proposed method.\n3. The paper is well writen and structured and easy to follow."
            },
            "weaknesses": {
                "value": "1. The information gathered in the relation matrix is quite limited and much information in the original structure is lost, especially those in the 3D structure. The matrix construction is quite similar to the work of  \"One transformer can understand both 2d & 3d molecular data\" published in ICLR 2023.\n2. Ablation studies on blending two masks should be provided.\n3. Some details of the experimental setup is missing."
            },
            "questions": {
                "value": "1. Does the author run all baseline methods on the experimented splits or cite some results from other papers? For the results in Table 4, does the  single-modality mask-then-predict strategies use the same network as the proposed blending strategy?\n\n2. In Table 4, I think the author compares blending three mask to using only one mask. What's the effect of blending two masks?\n\n3. The conclusion in section D.1 is not well supported, since different 3D networks may perform differently and may have different speed of convergence. It's not enough to draw the conclusion by comparing the proposed method to only one 3D model.\n\n4. Why run ablation studies on different datasets and different tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4139/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740569143,
        "cdate": 1698740569143,
        "tmdate": 1699636379244,
        "mdate": 1699636379244,
        "license": "CC BY 4.0",
        "version": 2
    }
]