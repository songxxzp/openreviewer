[
    {
        "id": "1H0svNK2Yq",
        "forum": "RUHli7EjbH",
        "replyto": "RUHli7EjbH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3995/Reviewer_zq48"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3995/Reviewer_zq48"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel distributed learning framework with differential privacy. The proposed method is demonstrated effectively on large models up to 10^5 million parameters. The algorithm is built upon ZeRO framework and several efficient DP training tricks from prior works. The experiments are thorough and the results are impressive."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is well-written despite some format issues.\n2. The proposed method enables training GPT-100B which beats state-of-the-art DP training in terms of scalability and efficiency."
            },
            "weaknesses": {
                "value": "I am curious about the utility of large models, like the GPT-100B. Is there a plot that shows accuracy drops?"
            },
            "questions": {
                "value": "Please see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821469175,
        "cdate": 1698821469175,
        "tmdate": 1699636361398,
        "mdate": 1699636361398,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "10V644JcOY",
        "forum": "RUHli7EjbH",
        "replyto": "RUHli7EjbH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3995/Reviewer_otjb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3995/Reviewer_otjb"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes DP-ZERO, a distributed training algorithm based on ZERO and adapted to do differentially private training with clipping and noising. The authors analyze the time and memory efficiency of DP-ZERO, showing that they're the same as original ZERO. The authors also conducted empirical evaluations on large models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper tackles a very important problem as differentially private training of large models is becoming more and more needed in this era.\nThe empirical evaluations prove that the proposed algorithm can be used to train large models."
            },
            "weaknesses": {
                "value": "The presentation of the paper might need to be improved in order for readers to have a clearer understanding of the proposed algorithm and its significance.\n\n1. Is DP-ZERO basically doing clipping in the unit of device, i.e. gradients of layers in one device is clipped? If so (or not), you might consider stating that more clearly. \n\n2. One thing I found a bit missing is the difficulty of the problem, i.e. why is it non-trivial to make a DP version of the original ZERO? I kind of feel like it's quite straightforward to add clipping to the algorithm, especially if (1) is true as we can simply operate on each device individually for clipping, which is the same as non-distributed training.\n\n3. The explanation of ZERO (Section 2) is a bit unclear at least to readers without much background knowledge like me. For example, in Section 2.2.2, you might state the memory needed for each variable clearly, so that readers can more easily add them up (e.g. to get the 16, 12, 14). You might state the unit of the memory (I presume \"byte\"?). Also, in Section 2.3, I think you can explain more details on mixed precision training, as that seems to be different for non-private and private training (as is mentioned in Section 3.4).\n\nMinor: 2nd last sentence in Section 2.3: \"does not need loss\" -> \"does not need loss scaling\"?\n\n4. The complexity of \"DP clip and noise\" in Table 2 seems to be a very important part of the paper and worth some detailed explanation in the main body. (I don't quite understand how it's calculated even after looking at Appendix B.) What does it mean to be \"figurative and dependent on settings\"?"
            },
            "questions": {
                "value": "Besides the points mentioned above in \"Weaknesses\", I wonder if the precision change can affect the precision of the noise and thus causing any problem / difference in privacy."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699250855814,
        "cdate": 1699250855814,
        "tmdate": 1699636361331,
        "mdate": 1699636361331,
        "license": "CC BY 4.0",
        "version": 2
    }
]