[
    {
        "id": "9oOawGtEyF",
        "forum": "f6CBQYxXvr",
        "replyto": "f6CBQYxXvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_fuyr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_fuyr"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose PROJECT AND PROBE, a lightweight framework consisting of 2 steps: (1) a projection step that extracts a diverse and predictive feature-space basis and (2) a probing step that interpolates between the projected features to efficiently adapt varying target distributions. The core idea is to ensure orthogonality among each component of the feature vector. Each component is utilized by an identical predictor but contains distinct information. Subsequently, these components are employed for predicting the target data. The proposed approach is supported by a theoretical analysis showing that the proposed approach improves sample efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is well-written and well-organized.\n- Enforcing feature orthogonality is intuitive and seems suitable for learning features that remain invariant to distribution shifts.\n- The proposed algorithm outperforms the baselines, especially when the sample size of the target data is relatively small."
            },
            "weaknesses": {
                "value": "- One major limitation of this work is the fact that the project and probe processes are considered solely in the linear model regime due to the pre-trained feature extraction. Also, the theoretical analysis was conducted with a linear model. how would it  extended to large-scale problems?\n\n- The authors only compare with projection-based baselines. I think comparisons with recent general unsupervised domain adaptation methods are needed. \n\n- While learning diverse/orthogonal features is novel in the context of domain adaptation. There is an active line of research that explores this idea in the standard supervised learning setting, such as [1-7]. I think these methods should be discussed in the related work. \n\n\n[1] Bansal, N., Chen, X., & Wang, Z. Can we gain more from orthogonality regularizations in training deep networks?. Neurips (2018)\n\n[2] Xie, P.; Singh, A.; and Xing, E. P. . Uncorrelation and evenness: a new diversity-promoting regularizer. ICML (2017)\n\n[3] Xie, B.; Liang, Y.; and Song, L.. Diverse neural network learns true target functions. In Artificial Intelligence and Statistics (2017)\n\n[4] Laakom, F., Raitoharju, J., Iosifidis, A., & Gabbouj, M. WLD-Reg: A Data-dependent Within-layer Diversity Regularizer. AAAI (2023)\n\n[5] Cogswell, M.; Ahmed, F.; Girshick, R. B.; Zitnick, L.; and Batra, D. Reducing Overfitting in Deep Networks by Decorrelating Representations. ICLR (2016)\n\n[6] LLaakom, F., Raitoharju, J., Iosifidis, A., & Gabbouj, . Learning distinct features helps, provably. ECML (2023).\n\n[7] Zbontar, J., Jing, L., Misra, I., LeCun, Y., & Deny, S. (2021, July). Barlow twins: Self-supervised learning via redundancy reduction. ICML (2021)"
            },
            "questions": {
                "value": "See Section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3993/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3993/Reviewer_fuyr",
                    "ICLR.cc/2024/Conference/Submission3993/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3993/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762333146,
        "cdate": 1698762333146,
        "tmdate": 1700633389244,
        "mdate": 1700633389244,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m9H5pZUhrs",
        "forum": "f6CBQYxXvr",
        "replyto": "f6CBQYxXvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_Ft2e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_Ft2e"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Project and Probe (PRO^2), a transfer learning method designed for scenarios with limited target data due to distribution shifts. PRO^2 is based on a two-step approach: first, it projects pre-trained embeddings from the source dataset onto orthogonal directions to derive a diverse, non-redundant set of predictive features; next, it trains a linear classifier on these projected features using the target data. Theoretical analyses emphasize the method's favorable bias-variance tradeoff, and experimental results across four datasets demonstrate an improved performance by 5-15% compared to traditional linear probing methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper stands out in terms of clarity, organization, and overall presentation. It also offers an extensive appendix that provides in-depth coverage of related topics, adding value for the reader.\n\n- The authors have presented a robust theoretical framework that substantiates their approach. They effectively highlight the method's capability to achieve a desirable balance between bias and variance.\n\n- The empirical experiments are detailed and present a wide range of scenarios. While there are certain reservations (addressed below), the breadth and depth of this section are commendable."
            },
            "weaknesses": {
                "value": "- The study by Morwani et al. (2023) has previously explored orthogonal projections as a remedy for feature collapse and simplicity bias. This prior exploration somewhat diminishes the uniqueness of the approach presented in this paper.\n\n- Some aspects of the empirical evaluation are unclear and require further details from the authors. See the \"Questions\" section for more details.\n\n- The paper presents a rather limited set of baselines. Given that the experimental setup seems relatively straightforward, it would be advantageous to have a more comprehensive range of baselines. Specifically, a comparative analysis involving methods anchored in LDA and QDA (as pointed out in Shysheya et al., 2022) could enrich the paper."
            },
            "questions": {
                "value": "1) Regarding the empirical assessment, was a consistent hyper-parameter search strategy employed across all the evaluated baselines, or was it exclusively used for the proposed model?\n\n2) There are approaches that exploits Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA) for the adaptation of the head of a pretrained model with success (Shysheya et al. 2022). Can the authors comment on the differences between their method and these methods? While the paper covers the relation with respect to LDA, it does not seem to mention the relation with QDA. Adding those baselines to the empirical evaluation may be beneficial.\n\n3) The authors briefly mention the relation with the previous work of Morwani et al. (2023) in the related work section. This section appears somewhat limited and would benefit from a more in-depth exploration. Could the authors elaborate on the parallels and distinctions between their work and Morwani et al. (2023)?\n\n4) Would the authors be able to provide a detailed analysis of the complexity for the proposed method (e.g. FLOPs and/or MACs)? Understanding complexity is crucial as it essentially represents the computational budget. How does the method's time complexity stand in comparison to leading fine-tuning approaches, such as BiT by Kolesnikov et al. (2020), which adapt the entire model body or FiT (Shysheya et al. 2022), which adapt a subset of the body parameters?\n\n\nReferences\n-----------\n\nMorwani, D., Batra, J., Jain, P., & Netrapalli, P. (2023). Simplicity bias in 1-hidden layer neural networks. arXiv preprint arXiv:2302.00457.\n\nKolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., & Houlsby, N. (2020). Big transfer (bit): General visual representation learning. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part V 16 (pp. 491-507). Springer International Publishing.\n\nShysheya, A., Bronskill, J., Patacchiola, M., Nowozin, S., & Turner, R. E. (2022). Fit: Parameter efficient few-shot transfer learning for personalized and federated image classification. arXiv preprint arXiv:2206.08671."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3993/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3993/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3993/Reviewer_Ft2e"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3993/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698782121944,
        "cdate": 1698782121944,
        "tmdate": 1700650631510,
        "mdate": 1700650631510,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zk3dDAgeBk",
        "forum": "f6CBQYxXvr",
        "replyto": "f6CBQYxXvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_sNr1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3993/Reviewer_sNr1"
        ],
        "content": {
            "summary": {
                "value": "This paper deals with the problem of transfer learning with a small amount of target data. It proposes Project and Probe, which first learns a liner projection that maps the pre-trained embedding onto orthogonal directions and then learns a linear classifier on top of the projected features on the small target dataset. The proposed method outperforms prior methods on transfer learning when given very limited target data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is clearly written and organized.\n\n- The enhanced sample-efficient generalization of the proposed method is supported by theoretical analysis."
            },
            "weaknesses": {
                "value": "- A critical comparison is missing from the experiments: How does the proposed method perform compared to zero-shot transfer learning methods (i.e., no target training data), as cited in related work?\n\n- For reproducibility, it is necessary to include the numerical values of the experimental results in addition to the line charts."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3993/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797562972,
        "cdate": 1698797562972,
        "tmdate": 1699636361037,
        "mdate": 1699636361037,
        "license": "CC BY 4.0",
        "version": 2
    }
]