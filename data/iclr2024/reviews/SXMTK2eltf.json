[
    {
        "id": "qV0neVjEi7",
        "forum": "SXMTK2eltf",
        "replyto": "SXMTK2eltf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_PY8W"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_PY8W"
        ],
        "content": {
            "summary": {
                "value": "The author proposed a scheme utilizing ChatGPT for motion planning, where perception results (or ground truth) are used as inputs. With meticulous prompt design and finetuning through the API, the approach achieved commendable open-loop performance on the large-scale Nuscenes dataset. Additionally, experiments were designed to demonstrate the large language model's generalizability (few-shot) and interpretability (reasoning) for motion planning tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The overall text flows smoothly and is easy to understand.\n2. Seeing the large language model demonstrate impressive performance and few-shot capabilities in such a simple manner is astonishing. This can better motivate people to continue validating the exploration of large language models in the direction of motion planning.\n3. The author will open-source the code, and since the experiment is relatively simple, I believe there is a high probability that the experiment can be reproduced. The confidence level in the experiment's results is very high."
            },
            "weaknesses": {
                "value": "1. While I personally appreciate the simplicity and effectiveness of this research, I do not believe it possesses sufficient novelty to be a paper for ICLR. The article simply utilizes the ChatGPT API for finetuning, which can be regarded as an application experiment report on motion planning using ChatGPT. Since it does not introduce any new modules or methodologies, I think its actual contribution to the field is quite limited.\n2. Motion planning ultimately needs to be validated in a closed-loop system, as the results from open-loop and closed-loop scenarios are not always aligned, as highlighted in [1]. In cases where perception results (or ground truth) are directly used as input, it is easy to integrate into a closed-loop system, and there are numerous readily available public datasets for closed-loop testing, such as Nuplan, Waymo Motion Dataset, MetaDrive, etc. If closed-loop results could be obtained, I believe it would significantly enhance the credibility and contribution of the paper.\n3. The descriptions in the RELATED WORKS section of the article are somewhat inaccurate. Dauner et al. (2023)[1] is actually a rule-based method.\n\n[1] Dauner, D., Hallgarten, M., Geiger, A., & Chitta, K. (2023). Parting with Misconceptions about Learning-based Vehicle Motion Planning. arXiv preprint arXiv:2306.07962."
            },
            "questions": {
                "value": "1. I hope to see closed-loop results; please refer to the \"Weaknesses\" section for more details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Reviewer_PY8W"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4601/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698693149729,
        "cdate": 1698693149729,
        "tmdate": 1699636438999,
        "mdate": 1699636438999,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ytnGs8ICKy",
        "forum": "SXMTK2eltf",
        "replyto": "SXMTK2eltf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_1ZwR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_1ZwR"
        ],
        "content": {
            "summary": {
                "value": "The authors propose some techniques for using ChatGPT3.5 to generate driving trajectories (as a list of coordinates) from a language representation of the world/ego state. The approach outperforms end-to-end learning-based approaches on a computer vision driving benchmark."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- How to best utilize LLMs for autonomous vehicles is an interesting and timely question that I think is of great interest to the community.\n- That the authors achieved such a huge improvement with fine tuning is a surprising insight (going from worst to best results), but potentially useful if it checks out."
            },
            "weaknesses": {
                "value": "- The benchmark comparison seems a bit apples to oranges. You compare against end-to-end computer vision approaches from CVPR, but your approach assumes the object detections are given and only solves the planning part. Even if you use the detections from a competing CV method, it is unclear to me how strong this result is as planning is perhaps not the main focus of their approach. It would have been good to have some conventional planning stack as baseline as well.\n- Your portrayal of related work outside of CV/learning seems weak/dated with the most recently cited planning paper being from 2018. I quite frequently see conventional planning/optimization papers for autonomous driving at other venues (robotics, AI...). Check some recent surveys, I include one which does not use your terminology of \"rule-based\" for these either (not sure what you mean by that). [1] S. Teng et al., \"Motion Planning for Autonomous Driving: The State of the Art and Future Perspectives,\" in IEEE Transactions on Intelligent Vehicles, vol. 8, no. 6, pp. 3692-3711, June 2023, doi: 10.1109/TIV.2023.3274536.\n- This really is \"GPT\"-driver, it just uses the web APIs for ChatGPT for prompting and fine tuning. GPT is state of the art (at least if you had used 4.0) so is somewhat defensible, but it would have been interesting to see how this generalized across other LLMs.\n\nMinor questionable claims or presentation issues:\n\n- You write \"Albeit simple, these approaches attempt to simultaneously regress waypoints across different scales, e.g. coordinate values ranging from 0 to over 50, which generally results in imprecise coordinate estimations of the more distant waypoints\": This seems like it would be fixed by a simple rescaling, is this really a fundamental problem with IL approaches? This also does not mention RL-based approaches (see [1]) \n- Sec 3.2:  Does all of the IL approaches really use absolute value loss, that seems oddly specific? The discussion of how a number is encoded as a text string seems pretty obvious/trivial.\n- \"It is worth noting that these state-of-the-art planners heavily rely on multiple heterogeneous observations such as detections, predictions, occupancy grids, and maps, which makes their systems intricate and time consuming.\" You rely on their detections (maybe predictions, unclear) so this seems at least half misleading."
            },
            "questions": {
                "value": "- What data did you use for fine tuning vs evaluation? I am not very familiar with this particular benchmark, but your trajectory prediction errors are surprisingly low. The optimal trajectory for driving is in reality sometimes ambigious, possibly multi-modal and an open research problem, so it seems a bit suspicious that you can get centimeter precision on trajectory prediction. \n- Can you clarify what prompts you used in your three-stage approach for training. Fig 3. seems to only include the prompt for the final stage?\n- Isn't your information about the obstacles both incomplete and technically cheating (acausal) in the simple prompting baseline, since you do not include obstacle velocities, but seemingly where they will be in the future? Care to comment on what this description really means, where they will stop / be x seconds? in the future?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Reviewer_1ZwR"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4601/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698784586359,
        "cdate": 1698784586359,
        "tmdate": 1701046775981,
        "mdate": 1701046775981,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MmpuJA5iOt",
        "forum": "SXMTK2eltf",
        "replyto": "SXMTK2eltf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_FVv6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_FVv6"
        ],
        "content": {
            "summary": {
                "value": "This work studied the application of LLM in motion planning for autonomous driving. In the proposed GPT-Driver framework, perception and prediction results (e.g., object types, coordinates, and predicted future coordinates) together with the ego states are converted into language tokens. Then, they are used to prompt an LLM to produce a planned trajectory alongside its decision-making process in natural language. In particular, the authors propose a fine-tuning scheme with auto-generated reasoning labels to fine-tune a GPT-3.5 model for the purpose of motion planning. The results show that the GPT-Driver outperforms existing learning-based motion planners in terms of imitating human drivers and performs on par with top methods in collision rate."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is simple, straightforward, and well-performing in the studied driving scenarios. \n2. It provides informative insights on the feasibility and performance of steering LLMs into motion planners producing numerical waypoints. It is particularly interesting and promising that the authors show that GPT-Driver can outperform existing approaches after few-shot fine-tuning."
            },
            "weaknesses": {
                "value": "While the proposed GPT-Driver has demonstrated impressive performance, the paper lacks in-depth analysis to help the audience gain a deeper understanding of the model's performance and limitations:\n\n1. For example, an ablation study should be conducted to evaluate the benefit of having chain-of-thought reasoning in the LLM's output. While it is well-known that chain-of-thought reasoning boosts LLM's performance, it is worth evaluating its contribution to the motion planning task. \n\n2. Also, there should be an ablation study to evaluate the benefit of having the auto-generated chain-of-thought reasoning labels during fine-tuning. While the proposed method to auto-label the chain-of-thought reasoning through hypothetical ego-trajectory is sensible, it is not guaranteed to generate the ground-truth reasoning process (i.e., identifying the actual causal objects and their relations to the ego agents). The authors claimed that this strategy worked well in practice. I wonder how the authors evaluated the quality of the auto-generated labels and drew such a conclusion. There should be numerical results to examine the quality of the auto-generated labels, and an ablation study to validate that the fine-tuning process indeed benefits from the plausibly noisy and inaccurate reasoning labels. \n\n3. The GPT model is only prompted with a simplified textual description of the traffic scene, e.g., without maps, historical trajectories of the objects, or predicted future trajectories over multiple timesteps. It is quite surprising that the GPT model can surpass carefully designed learning-based planners by a large margin in L2 errors. It is rather counter-intuitive as the information currently missing (e.g., maps, historical contexts, future trajectories) is normally considered important for motion planning in autonomous driving. The authors should provide an in-depth analysis and pinpoint the scenarios where GPT-Driver has clear advantages against SOTA methods and cases where GPT-Driver suffers. Only showing the average L2 errors and collision rates could be misleading, as the average statistics highly depend on the data distribution."
            },
            "questions": {
                "value": "1. Could the authors clarify how the hypothetical ego trajectory is generated? Whether an object is identified as critical seems to highly depend on the hypothetical ego trajectory. The authors should discuss how they designed the generation algorithm and adjusted the hyperparameters. \n\n2. Is the motion planning performance evaluated with the most likely output sequence? How stable and reliable is the GPT-Driver in generating sensible reasoning processes and trajectories? Is it able to account for multi-modality in driving behavior?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4601/Reviewer_FVv6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4601/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793305779,
        "cdate": 1698793305779,
        "tmdate": 1699636438841,
        "mdate": 1699636438841,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ogLG7Hjl36",
        "forum": "SXMTK2eltf",
        "replyto": "SXMTK2eltf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_cPYB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4601/Reviewer_cPYB"
        ],
        "content": {
            "summary": {
                "value": "The authors present a novel method for motion planning in the context of autonomous driving, where they propose to use GPT to both output the motion plan and to explain the reasoning behind it. They fine-tune the GPT model using textual representation of the surrounding context and the output motion plan, and show that the method compares very positively when compared to the existing state-of-the-art."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- A very relevant problem being evaluated.\n- Interesting and novel approach being proposed.\n- Promising experimental results."
            },
            "weaknesses": {
                "value": "- The method does not seem to be very feasible for online execution.\n- The method seems to critically depend on the existing SOTA methods as its integral part, making the overall system quite complex.\n- The experimental section can be improved."
            },
            "questions": {
                "value": "I found the work quite interesting, and the combination of the motion planner with GPT seems like a neat idea (although not that novel at this point). However, the method seems far from being actually applicable in the real world, which the authors don't really explore or address (beyond a very brief explanation in Section 4.6 that seems insufficient and handwavy). Moreover, the explanations of the method can be improved significantly, and the methodology itself seems quite complex and dependent on the existing SOTA methods.\nDetailed comments can be found below:\n- The authors should fix the format of the references. Instead of \"P3 (Sadat et al., 2020)\" they use \"P3 Sadat et al. (2020)\" throughout the work, which is incorrect and adds some confusion in several places.\n- Figure 1 is not referenced in the text.\n- The method assumes the existing strong method for perception and prediction, which seems like quite a large requirement. The input to GPT assumes detections and their predicted trajectories, which seems to add quite a lot of complexity (both from the training and inference standpoint).\n- Related to this, the authors don't really do an ablation study of the perception/prediction module, which would give an indication of how robust is GPT to this part of the methodology.\n- In eq (2) the authors say that the input to their model is a map, yet that is not the case as they don't provide the map to the model.\n- Later they say that their model can indeed take the map as an input, but given that they represent all inputs as a text it is far from clear how can that be done.\n- In Section 4.2 the authors say that other approaches depend on various heterogeneous inputs \"which makes their systems intricate and time-consuming\", yet the proposed method also depends on the same inputs since it depends on UniAD. So the authors are not being really honest in this case.\n- In Section 4.3 it is unclear if the authors use fully trained UniAD for generating input strings for their method, or if they use partially trained UniAD. This should be clarified.\n- Some sort of latency analysis should be provided, beyond just a handwavy explanation from Section 4.6. This is important for the practical application of their method and is something that the authors should explore."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4601/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811990459,
        "cdate": 1698811990459,
        "tmdate": 1699636438749,
        "mdate": 1699636438749,
        "license": "CC BY 4.0",
        "version": 2
    }
]