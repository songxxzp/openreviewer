[
    {
        "id": "RQh6UKadVn",
        "forum": "PfaPgIQTul",
        "replyto": "PfaPgIQTul",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_DLUu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_DLUu"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a training scheme for neural networks to approximate\nviscosity solutions of HJB equations. This presents a principled\napproach to optimal control in continuous-time deterministic RL\nsettings, overcoming the curse of dimensionality incurred by existing\nviscosity solution methods that rely on space\ndiscretization. Experiments on classical control environments with\nsmall timesteps are conducted, and the authors both demonstrate\ndesirable performance of their proposed method and identify the\nremaining challenges."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I found the approach presented in the paper to be interesting. While\nit is based on an existing approximation scheme for viscosity\nsolutions, I have never seen this applied to RL or general function\napproximation methods for solving HJB equations. The approach is\nsensible, and highlights an alternative paradigm to value learning\nthat replaces bootstrapping with PDE solving (using something like a\ncollocation method, as I understand it). I really appreciate how the\nauthors identified the remaining challenges surrounding their\napproach, which seems to provide nice motivation and direction for\nfuture work. I generally enjoyed learning about the proposed method,\nand found the scheduling and regularization technique interesting."
            },
            "weaknesses": {
                "value": "The most major issues for me are:\n1. The PINN method does not perform as well as existing DTRL methods\n   (or at least PPO) in settings that require function\n   approximation. While I appreciate that the authors give some\n   insight about why that may be the case (and ideas for future\n   research towards bridging the gap), I wish there was more\n   motivating results: even if the highlighted issues with the\n   approach are solved, what benefits should we expect to see relative\n   to DTRL algorithms? Particularly, it would have been nice to see\n   some results from the PINN method trained on much more data (i.e.,\n   to overcome the uniform sampling issue), to visualize the benefits\n   we can expect if we eventually find a more efficient training\n   scheme.\n2. While the $\\epsilon$ schedules that are presented seem intuitively\n   reasonable, it would have been nice to see more discussion and/or\n   analysis about those in the paper. I understand that space is\n   limited, but 5 pages are spent before the method is even\n   presented. Is there a theoretically principled way to choose the\n   $\\epsilon$ schedule, or is there a principled way to quantitatively\n   compare them?\n\nWhen referring to the HJ-DQN algorithm (Kim et. al, 2021), it says\n\"this approach is limited to Lipschitz continuous control\". I am\nfamiliar with this paper so I know what this means, but I definitely\nthink it is worth clarifying further, since \"Lipschitz continuous\ncontrol\" can be interpreted in at least a few different ways. On this\nnote, is this really a limitation? Controls that vary smoothly in time\nare often desirable.\n\nCitations for Definition 3.1 and Lemma 3.1 should be given.\n\nIt should be made more clear why you call some HJB solutions \"bad\" vs\n\"good\".\n\n## Minor issues\nPage 3, center, \"An other\" should be \"Another\".\n\nPage 3, just above section 3, \"estimations of value function\" should\nbe \"estimations of value functions\".\n\nJust above section 3.3, it says \"the value function $V$ is often\nnon-smooth, and only continuous on $O$\". I think it would read better\nto be more explicit about the problem here, for instance,\nby explicitly saying that the value function may be non-differentiable\non $O$, and therefore cannot solve the HJB equation in the familiar sense.\n\nWhat is the purpose of Figure 2 (middle)?\n\nTable 1 is hard to read, there should at least be horizontal lines\nto separate environments."
            },
            "questions": {
                "value": "The paper says that the work of Darbon et. al 2023 \"work with min-plus\nalgebra\", what does that mean? What types of optimal control problems\nis it not suitable for?\n\nIn equation 7, what is $\\nabla^2_x$? Is that the Laplacian? Likewise,\njust below, what is $\\nabla^2_{xx}$? What is the significance of the\nRHS in equation 7, can we choose other \"perturbations\" instead? How\ncan you know if the RHS in equation 7 converges to 0 when\n$\\epsilon\\to 0$?\n\nAt the bottom of page 5, it says \"dynamic programming approaches are\nable to find the solutions of the HJB equation that are intrinsically\nviscosity solutions\" -- what does \"intrinsically viscosity solutions\" mean?\n\nWhy does PPO seemingly scale better than the PINNs method? Is this\njust because PPO is specializing to regions of the state space visited\nby nearly optimal policies, whereas the PINNs method has to train on\nthe whole space? How do the methods based on the Pontryagin maximum\nprinciple that were mentioned in the related work compare?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Reviewer_DLUu"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7487/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698701400657,
        "cdate": 1698701400657,
        "tmdate": 1699636903613,
        "mdate": 1699636903613,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2LPZhaLQ1b",
        "forum": "PfaPgIQTul",
        "replyto": "PfaPgIQTul",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_N25p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_N25p"
        ],
        "content": {
            "summary": {
                "value": "The authors introduced a numerical method for solving continuous time HJB equations in a deterministic control and reward setting. The method depends on convergence theory of viscosity solutions to value function, a core Lemma that the authors elaborated in a very clear and accessible way. With three different types of decaying schemes for a core parameter $\\epsilon$, the authors used PINN/PDE solvers to solve a sequence of PDEs that approximate the interested optimal control problems. Numerical experiments demonstrate the introduced method is effective on some of the classic control tasks, although there are challenges to be addressed in the continuous time setting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors give a very detailed and clear introduction of optimal control problems in continuous time and the necessity of involving viscosity solutions. This (and the Appendices) makes the manuscript very easy to understand for non-experts in control theory. The authors also provide plentiful details on the numerical experiments, such as how to blend different $\\epsilon$ decaying schemes, what types of NN are more suitable for learning viscosity solution, etc. Numerical experiments, although for simple classic tasks, demonstrate acceptable improvements over other SOTA RL/optimal control methods."
            },
            "weaknesses": {
                "value": "The main weakness of this manuscript is its novelty and magnitude of its contributions in terms of both theoretical and experimental aspects. The details are listed below:\n\n1. The main theoretical foundation is Lemma 3.1, which is a well-known results in optimal control community. For clarity, the authors have to spend more than half of the main context introduce this Lemma. This left the only novelty in the algorithm design where the authors introduced three $\\epsilon$ decay schemes and the PDE solver (the latter of which has also been widely studied by PDE people). The overall significance of this work is therefore limited.\n\n2. If the authors want to enhance the theoretical contribution of this work, I would prefer to see how they would address the convergence in more details. Lemma 3.1 is a general result, but in the PINN setting, what conditions on the NN can guarantee convergence and how to characterize approximation error or convergence speed, etc. These are challenging theoretical questions if the authors want to go multiple steps further than just citing Lemma 3.1 as the foundation of their method.\n\n3. If the authors want to focus on the experimental aspect of their approach, I believe high dimensional control tasks may be the right playground for PINNs. The purpose of introducing NN in PDE community is for solving large dimensional problems. The value of PINN for optimal control problems are likely to be similar. Otherwise, with known dynamics and easily observable rewards (as in this work), it is relatively easy to come up with efficient functional forms to approximate value functions without PINNs."
            },
            "questions": {
                "value": "My suggestions for a more in-depth analysis from either theoretical or experimental perspective are in the above section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Reviewer_N25p"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7487/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698706176795,
        "cdate": 1698706176795,
        "tmdate": 1699636903464,
        "mdate": 1699636903464,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zxtSoltPtf",
        "forum": "PfaPgIQTul",
        "replyto": "PfaPgIQTul",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_2hDe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_2hDe"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed and testes a neural network based method for solving a deterministic Hamilton-Jacobi-Bellman (HJB) equation. The method utilizes the stability of viscosity sub(super)solution of HJB equation, and solves a sequence of PDEs to approximate the solution to HJB. Each PDE is solved by PINN method. Numerical experiments show that the proposed method outperforms PPO and A2C, but not the dynamic programming when it can be applied."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "A new method for solving deterministic HJB, showing success in limited numerical experiments."
            },
            "weaknesses": {
                "value": "Generally, there lacks theoretical study for numerical solutions to a PDE. To ensure the necessary convergence, the conditions of Lemma 3.1 have to be verified, most importantly $W^\\epsilon$ converges to $W$ uniformly. What presented in the subsection of $\\epsilon$-schedulers is not adequate for this purpose. \n\nThere are also several families of numerical methods for solving HJB, not limited to the ones that the authors listed (FD,FEM) and can be easily found in literature(such as level set , the method proposed here need to be compared to them for effective and accuracy. \n\nThe numerical experiments are limited to a few small scale problems, some large scale, high dimensional examples can certainly improve the quality of the paper."
            },
            "questions": {
                "value": "Several key parameters given between equation (12) and (13) are not presented precisely, for example how to pick $k_\\epsilon$ exactly for a given problem and the definition of $N_S$.   \n\nCould numerical methods for HJB be more thoroughly surveyed and compared? See e.g. Falcone, M., Ferretti, R.: Numerical methods for Hamilton-Jacobi type equations. Handb. Numer. Anal., Elsevier/North-Holland, Amsterdam,17, 603\u2013626 (2016)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7487/Reviewer_2hDe"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7487/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698709978234,
        "cdate": 1698709978234,
        "tmdate": 1699636903351,
        "mdate": 1699636903351,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lAXCXUvRvP",
        "forum": "PfaPgIQTul",
        "replyto": "PfaPgIQTul",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_S2st"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7487/Reviewer_S2st"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new way of solving Hamilton-Jacobi-Bellman (HJB) equation using the framework of Physics Informed Neural Network (PINN). To find the viscous solution, which is the optimal value function, this paper proposes an iterative algorithm to gradually decrease the epsilon for approximation.\nThe proposed algorithm works well in the pendulum task, but a problem in applying the method for higher dimension systems was identified."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This paper nicely reviews the concept of the viscous solution of HJB equation and presents a novel way of obtaining the solution by PINN, which utilized the automatic differentiation capability of recent deep learning tools."
            },
            "weaknesses": {
                "value": "Although the title is \"reinforcement learning,\" this method requires an analytic model of the system dynamics and the cost/reward function to apply PINN, and the states are sampled uniformly randomly in the state space. It may be better called optimal control rather than reinforcement learning, which usually assumes that the agent explore the environment by its own policy without explicit prior knowledge of the environment."
            },
            "questions": {
                "value": "In Figure 1, why are the solutions have a dip at the origin, where the value function should be maximum. Is there any issue with dealing with the terminal cost/reward?\nFor people new to PINN, isn't it better to include the network architecture diagram with inputs, outputs, and how derivatives are combined for the objective function?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7487/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699004589473,
        "cdate": 1699004589473,
        "tmdate": 1699636903221,
        "mdate": 1699636903221,
        "license": "CC BY 4.0",
        "version": 2
    }
]