[
    {
        "id": "27tBUjBYsR",
        "forum": "ChNy95ovpF",
        "replyto": "ChNy95ovpF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_9fkA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_9fkA"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method called DebateGPT, which uses data generated through multi-agent debate to  fine-tune GPT-3.5. The authors show that DebateGPT achieves comparable performance to GPT-4 on various tasks, including instruction following, commonsense reasoning, and mathematics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method achieves impressive results, with DebateGPT showing comparable performance to GPT-4.\n2. The paper provides detailed explanations and analysis of the proposed method."
            },
            "weaknesses": {
                "value": "1. If I'm understanding correctly, the Multi-Agent debate method used to generate data seems to following the approach in [1]. However, it's important to note that when comparing it to the baseline models, we're only looking at GPT-3.5 and GPT-4, and there's no direct mention of [1]. \n2. In the main contributions of the paper, it claims to \"offers a more economical alternative to leveraging models like GPT-4\". However, when we look at Figure 6, we see that both options are similarly priced. Furthermore, taking into account their divergent performance makes it difficult for me to fully support this claim.\n\n[1] Improving Factuality and Reasoning in Language Models through Multiagent Debate. https://arxiv.org/pdf/2305.14325.pdf"
            },
            "questions": {
                "value": "1. Which LLMs are included in the Multi-Agent used for data generation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4835/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4835/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4835/Reviewer_9fkA"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4835/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698480652193,
        "cdate": 1698480652193,
        "tmdate": 1699636466993,
        "mdate": 1699636466993,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nacazTrmc0",
        "forum": "ChNy95ovpF",
        "replyto": "ChNy95ovpF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_8M4v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_8M4v"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces DebateGPT, which fine-tuned GPT-3.5 using a dataset generated through multi-agent debate, reducing the necessity for resource-intensive human intervention. By augmenting this method with techniques such as summarization, confidence scoring, and data refinement, the dataset's quality sees significant enhancement. DebateGPT demonstrates performance levels on par with GPT-4 across a diverse range of tasks, including domains like commonsense reasoning and mathematics. Notably, DebateGPT's distinguishing feature lies in its relatively compact size compared to GPT-4, all while relying on a modest dataset, thereby challenging the prevailing notion that larger models are heavily reliant on extensive human feedback."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "They employ a multi-agent debate approach to generate the dataset, and through the incorporation of elements like confidence scoring, summarization, and data cleaning, they demonstrate a noticeable enhancement in dataset quality when compared to the GPT-3.5 baseline."
            },
            "weaknesses": {
                "value": "The primary contribution of this paper lies in its application of multi-agent debate for dataset creation. The experiments on dataset quality reveal that the introduction of multi-agent debate, along with summarization, confidence scoring, and data cleaning, results in an improved dataset quality. However, it's worth noting that the utilization of confidence scores and filtering techniques is a standard practice in the field of dataset augmentation, lacking any groundbreaking innovation apart from the incorporation of multi-agent debate. To make a meaningful assessment of its effectiveness, more comprehensive experiments should be conducted to compare these approaches with existing methods in data augmentation.\n\nFurthermore, the paper exclusively reports fine-tuned results on the dataset it generated. It remains unclear how fine-tuning the model on baseline datasets would perform in comparison. This omission prevents a thorough understanding of the extent to which a dataset with better quality can impact downstream tasks.\n\nAnother important consideration is the potential impact of fine-tuning on the model's generalization abilities for tasks beyond those presented in the paper. This aspect warrants further investigation to ascertain the overall implications of the fine-tuning process."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4835/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698514564830,
        "cdate": 1698514564830,
        "tmdate": 1699636466911,
        "mdate": 1699636466911,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dYrZBvbqPA",
        "forum": "ChNy95ovpF",
        "replyto": "ChNy95ovpF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_x4r2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4835/Reviewer_x4r2"
        ],
        "content": {
            "summary": {
                "value": "Pros: \n1. The author proposes a novel framework that utilizes multi-agent debate for data generation and supervised training. Multiple interesting features could be seen such as the confidence score, summarization, and cleaning.\n2. The results presented in the paper show that the model has increased performance on various benchmarks including commonsense reasoning, mathematics, factuality, etc.\n\nCons: \n1. The supervised data seems composed of questions and answers given by the multi-debate framework, rather than multi-agent debate demonstrations. It does not make so much sense to me as there are incorrect answers in the answers as well, right? (Plz correct me if any falsehood) Have the authors tried using answers given by human annotators?\n2. The author claims that the DebateGPT-3.5 is an economical alternative for GPT4, which could easily regarded as over-hyping (I am NOT doubting the results). However, the author should present more enriched results on more benchmarks.\n\nQuestions: \n1. Human-in-loop is so expensive,  utilizing other methods including debate might be a panacea, but need to carefully investigate. Does the multi-agent debate framework apply to the evaluation in the experiments?\n2. The confidence score sounds interesting, however, the reliability of the scalar given by LLM is still worth doubting (an empirical concern from the reviewer), has the author done any faithfulness investigation on that?\n3. The summarization makes sense to me, however, the answers from other agents will be compressed into a short answer, which inevitably brings a loss of information, has the author tried to handle that problem?\n4. agents only debate one time before issuing the final answer. How could they possibly converge to an answer with only ONE iteration? It sounds a little bit brutal to simply generalize the results before multi-iteration convergence (Du et al., 2023)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "See summary"
            },
            "weaknesses": {
                "value": "See summary"
            },
            "questions": {
                "value": "See summary"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4835/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698930447706,
        "cdate": 1698930447706,
        "tmdate": 1699636466837,
        "mdate": 1699636466837,
        "license": "CC BY 4.0",
        "version": 2
    }
]