[
    {
        "id": "GM8zc7Imq2",
        "forum": "K4fd38VWHt",
        "replyto": "K4fd38VWHt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes ScoreAG, a novel method that leverages score-based generative model to find adversarial samples. State-of-the-art methods can generate examples under the l-p-norm constraints, but such adversarial examples may be unrealistic due to the ignorance of semantic difference. To overcome these, the proposed ScoreAG introduces the diffusion models into adversarial example generation. Such score-based method is evaluated on CIFAR and TinyImagenet in its capability to synthesise from scratch, transform existing ones and purification to counter attack. Their results reveal that ScoreAG outperforms baselines in attacking effectiveness and defence competence after adversarial purification."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "By introducing ScoreAG, the authors bridge the gap between adversarial attack methods and score-based generative models. This intersection is not only innovative but also timely. In contrast to the limitations seen with traditional l_p norm-based methods, ScoreAG addresses the key issue of ignoring semantic shifts during image classification tasks. This addresses a crucial gap in existing methods, ensuring that adversarial examples remain contextually relevant and semantically consistent. \n\nMoreover, the flexibility of ScoreAG is evident in its ability to not only generate adversarial examples from pre-existing images but also to craft them from scratch. This versatility extends to its capability to purify blurry/noised samples, further emphasizing its practical utility. \n\nBy ensuring that ScoreAG aligns closely with real-world scenarios, the authors have underscored the framework's potential impact, emphasizing its relevance in practical settings. Overall, ScoreAG, unites diffusion models and adversarial attack, and offers tangible solutions for semantic-preserving image alterations."
            },
            "weaknesses": {
                "value": "Interaction between Different Tasks: The authors could explore and elucidate the interactions between different tasks such as GAS, GAT, and purification. Specifically, it would be insightful to understand the impact of applying purification post-GAS or GAT. A discussion on whether purification enhances the robustness of the adversarial examples generated by GAS or GAT would be valuable. This could provide readers with a deeper understanding of the potential synergies or trade-offs between these tasks.\n\nSemantic Preservation: The paper could benefit from a clearer explanation and justification of the semantic requirements (\u03a9) used in the experiments. The methodology and criteria used to ensure semantic coherence and relevance in the generated adversarial examples should be thoroughly discussed. Consider discussing and comparing the semantic perturbations introduced by ScoreAG with those from other image-based semantic perturbation adversarial attack methods, such as the one mentioned (\"SemanticAdv: Generating Adversarial Examples via Attribute-conditioned Image Editing\"). Including detailed results or comparisons concerning semantic preservation could bolster the reliability and credibility of the proposed method.\n\nComparative Analysis in Human Study:  The human study results presented in Table 4 only focus on ScoreAG without including comparisons with the baseline methods used in other parts of the evaluation. For a more comprehensive understanding and evaluation, it would be beneficial to include a comparative analysis showcasing the performance of ScoreAG against other established methods. Consider including a discussion on the variance in naturalness or the extent of perceptual shifts observed across different methods. This could provide a more nuanced view of ScoreAG\u2019s performance in maintaining image naturalness while generating adversarial examples. \n\nOverall, while the paper presents an innovative approach in ScoreAG and provides a comprehensive set of experiments, there are areas where it could go deeper in comparative analysis, semantic preservation, and the discussion on task interactions."
            },
            "questions": {
                "value": "- Could you provide results and discussions comparing ScoreAG to other baseline methods in the human study section?\n\n- Could you elaborate on the relationship between different tasks such as GAS, GAT, and purification within the ScoreAG framework? Can they be integrated into an ensemble for attack or defense?\n\n- How does ScoreAG ensure that the generated adversarial examples maintain semantic coherence and relevance?\n\n- Could you elaborate the perceptual shifts or changes in the naturalness of adversarial images from ScoreAG compared to other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698682559543,
        "cdate": 1698682559543,
        "tmdate": 1699636949905,
        "mdate": 1699636949905,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2rwAQN0voA",
        "forum": "K4fd38VWHt",
        "replyto": "K4fd38VWHt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_rCh2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_rCh2"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes ScoreAG, a framework for generating unrestricted adversarial examples using score-based generative models with diffusion guidance. The key idea is to leverage the generative capabilities of these models to synthesize new adversarial images from scratch (GAS), transform existing images into adversarial ones (GAT), and purify images to enhance classifier robustness (GAP)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written and the proposed method is novel. Generating semantic-preserving adversarial examples beyond standard threat models is an important research direction, and the use of score-based diffusion models is a promising approach. The experiments are extensive, comparing ScoreAG to several state-of-the-art attacks and defenses across multiple datasets. The results demonstrate ScoreAG's effectiveness in crafting unrestricted adversarial examples."
            },
            "weaknesses": {
                "value": "- The notion of \"unrestricted\" adversarial examples needs more discussion. While ScoreAG does not use an explicit lp norm, the samples are still constrained to the manifold learned by the generative model. Analyzing the diversity/range of examples is important.\n\n- More analysis is needed on why ScoreAG outperforms the other diffusion-based attack DiffAttack. The reasons are not fully clear.\n\n- The lack of certified or provable robustness guarantees for the purified models is a limitation. Evaluating security empirically is difficult.\n\n- The human study provides useful insights but is limited in scope. Expanding this to quantify semantic similarity and diversity of examples would strengthen the evaluation.\n\n- Lacking important references like \"Content-based Unrestricted Adversarial Attack\""
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740521919,
        "cdate": 1698740521919,
        "tmdate": 1699636949785,
        "mdate": 1699636949785,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZLDUYCGbDw",
        "forum": "K4fd38VWHt",
        "replyto": "K4fd38VWHt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_dx4f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_dx4f"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel framework called Score-Based Adversarial Generation (ScoreAG) for generating adversarial examples beyond the constraints of $\\ell_p$-norms. The authors leverage advancements in score-based generative models to synthesize semantic-preserving adversarial examples, transform existing images into adversarial ones, and purify images to achieve adversarial robustness. They conduct an empirical evaluation on CIFAR-10, CIFAR-100, and TinyImageNet datasets to demonstrate the effectiveness of ScoreAG."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The main contribution of this paper is the introduction of Score-Based Adversarial Generation (ScoreAG) and the following three uses of it: Synthesis (Generative Adversarial Synthesis, GAS), transformation (Generative Adversarial Transformation, GAT), and purification (Generative Adversarial Purification, GAP). This paper is well-structured and the method is described clearly."
            },
            "weaknesses": {
                "value": "This work is subject to several weaknesses that need to be addressed. \n\n1. Although GAS aims to generate the adversarial example from scratch that would be misclassified by the classifier while preserving the semantics of the truth class, it is disappointing to see that even human fails to classify the adversarial examples. As shown in Table 4, Human accuracy on the adversarial synthetic images is only 70%, this results do not support the argument that it preserves the semantics of a certain class. \n\n2. The paper argues that GAS provides a more *comprehensive robustness assessment*, but lacks quantitative results to support this assertion. \n\n3. A comparison with similar work [1] should be provided, along with an explanation of the differences in approach and findings. \n\n4. GAT transforms clean images into adversarial examples, but the comparison is limited to DiffAttack. Including other unrestricted attacks [2, 3, 4] in the comparison would provide a more thorough assessment. Additionally, reporting the mean and standard deviation for the results would enhance statistical robustness.\n\n5. It is unclear what the \"ScoreAG\" column represents in Table 2. If it indicates GAP, it is unclear what the given adversarial image ($\\mathbf{x}_\\text{ADV}$) is used to purify. If it is GAT, isn\u2019t the higher robust accuracy representing the weaker attack efficacy? Further clarifications are needed to understand the evaluation\n\n6. The robustness results (Table 2) should be compared with more baselines, including both attacks and defenses, such as DiffAttack and [1, 2, 3, 4]. Additionally, results should be reported for all datasets, not just CIFAR-10, to provide a comprehensive view.\n\n7. The claim that GAP further enhances the adversarial robustness of the model is not sound. Since, generally, adversarial robustness is to evaluate the model\u2019s accuracy under perturbations, the purification seems to serve merely as a defense approach. Therefore, it should be compared with other adversarial defense methods, such as [5, 6].\n\n8. In Section 4.2, the author argues that the $\\ell_p$-bounded methods display noticeable noisy fragments. However, I think it is because of cherry-picking. Also, I do not understand where the statement \u201c*the removal of a small fish \u2014 which prove to be important classification cues*\u201d comes from.\n\n9. The authors did not submit the code for review. If the authors want to avoid releasing publicly before acceptance, submitting to AC privately is a viable option.\n\n10. The practical application of the proposed approach should be discussed. How can it be used in real-world scenarios? How is it different from other approaches in practice?\n\n11. The visualization on ImageNet seems to have high quality, it would be great to report the experimental results on it to demonstrate the generalizability of the proposed approach.\n\n>   [1] Chen et al. AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models (ICCV 2023)\n> \n>   [2] Hsiung et al. Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations (CVPR 2023)\n>\n>   [3] Laidlaw et al. Perceptual Adversarial Robustness: Defense Against Unseen Threat Models (ICLR 2021)\n>\n>   [4] Bhattad et al. Unrestricted adversarial examples via semantic manipulation (ICLR 2020)\n>\n>   [5] Frosio and Kautz. The Best Defense is a Good Offense: Adversarial Augmentation against Adversarial Attacks (CVPR 2023)\n>\n>   [6] Cohen et al. Certified Adversarial Robustness via Randomized Smoothing (ICML 2019)"
            },
            "questions": {
                "value": "Please refer to the weakness. In addition, please also address the following questions.\n\n1. Table 1 only considers one model architecture (WRN-28-10), please provide more models to verify the efficacy of the proposed method.\n2. What is the computational cost of ScoreAG compared to other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792681449,
        "cdate": 1698792681449,
        "tmdate": 1699636949680,
        "mdate": 1699636949680,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UY8qAi5a0K",
        "forum": "K4fd38VWHt",
        "replyto": "K4fd38VWHt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
        ],
        "content": {
            "summary": {
                "value": "This work presents a framework, ScoreAG, designed for adversarial example generation beyond \\mathcal{l}_{p}-norm constraints. By integrating Score-based Generative Modelling with Diffusion Guidance techniques, ScoreAG effectively addresses the limitations of conventional adversarial generation approaches. By applying various conditional guidance terms in the reverse-time SDE process, ScoreAG can 1) synthesize adversarial images (GAS), 2) transform adversarial images (GAT), and 3) purify adversarial images (GAP). Experimental results show that ScoreAG can outperform leading benchmarks in adversarial attack and defense, generating adversarial examples while preserving their original semantic meaning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-organized and easy to follow.\n\n2. Conducting adversarial attacks using semantic-bounded examples offers an interesting viewpoint on robustness evaluation.\n\n3. As demonstrated in the experimental section, the proposed framework attains promising performance across three tasks."
            },
            "weaknesses": {
                "value": "1. Some formulas in this paper were derived incorrectly, such as equation 7 on page 4. The authors should check the methodology section to ensure correctness.\n\n2. The authors compare the attack effectiveness of GAT with other benchmark methods in Section 4.1. Given that generation efficiency is also an essential factor in evaluating the effectiveness of adversarial attacks, it is recommended that the authors add a discussion on the efficiency of adversarial sample generation to this part of the experiment.\n\n3. In Table 2, the evaluation results are displayed for Cifar-10. To ensure the applicability of the proposed method, evaluations on datasets of more categories or higher resolution, such as Cifar-100 and TinyImageNet, are advisable. Experimental results in Table 2 also compare the efficacy of various adversarial training and purification methods. However, the distinct architectures used by these methods raise concerns about the fairness of this comparison.\n\n4. This paper lacks details of the experimental implementation environments, which limits the reproducibility of the proposed method.\n\n5. As pointed out in Section 4.3, some misclassification cases are due to the low resolution of Cifar-10\u2019s images, indicating that employing higher-resolution datasets for testing would have been more appropriate."
            },
            "questions": {
                "value": "1. How time-efficient is the method you\u2019ve proposed?\n\n2. With the distinct architectures used by methods presented in Table 2, can we still view this comparison as fair?\n\n3. Why not use images from higher-resolution datasets for testing in Section 4.3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827530095,
        "cdate": 1698827530095,
        "tmdate": 1699636949549,
        "mdate": 1699636949549,
        "license": "CC BY 4.0",
        "version": 2
    }
]