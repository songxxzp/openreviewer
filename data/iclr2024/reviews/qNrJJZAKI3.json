[
    {
        "id": "TywQCUSi08",
        "forum": "qNrJJZAKI3",
        "replyto": "qNrJJZAKI3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a dataset for retinal disc/cup segmentation with several pre-defined attributes, which should be useful for studying the fairness problem in the medical domain. Furthermore, the authors set a baseline for the problem and define the evaluation metrics in this scenario. Overall, this work is sound and meaningful."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "[1] Providing a dataset for fairness-related research is meaningful for the current community, along with its baseline and evaluation setting.\n\n[2] Good writing and clear motivation"
            },
            "weaknesses": {
                "value": "[1] ICLR might not be the best place for this paper. Other medical journals or conferences would be more suitable.\n\n[2] There are many evaluation ways to assess the fairness problem. The selected metrics might not be the most suitable one. Please elaborate more on the motivation of baseline setting and evaluation.\n\n[3] Some current works should be included to make the experiments sufficient. See: FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification\n\n[4] Since most of the attributes are only for the patient level, why use the pixel-wise weights?"
            },
            "questions": {
                "value": "See the above weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Responsible research practice (e.g., human subjects, data release)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This work proposed a retinal dataset with several attributes, which should be further checked from the ethics view."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697507856167,
        "cdate": 1697507856167,
        "tmdate": 1699636900589,
        "mdate": 1699636900589,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uQKzOl8mxK",
        "forum": "qNrJJZAKI3",
        "replyto": "qNrJJZAKI3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_b2i2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_b2i2"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a fundus image dataset for benchmarking the fairness of medical image segmentation methods, which is the first dataset and benchmark in this field. The authors also proposed to rescale the loss function with the upper training error-bound of each identity group to tackle the fairness issue."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Novel Dataset: The paper introduced FairSeg, a new dataset for medical image segmentation with a focus on fairness. The creation of such a dataset is valuable as it addresses a gap in the current availability of medical datasets with fairness considerations.\n\n- Fairness-Oriented Methodology: The authors proposed a fair error-bound scaling approach and an equity scaling metric. These methods represent an advanced effort to integrate fairness directly into the model training process, which could lead to more equitable healthcare outcomes.\n\n- Open Access: I like that the author released the dataset and code for reproducibility and further research, which is a strong aspect of this work."
            },
            "weaknesses": {
                "value": "- Dice and IoU are equivalent (https://www.sciencedirect.com/science/article/pii/S1361841521000815), which are not necessary to be reported simultaneously. Instead, please add NSD which is suggested by metrics reloaded (https://arxiv.org/abs/2206.01653).\n\n- nnUNet is still the state-of-the-art in many segmentation tasks. It would be great to evaluate it on your dataset."
            },
            "questions": {
                "value": "- The dataset was released as npz format. Could you please also release the original format?\n\n- It would be great if you could release the trained models as well.\n\n- Where do you plan to host this benchmark? CodaLab could be a good platform."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698784223461,
        "cdate": 1698784223461,
        "tmdate": 1699636900403,
        "mdate": 1699636900403,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "w9QoDjt3kw",
        "forum": "qNrJJZAKI3",
        "replyto": "qNrJJZAKI3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_5cUh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_5cUh"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors introduced the new FairSeg dataset, designed to address fairness concerns in the domain of medical segmentation. Their innovative methodology centers on a fair error-bound scaling technique, which recalibrates the loss function by considering the upper error-bound within each identity group. Furthermore, they designed a new equity-scaled segmentation performance metric to facilitate fair comparisons between different fairness learning models for medical segmentation. Extensive experimentation underscores the efficacy of the fair error-bound scaling approach, demonstrating either superior or comparable fairness performance when compared to state-of-the-art fairness learning models. Furthermore, The related dataset and code are both made publicly accessible by the authors."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "+ The paper is well-written and easy to follow. \n+ The proposed framework is technically sound.\n+ The experiments are comprehensive."
            },
            "weaknesses": {
                "value": "There is no visualization comparison between different methods."
            },
            "questions": {
                "value": "1. In equation (1), a parenthesis is missing in the formula.\n2. The authors proposed a new the Dice loss with a novel Fair Error-Bound Scaling mechanism, however there are experiment results to show the differences between the new dice loss and common one."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698850170617,
        "cdate": 1698850170617,
        "tmdate": 1699636900064,
        "mdate": 1699636900064,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uYaRh16bmB",
        "forum": "qNrJJZAKI3",
        "replyto": "qNrJJZAKI3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a publicly available medical fairness segmentation dataset (FairSeg) that contains 10,000 subject samples of 2D SLO Fundus images. The paper also proposes equity-scaled segmentation performance metrics to facilitate fair comparisons."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The fairness concern is an important topic, especially in medical images and the lack of segmentation dataset is a big issue. The motivation of the proposed dataset is strong.\n\n2. The dataset contains a large amount of segmentation ground truths (10,000) and is well evaluated by authors with several SOTA learning algorithms.\n\n3. As described by the authors, the segmentation seems to undergo a rigorous process including a hand-graded annotation by a panel of five medical professionals after initial registration."
            },
            "weaknesses": {
                "value": "1. The accuracy of the Nifty reg needs to be investigated since it might not be the SOTA for image registration."
            },
            "questions": {
                "value": "1. Why validation set is not constructed/used in selecting models in training?\n\n2. It would be helpful to report Hausdorff distance and average surface distance along with Dice to better evaluate the methods.\n\n3. The details of how standard deviation is computed need to be elaborated. Is it computed across the mean of for each group?\n\n4. How is the training/testing split performed? Is it just randomly sampled without considering sensitive attributes at patient level?\n\n5. It would be helpful to discuss the importance of registration in preprocessing using NiftyReg."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699233898000,
        "cdate": 1699233898000,
        "tmdate": 1699636899772,
        "mdate": 1699636899772,
        "license": "CC BY 4.0",
        "version": 2
    }
]