[
    {
        "id": "5WjUYJDxZ7",
        "forum": "ale56Ya59q",
        "replyto": "ale56Ya59q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_KXQH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_KXQH"
        ],
        "content": {
            "summary": {
                "value": "Authors propose to use VQ-VAE in self-supervised audio quality estimation and enhancement based on solely training with clean audio. Idea is to correlate quantization error in the latent space to quality metrics. Speech enhancement is then performed by the way of finetuning using the adversarial noise. So still no need to feed in noisy samples."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Key idea of using the quantization error in VQ-VAE as the qualityt metric is novel as far as I know and also the idea is quite neat. I like it a lot. Enhacement idea based on this innovation is also quite nice. Experimental results do support the hypotheses."
            },
            "weaknesses": {
                "value": "- Very little theoretical analysis is found in the paper. When would the proposed method work and it would fail? Can anything be said about it?\n- Key parameters are not empirically, nor theorerically assessed. Especially codebook size appears to be extremely critical parameter. \n- Significance testing should be reported for each computed correlation."
            },
            "questions": {
                "value": "- How was the commitment weight \\beta = 3 decided?\n- Basically quantization error is the measure that you are using and it for sure does make sense. It would be interesting to see whether some distrubutional arguments can be made about the quantization errors. Note that those errors are scalar quantities and thus could be easily plotted and visually inspected."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Reviewer_KXQH"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1223/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698600896669,
        "cdate": 1698600896669,
        "tmdate": 1700661473513,
        "mdate": 1700661473513,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CAhe1wQ22E",
        "forum": "ale56Ya59q",
        "replyto": "ale56Ya59q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_eoAZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_eoAZ"
        ],
        "content": {
            "summary": {
                "value": "Contributions of the paper are two-fold; first, the authors propose a speech quality measure based on the comparison of speech embeddings before and after vector quantization using a VQ-VAE. Two metrics were used for comparison: a L_2 norm and a cosine similarity metric. During the experimental phase, the authors compare the proposed metric with some previously proposed objective speech quality metrics on four data sets that contain human perception metrics.  Among the metrics used for comparison, they included SNR, PESQ, SIG, BAK, and OVR.  Based on the SNR results, the authors also suggest that the proposed method can estimate SNR in a frame-based approach. Second,  the paper presents a model distillation approach using a two steps learning process where a noise component is learned such that it minimizes the performance of the quantization process, and a second step where the encoder of the student model is trained to revert that behavior, making it more robust to noisy samples. The decoder is trained to reduce the reconstruction error, as in any denoising approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper addresses a problem of interest in the state of the art that does not have a clear solution. The proposed solution for speech quality assessment is simple, yet it could be effective. The proposed method for speech enhancement requires only clean data and the proposed adversarial training is an interesting alternative to"
            },
            "weaknesses": {
                "value": "The novelty of the paper is limited. Quality metrics comparing embedding has already been proposed in multimodal or generative contexts including speech such as the Fr\u00e9chet Audio Distance. Moreover, the authors found a low correlation between the proposed score and the quality benchmarks when the speech quality is poor, limiting the proposed measure's reliability. The results of the proposed approach for speech enhancement are still behind those of supervised models."
            },
            "questions": {
                "value": "- Notation of equations 5 and 6 is inconsistent. According to Eq. 5, Lce is a function of two arguments, but Eq. 6 does not develop it correctly. Notation in general, should be reviewed.\n- The authors should show evidence of the training stability during the proposed adversarial training. \u00bfIs there any risk that during training, the model collapses to select the same token?\n- Other adversarial training strategies suffer from the high cost of generating adversarial samples, and the proposed approach does not seem to do differently. The authors should include analyses regarding computational load and scalability.\n- The paper should also include experiments to support the claims that the proposed approach can exhibit better generalization capabilities to new domains than supervised models. Telephony speech or artificially generated speech should also be included."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Reviewer_eoAZ"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1223/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698765351318,
        "cdate": 1698765351318,
        "tmdate": 1700661816691,
        "mdate": 1700661816691,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Wt5w8fVcWv",
        "forum": "ale56Ya59q",
        "replyto": "ale56Ya59q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_DUwZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_DUwZ"
        ],
        "content": {
            "summary": {
                "value": "In this paper authors propose VQScore to measure speech quality, which is based on the quantization error of VQ-VAE. It's a self-supervised metric without paired speech and noisy data in training. Based on it, the authors propose to improve speech enhancement with self-distillation with adversarial training. Experimental results show the effectiveness of the proposed methodology."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed methodology is technical sound. Its training uses clean speech data only, and this helps reduce dependencies on noisy/clean speech pairs to develop models for speech quality measure and speech enhancement. Overall, this paper clearly describes the proposed approach, with well designed experiments and analysis."
            },
            "weaknesses": {
                "value": "I think the experimental section could be further strengthened with more details added. Please see the Questions section below."
            },
            "questions": {
                "value": "1. How to determine the values for several hyper-parameters, e.g. \\beta in equation (3), codebook size etc.\n2. For the results tables, could authors include std to show if difference is statistically significant?\n3. For Table 3, could authors add a short summary about comparing model complexity for the proposed approach vs. baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1223/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698887787753,
        "cdate": 1698887787753,
        "tmdate": 1699636048665,
        "mdate": 1699636048665,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zphhgQSiS4",
        "forum": "ale56Ya59q",
        "replyto": "ale56Ya59q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_CJHD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1223/Reviewer_CJHD"
        ],
        "content": {
            "summary": {
                "value": "This is an interesting paper about developing a self-supervised speech enhancement solution. It does not use external noise corpus and uses a variation of VQ-VAE. It focuses on developing robust encoder and decoder using adversarial training (AT). They first train a regular VQ-VAE. Authors aptly describe the main idea as, \"Once the encoder can map the noisy speech to the corresponding tokens of clean speech, or the decoder has the error correction ability, speech enhancement can be achieved.\" AT is then used to fine-tune encoder and decoder. Authors show high correlation of their proposed metric with other quality metrics (real+hand engineered)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Novelty: Authors have attempted to combine VQ-VAE and AT to create an enhancer. This is novel per my knowledge.\n2. Choice of models to compare with is good."
            },
            "weaknesses": {
                "value": "1. No downstream evaluation (diarization, speaker recognition, ASR, etc.) provided which I would expect for ICLR.\n2. I am not able to determine if high linear correlation of proposed metric is enough to say this enhancement will work on real noisy datasets. Remember the goal of enhancement is to remove noise (and other unwanted information) such that it can used on a plethora end applications. It is not just about perceptually making it better. STOI-like metrics are ignored in this work which quantifies intelligibility. Note that it is also possible to produce good sounding audio which is not very intelligible.\n3. Lack of ablation or other analysis on proposed method. Since the proposed method is the main technical contribution, I would expect it to be evaluated more robustly.\n4. Noise corpora is not used which is readily available. It would be interesting to see how using external noises can improve model performance. AT noise is not the only noise that is readily available. In fact AT is slow.\n5. If TorchaudioSquim has mismatch issues (as authors point out), it can be retrained to make it more appropriate for comparison with proposed method.\n6. Table 4,5 is missing PESQ, STOI numbers. (CHECK: https://paperswithcode.com/sota/speech-enhancement-on-demand). I dont understand how Weiner is best in SIG (real subset, Table 4). I am not sure dereverberation should be investigated in this paper. DNS1 details are also not mentioned."
            },
            "questions": {
                "value": "1. Why role of PESQ is downplayed? Authors say it is something to do with generative models but they did not expand or give citations to support this idea.\n2. Why downstream evaluation is not done? To publish a new enhancement solution in ICLR, in my personal opinion, it becomes critical."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1223/Reviewer_CJHD"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1223/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699587558937,
        "cdate": 1699587558937,
        "tmdate": 1700738881579,
        "mdate": 1700738881579,
        "license": "CC BY 4.0",
        "version": 2
    }
]