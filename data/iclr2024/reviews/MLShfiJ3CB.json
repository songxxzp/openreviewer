[
    {
        "id": "gABGY2hxhJ",
        "forum": "MLShfiJ3CB",
        "replyto": "MLShfiJ3CB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
        ],
        "content": {
            "summary": {
                "value": "This paper examines the prevalent backdoor attacks and defenses, revealing an over-optimistic perception arising from the improper adaptation of defenses from CNNs to ViTs. With appropriate inheritance from CNNs, existing backdoor attacks can be effectively mitigated. Additionally, the paper introduces a more robust attack method: a minor perturbation on the trigger significantly enhances the resilience of existing attacks against diverse defenses."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It reveals an over-optimistic perception arising from the improper adaptation of defenses from CNNs to ViTs. \n\nThis paper introduces a more robust attack method against ViTs."
            },
            "weaknesses": {
                "value": "When testing existing backdoor attacks against ViT, the authors only use CNN-based backdoor attacks without ViT-specific backdoor attack methods. Thus, the possibility exists that existing ViT-specific backdoor attacks can also evade well-adapted backdoor defenses.\n\nWhen testing existing backdoor defenses, the authors only consider purified-based backdoor defenses. How about the detection-based backdoor defenses? Are they also over-estimated?\n\nLack of enough baselines to prove the effectiveness of the proposed attack method. After proposing a new backdoor attack, the authors should compare it with SOTA backdoor attacks, especially advanced ViT-specific backdoor attacks, to show its superiority.\n\nThere is insufficient evaluation to explore whether the proposed attack can evade the SOTA backdoor defenses designed for ViT.\n\nThere is a lack of enough complex datasets, such as Imagenet, to evaluate the effectiveness of the proposed attacks."
            },
            "questions": {
                "value": "See the concerns in weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697790257367,
        "cdate": 1697790257367,
        "tmdate": 1699636484139,
        "mdate": 1699636484139,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sZQ3EanazY",
        "forum": "MLShfiJ3CB",
        "replyto": "MLShfiJ3CB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_FbZc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_FbZc"
        ],
        "content": {
            "summary": {
                "value": "This paper first conducts a comprehensive evaluation of existing backdoor attacks on ViT and reveals the reason they can bypass existing defense is due to the inappropriate use of optimizer, e.g., SGD. After refining the existing backdoor defense, the experiment results show that existing backdoor attacks on ViT will no longer achieve effective attack after defense. Therefore, the authors propose a more reliable attack by adding special adversarial perturbations into the trigger pattern. The results show their method can achieve a stable attack after some type of defense."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors revisit the existing backdoor defense methods on ViT and find that these defense methods don\u2019t work well because of the misuse of the optimizer, i.e. SGD.\n\nThe authors conduct comprehensive experiments and ablation studies."
            },
            "weaknesses": {
                "value": "The hypothesis lacks enough evidence. Firstly, the authors claim \u201cViTs are typically trained by AdamW while its fine-tuning defense is trained by SGD (NOT AdamW, maybe inheriting from CNNs). This discrepancy in optimizers raises the possibility that the perceived vulnerability of ViTs (with defense) might be overstated, i.e., the success of attacks on ViTs with defense may be questionable.\u201d However, the authors don\u2019t cite papers that use SGD to mitigate backdoors in ViT. And when transferring the defense methods on CNN to ViT, the most straightforward scheme is to use the same optimizer as when training the model, i.e., SGD for CNN and AdamW for ViT. Secondly, the authors claim that the misuse of the optimizer in fine-tuning leads to suboptimal defense performance and conduct experiments in Table 2 to show the effect of optimizers. However, the attack methods used in Table 2 are all CNN-specific attack methods. Authors should conduct experiments on ViT-specific backdoor attacks [2,3,4] because they are investigating backdoor defense on ViTs.\n\n\nThe \u201cbackdoor defense\u201d in the paper only denotes the \u201cmitigation\u201d aspect. And the design of their reliable attack is based on \u201cthe difference in the intermediate-level representations between the inputs with and without triggers\u201d. It is not clear if this attack can bypass detection technologies that don\u2019t rely on the difference in activation, such as Neural Cleanse[1] which is based on reverse engineering and outlier detection."
            },
            "questions": {
                "value": "Is the proposed attack only effective on ViT? Is it possible that it also works well on CNN, since the proposed method doesn\u2019t leverage ViT\u2019s unique features compared to CNN? \n\nSame with weakness 2, is it possible that the authors can provide results of the attacks against backdoor detection techniques such as Neural Cleanse [1]?\n\n[1] B. Wang et al., \"Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks,\" 2019 IEEE Symposium on Security and Privacy (SP), San Francisco, CA, USA, 2019, pp. 707-723, doi: 10.1109/SP.2019.00031.\n\n[2] Zheng, Mengxin, Qian Lou, and Lei Jiang. \"Trojvit: Trojan insertion in vision transformers.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[3] Zheng, Runkai, et al. \"Data-free backdoor removal based on channel lipschitzness.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.\n\n[4] Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, and Hamed Pirsiavash. Backdoor attacks on vision transformers. arXiv preprint arXiv:2206.08477, 2022a."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812757030,
        "cdate": 1698812757030,
        "tmdate": 1699636484026,
        "mdate": 1699636484026,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7LHvCuxbRg",
        "forum": "MLShfiJ3CB",
        "replyto": "MLShfiJ3CB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
        ],
        "content": {
            "summary": {
                "value": "This paper study backdoor attack on Vision Transformers. They show that existing defenses successfully defend against backdoor attacks in ViT-B and CIFAR10 dataset. Moreover, they proposed Channel Activation attack (CAT). They show that CAT attack is more effective on CIFAR10 dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "[+] CAT attack can transfer to other Vision transformers on Table 4 in CIFAR10 dataset."
            },
            "weaknesses": {
                "value": "[-] Study of backdoor attack with only CIFAR10 and single vision transformer architecture is not convincing, and any conclusion based on these limited settings won\u2019t be accurate. Note that study of backdoor attack on the Vision Transformer has been conducted before.\n\n[-] What is your thread model in your proposed attack? Do you assume that adversary have access to the model during training? Current setting is confusing to me since there are two thread models: 1. Both source and target being same model 2. Source and target are different\n\n\n[-] In ImageNet experiments, both source and target are ViT-B. Does this means that adversary has access to model architecture and its parameters. This is not a practical scenario in my opinion and limits the impact of the paper."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817799184,
        "cdate": 1698817799184,
        "tmdate": 1699636483935,
        "mdate": 1699636483935,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O6DJvhMWqi",
        "forum": "MLShfiJ3CB",
        "replyto": "MLShfiJ3CB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_FJ73"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4969/Reviewer_FJ73"
        ],
        "content": {
            "summary": {
                "value": "The article identifies shortcomings in existing defense methods against backdoor attacks on Neural Networks, specifically focusing on Vision Transformers (ViT). It highlights deficiencies in fine-tuning-based defense and pruning-based defense on ViT and proposes adjustments to enhance their performance. Additionally, the authors introduce a new backdoor attack method, CAT, designed to bypass these defenses with increased robustness. CAT involves adding special adversarial perturbations to the trigger pattern to minimize noticeable channel activation differences between benign and triggered input."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper is easy to understand.\n- The article observes the use of different optimizers for training Convolutional Neural Networks (CNNs) and ViTs, suggesting a potential overstatement of ViTs' vulnerability to attacks with defense.\n- The CAT attack seems effective in attacking the ViT models."
            },
            "weaknesses": {
                "value": "- The contributions of this paper seem incremental, especially in the defense part. The experiments indicate that optimizing the choice of optimizer, adjusting epoch numbers, and selecting appropriate granularity for pruning can improve defense performance on ViT. To apply fine-tuning-based methods to ViT, the authors adjust optimizers and epochs. However, these improvements are based on experimental trials, and there is no methodology to guide us on how to pick good hyperparameters.\n- In Section 3.2, the impact of the epoch on fine-tuning defense is explored. The curve for the first 20 epochs differs significantly from the first 20 epochs when setting the experiment to 100 epochs, particularly in the left plot of (a) left. The variability in experimental results raises concerns about the reliability of the findings, considering the potential instability.\n- Table 4 illustrates that the CAT attack method improves ASR, but the enhancement is limited, as most unsuccessful attacks do not become successful.\n- Some symbols used in the formulas lack explanations. Appendix C Figure 7 should refer to Table 7."
            },
            "questions": {
                "value": "See my comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699201744538,
        "cdate": 1699201744538,
        "tmdate": 1699636483866,
        "mdate": 1699636483866,
        "license": "CC BY 4.0",
        "version": 2
    }
]