[
    {
        "id": "hR629YTBri",
        "forum": "PEoBvQWzHo",
        "replyto": "PEoBvQWzHo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
        ],
        "content": {
            "summary": {
                "value": "Within the realm of personalized federated learning, personalized models may exhibit suboptimal performance when confronted with data from disparate domains. This paper aims to devise a criterion rooted in uncertainty assessment, serving as a means to decide whether to employ a global model or a local model. This approach is envisioned to enhance performance on both in-distribution and out-of-distribution data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The writing is of high quality.\nThe algorithm is underpinned by a solid theoretical foundation. They introduce a stop gradient operation subsequent to the analysis of the problems associated with off-the-shelf loss functions."
            },
            "weaknesses": {
                "value": "1. Novelty is limited\n\nSeems that most of the framework is directly taken from previous works, and this paper just combines and applies these in the federated learning setting as an application. For example, the Dirichlet-based model formulation is the same as [1] and [2], and the criteria are based on [3] and [4]. The only modification seems to be the stop-gradient operation based on the analysis on page 6~7.\n\n2. Cannot scale to more complex datasets like CIFAR-10\n\nFrom Table 2, it seems that there is a significant drop in the in-distribution data. An improvement from $10+%$ to $20+%$ cannot mitigate the performance drop from $70+%$ to $50+$. This challenges the model ability in this Dirichlet-based framework, especially for even more complex datasets like CIFAR-100 and Tiny-ImageNet.\n\n3. Additional computation\n\nThe authors mention that they have to use a density model to decide if they should use a global or local model. This extra step adds more work for the computer. Even if they use a simple model, the reason why the model doesn't perform well on hard datasets might be that this density model is not very strong. But making this special model stronger would require more computation.\n\n[1] Bertrand Charpentier, Daniel Z\u00fcgner, and Stephan G\u00fcnnemann. Posterior network: Uncertainty estimation without ood samples via density-based pseudo-counts. Advances in Neural Information Processing Systems, 33:1356\u20131367, 2020.\n\n[2] Bertrand Charpentier, Chenxiang Zhang, and Stephan G\u00fcnnemann. Training, architecture, and prior for deterministic uncertainty methods. In ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML, 2023.\n\n[3] Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. Advances in neural information processing systems, 31, 2018.\n\n[4] Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? Advances in neural information processing systems, 30, 2017."
            },
            "questions": {
                "value": "Are there any explanations on why you can use entropy and average entropy as the criteria for Epistemic uncertainty and Aleatoric uncertainty respectively in Section 3.2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698584662048,
        "cdate": 1698584662048,
        "tmdate": 1699636528049,
        "mdate": 1699636528049,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SoCxvMZ9Qe",
        "forum": "PEoBvQWzHo",
        "replyto": "PEoBvQWzHo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
        ],
        "content": {
            "summary": {
                "value": "The paper sets out to introduce uncertainty quantification to Federated Learning. This can be particularly useful in deciding whether to use a local or global (federated) model for each user and sample. To this end, the paper uses a deep Bayesian algorithm, NatPN, with a slight modification to the loss function. Experiments show that the proposed framework can reduce the error on the OOD data while (often) not degrading on the InD data compared to existing baselines in Federated Learning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Judging by the Introduction, the research question is relevant to Federated Learning, and the contributions are original.\n- The conceptual scheme in 2.1 makes sense. The paper clearly explains the different kinds of uncertainties and their importance in the context of Federated Learning.\n- Design choices such as Dirichlet-based models, pseudo-count representation of $\\alpha$, and entropy-based uncertainty estimates, seem sensible.\n- The core experimental setup, i.e., dividing the data into InD and OOD, is sound."
            },
            "weaknesses": {
                "value": "- The methodological novelty is limited to applying existing approaches to a new problem.\n- The authors are right to note that the choice of the uncertainty threshold is the most subjective part of the approach. Ablations (where the threshold is varied) are required to inspect how important this choice is. This also leads me to a concern about the conceptual scheme described in 2.1: a misestimated threshold may result in abstaining from predictions in a large portion of the data. Perhaps, the global model should not abstain at all?\n- I am not sure about best practices in image classification these days, but the datasets seem simple.\n- One issue I have with Table 2 is that the Mix score depends on the mixing proportions. I think it would be more illustrative to divide this table into InD and OOD tables and highlight with bold the best models in the respective tables.\n- Ablations are required to complement the fix proposed in 3.3. Otherwise, I remain unconvinced that the described issue \u201ccould be a potential issue in federated learning\u201d or even exists.\n\nMinor issues\n- Some parts were unclear from the submission and I had to read cited sources to understand them. After eq. 2, properties of p(g(x)) are listed, but it isn\u2019t explained why f(g(x)) is required (as far as I understood, this term is a class prior, but then I do not exactly understand why it is required along with $\\alpha_{prior}$). Eq. 5 is hard to parse as cross-entropy, consider using $CE$ like Charpentier et al. (2020)."
            },
            "questions": {
                "value": "- Can there be scenarios where the scheme in 2.1 should be reversed? I.e., where the global model may have higher epistemic uncertainty.\n- Could the general approach be extended to other Federated tasks such as Regression or RL?\n- From the bounds of $\\psi(x)$ before eq. 7, wouldn\u2019t it make more sense to approximate it as $log(x) - 1/x$? Would it change the conclusions about issues with the loss function?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671704520,
        "cdate": 1698671704520,
        "tmdate": 1699636527921,
        "mdate": 1699636527921,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "t2dGdYujdi",
        "forum": "PEoBvQWzHo",
        "replyto": "PEoBvQWzHo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
        ],
        "content": {
            "summary": {
                "value": "Authors propose to use Dirichlet models for uncertainty quantification for personalized federated learning setup."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) First time using Dirichlet methods to assess uncertainty quantification in PFL to deal with OOD and mix of In & OOD.\n\n(2) I liked the idea of showing Mix and OOD data in experiments. Especially the Table 2. I have more comments in Weaknesses though."
            },
            "weaknesses": {
                "value": "(1) Authors claim to use Dirichlet methods for uncertainty quantification but do not compare with existing Bayesian federated methods such as FedPA[1], FedEP[2] , and FedPop[3], which are also assumed to perform efficient Bayesian inference for (P)FL.\n\n\n(2) Comparison is unfair for multiple reasons : 1)  Other models do not use a switching model. Technically speaking, other personalized FL models can benefit from \"switching\" too, but not exactly with the same way as this paper does. Also, the proposed method is the only method geared toward uncertainty quantification.  Bayesian FL methods and/or the methods mentioned above should be included as those methods are  (in)directly uncertainty quantification methods too. The paper claims that Dirichlet is an efficient method compared to MCMC and VI, but what about in terms of performance in federated settings? \n\n(3) 20 clients is practically low, and having an equal number of data points is not a practical assumption. I think 100 clients and using more difficult datasets such as CIFAR100 and Stackoverflow would be needed.  Also, an ablation study over the number of clients would be needed, too.\n\n(4) The claim \"In this paper, we proposed a personalized federated learning framework that leverages both a globally trained federated model and personalized local models to make final predictions.\" is misleading as there are previous papers utilizing both global and local models for prediction [4] \n\n(5) The transition from Section 3 to federated settings is poorly developed. Section 3 has too much text in it it is not clear what are the problems/complications of using Dirichlet methods in federated settings. Authors should condense Section 3 and move some parts to the Appendix as it is hard to understand what is the problem for federated learning.\n\n\n[1] Al-Shedivat, Maruan, et al. \"Federated learning via posterior averaging: A new perspective and practical algorithms.\" ICLR'21 arXiv:2010.05273 (2020).\n[2] Guo, Han, et al. \"Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach.\" ICLR '23arXiv:2302.04228 (2023).\n[3] Kotelevskii, Nikita, et al. \"Fedpop: A bayesian approach for personalised federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 8687-8701.\n[4] Hanzely, Filip, and Peter Richt\u00e1rik. \"Federated learning of a mixture of global and local models.\" arXiv preprint arXiv:2002.05516 (2020)."
            },
            "questions": {
                "value": "(1) Why is there no comparison with previous Bayesian FL methods such as such as FedPA[1], FedEP[2], and FedPop[3] ?\n\n(2) Federated loss was unclear to me. Are you using the loss in Eqn. (8)?\n\n\n\n[1] Al-Shedivat, Maruan, et al. \"Federated learning via posterior averaging: A new perspective and practical algorithms.\" ICLR'21 arXiv:2010.05273 (2020).\n[2] Guo, Han, et al. \"Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach.\" ICLR '23arXiv:2302.04228 (2023).\n[3] Kotelevskii, Nikita, et al. \"Fedpop: A bayesian approach for personalised federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 8687-8701."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792571068,
        "cdate": 1698792571068,
        "tmdate": 1699636527801,
        "mdate": 1699636527801,
        "license": "CC BY 4.0",
        "version": 2
    }
]