[
    {
        "id": "eFmLV1tMkT",
        "forum": "5twh6pM4SR",
        "replyto": "5twh6pM4SR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_StyD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_StyD"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to formulate continual learning as a sequence learning problem and applies self-referential weight matrices (SRWM), which can be considered a sequence model, as the key mechanism for continual learning.\nSRWM is a linear layer that produces self-modification as an auxiliary output."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I agree with the general direction of this paper that formulates continual learning as a sequence learning problem.\nThis idea of formulating a learning process as sequence learning has been used in the meta-learning literature, especially for few-shot settings, but has not been utilized in the continual learning domain.\nI believe this direction requires further investigation."
            },
            "weaknesses": {
                "value": "### Missing Related Works in Meta-Continual Learning\n\nAccording to my understanding, this work should be classified as a meta-continual learning (MCL) approach, which is also referred to as *learning to continually learn*.\nIt is a direct extension of meta-learning that replaces each learning episode with a continual learning episode, which also aligns with the authors' description in section 2.2.\nThere are several important prior works in this domain [1, 2, 3] that were not mentioned in the paper.\nThey should also be compared as baselines.\n\n### Confusing Description About the Experimental Settings\n\nSince MCL is a branch of meta-learning that aims to optimize a learning algorithm, it is crucial to separate meta-training and meta-test sets.\nAlso, there should be no overlap in the constituent tasks between them.\nOtherwise, the model can achieve a high score simply by memorizing the tasks in the meta-training set without learning new knowledge during the meta-test phase.\n\nIn the paper, I could not find any description of how meta-training and meta-test sets are constructed.\nI suspected that the authors would have followed the conventional meta-splits for Omniglot and Mini-ImageNet datasets, but I suggest the authors refine the overall terminology to be consistent with the existing meta-learning or MCL literature.\n\n### Weak Experimental Results\n\nThe proposed method is tested only on two-task and three-task CL scenarios, which is an unreasonably tiny scale compared to previous works on MCL [1, 2, 3].\nI do not think such a small number of tasks can be considered meaningful.\n\n### Reproducibility\n\nIt seems hard to reproduce the experimental results solely from the provided text.\nTo verify and reproduce experimental results, I believe that including code with the submission should be the standard practice.\n\n---\n- [1] Javed, Khurram and Martha White. \u201cMeta-Learning Representations for Continual Learning.\u201d NeurIPS (2019).\n- [2] Beaulieu, Shawn L. E. et al. \u201cLearning to Continually Learn.\u201d ECAI (2020).\n- [3] Banayeeanzade, Mohammadamin et al. \u201cGenerative vs. Discriminative: Rethinking The Meta-Continual Learning.\u201d NeurIPS (2021)."
            },
            "questions": {
                "value": "- Experiments with much longer training sequences, as in [1, 2, 3], seem necessary.\n- Since each convolution filter is just a linear layer applied to a local patch, shouldn't it be possible to construct a CNN version of ACL?\n- I have doubts about the representational capability of SRWM since the complex learning dynamics in non-stationary streams depend solely on the initial parameters. Is it really sufficient to manipulate the initial parameters? Can SRWM really handle long sequences?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9084/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698481349277,
        "cdate": 1698481349277,
        "tmdate": 1699637144101,
        "mdate": 1699637144101,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pjcJSthwnY",
        "forum": "5twh6pM4SR",
        "replyto": "5twh6pM4SR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_jN2L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_jN2L"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new way to think about, and potentially solve, the continual learning problem (in particular, the supervised task incremental learning variation of CL). \nThis new approach views CL as a sequence learning problem. Each sub-sequence consists of input/target examples corresponding to one task to be learned. These sub-sequences can then form longer sequences, for multiple tasks, by concatenating multiple sub-sequences.\nOnce formulated as such a sequence-learning task, a gradient descent search for CL learning algorithms can look for the desired CL behavior by constructing loss functions that avoid catastrophic forgetting and aim to achieve goals such as forward transfer."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "On the positive side, the approach of viewing the CL problem in the context of sequence learning seems interesting -- and it gives a fresh perspective to an area (CL) that is becoming increasingly incremental."
            },
            "weaknesses": {
                "value": "I have some major concerns about whether this method is actually doing CL (versus multitask learning). \n\nAnother major concern is whether ACL can be used in a practical context in which many tasks will be learned over time (as opposed to just a handful).  \n\nPlease see comments below."
            },
            "questions": {
                "value": "On Page 6, the paper states: \u201cUnless otherwise indicated, we concatenate 15 examples for each class for each task in the context during both training and evaluation (resulting in sequences of length 75 for each task).\u201d \nHaving a temporally structured input during evaluation is not a valid approach in the context of CL (although I am aware that some meta-learning papers unfortunately do that -- but that does not mean that their approach can be accepted without question because it has been previously published). Such temporally structured inputs makes discrimination between classes of different tasks trivial. For example, if you give someone 75 Omniglot examples and 75 Imagenet examples and ask them to classify an input x during testing, I can easily determine whether x is from Omniglot or Imagenet without learning (just by computing some statistics of pixel values). Letters would, of course, look different than natural images. Then, predictions become much easier.\n\nOn Page 6, the paper states: \u201cThe order of appearance of two tasks within training sequences is alternated for every batch.\u201d This sounds like both datasets are available at the same time. If that is true, what the paper is actually doing multitask learning, not CL.\n\nLooking at the loss function (Equation 4), the first term requires access to old model weights W_A (linear growth in memory requirement as they see more tasks), the second term is okay in terms of CL, but the third term requires access to a previous test dataset, which violates CL. It may be that these are some form of \u201creplay\u201d examples, but the paper does not mention that.\n\nI see that the method is significantly different from other continual learning methods, still I would expect the authors to benchmark against some existing methods. After all, the claim is that instead of hand-crafting CL algorithms, we can learn how to sequentially learn. Does ACL perform better than handcrafted tricks? The method is computation intensive, and it does not seem easily scalable to more tasks. So, I would at least want to see the paper outperform some existing methods in the two-task scenario to argue that learning how to continual learn is a promising direction to pursue.\n\nIf you examine Equation 5 on the last page, you'll notice that in order to learn a third task, they need to add three terms to the loss function. In continual learning, a five-task setting is considered small. To learn SplitMNIST, for example, they would actually need 1 + 2 + 3 + 4 + 5 (15) terms in the loss function. As a result, their method becomes quadratically more expensive in terms of computation (i.e., for Task n, you require backpropagation through (n)(n-1)/2 terms). This is clearly not practical."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Reviewer_jN2L"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9084/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698775216202,
        "cdate": 1698775216202,
        "tmdate": 1699637143982,
        "mdate": 1699637143982,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2keBhRkTei",
        "forum": "5twh6pM4SR",
        "replyto": "5twh6pM4SR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_WhrD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9084/Reviewer_WhrD"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a continual learning method based on self-referential weight matrices. By posing the continual learning problem as a meta-learning task, it is possible to formulate the standard continual learning desiderata (low forgetting, high forward and backward transfers) simply as terms of the meta-learning objective. Authors show that their approach is promising through experiments on MNIST, Omniglot, and Mini-ImageNet."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Originality is the main strength of the proposed approach. To my knowledge, the application of SRWM to continual learning is a novel idea. Automating the discovery of continual learning algorithms by including the desired requirements as loss terms of the meta-learner is an exciting approach and it would be great to explore it in a bit more details. The paper is well written and properly structured. The figures are of high quality and help in quickly grasping the main ideas."
            },
            "weaknesses": {
                "value": "The main weakness of the paper is the experimental evaluation. Despite presenting their approach as a continual learning method, the authors don't use any of the standard benchmarks (e.g. Split MNIST, Split Mini-ImageNet), nor do they compare to any previous work (regularization, replay, or parameter isolation methods). The meta-learning formulation is also a major limitation, as the number of loss terms grows rapidly with the number of tasks and it is not clear whether the method is practical for e.g. 10 tasks (which is still a small number compared to the requirements of real-world lifelong learning). It would also be great to include a figure that illustrates the architecture of your model in more detail."
            },
            "questions": {
                "value": "How do the data requirements of your method grow with the number of tasks?\n\nHow is the training sequence constructed? Do you use a single sequence? If not, doesn't it mean you're effectively performing joint training?\n\nCould you elaborate what do you mean by \"certain real-world data may naturally give rise to an ACL-like objective\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9084/Reviewer_WhrD"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9084/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698836408232,
        "cdate": 1698836408232,
        "tmdate": 1700578185884,
        "mdate": 1700578185884,
        "license": "CC BY 4.0",
        "version": 2
    }
]