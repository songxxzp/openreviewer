[
    {
        "id": "RUhf04VbXK",
        "forum": "WvVyG8qBCt",
        "replyto": "WvVyG8qBCt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_eHtL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_eHtL"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces two main new modifications to differentially private training of transformers. They refer to it as DPFormer. The authors argue that two problems with differentially private training of transformers is i) the additional computational overhead of training with per-sample gradient (initially addressed by Li et. al. 2022 with Ghost clipping) and ii) a phenomenon the authors refer to as attention distraction. To resolve this, the authors propose Phantom clipping which also allows weight sharing (as opposed to Ghost Clipping)  and re-attention. Experiments on two datasets show improvement over some standard baseline algorithms like vanilla transformer, GRU, LSTM."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* __[S1]__ I appreciate the message that pre-training might not be possible for all tasks and it is important to develop algorithms that can work in settings without pre-training. This message has also been highlighted in [A,B].\n\n* __[S2]__ It is important to show that modern DP algorithms can be run computationally efficiently, something which is often missed in works that show state-of-the-art accuracy at a huge computational cost. This problem is particularly pronounced for DP model-training where large batch sizes have somehow been used very commonly. To that effect, I appreciate the focus towards decreasing compitational cost.\n\n\n\n\n\n\n\n\n\n\n\n\n[A]  \"Considerations for differentially private learning with large-scale public pre-training.\" TPDP 2023.   \n[B]  \"PILLAR: How to make semi-private learning more effective\" TPDP 2023"
            },
            "weaknesses": {
                "value": "* __[W1]__ If data is long-tailed, the hand-wavy definition of this means that some parts of the data are over-represented and some parts are under-represented. As such, if the objective is to get high average accuracy (or its variant for recommendation problem), then ignoring the low frequency elements shouldn't be a problem. This paper seems to be looking at average metrics but it mentions long-tailed data in the title. \n\n* __[W2]__ The paper proposes a phenomenon called `attention distraction'. The suggestion is that tokens with high variance will be unfairly selected by the attention mechanism. But it is not very clear to me what this means formally. In addition, the theory seems to assume that every token's attention value is an independent gaussian, which is also unrealistic as all tokens are dependent on each other due to previous layers and I don't see why adding gaussian noise to gradients results in gaussian distribution for token activations. The whole section 4 assumes these two things but there isn't any empirical or theoretical justification for this.\n\n* __[W3]__ The experimental comparison is not thorough at all. Please see question 3 below for a more detailed explanation of why I think that is the case.\n\n\n\nMinor Comments\n1. What do the metrics used here actually mean ? Maybe I missed it but I don't see a definition of ndcg@10 and HiT@10. \n2. Figure 1 is not very understandable as there are terms like $a_s$ and $e_s$ which is not clarified.\n3. In general, the text is very heavy which can be distracting to readers. I would recommend (personally) to have shorter sentences to the point.\n4. Eq 1 isn't clear what G is.\n5."
            },
            "questions": {
                "value": "1. Regarding long-tailed data [W1] cam the authors explain\n    * motivation for why that is the central part of the story and where the long-tailed data comes into play.\n    * any evidence that the proposed method specifically helps for long-tailed methods.\nPerhaps the authors can draw some relation from [1] ?\n\n2. Regarding [W2], can the authors provide evidence that ``attention distraction'' \n    * truly happens without re-attention mechanism in transformer. I understand Figure 9 is supposed to show this but I don't exactly understand what the two axis here is. I am also not comfortable drawing summary statistics about this as a wider phenomenon that what is shown in the five plots. To me it appears that this is just learning a biased classifier (i.e. not learning the true signal) that puts all its signal on one token (if I understand it correctly).\n    * follows the same mathematical equations that Section 4 predicts it should.\n    * Re-attention actually solves it ?\n\n3. Both the datasets and baseline algorithms are fairly restrictive. Is there any reason apart from not having pre-trained models specialised for recommendation engines, why the experiments are limited to recommendation settings. \n    * The methods should also provide benefits for NLP tasks (with and without pre-training). \n    * Also, is there a comparison with Li et. al. or any other method for training transformers or recurrent models ? Such comparisons would be needed.\n    * Can the authors also try using a general pre-trained transformer for this recommendation tasks ?\n\n[1] \"Does learning require memorization? a short tale about a long tail.\" Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing. 2020.    \n[2] \"How unfair is private learning?.\" In Uncertainty in Artificial Intelligence, pp. 1738-1748. PMLR, 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4309/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675265549,
        "cdate": 1698675265549,
        "tmdate": 1699636399451,
        "mdate": 1699636399451,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FvdjQ2ozna",
        "forum": "WvVyG8qBCt",
        "replyto": "WvVyG8qBCt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_v4h1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_v4h1"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the differential privacy in transformers. They identify two key challenges as heavy computation due to per-sample gradient clipping, and unintentional attention distraction within the attention mechanism. They propose DP- Former, equipped with Phantom Clipping and Re-Attention Mechanism, to address these challenges. The theoretical analysis shows that DPFormer can reduce computational costs during gradient clipping and effectively mitigate attention distraction. Empirical results on two real-world recommendation datasets with varying degrees of long-tailedness, showing its significant improvement in terms of efficiency and effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper give DPformer to address the challenges of heavy computations and attention distraction.\nOriginality: The proposed methods addressed the two difficulties, it\u2019s novel and has good performance. Phantom Clipping inherit the basic idea of Ghost Clipping, obtain the per-sample gradient norm without the need for instantiating the per-sample gradient. p\nQuality: This methods performs well in experiments. But I doubt that whether the re-attention method after DP process can leak privacy?\nClarity: The logic structure of this paper is clear \nSignificance: These two problems are very important problems for differential privacy in Transforms, so this kind of work is necessary"
            },
            "weaknesses": {
                "value": "The correctness of this method. \nThis paper uses Phantom clipping and Re-attention mechanism to overcome the difficulties of heave computation and attention distraction. The most important thing is to make the whole mechanism be differentially private and have high utility. However, they authors didn't analyze the privacy of this mechanism, especially after the re-attention. It seems this process will leak privacy."
            },
            "questions": {
                "value": "What is the privacy guarantee for this method?\nWhat do NDCG@10 and HIT@10 mean?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4309/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735323114,
        "cdate": 1698735323114,
        "tmdate": 1699636399369,
        "mdate": 1699636399369,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n80FagV8bV",
        "forum": "WvVyG8qBCt",
        "replyto": "WvVyG8qBCt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_SzC2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_SzC2"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces two treatments for training transformer models with DP-SGD on long-tailed data. The first is phantom clipping which extends ghost clipping by handling parameter sharing between input and output layer (a common practice). Phantom clipping effectively enabled more efficient DP training of transformer models in practice. The second is a re-attention mechanism which rescale the attention scores in the transformer models by their error variances due to DP noise. The methods are evaluated on two benchmark recommendation datasets and showed better performance compared to the DP-SGD baseline."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper is well-motivated as transformer models are used in many ML applications and being able to train it with strong privacy guarantees is important for these models to scale further.\n- The methods are driven with the empirical observations of the shortcomings of DP-SGD on transformer models. Parameter sharing of embedding parameters is such a common thing to do but was not considered in prior work on speeding up DP-SGD. Also DP is known for generalizing worse on the tail and the re-attention mechanism is a simple yet effective workaround."
            },
            "weaknesses": {
                "value": "- The experiments, as the authors acknowledged, were conducted on the smaller scale models. Also only recommendation tasks were considered. It is unknown whether these methods will be effective on larger image or text models.\n- Some baselines for training with DP are missing where these methods also improve the performance of models for long-tailed data: [1] proposed a way to add DP noise adaptively according to the geometry of the loss space, which can effectively enable smaller noise on long-tailed data. [2] similarly uses auxiliary information such as the frequency of the vocabulary to apply DP noise. \n- Describing section 4 as an algorithm would be easier to read.\n\nReferences\n\n[1] Asi, Hilal, et al. \"Private adaptive gradient methods for convex optimization.\" International Conference on Machine Learning. PMLR, 2021.\n\n[2] Li, Tian, et al. \"Private adaptive optimization with side information.\" International Conference on Machine Learning. PMLR, 2022."
            },
            "questions": {
                "value": "- Is Figure 3 based on Ghost Clipping or Book-Keeping [1]? BK is supposed to be more efficient than Ghost Clipping.\n- In Equation 7, are the subscripts on the right-hand side supposed to be $X^{(l-1)}$? \n\nReferences\n\n[1] Bu, Zhiqi, et al. \"Differentially private optimization on large model at small cost.\" International Conference on Machine Learning. PMLR, 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4309/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772584168,
        "cdate": 1698772584168,
        "tmdate": 1699636399280,
        "mdate": 1699636399280,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Bd0E7CPmpV",
        "forum": "WvVyG8qBCt",
        "replyto": "WvVyG8qBCt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_FhGH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4309/Reviewer_FhGH"
        ],
        "content": {
            "summary": {
                "value": "This paper identifies two key challenges in learning differentially private Transformers, i.e.,\nheavy computation overhead due to per-sample gradient clipping and attention distraction due to\nlong-tailed data distributions. The authors then proposed DPFormer, equipped with Phantom Clipping and\nRe-Attention Mechanism, to address these challenges. Empirical results are also provided to justify the new design."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper aims at solving issues and improving the performance of DP transformers. Personally, I think this problem is very important and a key step towards enabling large model training under differential privacy. Given the popularity of large language models and transformers, this problem should be interesting to both DP community and LLM community."
            },
            "weaknesses": {
                "value": "Although the problem at which the paper aims is very important, the paper does not provide a satisfactory answer and leave many questions unanswered. Most importantly, this paper needs to greatly improve its clarity: there are many places with vague languages or unstrict math, making it very hard for the reader to follow or evaluate the paper's quality. Personally speaking, there is still a long way to go before the paper can be accepted.\n\nHere are some specific suggestions/confusion:\n\nPhantom clipping: \n1. All the notations in Claim 3.1 are used without being carefully defined. I do not find it enough to just define them by Figure 1 or simple languages in Claim 3.1. Could we have some strict math like section 2.2 in https://arxiv.org/pdf/2205.10683.pdf?\n2. I am not convinced why the phantom clipping has such great advantages over ghost clipping. Observing Claim 3.1, it has exactly the same idea (calculating the norm and avoiding gradient instantiation) with ghost clipping. Specifically, I do not understand why the BM^2 complexity is inherent to the ghost clipping under a careful implementation. With that in mind, I am concerned the paper may over-claim the advantages.\n3. Looking at the results from other papers  (e.g., https://arxiv.org/pdf/2205.10683.pdf) applying ghost clipping to transformers, the ghost clipping has shown a much better memory effIciency. I do not quite understand the gap between Figure 3 and those results.\n\nRe-attention\nGenerally speaking, the idea of re-attention is interesting. However, there are many vague places in both motivation and estimation, making me hard to feel convinced. Specifically,\n1. The math in the motivation is not very strict. Please make some revise. Furthermore, there are many other sources of randomness in model training except for DP noise. Please specify them in the conditional distribution.\n2. In section 4.1, the paper mentions that the attention distraction mainly happens when different parameters have different variance. However, in DP-SGD, the noise with the same std is added to each parameter. Could the authors explain about this?\n3. Section 4.2.2 is very hard to follow. For me, it just reads like a mixture of several techniques without a clear explanation. I have several confusions. For example, is the assumption realistic assuming i.i.d. Gaussian for each dimension in parameter? Furthermore, I do not quite follow how to estimate the mean and std of the start point.\n\nExperiments\n1. Since the paper is targeting large models, it is better to have some setting for fine-tuning instead of training from scratch. Also, revealing some results when eps = infty will also be helpful."
            },
            "questions": {
                "value": "Please refer to weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4309/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4309/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4309/Reviewer_FhGH"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4309/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698974070480,
        "cdate": 1698974070480,
        "tmdate": 1699894582607,
        "mdate": 1699894582607,
        "license": "CC BY 4.0",
        "version": 2
    }
]