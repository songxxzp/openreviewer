[
    {
        "id": "MPiDNh7xBs",
        "forum": "A7t7z6g6tM",
        "replyto": "A7t7z6g6tM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_3vp1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_3vp1"
        ],
        "content": {
            "summary": {
                "value": "The DNN\u2019s uncertainty due to composite set labels (i.e., an example might be labeled as a set of possible classes, but only one class is true) in training data is considered. This work introduces a new type of uncertainty termed vagueness, and propose a framework Hyper-Evidential Neural Network (HENN) to quantify this type of uncertainty. Further, a loss named uncertainty partial cross entropy (UPCE) is proposed. Finally, the proposed method is shown to be effective on four image datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tA novel type of DNN uncertainty is introduced, and the uncertainty calibration is evaluated with the metric Jaccard Similarity.\n2.\tAn extension of the partial cross, uncertainty partial cross entropy (UPCE) is proposed."
            },
            "weaknesses": {
                "value": "1.\tAlthough the newly introduced uncertainty concept and problem setup sound interesting, I am not sure the empirical evaluation is realistic and convincing enough. Are all the composite labels used in the empirical evaluations synthetically generated? Could you provide more concrete examples in these synthetic datasets? I am curious how realistic these generated composite labels are. If so, is it possible to run evaluations on real-world composite set labels?"
            },
            "questions": {
                "value": "Please see the comments in the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6833/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698552664689,
        "cdate": 1698552664689,
        "tmdate": 1699636790966,
        "mdate": 1699636790966,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "v21uhCfSap",
        "forum": "A7t7z6g6tM",
        "replyto": "A7t7z6g6tM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_AQu8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_AQu8"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel framework for deep learning to deal with composite labels, i.e. labels that couldn't be assigned to a single class due to quality of the input, for example, and were assigned to more than one class. The framework assumes a neural network to output, similarly to the training labels, both singleton classes and composite labels. The paper also proposes a novel uncertainty metric, called vagueness, that is measuring uncertainty related to composite label evidence in training. To train a novel neural network with composite output, the paper proposes a novel loss function."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* A very thorough work has been done with the new framework (and basically the new problem setup). Extensive theoretical evaluation, empirical evaluation including ablation study, a good number of baselines considered for comparison. \n* In addition to the new framework itself, the novel uncertainty metric is made as a proper contribution on its own with the thorough theoretical and empirical comparison with other uncertainty metrics. \n* The paper is mostly well-written and presents the context of prior work. The only drawbacks I can see are obviously due to the lack of space.\n\nOriginality: I am not familiar well with the related works, but both the framework and the uncertainty metric appears to be novel. \n\nQuality: Very well done and thought through piece of work. See above.\n\nClarity: Mostly well-written and easy to follow. \n\nSignificance: Empirical evaluation demonstrates that even in terms of single class classification (i.e. output of a NN is a single class) the proposed framework demonstrates improved accuracy in comparison to all considered baselines. Moreover, the proposed uncertainty metric demonstrates significantly superior performance in terms of distinguishing between composite and single labels examples."
            },
            "weaknesses": {
                "value": "The main weakness that I see in the paper is the lack of motivation how severe is the problem of having composite labels in practice for training and why we need a NN to output us a composite label in practice. The main conceptual motivation that I gathered from the paper is that the new framework allows to estimate uncertainty related to composite labels in training data. However, the argument is not too convincing. It seems that we don't have to produce a composite label in order to estimate the effect of composite labels in the training data (not that I know how to do it without). \nEmpirical evidence shows us the practical motivation of using the novel framework: it gives us the higher accuracy when we consider a single class prediction. However, again this is shown in the experiments with the composite labels in training, which is not well motivated how often in practice we would have these labels for training. \nTo this end, I think a small experiment, showing that the proposed framework still works with traditional setup of single labels for training only, would be beneficial. \n\nOriginality: I appreciate that the considered problem formulation is different in that a single class is expected to be true for each sample, but maybe lacking due to the quality of the sample, but still I find it is a related area. The area of research devoted to multiclass classification is missing in the related works (e.g., Augustin, A.; Venanzi, M.; Hare, J.; Rogers, A.; and Jennings, N. 2017. Bayesian aggregation of categorical distributions with applications in crowdsourcing. AAAI Press/International Joint Conferences on Artificial Intelligence, but there are lots of others).\n\nQuality: The code is provided which should elevate this weakness, but based on the text not all implementation details are provided sufficiently to reproduce the results. See details below. \nDifferent types of image corruption would be interesting to see in the experiments in addition to the Gaussian blur. \n\nClarity: A lot of theory is packed in a very small space with lack of illustrative examples. See details below. \n\nSignificance: As per the main drawback mentioned above, I am not sure about the significance of the paper due to very specific problem setup, which was not too convincing for me. \n\nSpecific comments/suggestions:\n1. First two sentence of the text are unclear how to connect to the rest of the text. The problem considered is not related to missing data but rather ambiguous data due to the quality of the input. \n2. Missing reference in third paragraph of Section 1. \n3. Section 3. Illustrative examples of what this means in practice would be much appreciated. Note that example from Table 1 is not sufficient. For example, what does evidence 24 mean in practice? 24 annotators voted for this category? \n4. Figure 1 right is not referred to in the text. \n5. UCE (page 6) is not defined.\n6. Propositions 1 and 2. How reasonable is the assumption of universal approximation property? \n7. Eq. 15 appears without any introduction, connection to the previous text. \n8. Preprocessing of the dataset to create composite labels is unclear (including the text in the appendix). \n* \"Several random subclasses for each selected superclass will be chosen\" - for what? How these subclasses are used further?\n* Which images are selected to be blurred? \n9. How CompJS is computed for baselines not producing composite output is unclear until explanation of what cutoff is in Appendix. Also mentioning of cutoffs in the main text is unclear until this explanation in Appendix (no reference in the main text). \n10. It is unclear exactly how superclasses are extracted for Living17 and Nonliving26 datasets.\n11. The full list of data augmentations is required for reproducibility.\n12. Up until the last paragraph in page 26 in Appendix, it is not clear how the process of duplicating samples with composite labels is working (there is no reference to this paragraph in the earlier text). \n13. Section F.4 There are SinglJS, SingleAcc and Acc mentioned in different places. What is the correct one?\n \n\nMinor:\n1. Page 7. The paragraph before Section 5. \"As a generalized framework of ENN, The HENN\" -> \"the\"\n2. Section F.4 title. \"regularier\" -> \"regulazier\""
            },
            "questions": {
                "value": "My main question to the authors, the answer to which hopefully will clarify any doubts from my side, is the question of motivation of the problem setup. I.e. how important is the problem of having composite labels during training and why do we need to also output composite labels by a NN?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6833/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698635344221,
        "cdate": 1698635344221,
        "tmdate": 1699636790800,
        "mdate": 1699636790800,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Y5Gwf9XJKC",
        "forum": "A7t7z6g6tM",
        "replyto": "A7t7z6g6tM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_Gzpb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_Gzpb"
        ],
        "content": {
            "summary": {
                "value": "A hyper-evidential neural network is presented in this paper, for classification of data, modelling predictive uncertainty based on training data with composite set labels. The uncertainty is measured by introducing the vagueness type of measure. Results are presented where HENN performance is compared favorably with other methods over four image datasets. Detailed analysis is included in Appendices."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper deals with a significant problem, i.e., to train DNNs when (some) training data have composite labels, being able to predict these labels and quantify the predictive uncertainty due to these labels. It defines a related measure, vagueness, to do so and extends neural network structures to model this uncertainty for classification problems; it uses an uncertainty partial cross entropy loss function extending the normal UCE function.  An experimental study is presented which illustrates a good performance over four image datasets, when compared to five other methodologies that can be applied in this context."
            },
            "weaknesses": {
                "value": "The paper defines vagueness as a measure of the predictive uncertainty due to composite labels of training data. It then uses gaussian blurring in the experiments to create such data cases and perform the experimental verification. However, this is a rather specific synthetically generated experiment, which can not justify the significance of the results over real world applications. Such applications could, for example, include classification of facial images showing compound and primary emotions in-the-wild (where compound emotions two or more primary ones), or in image2image translation tasks. Moreover, the comparison shown in Table 2 does not seem fair, since - as also discussed in the 'Classification' results subsection (in 5.2) - the other methods are not designed to handle this type of vague images."
            },
            "questions": {
                "value": "Following the above, would it be possible to apply the method in real world applications involving composite labels? \nMoreover, performance seems to heavily depend on regularization hyperparameter, which is selected in an ad-hoc manner. Is this a pitfall for method's robustness over different datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6833/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698741568380,
        "cdate": 1698741568380,
        "tmdate": 1699636790666,
        "mdate": 1699636790666,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oyH6N2bVVZ",
        "forum": "A7t7z6g6tM",
        "replyto": "A7t7z6g6tM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_RL9p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6833/Reviewer_RL9p"
        ],
        "content": {
            "summary": {
                "value": "The paper suggests a variant of Dempster-Shafer Theory to arrive at decisions that allow for uncertainty quantification for composite classification. In the proposed HENN framework the uncertainty from composite annotations during training is leveraged for quantification of classification uncertainty. Experiments on image datasets are used to demonstrate the effectiveness of HENN which the authors support by a theoretical analysis as well."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Undoubtedly, annotation uncertainty is a big challenge in today's machine-learning models. Thus, this paper tackles a highly relevant topic. In addition, uncertainty in the output of DNN models is the focus of many papers, e.g. to find the right calibration of the values to allow interpretation and decision-making. The authors suggest DST for solving this issue, which I did not see before for DNN. If the theoretical analysis (Sec. 4.1) can be confirmed to be correct and relevant in practice (which I could not!), I would see a relevant contribution by this work, at least to inspire others to look into hyper-opinions."
            },
            "weaknesses": {
                "value": "I see two significant shortcomings:\n1. composite classification is not new, and solutions exist in a different context and with different methods (i.e. no DST). See, for example, Brust et al.: Making Every Label Count: Handling Semantic Imprecision by Integrating Domain Knowledge. ICPR 2020. The authors did not make clear what the advantage of their framework is compared to such work. This referenced work might differ, but the overall modelling procedures look similar to the one in the submission: annotations are at a different level of a concept hierarchy (dog->husky, dog->wolf, might generate label \"dog\" if uncertain, or \"husky/wolf\" if certain). \n2. the selected datasets are not suitable to demonstrate a (at least for me) complex theory behind uncertainty and how to include it into deep learning loss functions and regularization. For example, I am not sure what Gaussian blurring will make with tiny-images, i.e. what remains as information after blurring. \n\nI am also not happy with the theoretical part of the paper, although I have to admit that I am not that familiar with DST, and this hindered me from diving deeper into the derivations done in Sec. 4.1 The notation and style of presentation is probably only proper for an expert in this area."
            },
            "questions": {
                "value": "I have only two questions:\n- do you see any relation to Brust et al.: Making Every Label Count: Handling Semantic Imprecision by Integrating Domain Knowledge. ICPR 2020 and which concepts of this work is related to yours? \n- did you perform experiments on more relevant benchmark datasets, like NABirds (https://dl.allaboutbirds.org/nabirds). For this dataset, hierarchies exists and benchmarks in fine-grained recognition which most likely would benefit most from your suggested idea."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6833/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827494667,
        "cdate": 1698827494667,
        "tmdate": 1699636790506,
        "mdate": 1699636790506,
        "license": "CC BY 4.0",
        "version": 2
    }
]