[
    {
        "id": "Ha775ix4zo",
        "forum": "5AbtYdHlr3",
        "replyto": "5AbtYdHlr3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_Ksk7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_Ksk7"
        ],
        "content": {
            "summary": {
                "value": "This study investigates a very interesting topic and introduces an algorithm for learning stochastic planning models, specifically targeting domains with dynamics that are challenging to model manually. The proposed approach could efficiently learn from example trajectories, ensuring accurate and safe action modeling."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The research topic is interesting.\n2. The theoretical analysis sounds good."
            },
            "weaknesses": {
                "value": "1. The manuscript requires substantial improvements in writing quality, with an emphasis on a more coherent logical structure.\n2. The paper contains numerous grammatical errors, even within the abstract. For instance, on page 1, there's a repeated \"the\", \"model\" in the abstract should be \"models\", \"at some point\" should be \"at some points\", and \"some other condition is satisfied\" should be \"some other conditions are satisfied\".\n3. Ensure that abbreviations are expanded upon their first use, for example, \"PPDDL\".\n4. Once an abbreviation has been defined, it's redundant to reintroduce it; consider the case with \"Stochastic Safe Action Model (SAM)\".\n5. The experimental section is lacking, making it challenging to evaluate the method's effectiveness."
            },
            "questions": {
                "value": "1. Could you clarify the meaning of \"IPC probabilistic tracks\"?\n2. Is there a correlation between the level of stochasticity and model performance?\n3. What is the relationship between effect probabilities and sample complexity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698536126281,
        "cdate": 1698536126281,
        "tmdate": 1699636380919,
        "mdate": 1699636380919,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pJPo2Nlwhn",
        "forum": "5AbtYdHlr3",
        "replyto": "5AbtYdHlr3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_cva7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_cva7"
        ],
        "content": {
            "summary": {
                "value": "The focus of the paper is on model learning in stochastic PPDDL. Here, the overarching goal is to learn a model of the domain from trajectories. The model here specifically refers to a set of preconditions and effects of taking a particular action. The trajectories are executed with a set of policies in a domain with discrete states. Each state is characterized by a set of boolean fluents. The goal of the paper is to learn a stochastic model where the probability of each effect is extracted from the data. Previous work in this setting provides safety and approximate completeness guarantees by assuming that each effect\u2019s action on each fluent is an independent random variable. This assumption eases the analysis. In contrast, this paper attacks a more challenging case using tools from tensor algebra. By performing a low-rank decomposition of the transition probability tensor using the method of moments, the authors are able to extract a model that is shown to satisfy safety and approximate-completeness criteria."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The contribution is novel, clear and significant. The idea of using tensor decompositions for PDDL has not been explored.\n\n2) The method is theoretically sound."
            },
            "weaknesses": {
                "value": "1) The presentation and clarity needs significant improvement. As a standalone contribution, the paper should be more rigorous in terms of presentation and lacks a diligent writing style. A more scrupulous approach to explaining all the math will help presenting the paper (with the appendix).\n\n2) It would be nice if half a page of the paper is delegated to demonstration of the method on one dataset.\n\n3) More preliminaries and related work on the method of moments algorithm applicable to tensors is encouraged. The related work section only attributes around five papers."
            },
            "questions": {
                "value": "1) I have some questions surrounding Lemma 1. I believe $|S|$ denotes the number of distinct elements in $S$. Is there any reason why the elements of $V$ would not be distinct? Are they necessary to be all distinct? Is all that is sufficient is that $rank(V)=r$ where $r$ satisfies Lemma 1? In that case, $rank(V)+2 rank(V^{\\otimes k}) \\geq 3r$? This part is unclear to the reader.\n\n2) More illustrations similar to section 3.2 equations (2) and (3) will help improve clarity.\n\n3) Section 4.1 is not explained properly and there are some cyclical arguments. Given that these are mainly a variation of Jennrich\u2019s algorithm, a preliminaries section can help ease the exposition.\n\n4) There is no explanation of what is a \u201cgeneric\u201d tensor? Is the qualification in Kruskal\u2019s theorem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698590285897,
        "cdate": 1698590285897,
        "tmdate": 1699636380844,
        "mdate": 1699636380844,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BQjsU1Ierl",
        "forum": "5AbtYdHlr3",
        "replyto": "5AbtYdHlr3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_YR2D"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_YR2D"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an approach based on tensor decomposition for learning stochastic action models for symbolic planning. The problem is really relevant and important, given the amount of work going on in different fields model learning like learning abstractions or learning symbolic models. \n\nThe paper theoretically shows that the learned model is safe (or conservative) in terms of the action only applicable in a state if and only if it is permissible in the true model (but given that they learn a conservative model from a set of only positive trajectories this is not surprising)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem is relevant, important and unsolved. \n\n- The approach is theoretically sound and strong."
            },
            "weaknesses": {
                "value": "As I mentioned, the problem is really interesting. However, the paper is equally inaccessible to a reader. The low novelty score given is because even though the paper may have novel contributions, these are not understandable for the reader. \n\n- There are many unsubstantiated claims in the paper. Theorems and Lemmas in the paper have almost no explanations.  While I support having theoretical results in the paper, they should be complete. The readers should not be left reading some previous work to understand even the basic premise of the theoretical results of the paper (in this case [Juba and Stern, 2022]) as the paper  does not have proofs for theorems and lemmas (Theorem under 2.2, Lemma 1, Theorem 1, and Theorem 2) or defer proofs to previous work. \n\n- The notations are non-intuitive. For, e.g., the preliminaries section is meant to be make the rest of the paper understandable. However, they have unproven lemmas and theorems as well as equations with undefined symbols (superscript cross d ). In Theorem under Sec 2.2, what are a_k,b_k and c_k? \n\n- The paper attempts to solve a very intuitive problem with a very non-intuitive approach. The most intuitive thing  would have been to include a running example that makes it really easy for the readers to follow. \n\n- The next big problem with the paper is a lack of empirical evaluation. Without an empirical evaluation, there is no practical explanation to if the approach is feasible for learning real world domain models. There are plenty of PPDDL domains available to learn. \n\n- The paper presents a similar functional approach as [Juba and Stern 2022] with near similar theoretical guarantees. It is not clear from the paper what is the motivation behind a different approach without any significant improvements."
            },
            "questions": {
                "value": "Please refer to the weaknesses highlighted in the previous section. \n\nThe most important question is: \n\n- Would it be possible to provide a running example in the **main paper** to help the reader understand the paper as it is currently extremely difficult to understand. \n- Why was not empirical evaluation provided and would it be possible to provide empirical evaluation on standard PPDDL domains?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4152/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4152/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4152/Reviewer_YR2D"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698779378742,
        "cdate": 1698779378742,
        "tmdate": 1699636380758,
        "mdate": 1699636380758,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "N921nNgH6q",
        "forum": "5AbtYdHlr3",
        "replyto": "5AbtYdHlr3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_bFXN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4152/Reviewer_bFXN"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce the problem of learning an action model in a stochastic environment of a PPDDL-type planning problem. Unlike the more standard MDP formulations of RL, here the state formulation consists of a set of 'fluents' which take boolean values, and the action model describes which 'effects' can follow after taking certain actions in given 'preconditions'. Compared to previous research in learning action models, in their formulation, the stochasticity of the effects that follow certain actions can be more general. The authors then show that, under these assumptions of the stochasticity, following closely the methodology of Juba & Stern (2022), they can learn an action model using tensor decomposition. They analyze the method and show that it can be used to achieve a particular notion of 'safety' and 'approximate completeness'."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The authors come up with an algorithm to learn the action model and they can then guarantee \"safeness\" and the \"approximate completeness\" of the approach."
            },
            "weaknesses": {
                "value": "* The paper is unnecessarily dense at times, please consider the use of examples and captions to illustrate the main ideas, especially to new audiences.\n\n* No experiments were performed to show the benefits of the introduced algorithm.\n\n* It is not clear at times what the contribution is compared to Juba & Stern 2022 paper. It seems that all the proof techniques rely on that previous paper. In particular note the last sentence of the paper: \"The only difference\nbetween the proofs of these theorems and Juba & Stern (2022) is that we change the dependence on\nthe number of fluents |F | to the dependence on the number of effects |F |O(log r).\"\n\n* It is not clear if the stochastic model considered reflects real-world problems accurately. In particular it would be nice for the authors to give an example of a real-world problem that is captured by the particular stochastic model."
            },
            "questions": {
                "value": "* I'm not sure that ICLR is a good conference to submit this type of paper, it seems rather to belong to the more standard AI/planning-focused conferences.\n\n* Is the Algorithm1 the authors' contribution, or is it also based on the Juba & Stern (2022) paper?\n\n* It's not clear if the proposed algorithm would actually run on a computer. Have the authors tried to do so? Are there any complications?\n\n* Minor comment: Two 'the's in the first sentence."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698918399352,
        "cdate": 1698918399352,
        "tmdate": 1699636380668,
        "mdate": 1699636380668,
        "license": "CC BY 4.0",
        "version": 2
    }
]