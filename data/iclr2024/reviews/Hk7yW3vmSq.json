[
    {
        "id": "t342D0viRr",
        "forum": "Hk7yW3vmSq",
        "replyto": "Hk7yW3vmSq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_wCZ7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_wCZ7"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to use semantic graphs as a vehicle for Counterfactual Explanations. Since handling distance over graph could be computationally too expensive the paper proposes a novel method based on GNNs to efficiently compute counterfactuals retrieved from a given database. The proposed method is validated both quantitatively and qualitatively on diverse modalities."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of applying GNNs over scene graphs to compute an approximate graph edit distance for Counterfactual Explanations is novel and interesting. \n2. The proposed method is evaluated both against previous SoTA methods and with human annotations."
            },
            "weaknesses": {
                "value": "1. The main contribution of the paper is rather empirical, to the best of my knowledge none of the proposed techniques is novel, however their joint application to solve the problem statement is interesting. As such, the impact of the work on the community could be increased by providing a more comprehensive evaluation of a broader set of modalities/domains (the current version of the manuscript mostly covers images and very briefly audio signals). \n2. The current version of manuscript works under the assumption that the \"retrieval database\" (of scene graphs) is \u201cdense enough\u201d. Such an assumption is key, especially when using Counterfactual Explanations for explaining specific failure modes of trained models. However, this assumption might not easily hold in practice. Can the authors comment more on this problem and how their new framework is expected to behave in realistic scenarios? It is not difficult to see that, as the scene graphs increase in dimension, all possible graph insertion/deletion/substitution lead to a combinatorial explosion of possible compatible scene graphs that might be hard to cover with a finite amount of data. \n3. Results in Table 5 are quite close, however authors claim that their method exhibits superior performance over the baseline, can the authors put the number into perspective? In absolute terms it appears that both models perform quite similarly (as it is highlighted in the qualitative Figure 4 as well)."
            },
            "questions": {
                "value": "Why \u201ccomputing the GED for only N/2 pairs to contract the training set is adequate for achieving high quality representations? Has it only been validated experimentally or it can be formalized more precisely? Can the authors make this point clearer in the manuscript? \n\n\nMinor: \n- Editorial suggestions:\n    - Please define acronyms before use, e.g. in the abstract.  \n    - The abstract could be summarized without loss of information. \n- What is actionability mentioned in the introduction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830078326,
        "cdate": 1698830078326,
        "tmdate": 1699636487183,
        "mdate": 1699636487183,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3YxXmS2xCo",
        "forum": "Hk7yW3vmSq",
        "replyto": "Hk7yW3vmSq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_iSZ3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_iSZ3"
        ],
        "content": {
            "summary": {
                "value": "The article presents an approach for providing more interpretable Counterfactual Explanations using concept graphs. Assuming instances to be represented as scene graphs and given a target \"counterfactual\" class, finding a counterfactual explanation is formulated as retrieving the instance of that class with minimum Graph Edit Distance (GED) from the current input. To avoid the costly process of explicitly computing GED for each pair of instances in the dataset, the method proposes to learn to embed scene graphs in such a way that their distance in the embedding space is similar to the GED of their graphs. This objective is supervised by computing GED on a subset of the dataset and experiments show that it generalizes even when fractions of the original dataset are provided. Comparisons with other semantically interpretable counterfactual XAI methods show that the approach retrieves counterfactual images with lower/more coherent GED distance w.r.t. to the ground-truth one."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Using distances among scene graphs to define counterfactuals is sound and of practical interest: as scene graphs ground the input to semantically interpretable concepts, the distance, and edits are inherently interpretable by humans, as also confirmed via the user studies Table 3 and Table 4.\n2. The introduction clearly motivates the proposed approach and provides an extensive overview of Counterfactual Explanation methods and their interpretability issues, motivating the targeted scenario and the employed solution. \n3. The approach is flexible as it can be applied to any input representable via graphs, as shown in the audio experiments of Table 7.\n4. As graphs are grounded to input instances, the edits are all actionable, a fundamental property for counterfactual explanations."
            },
            "weaknesses": {
                "value": "1. Most of the quantitative metrics are based on graph distances. For instance, Table 1, and Table 5 report the performance as the average number of graph edits between the retrieved instance by the proposed framework and the competitors. Similarly, Table 2 compares the ranking of the retrieved instance vs the \"gold-standard\" ranking provided by the ground-truth minimum GED. Given that the main contribution of the work is using GED over scene graphs as a way to provide counterfactuals and that the model is supervised with ground-truth GEDs over scene graphs (while the competitors are not), these results are not completely fair as the metric is biased toward the proposed model. Finding more method-agnostic metrics (as done in Tables 3 and 4) would make the claims stronger.\n2. Despite being biased on the metrics, it seems that the competitor SC can still retrieve samples with low edits (Table 5, Section 4.2) achieving either superior or comparable results with the proposed method. Section 4.2 claims the contrary (i.e. superiority of the proposed approach) but the quantitative evidence is not clear. This statement should be refined and the reason for these comparable results expanded.\n3. The SC approach (Dervakos et al., 2023) also uses GED but over knowledge graphs. From the text (and Section 2), it is unclear whether the contribution w.r.t. SC is mostly on the type of input graphs rather than on the selection criterion per se. Note that this would also impact the contribution in Section 1, as the article would not be the first to employ graphs for visual counterfactuals (but GNN for fast computation of GED).\n4. Tables present inconsistent sets of baselines as Tab. 3 does not report the CVE baseline, and Table 4 misses the SC one. This makes it hard to assess whether the proposed approach is superior to all competitors in all user studies.\n5. While using GED over scene graphs it is an interesting direction, it has two potential drawbacks. The first is that concepts of interest should be included in the pretrained scene-graph extractor. The article does not describe at the moment how the performance of the approach varies w.r.t. the scene graph extractor and Sections 4.1 and 4.2 assume graphs to be available (either via automatic extraction from labels or the dataset itself).\n6. The second point is that GED may not correlate with distance in the classifier space but rather in the graph-based input representation. This is taken into account methodologically when the retrieved sample is conditioned on the classifier scores ranking (last part of Section 3). Nevertheless, It would be helpful to add a discussion on how the two relate to each other, and even quantitative analyses  (e.g. on L2 distances in the feature space) to check whether distances in the feature/classifier space correlate with GED.\n7. For the analyses on Visual Genome, the approach is using a model pretrained on Places365 as a classifier. However, as the examples in Fig. 4 show, the images may depict a single foreground object rather than a scene. The choice of Places365 as a pretraining classifier rather than other choices (e.g. ImageNet) is not motivated in the text.\n\n\n\n-------------------------------------------------------------\n\n**Update post-response phase:**\n\nI thank the authors for the detailed answers, clarifying most of the concerns raised by all reviewers. I increased my score accordingly.  However, I still have some concerns, which I still deem as major:\n\n1. The claim that: \"GED is the most method-agnostic way to establish semantic distance because it is directly based on all possible semantic changes both in terms of objects as well as relations\" is semantic/dataset dependent and it assumes that the graph describes all relevant semantic relations needed for the classification task. This is questionable, as in some tasks changes in semantics are not easily captured via a semantic graph: a naive example are fine-grained manufacturing dataset (e.g. cars, aircrafts) where recognition of a model exploits other cues (e.g. textual for the brand). Note that I am not questioning that GED is a good way of representing semantic changes, especially when ground-truth graphs are available, but just the assumption that GED is the best way to capture them in general. \n \n2. While SC uses a proxy for GED, the article explicitly focuses on finding the shortest GED, facilitated by the specific scene graph used as input. While these choices are indeed a positive aspect and a contribution of the method, the 2/3 comparison tables with SC in the main paper focus on GED (Table 1, Table 5). SC is not included in Table 2 (where GED is nevertheless used as a criterion)  and Table 4 (with human tests). While I understand that Table 4 is a direct replication of the study in CVE, including SC would make the analysis more comprehensive and strengthen the claim that the method outperforms SC even in other metrics (i.e. not related to GED)."
            },
            "questions": {
                "value": "I believe semantic graphs are a useful tool for providing interpretable and semantically grounded Counterfactual Explanations. At the same time, I have concerns regarding the experimental evaluation and the methodology that I hope the rebuttal could address. Specifically:\n1. Is considering GED as ground truth for the rankings fair?\n2. What are the main differences (in terms of contribution) w.r.t. SC? And why the performance differences with SC is limited for the Visual Genome experiments?\n3. Why the user studies focused on different type of baselines?\n4. How do performance/explanations vary w.r.t.the underlying scene graph extractor? E.g. applying SGG to extract graphs Visual Genome and CUB would impact the performance of the model?\n5. Do distances on scene graphs correlate with distances on the classifier space?\n6. What is the reason behind the choice of Places365 as the pretraining dataset for the results on Visual Genome?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Reviewer_iSZ3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698838707696,
        "cdate": 1698838707696,
        "tmdate": 1700747758921,
        "mdate": 1700747758921,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7IbKudmc3k",
        "forum": "Hk7yW3vmSq",
        "replyto": "Hk7yW3vmSq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_B8to"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_B8to"
        ],
        "content": {
            "summary": {
                "value": "This paper propose a novel counterfactual approach that focuses on semantics shifts instead of explaining models' decisions via pixel-level changes. The authors represent images as semantic graphs derived from semantically annotated datasets. Subsequently, the counterfactuals for a given query image are defined as the closest graph (measured by graph edit distance) from another class. To enhance computational efficiency, the authors propose training a GNN to approximate the GED computation. Experimental results on widely-used datasets demonstrate superior performance compared to previous methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors employ graph similarity between a query and a target image, which is the first attempt in this direction. The authors have evaluate the method's performance across various datasets spanning different modalities, including CUB (an image classification dataset) and COVID-19 (an audio classification dataset), demonstrating the model-agnostic nature.\n2. The authors provide code for reproducibility check.\n3. The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "[Major]\n\n1. **Method & motivation:** A primary objective of counterfactual explanation is to discover why and how the deep model (system) decision changes when specific regions within the given query image are modified. However, the semantics constructed in this paper rely on annotations from the dataset rather than capturing from the target model. Consequently, this raises concerns regarding the fidelity of the explanations generated by the proposed conceptual graph counterfactual method to the deep model's decision-making process. For instance, in the context of adversarial attacks [1-2], imperceptible image modifications to humans can significantly impact the model's output, a phenomenon unaddressed by the proposed method.\n\n\n>[1] DeepFool: a simple and accurate method to fool deep neural networks. (CVPR 2016)\n>\n>[2] One Pixel Attack for Fooling Deep Neural Networks. (IEEE Transactions on Evolutionary Computation 2019)\n\n\n\n[Minor]\n\n1. The font size in the figures is excessively small, making them particularly challenging to decipher when printed. Furthermore, it is advisable for the authors to employ vector graphics to enhance the quality of the illustrations.\n2. As the authors pointed out in Appendix H, the method relies on massive annotation. At present, large vision (multi-modal) models [3-5] have the capacity to produce annotations with rich descriptions. It is advisable to evaluate the proposed method in conjunction with these large models.\n\n>[3] A Unified Model for Vision, Language, and Multi-Modal Tasks. (ICLR 2023)\n>\n>[4] Learning transferable visual models from natural language supervision. (ICML 2021)\n>\n>[5] Segment anything. (arXiv preprint 2023)"
            },
            "questions": {
                "value": "My questions are listed in \"Weaknesses\" section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Reviewer_B8to"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698853662552,
        "cdate": 1698853662552,
        "tmdate": 1699636487009,
        "mdate": 1699636487009,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VBSlhNL3AM",
        "forum": "Hk7yW3vmSq",
        "replyto": "Hk7yW3vmSq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_DyGD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4995/Reviewer_DyGD"
        ],
        "content": {
            "summary": {
                "value": "This work analyzes scene graphs built on semantic attributes of the data. In particular given a scene graph, this work proposes a method to identify the closest scene graph -- in terms of graph edit distance --- with a different label. Solving this problem is NP-hard and hence, this work adopts an approximate solution that uses a GNN. The GNN computes an embedding for each graph such that the distance between the embeddings of two graphs approximates the graph edit distance. The authors evaluate this method on a variety of datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This works designs a novel solution to compute the closest scene graph with a different label. The work uses an simple and elegant solution to the problem that is similar to multi-dimensional scaling (MDS). \n\nThe experiments highlight that their work empirically outperforms prior works like CVE and SC. Their proposed method finds graphs with smaller edit distance across different benchmarks. The human evaluators also prefer CEs and find them significantly easier to use them distinguish classes. The author also show that their method is significantly more efficient compared to computing the underlying GED."
            },
            "weaknesses": {
                "value": "**Understanding the significance of this work: aren't counterfactual explanations used to understand model predictions?**\nI am not an expert in this area so I am unable to accurately evaluate the significance of this work. I am unable to understand how these counterfactual explanations will be used. What kinds of insights can they provide and in what scenarios can they be used? \n\nThe counterfactual explanations in this work are model-agnostic which means that they cannot be used to understand  how models make predictions. However, I am only familiar with counterfactual explanations (see [1]) that help us understand why models have arrived at a particular decision. Can model-agnostic counterfactual explanations be used for other tasks?\n\n**How do you generate the scene graph for each data point if it isn't available?**\nEach data points requires a scene graph which may not be readily available. For example, CUB does not have a ground-truth scene graph and the authors are forced to construct one. As a result, the counterfactual explanations will change depending on how the graph is constructed. If this is the case, how should the graph be constructed in order to get the \"right\" counterfactual explanation? In this case, is modelling the scene graph the right thing to do?\n\nAlso, why is the graph edit distance a reliable way to measure the distance? Perhaps, editing should be assigned less weight compared to deletion when computing the distance.\n\n**Quality of the model is limited by the quality of the labelled data.**\nThe labelled data uses an approximate algorithm to find the edit distance. As a result, the neural network will also approximate the sub-optimal solution and not predict the optimal answer. Are there ways to get around this hurdle?\n\n**Why use cosine distance in Eqn 4, and why not use euclidean distance instead?**\nSince the training objective is also based on the euclidean distance, wouldn't be a better distance measure to compute the nearest scene graph?\n\n\n**References**\n\n[1] https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pd"
            },
            "questions": {
                "value": "1. **Why do we need a neural network? Why can't we just compute the ground-truth?** Isn't it possible to compute the ground-truth graph edit distance between all pairs of graphs instead of training a neural network to make these predictions. Since we need to create a lot of training data, why can't we compute graph edit distances for the entire data by throwing lots of compute at the problem? \n2. **What is error from ground-truth?** How different are the predictions of the network when compared to the ground-truth? Do the feature vectors accurately reconstruct the MDS or are they only correlated? While, the proposed method outperforms other methods, how far away is it from ground-truth?\n3. **What are the benefit of being model-agnostic?** What kind of problems can these counterfactual explanations be used to tackle?\n4. **What should we do if the scene graph is not readily available for a problem?** How should we construct such a scene graph from semantic attributes?\n5. **Why is the counterfactual explanation given by the minimum graph edit distance useful?** Should we count the edit of two different attributes to be equivalent (say stripe pattern and color) or does it make more sense to count them differently."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4995/Reviewer_DyGD"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4995/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698877114387,
        "cdate": 1698877114387,
        "tmdate": 1699636486929,
        "mdate": 1699636486929,
        "license": "CC BY 4.0",
        "version": 2
    }
]