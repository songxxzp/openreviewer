[
    {
        "id": "bGBDTUZsy4",
        "forum": "8Ju0VmvMCW",
        "replyto": "8Ju0VmvMCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_9biR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_9biR"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to study the interaction between samples in supervised learning from a learning dynamics viewpoint. To that end, the authors propose a the labeled pseudo Neural Tangent Kernel (lpNTK), a new adaptation of the NTK which explicitly incorporates label information into the kernel. First, lpNTK is shown to asymptotically converge to the empirical Neural Tangent Kernel (eNTK). Then, the authors demonstrate how lpNTK helps to understand phenomena such as identifying and interpreting easy/hard examples and forgetting events. Finally, the paper shows a case study in which lpNTK is used to improve the generalization performance of neural nets in image classification via pruning and de-biasing."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper's main conceptual contribution of incorporating label information into the NTK is novel and interesting!\n- The connection to sample difficulty and forgetting events is an interesting use-case for the lpNTK and allows us to connect sample difficulty with training dynamics.\n- I found it pretty interesting that lpNTK allows for pruning and simultaneous utility improvements. This could open up another connection to selective prediction (learning a high-confidence subset of the distribution).\n- Related work appears sufficiently discussed."
            },
            "weaknesses": {
                "value": "- Should Eq (1) contain the sign operator wrapped around the last factor? In Section 2.2, it is stated that the paper does not use the whole error term but only the sign as shown in Eq (2). I am also not sure I was able to follow the explanation as to why the magnitudes should not matter. Could the magnitude be useful for ranking?\n- Although Figure 2 and the displayed evolution of distinct FPC clusters is insightful, I was wondering whether additional visualizations of the lpNTK would have been possible? \n- The results in Table 1 showing the forgetting events don't seem particularly impressive (especially on MNIST). Am I missing something here?\n- It would have been great if the authors had provided a visualization of some of the pruned samples. Are there any patterns present in pruned examples in particular?\n- It is evident that the authors tried really hard to fit the paper into the page limit. There are formatting artifacts in terms of very little vspace throughout the paper, especially towards the end of the paper (pages 7-9). I would strongly encourage the authors to reduce dangling words instead of resorting to these very evident formatting tricks."
            },
            "questions": {
                "value": "- Have the authors considered drawing connections between interchangeable and contradictory samples and forging / machine unlearning [1], i.e. by training on a specific point we could plausibly say that we have also optimized for another datapoint? \n\nOther questions embedded in Weaknesses above.\n\nI am willing to increase my score as part of the discussion phase if the authors can address my concerns.\n\nReferences:\n\n[1] Thudi, Anvith, et al. \"On the necessity of auditable algorithmic definitions for machine unlearning.\" 31st USENIX Security Symposium (USENIX Security 22). 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Reviewer_9biR",
                    "ICLR.cc/2024/Conference/Submission2038/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2038/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826640891,
        "cdate": 1698826640891,
        "tmdate": 1700711710492,
        "mdate": 1700711710492,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BXvkZKyEh1",
        "forum": "8Ju0VmvMCW",
        "replyto": "8Ju0VmvMCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_4TQg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_4TQg"
        ],
        "content": {
            "summary": {
                "value": "This paper enhances the Neural Tangent Kernel by integrating label information, which offers a more nuanced understanding of the interaction between samples compared to the existing eNTK method. The authors explore the relationship between lpNTK and eNTK, and use vector angles to classify samples into interchangeable, unrelated, and contradictory categories. This novel categorization facilitates a 'data-centric' improvement in model training. The idea is interesting, but there lack baselines to validate their proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The integration of label information into the Neural Tangent Kernel (NTK) represents a novel approach that enhances the characterization of sample interactions during optimization. And the sign approximation also makes sense.  \n2. The application of the proposed lpNTK is both reasonable and beneficial. It effectively validates the utility of lpNTK's mapping functions (vectors), demonstrating their practical effectiveness."
            },
            "weaknesses": {
                "value": "I have the following concerns:\n1. Concerning Theorem 1, the authors assert that 'the gap between lpNTK and eNTK will not be significantly different.' However, this seems contradictory to subsequent analysis and empirical studies presented. The paper's central theme appears to be the integration of label information for a more nuanced understanding of sample relationships. If the lpNTK kernel closely resembles the original eNTK, could the authors clarify how this supports the stated claim? This warrants further explanation.\n2. The categorization of samples into three groups mirrors the 'data-IQ' framework in Seedat et al. (2022), which also segments samples into easy, ambiguous, and hard categories. Data-IQ assesses prediction error and confidence throughout the training process, a concept seemingly echoed in this paper. I recommend that the authors draw comparisons with this methodology to highlight distinct aspects and contributions of their work.\n3. There lack baselines to validate the effectiveness of the proposed method for measuring sample similarity. For instance, the influence function is a known technique for understanding relationships between samples during training. A comparison with such established methods would provide a more robust validation of the proposed approach.\n4. It would be beneficial if the authors could include a computational complexity analysis of the lpNTK. This information would be crucial for understanding the practicality and scalability of the proposed method in different settings.\n\n[1] Seedat, N., Crabb\u00e9, J., Bica, I., & van der Schaar, M. (2022). Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data. Advances in Neural Information Processing Systems, 35, 23660-23674."
            },
            "questions": {
                "value": "Please refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Reviewer_4TQg"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2038/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699686480244,
        "cdate": 1699686480244,
        "tmdate": 1700712024696,
        "mdate": 1700712024696,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1hxH6llMAK",
        "forum": "8Ju0VmvMCW",
        "replyto": "8Ju0VmvMCW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_3vgc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2038/Reviewer_3vgc"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed to incorporate label information into the Neural Tangent Kernel (NTK) and designed a kernel called lpNTK to study the interaction between training examples. The author suggested classifying the relationships between a pair of examples into three types --- interchangeable, unrelated, and contradictory --- based on the angles between the vectors represented in lpNTK. The author then used these concepts to analyze some phenomena and techniques of learning dynamics, such as learning difficulty, forgetting, pruning, and redundancy. The observations and analyses were supported by experiments on the MNIST and CIFAR10 datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Disclaimer: I'm not very familiar with the literature and some technical details of NTK. I might be biased because other reviews are visible to me before I write mine.\n\n- The learning dynamics and learning difficulty is an important problem in many subfields of machine learning. The author provided nice theoretical tools for it based on NTK.\n- Incorporating label information is useful for analyzing many supervised learning tasks in a more fine-grained way. The use case of data pruning is reasonable and convincing. I believe that the proposed tools can be used to deepen our understanding of some methods for learning from noisy/imbalanced data.\n- This paper is well structured. The author raised intuitive hypotheses, asked clear questions, and then conducted reasonable experiments to verify them.\n- The author contextualized this paper well and discussed related work sufficiently."
            },
            "weaknesses": {
                "value": "- Maybe it's because I'm unfamiliar with the literature, but I feel that this paper can benefit from mathematically clearer definitions of some terms such as interaction and learning difficulty.\n- The author stated that \"contradictory samples are rare in practice\" but didn't explain why. I suspect that it's because the MNIST and CIFAR10 datasets used in experiments are relatively clean, and there are few ambiguous training examples. The conjectures in C.3 were nice, but I would expect more solid explanations or explorations.\n- The author did not discuss much about the limitations of this work.\n\nMinor issues:\n- Section 2.1: the abbreviation $\\mathbf{z} \\in \\mathbb{R}^K$ is misleading because I think $\\mathbf{z}$ is a $\\mathbb{R}^K$-valued function, not just a vector.\n- Rigorously, a simplex with $K$ values is $(K-1)$-dimensional, i.e., it should be $\\Delta^{K-1}$.\n- Since many methods for noisy label learning and selective prediction (classification with rejection) heuristically make use of the learning dynamics, it would be convincing to apply lpNTK to those applications. However, those can be future work directions."
            },
            "questions": {
                "value": "- It is not completely clear to me why it is reasonable to fix the similarity matrix $\\mathbf{K}$. Isn't it that a pair of training examples can be similar or dissimilar during different stages of training? How can we obtain the model that performs the best on the validation set in applications like data pruning?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2038/Reviewer_3vgc"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2038/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700035611983,
        "cdate": 1700035611983,
        "tmdate": 1700035611983,
        "mdate": 1700035611983,
        "license": "CC BY 4.0",
        "version": 2
    }
]