[
    {
        "id": "0pMuCV4Fnf",
        "forum": "7ipjMIHVJt",
        "replyto": "7ipjMIHVJt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
        ],
        "content": {
            "summary": {
                "value": "The authors present a new self-supervised learning model for the task of earthquake monitoring given Distributed Acoustic Sensing (DAS) data. Specifically, the authors specify the evaluation as an anomaly detection task, where the DASFormer outperforms a wide range of various supervised models for detecting seismic phases. The details and motivation of the construction of the DASFormer, with the accompanying figure, are clear. The study adds to the existing literature of demonstrating the opportunities that DAS data has to offer."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is clearly written and has a good structure that makes the paper nice to read. Enough details are given to understand the introduced DASFormer and the experimental setup. The evaluation on the seismic phase detection task includes an extensive range of supervised Deep Learning approaches, as well as a traditional baseline. On the downstream tasks the introduced SSL method shows significant improvement across metrics compared to the supervised methods."
            },
            "weaknesses": {
                "value": "Training Regime:\n\n- The laborious objective function came a bit surprised and is the part that could benefit from an inclusion in the figure\n\nEvaluation Scheme:\n\nThe main weakness I see in the paper, as I aim to layout below, is whether the selected methods DASFormer is compared to, are reasonable, or whether there could be other baselines that would perform stronger than the selected ones (even though they are regarded as SOTA)\n\n- I understand your main claim of the paper to be that your choice of architecture and training scheme can achieve superior results to existing Deep learning Models. However, your evaluation scheme is mainly demonstrating the usefulness of SSL pretraining using a lot more data than the other supervised methods have available. Thus, to me the more relevant question is why is your extensive pretraining technique necessary as opposed to \"more standard\" SSL methods in Computer Vision like MAE, Moco etc. In other words you should compare your SSL technique to another SSL technique to support the claim that it is necessary and superior. Therefore, I would be highly interested in a \"baseline\" SSL technique that you can compare the DASFormer results to. I would believe that this could potentially also give more insights into the unique aspects of DAS data. Additionally, you could evaluate the quality of extracted features from different SSL methods via Linear Probing\n- ignoring the DASFormer approach for a second, your results table shows that the \"traditional\" aggregation baseline \"aggregation-0\" is actually really strong, on par with or better than all the Deep Learning models, doesn't this illustrate that there could be potentially some other, much simpler modelling approach to achieve good results?\n- There is some literature, for example [Makridakis et al 2020](https://www.tandfonline.com/doi/full/10.1080/01605682.2022.2118629) and [Nixtla](https://github.com/Nixtla/statsforecast/tree/main/experiments/m3), showing that simple models outperform Deep Learning methods on time-series tasks, so I wonder what results you would get with a Random Forest for example, that could also offer more insights into \"explaining\" a model prediction\n- The authors point out several times that it is not appropriate to train models with the standard point-wise loss. However, this point-wise loss is applied in all the baseline models that the DASFormer is compared to, so shouldn't there be a comparison to a baseline that does not have this weakness?\n\nGeneral Comment:\n\n- Given the crucial task of earthquake monitoring and the author's acknowledgement that \"DAS data includes various stochastic noise, such as environmental and instrumental noise\", I was very surprised to not find the word \"uncertainty\" or a discussion thereof anywhere in the paper. Uncertainty is of course not a trivial topic, especially with Deep Learning models that are so over parameterized, nevertheless there should be an effort to at least discuss its influences and impacts."
            },
            "questions": {
                "value": "Content:\n- Under 5.1\"Implementation Details\" you state that the anomaly score is defined between the predicted model values and the actual values. How does your approach work in a \"real\" setting then when you are forecasting into regions without any data? Or is it enough due to the time-scale of seconds to detect an anomaly \"in hindsight\"? This was not entirely clear to me.\n- Are there advantages/disadvantages of the selected anomaly score distance metrics that you could discuss? \n\nWriting:\n- First sentence of section 3, I think you mean \"also known as\" instead of \"as known as\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698592906221,
        "cdate": 1698592906221,
        "tmdate": 1699636756696,
        "mdate": 1699636756696,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "05NAb3fdBC",
        "forum": "7ipjMIHVJt",
        "replyto": "7ipjMIHVJt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_Hht1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_Hht1"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a foundation model for DAS data (optic fiber), used in particular for earthquake detection. The specificities of the data (noise, time dependence, spatial dependence) are well studied in order to propose a specific fondation model; based on Swin-Unet, convolutional U-net and GAN-strategy. For the self-supervision, a masking strategy is applied. Comparisons with forecasting multi-variate time series and anomaly detection methods are performed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is correctly written, the method is interesting (even though very complex) and the forecasting results are convincing. But I have several major concerns that needs to be clarifed first."
            },
            "weaknesses": {
                "value": "1) The first concern is the goal of the paper. Indeed, DAS earthquake detectors exists (one of them was cited by the autors, PhaseNet-Das, Zhu et al. 2023, there might be others), and no comparison was made, nor a justification on the benefit of your method against theirs. If the claim is to say that this is a foundation model, and the test on this task is only as a proof of concept, it should be clearer, and then show or justify a future useful application.\n2) I think the purpose of a foundation model would be its applicability at a larger scale. Yet, is your method generalizable to other DAS sensors? It is not clear whether it is site and sensor-specific or not; if so it means a new self-training needs to be performed again for any new DAS.\n3) The whole idea of this method is that earthquakes are unpredictible. It is clever indeed, but I see 2 major limitations: 1) this foundation model is thus harder to use for other tasks (which could be predictable) 2) in a series of aftershocks (which could maybe be seen as more predictable), how does your measure performs? \n4) The comparison with other multi-variate time series are somehow misleading. Indeed, in multi-variate time-series, we suppose that the different time series (or sensors) are not ordered and not equally-spaced: DAS is a very particular type of 'multi-variate time-series'. I don't think it is worth presenting all of these methods (maybe only one), and it should be clearly stated in the paper. Yet, a comparison with image 2D foundation models, or by modifying a video framework from a 2D+t to a 1D+t, would be more relevant."
            },
            "questions": {
                "value": "Other questions:\n\nQ1) Masking: the authors said that it is inspired by BERT, but maybe closer to this application, by self-supervised on image data? like Pathak, Deepak, et al. \"Context encoders: Feature learning by inpainting.\" CVPR 2016.(and later works with ViTs)\nQ2) I don't understand the dynamic masking, and I don't see why it is useful. Does it comes from other studies?\nQ3) The ablation study should first be 'ablation': i.e. what if we only use the fine generator, or the fine coarse? What if we only use a 'generator' without the need of the discriminator? Also, why is the fine generator a convolutional U-net, and the coarse a Swin-based Unet?\nQ4) comparison with PhaseNet is rather unclear. First, it is stated that the table 1 shows comparisons with time series forecasting and anomaly detection, but PhaseNet is neither of those, and is only single-station. In the table, it is unclear the use of 'traditional method', and the 'aggregation'. Would have been best to compare with PhaseNet-DAS, no?\n\n- Figure 1 left: sensors and time axes not clear.\n- page 2 : define P and S\n- Figure 2: what is smm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698670838720,
        "cdate": 1698670838720,
        "tmdate": 1699636756563,
        "mdate": 1699636756563,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L0ntUSYvcU",
        "forum": "7ipjMIHVJt",
        "replyto": "7ipjMIHVJt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
        ],
        "content": {
            "summary": {
                "value": "Authors apply self-supervised learning to Distributed acoustic sensing (DAS) data to learn representations that are suitable for several downstream tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality.** While the application to DAS data might be original, the paper is essentially an application of self-supervised learning to a new domain.\n\n**Quality and clarity.** The paper is well-written and easy to follow.\n\n**Significance.** Results seem to be promising, lacks comprehensive sensitivity analysis to be a viable real-world solution."
            },
            "weaknesses": {
                "value": "* While the approach seems to outperform several baselines, the visual inspection of the forecasting results in the appendix is underwhelming.\n\n* Detection becomes more important and challenging for smaller earthquakes. It is unclear how the method performs for smaller earthquakes and whether there are many false positives.\n\n* I found this paper to be too focused on the application and not enough on the method. I feel there are not enough methodological novelties to make it a suitable choice for this conference."
            },
            "questions": {
                "value": "* It would be beneficial to conduct a sensitivity analysis of the method concerning the choice of hyperparameters, especially since this is a real-world application. As authors have indicated, this application is associated with hazards to public safety so quantifying the uncertainty of the method is crucial.\n\n* What is the distribution (histogram) of the metric as a function of earthquake magnitude? How does it compare to the baseline? How about traditional signal processing techniques?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793591521,
        "cdate": 1698793591521,
        "tmdate": 1699636756433,
        "mdate": 1699636756433,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aefLZvQc2M",
        "forum": "7ipjMIHVJt",
        "replyto": "7ipjMIHVJt",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_8ntH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6627/Reviewer_8ntH"
        ],
        "content": {
            "summary": {
                "value": "This article leverages a self-supervised pretrained network model to enhance seismic detection efforts, addressing the challenge of insufficient labeling for distributed acoustic sensing (DAS) data. The network architecture is thoughtfully designed with a Swin U-Net and Convolutional U-Net, allowing it to efficiently capture the spatio-temporal characteristics of DAS data. The network's performance is further enhanced through the implementation of various strategies, including convolutional pathing, DASFormer blocks, and noise injection. The primary contribution of this article lies in its introduction of a self-supervised pre-training framework for DAS seismic monitoring, even in cases where labeled data is unavailable. This framework is validated in downstream tasks such as earthquake detection and P/S seismic phase pickup."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The research problem is of great importance to society and is not well studied. \n2. Using a self-supervised pre-trained network model to enhance seismic detection efforts sound promising to address the challenge of insufficient labeling for distributed acoustic sensing (DAS) data.\n3. The network architecture is thoughtfully designed with a Swin U-Net and Convolutional U-Net.\n4. This framework is validated in downstream tasks such as earthquake detection and P/S seismic phase pickup."
            },
            "weaknesses": {
                "value": "This article introduces a novel self-supervised pretrained model for DAS data, yet it falls short in demonstrating its superiority over existing methods. The reasons for this decision are outlined below:\n1. While the paper compares different structures of pre-trained Benchmark models for seismic detection, these benchmarks suffer from poor representation and fairness issues:\n(1)\tThe 'Aggregation-0' and 'Aggregation-inf' models provided in Table 1 lack clear descriptions and references to existing work, making it difficult to understand their characteristics and suitability (I am not sure if this is the LTA/STA method?)\n(2)\tThe use of the j-DAS method, primarily designed for DAS data denoising, in a seismic detection comparison is considered unfair and may not yield equitable results.\n(3)\tThe absence of an effective comparison with established DAS seismic detection methods, such as CNN-RNN (Hern\u00e1ndez et al., 2022) and PhaseNet-DAS (Zhu et al., 2023), diminishes the paper's ability to demonstrate the effectiveness of its proposed approach\n2. The resampling of the dataset from 2000-4000Hz to 10Hz for pre-training lacks a comparative verification of its impact on downstream tasks. Notably, the usual data sampling frequency for seismometer-based seismic detection tasks is within the range of 100-250Hz.\n3. The paper does not adequately address the low signal-to-noise ratio (SNR) characteristic of DAS data, failing to provide clear information about the magnitude distribution and SNR of the training data. This omission leaves unanswered questions regarding the model's ability to detect earthquakes below a certain magnitude or signal-to-noise ratio. \n4. The paper fails to make a clear distinction between P/S phase pickup and seismic detection tasks. For seismic monitoring purposes, distinguishing between P/S phases might be unnecessary, causing confusion in the results presented in Table 1. Additionally, the paper lacks a detailed description of the dataset and evaluation metrics for the downstream task of accurate seismic phase-on-arrival pickup. It only mentions fine-tuned training with 20 labeled data points in Figure 4, leaving crucial aspects of this task unexplained.\n5. The paper lacks ablation experiments to elucidate the quantity of training data necessary for effective seismic monitoring.\n\n\nThe paper has many imprecise parts. Here are a few\n1.  The 'Deep Learning on DAS Data' section of the RELATED WORKS lacks sufficient relevance to DAS data, apart from PhaseNet-DAS and j-DAS. More pertinent related work should be incorporated to provide a comprehensive context.\n2. In the 'Time Series Modeling' section, the paper emphasizes the limitations of existing time series models in incorporating spatial information. However, there are network structures that can effectively integrate both spatial and temporal analyses. Including and comparing these structures with the work presented in this section would enhance the paper's precision.\n3. The paper emphasizes the role of the coarse and fine steps in its approach, but it does not include ablation experiments to demonstrate the individual contributions and effectiveness of these two components. Such experiments would provide valuable insights into the significance of each step.\n4. Figure 3 exclusively compares the earthquake detection effects of different prediction methods, with DASFormer being the only one shown to predict effective information. To enhance credibility, the paper should consider verifying and comparing these solutions with examples where other methods are equally capable of prediction, thus providing a more comprehensive assessment of their capabilities."
            },
            "questions": {
                "value": "please check the weakness part"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699089278448,
        "cdate": 1699089278448,
        "tmdate": 1699636756316,
        "mdate": 1699636756316,
        "license": "CC BY 4.0",
        "version": 2
    }
]