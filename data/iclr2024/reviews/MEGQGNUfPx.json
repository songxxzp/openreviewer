[
    {
        "id": "zD6gDu31la",
        "forum": "MEGQGNUfPx",
        "replyto": "MEGQGNUfPx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_FBLx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_FBLx"
        ],
        "content": {
            "summary": {
                "value": "This work aims to address the generalization gap in adversarial training. The authors exploit the random forgetting to adjust the  weights of models. Three datasets and two adversarial attacks are used to evaluate the proposed method. The experimental results show that the method can improve the robust accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This work proposed a new method to solve the generalization gap in adversarial training.  The perspective of random forgetting is interesting.\n\n2. The introduction to the forgetting mechanism in Methodology is clear."
            },
            "weaknesses": {
                "value": "1. The description in the caption of Figure 2 is inconsistent with the content of the image. The former states that the consolidation phase is behind the forgetting phase, while the latter expresses that theconsolidation phase is before the forgetting phase. In addition, please present more clearly in the figure what the generalized information is.\n\n2. In Figure 1, FOMO is only compared with standard adversarial training, but not with methods that aim to reduce the generalization gap (such as AWP). This result may not appreciably represent the effectiveness of the proposed method.\n\n3. The authors use two adversaial attacks to evaluate the proposed method, they can consider more adversarial attacks (such as L2-norm CW, DDN) to conduct a more comprehensive evaluation.\n\n4. Figures can be clearer and more aesthetically pleasing."
            },
            "questions": {
                "value": "Please see weaknesses.\n\n============After rebuttal============\nThe authors provide adequate explanations for most of my questions, so I am willing to raise the rating score to 6."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8178/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8178/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8178/Reviewer_FBLx"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8178/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698559158209,
        "cdate": 1698559158209,
        "tmdate": 1700641818773,
        "mdate": 1700641818773,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fvOpNBFB8X",
        "forum": "MEGQGNUfPx",
        "replyto": "MEGQGNUfPx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_WNii"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_WNii"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a method, FOMO, to deal with the adversarial overfiting issue. The proposed method alternates between the forgetting phase and the relearning phase."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is in good structure and easy to follow. \n\nThe topic, which is to deal with adversarial overfitting, is interesting.\n\nThe method is simple yet effective. \n\nAn ablation study is provided."
            },
            "weaknesses": {
                "value": "The description of the method is too intuitive. \n\nIn Table 1, the delta, which measures the adversarial overfitting, never favors the proposed method. This cannot show that the proposed method is good at dealing with adversarial overfitting."
            },
            "questions": {
                "value": "In this paper, the author only shows the result under a combination of white box and black box attacks, i.e., Autoattack. However, this cannot show \"the efficacy of FOMO against the black box and white box attacks\". Standard Autoattack has 4 adversarial attacks: three white-box attacks and one black-box attack. It is possible that FOMO has a strong resistance against white-box attacks while being vulnerable to the black-box attack."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8178/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8178/Reviewer_WNii",
                    "ICLR.cc/2024/Conference/Submission8178/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8178/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807201882,
        "cdate": 1698807201882,
        "tmdate": 1700624428087,
        "mdate": 1700624428087,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UO6vOHeGec",
        "forum": "MEGQGNUfPx",
        "replyto": "MEGQGNUfPx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_Jeha"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8178/Reviewer_Jeha"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the challenge of robust overfitting in adversarial training of deep neural networks, which affects their generalization performance. The authors propose a new method called \"Forget to Mitigate Overfitting (FOMO),\" drawing inspiration from the brain's mechanism of active forgetting. FOMO operates by periodically resetting a subset of the network's weights to promote the learning of more generalizable features. The approach suggests a promising direction for enhancing neural network robustness against adversarial attacks by mitigating overfitting through controlled forgetting and relearning. Experimental results show that FOMO is a promising method to improve model robustness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The authors conducted comprehensive experiments to demonstrate the effectiveness of FOMO. The proposed method is effective and outperforms the existing method, according to Table 3 and other experimental results.  \n* The proposed method is intuitive and easy to implement."
            },
            "weaknesses": {
                "value": "* My main concern is that the proposed method seems to be heuristic and empirical. there is not enough discussion on its intuition or theoretical foundation.\n* I don't think the running time and convergence analysis are well-studied in this paper, the authors may need to provide a table showing how many epochs are needed to converge and compare the running time with the existing methods. \n* Minor: Please refrain from only using color to distinguish curves and bars as in Figures 3, 4, 5, and 6, as it is not friendly to readers with color blindness.\n* Minor: Missing reference on robust generalization: Zhang, et al. \"The limitations of adversarial training and the blind-spot attack.\" ICLR 2019."
            },
            "questions": {
                "value": "Please refer to the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8178/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699421953368,
        "cdate": 1699421953368,
        "tmdate": 1699637013905,
        "mdate": 1699637013905,
        "license": "CC BY 4.0",
        "version": 2
    }
]