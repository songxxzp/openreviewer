[
    {
        "id": "E1oqbBlFll",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_6HHN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_6HHN"
        ],
        "forum": "fIKRJeLH7W",
        "replyto": "fIKRJeLH7W",
        "content": {
            "summary": {
                "value": "This paper proposes a framework called BCNAS-SNN that automatically searches for the optimal placement of global backward connections (BCs) in spiking neural networks (SNNs). They develop the search space and implement an effective BC search using an evolutionary algorithm and a two-step strategy. The authors show that BCNAS-SNN can discover effective BCs that improve the performance of SNNs on various datasets, such as CIFAR10, CIFAR100, Tiny-ImageNet, and CIFAR10DVS."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes a novel method to search for optimal backward connections in spiking neural networks. The paper introduces a two-step search strategy to efficiently explore the large search space of BCs placement. The paper also reveals an interesting phenomenon that the searched BCs prefer to be connected to the front layers of SNNs, which may inspire future architecture design of SNNs.\n\nThe paper is well-written and organized, with clear definitions and notations. The paper uses figures and tables to illustrate the concept of BCs and the results of the experiments."
            },
            "weaknesses": {
                "value": "We noticed that the performance increment is limited compared to previous works [1,2]. On dataset CIFAR-100, Guo et al [1] achieved 79.51% accuracy while this work reported a 78.59% average accuracy. Also, on dataset CIFAR10-DVS, this work reported an 82.60% accuracy, which is only 0.2% higher than Deng et al [2]. Also, although costly, it would be more convincing if authors post the result on ImageNet dataset, which is a more popular and large-scale dataset.\n\n[1] Guo, Y., Zhang, Y., Chen, Y., Peng, W., Liu, X., Zhang, L., ... & Ma, Z. (2023). Membrane Potential Batch Normalization for Spiking Neural Networks. ICCV.\n\n[2] Deng, S., Li, Y., Zhang, S., & Gu, S. (2022). Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting. ICLR.\n\nAuthors should demonstrate the extra training cost of the architecture search. In my understanding, the NAS usually requires more training cost. However, the performance improvement of this work is subtle. Whether using the extra training resources is worth the small performance gain?\n\nAuthors should explain why they choose to perform architecture search on backward connections and why adding BCs can improve the performance. What is the advantage of BC search compared with other NAS methods?"
            },
            "questions": {
                "value": "The results show that the searched BCs prefer to be connected to the front layers of SNNs. Is it because adding such connection can alleviate the problem of gradient explosion or gradient disappearance in deep networks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697193840526,
        "cdate": 1697193840526,
        "tmdate": 1699636517944,
        "mdate": 1699636517944,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "12YU7EPtb1",
        "forum": "fIKRJeLH7W",
        "replyto": "fIKRJeLH7W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_FSBw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_FSBw"
        ],
        "content": {
            "summary": {
                "value": "This study explores the potential benefits of introducing backward connections (BCs) in Spiking Neural Networks (SNNs) and proposes the BCNAS-SNN search framework to automatically identify the optimal BCs. The research findings indicate that BCSNN achieves state-of-the-art results on the CIFAR10/100 and Tiny-ImageNet datasets, and it is observed that BCs tend to be connected to the first two layers."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The research topic is forward-looking, exploring the potential benefits of BCs in SNNs. It introduces the BCNAS-SNN search framework for automatically searching for the optimal BCs."
            },
            "weaknesses": {
                "value": "There is a missing part on the right side in Figure 1. The validation of the experimental section is not sufficiently thorough. Additional experimental validation regarding non-residual structures such as VGG can be included. The method's application in ANN and SNN can be compared. A comparison with the accuracy without backward connections can be added in Table 1."
            },
            "questions": {
                "value": "Is this method constrained by computational resources, or are there plans to further optimize it for improved efficiency?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698132545299,
        "cdate": 1698132545299,
        "tmdate": 1699636517862,
        "mdate": 1699636517862,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lj0bdJKTpY",
        "forum": "fIKRJeLH7W",
        "replyto": "fIKRJeLH7W",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_SWJe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5207/Reviewer_SWJe"
        ],
        "content": {
            "summary": {
                "value": "This study investigates the impact of backward connections (BCs) on Spiking Neural Networks (SNNs) and introduces the Backward Connection Neural Architecture Search (BCNAS-SNN) framework to optimize BC placement. The research contributes by examining the effects of global backward connections in SNNs and proposing a novel search space for BC-based SNNs. Ablation studies are conducted to analyze design components."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This study is the first to comprehensively investigate the varying effects of global backward connections in SNNs.\n2. It introduces a two-step search strategy to reduce the search space of BCs."
            },
            "weaknesses": {
                "value": "Please refer to `Questions`."
            },
            "questions": {
                "value": "1. I would like to ascertain the precise definition of \"BCSNN.\" Is it an abbreviation for \"Backward Connection SNN\" and does it refer to subnets extracted from a supernet?\n\n\n2. The research lacks an analysis of time series data. While backward connections may exhibit potential advantages in time series data, their performance in static data is unclear. Some studies suggest that BCs perform similarly to forward connections in static data but offer improved biological relevance. Has the author conducted experiments on time series data like DVS gesture recognition to address this aspect, instead of focusing solely on static data?\n\n3. The analysis of the search process is not comprehensive.  \n   3.1. Is it established that 100 epochs of training are sufficient to fully converge the supernet? Has any experimentation been done to establish the relationship between the performance of a subnet extracted from the trained supernet and a subnet trained from scratch until full convergence? Is there a strong positive correlation between the two?  \n   3.2. How many different seed values were employed in the ablation study? The experiment showed a slight improvement in performance, so it's important to discern whether this improvement can be attributed to the variation in random seed values or if it is linked to the different search methods applied.  \n   3.3. In Experiment 8 of the ablation study, it would be valuable to provide a comparison by conducting the same experiment but with a random search strategy in step 2, thereby comparing evolutionary search to random search.  \n   3.4. Given that the evolutionary search in Experiment 8 appears less effective, could the author include a plot depicting the search iteration versus accuracy to help illustrate the search process?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698715840479,
        "cdate": 1698715840479,
        "tmdate": 1699636517773,
        "mdate": 1699636517773,
        "license": "CC BY 4.0",
        "version": 2
    }
]