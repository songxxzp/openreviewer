[
    {
        "id": "eCLngYKtWy",
        "forum": "SBj2Qdhgew",
        "replyto": "SBj2Qdhgew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_GNty"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_GNty"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the problem of trying to achieve fairness in a federated learning setting. There are multiple data sets that are all privately held and a model is trained for each one. The questions are: When are the models fair on each data set? And, when are the models fair on all the data?\n\nThe paper relates fairness in both settings and mutual information. In particular, they show that mutual information between the  model's prediction and the sensitive attribute is an upper bound on the square of statistical parity (Lemma 1). They also define \"local disparity\" as mutual information conditioned on the particular machine. They then analyze mutual information and show it comes from three sources: information only in the predictions or sensitive attributes, information in both individually, or information in both together.\n\nThey prove necessary/sufficient conditions about when mutual information is low depending on the sources of mutual information. I did not check the appendix for the proofs of these results.\n\nThey introduce a convex optimization problem for minimizing classification error subject to constraints that the mutual information and local information are low. They they solve the problem experimentally for different datasets and visualize the results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "\u2022 The paper investigates the problem of relating global and local fairness in the federated learning setting. According to them (I have not checked), the problem has not been studied before.\n\n\u2022 The use existing literature on partial information decomposition to identify sources of mutual information. \n\n\u2022 There are a ton of lemmas and theorems about when mutual information is small. It appears very comprehensive but I'd like a more direct narrative about what I should be surprised and impressed with.\n\n\u2022 I like the idea of the convex optimization problem and optimizing for error under mutual information constraints.\n\n\u2022 The experiments seem very comprehensive in terms of data sets and different settings of data distributions across clients."
            },
            "weaknesses": {
                "value": "\u2022 They don't persuade me that mutual information is the \"right\" notion of fairness. Lemma 1 establishes that mutual information is an *upper bound* on statistical parity but it could be a loose upper bound.\n\n\u2022 I think the presentation is difficult to follow and the paper should be rewritten in the following ways:\n- Give an example of the way the theorems and lemmas are proved.\n- I was confused by the general approach until I read the examples in Section 3.1. These examples aren't results so I think they should be moved up to the preliminaries section to facilitate understanding.\n- Lemma 1 and Lemma 2 are results proved by the authors but they appear in the preliminaries section. This was confusing to me especially because there was no discussion of how they were proved.\n- Unique information is used in the preliminaries before it is defined in Definition 3. I didn't find this definition helpful and I don't see similar definitions for redundant information or synergistic information. It would be great if you could define these three quantities in a direct and similar way. I don't know if this is true but maybe something like I(Z,Y|A \\cap B) is redundant information and I(Z,Y |A \\cup B) is synergistic information. I found the notation you used excessive.\n- I'm not sure from reading the main result section if the proofs of the theorems/lemmas following trivially from the definitions or not. Please make this clear with a proof of one of them.\n\n\u2022 The convex optimization section is very short. I think you should restructure to spend more space here given that it's one of your contributions.\n\n\u2022 I got the sense that the experiments were comprehensive but I was missing a discussion about what was interesting here. It'd be great to highlight interesting observations and findings from the experiments. Examples of how the mutual information perspective gives insight into local and global fairness would be great."
            },
            "questions": {
                "value": "Lemma 1 upper bounds statistical parity with mutual information, how loose is the upper bound?\n\nWhat are interesting observations from your expeirments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2342/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2342/Reviewer_GNty",
                    "ICLR.cc/2024/Conference/Submission2342/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698351797681,
        "cdate": 1698351797681,
        "tmdate": 1700685712729,
        "mdate": 1700685712729,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BjZyW3z2GT",
        "forum": "SBj2Qdhgew",
        "replyto": "SBj2Qdhgew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_rTkq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_rTkq"
        ],
        "content": {
            "summary": {
                "value": "This work presents an information-theoretic perspective on group fairness trade-offs in federated learning (FL) with respect to sensitive attributes. This paper leverages partial information decomposition to identify three sources of unfairness in FL. They introduce AGLFOP, a convex optimization that defines the theoretical limits of accuracy and fairness trade-offs, identifying the best possible performance any FL strategy can attain given a dataset and client distribution."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper studies group fairness from an information theory perspective, which is valuable for the community to understand the group fairness of FL.\n2. The decomposition result is interesting."
            },
            "weaknesses": {
                "value": "1. Although this paper proposes an optimization framework with Definition 5, it does not give any solution or algorithm for solving the problem. \n2. The experiments are somehow weak, both the baseline and dataset are rare. There are other works focusing on FL group fairness like [1,2], and also about fairness and accuracy tradeoffs, like [3], that should be compared.\n3. The visualization (table or figure) of accuracy and global-local fairness trade-off results is relatively insufficient relying solely on the Pareto Frontiers shown in Figure 3. \n4. It seems of vital importance to properly set the hyper-parameters $\\epsilon_g$ and $\\epsilon_L$ for the optimal trade-off. The acc-fairness Trade-off figure displayed in Figure 3, lacks discussion based on more experimental settings and datasets.  \n5. The experiment setting details are not clear, for example, what is the used model and parameter settings?\n\n[1]Ezzeldin Y H, Yan S, He C, et al. Fairfed: Enabling group fairness in federated learning[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(6): 7494-7502.\n[2]Papadaki A, Martinez N, Bertran M, et al. Minimax demographic group fairness in federated learning[C]//Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency. 2022: 142-159.\n[3]Wang L, Wang Z, Tang X. FedEBA+: Towards Fair and Effective Federated Learning via Entropy-Based Model[J]. ICLR 2023 Workshop ML4IoT.\n\nMinors:\nWhat is the formal definition of global fairness and local fairness?"
            },
            "questions": {
                "value": "1. Could you explain the main difference from [4]?  It seems it is a trivial improvement (Apply the PID analysis on FL) compared with this paper.\n2. Could you provide experiments of different baselines and different datasets, in the FL setting (partial client participation of cross-device FL.)\n3. Could you provide more results for trade-offs on accuracy and global-local fairness?\n4. Could you provide more details about the selection of hyperparameters to ensure optimal trade-off strategy under different data distributions and datasets?\n\n[4] Dutta S, Hamman F. A Review of Partial Information Decomposition in Algorithmic Fairness and Explainability[J]. Entropy, 2023, 25(5): 795."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2342/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2342/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2342/Reviewer_rTkq"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767378142,
        "cdate": 1698767378142,
        "tmdate": 1700751716455,
        "mdate": 1700751716455,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sbAhdaeStC",
        "forum": "SBj2Qdhgew",
        "replyto": "SBj2Qdhgew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_P5hg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2342/Reviewer_P5hg"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces information theoretic tools to interpret the relationship among multiple group fairness trade-offs in federated learning. It is commonly known that global and local fairnesses both contribute to unfairness in federated learning, but their relationship (e.g. whether one implies the other) is unknown. The authors identify three fundamental sources of unfairness, and utilize them to derive fundamental limits on the trade-offs between global and local unfairnesses."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This paper provides a novel \"solution\" for unfairness in federated learning. Even if this issue has been extensively studied, there has been few work attempting to investigate the fundamental root that causes unfairness, let alone giving a theoretical explanation. This work uses a mathematically rigorous tool to give a promising attempt to explain unfairness. The theoretical justifications are rigorous and insightful.\n\nIn particular, Theorems 1, 2 and 3 are both conclusive and powerful, so that one may predict the fairness performances based upon those three sources of unfairness."
            },
            "weaknesses": {
                "value": "Overall this paper is well-written, but in Section 2, it would be great if the authors could provide some more justifications for Definitions 1 and 2, both mathematically and conceptually, even if the definitions are indeed fairly intuitive. This may be immensely helpful for readers especially those who do not have a strong background in information theory."
            },
            "questions": {
                "value": "1. This was mentioned in the Weaknesses section, and I would be very interested in seeing more explanations for choosing those definitions.\n\n2. Under a concrete data set, how are Uni(), Red(), and Syn() efficiently computed? I might be wrong, but my first impression is that, since they are relevant with mutual information, such computation may be expensive?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793093829,
        "cdate": 1698793093829,
        "tmdate": 1699636166307,
        "mdate": 1699636166307,
        "license": "CC BY 4.0",
        "version": 2
    }
]