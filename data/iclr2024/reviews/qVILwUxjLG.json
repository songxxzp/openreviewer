[
    {
        "id": "x5w2aKrXQP",
        "forum": "qVILwUxjLG",
        "replyto": "qVILwUxjLG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_jNAd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_jNAd"
        ],
        "content": {
            "summary": {
                "value": "The authors propose their NeuralPES algorithm and mention that it aids recommendation systems for real-world dynamics such as seasonal preferences. They combine a  neural network architecture with their  proposed exploration strategy which they claim can more efficiently gather valuable information in evolving environments. They empirically evaluate it on real world datasets such as the Microsoft News website, where they compare it against baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* Overall the paper is well written and clear to follow.\n* The theoretical analysis and ablation studies are comprehensive."
            },
            "weaknesses": {
                "value": "* Nit: Some of the plots (Figure 3) are hard to read, could be plotted more clearly.\n* It would be interesting to see this evaluated in a a real world dataset, distinct from the recommender system tasks to compare it's performance in a different domain, eg dynamic pricing"
            },
            "questions": {
                "value": "The limitations of the work are not clearly described. What are (if any) some of the challenges with this approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None so far."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697514921991,
        "cdate": 1697514921991,
        "tmdate": 1699637067976,
        "mdate": 1699637067976,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xtMDTZa7FA",
        "forum": "qVILwUxjLG",
        "replyto": "qVILwUxjLG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_Coy3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_Coy3"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the contextual nonstationary bandit problem, presenting NeuralPES, a deep neural network-based algorithm as a solution. The algorithm is a combination of ensemble sampling and future reward prediction, achieved through sequence modeling.\n\nIn essence, NeuralPES can be interpreted as a neural network implemented version of Linear Predictive Sampling (LinPS), a model that holds regret guarantees under various nonstationary environments.\n\nThe effectiveness of this approach in dealing with nonstationarity is corroborated by experiments conducted with (i) synthetic data, (ii) a real-world dataset featuring short-term nonstationarity (one week), and (iii) a real-world dataset with long-term nonstationarity (two months)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper, to my knowledge, is the first to address nonstationarity by considering the rate at which information disappears in the future, taking into account the applicability to real-world data.\n\nIn real-world data, there exist high-dimensional, non-linear, and diverse features (or contexts). This paper proposes a neural network-based method and architecture that allows efficient handling of these features while effectively addressing non-stationarity (via prediction). The usefulness of this approach has been verified across various applications.\n\nAs an algorithm, it enables NN-based sequence reward modeling, which predicts future rewards based on the weight sequence of past models, and ensemble sampling, which can be applied even when it is difficult to calculate the posterior distribution, to be combined.\n\nThe authors have been able to experimentally demonstrate superior performance compared to other neural-based bandit algorithms, as well as their sliding window versions."
            },
            "weaknesses": {
                "value": "I have many concerns regarding this paper, all of which I believe to be addressed by the authors.\n\n1. The paper lacks a clear comparative analysis between PS and NeurPS. It would be beneficial for the readers if the authors could elucidate the apparent differences between the two.\n\n2. The authors mention that PS \"suffers from their scalability\" and \"it does not efficiently scale\", however, the specifics of these issues are not clearly outlined. I would recommend providing concrete examples or explanations to support these statements.\n\n3. It seems that PS (Liu et al. 2023) operates on an infinite reward sequence for decision-making, yet this element is not present in the current paper. It would be interesting to know how this differs or if it is similar. Either way, a discussion on this point seems necessary.\n\n4. The theoretical analysis may appear almost identical to that of (Liu et al. 2023). Are there any differences that the authors could highlight?\n\n5. How much execution time is required for NeuPS's learning and inference (or decision-making)? Considering the time-intensive nature of neural network training and inference, and even more so for ensemble models (depending on the value of M), it would be important to discuss the scalability implications of the execution time.\n\n6. Given that the authors are using an \"A100 40GB GPU\", if the learning time is long, this could significantly increase the cost, which is a critical factor for practical applications.\n\n7. The authors state that \"the regret of LinPS is zero\" and \"LinPS achieves 0 regret\". Is this regret referring to long-run average regret?\n\n8. The paper mentions that the algorithm \"is such optimal\". It would be helpful if the authors could clarify what they mean by \"optimal\", as many algorithms can achieve a long-run average regret of 0.\n\n9. How is the ensemble size M set? Is it adjusted for each experiment? Knowing the effect of its size on reward changes and computation time seems necessary for demonstrating scalability.\n\n10. For the long-term experiments, how is the data processed? The authors mention grouping every 12 hours of recommendation into a contextual bandit format. Does this mean that the order of recommendations presented within the 12-hour period is ignored? If so, could this introduce bias?\n\n11. Despite the major contributions of the paper appearing to lie in the experimental section, the experiments are not written in a reproducible manner. The code is not shared, and it seems that there are parameters, such as the value of M, that are not mentioned in the paper."
            },
            "questions": {
                "value": "I hope you can answer me about the comments I wrote in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Reviewer_Coy3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698558693709,
        "cdate": 1698558693709,
        "tmdate": 1699637067841,
        "mdate": 1699637067841,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YAH9OIAqiJ",
        "forum": "qVILwUxjLG",
        "replyto": "qVILwUxjLG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_Fa2p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_Fa2p"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors study a non-stationary contextual bandit problem and propose an algorithm called Neural Predictive Ensemble Sampling (NeuralPES), which is scalable with neural network structure and incorporates an exploration mechanism. The authors provide theoretical results that show the strength of their method over NeuralEnsemble, a neural network based Thompson sampling algorithm. Finally, they conducted numerical experiments and tested the effectiveness of their approach on non-stationary real-world data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well organized, with both theoretical results and empirical evaluations on real-world data set.\n- The problem of non-stationary contextual bandits remain largely unexplored and has potential real-world significance. \n- The authors provide good insights for why prioritizing last information is important in a non-stationary environment."
            },
            "weaknesses": {
                "value": "- One major weakness is that I find it hard to evaluate the significance of the theoretical results presented in this paper. It appears that the authors have only compared the performance of the LinPS algorithm against TS in a non-stationary environment, which is restricted to linear contextual bandits setting and also does not really reflect the optimality/near-optimality of the algorithm. \n- It is unclear how the non-stationarity of the environment is defined. Does the proposed algorithm deal with all kinds of non-stationarity? Related to the point I raised above, the theoretical results that the authors provide are only for environments with abrupt change or AR(1) type of changes. But the paper positions itself in a way that suggests the algorithm can deal with any kind of non-stationarity.\n- The current results also appear to extend from similar results established under the non-contextual bandit setting. A discussion that establishes connection between the results here and those for non-contextual bandits would be helpful. \n- The presentation of the algorithms also make it difficult for readers to comprehend what each component is designed for. Currently there are 5 algorithms in the paper and the relationship among these algorithms is unclear. For example, what is TrainNN used as part of Algorithm 4? What are the connections between all of the algorithms? Why are you presenting Neural Ensemble Sampling before NeuralPES and can you highlight the differences?"
            },
            "questions": {
                "value": "I also have some questions related to the theoretical results established:\n- Could you provide more discussions that help readers understand the regret bounds in Theorem 1 and Corollary 1? For example, I am not sure what is $\\mathbb{I}(\\theta_2; \\theta_1)$ in the regret bound of THM 1. In corollary 1, please also elaborate on what the entropy term represents.\n- I am also unsure of the statement that says when $\\theta_t$ changes very quickly, \u201cthen the regret of LinPS is zero that LinPS achieves optimal\u201d. Could you elaborate? From the regret term defined in Definition 3, it seems that the benchmark that the algorithm is compared against is the best arm at every $t$. How could the regret be zero when the changes are even more frequent?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8538/Reviewer_Fa2p"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698607668301,
        "cdate": 1698607668301,
        "tmdate": 1699637067710,
        "mdate": 1699637067710,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RPadC40cVX",
        "forum": "qVILwUxjLG",
        "replyto": "qVILwUxjLG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_EExp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8538/Reviewer_EExp"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the contextual bandits due to non-stationarity caused by factors like seasonality and evolving social trends. Existing algorithms either overly explore or cannot handle high-dimensional user-specific features and large action sets. The paper introduces a non-stationary contextual bandit algorithm that combines a scalable deep neural network architecture with a strategic exploration mechanism that prioritizes valuable information in a changing environment. Empirical evaluations on real-world recommendation datasets with non-stationarity show that this approach outperforms state-of-the-art baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It is very interesting and necessary to extend neural bandits to the non-stationary environment. It is indeed my first time to see the neural bandit's work extending to non-stationary. The introduced algorithm is embedded with slide window to overcome the changing reward mapping."
            },
            "weaknesses": {
                "value": "However, (1) I am not very convinced by the exploration effectiveness of ensemble networks. The exploration comes from randomly draw ing neural models, but it doesn't consider the estimation confidence interval of a single neural model like UCB or TS. It looks like an ensemble of greedy models. \n\n(2) The training cost is too huge for this approach. In linear bandits, the training of linear models can be trained quickly. But for neural models, it cannot work. For one neural model, the training cost is already huge, but the algorithm needs to train a set of neural models in each round. Especially, it is for online learning scenarios. I don't think this algorithm can be scaled to large systems in practice.\n\n(3) The analysis is for the linear model with linear reward function, which avoids the challenge of analyzing neural networks."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698698179210,
        "cdate": 1698698179210,
        "tmdate": 1699637067576,
        "mdate": 1699637067576,
        "license": "CC BY 4.0",
        "version": 2
    }
]