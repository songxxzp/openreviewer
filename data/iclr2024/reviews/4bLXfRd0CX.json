[
    {
        "id": "8wUoPIKgar",
        "forum": "4bLXfRd0CX",
        "replyto": "4bLXfRd0CX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_XE26"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_XE26"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a training objective called Earth Mover Distance Optimization (EMO) for autoregressive language models. In contrast to maximum likelihood estimation, which solely enhances the likelihood of the ground-truth token, EMO takes into account the embedding similarity between predicted tokens and the ground-truth token, promoting predictions of tokens with high embedding similarity. Experimental results demonstrate that EMO generates superior outputs compared to MLE when employing unbiased sampling."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper is easy to follow. The presentation is mostly clear."
            },
            "weaknesses": {
                "value": "1. **There are significant concerns regarding the evaluation methodology in this paper. Comparing MLE and EMO based on outputs generated by unbiased sampling is unfair, as the two objectives result in considerably different model distributions.** The expected MLE loss is minimized when the model distribution Q matches the data distribution P. As mentioned in the paper, the expected EMO loss is $E_{v_i ~ Q}[\\sum_{j=1}^{|V|}P(v_j)C(v_i, v_j)]$, which is minimized when the model distribution Q is a one-hot distribution that only outputs the token i that maximizes $\\sum_{j=1}^{|V|}P(v_j)C(v_i, v_j)$. Consequently, models trained using EMO will predict a much sharper distribution, leading to higher-quality but lower-diversity outputs when sampling from EMO. The evaluation methodology in this paper, i.e., comparing the sampling results of EMO and MLE, is therefore like comparing the output quality of greedy decoding and unbiased sampling, which is inherently unfair. The fair way is to compare their decoding results of greedy/beam search, necessitating further experiments to establish the effectiveness of EMO.\n\n2. Based on the above analysis, the authors' motivation appears to be flawed. Under ideal circumstances, MLE trains the model to conform to the data distribution. In contrast, EMO results in a one-hot distribution, which is recall-prioritization and negative diversity ignorance. \n\n3. The proposed EMO loss is very similar to the word embedding-based loss [1]. The only difference lies the choices of distance mertics (Cosine distance in EMO, Euclidean distance in [1]).\n\n[1] https://arxiv.org/pdf/1807.11219.pdf"
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Reviewer_XE26",
                    "ICLR.cc/2024/Conference/Submission1681/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1681/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697725746625,
        "cdate": 1697725746625,
        "tmdate": 1700218576441,
        "mdate": 1700218576441,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ymzpfZWBLq",
        "forum": "4bLXfRd0CX",
        "replyto": "4bLXfRd0CX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_JZqx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_JZqx"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel loss function, EMO. The main idea behind emo is to soften the loss function (vanilla cross entropy) based on the cosine similarity of pretrained lm head embeddings. EMO demonstrates consistently better than MLE across models, tasks, scales, and metrics."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well-organized and well-written, so it is generally easy to follow.\n2. The intuition of the idea makes sense, and it is good that the complex earth mover distance loss can be reformulated into the cosine similarity dot probability. \n3. The author(s) conducted extensive and detailed experiments, encompassing different model sizes, data scales, and evaluation metrics (which is very important). The thorough and detailed experiments show the advantages of EMO, adding to the soundness of the paper."
            },
            "weaknesses": {
                "value": "I have two concerns here.\n\n1) Originality of the method.\nIn my view, the final loss function is very similar to the d2gpo loss, the authors did cite the d2gpo paper, but they ignored the methodology comparison and they should add d2gpo as a baseline.\n\n2) Why Cosine Similarity?\nUsing cosine similarity is a choice, but may not be the best choice. The cosine similarity relies on the pre-trained llm head embedding, which makes it not unbiased. And through the 3.3 section, the gradient of the proposed EMO is very similar to the REINFORCE with cosine similarity as the reward, so maybe RLHF/RLAIF will be a better reward model?"
            },
            "questions": {
                "value": "pls see weakness and the following questions:\n\n3) why EMO can make ppl better? ppl is directly related to MLE, in other words, there does not exist a training-test mismatch problem. Is that because the evaluation is conducted over the sampled sentences instead of the test set. If so, please also report the ppl in another table.\n\n4) please also compare with label smoothing, which is also a very useful loss function in the era of pre-llm.\n\n5) what does the accuracy mean in sec 4.2.3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Reviewer_JZqx"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1681/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698764474065,
        "cdate": 1698764474065,
        "tmdate": 1699636096300,
        "mdate": 1699636096300,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KTCGbptnN5",
        "forum": "4bLXfRd0CX",
        "replyto": "4bLXfRd0CX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_TjsD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_TjsD"
        ],
        "content": {
            "summary": {
                "value": "The authors propose to train the language model using an upper bound of Earth Mover Distance. The cost function of EMO is established by the similarity of embeddings from pretrained language model. The authors provide theoretical analysis and argue that EMO is better at handling synonyms compared with MLE. Experiments on various tasks demonstrate EMO's superiority."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors propose to apply the Earth Mover Distance to train the language model and establish an upper bound for practical backward propagation training.\n2. The experiments demonstrate promising performance of EMO on various tasks."
            },
            "weaknesses": {
                "value": "1. The authors argue that MLE exhibits a recall-prioritization behavior, which serves as the primary motivation for introducing their proposed approach, EMO. The claim appears to be confusing, as MLE is equivalent to minimizing the forward KL-divergence, i.e., $KL(p||q_{\\theta})$.\nIf the model $q_{\\theta}$ has sufficient capacity, the optimal $q_{\\theta}$ converges to $p$. Otherwise, $q_{\\theta}$ tends to exhibit a mean-seeking behavior. Therefore I have doubts about whether \"recall-prioritization\" is proper.\n\n2. As pointed out in Section 3.3, EMO exhibits a property of harmonizing recall and precision. A straightforward inference is that EMO is better at handling synonyms compared to MLE, potentially granting EMO-trained models the capability to generate more diverse texts than models trained with MLE. The authors did not conduct such experiments.\n\n3. I guess the distribution of model trained by EMO is very different from that by MLE. However, there's no experiments and analyses regarding that."
            },
            "questions": {
                "value": "What are the results of EMO-trained models and MLE-trained models when employing beam search instead of sampling?\nI am curious as sampling reflects the entire distribution, whereas beam search captures the distribution's mode."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1681/Reviewer_TjsD"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1681/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837750531,
        "cdate": 1698837750531,
        "tmdate": 1699636096216,
        "mdate": 1699636096216,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IUohXjvzQZ",
        "forum": "4bLXfRd0CX",
        "replyto": "4bLXfRd0CX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_2RWM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1681/Reviewer_2RWM"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to train \"decoder-only\" language model with a different loss function EMO  derived from the EMD (Earth Moving Distance).  The motivation is threefold: Tradeoff between Recall and Precision, Negative Diversity, Train-Test Consistency. These three points are clearly defined and compared for the standard loss (maximum loglikelihood, MLE) and EMO. The authors propose to define the inner cost of this distance with a semantic similarity (cosine between word vectors obtained from a pretrained LM). They also use a more tractable upperbound on the EMD.  The experimental setup proposes different kind of evaluation to assess the impact of this new training strategy."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is overall well written and describes an interesting idea. The experimental setup is well described and the results look reproducible."
            },
            "weaknesses": {
                "value": "A \"related work\" section is missing, and it could be nice to better discuss the introduction of EMD (and optimal transport in general) in NLP and this kind of task. \n\nThe experimental setup focuses on the improvement of MAUVE. This is a quite recent metric that makes a tradeoff between precision and recall. While it is interesting to use that metric, it could be nice also to provide also perplexity. I know MLE optimizes the perplexity so it is not fair for EMO, but it can provides a meaningful comparison point (I mean in table 1)."
            },
            "questions": {
                "value": "The decoding process is unique and since your purpose is to improve diversity, it could be nice to have a discussion on decoding, ie generation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1681/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699431252947,
        "cdate": 1699431252947,
        "tmdate": 1699636096123,
        "mdate": 1699636096123,
        "license": "CC BY 4.0",
        "version": 2
    }
]