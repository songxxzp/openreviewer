[
    {
        "id": "EtFeXrJKaR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_E32F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_E32F"
        ],
        "forum": "r1IbewSnqq",
        "replyto": "r1IbewSnqq",
        "content": {
            "summary": {
                "value": "The authors propose a new aggregation scheme for FL instead of regular FedAvg. For this, they draw on quadratic voting proposed in the election literature and design a scheme where the weighting of submitted gradients is determined based on both the similarity to the previous global model and a voting budget. The authors also briefly discuss an optimization/extension that includes a reputation system. Notably, the scheme is compatible with existing privacy-preserving and robust aggregation schemes. The authors successfully evaluate the resistance of their scheme when training for standard image classification tasks under a wide range of targeted as well as untargeted data and model poisoning attacks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written and accessible for non-experts.\n\nThe suggested scheme is compatible with secure and robust aggregation schemes.\n\nThe claims on convergence and truthfulness are theoretically proven.\n\nThe authors evaluate the effectiveness on a wide range of both untargeted and targeted attacks instead of focusing on only a specific type of attack."
            },
            "weaknesses": {
                "value": "References and appendix are not included in the submission PDF and can only be found in the supplementary material.\n\nIt is unclear why the similarity computation takes place on the client instead of server side. Moreover, it is unclear why the server simply relies on the submitted similarity score s instead of verifying this computation. I assume this is for compatibility with secure aggregation methods where the server does not see gradients in the clear. However, this is not discussed and gives opportunity for trivial attacks where the client submits an extremely harmful w but lies about similarity s. Likewise, it might be worth to discuss what happens if advanced attackers optimize their malicious w to cause maximum damage while still keeping the similarity just below the detection threshold.\n\nIt is furthermore unclear to me how the proposed \"masked\" voting rule is supposed to prevent the client from tracking their voting budget. The propsed rule H simply is a log calculation over the normalised similarity s. Intuitively, the clients can thus at least roughly estimate its budget and act accordingly.\n\nThe paper assumes a very high number of malicious clients in the system, e.g., it discusses cases where \"attackers manage to control the majority of votes, then via poisoning their tyranny will manifest itself as a degradation of the accuracy of the FL model used by the minority\". In the experiments, between 10%-50% is assumed. However, Shejwalkar et al. (SP'22) have shown that in cross-device production systems the corruption is below 0.1%. It remains unclear how FedQV performs in these settings.\n\nThe considered data poisoning attacks are not all state of the art. For example, the authors consider simple static label flipping (Fang et al.) but not more advanced dynamic label flipping attacks (Shejwalkar et al., SP'22).\n\nThe paper states that robust aggregations cannot be combined with secure aggregation. However, works like HyFL (arXiv:2302.09904) implement such aggregation schemes in secure computation."
            },
            "questions": {
                "value": "- Why does the server not compute and verify the similarity measure?\n- How does the masked voting rule prevent the client from roughly tracking/estimating the remaining budget?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Reviewer_E32F"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7549/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697365191291,
        "cdate": 1697365191291,
        "tmdate": 1699636913132,
        "mdate": 1699636913132,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0P9CIONams",
        "forum": "r1IbewSnqq",
        "replyto": "r1IbewSnqq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_dir9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_dir9"
        ],
        "content": {
            "summary": {
                "value": "Federated learning is vulnerable to poisoning attacks by malicious participants. This gets aggravated when the influence of parties is proportional to the amount of data they have. This is due to the fact that malicious participants that claim to have large datasets have a big impact when they send corrupted updates. \n\nThis work presents FedQV, a technique to improve resilience to byzantine attacks in federated learning by leveraging ideas from different domains. First, the work takes ideas from quadratic voting, a technique for robust aggregation of weighted contributions that reduces the otherwise-large influence of participants that possess big datasets. Second, it proposes a control mechanism that requires users to publish the similarity of their updates with respect to the previous global model. Third, it proposes a truthful mechanism that incentives parties to upload consistent contributions to maximize its own utility. Finally, it provides a reputation based approach which assigns different weights to contributions depending on their past faults. \n\nThe paper theoretically shows convergence in the presence of malicious adversaries as well as improved resilience when compared to regular Federated Averaging. In addition, it shows improved resilience when FedQV is combined with other defense measures taken by the server."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes novel ideas by taking techniques from different domains.\n\nI think that the inclusion of incentive-based approaches to deal with corrupted parties is currently less explored that other techniques and can potentially provide new means to understand which attacks are realistic. Therefore, this is a valuable aspect of the contribution. \n\nOther ideas such as the integration of robust voting techniques and the use client-side measures are original and constructive in the discussion of byzantine resilience. In particular, techniques that are compatible with privacy enhancing technologies such as secure aggregation are valuable, especially given that an important use case of federated learning is privacy preserving machine learning."
            },
            "weaknesses": {
                "value": "However, the contribution presents major problems which are listed below: \n\n1- The threat model of the paper is not clear. A well defined threat model is crucial when studying defenses against active adversaries. In the current contribution, I do not see what are the adversaries' possible behaviors and what are they willing to risk to harm the model (e.g. are they able to collude?). Therefore, it is not clear in practice in which scenarios would the truthfulness and convergence properties hold. This makes hard to evaluate the real impact of the contribution. \n\nFor example, consider an adversary which controls many parties and each party sends a harmful update in a different round. The adversary is willing to sacrifice parties to harm the model. Would this affect the truthfulness property? \n\n2- Clarity. The contribution is a combination of many ideas taken from different domains. However, the inclusion of each ingredient is not properly justified:\n\n2a- The paper introduces quadratic voting (QV) as a defense to reduce the impact of malicious users that falsely claim to have large datasets. However, the paper does not show how this kind of attack can affect other current Federated Learning defenses in practice and how QV is an effective defense. Moreover, the paper does not evaluate the resilience against any attack in which the adversary falsely claims to have a large dataset. Therefore, I am not sure if the initial motivation of QV is present in practice. \n\n2b- The paper introduces adaptive budgets as a reputation system. The original FedQV (Algorithm 1) already seems to penalize contributions. Therefore, the reputation protocol (Algorithm 2) appears a bit redundant. In the following sections of the paper, it is not clear when FedQV-Alg1 and FedQV-Alg2 are applied. \n\n2c- Compatibility with privacy enhancing primitives. In Section 3.2, the paper claims that the compatibility with privacy enhancing primitives (Secure Aggregation, Fully Homomorphic Encryption, Differential Privacy) is one of its main benefits of FedQV. However, I do not see a clear compatibility. For example, in Secure Aggregation the aggregation is not done by the server. Therefore, it not clear (i) how can the server adjust the weights of the aggregation properly and (ii) how can clients share similarity scores and local dataset size with the server without breaking the privacy guarantees. \n\n2d- Meaning of the truthfulness property: Section 4.2 claims that any possible corrupted contribution diminishes the probability of harm as server penalties reduce the influence of corrupted parties. This gives the impression that being honest is better for local utility than performing an attack. However, this is not what we can see empirically in section 5.  \n\n3- Evaluation of FedQV:  the proposed protocol claims to be easy to integrate with other resilience measures because similarities are computed in the client side. As said, this is an interesting feature, but is particularly vulnerable to client-side manipulations of the similarity scores and dataset sizes. It is true that protocol is evaluated against QV-adaptive, an attack that exploits this vulnerability. However, delegating the control of the defenses to possibly malicious clients is a high risk to take. Therefore, its evaluation of this risk requires a more comprehensive treatment. \n\nFor example, an important aspect of the evaluation which I feel is missed is (as said in point 2a) the resilience against an attack in which the adversary falsely claims to have a large dataset."
            },
            "questions": {
                "value": "Please elaborate on the weaknesses outlined above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Reviewer_dir9"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7549/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698684024287,
        "cdate": 1698684024287,
        "tmdate": 1699636912996,
        "mdate": 1699636912996,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LHSnTwhF4O",
        "forum": "r1IbewSnqq",
        "replyto": "r1IbewSnqq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_WYWh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7549/Reviewer_WYWh"
        ],
        "content": {
            "summary": {
                "value": "The paper introduced the quadratic voting scheme into federated learning to replace the traditional 1p1v strategy. The idea of allowing the participation parties to decide their participation weight in each round is interesting but I am not sure how useful it is to prevent Byzatine attacks. The authors also integrate other countermeasures to make the scheme Byzantine-robust like suppressing gradients different from the majority and allocating budget based on reputation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of allowing FL participants to decide how to participate in FL using budget is novel. However, I am not sure how useful it is to prevent against Byzantine attackers since this gives the attacker more attack space to explore. For instance, comparing to limiting each client to participate in at most k rounds, the QV strategy of giving a client budget k is a super set and gives the adversary more freedom to design their attacks."
            },
            "weaknesses": {
                "value": "In the evaluation section, FedQV is only compared with FedAvg. There are many existing Byzantine-robust FL strategies that should be compared with\n[1] Attack-resistant federated learning with residual-based reweighting. Shuhao Fu, Chulin Xie, Bo Li, and Qifeng Chen.\n[2] Robust aggregation for federated learning. Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui.\n[3] Byzantine stochastic gradient descent. Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li.\n[4] Learning from history for byzantine robust optimization. Sai Praneeth Karimireddy, Lie He, and Martin Jaggi.\n[5] Byzantine-Robust Federated Learning with Optimal Rates and Privacy Guarantee. Banghua Zhu, Lun Wang, Qi Pang, Shuai Wang, Jiantao Jiao, Dawn Song, Michael I.Jordan.\n[6] Byzantine-resilient non-convex stochastic gradient descent. Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, and Dan Alistarh.\n[7] Byzantine-robust learning on heterogeneous datasets via bucketing. Sai Praneeth Karimireddy, Lie He, and Martin Jaggi.\n[8] Variance reduction is an antidote to byzantines: Better rates, weaker assumptions and communication compression as a cherry on the top. Eduard Gorbunov, Samuel Horv\u00e1th, Peter Richt\u00e1rik, and Gauthier Gidel.\n[9] Secure byzantine-robust distributed learning via clustering. Raj Kiriti Velicheti, Derek Xia, and Oluwasanmi Koyejo.\n[10] Byzantine-resilient high-dimensional sgd with local iterations on heterogeneous data. Deepesh Data and Suhas Diggavi."
            },
            "questions": {
                "value": "Please compare with other existing Byzantine-robust FL systems."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7549/Reviewer_WYWh"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7549/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700778753793,
        "cdate": 1700778753793,
        "tmdate": 1700778753793,
        "mdate": 1700778753793,
        "license": "CC BY 4.0",
        "version": 2
    }
]