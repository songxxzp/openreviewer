[
    {
        "id": "Ew7EAzwXij",
        "forum": "tc1jaWpi7M",
        "replyto": "tc1jaWpi7M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission739/Reviewer_t7dr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission739/Reviewer_t7dr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to boost the object completion via integrating object segmentation into the denoising process of diffusion. The listed visual results look good."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Introducing mask segmentation to facilitate object completion is reasonable, since the completed objects shouldn't reflect strange shapes."
            },
            "weaknesses": {
                "value": "1. Overall, the paper is easy to follow, but need to be further improved. For example, some symbols are not well explained like the condition $E$ in Line 156. The subscript '_t' is misleading to denote the denoising step of DDPM/DDIM and the proposed IMD. The figure 3 is also confusing. The diffusion model should denoise $x_t$ to $x_0$, but the authors give the start noise as $x_0$. Besides, the time-step of IMD is not illustrated in this figure.\n\n2. It's not rigorous to name the progressive completion process as 'mask denoising'. The object's mask generated from SAM is taken as  a condition to diffusion instead of the denoising uint as $x_t$.   \n\n\n3. It is not clear that whether the other comparison method are retrained in the evaluation data. If yes, the training details and the incomplete mask's interaction in their networks should be claimed, otherwise the authors should explain how to obtain these completion results with the off-the-shelf generation models.\n\n4. It would be better if the authors can give some analysis on the sampling speed and more qualitative results of the proposed method."
            },
            "questions": {
                "value": "Overall, the proposed idea of leveraging object segmentation to boost object completion is interesting, while the authors should further improve the manuscript to make the contribution more convincing. I am glad to upgrade the rate depending on the rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission739/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission739/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission739/Reviewer_t7dr"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission739/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698485384656,
        "cdate": 1698485384656,
        "tmdate": 1700561924650,
        "mdate": 1700561924650,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "I26Ookncta",
        "forum": "tc1jaWpi7M",
        "replyto": "tc1jaWpi7M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission739/Reviewer_2Pq9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission739/Reviewer_2Pq9"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an iterative generation strategy for object completion, which alternates between a mask-conditioned image generation stage and a segmentation stage. Specifically, given a partial object and partial mask, the generation stage trains a conditional diffusion U-Net to generate a complete object; the segmentation stage re-segments the generated object image, and the result, which hopefully is more complete,  will be used as the conditional mask for the subsequent generation stage.  The proposed method is evaluated on AHP and DYCE datasets with comparisons to diffusion-based baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed joint object image and mask completion strategy is well-motivated and the overall method seems novel for the target task. \n- The paper is mostly easy to follow. \n- The experiments include both automatic and human-based metrics for evaluation, and the results are better than baselines."
            },
            "weaknesses": {
                "value": "- The justification for the entire iterative procedure is lacking. While it is ideal to achieve improvements as shown in Figure 5, there is no guarantee that such improvement can be realized in a realistic setting. In particular, the mask-denoising controlnet is trained in a local manner, which may generate a worse image, and the segmentation stage is largely dependent on the segmentation model S, which may produce noisy segmentation output. Therefore, it is unclear whether this design would work in general cases.    \n\n- The proposed method lacks mode diversity for object completion. The segmentation stage uses an averaging operator, which seems problematic since it would lead to mode average and is unable to capture potential different modes in object completion. This is important to generate different candidates for image editing since there are multiple possibilities for the occluded regions. \n \n- Some technical aspects of the method are unclear. For example:\n   + In the generation stage, how does the interpolation is implemented? How does the method generate the interpolated masks and its time embedding? \n   + What are the notations M, E in the paragraph of \"Diffusion model\" ? The details of the adopted diffusion model are missing in the main text. \n \n- Experimental evaluation is a bit lacking in several aspects and the results are not fully convincing: \n   + It is unclear how the baselines and this method are compared. It is worth noting that the proposed method only generates the foreground object while the other methods also produce the background. Are the background removed before comparison, for the FID computation and user study? It seems unfair if the background is treated differently.  \n   + A reasonable baseline is to combine amodal segmentation with condition control image generation, which is missing in the comparison. \n   + It is unclear how the method is sensitive to the segmentation quality. What if there are different degrees of segmentation error?\n   + As mentioned above, it would be more convincing if the method is evaluated on the cases with diverse modes of object shape in the occluded regions."
            },
            "questions": {
                "value": "See above for detailed questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission739/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698739417076,
        "cdate": 1698739417076,
        "tmdate": 1699636000940,
        "mdate": 1699636000940,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "me4V4LOya7",
        "forum": "tc1jaWpi7M",
        "replyto": "tc1jaWpi7M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission739/Reviewer_PKfR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission739/Reviewer_PKfR"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to generate a complete object given partial observation. Instead of designing an end-to-end pipeline, this paper introduces object masks as an intermediate representation to complete the object interactively. Specifically, in each iteration, the proposed method generates a set of completions using stable diffusion and extracts the corresponding masks with a segmentation model. These masks are fused and fed into the generation process for the next iteration. Experiments and analysis demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method (MaskComp) introduces a novel interactive approach to complete an object by generating object masks as guidance.\n\n1. Section 3.3 tries to give some theoretical analysis of MaskComp, which is interesting and helps to understand the benefit of introducing masks in the generation approach.\n\n1. From the visual results, I find MaskComp completes the input partial object and achieves higher perceptual quality compared to other methods. Quantitatively, it also achieves higher FID and user study scores.\n\n1. The paper's presentation is good, making it easy to follow and understand."
            },
            "weaknesses": {
                "value": "1. The technical contributions of the proposed method could be further improved. For now, the proposed method is mainly a mask-guided stable diffusion model with an off-the-shelf segmentation model to produce the mask condition. Using SAM to generate masks is straightforward and the mask voting process gives no surprises.\n\n1. If generating a mask is the key to generating high-quality images, why not directly use an encoder-decoder model like U-Net or an SD to predict the target complete mask in one step? As generating the mask is relatively a simple task, I believe a U-Net might be enough to obtain an accurate object mask (this can be regarded as an outpainting task for binary images). It would be interesting to have conducted such an experiment.\n\n1. More ablations study of the proposed method should be given. E.g., different segmentation models, different mask voting strategies, \n\n1. One of the main drawbacks of the proposed method is its slow inference speed. Each iteration in the generation process involves generating multiple image candidates and their segmentations (segment anything model is quite slow), let alone running for multiple iterations. The authors did not report the running time statistics of different methods and omitted this limitation in the limitations section. I encourage the authors to have more comparisons and discussions of the running time.\n\n1. The FID metric shown in Table 1 is problematic. The FID only considers the ground-truth object area; however as shown in Figure 6, different methods generate different foreground areas that may not match the ground-truth object mask. Thus, this metric will yield a higher FID score if the generated object has a large discrepancy \bwith the ground truth even if it is realistic.\n\n1. I cannot find the qualitative comparisons with ControlNet and Kandinsky.\n\n1. I would like to see the results of using the ground-truth mask as input to see how different methods perform with such an oracle. This also tells the generation upper bound of mask-guided methods."
            },
            "questions": {
                "value": "The authors should provide more experiments and discussions in the rebuttal to address the weaknesses raised above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission739/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831749465,
        "cdate": 1698831749465,
        "tmdate": 1699636000870,
        "mdate": 1699636000870,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Qy9zmHkvzJ",
        "forum": "tc1jaWpi7M",
        "replyto": "tc1jaWpi7M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission739/Reviewer_xAwN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission739/Reviewer_xAwN"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a method to complete an object which undergoes occlusion. The algorithm alternats generation and segmentation stages to infer the shape and texture of the original object without occlusion. The segmentation and generation helps each other to refine the  result as the iteration goes on. Diffusion model generates the image utilizing the mask info as a condition. Segmentation is basically derived from the generation result; for better result multiple instance of images are generated and their segments are averaged to yield segmentation mask. The experimental result shows IFD comparision with some recent researches, and human assessment is also performed to compare the results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Clever idea improved the result of occluded object completion effectively. The recent progress of image generation models are actively analyzed and the authors found useful problem task.\nIn the quantitative evaluation the FID metric shows significant performance compared other method, and the numbers are convinced by showing qualitative results.\nGreatly overcame the random unstable results which occurs frequently from the image generation model by averaging the results of multiple runs."
            },
            "weaknesses": {
                "value": "While this paper has attractive strengths, this research is rather applicational research that exploits good features of prior researches. Considering the overall direction of the papers presented in this conference (ICLR), readers may expect more theoretical idea or fundamental thas can be transferrable to of stimulate other research. This paper is heavely dependent on Zhang 2023 paper."
            },
            "questions": {
                "value": "The user study is included in this research to evaluate the quality of object completion.\nIf more details of the user study are provided, it will be more convincing. In many other research areas user study is conducted; and to dispel any latent bias or mistakes they generally offer user study method and protocol, such as: how many persons participate? how to select the subjects? what exactly were the sentences for questions? how was the user interface or the testing environment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission739/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698892264950,
        "cdate": 1698892264950,
        "tmdate": 1699636000792,
        "mdate": 1699636000792,
        "license": "CC BY 4.0",
        "version": 2
    }
]