[
    {
        "id": "kreDhX4CXq",
        "forum": "HKkiX32Zw1",
        "replyto": "HKkiX32Zw1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_AFtS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_AFtS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Promptbreeder (PB), a general-purpose self-referential self-improvement mechanism of LLMs that evolves and adapts prompts for a given domain.\nThis mechanism mutates a population of task-prompts, evaluates them for fitness on a training set, and repeats this process over multiple generations to evolve task-prompts.\nAuthors shows that PB outperforms state-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve Prompting on commonly used arithmetic and commonsense reasoning benchmarks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* This paper focuses on the problems of prompt strategies that hand-crafted prompt-strategies are often sub-optimal,\nand present Promptbreeder (PB).\n* A self-referential self-improvement mechanism is promissing approach as the prompt optimization. \n* The authors conducted  extensively survey and support their originality."
            },
            "weaknesses": {
                "value": "**The comparative study of alternative methods is weak and does not fully support the validity of the proposed method**\n* While Promptbreeder is an important approach as the prompt strategies, it is complex in its composition such as a mutation prompt, a hyper mutation prompt,  a domain-specific problem description, and a seed thinking-styles, and then lacks the ablation analysis to show which components are effective and how effective they are.\n* Promptbreeder appears to rely on past prompt strategies or their combination, lacks its motivation and theoretical considerations, and lacks sufficient experimental results to support them.\n* As authors use only two LLMs as baselines, the generality of the proposed method cannot be determined."
            },
            "questions": {
                "value": "* What is the rationale for the baseline selection in Table 1?\n* Can you explain the result that PS+ does not show a better performance than PS for PaLM 2-L than text-davinci-003, in Table 1?\n* Which resullt supports your claim ``we investigate the various self-referential components of Promptbreeder and their contribution to our results.''?\n* Can you show how effective it is compared to LLaMA or OPT as baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698157194652,
        "cdate": 1698157194652,
        "tmdate": 1699636528601,
        "mdate": 1699636528601,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZrPWvvJlZ0",
        "forum": "HKkiX32Zw1",
        "replyto": "HKkiX32Zw1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_DPYS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_DPYS"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces PromptBreeder (PB), a novel prompt evolution system that automates the exploration of prompts within a specific domain, thereby improving a language model's ability to answer questions in that domain. PB employs a self-referential self-improvement mechanism to evolve and adapt task-prompts. By mutating a population of task-prompts, evaluating their fitness on a training set, and iteratively repeating this process, PB successfully evolves task-prompts. The empirical evidence presented in the paper provides strong support for the effectiveness of PB in enhancing the language model's performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper introduces an innovative automatic strategy for prompt discovery, eliminating the requirement for manual engineering and design. This approach streamlines the process and saves time and effort.\n2. The proposed prompt strategy showcases exceptional performance when compared to currently available state-of-the-art approaches. \n3. The paper is commendable for its clear and well-structured organization. The logical flow of the content enhances readability and comprehension, contributing to a more effective communication of the research findings."
            },
            "weaknesses": {
                "value": "1. The proposed PB algorithm appears to rely heavily on interactions with the LLM compared to the baselines. As a result, solely evaluating its performance based on accuracy may not provide a fair assessment of its capabilities.\n2. While the authors acknowledge that hand-crafted prompt-strategies are often sub-optimal, they do not offer a guarantee or highlight any asymptotic properties for the PB algorithm, leaving room for uncertainty regarding its long-term effectiveness.\n3. The main text of the paper is relatively concise, with several crucial aspects relegated to the appendix. This arrangement can disrupt the smoothness of the reading experience."
            },
            "questions": {
                "value": "1. I am quite curious about the sample efficiency of the algorithm. As evolutionary algorithms often suffer from the poor sample efficiency.\n2. I hope that authors will provide how PB perforems if the size of train dataset is limited.\n3. It will be nice to provide guarantee or asymptotic property for the PB."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5283/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5283/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5283/Reviewer_DPYS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668836775,
        "cdate": 1698668836775,
        "tmdate": 1699636528494,
        "mdate": 1699636528494,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "v0C52YKQAS",
        "forum": "HKkiX32Zw1",
        "replyto": "HKkiX32Zw1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_ceRr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_ceRr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Promptbreeder, a self-referential self-improvement method to evolve prompts for a specific domain. Given some seed prompts, domain description, and thinking-styles, Promptbreeder can generate variations of both task prompts and mutation prompts.  Experiments on various benchmarks have verified that the method outperforms other prompt strategies like CoT and Plan&Solve."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper proposes a systematic framework to evolve domain-specific prompts, and shows better results compared to other prompt strategies."
            },
            "weaknesses": {
                "value": "1. The experiment is not extensive. In Table 1, the compared LLMs do not involve the most recognized models like gpt-3.5 or gpt-4, and the compared methods should contain CoT on PaLM 2-L.\n2. The proposed method Promptbreeder still requires initial information for specific task (like description or mutation prompts), where worse initialization may lead to worse performance. This makes the method may not generalize to various tasks."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5283/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5283/Reviewer_ceRr",
                    "ICLR.cc/2024/Conference/Submission5283/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698822054327,
        "cdate": 1698822054327,
        "tmdate": 1700738421591,
        "mdate": 1700738421591,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cztDNzwPBW",
        "forum": "HKkiX32Zw1",
        "replyto": "HKkiX32Zw1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_7CXL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_7CXL"
        ],
        "content": {
            "summary": {
                "value": "This manuscript proposed PROMPTBREEDER, a new self-referential self-improvement method using an LLM to generate and refine both task- and mutation- prompts over multiple generations. PROMPTBREEDER incorporated nine mutation operators falling into five broad classes to promote varied and robust prompt evolution. This method has been evaluated in 8 tasks with promising performance using the PaLM 2-L model, surpassing serval established baselines such as CoT, APE, and Plan-and-Solve."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- PROMPTBREEDER showed promising performance and outperformed competing baseline approaches in 7 out of 8 tasks with a large margin.\n- The PROMPTBREEDER method was well elaborated in the manuscript and in the supplementary material."
            },
            "weaknesses": {
                "value": "- PROMPTBREEDER aimed to concurrently refine both task and mutation prompts, considerably expanding the search space. However, the absence of navigation during each evaluation often resulted in unpredictable performance for the successive generated prompts. This is evidenced by the persistence of less effective prompts after extensive evaluations, as illustrated in Figure 3.\n- In light of the above, PROMPTBREEDER appears to rely on an extensive series of trial-and-error iterations to identify an optimized prompt, raising concerns about the method's efficiency in exploring potential solutions. It would be helpful if the authors can include a comparative analysis detailing the correlation between the number of prompts generated and the performance for each evaluated baseline and for PROMPTBREEDER itself.\n- It is not clear how the \"Mutator Prompts\" (Table 2) and \"Thanking Styles\" (Section D) are created. Are they derived from pre-existing prompt strategies? Are these prompts hand-crafted?"
            },
            "questions": {
                "value": "1. This study exclusively shows the performance of PROMPTBREEDER with PaLM 2-L, raising questions about its generalization ability to other LLMs. Specifically, \n\n- Whether PROMPTBREEDER method can be effectively utilized to enhance prompts for LLMs?\n\n- Whether the prompts refined using PROMPTBREEDER in conjunction with PaLM 2-L can yield improved results when employed with alternative LLMs.\n\n2. In Figure 3, the y-axis label is not visible. Additionally, what is the relationship between \"number of evaluations\" and \"number of generations\"? It is confusing since Section 4 reported that the populations \"evolved for typically 20-30 generations,\" but there are 2000 evaluations in Figure 3.\n\n3. Please clarify why OPRO was only evaluated on GSM8K in Table 1.\n\nMinor Comment:\n\nFor the sake of readability, it would be beneficial if the color coding is consistent across different figures and texts. For example, the \"mutation prompt\" is color-coded as red in the text on Page 6, yet appears in shades of blue (and not the exact same blue) in Figures 1 and 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699575565239,
        "cdate": 1699575565239,
        "tmdate": 1699636528307,
        "mdate": 1699636528307,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kieYYEkh3E",
        "forum": "HKkiX32Zw1",
        "replyto": "HKkiX32Zw1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_PsCD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5283/Reviewer_PsCD"
        ],
        "content": {
            "summary": {
                "value": "In this paper, authors propose a genetic algorithm to improve both task prompts and additional \u201cmutation\u201d prompts for the specific downstream task. In details, authors utilize direct mutation, estimation of distribution mutation, hypermutation, Lamaerckian mutation and prompt crossover and context shuffling to randomly change either only task prompt or both task prompt and mutation prompts. The overall genetic algorithm is based on a binary tournament genetic algorithm framework where two individuals are sampled and the worse one is replaced with the mutated version of the better one. In most experiments, authors show that their method achieved better results in the targeted downstream tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1: How to generate appropriate LLM prompt for the target downstream task is indeed a very important research question and still lacks a solid answer. I agree with authors that LLM are qualitiifly different from other deep learning models as they have the potential to self-improve their thinking process (e.g. self-generating prompts).\n\n2: From the point of view of genetic algorithm, authors propose a comprehensive set of mutation stratergy, which includes certain extent of \"self-referential'/self-improvement mutation stratergy. Overall it seems interesting in general."
            },
            "weaknesses": {
                "value": "1: The major concern I have is whether evolution algorithm framework in general is not capable enough for the large prompt space for LLM. Overall from the examples provided by the authors in Figure3 appear to show not much different between prompts, which might suggest under-explored prompt space. Personally I feel certain level learning/gradient signal is needed to better explore and generate the prompts for complex LLM models. It will be very interesting (but not necessay) to have some comparision with prompt tunning algorithms if white box LLM models are used.\n\n2: Some result sections in appendix should be moved to the main text as it really helps to show how the algorithm improve the prompts and how the prompts look in the end.\n\n3: I am afraid that I am not familiar with evolution algorithm literature but I personally feel the overall novel comtribution of this paper is limited as it seems all mutation operators are pretty standard, even those \"self-referential\" ones. And the backbone evolution algorithim seems very simple and out of box.   \n\n4: A minor point is that in the result tables, half of the baselines are using different LLM models, which are not directly comparable to authors' method. I strongly encourage authors to rerun the baselines with the same models if possible, or just remove them from the table."
            },
            "questions": {
                "value": "Please see my comments in weakness sections.\n\nOverall, my main question is how such method will compare with prompt tunning method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699599250862,
        "cdate": 1699599250862,
        "tmdate": 1699636528201,
        "mdate": 1699636528201,
        "license": "CC BY 4.0",
        "version": 2
    }
]