[
    {
        "id": "7O5gymps37",
        "forum": "Oi6BhzIu7R",
        "replyto": "Oi6BhzIu7R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_7jdE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_7jdE"
        ],
        "content": {
            "summary": {
                "value": "Improving adversarial robustness against adversarial attacks is an important but challenging task. This paper presents a critical problem that generalizing to numerous unseen adversarial attacks is difficult but paid less attention in the community, and proposes a new concept, i.e. generalizable robustness. Inspired by test-time adaptation, this paper proposes a new test-time defense methodology in robustness and overcomes the non-reasonable prediction entropy assumption in defense, and designs a two-stage rectification approach, i.e, REAL, through a max-min entropy optimization with attack-aware weighting mechanism. This submission brings some new perspectives that will promote adversarial robustness against unknown attacks. Experiments on benchmark datasets show the proposed REAL greatly improves the robustness of previous sample rectification models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The idea of REAL is interesting, rational, and novel. First, it is valuable to explore new generalizable adversarial defense approaches against unseen attacks. Second, considering that adversarial perturbations are diverse and unseen in real applications, it is rational to establish a test-time training paradigm for removing perturbations. Third, since such a paradigm is still seldom studied in this field, the proposed test-time adversarial sample rectification approach is novel in multiple aspects, which may produce a high impact in related fields.\n2. The proposed max-min entropy optimization strategy is new. The authors clearly claim that in conventional test-time adaptation for natural image classification, the entropy loss is commonly used for training unlabeled target data, and successfully reveal that this is not appropriate for adversarial samples as shown in Fig.1. Therefore, the authors propose a natural and novel idea to maximize the entropy of adversarial samples (stage 1) instead of minimization. For the final objective of accurate recognition, stage 2 is formulated for minimizing the entropy of rectified adversarial samples. The two-stage rectification paradigm achieves test-time defense on the fly.\n3. Another merit of this paper is the proposed attack-aware weighting mechanism, which is simple but useful. The intuition behind this is clear because each sample should be treated unequally due to the differences in their attacking power. This paper contributes a simple metric of attack strengths by assessing samples' prediction entropy.\n4. Experiments on benchmark datasets fully prove the superiority of the proposed REAL method, by plugging and playing in the classical SOAP model."
            },
            "weaknesses": {
                "value": "1. Since the auxiliary task is leveraged during test-time optimization, the authors could discuss some choices of different auxiliary tasks, although one may not decide which one is better without empirical observation.\n2. Since this work aims to improve generalization, a more complete setting toward attack generalization can be implemented in the future and produce a higher impact.\n3. It is better to clarify which module is frozen and noted in Figure 2."
            },
            "questions": {
                "value": "1. Is the code of the proposed REAL approach available? This is also important to improve the impact on the open-source community.  \n2. In Fig.2, are the C and E frozen during test-time max-min optimization? \n3. In Eq. 3b and 4b, what is \"S\" ? which is not defined. I guess this is a typo error, which may be \"C\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7541/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698460249346,
        "cdate": 1698460249346,
        "tmdate": 1699636911498,
        "mdate": 1699636911498,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dgNKuIKA7L",
        "forum": "Oi6BhzIu7R",
        "replyto": "Oi6BhzIu7R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_nJ3p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_nJ3p"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a test-time adversarial defense that uses a combination of auxiliary task loss thresholds, entropy thresholds, and two sets of self-adversarial rectification rounds. The method is applied to adversarial defense on MNIST, CIFAR-10, and CIFAR-100, and it is observed that the method can provide robustness to an unsecured classifier."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The method investigates an ambitious and relevant task of test-time adversarial defense.\n* A wide variety of ideas from many different defenses are integrated into a novel method."
            },
            "weaknesses": {
                "value": "* The presentation of the method and the motivation of the difference aspects is somewhat difficult to follow. \n* The primary weakness is that the method appears to be built upon a broken defense, namely the SOAP model. The work [a] reports breaking the SOAP defense using BPDA. I expect that a similar attack could be used against this method. Although this work does present an adaptive attack, from what I can tell the attack does not differentiate through the purification. BPDA provides an efficient way to do this approximately. Re-evaluation of this defense using the methodology in [a] is essential, especially given that this methodology has broken the SOAP defense this work is based on.\n* The method does not compare with recent diffusion-based purification defenses such as [b], which generally obtain stronger results than those reported in this work.\n\n[a] https://arxiv.org/pdf/2202.13711.pdf (ICML 2022)\n\n[b] https://arxiv.org/pdf/2205.07460.pdf (ICML 2022)"
            },
            "questions": {
                "value": "Can the authors re-evaluate their defense using the adaptive attack used against SOAP in [a]?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7541/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834911921,
        "cdate": 1698834911921,
        "tmdate": 1699636911344,
        "mdate": 1699636911344,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tY7Xf6jd1H",
        "forum": "Oi6BhzIu7R",
        "replyto": "Oi6BhzIu7R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_f1E9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7541/Reviewer_f1E9"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the properties of prediction entropy in adversarial samples and presents several strategies for adversarial defense. Specifically, it introduces a max-min entropy optimization scheme and an attack-aware weighting mechanism. The results demonstrate that these approaches are compatible with existing models and exhibit strong performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The starting point is novel and the proposed attack-aware weighting mechanism is technically sound.\n- The paper is generally well-written and easy to follow. The authors have illustrated their settings and motivations using bullet points to provide a clear understanding of their objectives."
            },
            "weaknesses": {
                "value": "- The limitation of selecting the detection threshold and auxiliary tasks is crucial yet challenging. Besides, in numerous real-world attack scenarios, the specific attack methods are often unknown.\n- The motivation behind employing a max-min optimization scheme is unclear. Why is a mask loss necessary in this context?\n- Additionally, the experiments conducted seem insufficient, and it would be beneficial to observe more results obtained on ImageNet.\n- In the text, $L_{ent}$ and $L_{cls}$ are not consistent. \n- In the preliminary, you'd better provide more introduction and explain about the $\\delta$."
            },
            "questions": {
                "value": "- If entropy is related to error rate, what about mutual information or signal-to-noise ratio (SNR)? Do they have a similar effect?\n- The effectiveness of the max-min optimization scheme lacks convincing evidence. Could you please include a comparison of the robust accuracy of $x_{mask}$ to support your claim further?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7541/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699461866637,
        "cdate": 1699461866637,
        "tmdate": 1699636911212,
        "mdate": 1699636911212,
        "license": "CC BY 4.0",
        "version": 2
    }
]