[
    {
        "id": "Wv186UYdhF",
        "forum": "hkWHdI8ss5",
        "replyto": "hkWHdI8ss5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission154/Reviewer_dbEu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission154/Reviewer_dbEu"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles the problem of monocular 3D textured mesh reconstruction with test-time optimization. The authors propose a framework that integrates feed-forward mesh generation that can quickly create 3D initial shapes and an optimization-based feedback loop in test time."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The integration of feed-forward mesh generation and test-time optimization is reasonable.\n- This paper is easy to follow."
            },
            "weaknesses": {
                "value": "- The novelty of this paper is limited. It just mounts the optimization block based on Zero123 SDS loss onto a feed-forward mesh generation method, which is a well-used setup.\n- The experiments are not performed well. The experiments are only performed on chairs, and the compared methods are few. Both the qualitative experiments and quantitative experiments are not enough to demonstrate the effectiveness of the proposed method."
            },
            "questions": {
                "value": "The main body of this paper seems to exceed 9 pages?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697860069915,
        "cdate": 1697860069915,
        "tmdate": 1699635940856,
        "mdate": 1699635940856,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gRelIphbf3",
        "forum": "hkWHdI8ss5",
        "replyto": "hkWHdI8ss5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission154/Reviewer_JToQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission154/Reviewer_JToQ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a technique for generating 3D shapes from a singular image. Initially, it utilizes Total3DUnderstanding to deduce the initial shape and viewpoint from a single image and incorporates a pre-existing segmentation module for image segmentation. In the subsequent phase, the initial mesh is refined using DMTet and the SDS loss, derived from a pretrained 2D diffusion network, Zero123. Multiple loss functions are used to aid the optimization process."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper introduces an innovative technique for deriving 3D shapes from a single image. Employing a feed-forward approach to produce an initial shape may simplify the optimization process and enhance efficiency."
            },
            "weaknesses": {
                "value": "1. The motivation behind the proposed two-stage pipeline remains unclear. While the per-shape optimization via Zero123 can accommodate various categories in an open-world scenario, the integration of a feed-forward method for the initial shape generation might compromise this capability, since the feed-forward module is trained on a finite 3D dataset.\n\n2. In the evaluation results, the focus appears to be on familiar categories like chairs, sofas, and tables. If the methodology primarily targets closed domain 3D generation, there are more robust baselines available, such as LAS-Diffusion and Get3D, which excel in these common categories. However, comparisons with these are conspicuously absent. The method seems to benchmark only against a few optimization-based techniques, which are known to proficiently handle open-world objects.\n\n3. The experimental evaluation is very weak. The training and test set are not clearly stated. It's unclear how many shapes are used in the quantitative evaluation and whether the construction of the test set is fair. \n\n3. The experimental evaluation lacks depth. The specifications of the training and test sets are vague. There's ambiguity regarding the number of shapes used for quantitative analysis and whether the test set is constructed fairly. \n\n4. The user study section lacks clarity. It would be beneficial to elaborate on the details, such as the number of shapes evaluated and the methodology behind score computation.\n\n5. The ablation study is weak and problematic.  Without the initial shape, the per-shape optimization with Zero123 should yield superior outcomes. Additionally, when using Zero123 with the SDS loss, there's no apparent need for camera poses.\n\n6. The document would benefit from meticulous proofreading. Notable typos include:\n\na. page 1: \"which, as explained in ?, imposes constraints on the resulting resolution.\"\n\nb. page 7: \"where . they are the most recent advancements in this field.\""
            },
            "questions": {
                "value": "1. In equation (2), could you clarify the method used to sample the point set P?\n\n2. Equation (6) is not straightforward, and there appears to be a mismatch in the parenthesis. An elaboration on the rationale behind this loss function would be greatly appreciated.\n\n3. The equation: \"ks = (1 \u2212 m) \u00b7 0.04 + m \u00b7 kd.\" requires a more detailed explanation.\n\n4. On page 8, the statement, \"To assess the appearance consistency between novel views, we also present the minimum value of the CLIP score,\" is ambiguous to me."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698529495133,
        "cdate": 1698529495133,
        "tmdate": 1699635940773,
        "mdate": 1699635940773,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n6rFjOXzUL",
        "forum": "hkWHdI8ss5",
        "replyto": "hkWHdI8ss5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission154/Reviewer_tSLs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission154/Reviewer_tSLs"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes SITTO, a two-stage method for single-image 3D reconstruction. For the first stage, it uses a traditional domain-specific single-image mesh reconstruction model Total3DUnderstanding, which is trained on Pix3D (395 furniture models). For the second stage, it leverages Magic3D-style SDS optimization for mesh refinement."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The model could generate some high-quality furniture shapes."
            },
            "weaknesses": {
                "value": "1. Spending 1 hour to optimize a coarse mesh from a domain-specific model for furniture is not necessary. For domain-specific single-image 3D reconstruction, there are many existing fast and robust models\u2014for example, Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction.\n2. No technical novelty. It is a simple combination of two off-the-shelf models: Total3DUnderstanding and Magic3D-style DMTet finetuning.\n3. The domain-specific model is trained on Pix3D. And the experiments are conducted on Pix3D. Such comparisons to those zero-shot single-image 3D reconstruction models are even more unfair.\n4. No two-stage ablation studies. The paper does not ablate either stage to show the significance of design choices."
            },
            "questions": {
                "value": "Please try conducting ablations on two stages and evaluating the models on a more diverse set of shapes.\n\nThere is no discussion of limitations. The current image-to-shape model cannot be generalized outside a limited amount of furniture.\n\nI recommend that authors refrain from haphazardly combining A and B without a well-founded motivation for the task. It is crucial to conduct more comprehensive literature reviews to provide a solid foundation for the task and ensure a strong motivation for your research.\n\nWriting mistakes:\n\n1. Parenthetical citations are not used correctly in many cases.\n2. Page 2, \u201cexplained in ?\u201d is not specified.\n3. Sec 4.1, \u201cwhere . they are\u201d"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission154/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission154/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission154/Reviewer_tSLs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission154/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834176484,
        "cdate": 1698834176484,
        "tmdate": 1699635940651,
        "mdate": 1699635940651,
        "license": "CC BY 4.0",
        "version": 2
    }
]