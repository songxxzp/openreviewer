[
    {
        "id": "LaY8hBcY9V",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_zuiK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_zuiK"
        ],
        "forum": "HgSfV6sGIn",
        "replyto": "HgSfV6sGIn",
        "content": {
            "summary": {
                "value": "The study introduces STExplainer, a global GNN explanation mechanism leveraging frequent subtree mining. Initially, the method isolates the Top-K frequent L-hop subtrees, employing the root node's embedding as the subtree's representation. Subsequently, it computes scores for each subtree and selects the top M as the global subgraph explanation. Additionally, the method incorporates overlapping graph combination techniques and a subgraph matching algorithm to pinpoint intricate and basic subgraphs."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The global-level GNN explainer is an important topic that needs further research.\n2. Using subtree to construct explanations is interesting.\n3. The paper is well-organized and easy to follow."
            },
            "weaknesses": {
                "value": "1. My first concern regarding the proposed method is its complexity. After selecting the Top-K subtrees, the method merges overlapping subtrees to form subgraph patterns, necessitating access to all graph instances. Furthermore, the technique involves extracting intersection subgraphs from these patterns within a cluster through subgraph matching and employs additional subgraph matching to eliminate redundant subgraphs. Repeatedly accessing all graph instances can amplify the method's complexity. It is imperative for the authors to delve into the method's computational complexity and provide experimental comparisons with other baseline approaches.\n2. An initial subtree candidate is derived from an L-hop subgraph, and the size of the subtree candidate will significantly influence the results. This implies that the method's efficacy hinges on the configuration of the target GNNs. I highly recommend authors explain how L affects the method and use an experiment to show it.\n3. The suggested approach employs a Multi-Layer Perceptron (MLP) to obtain a node embedding matrix from the subtree feature matrix. This embedding matrix subsequently represents the score vector for all subtrees. However, integrating an additional neural network as a scoring mechanism complicates interpretability. Also, as the score of an individual subtree contributes to determining the score for the overall subgraph explanation and the overlapping of subgraph patterns, the construction of the initial subtree will significantly impact the results.\n4. Subtrees are ranked according to their frequency. However, as depicted in Figure 4, the performance on the NCI datasets appears to be closely linked to some infrequent subtrees. Does this suggest that frequency might not be an optimal criterion for subtree selection?\n5. In the process of selecting the Top-K subtrees, there is no provision to detect isomorphic subtrees. As a result, isomorphic subtrees might be assigned differing importance scores."
            },
            "questions": {
                "value": "Please refer to Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Reviewer_zuiK"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2814/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697222806132,
        "cdate": 1697222806132,
        "tmdate": 1699636224333,
        "mdate": 1699636224333,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DN72ihcqDt",
        "forum": "HgSfV6sGIn",
        "replyto": "HgSfV6sGIn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_tXc8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_tXc8"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new approach to global-level explainability in GNNs called \"SubTree Explainer.\" This method focuses on mining important rooted subtrees across a dataset, offering a more comprehensive view of GNN behavior compared to existing local-level methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors provide a more intuitive and validated method for GNN explainability.\n2. STExplainer directly mines important rooted subtrees across the entire dataset, making the process more efficient and focused. \nThis paper is well-articulated with a clearly defined objective.\n3. This paper demonstrates the effectiveness of STExplainer in generating high-quality  global explanations on synthetic and real-world datasetss."
            },
            "weaknesses": {
                "value": "1. The experimental section could be more detailed."
            },
            "questions": {
                "value": "1. It is expected that the authors could explain the reasons forwhy not select accuracy as one of the metrics? \n2. In Table 1, the authors present the results of their model,  suggest that they could choose some baselines for comparison to better illustrate the model's effectiveness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2814/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697828187424,
        "cdate": 1697828187424,
        "tmdate": 1699636224226,
        "mdate": 1699636224226,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nD1oX3i43c",
        "forum": "HgSfV6sGIn",
        "replyto": "HgSfV6sGIn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_GgEn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_GgEn"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a novel method to extract global explanations for a GNN via rooted sub-trees on a dataset. The authors method works by enumerating all possible L-hop subtrees which is more efficient than enumerating all possible subgraphs.  They take the top T subtrees that belong predominantly to a single target class (ensuring trees that belong to multiple classes are ignored). From these trees they obtain weighted embeddings. The weighted embedding is passed into the classifier of the original GNN resulting in the final prediction values of each output class prior to softmax layers. They choose the M most important subtrees that they obtain by minimizing a loss function that tries to find the most important subtrees for a target class while penalizing embeddings with larger weights. From these subtrees they combine overlapping ones into subgraphs. They cluster them via k-means in the embedding space for these subgraphs and obtain a representative subgraph per cluster by subgraph matching S subgraphs from the cluster. These subgraphs are the global explanations for a class. \n\nThe authors then conduct experiments on 2 synthetic datasets (BA2-Motifs and BAMultiShapes)  and 2 real datasets ( Mutagenicity and NCI1) and evaluate the fidelity and infidelity on these datasets. The authors also show cases where other Global explainer methods do not provide adequate explainability.; GLGExplainer and GCNeuron make errors on BA-2Motifs dataset and Mutagenicity respectively. They also visually show how the different global explanations distinct from different classes; that is when they are done with their method there explanations are not overlapping."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper provides a novel approach to a relatively new research direction of global explanations in GNNs. The method is novel and the pipeline to extract explanations makes sense and intuitively seems like a step in the right direction for global explanations of GNNs. Each step of the pipeline also makes sense intuitively to extract explanations that do not overlap, are significant, and is more efficient than enumerating all possible explanations. The experiments also seem initially promising, and there are certain cases where this method does significantly better than existing global GNN explainers. The experiment methodology also lists all applicable hyperparameters to reproduce the experiments."
            },
            "weaknesses": {
                "value": "Their method they introduce is novel and intuitive but certain choices in their method seem arbitrary and perhaps even sub-optimal without justification. For instance, when conducting k-means clustering they choose k so that the centers of the clusters are distant enough which is parameterized by a hyperparameter tau. Clearly the choice of tau influences the choice of k and hence the rest of the method it is important to justify this choice. In all their experiments they set tau =2 and it is not clear why this particular value. Also as the authors have stated they want to incentivize the center of the clusters to be close to each other however it would be relevant and important to explore the performance of this method with different choices of this hyperparameter and hence k. \n\nAlso after extracting overlapping subtrees which leads to subgraphs their method then does k-means clustering on the embeddings. From this cluster they sample S subgraphs and average to obtain a representative subgraph for the cluster. Using this method to obtain a prototype seems arbitrary, why not just use the centroid itself or other prototype learning techniques to obtain the representative sample. \n\nFinally, the experimental section shows promise for this method. However, the experiments are not exhaustive and only work with 2 datasets that are real and 2 that are synthetic. The authors justify why they do not compare to other global explainers however more cases where other methods fail and they succeed would provide a much stronger case for their approach. The authors also use 1 choice of major hyperparameters such as tau, and lambda. They should also show experiments on how the choice of these parameters affect their method."
            },
            "questions": {
                "value": "If further justification for particular choices used in their method are made. For instance why is averaging S subgraphs from a cluster the optimal choice for a representative subgraph. \n\nAlso why choose tau=2 for all experiments, what other good choices are there for this hyperparameter?\n\nThe experiments also do not seem sufficient in showing their method\u2019s performance especially with the limited choice of hyperparameters. If further justification to why these experiments are sufficient this would alleviate concerns of the methods feasibility. Alternatively it would be best to show more experiments in a wider range of settings, with greater choices of hyperparameters. \n\nLastly, there are some typos:\n\nIn the second last sentence of the Introduction the authors wrote \u2018methos\u2019 instead of \u2018methods.\u2019\n\nIn the Introduction when listing the authors\u2019 contributions; specifically the last sentence of ii) instead of writing \u2018...concepts rather latent representation...\u2019 it should be \u2018...concepts rather than latent representation...\u2019\n\nIn the appendix specifically section A5 there are several incorrect uses of forward quotations and backwards quotation marks. \n\nAlso in the appendix the title of section A6 is mispelled it should be \u2018Hyperparameter\u2019 \n\nThese should be fixed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2814/Reviewer_GgEn"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2814/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698003697236,
        "cdate": 1698003697236,
        "tmdate": 1699636224137,
        "mdate": 1699636224137,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Soy0f60aLo",
        "forum": "HgSfV6sGIn",
        "replyto": "HgSfV6sGIn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_zhbU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2814/Reviewer_zhbU"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method that provides global explanations for the GNN inferences. Unlike the conventional global explanations that aggregate local explanations, the proposed method utilizes frequent subtrees within the dataset. The weighted sum of the embeddings of the rooted nodes of the subtrees is put into the GNN classifier, and the weights are optimized so that the value of the softmax function for the designated class is maximized. Thus the highest weights are assigned to the globally important subtrees for the class. Moreover, these subtrees are classified into clusters and aggregated into subgraphs according to the overlapped subtrees. The experimental results using two artificial datasets and two real-world chemical datasets show that the proposed method provides human-readable global explanations better than conventional global explanation methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper tackles the difficulties of global explanations for GNN inferences where human-readable global explanations are hard to obtain because of the wide range of possibilities of graph structural features. It gives a solution by utilizing frequent subtrees within the dataset and aggregating them into subgraphs suitable for each instance. It empirically shows that the proposed method can provide easily understandable global explanations for two artificial datasets and two real-world chemical datasets better than conventional global explanation methods for GNNs."
            },
            "weaknesses": {
                "value": "The novelty of the proposed method is somewhat weak. In fact, it successfully provides human-readable global explanations for the datasets used; however, the method itself is some kind of a surrogation model for the given GNNs and it seems possible to be realized by using several traditional methods such as those using graphlet kernels.\n\nMoreover, the comparison to the conventional methods is shown only by using anecdotal examples such as in Figure 2. More evaluation compared to the conventional methods is required in order for readers to know how the proposed method can be used in their own tasks.\n\nIn addition, Figure 3 is difficult for readers to understand because there is not enough explanation, especially for the plots of the original graphs."
            },
            "questions": {
                "value": "- Is there any quantitative evaluation results in comparison to the conventional methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2814/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698143346354,
        "cdate": 1698143346354,
        "tmdate": 1699636224023,
        "mdate": 1699636224023,
        "license": "CC BY 4.0",
        "version": 2
    }
]