[
    {
        "id": "2r3icsMOor",
        "forum": "TGaFO0YglG",
        "replyto": "TGaFO0YglG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
        ],
        "content": {
            "summary": {
                "value": "The paper studies maximizing a submodular function F that is decomposable into N submodular functions. It provides a method to sample a subset of these N functions and form a weighted sum to approximate F. They show that with enough samples, they can get the optimal guarantees of the Greedy algorithm for cardinality constraint and also p-systems. Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "They provide a sampling method to approximate decomposable function F with a weighted sum of its member functions such that the number of terms is independent of N. Here N is the number of submodular functions contributing to F. The number of terms depend polynomially on the size of the ground set."
            },
            "weaknesses": {
                "value": "Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint. \n\nQuestion to authors: Could you provide a practical example that N is substantially larger than n times k to motivate your algorithms?\n\nApproximation of function F:\nIn line 6 of algorithm 2, you look for an approximate version of the function F_{S_j}. The description of how you use 3 to achieve that is not completely clear. But the likeliest interpretation that comes to mind is the following. You call algorithm 3 with function F initialized as F_{S_j} in the j\u2019th iteration of the Greedy algorithm. This requires O(Nn) oracle calls because of line 1 of Alg 3 every time you call Alg 3. Since you need k approximate functions for the k iterations of the greedy algorithm, overall you have O(Nnk) oracle calls which makes the whole motivation point of your paper irrelevant.\n\nThe statement of Lemma 8 suggests that you had the above interpretation in mind (\\hat{F} sampled after S is fixed).\n\nIf you had another way of calling Alg 3 in mind, you should completely rewrite the presentation of Alg 3 and its description. For instance, if you want to call Alg-3 k times but want to perform its first line only once, you need to separate that as a preprocessing step in another pseudo code and explicitly explain it. It sounds counterintuitive to have the same probably vector <p_1, \u2026, p_N> and do the sampling (lines 3-6 of Alg 3) k separate times. Even if you want to do that, it takes O(N) to find this approximate function. I note that O(N) is not mentioned in the (non-preprocessing) runtime of your algorithm because you only count the number of oracle calls. Nevertheless you pay the O(N) in runtime and you should mention it. \n\nThere is a third interpretation which is calling Alg 3 only once and using the same approximate function in all k iterations of greedy. I strongly recommend correcting the presentation to reflect this ambiguity. \n\nRelated work:\nThe problem of submodular maximization in the case of multiple underlying submodular functions has been studied previously in the context of probabilistic submodular maximization or two stage submodular maximization. \nProbabilistic Submodular Maximization in Sub-Linear Time, Stan et al. ICML 2017\nLearning Sparse Combinatorial Representations via Two-stage Submodular Maximization\nEric Balkanski et al. ICML 2016.\n\nIn this setting, the submodular function we want to optimize is sampled from a distribution (e.g. each user has a submodular valuation function and a user is drawn from the distribution). Their approach is to compute a compact subset of items in the ground set and study the compression and approximation errors separately. These methods are not necessarily directly applicable to your setting but doing a more thorough compare and contrast seems necessary. In particular, their results are constant approximations strictly below the 1-1/e target approximation in your paper. I should mention that this connection is different from the relevance of your work to Mini-batch methods you reviewed in the related work section.\n\nTypos:\n1. The equation after theorem 1: \\hat{F}^j_{S_j} \u2192 \\hat{F}^j_{S_j}(e)\n2. Last inequality in page 4: The lower bound on F(S_{k+1}) should have the extra error term, gamma epsilon\u2019 F(S^*) as a deductive term not addition. The current form is a stronger guarantee even though we have the additive error term. I believe it should be:\nF(S_{k+1}) \\geq F(S^*)\\beta - \\gamma \\epsilon\u2019 F(S^*) \n3. Page 5, Mini-batch setting paragraph: \u2026 its is \u2026 \u2192 it is"
            },
            "questions": {
                "value": "Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint. \n\nQuestion to authors: Could you provide a practical example that N is substantially larger than n times k to motivate your algorithms?\n\nApproximation of function F:\nIn line 6 of algorithm 2, you look for an approximate version of the function F_{S_j}. The description of how you use 3 to achieve that is not completely clear. But the likeliest interpretation that comes to mind is the following. You call algorithm 3 with function F initialized as F_{S_j} in the j\u2019th iteration of the Greedy algorithm. This requires O(Nn) oracle calls because of line 1 of Alg 3 every time you call Alg 3. Since you need k approximate functions for the k iterations of the greedy algorithm, overall you have O(Nnk) oracle calls which makes the whole motivation point of your paper irrelevant.\n\nThe statement of Lemma 8 suggests that you had the above interpretation in mind (\\hat{F} sampled after S is fixed).\n\nIf you had another way of calling Alg 3 in mind, you should completely rewrite the presentation of Alg 3 and its description. For instance, if you want to call Alg-3 k times but want to perform its first line only once, you need to separate that as a preprocessing step in another pseudo code and explicitly explain it. It sounds counterintuitive to have the same probably vector <p_1, \u2026, p_N> and do the sampling (lines 3-6 of Alg 3) k separate times. Even if you want to do that, it takes O(N) to find this approximate function. I note that O(N) is not mentioned in the (non-preprocessing) runtime of your algorithm because you only count the number of oracle calls. Nevertheless you pay the O(N) in runtime and you should mention it. \n\nThere is a third interpretation which is calling Alg 3 only once and using the same approximate function in all k iterations of greedy. I strongly recommend correcting the presentation to reflect this ambiguity. \n\nQuestion: which of the above interpretations did you have in mind?\n\nTypos:\n1. The equation after theorem 1: \\hat{F}^j_{S_j} \u2192 \\hat{F}^j_{S_j}(e)\n2. Last inequality in page 4: The lower bound on F(S_{k+1}) should have the extra error term, gamma epsilon\u2019 F(S^*) as a deductive term not addition. The current form is a stronger guarantee even though we have the additive error term. I believe it should be:\nF(S_{k+1}) \\geq F(S^*)\\beta - \\gamma \\epsilon\u2019 F(S^*) \n3. Page 5, Mini-batch setting paragraph: \u2026 its is \u2026 \u2192 it is"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC",
                    "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698265575252,
        "cdate": 1698265575252,
        "tmdate": 1700065148167,
        "mdate": 1700065148167,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cewItRWyCM",
        "forum": "TGaFO0YglG",
        "replyto": "TGaFO0YglG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a mini-batch algorithm for maximizing a non-negative decomposable submodular function under a set of constraints. The algorithm reduces the number of oracle evaluations compared to previous methods and achieves good approximation guarantees. The paper provides a proof for the algorithm's effectiveness and compares it to other algorithms. The algorithm is shown to be effective for cardinality and p-system constraints. Overall, the paper contributes a new algorithm that efficiently optimizes submodular functions with good approximation guarantees."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper introduces a mini-batch algorithm that maximizes non-negative decomposable submodular functions under constraints, which reduces the number of oracle evaluations in some cases. The methodology is sound and the results are well-supported. Furthermore, the paper underscores the potential for applying the mini-batch approach to other constraints and functions beyond submodularity, indicating its broader applicability."
            },
            "weaknesses": {
                "value": "1.\tThe paper posits that the time complexity of the na\u00efve greedy algorithm is dependent on N, which leads to high time complexity when N is large. The motivation behind their algorithm is to eliminate this dependence on N. It would be beneficial for the authors to provide a substantial number of examples demonstrating scenarios in real life where N is exceptionally large. This would strengthen their motivation, especially considering that there are few published papers with a similar motivation, indicating that such a motivation has not yet been widely accepted.\n2.\tThe results obtained by the paper under the unbounded curvature case do not seem to significantly improve upon the results of Rafiey & Yoshida (2022). The superiority or inferiority between the two depends on the values of B, n, p, and k.\n3.\tThe paper lacks experiments to validate the performance of the proposed algorithm. It would be advantageous for the authors to include empirical evidence supporting their theoretical claims.\n4.\tThe organization of the paper appears to be chaotic, giving an impression of an unprepared manuscript rather than a ready-to-publish paper."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698483755448,
        "cdate": 1698483755448,
        "tmdate": 1699636006068,
        "mdate": 1699636006068,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4RoxoRKVZL",
        "forum": "TGaFO0YglG",
        "replyto": "TGaFO0YglG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the problem of maximizing a decomposable monotone submodular function $F$ over a ground set of size $n$. By decomposable it means that $F=\\sum_{i=1}^N f_i$, where each $f_i$ is monotone submodular and can be accessed via a value oracle. The paper presents fast algorithms for the problem under the cardinality constraint and the $p$-system constraint. More specifically, for the cardinality constraint, a na\u00efve greedy algorithm needs $O(Nnk)$ queries, where $k$ denotes the constraint parameter. In contrast, the paper presents an algorithm using $O(Nn+k^3n^2/\\epsilon^2)$ queries up to a logarithmic term. Furthermore, when the function has a bounded curvature, the algorithm uses $O(Nn+kn^2/\\epsilon^2)$ queries up to a logarithmic term. This improves over two previous results. For the $p$-system constraint, a similar improvement can be obtained."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe basic idea for solving the problem is to construct a sparsifier of $F$ which approximates $F$ at all subsets. The paper observes that one can construct a sparsifier which only approximates the marginal values of each single element during the execution of the greedy algorithm. The observation is clever and general. I believe it can be applied for more general functions and various constraints.\n2.\tThe algorithm and analysis are presented in a transparent and readable way."
            },
            "weaknesses": {
                "value": "1.\tThe motivation of the paper is problematic. Since the problem itself is a traditional combinatorial optimization problem, it is strange to consider the preprocessing part. In my understanding, the preprocessing part is meaningful if we consider one decomposable submodular function under a large number of different constraints, since the preprocessing part is not related to the constraint. But I am not sure about the motivation of this kind of setting. Besides, even in the case where the preprocessing part is necessary, the proposed algorithm is superior to the na\u00efve $O(Nnk)$ algorithm only when $N$ is large. However, since the Nn term looks inevitable, I suspect that for large $N$, the proposed algorithm is still too slow in practice. Unluckily, the authors do not explain more about this. Specifically, the authors do not suggest any applications where $N$ is in fact large and the paper lacks experiments to demonstrate the advantage of their algorithm for solving such instances.\n2.\tThe paper has few technical contributions. It builds on a simple observation. Although this observation is clever, it is more like a trick and does not need many insights into the problem.\n3. The proof of Theorem 3 is problematic. Note that the sparsifier is determined before the greedy algorithm is executed. So it\u2019s unknown which $S_j$\u2019s the greedy algorithm will reach. Consequently, to ensure that the incremental value of $S_j$ can be estimated accurately, one needs to combine the union bound with Lemma 8 to show the estimate is accurate for all subsets of size at most $k$. This means that $\\alpha$ should be $\\Theta(\\epsilon^2 k \\log n)$ and now the number of oracle evaluations is $O(k^2n^2 \\log n)$. So, under the cardinality constraint, the proposed algorithm has no advantage over Kudla & Zivny (2023), which further reduces the contribution of the paper.\n4.\tThe paper is presented in a TCS rather than an ML style, which makes it less attractive to AI researchers. I suggest the authors to rewrite the Introduction and explain why the paper\u2019s results are important to the AI community."
            },
            "questions": {
                "value": "1.\tThe sentence \u201cThe expected number of oracle evaluations of our algorithm only depends on the size of the ground set\u201d in the Abstract is misleading. I understand the authors regard the Nn term as the preprocessing time. However, it will not disappear in practice. And it\u2019s unfair to compare with previous algorithms while omitting this term.\n2.\tRafiey & Yoshida (2022) is published in AAAI22, please update the reference.\n3.\tI suggest the authors to moving the Related Work to the beginning of the Introduction, and explain more about the reason why the paper\u2019s results are important to the AI community.\n4.\tPage 2, in the second to last paragraph, I can not figure out why the sentence \u201cWhile the mini-batch approach results\u2026\u201d can imply the sentence \u201cThis means that we need to reestablish\u2026\u201d."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698752664543,
        "cdate": 1698752664543,
        "tmdate": 1699636005953,
        "mdate": 1699636005953,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i2sq2TktM0",
        "forum": "TGaFO0YglG",
        "replyto": "TGaFO0YglG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors present a new algorithm for maximizing monotone decomposable submodular functions subject to cardinality and p-system constraints."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The improvement in preprocessing time and the main algorithm for unbounded curvature is beneficial when $N \\gg n$.\n2. Removing the dependence on $B$ is also beneficial in the bounded curvature setting.\n3. Although \"mini-batching\" ideas have been used in this context before, the way they are used in this work is novel."
            },
            "weaknesses": {
                "value": "1. The paper is poorly written and difficult to understand in some places. Algorithm 2 is not an algorithm, line 4 does not make sense, and line 7 at least needs a pointer.\n2. The paper does not provide sufficient justification for the importance of the problem or their algorithms improvements.\n3. The paper does not compare the results in an experimental setting, which, combined with the above issue, raises significant concerns about the applicability of the authors' algorithms.\n4. The authors claim that \"The expected number of oracle evaluations of our algorithm only depends on the size of the ground set,\" which is clearly impossible. Their preprocessing still has linear dependency on N. I believe this type of overreaching claims is very confusing and can give the false impression of the quality of the work."
            },
            "questions": {
                "value": "Please provide responses for the above concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698765643869,
        "cdate": 1698765643869,
        "tmdate": 1700045773689,
        "mdate": 1700045773689,
        "license": "CC BY 4.0",
        "version": 2
    }
]