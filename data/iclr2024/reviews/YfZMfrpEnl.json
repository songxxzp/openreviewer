[
    {
        "id": "fbokfSswEv",
        "forum": "YfZMfrpEnl",
        "replyto": "YfZMfrpEnl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_ysA7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_ysA7"
        ],
        "content": {
            "summary": {
                "value": "The paper adopts a stochastic transformer architecture that uses distributional embedding and Wasserstein distance-based attention mechanism for self-supervised learning pipelines. The contrastive regularization terms are added to the training objective."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and concise.\n- The paper investigates an important research question, which can potentially interest many researchers."
            },
            "weaknesses": {
                "value": "- More explanations needed for baselines. e.g. For the baseline MC-Dropout, it only mentions the dropout regularization applied during pre-training, and the ratio is set to 0.3; but for MC dropout, the dropout is applied at both training and test time, and there is no detail for the testing. \n- The performance is not convincing enough. The improvement is not significant, and according to the ablation study, it also seems very sensitive to the hyperparameters. \n- It's not proper for the paper to say 'We propose a stochastic transformer architecture with distributional embedding......', since the distributional embeddings and Wasserstein distance-based attention mechanism are the same as Fan et al., 2022."
            },
            "questions": {
                "value": "Why set dropout ratio as 0.3 for the MC-Dropout baseline? Isn't it slightly higher than the common options?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8438/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8438/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8438/Reviewer_ysA7"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698705983675,
        "cdate": 1698705983675,
        "tmdate": 1699637052402,
        "mdate": 1699637052402,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yiwO6o2Aa3",
        "forum": "YfZMfrpEnl",
        "replyto": "YfZMfrpEnl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_67qY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_67qY"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a stochastic vision transformer that integrates uncertainty and distance awareness into self-supervised learning (SSL) pipelines. The core idea is to encode image patches into elliptical Gaussian distributional embeddings, and use Bures-Wasserstein to calculate the (dis)similarity between encoded patches and define a Wasserstein-based attention. The authors demonstrate the performance of their proposed method across different tasks such as in-distribution generalization, out-of-distribution detection, dataset corruption, semi-supervised settings, and transfer learning to other datasets and tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The idea of stochastic token embedding and Wasserstein-based attention mechanism is interesting, and timely. \n\n* The paper is written clearly and it is straightforward to follow."
            },
            "weaknesses": {
                "value": "* My main criticism of this paper is the experimental results. \n\n  * First, the experimental results are limited as the experiments only focus on small-scale datasets, namely CIFAR-10 and CIFAR-100. The results will be much more conclusive if the author reports results on larger-scale datasets, e.g., imagenet, or at least datasets with larger images (e.g., mini-imagenet, or tiny-imagenet).\n  * Secondly, in most of the experiments, the results either match the baselines or are only marginally superior. Additionally, the method is more than twice as costly in terms of time when compared to the baseline (~4hrs vs ~9hrs). Compounding the issue, I couldn't determine if the results are reported as an average over K runs.\n\n  Respectfully, the results section of this paper is significantly below the standards of an average ICLR paper, and I encourage the authors to work on improving this section to increase their impact.  \n\n* There are several typos throughout the formulations that make me question the rigor of the paper. \n   * Equation (4) is $W_2^2(z_1,z_2)$ and not $W_2(z_1,z_2)$. The same goes for all equations that use $W_2$.\n   * Equation (10), did you mean to write: $\\mathcal{L}_p-\\lambda log(\\sigma(-W_2^2 (z\\_{out},f_z(y^+))))$?"
            },
            "questions": {
                "value": "*  In Equation (10), why do you consider only positive samples? Wouldn't a generalized version using both negative and positive samples (similar to the classic works like SimCLR) be better? In other words, something like the following:\n\n  $$-\\lambda_1 log(\\sigma(-W_2^2 (z_{out},f_z(y^+))))+\\lambda_2 log(\\sigma(-W_2^2 (z_{out},f_z(y^-)))) $$\n\n  where if you set $\\lambda_2=0$ you will recover the only positive sample case."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762602251,
        "cdate": 1698762602251,
        "tmdate": 1699637052269,
        "mdate": 1699637052269,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5AQIMpad9o",
        "forum": "YfZMfrpEnl",
        "replyto": "YfZMfrpEnl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_ynaf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8438/Reviewer_ynaf"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on self-supervised learning by considering the model\u2019s confidence and uncertainty, it proposes a new stochastic vision transformer that integrates uncertainty and distance awareness into a pipeline by a Wasserstein distance-based attention. The method is evaluated using various tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The motivation is clear and convincing, the method seems nice and the methods are evaluated on various tasks."
            },
            "weaknesses": {
                "value": "n/a"
            },
            "questions": {
                "value": "n/a"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698894512815,
        "cdate": 1698894512815,
        "tmdate": 1699637052153,
        "mdate": 1699637052153,
        "license": "CC BY 4.0",
        "version": 2
    }
]