[
    {
        "id": "VDJXwQfP95",
        "forum": "1BuWv9poWz",
        "replyto": "1BuWv9poWz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_Qpbi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_Qpbi"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to increase the tranferrability of adversarial attacks across Transformer models. The key idea is to attenuate mild gradients and to do frequency adaptive perturbation of the input signal.\n\nAfter rebuttal, I decided to increase my score to reflect the answers."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The comperhensive numerical results in the paper across a number of architectures and attack methods shows the benefits of the approach, consistently achieving very high transferrability scores. The method itself seems quite simple to implement."
            },
            "weaknesses": {
                "value": "This paper was written in a manner which made it very difficult for me to follow the exact approach. I have a number of questions below which I hope the authors will address. I am not up to date on the latest adversarial literature and therefore it may be that I have missed obvious ideas, but nevertheless I think the authors should write the paper for a general ICLR audience rather than adversarial sub-field experts. I am willing to re-visit my rating if the authors can provide satisfactory answers to the questions below, which are mostly to do with the very opaque setup in the paper."
            },
            "questions": {
                "value": "Questions:\n\n1. What are \"strong\" and \"mild\" gradients? These terms are assumed to be understood by the reader, but never explicitly defined. At the least, one would expect some informal definition to give the reader some intuition.\n\n2. The definition of \"channels\" in a Transformer model is unclear. For conv nets, it is obvious what this refers to. It seems to refer to the number of attention heads, but it was not too clear.\n\n3. It is unclear why attentuating certain types of gradients (\"mild\") leads to better transferability. Is there an intuition that the authors can provide for this phenomenon?\n\n4. The HFA method was quite unclear to me (and I guess it will be to many readers). \n\n5. How are the GNS and HFA methods combined?  \n\n6. What exactly do the results in Table 1 show us? Is there one model on which the adversarial attacks were generated, and the remaining were the rates of success?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5069/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5069/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5069/Reviewer_Qpbi"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5069/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698623679106,
        "cdate": 1698623679106,
        "tmdate": 1700600178400,
        "mdate": 1700600178400,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "waXh4QqsCg",
        "forum": "1BuWv9poWz",
        "replyto": "1BuWv9poWz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_6tAt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_6tAt"
        ],
        "content": {
            "summary": {
                "value": "In order to enhance the transferability of adversarial attacks on ViTs, this paper introduces a novel gradient normalization scaling method for fine-grained gradient editing. After calculating the distribution of gradients, tanh is used for scaling the gradients that are considered as prone to cause overfitting and have minimal impact on attack capability. A high frequency adaptation method is proposed to explore the sensitivity of ViTs to adversarial attacks in different frequency regions, on the premise that ViTs shows different attention areas from CNNs in frequency. DCT transformation is conducted to obtain high frequency features, and then reverse transformation is put afterward to feed into the network for backpropagation. From the comparison of Attack Success Rates on ViT and CNN models, this work achieves better performance, enhancing the transferability of adversarial samples on ViTs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper comes up with a novel problem space.\n2. Utilizing normalization, or scaling is innovative.\n3. Achieved better attack transferability performance than SOTA methods."
            },
            "weaknesses": {
                "value": "1.\tLack of soundness of mild gradients and extreme gradients.\n2.\tNormalization and scaling process is insufficiently demonstrated.\n3.\tMiss rationale of utilizing high frequency. Is frequency transformation for better ViTs or for better attacks?\n4.\tAblation study is insufficient to evaluate the impact of your two components on the final method performance and verify their importance.\n5.\tSome sentences contain grammatical errors, such as missing subjects."
            },
            "questions": {
                "value": "1.\tIn your Abstract, after a one-sentence introduction to ViT, quickly talk about enhancing the transferability of adversarial attacks on ViTs is somewhat discontinuous. Adding an introduction to adversarial attacks in between would make it smoother. There are many more logical breaks like this. \n2.\tStructure illustration figure can be more detailed/comprehensible. Figure annotations could provide more explanation. \n3.\tThere should be more explanations about how mild gradients and extreme gradients in Figure 3 react to your specific parameters (briefly introduce u here instead of later), and why mild gradients are the easiest to overfit. Besides, why is \u00b5 + u \u2217 \u03c3 the watershed between mild and extreme gradients? \n4.\tNormalization and scaling seem to be one and the same.\n5.\tGive more arguments for tanh and frequency transformation.\n6.\tGNS-HFA is a combination, so does each part fit your hypothesis? What role do they play? Which one contributes more?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5069/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698936767107,
        "cdate": 1698936767107,
        "tmdate": 1699636497165,
        "mdate": 1699636497165,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AOf4xFJRTb",
        "forum": "1BuWv9poWz",
        "replyto": "1BuWv9poWz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_98px"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5069/Reviewer_98px"
        ],
        "content": {
            "summary": {
                "value": "In this submission, the authors proposed a gradient normalization scaling and high frequency adaptation for vision transformers. Specifically, the authors proposed to improve the generalization ability of ViTs by using gradient normalization. Moreover, the authors proposed a high frequency adaptation approach to guide the back-propagation in ViTs. Experimental results on several public datasets for adversarial attack have illustrated the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is easy to follow.\n2. The idea is well motivated and presented."
            },
            "weaknesses": {
                "value": "The contribution is marginal, since the gradient normalization was demonstrated in [1], please discuss the major differences.\n\n[1] Wu, Y. L., Shuai, H. H., Tam, Z. R., & Chiu, H. Y. (2021). Gradient normalization for generative adversarial networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 6373-6382)."
            },
            "questions": {
                "value": "Please conduct ablation studies using only GNS or HFA to demonstrate the effectiveness of those two methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5069/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698972684625,
        "cdate": 1698972684625,
        "tmdate": 1699636497087,
        "mdate": 1699636497087,
        "license": "CC BY 4.0",
        "version": 2
    }
]