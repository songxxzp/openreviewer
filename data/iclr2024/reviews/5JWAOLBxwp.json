[
    {
        "id": "s0MrcYqsdq",
        "forum": "5JWAOLBxwp",
        "replyto": "5JWAOLBxwp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_HjVh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_HjVh"
        ],
        "content": {
            "summary": {
                "value": "The work proposes an SO(3) equivariant pointcloud network by extending vector neurons representation from a list of 3-dim vectors to a list of k-dim vectors. To accommodate this  increase in dimensionality a rotation operator construction is developed that can map a rotation in SO(3) to k dim."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The work demonstrates improvement in detail preservation compared to the baseline VN. Quantitatively, it manages to bridge the reconstruction gap reported in VN with the non-equivariant baseline, occNet. Qualitatively, it can be seen the the proposed method is able to preserve some details such as the vehicle side mirror.\n- The paper compares performance with the baseline VN on many additional applications including compression, normal estimation, classification, segmentation and registration. In all of them if demonstrates superior performance."
            },
            "weaknesses": {
                "value": "- The paper's presentation is one of the main reasons for my low rating. It is possible that I did not understand some important insights, but given my relatively broad background in the field, this suggests that the authors did not do an adequate job of presenting and conveying their ideas to the reader. Key issues include the lack of a clear motivation, insufficient highlighting of limitations in existing solutions, inadequate consideration of the suggested design choices, and\u2014most importantly\u2014an outdated comparison with relevant literature\n- The description of the limitation of VN is not clear. VN embeds features in a high dimensional space. But instead of using a n-dim vector, they use a nx3 matrix to keep the rotation operation in its same form as in the input space. It is thus my understanding that the representation capacity shouldn\u2019t be smaller than any other global-embedding network which maps inputs to a high n-dim space. Therefore, i couldn\u2019t quite understand the authors claim about VN having \u201c3dim\u201d features. First, I don\u2019t think this is an accurate description of the dimensionality of VN, but more importantly i don\u2019t understand how the fact that the vectors in the list live in 3 dimensions is causing issues with representing geometric details. I\u2019ll try to give an intuitive example. Imagine a very dense pointcloud that captures fine details of the shape. Such a pointcloud may have 10^6 points and these points may live in 3D. My point is, the fact that the points live in R^3 isn\u2019t itself a problem for capturing these details. Instead, what is known to cause issues with capturing fine details in neural fields is global representations. To fight this, many methods focus on partitioning the shape or scene into smaller regions and representing each of them with a local function, like switching from occnet to conv-occnet. In fact, there have been several follow up works to VN that try to do that. Other works tried to improve the encoder too. These works are not mentioned in the submission but should be discussed and compared with: [1,2,3,4].\n- It is perhaps my misunderstanding, but it seems the lifting to R^N replaces the principal axes in R^3 with a 3-dim subspace in R^N. Why then is this helpful?\n- The compression experiment is a bit unclear to me. There\u2019s no report of the compression ratio \u2014 how much is the original pointcloud compressed wrt the embedding? It seems to measure reconstruction on the train set rather than compression.\n\n**Minor**:\n\n- The presentation should be more accurate. Sentences like \u201cEquivariant neural networks (NN) change the output accordingly when the point cloud input is rotated without additional training.\u201d are not accurate.  Equivariant NN are more general than that. Here the authors refer specifically to point cloud networks that are rotation equivariant.\n- why is z/z not shown for part segmentation?\n\nTypos:\n* theoremIf\n\n**References**: \n\n[1] VN-Transformer: Rotation-Equivariant Attention for Vector Neurons\n\n[2] VNT-Net: Rotational Invariant Vector Neuron Transformers\n\n[3] 3D Equivariant Graph Implicit Functions\n\n[4] On the universality of rotation equivariant point cloud networks"
            },
            "questions": {
                "value": "- which experiment is meant to demonstrate that the lack of details is due to the 3 dim feature vector? Take the non-equivariant network occNet. This network maintains better details and still has N dim. I therefore am not convinced that the issue is with the dim of the features. \n- I understanding that the motivation in the proposed lifting to k-dim is to keep it simpler than other tensor networks, but how is the proposed representation compare to it? is it less expressive? i would be glad to see a discussion"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9205/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697912376254,
        "cdate": 1697912376254,
        "tmdate": 1699637158567,
        "mdate": 1699637158567,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "747ORqdqxN",
        "forum": "5JWAOLBxwp",
        "replyto": "5JWAOLBxwp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_XaCw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_XaCw"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an equivariant feature representation to map per 3D point to a high-dimensional feature vector, which is supposed to be more capable to represent rich point information. Extensive experiments are conducted to verify the effectiveness in multiple tasks: point cloud completion, 3D shape compression, normal estimation, point cloud registration, and point cloud classification and segmentation. The results are very positive."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The primary strength of the proposed component lies in its capability to map 3D points to high-dimensional feature space with the property of SO(3)-equivariant, while the existing work Vector Neuron(VN) can only deal with three-dimensional features. The construction of the frequency-based transformation function D in equation (1) looks very reasonable and provable. \n\nSecondly, the effectiveness of the proposed module has been extensively evaluated on multiple tasks and datasets, which makes this work very solid and convincing."
            },
            "weaknesses": {
                "value": "There are some minor questions.\n\n1. The proposed component is always applied together with the existing VN module. Is it possible to work by its alone? If so, how to extend it? \n\n2. Since the construction of transformation function D is related to different frequencies. However, in the evaluation, there is a lack of concrete experiments to deeply analyse how such frequency-based function can help the network to learn more discriminative features. Although most of downstream tasks have excellent performance, it is unclear what type of features are learned while keeping the SO(3) equivariance. \n\n3. All experiments are conducted on very small-scale point clouds like objects. Is it possible to scale up the proposed method on larger scale 3D point clouds such as room-level ScanNet/S3DIS datasets or even urban-level SensatUrban dataset? If not, what are the potential reasons?\n\n4. In Section 2.2, the last line states that \"Our feature representation can xxxx, which is not equivariant, so that it is equivariant\". It's suggested to clarify the point?\n\n5. In page 4, the section \"Theorem 1.\", you may need to remove the word \"theorem\"?"
            },
            "questions": {
                "value": "Details in weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9205/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698655849891,
        "cdate": 1698655849891,
        "tmdate": 1699637158455,
        "mdate": 1699637158455,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RZoeuWpnDh",
        "forum": "5JWAOLBxwp",
        "replyto": "5JWAOLBxwp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_79hQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_79hQ"
        ],
        "content": {
            "summary": {
                "value": "The paper targets the challenging 3D representation problem and a new equivariant feature representation which can map 3D points to high-dimensional feature space is presented. The experimental results have been validated on several tasks like point-cloud completion, shape compression, normal estimation, point cloud registration, point cloud classification and segmentation. Reasonable results have been reported with a comparision with the existing work."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. A new 3D representation is presented which can discern multiple frequencies in the 3D data. Also, it provides theretical justification of the proposed approach. \n2. The proposed approach is valiated on several tasks like point-cloud completion, shape compression, normal estimation, point cloud registration, point cloud classification and segmentation. Competitive performances have been reported with a comparison of the existing baselines."
            },
            "weaknesses": {
                "value": "1. For the experiments on point-cloud completion, as the experimental setup discussed, it samples 300 points for the evaluation. How about the performance of different number of sampled points?\n2. For the experiments on the test classification and part segmentation, it seems the proposed algorithm does not have obvious performance gain over the existing work like PaRINet. What is the main reason under this result?\n3. A minor suggestion, the baselines are usually introduced in the year before 2022. Is it possible to report more recent results for the comparison in the experimental section, like the work published in 2023?"
            },
            "questions": {
                "value": "Please address the questions in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9205/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698664646186,
        "cdate": 1698664646186,
        "tmdate": 1699637158343,
        "mdate": 1699637158343,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MflIochfta",
        "forum": "5JWAOLBxwp",
        "replyto": "5JWAOLBxwp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_MkmG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_MkmG"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a frequency-based input representation for Vector-Neuron for SO-3 equivariant network. It provides compelling evidence to support the claim of keeping equivariance with this input representation. Both visualized and numerical results demonstrate the effectiveness of the proposed method, thus validating its ability to achieve equivariant representations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper presents sufficient mathematical proofs, which provide robust support for the proposed representation. This strong evidence reinforces the credibility of the approach.\n- The multi-frequency design demonstrates its effectiveness in terms of both visualization and benchmark performance. \n- The writing style and figures in the paper are great as they effectively elucidate the design and motivation behind the proposed representation. \n- The experiments conducted in the study convincingly demonstrate the effectiveness of the proposed method across various downstream tasks."
            },
            "weaknesses": {
                "value": "- Lack of ablation studies\n- (This is not a weakness) Does author try to extend the method on scene (indoor) ?"
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9205/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698736614208,
        "cdate": 1698736614208,
        "tmdate": 1699637158216,
        "mdate": 1699637158216,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "r5J9XX9CHe",
        "forum": "5JWAOLBxwp",
        "replyto": "5JWAOLBxwp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_Jvrz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9205/Reviewer_Jvrz"
        ],
        "content": {
            "summary": {
                "value": "In this paper the authors propose a representation for point cloud data that can be used with the existing method [1] to improve expressivity while maintinaing equivariance to 3D rotations. The representation is constructed by transforming points to an axis-angle representation, then lifting that representation to a random subspace of SO(n). The subspace is defined by three matrices J_1, J_2, and J_3, where J_1 is a random vector in the Lie algebra of SO(n), and J_2 and J_3 (also in the Lie algebra) are matrices whose Lie bracket is close to J_1. The final SO(n) representation of a given point is the exponential map of the linear combination of J_1, J_2, and J_3, where the combination coefficients are determined by the axis-angle representation.\n\n[1] Deng, Congyue, et al. \"Vector neurons: A general framework for so (3)-equivariant networks.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "*Originality:* The proposed approach appears novel. Although other approaches have used a Fourier like representation to represent 3D objects [1,2,3], this approach differs from those in that 1) the representation is intentionally high-dimensional, 2) only a subspace of the high-dimensional space is considered.\n\n*Quality:* In the experiments, proposed method performs on-par with or better than most baselines.\n\n*Clarity:* (see weakness)\n\n*Significance:* Designing expressive equivariant representations is a challenging and important problem in the field.\n\n\n[1] Esteves, Carlos, et al. \"Learning so (3) equivariant representations with spherical cnns.\" Proceedings of the European Conference on Computer Vision (ECCV). 2018.\n\n[2] Cohen, Taco S., et al. \"Spherical cnns.\" arXiv preprint arXiv:1801.10130 (2018).\n\n[3] Kondor, Risi, Zhen Lin, and Shubhendu Trivedi. \"Clebsch\u2013gordan nets: a fully fourier space spherical convolutional neural network.\" Advances in Neural Information Processing Systems 31 (2018)."
            },
            "weaknesses": {
                "value": "*Quality:* \n* The authors present a very critical view of methods that use spherical harmonics which I think is not only inappropriate but also incorrect. Spherical harmonics can be seen analogous to the Fourier basis which have been applied in signal processing problems for centuries, and the authors rely on for intuition building. Also, the authors state that spherical harmonics come from quantum mechanics, but the use of spherical harmonics predates the \"discovery\" of quantum mechanics by more than a century. \n* There does not appear to be any discussion of the impact of choosing a higher dimensional input representation space. How does the choice of $n$ impact performance? What is the additional computational cost?\n* The notation is inconsistent (see questions)\n* Some proofs are missing (see questions)\n\n*Clarity:* I found the presentation to be difficult to follow. The paper uses advanced math concepts such as the Lie bracket without motivating or even naming them."
            },
            "questions": {
                "value": "*Questions:*\n- What is meant by \u201c$R^z(\\hat{u})$ is a rotation matrix defining the orientation measured from the $z$-axis to $\\hat{u}$.\u201d Is it the 2D rotation about the axis $z \\times \\hat{u}$ that aligns the $z$-axis and $\\hat{u}$?\n- It seems like the map is from SO(3) to a subspace of SO(n) is that right\n- Is the axis arbitrarily selected?\n- Createsearchspace from Algo 2 is not described in the text, how does this work?\n\n*Possible typos:*\n- \u201cTheorem 1. theoremIf\u201d \u2192 \u201cTheorem 1. If\u201d \n- Are $\\hat{u}$ and $\\overrightarrow{u}$ used interchangeably in section 3? It would be clearer if the notation were consistent\n- \u201cintuitively, just like F1, F2 and F3 represent angles\u201d \u2192 \u201cintuitively, just like F1, F2 and F3 represent axes of rotation\u201d\n- Should \u201caxes \u03c8(\u02c6x), \u03c8(\u02c6y), and \u03c8(\u02c6z)\u201d be \u201caxes \u03c8(F_1), \u03c8(F_2), and \u03c8(F_3)\u201d? If not what does $\\hat{.}$ mean here?\n- \u201c effective-yet-rotation-equivariant\u201d \u2192  expressive yet rotation equivariant\n- In section D, readers are referred to the proof of Thm 1 for the proof of Prop 1, but the proof of Thm 1 does not prove Prop 1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9205/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699208434926,
        "cdate": 1699208434926,
        "tmdate": 1699637158024,
        "mdate": 1699637158024,
        "license": "CC BY 4.0",
        "version": 2
    }
]