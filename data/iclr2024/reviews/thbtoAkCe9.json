[
    {
        "id": "6cFWqIygqX",
        "forum": "thbtoAkCe9",
        "replyto": "thbtoAkCe9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_3E93"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_3E93"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel coreset selection algorithm called D2 pruning (Diversity-Difficulty pruning), which leverages undirected graphs and message passing to calculate difficulty score. The algorithm's primary goal is to tackle two important aspects: example difficulty and diversity within the selected subset of data points. D2 pruning works in the following way: 1. Graph Initialization: Nodes in graph G represent dataset examples and are connected to their k-closest neighbors in the embedding space. 2. Update difficulty score: Use message passing on the graph to update difficulty scores based on neighbor distance and difficulty.  3. Coreset Selection: Iteratively select balanced samples from high-density low-difficulty and low-density high-difficulty regions. Down-weight neighbors of selected samples to promote coreset diversity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors proposed a novel coreset selection algorithm that aims to unify the benefits of data diversity and data difficulty. The proposed method is intuitive.\n\n2. The proposed method is also evaluated on NLP datasets - lacked in prior work. \n\n3. The evaluation compares $D^2$ with various baselines and shows that $D^2$ achieves better or comparable performance than SOTA methods.\n\n4. The writing is good and easy to follow."
            },
            "weaknesses": {
                "value": "1. The performance improvement seems marginal. In most cases, the improvement is less than $1\\%$. \n\n2. With such performance differences, repeated evaluation can be suggested to mitigate the variance in the model training.\n\n3. $D^2$ introduces some additional hyper-parameter, which may increase the coreset selection cost."
            },
            "questions": {
                "value": "1. How many iterations will the forward message passing phase have?\n\n2. What is the importance score in fig 2 (what metrics used)? \n\n3. It seems that $D^2$ can be combined with other metrics. Do you run an ablation study to see how $D^2$ performs with other importance scores?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6731/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698783340874,
        "cdate": 1698783340874,
        "tmdate": 1699636774051,
        "mdate": 1699636774051,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i1nhXrPT4p",
        "forum": "thbtoAkCe9",
        "replyto": "thbtoAkCe9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_niHR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_niHR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to balance both difficulty and diversity in the data sampling process. The authors argue that difficulty and diversity have been independently optimized but should be optimized together. To this end, this work proposes a graph-based method, D^2 pruning, which builds the graph based on data diversity and uses message passing to get information difficulty."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors perform extensive experiments, on both vision and NLP datasets, and compare to a well-covered set of baseline. Empirical results appear to be promising.  The methodology itself also appears to be interesting and novel, to the best of my knowledge."
            },
            "weaknesses": {
                "value": "The authors use distance in embedding space to construct the near-neighbor graph. However, there is a lack of support for why distance in embedding space is a good indicator of diversity. For example, what if we use another model to generate the embedding? What\u2019s the influence between feature level embedding versus final layer embedding? Similarly, the authors use the forgetting score as the difficulty indicator. There is no discussion on why the author choose forgetting score? What would be the influence of choosing another score, such as a consistency score or loss of an approximate model?"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Reviewer_niHR"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6731/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812463064,
        "cdate": 1698812463064,
        "tmdate": 1700719723932,
        "mdate": 1700719723932,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9ZGMHT5Gn8",
        "forum": "thbtoAkCe9",
        "replyto": "thbtoAkCe9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_2S5F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_2S5F"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a new data pruning model called D^2 pruning that balances diversity and difficulty via a message-passing algorithm.\nThey show the performance superiority of the proposed method on vision and NLP datasets with supervised and self-supervised variants."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Clear presentation and easy-to-follow writing.\n- The algorithm is straightforward and easy-to-implement.\n- The evaluation is extensive, with many datasets in multiple tasks, and solid."
            },
            "weaknesses": {
                "value": "- No time complexity analysis. The proposed algorithm based on message-passing seems to take quite a lot of time. The author should provide the time-complexity analysis with the exact GPU time taken because a data pruning method that takes too long time is less practical.\n- No theoretical analysis. How this message-passing algorithm can guarantee better generalization than other baselines? Although the author provides some intuition (data pruning should consider both diversity and difficulty), why it should be achieved by the message-passing and how it can reduce the generalization error in Eq.(1) is missing."
            },
            "questions": {
                "value": "I think this work is also related but missed in discussion/comparison.\n\n[a] Active learning is a strong baseline for data subset selection. NeurIPS workshop, 2022"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Reviewer_2S5F"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6731/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821437549,
        "cdate": 1698821437549,
        "tmdate": 1700709169229,
        "mdate": 1700709169229,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "P813VS8hhv",
        "forum": "thbtoAkCe9",
        "replyto": "thbtoAkCe9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_4iU9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_4iU9"
        ],
        "content": {
            "summary": {
                "value": "This paper starts by emphasizing the significance of maintaining a balance between the diversity and difficulty of samples used in data subset selection, for speeding up the training process. To this end, the authors initially illustrate instances in which diversity sampling can result in an excessive over-sampling (attributable to over-representation) from regions characterized by relatively low complexity. Following this, as shown in Figure~2, the authors introduce a graph-based algorithm designed to select training examples that maintain a balance between diversity and difficulty. The algorithm is based on message parsing on the constructed graph where each datapoint is a node. Subsequently, the paper provides experimental evidence in support of their proposed method, conducted across a range of datasets encompassing both vision and language domains, as well as their joint modality. The experimentation includes scenarios involving both supervised and self-supervised learning. The paper also addresses the interesting datacomp setting and evaluates its performance against the corresponding benchmarks, including VTAB and retrieval."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "A wide range of data modalities is considered which I particularly appreciate, unlike other papers in the community. Ablation is also done on the hyperparameters mentioned in the proposed algorithm, which include $\\gamma_r$, $\\gamma_f$ (kernel width), and the sparsity of the graph. The paper was pretty much straightforward and they mentioned that $D^2$ provides boosts under a low to medium \"pruning\" regime. Overall, I like the simplicity of writing."
            },
            "weaknesses": {
                "value": "I feel that the prime weakness of this work is from the angle of related works, and baselines. Highlighting the importance of balancing diversity and difficulty is not new, and indeed if one is using not well-tuned diversity selection methods, then they won't be able to give a full representation of the dataset (minor modes which are not outliers but are difficult). That being said, I need an explanation, and if possible, results on the following baselines --\n\nFor general supervised cases \n\n- CRAIG [1]\n- GLISTER (this paper has the same motivation as mentioned in Eq1) [2]\n- GradMatch [3]\n- Top-k method [4]: Another graph-based sampling that downweighs the contribution based on neighbors.\n- CREST (an extension of CRAIG) [5]\n\nA combination of submodularity with difficulty has been explored in the following -- \n\n- FASS (two-stage procedure for active learning, but a similar two-stage procedure can be considered here) [6]\n- A combination of submodularity and difficulty has been considered in CAL-SDS2 [7]\n- MCL (Combination of hardness and diversity for curriculum learning) [8]\n- DIHCL (another combination of hardness and diversity for curriculum learning) [9]\n\nMore recent works on diversity-based selection (for NLP) --\n- MILO [10]\n- INGENIOUS [11]  \n\nOn SSL: \n- See SAS [12] \n\nOn multimodality see T-MARS [13]\n\nConcluding thoughts: \nI believe the paper should discuss these works and should include some of them as baseline.  \n\nReferences\n- [1] Data-efficient Training of Machine Learning Models (ICML'20) \n- [2] GLISTER: Generalization-based Data Subset Selection for Efficient and Robust Learning (AAAI'21) \n- [3] GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training (ICML'21)\n- [4] SELECTIVE ANNOTATION MAKES LANGUAGE MODELS BETTER FEW-SHOT LEARNERS (ICLR'23)\n- [5] Towards Sustainable Learning: Coresets for Data-efficient Deep Learning (ICML'23)\n- [6] Submodularity in Data Subset Selection and Active Learning (ICML'15)\n- [7] Accelerating Batch Active Learning Using Continual Learning Techniques (TMLR/DMLR@ICML'23)\n- [8] Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity (ICLR'18)\n- [9] Curriculum Learning by Dynamic Instance Hardness (NeurIPS'19) \n- [10] MILO: Model-Agnostic Subset Selection Framework for Efficient Model Training and Tuning \n- [11] INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models\n- [12] Data-Efficient Contrastive Self-supervised Learning: Most Beneficial Examples for Supervised Learning Contribute the Least (ICML'23)\n-  [13] T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"
            },
            "questions": {
                "value": "- For the difficulty-based methods, in supervised settings, methods such as forgetting-event are clear that they use the learning dynamics. However, methods such as -- entropy, EL2N (which is similar to the norm of the gradient concerning bias term), and area under margin score, can be computed during any step of training. Therefore, does the paper consider the moving average of the dynamics (of some pre-trained models, for which they've assumed the access), or is it taken at the end of the training? In case it is moving average, I am okay with it, but if it is taken at the end of the training, then the training set methods like entropy/margin/EL2N can be very wrong in judging the hardness. \n\n\n- Can authors provide standard deviation or statistical analysis in cases where the second-best technique is very close? \n- For BADGE does the author use true labels instead of pseudo labels? BADGE was proposed in Active learning and hence it is important to make sure it doesn't have a disadvantage in supervised setting comparisons. \n- k and s_k are overloaded as expressions in the paragraph above equation 6. \n- What happens when one runs message parsing for more than one round? Can authors provide an experiment on that or justification? \n- Eq. 1 theta should rather me $\\theta^*(S')$ to show that it is a solution to the optimization."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Reviewer_4iU9"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6731/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699067905686,
        "cdate": 1699067905686,
        "tmdate": 1700699459835,
        "mdate": 1700699459835,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2P1l83oTdv",
        "forum": "thbtoAkCe9",
        "replyto": "thbtoAkCe9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_DbMJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6731/Reviewer_DbMJ"
        ],
        "content": {
            "summary": {
                "value": "The $\\mathbb{D}^2$ PRUNING method presented in this paper demonstrates a novel approach for selecting the most useful data from large training sets (coresets) for deep learning model training. \n\nIt combines two key factors: data diversity and sample difficulty. The method represents the training dataset as a graph and uses a message-passing algorithm to update each data point's difficulty score by considering its neighbors. This process ensures a balance of diverse and challenging data in the selected coreset. \n\n$\\mathbb{D}^2$ PRUNING has shown to be effective in improving model performance, particularly for image classification and natural language processing tasks, and is especially useful at low-to-medium data pruning rates."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper presents a novel approach - $\\mathbb{D}^2$-PRUNING, which balances both data diversity and difficulty, along with its applicability to both supervised and self-supervised learning contexts. This positions it as a valuable tool in the ongoing evolution of corset selection techniques for data efficient learning.\n2. The experiments are clear and the authors provide ablation experiments to support the theory and newly introduced hyper-parameters in the paper.\n3. It is commendable that the paper divulges into the NLP domain and demonstrates improved performance over existing methods in coreset selection."
            },
            "weaknesses": {
                "value": "1. The paper demonstrates very incremental gains in performance over State-of-the-Art method (like Ash et al., 2019).\n2. The experiments in section 5.1 do not compare $\\mathbb{D}^2$-PRUNING State-of-the-Art methods discussed in (Guo et al., 2021) such as GLISTER (Killamsetty et al., 2021), CRAIG (Mirzasoleiman et al., 2020), GRAD-MATCH (Killamsetty et al., 2021) etc."
            },
            "questions": {
                "value": "1. The paper uses inconsistent numberings (A and then 2, 3) in section 1 which should be rectified.\n2. An important investigation aspect for this paper would be to demonstrate performance on very small values of selection ratios $k$ as discussed in (Guo et al, 2021) and perform more than 1 message passing (K-shot setting).\n3. The paper refers to additional information in the appendix section. It would greatly improve the readability of the paper if the authors point to exact section numbers in the appendix.\n4. It is unclear if the parameter $\\gamma$ mentioned in section 5.1 refers to $\\gamma_f$ or $\\gamma_r$. \n5. Although optional, including an algorithmic view of the proposed approach would be interesting to clarify how $\\mathbb{D}^2$-PRUNING fits into the training and evaluation process of deep-learning models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6731/Reviewer_DbMJ"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6731/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699639421683,
        "cdate": 1699639421683,
        "tmdate": 1699639421683,
        "mdate": 1699639421683,
        "license": "CC BY 4.0",
        "version": 2
    }
]