[
    {
        "id": "d1RZWRjC59",
        "forum": "WwCirclMvl",
        "replyto": "WwCirclMvl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_VjxR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_VjxR"
        ],
        "content": {
            "summary": {
                "value": "The authors present a model-free posterior sampling approach for offline RL using Langevin Monte Carlo (LMC) for posterior approximation. They introduce practical algorithms in an episodic setting for both linear low-rank MDPs, and general MDPs (with over-parameterized neural networks for value function approximation, alongside an auxiliary linear model for LMC). Notably, the paper establishes frequentist sub-optimal bounds both cases. Empirical evaluations on linear MDP and non-linear contextual bandits support the proposed algorithms' effectiveness."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I believe the most important strength is that the paper offers an insightful advancement in offline RL through a Bayesian lens. While the value-based variation to classical PSRL and the employment of LMC for posterior approximation are not novelties in isolation, their integration within offline RL is both meaningful and aptly executed. \n\nThe implicit pessimism by posterior sampling with the proof of a frequentist bound is also a non-trivial contribution, and provides a fresh perspective to ongoing discussions in this domain."
            },
            "weaknesses": {
                "value": "While the paper makes significant theoretical advancements, it would further solidify its applicability if the proposed algorithms were tested on well-regarded benchmarks, such as the MuJoCo tasks from the D4RL suite. Additional experiments with model-based approaches would offer a comprehensive perspective on the approach's effectiveness.\n\nThe presented approach captures pessimism through posterior sampling. While innovative, one could question whether this form of pessimism adequately represents the complex nature of uncertainties found in the offline dataset, particularly given the non-stationary distributions that can arise from varied data collection policies."
            },
            "questions": {
                "value": "Please refer to the concerns in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8841/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698588258126,
        "cdate": 1698588258126,
        "tmdate": 1699637112078,
        "mdate": 1699637112078,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "r5cryazQhd",
        "forum": "WwCirclMvl",
        "replyto": "WwCirclMvl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_jpdm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_jpdm"
        ],
        "content": {
            "summary": {
                "value": "This paper explores convergence of posterior sampling via Langevin Monte Carlo for offline RL."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The study sounds solid, although I did not go through each step of the proof."
            },
            "weaknesses": {
                "value": "The paper did not clearly explain the fundamental difference between the convergence of Langevin Monte Carlo and the convergence of the RL posterior sampling under the offline setting."
            },
            "questions": {
                "value": "1. What is the difference between the convergence of Langevin Monte Carlo and the convergence of the RL posterior sampling under the offline setting? Will the former lead to the latter? \n\n2. Why is LMC, instead of SGLD, used in Algorithms 2 and 3?  Can mini-batch data be used in simulations of the proposed algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8841/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698629057871,
        "cdate": 1698629057871,
        "tmdate": 1699637111902,
        "mdate": 1699637111902,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u4MZfo08d5",
        "forum": "WwCirclMvl",
        "replyto": "WwCirclMvl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_Cabd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8841/Reviewer_Cabd"
        ],
        "content": {
            "summary": {
                "value": "The submission studies a Bayesian method for offline RL. The proposed method is quite simple (which I see as a pro), simply do the noisy gradient descent on the regression objective. Analysis with improved bounds is the main contribution of the paper."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method is simple and seems implementable in practice. \n\n- The bounds are improved from previous work. \n\n- Analysis of the NTK regime is performed, which might be of independent interest."
            },
            "weaknesses": {
                "value": "- I do not see particularly new ideas from the submission, either in the algorithm or in the analysis. Thus, the novelty of the paper is limited. \n\n- The work in Uehara and Sun [US21] considers the setting where the representation of state-action $\\phi(s,a)$ is unknown, whereas the submission assumes the feature representation function is known. I think it is not fair to claim the improvement from [US21].\n\nIn general, even though this is a technical paper, the submission is a bit hard to parse. \n\n- How is the regression objective related to posterior sampling? How is this a \"Langevin\" Monte Carlo method? It would be good to be introductory to Langevin Monte Carlo methods, and how the concepts are attached to the actual algorithm presented. \n\n- I had to understand the linear (or low-rank) MDP part very clearly before paying attention to the NTK function approximation part. I do not see any particular contribution from the NTK part to reinforcement learning theory. It is a good add-on result though."
            },
            "questions": {
                "value": "- I wonder how this method performs on some offline deep-RL benchmarks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8841/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817616617,
        "cdate": 1698817616617,
        "tmdate": 1699637111777,
        "mdate": 1699637111777,
        "license": "CC BY 4.0",
        "version": 2
    }
]