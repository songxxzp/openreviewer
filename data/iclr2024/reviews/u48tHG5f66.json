[
    {
        "id": "wuBzJNUdEe",
        "forum": "u48tHG5f66",
        "replyto": "u48tHG5f66",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_3ixD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_3ixD"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an (almost) training-free solution for adapting a pre-trained diffusion model to generate images of much higher resolution than the image size used during training.\nTo achieve this goal, the authors consider the procedure of convolution dispersion which aims to increase the receptive field (in terms of pixels) of convolutional blocks while preserving the properties of the original layer.\nIn addition, the presented technique of noise-damped classifier-free guidance leverages both the original model and its modification with dispersed convolutions in order to combine the generative power of the former and better denoising in high resolution of the latter.\n\nAccording to the qualitative evaluation, the proposed approach successfully eliminates the issue of object repetition and implausible object structures. This is also confirmed with quantitative measurements."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The problem tackled in this work is quite important for the community. In general, this paper is clearly written. The motivation is explained well, and the details of the method are concise (see minor remarks below). The samples provided by the authors look quite plausible. Also, I appreciate the implementation details specified in the Appendix."
            },
            "weaknesses": {
                "value": "1. As far as I can judge, there is no discussion in the paper of the ability to magnify the output produced with the original diffusion model in standard resolution. I suggest adding it to the paper since it seems that it can be relatively straightforward to add it to the existing guidance (Eq. 5). This can help to make the comparison with SD+SR (Tab. 2) more conclusive.\n1.  None of the reported quantitative metrics except for human assessment estimates the plausibility of generated high-frequency details, since common implementations of FID/KID downsample the input images to the ImageNet resolution before the feature extraction. Therefore, I recommend reporting e.g. patch-FID [1]  to assess high-resolution textures in addition. Also, some other variations like sFID [2] are known for better assessment of spatial variability.\n\n1. Minor remarks:\n    1.  Eq. 1 probably has a typo: the variable $o$ exists in LHR but not in RHS.\n    1.  Probably, one needs to replace $\\min$ with  $\\arg\\min$ in Eq. 4.\n    1.  Please highlight the best metrics in tables consistently (see Tab. 2).\n    1.  There is no such block as MB3 in Fig. 1 of Appendix A2, please edit the caption.\n\nReferences:\n\n[1] Chai et al. Any-resolution Training for High-resolution Image Synthesis. In ECCV, 2022.\n\n[2] Nash et al. Generating images with sparse representations. In ICML, 2021."
            },
            "questions": {
                "value": "1. Please, address the weaknesses mentioned above.\n1. Since the dispersed convolution is a dense operation with a larger receptive field, it introduces additional computational costs. How significant is the computational overhead of the method?\n1. Is the re-dilation described in Sec. 3.2 actually used in the method? As far as I understood, in practice only dispersed convolutions are applied in the modified UNet. Probably, this part of the description needs more polishing.\n1. Is it possible to find a closed-form solution for the optimization problem in Eq. 4? If so, it would be nice to add it to the paper or supplementary. Otherwise, the method implementation is not entirely training-free (although still pretty cheap), and the claims should be adjusted."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698213112256,
        "cdate": 1698213112256,
        "tmdate": 1699636281905,
        "mdate": 1699636281905,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YLFaaKVGZ8",
        "forum": "u48tHG5f66",
        "replyto": "u48tHG5f66",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_URVR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_URVR"
        ],
        "content": {
            "summary": {
                "value": "This paper conduct research on the capability of generating higher resolution image from pre-trained diffusion models using lower resolution training data. The authors find that in the existing structures, the perception field of convolutional kernels is limited. Based on this, the authors propose a re-dilation method that can adjust the convolutional perception field during inference. The proposed method in this paper can generate high resolution images with 4096x4096 resolution without extra training. Experimental results show that the proposed method is able to achieve the SOTA results. This paper is well organized and easy to follow."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Here are the strength points of this paper:\n\nThe authors proposed an observation and explanation for the objective repetition problem. They also designed a re-dilation method to address this problem for high-resolution image generation. The proposed method is applied and evaluated on multiple models, the results show that the proposed method is effective."
            },
            "weaknesses": {
                "value": "Here are the weak points of this paper:\n\nSee the detailed comments and questions."
            },
            "questions": {
                "value": "Here are my detailed comments and suggestions:\n\nThis article is generally good, but I still have some questions about the design of the model and the experimental process.\n\n1.\tThe section on \"re-dilation\" mentions the use of a predefined dilation schedule function D(t,l). How is this function defined, and have any experiments been conducted to validate or optimize its selection?\n\n2.\tIn the \"convolution dispersion\" section, a linear transformation R and structural-level calibration are used to enlarge the convolution kernel. Does this step add to the model's computational complexity? If so, by how much?\n\n3.\tIn the \"noise-damped classifier-free guidance\" section, a guidance scale w is mentioned. How is this parameter chosen? Does it require adjustments for different tasks or datasets?\n\n4.\tThe authors used FID and KID as the metrics that require downsampling images to 229 \u00d7 229, does this imply that these metrics are not very suitable for evaluating high-resolution images?\n\n5.\tHas the paper considered comparisons with other recently published methods for high-resolution image generation? Would such comparisons further validate the effectiveness of the model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698676318068,
        "cdate": 1698676318068,
        "tmdate": 1699636281829,
        "mdate": 1699636281829,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ijFAOEtrkx",
        "forum": "u48tHG5f66",
        "replyto": "u48tHG5f66",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_6a3j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_6a3j"
        ],
        "content": {
            "summary": {
                "value": "This submission proposes to generate images from pre-trained diffusion models at a much higher resolution without the problems of object repetition and unreasonable object structures. In particular, it presents the key problem of the limited perception field of convolutional kernels and represents the new dispersed convolution and noise-damped classifier-free guidance. The experimental results, including ultra-high-resolution image and video synthesis, are very impressive."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The paper addresses a significant challenge in image generation by investigating the generation of images at much higher resolutions than the training image sizes, while also allowing for arbitrary aspect ratios. This is a novel and important problem in the field of image synthesis.\n- The proposed approach of using re-dilation to dynamically adjust the convolutional perception field during inference is a key contribution. This addresses the identified limitation of convolutional kernels, which is a crucial insight for improving high-resolution image generation.\n- The paper's extensive experiments demonstrate the effectiveness of the proposed approach in addressing the repetition issue and achieving state-of-the-art performance, particularly in texture details. This provides strong empirical support for the proposed techniques.\n- Overall, the paper appears to make a valuable contribution to the field of image synthesis, specifically in the context of generating high-resolution images with arbitrary aspect ratios. The proposed techniques and insights are well-motivated and supported by extensive experiments."
            },
            "weaknesses": {
                "value": "- Fig. 5-7 and Table 2-4 could be presented in a former manner.\n- More ablation studies could be presented in the main text and limitations are suggested."
            },
            "questions": {
                "value": "Please refer to the above weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N.A."
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698754918353,
        "cdate": 1698754918353,
        "tmdate": 1699636281760,
        "mdate": 1699636281760,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3lYv9VuCkj",
        "forum": "u48tHG5f66",
        "replyto": "u48tHG5f66",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_7LTr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3323/Reviewer_7LTr"
        ],
        "content": {
            "summary": {
                "value": "This submission proposed the generation of high-resolution images from pre-trained diffusion models. The authors claimed that their approach can address the persistent issues with the generated images. A re-dilation method was proposed to dynamically adjust the convolutional perception field during inference. Moreover, the authors implemented ultra-high-resolution image generation with a dispersed convolution and noise-damped classifier-free guidance. The experiments were conducted to demonstrate the advantages of the proposed solutions."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "As claimed by the authors, the proposed solution is simple and efficient, but it is powerful enough to generate ultra-high-resolution images and videos. The method does not require any training and optimization."
            },
            "weaknesses": {
                "value": "The major issue is with the experiments. It is unsure whether the results in Table 1 tell about the differences among SD solutions or the differences between the \"Method\" in the second column. And when the resolution changes, how did the results vary accordingly? Are the metrics still acceptable if a higher-resolution image is generated? What do the metrics mean for the application in addition to their use for comparison? \n\nAs the authors mentioned the results in Table 2 were not better than the SR+SR method, what is the justification to use the proposed solution? How could the user balance the efficiency and the quality in terms of the application's needs? It is unclear."
            },
            "questions": {
                "value": "The significance of the proposed method is still unclear after the presentation of the experimental results. The method can achieve similar or slightly better results. However, it is not sufficient to justify the significance of the work. This is a major concern."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3323/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3323/Reviewer_7LTr",
                    "ICLR.cc/2024/Conference/Submission3323/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699055755526,
        "cdate": 1699055755526,
        "tmdate": 1700841730723,
        "mdate": 1700841730723,
        "license": "CC BY 4.0",
        "version": 2
    }
]