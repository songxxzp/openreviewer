[
    {
        "id": "6oYRLUAZsX",
        "forum": "HOf3K763zg",
        "replyto": "HOf3K763zg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_7YF3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_7YF3"
        ],
        "content": {
            "summary": {
                "value": "The authors of this paper introduce a new approach to neurosymbolic learning called Infer-Sample-Estimate-Descend (ISED). Neurosymbolic learning aims to combine classical algorithms and deep learning. Unlike existing neurosymbolic frameworks, ISED allows for the use of black-box programs written in general-purpose languages, expanding its applicability. ISED is designed for algorithmic supervision, where a black-box program is applied to the output of a neural model, and the goal is to optimize the model parameters using end-to-end labels. ISED consists of four phases: Infer, Sample, Estimate, and Descend, where neural models predict distributions for inputs, samples are generated, the program is executed, probabilities are estimated, and the loss function is computed. ISED is evaluated on 30 benchmark tasks with black-box programs written in Python and achieves higher accuracy than end-to-end neural approaches, often outperforming a state-of-the-art neurosymbolic framework called Scallop."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Good performance and quality experiences with clear text ."
            },
            "weaknesses": {
                "value": "Poor quantitative aspects of training, including memory requirements, training time for each model, and for each dataset."
            },
            "questions": {
                "value": "What are the shortcomings related to the quantitative aspects of training, such as memory requirements, training time for each model, and for each dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698571103223,
        "cdate": 1698571103223,
        "tmdate": 1699636976690,
        "mdate": 1699636976690,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SaW3wgC3js",
        "forum": "HOf3K763zg",
        "replyto": "HOf3K763zg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_9rTK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_9rTK"
        ],
        "content": {
            "summary": {
                "value": "This article introduces a Neuro-Symbolic learning framework designed to utilize structured knowledge pertaining to the outputs of neural networks, expressed through black-box programs. The method proposed in this paper requires only that the reasoning part be capable of forward reasoning, without necessitating that the output of the reasoning part be differentiable with respect to the input. Authors validate the adaptability of the learning framework through extensive experimentation on a variety of synthetic and classic benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper is easy to read, with Figures 1 and 2 providing a clear and intuitive illustration of the proposed method.\n2.\tThe paper conducts a comprehensive evaluation of the proposed method on synthetic and classic tasks such as MNIST Add, HWF and Sorting, demonstrating the method\u2019s adaptability."
            },
            "weaknesses": {
                "value": "1.\tIn the abstract, the authors mention that \u2018existing general neuro-symbolic frameworks require that programs be written in differentiable logic programming languages\u2019. However, there already exist frameworks aiming at bridging machine learning and logic reasoning such as Semantic Loss [1], Abductive Learning [2] and NEUROLOG [3], which do not impose a requirement for differentiability and they use non-differentiable programs. The paper does not conduct comparisons with such methods.\n2.\tThe novelty of the proposed work needs to improve to meet the desired standards. The method proposed in this paper involves employing the REINFORCE algorithm to eliminate the requirement for differentiability in neural-symbolic system. However, this idea has already been introduced in the previous work [4]. Another critical component of the method, 'Estimate', fundamentally constitutes a sampling estimation of the well-known semantic loss [1], yet the paper does not provide reference to this work.\n\n[1] Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van den Broeck. A Semantic Loss Function for Deep Learning with Symbolic Knowledge, ICML 2018.\n\n[2] Zhi-Hua Zhou. Abductive learning: Towards bridging machine learning and logical reasoning. Science China Information Sciences, 2019. \n\n[3] Tsamoura, Efthymia, Timothy Hospedales, and Loizos Michael. Neural-Symbolic Integration: A Compositional Perspective, AAAI 2021.\n\n[4] Cornelio Cristina, Jan Stuehmer, Shell Xu Hu, and Timothy Hospedales. Learning where and when to reason in neuro-symbolic inference, ICLR 2023.\n\n3.\tInconsistent styles: some NeurIPS references include page numbers, while others do not; some conference names have abbreviations, while others do not."
            },
            "questions": {
                "value": "1.\tProlog is Turing-complete, possessing the same expressive capabilities as Python, and is also suitable for general-purpose use.\n2.\tThe neural network's initial performance is nearly equivalent to a random output, and methods based on sampling may encounter difficulties in capturing certain symbols. How you address this cold start issue?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7948/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7948/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7948/Reviewer_9rTK"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698822235453,
        "cdate": 1698822235453,
        "tmdate": 1699636976574,
        "mdate": 1699636976574,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FRZXgT2cG1",
        "forum": "HOf3K763zg",
        "replyto": "HOf3K763zg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_Bw9k"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_Bw9k"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a general Neuro-Symbolic solver approach using fixed black-box programs with the premise this allows anyone to write the program in any language as it removes the need for the program to be differentiable. This changes the neurosymbolic problem from program inference, to focus on parameter sampling and gradient propagation around the black box. The authors show that on three tasks  calculation, sorting and disease detection their method is able to outperform the baseline."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- In principle, the approach is a general-purpose neuro-symbolic approach.\n- Despite the removal of gradients during the execution step, the performance is equivalent to the baseline\n- The idea of using user-defined programs in execution is interesting and novel.\n- The author's multi-dataset evaluation provides a broad context in different settings.  However, the leaf disease setting does not need to be a neuro-symbolic approach as shown by the simple program. A spatial reasoning test would probably have been a better choice."
            },
            "weaknesses": {
                "value": "- The introduction of the black-box programs seems to constrain the problem largely. In the writing, it isn't clear if the programs are only used as supervision or explicitly used as the symbolic aspect. If it is the latter this greatly reduces the difficulty of the problem as the symbolic aspect is largely unneeded, as you could include an expert program to solve without needing symbolic, this is especially evident in the leaf disease test as there are a number of off the shelf expert models that could be applied without needing a threshold of % diseased. The approach would have been better argued by another approach, such as logical reasoning, ideally on Knowledge Graphs, which would be a compatible setting to prior methods, increasing the number of comparisons the authors could perform.\n- It isn't clear how this would scale to larger, more complex problems where the black-box program actually is complex. All examples are relatively trivial.\n- It isn't clear how they handle the gradients around the black box as they just state an optimizer solves this without any specificity."
            },
            "questions": {
                "value": "- Greater explanation of whether the programs are learnt or if they only the inputs are being estimated.\n- Explanation of how gradients are propagated\n- Any prediction of how this would scale to complex problems"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698833984385,
        "cdate": 1698833984385,
        "tmdate": 1699636976465,
        "mdate": 1699636976465,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xWtHZBDax3",
        "forum": "HOf3K763zg",
        "replyto": "HOf3K763zg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_4kqW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7948/Reviewer_4kqW"
        ],
        "content": {
            "summary": {
                "value": "This work presents a general framework for neurosymbolic learning with black-box programs (ISED). This framework does not need the differentiability of the program and uses a sampling-based method to approximate the gradient of the program execution. The evaluation results show that ISED is more accurate."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper uses lots of illustrations, which make the presentation clear."
            },
            "weaknesses": {
                "value": "1. Limited Benchmark: The evaluation compares with Scallop and CNN. However, this work did not compare with another differentiating neurosymbolic program work: DeepProbLog, which limits the significance of the performance.\n2. Scalability. This work can only cover an input length of 7, concluding the multiplication and additional operation. However, a traditional neurosymbolic program\u2019s statement may not limit two these two operations."
            },
            "questions": {
                "value": "1. How accurate the sampling-based method is? Is there any theoretical analysis about the gradient error from the estimation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698986256940,
        "cdate": 1698986256940,
        "tmdate": 1699636976363,
        "mdate": 1699636976363,
        "license": "CC BY 4.0",
        "version": 2
    }
]