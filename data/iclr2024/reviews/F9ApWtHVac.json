[
    {
        "id": "vHUaIoVrg2",
        "forum": "F9ApWtHVac",
        "replyto": "F9ApWtHVac",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_zyj4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_zyj4"
        ],
        "content": {
            "summary": {
                "value": "This paper presents Bridge-TTS, which incorporates the Schr\u00f6dinger Bridge concept into text-to-melspectrogram generation. By introducing the Schr\u00f6dinger bridge that directly connects the deterministic latent representation from the text encoder and the data, it allows for more direct use of the text encoder output compared to Grad-TTS. It demonstrated better sample quality with fewer sampling steps than Grad-TTS on the LJSpeech dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper applies a strong theoretical background on the Schr\u00f6dinger Bridge and the recent sampling methods from diffusion models to TTS.\n\n2. Bridge-TTS shows better sample quality with fewer sampling steps compared to Grad-TTS, and even with very few sampling steps (2-step generation), it produces reasonably good quality samples."
            },
            "weaknesses": {
                "value": "1. The performance improvement compared to Grad-TTS is marginal. Grad-TTS is a paper published in ICML 2021, and improving upon this baseline for a single speaker dataset (LJSpeech) doesn't seem to be a challenging issue in speech synthesis at present and appears to be a straightforward application. Thus, I believe it would be difficult for it to be published in ICLR 2024. Exploring this new generative model seems to have a fresh aspect, so targeting a speech-related venue might be more appropriate. Personally, I feel that the TTS problem for single speaker datasets in the years 2023-2024 is relatively a toy problem. Generating high-quality samples from LJSpeech doesn't appear to be a challenging issue, and I'm not particularly motivated by applying the Schr\u00f6dinger bridge to TTS given the experimental results in the paper."
            },
            "questions": {
                "value": "* The paper explores the scalar values of f and g, and shows the CMOS ablation results in Table 4. If the mel-spectrogram data is normalized to have values between [-1, 1] before training, couldn't we simply use 0 for f and 1 for g? By using f=0 and some scaling value for g, this approach appears to be the application of the Brownian bridge by Tong et al to TTS, as also mentioned in the paper.\n\n* The Schr\u00f6dinger bridge is used in the image domain for applications like Image-to-image translation. If the Schr\u00f6dinger bridge offers advantages in TTS not only for sampling speed on a single speaker but also for applications like translation in the speech domain (e.g., speech-to-speech translation, voice conversion, etc.), highlighting such results would have provided stronger motivation for its application. This could have made the research more compelling."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Reviewer_zyj4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1017/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818224066,
        "cdate": 1698818224066,
        "tmdate": 1700728565483,
        "mdate": 1700728565483,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "A9b0WQhjqp",
        "forum": "F9ApWtHVac",
        "replyto": "F9ApWtHVac",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_8tg3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_8tg3"
        ],
        "content": {
            "summary": {
                "value": "The paper presents Bridge-TTS that generates mel-spectrograms from deterministic text latent representations. To achieve this, the authors first introduce a fully tractable Schrodinger bridge for paired data in TTS modeling. Subsequently, they propose a novel first-order discretization of the Bridge SDE/ODE for accelerated sampling. Experimental results emphasize that the proposed approach offers synthesis quality comparable to or surpassing baseline methods, especially in few-step sampling scenarios."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The authors introduce a theoretically novel approach to employ Schrodinger bridge for TTS that produces outputs from deterministic latent representations.\n* They present a new sampling scheme optimized for fast sampling."
            },
            "weaknesses": {
                "value": "* A lack of empirical validation for the superiority of the proposed method.\n\nIt is uncertain whether the proposed deterministic latent representations are superior to the noisy Gaussian conditional prior distribution of diffusion-based TTS. Experimental results suggest that for fewer than 50 sampling steps, the proposed method seems to yield better sample quality compared to other models. However, at 1000 steps, the diffusion-based TTS model, namely Grad-TTS, outperforms the proposed methodology.\n\nAccordingly, for a fair comparison concerning its efficient sampling scheme, it would be appropriate to contrast it with diffusion-based TTS models using a sampling scheme like the DDIM."
            },
            "questions": {
                "value": "It would be essential for the authors to provide an explanation for the observed worse sample quality of their proposed method compared to the baseline diffusion-based approach at 1000 sampling steps.\nAdditionally, the generation quality between the proposed method and diffusion-based methods using a comparable sampling scheme in few-step sampling scenarios would also be an interesting aspect of this research.\n\ntypo: (p.7, Sec.4.1.,) English graphme -> English grapheme"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Reviewer_8tg3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1017/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839696438,
        "cdate": 1698839696438,
        "tmdate": 1699636027757,
        "mdate": 1699636027757,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mdFREvS9hk",
        "forum": "F9ApWtHVac",
        "replyto": "F9ApWtHVac",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_SrNQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_SrNQ"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a novel neural TTS system based on SB. Informative prior in generative models is an important technical point that is well handled by this paper. In certain scenarios, they show improvement over SOTA methods like Grad-TTS and DiffSinger. The proposed tractable SB is created by defining a reference SDE in alignment with diffusion models. Bridge sampling is discussed in this context to generate the target when trained with paired data (clean text, mel spectrogram). Real-time Factor (RTF) is also discussed alongside MOS, CMOS in evaluation on LJSpeech. Proposal shows improvement in reducing high-frequency artifacts."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Novelty: Introducing SB to TTS domain.\n2. Technical rigor\n3. Ablation studies"
            },
            "weaknesses": {
                "value": "1. Generalizability of the proposed method is an issue. We don't know if this works on other test sets, other speakers, etc. I am not confident if this model is vast improvement in the TTS research space.\n2. Focus of paper seems to be on technique. TTS-related discussion is lesser than expected.\n3. \"NFE\" is not defined. For new audience, it could be an issue.\n4. References are needed to say that some improvement in MOS is actually significant (which is what authors are conveying).\n5. Some more intuition on SB would be nice for audience with less background knowledge. Maybe a graph of training with loss or some term going down."
            },
            "questions": {
                "value": "1. I would like to know if pre-trained models (text encoders) can be leveraged to fasten or improve the proposed SB solution.\n2. Would authors like to comment on phoneme-level improvement or provide some information on trends?\n3. Any word on if there is a trade-off between the quality of the synthesized speech and the computational efficiency of the method?\n4. Can you add some additional consistency loss term which can further brings artifacts down?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Reviewer_SrNQ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1017/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699150897150,
        "cdate": 1699150897150,
        "tmdate": 1700740738812,
        "mdate": 1700740738812,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "87LD6A7MAg",
        "forum": "F9ApWtHVac",
        "replyto": "F9ApWtHVac",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_vLu2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1017/Reviewer_vLu2"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a non-autoregressive TTS model called Bridge-TTS, which is build on the Schrodinger bridge (SB). Bridge-TTS follows the two-stage TTS pipeline, i.e., the TTS system comprises with a text-to-spectrogram acoustic model and spectrogram-to-wave vocoder model, where the Schrodinger bridge is used in modeling the former. Unlike most diffusion-based TTS models, Bridge-TTS uses deterministic prior, which is learned from the text input in a deterministic way via a text encoder module. Bridge-TTS is able to use diffusion-TTS-like sampling procedure to synthesis samples from the prior, where different SDE/ODE-based samplers can be adopted to trade-off the inference speed and the sample quality. In general, this submission makes a clear presentation, making detailed and well-structured explanations from the theories of diffusion models to that of the Schrodinger bridge, and decent derivation of the methodology in adopting SB in paired data modeling, e.g., TTS task, as long as the training objective and different sampling schemes. A singer-speaker TTS experiment using the well-known TTS benchmark corpus LJ-Speech is conducted to verify the arguments by the paper."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper introduces yet another generative model, i.e., the Schrodinger bridge, for tackling the TTS task.\n- This paper presents derivations for bridge sampling in the context that the number of sampling steps is small for the first time, and gives exact solution and 1st-order discretization of SB SDE and ODE, allowing for efficient sampling with SB-based generative models. Relationship of the solution to some famous sampling schemes, such as DDIM, is also presented.\n- This submission has source codes, which could be helpful for reproducing the results presented."
            },
            "weaknesses": {
                "value": "Novelty:\n\nThe methodology of Bridge-TTS introduced in this submission does not attempt to address the most urgent issues of in the TTS research field, e.g., the prosody modeling, and the paper doesn\u2019t even specify which duration modeling and text-spectrogram alignment scheme are employed. Moreover, the contribution is incremental since this paper introduces yet another kind of generative model into TTS and does not receive significant performance improvement according the experimental results presented. This submission argues that  replacing the noisy prior in previous systems with the clean and deterministic prior can boost the TTS sample quality and inference speed. However, similar arguments have been made and verified in previous works, such as DiffSinger and DiffGAN-TTS. If we look at the training scheme and loss objective carefully, the text encoder output $z$ is in fact the coarse predicted Mel spectrogram as in DiffSinger, which is learned by using the simple MSE-based reconstruction loss. The SB-based module is indeed a spectrogram post-processing module or a \u201cspectrogram super-resolution module\u201d, and can only refine the details of the produced spectrogram and can not fully leverage the generative modeling power of diffusion-based or SB-based models. In this regard,  the contribution of this paper is not sufficient and only incremental.\n\nExperiments:\n\n- Only conducted single-speaker TTS on the LJ-Speech corpus: this is not sufficient since TTS models have reached human-level quality on this data, e.g., NaturalSpeech and StyleTTS-2. It will be more sound if multi-speaker or even multi-emotion TTS experiments are conducted.\n- The reason for explaining why Grad-TTS with 1000 NFEs has higher MOS score than that of Bridge-TTS with 1000 NFEs is not convincing."
            },
            "questions": {
                "value": "- Why the MOS scores of \u201cRecording\u201d and \u201cGT-Mel-Voc.\u201d in Table 2 are so different from those in Table 3?\n- Why Grad-TTS (NFE=1000) is faster than Bridge-TTS (NFE=1000) in terms of RTF, and in other cases such as NFE=50 and 4, Grad-TTS is slower than or has equal RTF to Bridge-TTS?\n- Why do you think SB-based spectrogram post-processor is better than diffusion-based ones, e.g., coarse predicted Mel spectrogram as condition to Grad-TTS decoder? Is there an intuitive explanation?\n- How do you align text and spectrogram during training and how do you model phoneme durations?\n\nTypos and minor edits in presentation:\n\n- There is no definition of $\\Psi$ and $\\hat\\Psi$.\n- I think the symbols of \u201cforward score\u201d and \u201cbackward score\u201d in the title of Table 1 are reversed.\n- \u201cIn practice, we prefer the noise prediction\u201d \u2192 \u201cIn practice, we prefer to the noise prediction\u201d"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1017/Reviewer_vLu2",
                    "ICLR.cc/2024/Conference/Submission1017/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1017/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699333447009,
        "cdate": 1699333447009,
        "tmdate": 1700660858584,
        "mdate": 1700660858584,
        "license": "CC BY 4.0",
        "version": 2
    }
]