[
    {
        "id": "tpoZg1WuQU",
        "forum": "ZKEuFKfCKA",
        "replyto": "ZKEuFKfCKA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_ByHL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_ByHL"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses a critical issue in federated learning (FL) where clients have varying and unknown participation rates, which can hinder FL's performance. Existing solutions often rely on global variance reduction, which consumes substantial memory resources. The paper introduces a lightweight method called FedAU, which adapts aggregation weights in FedAvg based on each client's participation history. FedAU resolves this problem by adaptively weighting client updates using online estimates of optimal weights, even without knowledge of participation statistics. Theoretical analysis shows that FedAU converges to the original objective's optimal solution with desirable properties such as linear speedup, and experimental results support its advantages over baseline methods in various participation scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strengths of this paper's contributions are as follows:\n\n1. The authors introduce a lightweight procedure named FedAU for estimating optimal aggregation weights for each client based on their participation history. This approach supports FL even when participation statistics are unknown, making it highly practical.\n\n2. The paper provides a novel and thorough analysis of the convergence upper bound for FedAU. It employs a unique method to handle weight error in the convergence bound and shows that FedAU converges to the optimal solution of the original objective. Furthermore, it achieves desirable linear speedup in convergence when the number of FL rounds is sufficiently large.\n\n3. Experimental results validate the advantages of FedAU over various datasets and baseline methods, particularly in scenarios with diverse participation patterns, including independent, Markovian, and cyclic patterns. This demonstrates the robustness and effectiveness of the proposed approach."
            },
            "weaknesses": {
                "value": "1. The theoretical results in the paper are founded on the assumption of a Bernoulli distribution for client participation. It does introduce an extra layer of specificity that might not hold universally. It would be beneficial for the authors to explicitly state this assumption within the paper, as the current presentation of the four assumptions largely omits this fact.\n\n2. I wonder if there is a potential limitation in scenarios where clients rarely participate in the training process, as seen in cases like cross-device federated learning. In such instances, the online estimation of the aggregation weights (w_t) could be challenging or, at best, very inaccurate."
            },
            "questions": {
                "value": "see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697945162119,
        "cdate": 1697945162119,
        "tmdate": 1699636442041,
        "mdate": 1699636442041,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PVbr6qgiHg",
        "forum": "ZKEuFKfCKA",
        "replyto": "ZKEuFKfCKA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_X6kq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_X6kq"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of partial participation in federated learning. More specifically, the authors consider the FedAvg algorithm and assume that each client $m$ will participate with some unknow probability $p_m$. The authors show that if we are aiming to optimize the objective in equation (1), the non-adaptive aggregation weight in FedAvg will lead to a solution of optimizing another objective. In addition, the authors propose a new method that can compute the adaptive aggregation weight efficiently, and provide the corresponding convergence rate."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strengths of the paper:\n1. The authors provide a result to show that non-adaptive aggregation weight in FedAvg is bad for optimizing the objective in equation (1).\n2. The authors develop an efficient method to estimate the adaptive aggregation weight that can be used in FedAvg.\n3. The authors establish the convergence rate of the proposed method which demonstrates the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "The weaknesses of the paper:\n1. There is no (theoretical) comparison with existing baselines.\n2. Several conditions in the established results are unclear."
            },
            "questions": {
                "value": "I have the following questions regarding the current paper:\n1. What are the other baseline algorithms and their corresponding convergence rates?\n2. According to Theorem 1, when we have full participation, i.e., $p_n=1$ and $w_n=1$, the objective in (2) will reduce to the objective in (1). Therefore, whether your results will recover the convergence rate of FedAvg with full participation? In addition, when we have partial participation with $p_n=p<1$ and $w_n=1$, the objective in (2) will also reduce to the objective in (1). How will your result look like compared to the existing results?\n3. What is the expression on $\\Psi_G$ in your theorems?\n4. In Corollary 4, what do you mean by sufficient large $T$? Do you mean the results hold only asymptotically?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809456965,
        "cdate": 1698809456965,
        "tmdate": 1699636441923,
        "mdate": 1699636441923,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "e3Zh8Hp2kh",
        "forum": "ZKEuFKfCKA",
        "replyto": "ZKEuFKfCKA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_p8tC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_p8tC"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the FedAvg algorithm with unknown participation statistics. It first proves that FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective. Next, it proposes an adaptive method to estimate the participation weight and come up with the FedAU algorithm that can converge to the desired solution even under the unknown participation statistics. Numerical experiments validate the theoretical findings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. It shows that, with unknown participation statistics, FedAvg with non-optimal weight will diverge from the optimal solution of the original FL objective.\n\n2. It proposes an interesting online Algorithm 2 to estimate the unknown participation weight.\n\n3. It proposes FedAU algorithm that can converge to the desired solution even with unknown participation weight."
            },
            "weaknesses": {
                "value": "The linear speedup term in Eq.(8) seems unreasonable. According to the FedAvg result in reference [R1] (see Table 2), when only a subset of clients (say S clients) participate in the FedAvg, the linear speedup term should be O(1/sqrt{S*I*T}), not O(1/sqrt{N*I*T}).  I believe O(1/sqrt{S*I*T}) makes more sense since only S clients sample data and participate in algorithm update per iteration.\n\n[R1] Karimireddy et.al., SCAFFOLD: Stochastic Controlled Averaging for Federated Learning, ICML 2020."
            },
            "questions": {
                "value": "1. Please clarify why does your linear speedup term is O(1/sqrt{N*I*T}) not O(1/sqrt{S*I*T}) as shown in reference [R1] with partial client sampling. I think O(1/sqrt{S*I*T}) makes more sense since only a subset of S participates in data sampling and model update per iteration.\n\n2. Why do you need both bounded variance assumption in (4) and bounded global gradient assumption in Theorem 2? The bounded gradient assumption is typically very restrictive and are not used in literature such as in [R1]. Can the bounded global gradient assumption be removed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Reviewer_p8tC"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699460936910,
        "cdate": 1699460936910,
        "tmdate": 1700583407517,
        "mdate": 1700583407517,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qmvl5S5HIv",
        "forum": "ZKEuFKfCKA",
        "replyto": "ZKEuFKfCKA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_dwXt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4628/Reviewer_dwXt"
        ],
        "content": {
            "summary": {
                "value": "The article tackles the problem of Federated Learning under heterogeneous client participation. The authors propose a correction of FedAvg algorithm which handles heterogeneous participation through estimation of optimal aggregation weights based on client participation history, in a new algorithm called FedAU. Theoretical results are derived, which highlight sub-optimality of classical FedAvg algorithm in this setting, as well as convergence analysis of FedAU. Numerical experiments illustrate the theoretical findings.\n\nI have read the authors response, which thoroughly answered my questions. In this regard, I think the paper is very strong and updated my score accordingmy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper tackles an important practical limitation on existing FL algorithms, which often depend on a known, homogeneous client's participation rate. \n- The proposed algorithm is original as it tackles client participation heterogeneity using novel methodologies quite different from existing litterature mostly based on variance reduction techniques. In addition, the proposed algorithm enjoys favourable computational complexity compared to existing works.\n- The proof techniques are also original and could be reused in other settings\n- The paper is very clear and well-written, the problematic, related work and contributions are clearly highlighted, and scientific methodology is easy to follow. In particular, the authors made the effort of stating intuitive results and presenting formal theorems in a user-friendly manner."
            },
            "weaknesses": {
                "value": "- The authors mention that the proof techniques, but I didn't find any sketch of the proof in the main text, which is a shame because it could help readers understand the novelty, and maybe reuse proof techniques.\n- The numerical experiments are a bit disappointing in the sense that they do not really highlight how much of the theoretical results are observed in practice, but only that FedAU improves over FedAvg on the proposed use cases. It would have been interesting to see experiments highlighting convergence error for varying values of K or ground truth average participation rates (even on simple simulations)"
            },
            "questions": {
                "value": "- In practice, what is the order of magnitude of the lowest participation rate that can be estimated? \n- Related question, did you perform any experiments to understand at what point the weights might explode (in the case where K is very large) ?\n- It is also likely that clients participation rate pn actually vary over time, while remaining independent across t. Do you think your theoretical results could easily be adapted to such cases ?\n- Concerning the theoretical results, using your proof techniques, do you recover existing results in the particular case where pn are homogeneous/known ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "10: strong accept, should be highlighted at the conference"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4628/Reviewer_dwXt"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699546189925,
        "cdate": 1699546189925,
        "tmdate": 1700730087538,
        "mdate": 1700730087538,
        "license": "CC BY 4.0",
        "version": 2
    }
]