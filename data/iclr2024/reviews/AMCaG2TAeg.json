[
    {
        "id": "5Gai7iBPRt",
        "forum": "AMCaG2TAeg",
        "replyto": "AMCaG2TAeg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_LtoA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_LtoA"
        ],
        "content": {
            "summary": {
                "value": "This paper emphasizes the importance of allowing learning agents to generalize to various situations, rather than being constrained by limited demonstrations. In real-world scenarios, the combinatorial complexity necessitates a significant amount of data to prevent neural network policies from relying on non-causal factors. Therefore, the authors propose CAIAC, a data augmentation method that generates synthetic samples from a fixed dataset without requiring new interactions with the environment. This method is inspired by the idea that an agent can only change its environment through actions. Hence, parts of the state space that are unaffected by actions are swapped from different trajectories in the dataset. The paper utilizes Causal Action Influence\" (CAI) to identify action-independent entities and then swap states of these entities from other observations in the dataset. The introduction highlights the potential of teaching robots using demonstrations and datasets, which is a promising approach for developing competent robotic assistants."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of using local independence to do counterfactual data augmentation is neat and interesting. As there could exist many spurious correlations during the offline data collection process, counterfactual data augmentation is important for breaking the spurious correlation.\n\n2. The paper is well-written and easy to follow. The formulation of the problem and the proposed method is clear."
            },
            "weaknesses": {
                "value": "1. If I understand correctly, a strong underlying assumption of the proposed method is that the swapped states are irrelevant to the goal state. In the experiment part, the authors mention that \u201cwe initialize all non-target entities (with p = 0.5) to a random state\u201d, which is why I think there exists such an assumption. This assumption is required since local independence does not imply the dependency between the current state and the goal state. This assumption is fine if the task is simple and the horizon is short. However, if the task is long-horizon and the later sub-tasks require some pre-conditioned to be satisfied, the local independence may not always be true. \n\n2. Another assumption of the method is the fixed factorization of the state space, which may not be available in most real-world tasks. Determining which variable to be abstract from raw sensors may limit the usage of this method. \n\n3. Missing related literature on causal reinforcement learning [1-11].\n\n4. Using counterfactual data augmentation to improve RL algorithms has been investigated a lot in previous work. CoDA is an important work but cannot cover all existing baselines. The authors may need to add more baselines to show fair comparison, for example [1, 2, 4, 7, 9].\n\n\n---\n[1] Pitis, S., Creager, E., Mandlekar, A., & Garg, A. (2022). Mocoda: Model-based counterfactual data augmentation. NeurIPS 2022\n\n[2] Lu, C., Huang, B., Wang, K., Hern\u00e1ndez-Lobato, J. M., Zhang, K., & Sch\u00f6lkopf, B. (2020). Sample-efficient reinforcement learning via counterfactual-based data augmentation. arXiv preprint arXiv:2012.09092.\n\n[3] Ding, W., Lin, H., Li, B., & Zhao, D. (2022). Generalizing goal-conditioned reinforcement learning with variational causal reasoning. NeurIPS 2022\n\n[4] Ding, W., Shi, L., Chi, Y., & Zhao, D. (2023). Seeing is not believing: Robust reinforcement learning against spurious correlation. NeurIPS 2023\n\n[5] Wang, Z., Xiao, X., Xu, Z., Zhu, Y., & Stone, P. (2022). Causal dynamics learning for task-independent state abstraction. ICML 2022\n\n[6] Ke, N. R., Didolkar, A., Mittal, S., Goyal, A., Lajoie, G., Bauer, S., ... & Pal, C. (2021). Systematic evaluation of causal discovery in visual model-based reinforcement learning. arXiv preprint arXiv:2107.00848.\n\n[7] Lyle, C., Zhang, A., Jiang, M., Pineau, J., & Gal, Y. (2021). Resolving causal confusion in reinforcement learning via robust exploration. In Self-Supervision for Reinforcement Learning Workshop-ICLR (Vol. 2021).\n\n[8] Zhang, A., Lyle, C., Sodhani, S., Filos, A., Kwiatkowska, M., Pineau, J., ... & Precup, D. (2020, November). Invariant causal prediction for block MDPs. ICML 2020\n\n[9] Zhang, A., McAllister, R., Calandra, R., Gal, Y., & Levine, S. (2020). Learning invariant representations for reinforcement learning without reconstruction. ICLR 2021\n\n[10] Gasse, M., Grasset, D., Gaudron, G., & Oudeyer, P. Y. (2021). Causal reinforcement learning using observational and interventional data. arXiv preprint arXiv:2106.14421.\n\n[11] Buesing, L., Weber, T., Zwols, Y., Racaniere, S., Guez, A., Lespiau, J. B., & Heess, N. (2018). Woulda, coulda, shoulda: Counterfactually-guided policy search. ICLR 2019"
            },
            "questions": {
                "value": "1. The analysis of the failure cases in Table 1 is missing. The proposed method does not have an improvement in the last three tasks (i.e., Slide cabinet, Light switch, Hinge cabinet). I also observe such a performance drop in Figure 5. According to the design of the spurious correlation, I expect that the proposed method should generally work for all tasks. Could the authors explain the reasons for the failure?\n\n2. In Section 5.2, the authors explore a goal-conditioned task. One question about the results is the statement \u201cAll methods perform similarly, given that there is enough coverage of the state space in the original dataset.\u201d. It looks like the proposed method is the worst among all four methods. I don\u2019t think the gap between CAIAC and No Aug. is caused by randomness. Usually, using data augmentation will not harm the performance. Could the authors provide some explanations? Is this related to the first point of the weakness part of my review?\n\n3. Still in Section 5.2, the statement \u201cthe transformer model is able to discover the causal graph and creates realistic counterfactuals\u201d is not supported by any evidence. \n\n4. Could the authors provide a detailed comparison between CAIAC and CoDA? I think these two methods have very similar ideas but with different implementations. CoDA may suffer the problem of data scarcity for training a good transformer, but generally, what is the main advantage of using CAI to identify local independence?\n\n5. \u201cFor Fetch-Push we set \u03b8 = 0.1, and \u03b8 = 0.3 for Franka-Kitchen.\u201d How do you select the parameter \u03b8?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698619158506,
        "cdate": 1698619158506,
        "tmdate": 1699636888076,
        "mdate": 1699636888076,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "16RxdgW3aL",
        "forum": "AMCaG2TAeg",
        "replyto": "AMCaG2TAeg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes CAIAC, a novel counterfactual data augmentation technique that generates additional data by swapping causally \u201caction-unaffected\u201d state dimensions of different transitions. CAIAC identifies action unaffected state dimensions using a Causal Action Influence (CAI) metric. Empirically, CAIAC outperforms other counterfactual data augmentation techniques (CoDA and CoDA-ACTION, sort of interpolation between CAIAC and CoDA) on offline Franka Kitchen tasks and a two-block FetchPush task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The topic of counterfactual data augmentation is of general interest to the RL community, as many real-world tasks have local causal structures (as noted in the paper).\n2. The paper is well-motivated, and I found the description of local causal models easy to follow."
            },
            "weaknesses": {
                "value": "1. There seems to be a fine distinction between CAIAC, CoDA, and CoDA-ACTION that that isn\u2019t quite clear to me. My understanding is as follows:\n* CoDA uses a learn local causal model (or a hard-coded heuristic) to identify locally independent state dimensions and then generates augmented transitions by swapping the locally independent state dimensions of observed transitions. The resulting augmented transitions.\n* CAIAC is identical to CoDA but uses a CAI metric to identify locally independent state dimensions.\n* I could not understand the difference between CoDA and CoDA-ACTION.\n\n\n  I hope the authors can clear up my confusion on this matter. If my current understanding of CAIAC vs CoDA is correct, then algorithmic contribution of this work is limited. In any case, a figure that clearly illustrates the difference between CoDA, CODA-ACTION, and CAIAC would be immensely helpful towards understanding (1) the CAIAC algorithm and (2) the novelty of this work. It would also be helpful if the authors evaluated these algorithms on a simple, didactic toy task like the SpriteWorld task used CoDA.\n    \n2. Empirical results seem weak. In Table 1, CAIAC outperforms baselines with obvious significance in 3/6 tasks (Kettle, Microwave, Bottom-burner), and struggles in the remaining 3 tasks (Slide Cabinet, Light Switch, Hinge Cabinet). Since the algorithmic contribution seems limited, I would like to see CAIAC evaluated on additional tasks -- tasks that show some learning progress with CAIAC and in an online learning setting. Some possible tasks: FetchSlide, FetchPickAndPlace, FetchStack, or the analogous PandaGym tasks. \n\n3. The paper states that CoDA and CODA-ACTION are (1) unable to recover the correct causal graph and (2) create dynamically infeasible data which harms performance, but there is no empirical evidence to support this claim. Given a dataset of augmented transitions {(s, a, r, s')}, the authors might consider validating claim (2) by initializing simulation to s, taking action a, and then checking if s' equals the simulators true next state. Then we could compute the probability that each algorithm generates feasible data and see if CoDA and CoDA-ACTION are more likely to generate such data than CAIAC. Claim (1) would then follow immediately -- if an algorithm generates a relatively large amount of infeasible data, then it surely has the wrong causal model. \n\n1. It\u2019s not immediately clear what CAIAC is doing from Figure 1. I suggest explicitly stating in caption or the figure itself what is being swapped and what augmented data is generated.\n\nOther comments:\n\n1. I found Figure 6 to be quite helpful in understanding the CAI scores. If possible, this figure would be a nice addition to the main paper.\n\n2. When describing the local causal structure in the chosen benchmark tasks, it may be beneficial to concretely describe the structure. In particular, the agent's actions only affect an object if the agent is in contact with the object.\n\n3. The authors may find the following references particularly relevant to this work:\n* MoCoDA [1] is an extension of CoDA that enables a user to control the distribution of augmented data.\n* GuDA [2] is a framework for generating expert-quality augmented data.\n\n[1] MoCoDA: Model-based Counterfactual Data Augmentation. Pitis et. al, NeurIPS 2022.\n\n[2] Corrado & Hanna. Guided Data Augmentation for Offline Reinforcement Learning and Imitation Learning. arXiv:2310.18247"
            },
            "questions": {
                "value": "1. In the weaknesses section, I suggested additional online RL experiments. CAIAC, like CoDA, can be used in online learning too, correct?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7407/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX",
                    "ICLR.cc/2024/Conference/Submission7407/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698774106028,
        "cdate": 1698774106028,
        "tmdate": 1699642739407,
        "mdate": 1699642739407,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GuR0lwFin8",
        "forum": "AMCaG2TAeg",
        "replyto": "AMCaG2TAeg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_GhVi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7407/Reviewer_GhVi"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method called Causal Influence Aware Counterfactual Data Augmentation (CAIAC) that addresses the challenge of generalizing robot behaviours to new situations using pre-recorded data and human-collected demonstrations. By swapping causally action-unaffected parts of the state-space from different observed trajectories in the dataset, CAIAC creates feasible synthetic samples without the need for new environment interactions. The experimental results demonstrate the generalization capabilities and sample efficiency of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper proposes a data augmentation method called Causal Influence Aware Counterfactual Data Augmentation (CAIAC) that can create feasible synthetic samples from a fixed dataset without the need for new environmental interactions.\n\n- The paper is well-written and easy to follow.\n\n- The experiments on offline self-supervised skill learning and offline reinforcement learning showcase the effectiveness of the proposed method as some extent.\n\n- The proposed approach is independent and can be used with any learning algorithm."
            },
            "weaknesses": {
                "value": "- The novelty is limited, drawing heavily on the groundwork laid by Seitzer et al., 2021, for local causal graph estimation and CAI's influence measurement. The conceptual leap from the work of CoDA (Pitis et al., 2020), which also involves counterfactual generation through connected component swapping, to the present technique of swapping uncontrollable subgraphs, seems incremental rather than revolutionary.\n\n- While the paper successfully argues the challenges and pitfalls of complete causal structure estimation, it only partially addresses the performance of CAIAC in high-dimensional, low data regime environments, leaving a gap in the analysis. A more exhaustive exploration of the method's computational demands and scalability would greatly enhance the reader's understanding.\n\n- The experimental comparisons seem to lack a critical control condition \u2014 an alternative method that also augments counterfactual data through local causal structure estimation with CAI but swap the connected components to form new transitions given two transitions that share local causal structures. Including such a benchmark would provide a clearer picture of CAIAC's relative efficacy."
            },
            "questions": {
                "value": "- Could the authors provide more insight into CAIAC's performance in environments with abundant data? The discrepancy in performance between low and high data regimes in high-dimensional settings warrants further clarification.\n\n- Moreover, could the authors elaborate on the computational complexity and scalability of the CAIAC method, especially in comparison to existing methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699485484626,
        "cdate": 1699485484626,
        "tmdate": 1699636887758,
        "mdate": 1699636887758,
        "license": "CC BY 4.0",
        "version": 2
    }
]