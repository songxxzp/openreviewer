[
    {
        "id": "1603RYvbCi",
        "forum": "r125wFo0L3",
        "replyto": "r125wFo0L3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_ixB2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_ixB2"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an architecture for trajectory prediction using a generic causal transformer, and validates the scaling law on large datasets (WODM, NuPlan), achieving good performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Sufficient originality and significance. The story captures the existing popular trends, targeting the task of autonomous driving trajectory prediction. It adopts a generic and easily scalable architecture, and validates the scaling law on large datasets, offering a certain reference value.\n2. The article is overall well-written, flowing smoothly, and easy to understand.\n3. Achieved commendable results on large public datasets."
            },
            "weaknesses": {
                "value": "1. The story is well told, but the experimental support is weak, some of key ablations are missing: \n* There is a lack of ablation studies for the model design, such as quantifying the improvement brought about by the proposed keypoints module, or comparing the GMM decoder versus the diffusion decoder. \n* For the planning module, there is a lack of closed-loop evaluation, which is crucial for the planning component."
            },
            "questions": {
                "value": "1. Why haven't the closed-loop results on NuPlan been included? Since you've already integrated the open-loop evaluation with NuPlan, conducting a closed-loop test should be quite straightforward. Is it because the results were not satisfactory?\n2. In Table 2, STR(CPS)-16m (Ours) performs better than MTR-e2e in terms of the MAP metric; however, it lags behind in minADE, minFDE, and MR. Could you elaborate on the reasons behind these differences?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5908/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5908/Reviewer_ixB2",
                    "ICLR.cc/2024/Conference/Submission5908/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5908/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698090908842,
        "cdate": 1698090908842,
        "tmdate": 1700432265923,
        "mdate": 1700432265923,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "q6S4pbqG21",
        "forum": "r125wFo0L3",
        "replyto": "r125wFo0L3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_Cy2V"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_Cy2V"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes State Transformer (STR) that leverage the transformer model to conduct the motion prediction and motion planning simultaneously, by predicting both the future key points and states.  Extensive experiments show that STR outperforms the baseline methods on NuPlan motion planning dataset significantly."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed STR is able to conduct motion planning and prediction simultaneously, thereby being able to capture the complexed semantic information.\n2. The proposed STR leverages the temporal information by formulating the motion tasks and sequential prediction problems, which helps to improve the performance."
            },
            "weaknesses": {
                "value": "1. The method description is not well organized and some details are missing, e.g., the proposal, key points and $O_t$ in Fig. 1. Besides, the introduction of the conditional diffusion (Sec 3.2) has no tight logic connection with the method (Sec 4). The only place that mentioned diffusion model in Sec 4 is \"STR is compatible with diverse decoders like Gaussian Mixture Model or diffusion decoders.\" \n2. The novelty of this work. Though it is interesting to apply transformer and diffusion on motion planning/prediction tasks, it remains ambiguous as to the unique contributions or innovations introduced by this work in adapting the diffusion model to this specific domain.\nSpecifically, it is not new to adopt an encoder-decoder architecture to take the context as input, and predict the future states, which has been studied by MPNet [R1]. STR uses a different but existing neural architecture which seemingly lacks new contributions. \n\n[R1] Qureshi, Ahmed H., et al. \"Motion planning networks.\" 2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019."
            },
            "questions": {
                "value": "1. What is the data format of the context? Do you need to convert it into a set of vectors?\n2. As in Section 5.2, you have different choices of encoders for different datasets, what is the concern here? Is there any guidance on how to select the proper encoder when facing a different dataset?\n3. Similar to above questions, Sec 4 mentioned that \"STR is compatible with diverse decoders like Gaussian Mixture Model or diffusion decoders.\" Do you have any thoughts on how to select the proper decoders and what are their pros/cons?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5908/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5908/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5908/Reviewer_Cy2V"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5908/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777018989,
        "cdate": 1698777018989,
        "tmdate": 1699636627984,
        "mdate": 1699636627984,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "muBS0QTay2",
        "forum": "r125wFo0L3",
        "replyto": "r125wFo0L3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_2D3R"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_2D3R"
        ],
        "content": {
            "summary": {
                "value": "Inspired by the success of self-attention for sequence modeling in large language models, this paper attempts to demonstrate scaling laws for predicting future vehicle trajectories with self-attention-based large *trajectory* models.\n\nTo do so, the paper casts motion forecasting (trajectory prediction for non-ego actors) and motion planning (trajectory prediction for the ego vehicle) as a sequence modeling problem suitable for autoregressive transformers. The sequence tokens are divided between the context, proposal, key points, and future states. The context consists of input data such as the map elements and past actor trajectories. The proposals are only relevant for the Waymo Open Motion Dataset (WOMD) and are (I think) implemented as intention points from MTR++ [0]. The key points are spatial locations 0.5, 1, 2, 4, and 8 seconds in the future. Finally, the future states are the full set of positions over each 100ms frame of the full 8 second trajectory.\n\nThe context is generated with dataset-specific encoders. For instance, for NuPlan, a ResNet18 raster encoder is used; for WOMD, an MTR vector encoder is used. The outputs of these encoders become inputs to the autoregressive transformer.\n\nThe proposals, key points, and future states have different decoders. Proposals and future states are trained with simple cross-entropy and mean-squared error losses, while the key points are output using a pre-trained keypoint diffusion model.\n\nTheir model (State Transformer or STR) is evaluated using standard metrics on NuPlan and WOMD. On WOMD, a 16-million parameter variant of their model is outperformed by MTR [1]. On NuPlan, the top performing model is their 125M parameter model; scaling the model to 1.5B parameters does not significantly improve the model performance. The STR model outperforms all baselines on NuPlan, although there is significantly less literature evaluating on NuPlan (in contrast to WOMD).\n\nFinally, this paper attempts to demonstrate scaling laws and properties of motion forecasting. Qualitative analysis shows that larger models produce improved trajectories, even though quantitative analyses do not show as strong a trend. Additionally, qualitative analyses show improved generalization. The experiments demonstrate improved performance as measured by converged loss as a function of both dataset size and model size.\n\n\n[0] https://arxiv.org/pdf/2306.17770.pdf\n[1] https://arxiv.org/pdf/2209.13508.pdf"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper is the first attempt to scale up trajectory forecasting to models significantly larger than a few million parameters and is one of the first few demonstrations of using an autoregressive transformer for motion forecasting. Additionally, it demonstrates the usefulness of the NuPlan dataset when performing larger scale research, since the dataset is comprised of a larger set of trajectories.\n\nThe experiments do convincingly show improved performance with dataset size and model size, indicating that larger datasets and larger models are likely to improve performance significantly further."
            },
            "weaknesses": {
                "value": "The two key weaknesses of this paper which need to be addressed are complexity and clarity of writing. \n\nFirst of all, the described model is too general. Instead of describing what was actually implemented, the authors write about what *could* have been implemented. This is partially because the authors are trying to describe their work as one model on two different datasets; in reality, they have implemented two *different* albeit related models, customized towards the two datasets they work on. I would recommend reworking the description to be as clear as possible about what was implemented rather than describing the possibilities. For example:\n\n\"These Proposals can be intention points (Shi et al., 2022), goal points (Gu et al., 2021), or endpoints heat maps (Gilles et al., 2021).\"\n\nIt is not important what the proposals *could* be, what is important is what was actually implemented in this work.\n\nThe same applies to key points and future states: please state clearly what *precisely* these are when introducing the concepts, rather than leaving that detail to later sections.\n\nAs an example, \"For each Key Point, STR is compatible with diverse decoders like Gaussian Mixture Model (GMM) decoders (Chai et al., 2019), or diffusion decoders to produce K different predictions\": it does not matter what STR is compatible with, what is important is what was implemented and evaluated. If GMMs were not used, it is not relevant to include in the description.\n\nNext, the model is quite complex, and as a result, it's very hard to understand where gains and performance are coming from. While the authors attempt to reduce motion forecasting to a self-attention transformer sequence modeling problem, in practice, that's not what is happening here; for example, on WOMD, the model is an MTR encoder, followed by a flattening into a sequence, followed by a diffusion model for the keypoints but not for the future states. The parameters are split between the dataset-specific encoders, the transformer backbone, and the diffusion model.\n\nI would recommend making a few changes:\n\n1. Remove diffusion models from this paper. The diffusion models are tangential to the point the paper is aiming to make around scaling, and they add significant complexity to the work that will make it difficult to reproduce and evaluate.\n2. Consider separate the model used for NuPlan and for WOMD and describe those models separately.\n3. Describe the split of parameters between the encoders and the transformer. \n4. (General) Find ways to simplify the setup, model, and description.\n\nOverall, the paper has a very strong core experimental setup and approach, but it is hindered significantly by the complexity of the model (in contrast to the simplicity of large language models) and the complexity of the writing. If these can be simplified to isolate the core result to one about performance of a simple model scaling with data and compute, this paper can be much improved."
            },
            "questions": {
                "value": "There are a few unclear technical choices made. Causal transformers are relevant for language modeling due to a sampling step after each token. However, in this problem, there is no sampling step until the key point generation, so why is the entire transformer causal? Similarly, autoregressive modeling is crucial for language models due to the sampling step, but since there is no sampling when producing the future states, is it important to have the autoregressive setup?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5908/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820474332,
        "cdate": 1698820474332,
        "tmdate": 1699636627719,
        "mdate": 1699636627719,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tKFvSlJp73",
        "forum": "r125wFo0L3",
        "replyto": "r125wFo0L3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_6cJv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5908/Reviewer_6cJv"
        ],
        "content": {
            "summary": {
                "value": "The authors tackle the problems of motion prediction and planning for self-driving. The authors first frame these problems as identical except for the fact that planning requires conditioning on a high-level route. The authors then propose to model 8 second trajectories by autoregressively sampling locations at (8,4,2,1,0.5) seconds into the future, then using regression to upsample these key points to a full 10hz 8 second trajectory. A highlight of the paper is that the authors leverage causal transformers and demonstrate that larger variants of their model converge to a better validation loss as the dataset size is scaled, similar to large language models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Motion prediction is certainly an important problem for self-driving, and I think stating explicitly how planning and motion prediction are connected as the authors have done is important for the self-driving community. I also think understanding how these models scale with compute and data is important so that we can make better guesses about how much data needs to be collected in order to achieve a certain performance. I haven't seen these kinds of scaling plots in other motion prediction papers. Finally, I think diffusion is a promising technique for modeling trajectory distributions, and it's great to see new techniques - such as the author's approach of only modeling a coarse trajectory then regressing the rest - for making diffusion work in practice for the motion prediction task."
            },
            "weaknesses": {
                "value": "The first weakness I want to mention is that I'm missing the motivation for some of the design decisions of the model. A central claim of the paper is that they reduce motion prediction to a \"sequence modeling task\". However, for the historical trajectories and map information that the model conditions on, I don't see the motivation for encoding this information causally in time. Full attention across time should work just as well while being more parameter-efficient (for instance, as was done in wayformer), especially when some of the history is partially occluded as in motion prediction data. Additionally, since the authors use diffusion to model future keypoints, I also don't see the motivation to force the diffusion model to be autoregressive. In my mind, the diffusion model should be able to model all future points at once without generating each one-by-one. If performance was amazing with these choices, I'd understand it, but Table 2 shows that motion prediction performance is well below SOTA. If the authors want to claim that these choices improve the scalability of the model, they should compare against a model with full attention in the encoder and all-at-once diffusion in the scaling plot Figure 2.\n\nThe second weakness I see is that the way in which the model is adapted from MTR or other motion prediction models is not stated as clearly as it should be. My sense is that the method that the authors propose involves training a GPT-like model with temporally-causal mask to regress (x,y) locations at (8,4,2,1,0.5) seconds, then freezing the encoder and training the keypoint decoder with diffusion instead of regression, then keeping the encoder frozen and training an output head that upsamples the keypoints to a 10hz 8-second trajectory. The authors also reference \"classification scores\" though, so I don't think I'm getting the full picture. My sense from Appendix A.1 is that the reason for these choices is that they stabilize the training of the diffusion model. If that's the case, I think most of the motivation of the paper should emphasize that the goal is to improve stability of diffusion for motion prediction, not to turn motion prediction to a sequence prediction task which is currently stated as the main motivation.\n\nOther notes are included below:\n\n- abstract \"learn to make complex reasonings for long-term planning, extending beyond the horizon of 8 seconds\" - where do the authors show that the model generalizes beyond 8 seconds in the paper?\n- intro \"We arrange the past and future states of the target into one sequence for learning and generation\" - I feel the main novelty of the paper is in the design of the decoder. So maybe it's only important to mention that future states are encoded in a sequence.\n- 3.1 first paragraph - there's a mismatch in notation between $s^F$ and $s^T$. Additionally, it should probably be acknowledged in this paragraph that this paper approximates the multi-agent future trajectory distribution as independent, e.g. $p(s^T | c, s_{ego}, s) \\approx p(s^T_{ego} | c, s_{ego}, s) \\cdot p(s^T_0 | c, s_{ego}, s) \\cdot ... \\cdot p(s^T_N | c, s_{ego}, s)$.\n- Section 4 \"Finally, the model learns the pattern to generate all future states given the contexts and conditions with direct regression losses\". Would it make sense to represent the full trajectory as a sequence of key points? Regression can lead to out-of-distribution trajectories, even when key points at t=(0.5,1,2,4,8) seconds are used for conditioning.\n- Figure 2 - for the plot on the right, what do the circular dots and the square/triangle dots represent?\n- 5.2 \"in case the potential features from images and videos from cameras are able to be incorporated in the future\" - I don't exactly see why it's easier to incorporate camera-frame features if the input is rasterized? Some elaboration of this point would be helpful.\n- 5.2 \"decoders\" - I found this section hard to understand. What are \"stacked MLPs\"? What is the \"additional MSE loss\" in addition to? Is \"distance regression loss\" different from MSE loss? For the \"classification scores\", what is the network classifying between?\n- Appendix A.1 \"a plain MLP decoder is used when training the Transformer backbone from scratch, then the backbone is frozen and we train a diffusion-based key points decoder\" are there issues when the model is trained with diffusion from scratch? Is there a reason to make the decoder autoregressive if diffusion is being used?\n- Table 2 - Can the authors expand on why they only compare to MTR-e2e? MTR and MTR++ get mAP above 0.40 on WOMD"
            },
            "questions": {
                "value": "My main questions are included in the \"weaknesses\" section. If the authors only focused on comparing scaling laws for standard motion prediction architectures, that would be one thing. But since the authors measured scaling curves only for the new model that they proposed, it's important to understand if the proposed model has a principled design. It seems the authors main some design choices to improve the stability of diffusion, and it would be very helpful if the authors could ablate these choices more thoroughly. I also currently do not see the value in framing the approach as \"sequence modeling\" - which is a big emphasis of the paper - given that full attention and all-at-once diffusion should be more compute and parameter efficient."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5908/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698952211195,
        "cdate": 1698952211195,
        "tmdate": 1699636627611,
        "mdate": 1699636627611,
        "license": "CC BY 4.0",
        "version": 2
    }
]