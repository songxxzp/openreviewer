[
    {
        "id": "fUF6TEOv3u",
        "forum": "27YiINkhw3",
        "replyto": "27YiINkhw3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_uQYf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_uQYf"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use Finite State Machine (FSM) for LLM decoding to constrain the search space and reduce the syntax error for the tool use by LLM. The idea is very simple: It is basically to construct an FSM from the tool signature and introduce a special symbol to switch the normal text mode and the tool use mode and use the FSM to constrain the search space of LLM. As long as the text to use tools is generated in the tool use mode and we can assume that all paths in the mode are all valid, it is guaranteed that there is no syntax error. The experimental results confirm that the proposed method can make the number of syntax error generated by LLM be zero."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper shows that LLMs still require an external knowledge to constrain the search space for tool use and existing methods such as finetuning and in-context learning are not enough. It shows that the type of errors (syntax errors) can be addressed by an adoption of a simple FSM. It is shown that it is true for the settings the method was tested for."
            },
            "weaknesses": {
                "value": "1. Novelty\n\nIt is essentially about constraining the search space of a language model by a grammar. It is definitely expected that the use of a grammar can reduce syntax errors if we know that the output needs to follow the grammar. I feel that it is a known technique but not a novel finding although probably it has not been applied for LLMs yet. It does not necessarily need to be theoretical, but I would probably at least want to see deeper discussions on why LLM has limitations without such external knowledge. Does a much stronger LLM have the same problem?\n\n2. Complexity\n\nA good thing about LLMs is that the input and output are both plain text and the mechanism is very simple. This technique is against the simplicity. It says the FSM can be automatically constructed, but I am not sure if it is always the case for more complex tools. Defining FSM manually could be tedious and error-prone for complex ones. Decoding with an external FSM will add additional complexity to the system although this could be standardized by for example open tools."
            },
            "questions": {
                "value": "I would love to see the list of tools and their signatures used in the experiments. It should help to understand the complexity of the problem addressed by this paper. I would love to see the prompt used for both baselines and the proposed method. I should be able to find some of the information by looking into previous studies or the original datasets, but I think having it in the paper should be valuable. It could be in appendix."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concern."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6402/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6402/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6402/Reviewer_uQYf"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722876445,
        "cdate": 1698722876445,
        "tmdate": 1699851281767,
        "mdate": 1699851281767,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WXy1b0neiK",
        "forum": "27YiINkhw3",
        "replyto": "27YiINkhw3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_R8ud"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_R8ud"
        ],
        "content": {
            "summary": {
                "value": "It is desirable in some applications to augment instruction-tuned language models with the ability to call tools, such as calculators, in responding to user prompts. This can mitigate certain inherent limitations of the language model as well as augment it with novel capabilities. However, \"teaching\" a language model to use tools is difficult, due to the lack of suitable training data. This paper proposes an inference-only constrained decoding approach using finite-state machines (FSM). By hand-crafting a FST for each tool, it is possible to eliminate syntax errors that can occur when relying solely on in-context learning. The approach is applied \u201con top\u201d of two existing tool-augmented language models, ToolLLM and ToolkenGPT, showing improvements in the ability to correctly apply tools. In a further experiment, generalization to novel tools is evaluated, showing that the approach can successfully be adapted to new tools."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Experimental validation that enforcing prefix-checkable constraints on generation can result in more effective tool use for a relatively large set of tools.\n* The decoding approach is validated for several different LLM (ToolkenLLM, RestGPT, and ToolLLM), and appears to improve the in-context learning ability of the LLM (S4.3).\n* Approach maintains levels of accuracy even with increasing numbers of unseen tools in the test set (Figure 5)."
            },
            "weaknesses": {
                "value": "* Unclear why general machinery of FSM is necessary when the approach amounts to constrained decoding using prefix-checkable constraints on next token generation. The paper states \u201cNote that in practice, it\u2019s not necessary to explicitly construct this FSM. Any grammar checker that tells the set of valid next tokens suffice.\u201d Perhaps there could be better motivation for using FSM?\n* In some ways, the approach seems like a step backwards to expert-based AI, in that the improvements from the proposed approach appear largely to be the result of hand-crafting decoding constraints.\n* Related to the above concern, it\u2019s unclear how the proposed approach was validated. Was the hand-crafted decoding approach tailored to perform on test data?"
            },
            "questions": {
                "value": "* Table 4 contains timing results in seconds. Were all methods equally optimized?\n* The \"fine-tuning\" terminology is confusing since the approach consists of hand-crafted decoding constraints; there's no parameter fine-tuning involved in ToolDec as I understand. So does this refer to the LLM + ToolDec only being evaluated on unseen tools?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773496612,
        "cdate": 1698773496612,
        "tmdate": 1699636710966,
        "mdate": 1699636710966,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "x2jWzW8eLW",
        "forum": "27YiINkhw3",
        "replyto": "27YiINkhw3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_ydwb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_ydwb"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a decoding method for LLMs to use external tools while avoiding syntax errors. The core idea is to constrain the models in only able to decode from a selected set of valid tokens that conform with the tool signatures. The method is compatible with existing LLM tool-use schemes (in-context learning and finetuning), and empirically removes syntax errors and thus achieving improved performances."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The FSM guided decoding method is intuitive and suitable for solving the syntax errors.\n- The proposed method is compatible with existing LLM tool-use schemes, i.e., both finetuning or in-context learning.\n- The method has shown to be empirically effective in eliminating syntax error, and leads to performance improvements."
            },
            "weaknesses": {
                "value": "- The FSM construction may require careful curation. For example, how does one decide what's the best naming for a tool? Are LLMs robust to the name changes? Also, what would the process be like for one to construct the FSMs for a large collection of tools? Would it be done through parsing the tool documentations? It'd be helpful if the authors provide more discussion here.\n- It is not clear to me as to how ToolDec can enable generalization to new tools? While adding new FSM (for the new tool) can ensure the LLM uses the new tool in a syntactically correct way, the FSM itself does not provide sufficient information on when the tool should be invoked. Current generalization then seems to only depend on LLM's language prior, and thus related to above, it's tool use performance can largely depend on the proper naming of the tools.\n- Following from above, it'd be interesting to see an experiment testing the robustness of ToolDec by assigning tool names that not are not semantically meaningful."
            },
            "questions": {
                "value": "- Why would ToolDec be faster at inference compared to ToolkenGPT? Could the authors provide more explanation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698788201361,
        "cdate": 1698788201361,
        "tmdate": 1699636710620,
        "mdate": 1699636710620,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vGMdDo1lcz",
        "forum": "27YiINkhw3",
        "replyto": "27YiINkhw3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_7DQS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6402/Reviewer_7DQS"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces TOOLDEC, a novel approach for improving the performance of large language models (LLMs) when using external tools. The method tries to avoid generating syntactically invalid tool calls in these approaches. TOOLDEC is a finite-state machine-guided decoding algorithm, which designs to work with any tool-augmented LLM and ensures the generation of valid tool names and type-conforming arguments. Notably, TOOLDEC empowers LLMs to select tools solely based on their names, eliminating the need for fine-tuning or in-context documentation."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths:\nThis paper proposes the finite-state machine-guided decoding algorithm, which reduces the errors during calling tools. It is a clear and simple method to restrict the decoding space.\nThe experimental results show that the method is effective in the tool learning task, which significantly reduces name errors."
            },
            "weaknesses": {
                "value": "Weaknesses:\nEven though the model achieves significant improvements, it is unclear the language and tool mechanism switching. I think the switching effectiveness should be evaluated and whether the <T> token can be appropriately decoded.\nThe augment errors are zero. However, this reason may lie in that the existing tool learning benchmark is a little easy. If the input is a more complex problem and contains several numbers, the argument can also be wrong. The zero error rate should be carefully claimed."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6402/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698840727707,
        "cdate": 1698840727707,
        "tmdate": 1699636710386,
        "mdate": 1699636710386,
        "license": "CC BY 4.0",
        "version": 2
    }
]