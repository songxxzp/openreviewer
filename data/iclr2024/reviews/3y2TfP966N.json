[
    {
        "id": "F1IjqZ1rlk",
        "forum": "3y2TfP966N",
        "replyto": "3y2TfP966N",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a time embedding method in representation learning on unlabeled time series data. Following existing contrastive learning framework, it proposes two new regressive tasks to induce the learned time embeddings to play a good role in the final representation. Experiments on three different task categories  are performed to support the effectiveness of the proposed designs. An analysis on the robustness to missing data is also provided."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The presentation of the paper is smooth and easy to follow. The limitation of the existing methods and the novel part in the proposed method is quite clear.\n2. Comprehensive experiment results are provided to show the versatility of the learned representations."
            },
            "weaknesses": {
                "value": "1. The biggest flaw of the paper is the lack of ablation study, in my opinion. While sufficient quantitative results are provided to showcase the advantage of the proposed T-Rep, there is no clear evidence that support the effectiveness of the time embedding module, the very core highlighted in the paper. While the evidence in the analysis of robustness to missing data claims that the use of time embedding is leveraged to improve the contextual awareness and to fill the gap of the missing interval, but it is not supported by any rigorous analyses and remains a conjecture. \nExtensive ablation studies should be provided to compare the T-Rep with the baseline of TS2Vec and versions with either of the regressive pretext task removed. \n2. Above the flaw in empirical study, the idea of using time embedding to improve contrastive learning is not well-motivated. It is not clear why time embedding would be the ideal way to improve the latent temporal structure. See details in questions."
            },
            "questions": {
                "value": "1. While the authors claim that time embedding $\\tau$ are induced to learn such time-related features as trend, periodicity etc. , they are function of the time indices and are unaware of the time series values. How could the aforementioned features be captured from indices only?\n2. I understand that $\\tau$ is normalized so that their difference can be measured by JSD. But there are alternative ways to measure the divergence without confining the norm of time embeddings. \n3. The task in Sec 4.2.1 aims to regress difference in the representation to the time distance. As stated in point 1, again, various pattern difference might be contained in the representations from arbitrary pairs of time series, therefore it's very likely that they can not regress to the consistent time distance. Same concern applies to the other task\n4. The claim that the two proposed task complement each other needs to be elaborated."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795679982,
        "cdate": 1698795679982,
        "tmdate": 1700686648456,
        "mdate": 1700686648456,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kfFZ8qbmDd",
        "forum": "3y2TfP966N",
        "replyto": "3y2TfP966N",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a sef-supervised representation learning method with a temporal, timestep granularity. The model is a linear projection layer and time embedding module that is fed into a dilated convolutional encoder. This representation is then used by four pretext tasks, two of which (time-embedding divergence prediction and time-embedding conditioned forecasting) are introduced in this paper. A linear combination of the pretext task losses is then used to compute a hierarchical loss. The paper evaluates the approach on different downstream tasks, including anomaly detection, forecasting, and classification. Additionally, the model authors show that the model is robust to missing data and qualitatively visualize the time evolution of the representation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "### Originality\nIntroducing the temporal structure into time series representations are an important problem. This paper attempts to capture the time evolution with two additional pretext tasks and a time embedding module. These components are well reasoned and appear to result into a representation that can be successfully leveraged in tasks that require timestep granularity (forecasting, anomaly detection) and tasks that might not necessarily need it (classification).  \n\n### Quality\nThe discussion of the related work covers related articles well and summarizes the gap in learning temporal resolution in representation learning for time series. The experimental section covers standard benchmarks for anomaly detection, forecasting, and classification. I think the experimental evaluation has some weaknesses, which I will elaborate in the Weaknesses section. \n\n### Clarity\nThe paper is well written. The introduction and related work clearly introduces the challenges and previous work in this space and points out the specific challenge that the paper aims to address (learning timestep granular representations that work for several downstream tasks). The experimental section is also well written and easy to follow. \n\n### Significance\nTime series representation learning is an important problem. Previous work focused on classification or other tasks that don't require timestep granularity of the embeddings, while some applications (like forecasting) would require this. This paper represents a significant step into this direction of universal time series embeddings that are useful for several different applications."
            },
            "weaknesses": {
                "value": "The paper has two weaknesses in the experimental evaluation: Missing ablation experiments and choice of baselines. \n\n### Ablation study \n\nThe method presented in this work shares several components with TS2Vec (linear projection layer, dilated convolution encoder, instance-wise/temporal contrasting, and the hierarchical loss). It would be beneficial for the readers to point out the common components of T-Rep and TS2Vec. It would also be interesting for the reader to understand, which of the additional components introduced in this work actually improved the performance, but an ablation study to investigate this is missing. My understanding is that the additional pretext tasks require the time embedding (TE) module, so factoring that out for ablation is probably difficult. However, testing the impact of the pretext tasks setting the weights of the linear combination loss for the TE-conditioned forecasting and/or TE-divergence prediction should be straightforward. I would kindly ask the authors to add these ablation results. I would consider raising my score if the ablation study is added. \n\n\n### Choice of baselines \n\nFor the forecasting experiments, the authors use the benchmark introduced by Zhou et al., AAAI 2021 is a common benchmark in forecasting. However, several iterations on transformer architectures have been published since this work, some of which are even outperformed by linear baselines (Zeng et al., AAAI 2022). Given that the forecasting task introduced here is a linear regression layer using the time series embeddings, it would be good to understand the gain in performance relative to the linear methods (N-Linear and D-Linear) that are introduced in Zeng et al., AAAI 2022. I would kindly ask the authors to consider these baselines. \n\nFor classification, Minirocket (Dempster at al., KDD 2021) is a simple and fast baseline for practical applications and it would be interesting to understand the gain in accuracy from T-Rep over Minirocket."
            },
            "questions": {
                "value": "Appendix A.2 mentions that each models are run 10 times but also notes \"Also, we do not use any random seed, (...)\". I'm unsure what this means. Are all experiments started from the same seed or are ten (fixed) seeds used here? I would kindly ask the authors to clarify that."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698930382191,
        "cdate": 1698930382191,
        "tmdate": 1700671449752,
        "mdate": 1700671449752,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BbypRcymac",
        "forum": "3y2TfP966N",
        "replyto": "3y2TfP966N",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes T-Rep, a self-supervised method for learning time series representations at the timestep level. The key innovation of T-Rep is the use of learnable time embeddings in pretext tasks to learn detailed temporal dependencies and robustness in time series representations. Experiments demonstrate improved performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes T-Rep, a self-supervised method for learning representations of time series at the timestep level.\n\nT-Rep learns vector embeddings of time called \"time-embeddings\" alongside its feature extractor encoder. The time-embeddings help capture temporal features like trend, periodicity, distribution shifts.\n\nThe time-embeddings are incorporated into pretext tasks to learn fine-grained temporal dependencies and make the model robust to missing data. Two new pretext tasks are proposed: time-embedding divergence prediction and time-embedding-conditioned forecasting.\n\nT-Rep is evaluated on downstream tasks of classification, forecasting, and anomaly detection. It outperforms previous self-supervised methods like TS2Vec, showing the benefit of time-embeddings.\n\nT-Rep is more robust to missing data than methods like TS2Vec. Visualizations show T-Rep can produce smooth representations even with missing timesteps."
            },
            "weaknesses": {
                "value": "The choice of time-embedding architecture is not well motivated or analyzed. Different architectures are used for different tasks, but it is unclear why they perform best in each case. More ablation studies on the time-embedding design could strengthen this key component.\n\nThe pretext tasks using time-embeddings seem somewhat ad-hoc. While they demonstrate the utility of time-embeddings, developing more principled pretext tasks derived from intrinsic properties of time series could be beneficial.\n\nThe comparison to previous methods like TS2Vec is not entirely fair, as T-Rep uses a larger encoder architecture. Comparisons with a TS2Vec model of comparable complexity could better isolate the benefits of the time-embeddings. Besides, the composition on TimeNet and PatchTST on SOTA ETT dataset is necessary.\n\nThe treatment of missing data is a major claimed contribution, but the missing data experiments are limited. More systematic tests on real-world messy data with different missing data types could better showcase these abilities.\n\nThe interpretability of representations is claimed but only briefly demonstrated with some visualizations. More analysis connecting latent dimensions to meaningful time series properties could better support the interpretability claims.\n\nThe classification task does not standalone evaluate the quality of the learned representations. Adding unsupervised evaluations like clustering could help assess representation quality."
            },
            "questions": {
                "value": "See the weekness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698977685791,
        "cdate": 1698977685791,
        "tmdate": 1699636593619,
        "mdate": 1699636593619,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Nbe84tnJEQ",
        "forum": "3y2TfP966N",
        "replyto": "3y2TfP966N",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_rWLt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_rWLt"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a time series representation learning methodology based on self-supervision. The paper identifies two key issues with current time-series embedding using contrastive learning which -- a) aims to embed entire trajectories based on a binary notion of similarity vs. dissimilarity, ignoring temporal structure, and b) incompatibility with systems which switch between states, where notions of similarity vs. dissimilarity are based on states. They propose two pretext tasks to address these issues. \n\n\nOverall, I think the paper is very well written and motivated, except a few things that can really improve the quality. I hope authors can address these in the discussion."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is very well motivated, I congratulate the authors on explaining the issues with contrastive learning in the context of time-series. \n2. The paper is overall well-written and easy to follow. \n3. Experiments are set-up well except that monte-carlo simulations are missing."
            },
            "weaknesses": {
                "value": "1. The results are not repeated across random seeds, which significantly impacts the confidence in the method. \n2. Visualizations: since the paper centers around time series representation learning, it would have been extremely valuable to see t-SNE plots of the learned embeddings to see how T-Rep performs over SOTA (TS2VEC) and others. \n3. There are a number of moving parts, and some level of ablations are expected, but missing. For instance, impact of overlap in contexual consistency etc."
            },
            "questions": {
                "value": "1. How may dataset are used for anomaly detection (sec 5.1)?\n2. How does the issues of similarity/dissimilarity play out in multivariate settings? What if the switching behaviour is only present in a few of the channels?\n3. Why does T-Rep perform better in some cases and not it others? For instance, in Table 5 in ETTh_2 T-Rep performs better at larger horizons, while being significantly worse at lower ones. This is counter-intuitive, since in section 4.2.2. the paper mentions that the pretext forecasting task specifically aims to predict shorter horizons.\n4. It seems that the methods requires supervision in pretest task 4.2.1 and not in 4.2.2 for the pretext task, can the authors comment on potential use of T-Rep in completely unsupervised pretraining?\n5. How much overlap do we need for contextual consistency? How is this parameter decided? \n6. In section 3, the terms such as contextual consistency and heirarchical loss are only defined intuitively. These need to be defined in terms of their mathematical formulation(s). Currently, these are difficult to understand. Furthermore, it is also unclear how this plays out mathematically in linear projection layer. \n7. What is the mathematical action of TCN layer, and what is its role?\n\n\nMinor: \n1. Fig. 1 uses yellow against a whote background is difficult to read."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699142102810,
        "cdate": 1699142102810,
        "tmdate": 1699636593526,
        "mdate": 1699636593526,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TV2DeFfwA2",
        "forum": "3y2TfP966N",
        "replyto": "3y2TfP966N",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_99iS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5683/Reviewer_99iS"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a self-supervised way of learning latent representations of variable length time series data that are useful for various downstream tasks like time series anomaly detection, forecasting and classification. The authors propose two surrogate loss functions in form of 'pretext tasks' that influence the learned representation/embedding to persist temporal consistency in latent space along with information to forecast, and thus be robust to missing data. The results are demonstrated on three downstream tasks where T-Rep outperforms the SOTA time series representation learning methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Below are the strengths of this proposed work: \n1. The problem is highly relevant to the time series research community and well motivated by the authors. They also do a good job at covering the related work and highlighting the necessity of temporal robustness in the representations that's usually overlooked when learning time series representation. \n2. The authors introduce surrogate loss functions to train the representation model in a self supervised manner which they refer to as 'pretext tasks'. The two loss functions (although not novel) are practically reasonable given the need of temporal consistency and predictability in the learned representations. \n3. Authors do a good job of testing T-Rep across three key downstream tasks which helps in validating the usefulness of learned representation as task-agnostic."
            },
            "weaknesses": {
                "value": "Following are weaknesses of this work: \n1. The effectiveness of the proposed method relies on the evaluation done mainly on UCR/UEA and Yahoo Datasets which are infamous for their incorrectness, and triviality in labels. Refer: https://arxiv.org/pdf/2009.13807.pdf. This questions the effectiveness of the proposed method and how well would it work in real-world scenarios?\n2. Similar to Pt.1, I feel the downstream benchmarks are bit too trivial to test the true effectiveness/usefulness of a representation learning method. For e.g., in the task of anomaly detection, the authors propose to use a simple point-based evaluation method which is not realistic, as real world anomalies are usually segment based and need more rigorous evalution to demonstrate usefulness. Refer: https://arxiv.org/pdf/2109.05257.pdf. \n3. In Sec 5.5, I get that one can manually look at the heatmaps to infer similarities between the patterns in raw time series signal and the learned representation but I didn't fully understand the usefulness of that? Can I just look at the heatmap and use that information? if so, how? Manually matching pattern is pleasing but I don't see any usability, and hence don't see any true interpretability coming out of it."
            },
            "questions": {
                "value": "My questions can be found in Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699516726452,
        "cdate": 1699516726452,
        "tmdate": 1699636593410,
        "mdate": 1699636593410,
        "license": "CC BY 4.0",
        "version": 2
    }
]