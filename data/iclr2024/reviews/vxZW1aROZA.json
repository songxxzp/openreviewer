[
    {
        "id": "rjxjWsDUTC",
        "forum": "vxZW1aROZA",
        "replyto": "vxZW1aROZA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission436/Reviewer_UE2g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission436/Reviewer_UE2g"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an economically efficient language model agent that can interact with API. It incorporates three techniques: 1) conversationally interact with the execution environment, 2) saves cost by using a hierarchy of LLM assistant, 3) using successful demonstration as the in-context examples. Empirical results show that the proposed approach is indeed effective."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes an economically efficient system that can interact with APIs via code. The empirical results look convincing to me."
            },
            "weaknesses": {
                "value": "This paper delivers a good system and represents a reasonable engineering contribution. However, I am a bit skeptical about its novelty: while probably no one has combined all these three tweaks together before, each of them seems relatively straightforward to me. Can fellow reviewers comment on the novelty for each of the three tweaks? \n\n(sorry that I am not following the related works very closely so I do not know exactly how novel these ideas were; however, I think they are very straightforward ideas to try after gpt-4 release and does not require conceptual innovations)"
            },
            "questions": {
                "value": "- Would you mind commenting on the novelty of the proposed approach, or say, the most surprising part of this paper? Thanks!"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Reviewer_UE2g"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission436/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698624168583,
        "cdate": 1698624168583,
        "tmdate": 1700751662687,
        "mdate": 1700751662687,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gtUSlNygbZ",
        "forum": "vxZW1aROZA",
        "replyto": "vxZW1aROZA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission436/Reviewer_R6M4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission436/Reviewer_R6M4"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a framework, EcoAssistant for LLMs to generate API calls for answering user\u2019s queries that require external knowledge. The framework consists of three components: iterative refinement based on automatic feedback from executors; a priority queue of LLMs where cheaper LLMs are used first; cache previously high-quality response as demonstration for further generation. The resulting system demonstrates better performance, and it\u2019s more cost-efficient.  \n\nOverall, the design of EcoAssistant makes a lot of sense, but it lacks novelty and research depth considering many related work in this direction."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- clear presentation of the framework and results\n- significant empirical improvement"
            },
            "weaknesses": {
                "value": "- EcoAssistant relies on a set of known techniques (e.g., iterative refinement, demonstration library), the system per se is not novel from the technical perspective.\n- from the research perspective, it does not investigate (or focus on) several key problems in this system: 1) how do you reliably collect feedback from executors? are the automatic feedbacks reliable, 2) how to decide whether a generated response is good enough to be put in the demonstration library, 3) how to design the policy for back off in the general case?\n\nOverall, I think the design of EcoAssistant is not a significant contribution, and the authors do not go further beyond showing the empirical results of it. Though cost-efficiency is an appealing property, it\u2019s very unclear to me what the back-off policy looks like in general."
            },
            "questions": {
                "value": "how do you decide whether a response is a success or not?  is it based on execution error?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission436/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698899054869,
        "cdate": 1698899054869,
        "tmdate": 1699635970038,
        "mdate": 1699635970038,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KKnKsXUsd3",
        "forum": "vxZW1aROZA",
        "replyto": "vxZW1aROZA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission436/Reviewer_wYWS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission436/Reviewer_wYWS"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors present EcoAssistant, a framework for using existing LLMs to generate responses to invoke API calls in a cost effective manner and in a more autonomous manner."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Having cost-effective solutions are useful and having this paper especially optimize for the cost is a useful strategy. \n\n- The authors present an intuitive system that's easy to replicate, and have shown useful empirical results."
            },
            "weaknesses": {
                "value": "- I think this paper does suffer from lack of novelty. I think the paper does show an intelligent combination of existing techniques and models, but in my opinion it doesn't meet the threshold for a full paper. It would have been useful if the authors presented a methodology/algorithm that would help automatically optimize given a set of LLMs, or presented an empirical analysis on a much larger dataset with more complex APIs."
            },
            "questions": {
                "value": "- How does this method scale with # of APIs? For instance, the ToolLLM[1] paper had >16,000 APIs in their dataset. This would require some shortlisting using a retriever to make it compatible but I think adding that part would significantly help improve the novelty aspect of the paper.\n\n- I think more error analysis would also be needed to identify what kind of queries are problematic for which models. For instance, if we can identify if smaller LLMs can easily answer easy queries then we don't need to ever invoke the larger LLMs - are you already doing this? \n\n- Can you help me understand how do you define an exit criterion? For instance, what if the agent gets stuck in an infinite loop where the larger LLM and the smaller LLM agent keep going back and forth? \n\n\nReferences\n\n[1] Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., ... & Sun, M. (2023). Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission436/Reviewer_wYWS"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission436/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699662977905,
        "cdate": 1699662977905,
        "tmdate": 1699662977905,
        "mdate": 1699662977905,
        "license": "CC BY 4.0",
        "version": 2
    }
]