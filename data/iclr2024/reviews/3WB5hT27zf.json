[
    {
        "id": "QyZ4bJTnaN",
        "forum": "3WB5hT27zf",
        "replyto": "3WB5hT27zf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
        ],
        "content": {
            "summary": {
                "value": "The paper considers an open-set semi-supervised learning where there potentially are \u201coutliers\u201d in the unlabeled data distribution. The paper provides a novel loss function inspired by Partial optimal transport to handle OOD detection and demonstrates the effectiveness and robustness of the proposed method on multiple datasets."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. Strong empirical performance\n2. Various ablations suggest that the method is robust and has a lower computation time and other baselines.\n3. A connection to optimal transport is intuitive"
            },
            "weaknesses": {
                "value": "1. Lack of clarity in writing.  I found it hard to understand what is the main idea of the paper up until page 6. The author mentions in the abstract/ introduction that a mass score function (MSF) to measure the likelihood of unlabeled samples being outliers, yet I did not mention how this is related to OT/POT and it\u2019s not clear to me how OT is beneficial to the OSSL task. The following sentence is helpful for me to understand the idea,  \u201cwe can utilize the transport mass as a reliable OOD score, where a sample with a smaller value of mass score function tends to be an OOD sample\u201d. However, it is mentioned on page 6. It would be nice if one could provide something like this earlier in the paper and provide a clear problem setting early on.\n\n\n2. Many definitions and acronyms are used before being defined (see questions)\n\n3. The definition of distribution in equation 8) is not mathematically valid? By adding a factor of k, the sum of the probability mass is greater than 1 and therefore is not a valid probability distribution.\n\nI am willing to increase the score if these issues are addressed."
            },
            "questions": {
                "value": "1. OSR is not defined, MSR is mentioned before it is defined in section 2.2.\n2. Section 4.1, the distribution L and U are not defined.\n3. Section 4.1, \u201cthe features of these d-dimensional samples\u201d, do you mean the features or samples that has d-dimensional ?\n4. Notation in equation 7) is not clear. Does this means T1_{\\mathcal{L}} \\leq \\mathcal{L} point-wise less than or equal to ?\n5. In algoirthm3, L_x and L_u is not defined in the main text ?\n6. What is the number 50, 100, 500 for in Table 5 ?\n7. \u201cmagnituWde\u201d -> \u201cmagnitude\u201d ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1549/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP",
                    "ICLR.cc/2024/Conference/Submission1549/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698698984496,
        "cdate": 1698698984496,
        "tmdate": 1700610115285,
        "mdate": 1700610115285,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2J0WNilOsE",
        "forum": "3WB5hT27zf",
        "replyto": "3WB5hT27zf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
        ],
        "content": {
            "summary": {
                "value": "The paper tackles the open-set semi-supervised learning (OSSL) challenge, specifically aiming to frame the treatment of out-of-distribution data (OOD) as a partial optimal transport (POT) problem. It introduces a mass score function (MSF) designed to evaluate the likelihood of a sample being an outlier during training. Additionally, the paper presents an OOD loss, allowing conventional semi-supervised learning methods to be adapted for OSSL scenarios via end-to-end training. The authors compare their proposed method against MTCF, T2T, and OpenMatch, on CIFAR10, CIFAR100, and Imagenet-30, showing superior performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Semi-supervised learning is a significant area of research in machine learning, aiming to enhance performance by effectively utilizing both labeled and unlabeled data. \n\n* The OOD angle used in the paper makes it interesting to a broader audience.\n\n* Incorporating (partial) optimal transport as a framework is a novel and innovative aspect of this work."
            },
            "weaknesses": {
                "value": "* Respectfully, the novelty of the method is limited and the paper overclaims novelty.\n   *  For instance, one main contribution of this paper is the introduction of the \"novel\" MSF score. The score function essentially corresponds to what is commonly referred to as \"barycentric projection,\" a concept well-documented in both classical and contemporary optimal transport (OT) theory literature (for reference, please see sources such as [Ambrosio et al.](https://link.springer.com/book/10.1007/b137080)). In this context, it is more appropriate to state that the paper utilizes classical concepts from OT theory to address new application challenges. The sentence \u201cwe devise a new score function\u201d is more or less misleading.\n\n* The parameter $k$, which deals with the amount of redundancy, plays a crucial role in the methodology presented in the paper. Varying the value of k leads to significant variations in the outcomes of ODD detection. It would enhance the paper's quality if it delves into the process of determining this value. Specifically, the paper could explore methods for assessing the amount of data that should be classified as outliers before initiating the algorithms. \n\n* Some implementation details and important ablation studies are missing from the paper. For instance, the utilized batch size and the effect of having a small batch size (which presumably reduces the performance of the proposed method) are missing from the paper. \n\n* The rationale behind the decision to use (10) instead of the original constraint (7), i.e., enforcing all mass from $\\mathcal{L}$ to be transported to a subset of $\\mathcal{U}$, is not well presented. Couldn't the unsupervised data be missing an entire class? In that case, the missing classes in $\\mathcal{L}$ must be destroyed, i.e., not transported, and the constraints in (7) would allow that. I believe this can easily happen in minibatch training. \n\n* Some of the very relevant references are missing from the paper: \n   * Rizve, M.N., Kardan, N. and Shah, M., 2022, October. Towards realistic semi-supervised learning. In European Conference on Computer Vision (pp. 437-455). Cham: Springer Nature Switzerland.\n   * Xu, R., Liu, P., Zhang, Y., Cai, F., Wang, J., Liang, S., Ying, H. and Yin, J., 2020. Joint Partial Optimal Transport for Open Set Domain Adaptation. In IJCAI (pp. 2540-2546).\n   * Yang, Yucheng, Xiang Gu, and Jian Sun. \"Prototypical Partial Optimal Transport for Universal Domain Adaptation.\" (2023)."
            },
            "questions": {
                "value": "* For Algorithm 2, in the line of OOD score, shouldn't the formula be $Score_\\{\\mathcal{U}\\}=\\mathbf{T}^T\\mathbf{1}_n$?\n\n* The transportation cost is set to \"Cosine distance.\" The definition  \"d(x,y)=1-Cosine(x,y)\"  is only a true metric if $x,y\\in \\mathbb{S}^{d-1}$, i.e., $x$ and $y$ are unit vectors. Is your backbone returning unit vectors? Even if that is the case, and for the sake of mathematical rigor, I suggest adhering to the Euclidean distance, which is equivalent to the cosine distance when $x$ and $y$ are unit vectors and is still sensible when they are not!"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777366796,
        "cdate": 1698777366796,
        "tmdate": 1699636083325,
        "mdate": 1699636083325,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PR4Db9ZtDW",
        "forum": "3WB5hT27zf",
        "replyto": "3WB5hT27zf",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on studying the problem of Open-Set Semi-Supervised Learning (OSSL). The authors present a novel framework that transforms the OSSL problem into the Partial Optimal Transport (POT) problem. The authors aim to leverage the benefits of POT to detect the OOD samples. Empirically, POT achieves competitive performance on various benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-\tThis paper is straightforward and well-written. It is quite easy to follow.\n-\tThe paper solves Open-Set Semi-Supervised Learning (OSSL), an important ML problem in practice.\n-\tEmpirical results demonstrate that POT can achieve SOTA results on several benchmarks."
            },
            "weaknesses": {
                "value": "-\tBased on the description provided, it is possible that the article's approach could be categorized as an auxiliary OOD classifier approach, similar to methods such as MTCF, T2T, and OpenMatch. What is the difference between the proposed method and them? A more detailed discussion may be required.\n-\tThe author's explanation for why POT is more effective at detecting OOD is not adequately provided.\n-\tIn similar settings, Partial Optimal Transport (POT) has also found applications, such as in Open-set Domain Adaptation and Positive-Unlabeled Learning. The authors should consider discussing the connections and distinctions between their work [1-3] and the research presented in these articles. And what are the strengths of POT for Open-Set Semi-Supervised Learning? Are there some special designs for Open-Set Semi-Supervised Learning compared with other tasks, such as PU leanring, Open Set Domain Adaptation?\n-\tThe authors should offer an explanation for why Fixmatch algorithm yields better results compared to certain Open-Set Semi-Supervised Learning (OSSL) methods.\n-\tThere lack of many experiment details in the paper, such as the specific parameter settings for Fixmatch and the implementation specifics of the T2T algorithm.\n-\tTable 3 lacks some of the comparative algorithms present in Table 1.\n-\tThere is an inconsistency in the notation of the k in Algorithm 3.\n-\tOn page 8 in the experimental section, $L_{ood}$ --> $\\lambda_{ood}$\n-  What is \"graph\" in the last of Subsection 2.2?\n\n[1] Partial Optimal Transport with Applications on Positive-Unlabeled Learning, NeurIPS 2020.\n\n[2] Joint Partial Optimal Transport for Open Set Domain Adaptation, IJCAI 2020.\n\n[3] Prototypical Partial Optimal Transport for Universal Domain Adaptation, AAAI 2023."
            },
            "questions": {
                "value": "Please see the weakness for details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698813130006,
        "cdate": 1698813130006,
        "tmdate": 1699636083256,
        "mdate": 1699636083256,
        "license": "CC BY 4.0",
        "version": 2
    }
]