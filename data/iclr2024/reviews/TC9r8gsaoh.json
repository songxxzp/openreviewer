[
    {
        "id": "fO5tgl1BP7",
        "forum": "TC9r8gsaoh",
        "replyto": "TC9r8gsaoh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_KLj8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_KLj8"
        ],
        "content": {
            "summary": {
                "value": "The research introduces the Nuisance-Robust Transformed Outcome Regression Network (NuNet) within a standard causal inference framework, which aims to discern between factual and counterfactual potential outcomes using observational data. In empirical tests, many established methods showcased an inclination towards optimism particularly under conditions of noise heterogeneity. NuNet distinguishes itself by merging nuisance estimation and target estimation into a singular step, guided by the pessimism principle. The primary goal is to pinpoint a potential outcome function to determine the causal e\ufb00ect of a treatment action. Accuracy is gauged through the PEHE, contingent upon three foundational assumptions: the Stable Unit Treatment Value, unconfoundedness, and overlap.\n\nEmpirical tests claim that NuNet oLen surpasses or parallels baseline plug-in methods, particularly in diverse noise seMngs and real-world datasets. However, it faces challenges with techniques prioritizing joint optimization. Inspired by pessimism in o\ufb04ine reinforcement learning, this causal inference method o\ufb00ers a di\ufb00erent approach. Most conventional techniques adopt a plug-in estimation, but this may show sub-optimality if nuisance accuracy isn't accounted for. The signi\ufb01cance of addressing the gap between optimistic and pessimistic errors is emphasized, leading to adherence to the pessimism principle. The study also delves into various methods used for estimating the CATE. Notable methods include Transformed Outcome Regression, PWNet, Doubly Robust Learner (DRNet), and NuNet. These strategies aim to enhance robustness against nuisances and unobserved confounders, ultimately aiming for reliable and accurate estimations. For future exploration, the authors suggested constructing a pessimism-based theoretical structure and delving into principled learning avenues could propel the evolution of causal inference methodologies."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. Clear mention of shortcomings of the conventional statistical and end-to-end adversarial learning networks.\n2. Evaluation of robustness of the approach under conditions including heterogeneous noise, AN setting, MN setting and real-world datasets."
            },
            "weaknesses": {
                "value": "Considerable di\ufb00erence between the results of NuNet and SNet (best performing) pertaining to PEHE on the additive noise dataset."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8811/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699072854164,
        "cdate": 1699072854164,
        "tmdate": 1699637108019,
        "mdate": 1699637108019,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WVO73ovz82",
        "forum": "TC9r8gsaoh",
        "replyto": "TC9r8gsaoh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_S5uy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_S5uy"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method for estimating CATE. In contrast to previous two-stage estimators, the propensity score is simultaneously optimized with the second-stage regression. This is done in an adversarial manner to ensure robustness regarding estimation errors in the propensity score. The method is evaluated using simulated an real-world data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well written.\n- CATE estimation is an important problem, with applications in various domains.\n- The proposed method performs well empirically."
            },
            "weaknesses": {
                "value": "- I am not convinced of the advantages of the proposed method. The robustness of CATE estimation with respect to estimated nuisance functions is central to recent well-established works on CATE estimation that make use of semiparametric estimation theory, e.g., by Chernozhukov et al. (2018), Foster and Syrgkanis (2019), Nie and Wager (2021), Kennedy (2023). One of the key results is that CATE estimators with Neyman orthogonal loss functions (e.g., DR-learner, R-learner) are robust with respect to estimation errors of nuisance parameters (response surfaces, propensity score) in the sense of a fast guaranteed convergence rate. It is not clear to me that the proposed adversarial end-to-end approach improves on that. The proposed method already uses the Neyman orthogonal loss of the DR learner which makes the adversarial approach of optimizing for a pessimistic propensity score seem redundant.\n- Despite being central to the topic of the paper, three of the four works mentioned above are not cited in the paper. Neither is the R-learner considered as a baseline.\n- Furthermore, I do not understand why the proposed approach only performs adversarial learning w.r.t. the propensity score in combination with the doubly robust loss. Why not also for the response surfaces? Only accounting for the estimation errors in one nuisance parameter while ignoring the others seems arbitrary.  \n- A property of the DR loss is that only requires **either** the propensity score **or** the response surfaces to be estimated correctly to achieve a fast convergence rate (Kennedy, 2023). Again, this would make the proposed approach redundant if the response surface estimators converge sufficiently fast.\n- While the method performs well in the experiments, the datasets seem to favor methods that focus on response function estimation rather than propensity score. PW-Net has a huge variance and the estimation error seems to grow with sample size for some reason. I suspect that there might be possible overlap violations in the simulated data. I could imagine that the proposed method offers some advantages in dealing with overlap violations, which might lead to an alternative way to frame the paper. However, this would require additional intuition and experiments.\n- In summary, I think the problem of CATE estimation (or more generally, statistical estimation with nuisance parameters) is already quite well understood regarding the robustness to nuisance errors. I am not convinced that the proposed approach adds much benefit to the existing state-of-the-art.\n\nMinor points\n\n- The introduction puts a lot of emphasis on the CATE literature on representation learning. Personally, I do not think this literature stream is very relevant to the paper as it does not focus on representation learning, but CATE estimation as a statistical estimation problem with nuisance components. The same holds for the related work.\n- The related work on CATE could be expanded. \n- There are existing works on ATE estimation that estimate nuisance functions and ATE in an end-to-end manner (Shi et al. 2019, Frauen et al. 2023) which should be mentioned in the related work. However, these works perform end-to-end estimation to \"target\" the model parameters to fulfill estimation equations from semiparametric efficiency theory.\n- In the literature, $\\mu$ is usually used for the response functions and $\\pi$ for the propensity score\n- The consistency assumption is missing in Sec. 2"
            },
            "questions": {
                "value": "-Was data-splitting/ cross-fitting performed for the proposed method and the DR learner?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Reviewer_S5uy"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8811/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699564939930,
        "cdate": 1699564939930,
        "tmdate": 1699637107899,
        "mdate": 1699637107899,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2rnYTzlmLv",
        "forum": "TC9r8gsaoh",
        "replyto": "TC9r8gsaoh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_DQuR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8811/Reviewer_DQuR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a CATE estimation method using doubly robust estimators and machine learning.\n\nHere the outcome and propensity models are learned with ML in a \"targeted\" way to minimize the MSE of the CATE estimator, rather than being fit separately and plugged in. They then derive and bound/regularize additional loss terms that account for the contribution of nuisance mis-estimation to estimator bias."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- It's important to bridge the gap between ML and traditional yet challenging estimation problems such as CATE from observational data\n- Theory looks good/correct\n- Go beyond deriving a standard DR estimator and characterization additional issues with nuisance mis-estimation and what to do about it\n- Experiments are pretty complete."
            },
            "weaknesses": {
                "value": "There seems to be substantial discussion of related work missing.\n\nIn particular, there is a lot of existing work that also directly estimates the nuisance functions with ML, and even does so in a regularized way to directly target the estimand.\n\nSome examples include:\n- Adapting Neural Networks for the Estimation of Treatment Effects, https://arxiv.org/abs/1906.02120\n- RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests https://arxiv.org/abs/2110.03031\n\n(EDIT: I saw that the Shi work was added in the revision. See \"Questions\")\n\nMore generally, as mentioned in questions below, I think there are some clarity issues, such as incomplete sentences, that make the work hard to understand. Some of those unclear sentences appear exactly when there is an important differentiation about related work to be made.\n\nI would be willing to raise my score if the other reviewers believe that the related work has been clarified in the revision, and if the other reviewers and AC believe that unclear sentences/discussion points such as those above could be clarified easily."
            },
            "questions": {
                "value": "1)\n\n(EDIT after revision) I saw that the updated draft includes the passage: \"Joint optimization approaches have also been proposed for ATE estimation (Shi et al., 2019), though it may lead to cheating by less weighting to noisy regions especially under noise heterogeneity\"\n\nI am not sure what \"cheating\" means and what \"less weighting\" means?\n\n2) \n\nIn the baseline section, in passing, the authors mention \"DeR-CFR\" (Wu et al., 2022) as another method that optimizes weights and outcome model simultaneously, but do not clarify why it is not compared against.\n\n3)\n\n\"Although f0 and f1 are also nuisance parameters, the uncertainty of them do not differ among the target parameter space, thus we need not take care\"\n\nThis sentence is very hard to understand; it is not complete and certain phrases are not defined \"uncertainty does not differ\" and \"not taking care\". Which uncertainty?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8811/Reviewer_DQuR"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8811/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700849047171,
        "cdate": 1700849047171,
        "tmdate": 1700849229221,
        "mdate": 1700849229221,
        "license": "CC BY 4.0",
        "version": 2
    }
]