[
    {
        "id": "V0Bdp7WPo4",
        "forum": "8sKcAWOf2D",
        "replyto": "8sKcAWOf2D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission439/Reviewer_AnWX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission439/Reviewer_AnWX"
        ],
        "content": {
            "summary": {
                "value": "This paper examines the impact of fine-tuning on the internal computations of language models through a case study. Specifically, the authors investigate the entity tracking mechanism of Llama-7B and its fine-tuned versions. The authors argue that the performance enhancements resulting from fine-tuning can be attributed to the improved ability of attention heads to handle positional information.\nThey utilize Desiderata-based Component Masking (DCM) to confirm that the entity tracking mechanism and the functionality of a subset of attention heads remain the same in Llama-7B and its fine-tuned variants. Additionally, they introduce CrossModel Activation Patching (CMAP) to reveal the improved mechanisms of attention heads."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is generally well-written and easy to follow.\n\n2. The authors provide an explanation for the performance enhancement observed in the fine-tuned model, focusing on the entity tracking circuits."
            },
            "weaknesses": {
                "value": "1. The methods employed in this paper are limited to a single type of model on an entity tracking dataset. Moreover, the entity tracking mechanism is likely just one of many contributing factors, raising questions about the generalizability of their claims.\n\n2. I personally do not see the significance of the entity tracking problem to be particularly high."
            },
            "questions": {
                "value": "Why is it justified to employ attention mechanisms to delve into the entity-tracking circuit? I acknowledge there may be some associations between them, but are these connections truly substantial?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission439/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735990668,
        "cdate": 1698735990668,
        "tmdate": 1699635970434,
        "mdate": 1699635970434,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tFlSncg7q8",
        "forum": "8sKcAWOf2D",
        "replyto": "8sKcAWOf2D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission439/Reviewer_fhvV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission439/Reviewer_fhvV"
        ],
        "content": {
            "summary": {
                "value": "This work aims to answer the question: why fine-tuning language models (LMs) can enhance their performance on a range of tasks? As a case study, the authors experiment with LLaMA-7B and two fine-tuned versions, Vicuna-7B and Goat-7B, on the entity tracking task. They first apply Path Patching to extract the circuit, a subset of LM heads, from LLaMA-7B and find that all three models can reach high faithfulness scores with the circuit identified in Llama-7B, a.k.a., all three models share a similar circuit. Then, they apply Desiderata-based Component Masking (DCM) to identify LM heads responsible for specific functionality and find that each group of LM heads on all three models share the same functionality. Finally, they propose the Cross-Model Activation Patching (CMAP) to attribute the performance gain of fine-tuning to specific components, a.k.a., Value Fetcher, and Position Transmitter heads.\n\nThe work conducts extensive experiments to uncover the internal mechanisms of fine-tuning by applying two existing methods, Path Patching and DCM, and proposing one novel method, CMAP. The authors disclose some interesting experiment findings, e.g., the performance gain of fine-tuning attributes to the improved ability to handle positional information."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- A novel method CMAP for mechanistic interpretability.\n\n- The authors conducted extensive experiments by applying Path Patching, DCM, and their proposed CMAP to analyze the underlying mechanism of fine-tuning, which discloses several exciting findings, e.g., (1) The language model (LM) and its two fine-tuned versions share the same circuit. (2) The components of this circuit in these three models share the same functionality. (3) The performance gain of fine-tuning attributes to the improved ability to handle positional information.\n\n- The presentation is clear, although it requires the reader to have some background of mechanistic interpretability."
            },
            "weaknesses": {
                "value": "- The experiment results can not lead to the claim that the original model and its fine-tuned versions implement entity tracking with the \u201csame\u201d circuit: (1) the fine-tuned model, Goat-7B, reaches an accuracy of 82% while the circuit identified in Llama-7B reaches an accuracy of 68%; this considerable performance gap indicates that Goat-7B\u2019s circuit may be different from Llama-7B\u2019s circuit, although these two circuits may have considerable overlap. (2) It is necessary to explore the mentioned overlap. For example, could authors apply Path Patching to Vicuna-7B and Goat-7B to extract their circuits and compute the overlap between their circuits and Llama-7B\u2019s circuit?\n\n- As mentioned in (Wang et al., 2022) [1], faithfulness is not sufficient to prescribe which circuits explain the behavior well. Why do not authors show the completeness and minimality scores, similar to (Wang et al., 2022) [1]? \n\n- In Section 4.2: CIRCUIT EVALUATION, the expression F(Cir \\ K) - F(Cir \\ (K U {v})) / F(Cir \\ (K U {v})) in the Minimality paragraph seems wrong. Moreover, the authors mention that they filter out the heads that contribute less than 0.5% of the functionality defined by subset K. This description is inconsistent with the above expression since the denominator of the equation is the functionality defined by the remaining nodes after removing K and v.\n\n[1] Wang, Kevin, et al. \"Interpretability in the wild: a circuit for indirect object identification in gpt-2 small.\" arXiv preprint arXiv:2211.00593 (2022)."
            },
            "questions": {
                "value": "- What is the motivation to divide heads into four groups (A, B, C, D) instead of three or five? In other words, since authors iteratively identify groups of heads with high direct effects on each other using the path patching score, why did authors end with four groups instead of other numbers?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission439/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772771940,
        "cdate": 1698772771940,
        "tmdate": 1699635970345,
        "mdate": 1699635970345,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jrDLeKJjA2",
        "forum": "8sKcAWOf2D",
        "replyto": "8sKcAWOf2D",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission439/Reviewer_M52Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission439/Reviewer_M52Y"
        ],
        "content": {
            "summary": {
                "value": "The authors investigate the effects of fine-tuning on circuit-level mechanisms within large language models (LLMs) using entity tracking as a focal point. Initially, they employ a path-patching technique to isolate circuits responsible , categorizing attention heads into four groups based on the characteristics inherent to entity tracking. By defining four distinct groups, they ascertain the consistency and effectiveness of these circuits across various models. To delve deeper into the functionality of each group, they outline three main desiderata: Object, Label, and Position. Through activation patching, they discern the role of each group and confirm the commonality of circuit functionality across all models using Desiderata-Based Component Masking. The final phase involves Cross-Model Activation Patching, a method requiring the overlay of activations from similar components of different models on identical inputs. This assists in elucidating how a math-fine-tuned model augments an existing circuit in a base model, leading to enhanced performance in entity tracking. Experiments on LLaMA-7B and its two fine-tuned variants, Vicuna-7B and Goat-7B, reinforce their conclusions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors effectively elucidate the impact of fine-tuning on the internal computations of large models, particularly with respect to entity tracking. This provides a deeper understanding of how fine-tuning influences model behavior. Utilizing path patching, they constructed four distinct groups of attention heads and enable a granular examination of the model's functionalities. Demonstrated consistency across different models, validating the universality of the identified circuits in performing the entity tracking task.\n2. In subsequent tests of the individual capabilities within the identified paths, three out of the four attention head groups exhibited similar functionalities.This substantiates the hypothesis that the circuits in fine-tuned models implement similar functionalities.\n3. Experimental results on DCM concerning the Positional Transmitter and Value Fetcher in Goat-7B, as opposed to the original LLaMA-7B, align well with the CAMP experiment. This consistent alignment between the experimental findings and the initial hypotheses strengthens the paper's credibility."
            },
            "weaknesses": {
                "value": "1. The study's scope is limited to a single foundational model, raising concerns about the generalizability of the conclusions. Without further investigation across a broader spectrum of models, it's challenging to ascertain if the observed mechanisms are universally applicable.\n2. When establishing the Desiderata for identifying circuit functionality, the connection between the three tasks and their corresponding abilities remains ambiguously articulated. A clearer exposition of these relationships would have enhanced the clarity and rigor of the study.\n3. The section detailing the use of CMAP to patch activations from Goat-7B to Llama-7B lacks clarity, particularly when validating the impact of QKV on the model's performance. The rationale behind why patching the QK-circuit of the Value Fetcher and the value vector of the Position Transmitter heads results in the most significant enhancement is not well-explained."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission439/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805495058,
        "cdate": 1698805495058,
        "tmdate": 1699635970270,
        "mdate": 1699635970270,
        "license": "CC BY 4.0",
        "version": 2
    }
]