[
    {
        "id": "kqEOfD5wOQ",
        "forum": "sRBnyzoqkU",
        "replyto": "sRBnyzoqkU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_ffLz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_ffLz"
        ],
        "content": {
            "summary": {
                "value": "The paper presents \"model breadcrumbs\" as an enhanced mechanism to combine fine-tunings of a shared base model for a range of additional tasks. To create the \"model breadcrumbs\", the paper proposes to compute the differences between the weights of the models before and after fine-tuning and reject outliers among the differences in each layer. The resulting inlier weights are linearly combined across fine-tuned models and base model to provide enhanced generalization. The proposed method shows performance improvement over the task vectors approach used as base."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Results show improvements with respect to the baseline (Ilharco et al., 2022a)."
            },
            "weaknesses": {
                "value": "- The paper proposes a per-layer bottom and top percentile rejection of fine-tuned weights to be combined with the pre-trained model, but this proposal is not compared to any outlier-detection alternative.\n- The paper excessively relies on (Ilharco et al., 2022a) throughout the text (I counted up to 3 instances in a single paragraph), resulting in a hard to read paper."
            },
            "questions": {
                "value": "- Since the paper heavily relies on a single piece of previous work, I would suggest to rewrite the conclusions to more appropriately reflect the scope of the contribution of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Reviewer_ffLz"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6423/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698616228058,
        "cdate": 1698616228058,
        "tmdate": 1699636716553,
        "mdate": 1699636716553,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zdMUHOg0zH",
        "forum": "sRBnyzoqkU",
        "replyto": "sRBnyzoqkU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_dEWb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_dEWb"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the problem of leveraging foundation models for multi-task learning. It introduces Model Breadcrumbs, which is a method that constructs multi-task models from existing fine-tuned models. It builds on the Task Vectors paper (Ilharco et al. 2022) and claims to resolve existing limitations--scalability and hyperparameter tuning, particularly when the number of tasks increases. More specifically, to handle outliers and insignificant weight differences, which could otherwise impair the effective merging of multiple Task Vectors, the authors propose a sparsification process employing a masking operation. The authors claim that Model Breadcrumbs yields high-performing multi-task models is robust towards hyperparameter perturbations, generalizing as the number of tasks increases."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The motivation for the paper regarding improving the scalability and use of the growing pool of available fine-tuned models is clear and intuitive. \n- The method is empirically evaluated on 8 datasets.\n- The paper is overall well written and easy to follow."
            },
            "weaknesses": {
                "value": "- The method has very limited novelty over Task Vectors and is hacky. It is also not described very rigorously. The selection process for masking relies on the absolute magnitudes of the weights, but how do you decide what is \"excessively large\" or \"relatively small\"? \n- There is no clear justification for the hacky masking method. Presumably, it is just having some sort of regularizing effect, but this is not explored and there are other ways that people can regularize models to improve performance. \n- In addition, the experimental evaluation is quite limited, even compared to the original Task Vectors paper, which considered other benchmarks (including language tasks) as well. Additionally, the authors claim that they do not need a validation set but in fact it seems like they still do in order to tune hyperparameters on at least some of the tasks. \n- Overall, the paper presents very limited new insights over the existing Task Vectors paper."
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6423/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698709327029,
        "cdate": 1698709327029,
        "tmdate": 1699636716424,
        "mdate": 1699636716424,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uvbSyUg3G1",
        "forum": "sRBnyzoqkU",
        "replyto": "sRBnyzoqkU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_mobQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_mobQ"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to merge mutiple fine-tuned model (on mutiple tasks). The method measures the magnitude of \"task vector\"  which equals to fine-tuned weights - initial pretrained weights. Then mask out top $\\gamma$ and tail $\\beta$ percent elements in task vector according the magnitude of the task vector. Experimental results show the proposed method is helpful."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method is intuitive. \n- Experiments show the proposed weight averaging method is better than the naive weight averaging.\n- Authors provide a rich literature review of model merging."
            },
            "weaknesses": {
                "value": "- The method and experiments are kinds of superficial. The idea of elimiting large outliers and small noise is very common, e.g. [1]. \n-  Mutiple fine-tuned non-convex neural network could be not-averagable. However, this work didn't discuss this point. \n\n\n[1] Yadav, P., Tam, D., Choshen, L., Raffel, C., & Bansal, M. (2023). Resolving Interference When Merging Models. arXiv preprint arXiv:2306.01708."
            },
            "questions": {
                "value": "- I suggest to compare with or at least discuss [1]. Because [1] is close to the proposed method. \n-\n\n\n[1] Yadav, P., Tam, D., Choshen, L., Raffel, C., & Bansal, M. (2023). Resolving Interference When Merging Models. arXiv preprint arXiv:2306.01708."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6423/Reviewer_mobQ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6423/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698784220167,
        "cdate": 1698784220167,
        "tmdate": 1699636716305,
        "mdate": 1699636716305,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2YvilH0KwM",
        "forum": "sRBnyzoqkU",
        "replyto": "sRBnyzoqkU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_VPFm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6423/Reviewer_VPFm"
        ],
        "content": {
            "summary": {
                "value": "In this paper, a model merging method is proposed. The motivation lies in merging models fine-tuned for multiple tasks from a single foundation model. The proposed method is based on previous work of task vector [Ilharco et. al., 2022], and further design a pruning strategy that masks outlier model weights with small and large weights. Experimental results on benchmark datasets verify the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-motivated. It studies a very interesting problem: merging multiple models fine-tuned from a single foundation model into a single one. A solution of this problem would be very useful in real applications.\n\n- The experimental results show that the proposed method is effective on a number of benchmark datasets."
            },
            "weaknesses": {
                "value": "- The proposed method is somehow a tweak of the task vector method. Thus the technical contribution is limited. More importantly, the masking strategy is more of a heuristic method. The analysis of why it works is missing in the paper. The analysis is essential to justify that the proposed method can work beyond the benchmark datasets in the experiments.\n\n- The description of the proposed method is not quite clear. In the second paragraph of Page 4, it is said that \"If a weight\u2019s absolute\nmagnitude is excessively large relative to the remaining weights in that layer, it is subject to masking\". Does this mean that the large weights are set to zero? Or just thrown away like dropout? The description should be made precise.\n\n- I also suggest experimental investigation on the proportion of shared and deviated weights of models fine-tuned from a single foundation model, as well as how they are distributed (e.g. more similar in bottom layers or the opposite). I believe that more insights can be obtained from such kind of analysis."
            },
            "questions": {
                "value": "As discussed above, precise description of the masking operation is necessary."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6423/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699358597863,
        "cdate": 1699358597863,
        "tmdate": 1699636716196,
        "mdate": 1699636716196,
        "license": "CC BY 4.0",
        "version": 2
    }
]