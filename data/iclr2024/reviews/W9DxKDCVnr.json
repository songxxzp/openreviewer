[
    {
        "id": "Fil5jCMFAS",
        "forum": "W9DxKDCVnr",
        "replyto": "W9DxKDCVnr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_mU8z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_mU8z"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a graph continual learning dataset and defines standard incremental settings and evaluations. It proposes a trainer to evaluate the performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed datasets seem to be useful in graph incremental learning.\n2. The dataset settings and evaluations seem to be sound."
            },
            "weaknesses": {
                "value": "1. The authors do not propose their method for graph incremental learning.\n2. The organization of this paper is not good. The main contribution is the dataset but there is no intuitive information of what the dataset looks like. For example, what it contains, the scale, and other information.\n3. The performance in Table 3 is not complete."
            },
            "questions": {
                "value": "see the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4873/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668032802,
        "cdate": 1698668032802,
        "tmdate": 1699636471606,
        "mdate": 1699636471606,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "e38oN7b760",
        "forum": "W9DxKDCVnr",
        "replyto": "W9DxKDCVnr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_xQU7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_xQU7"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a benchmark specifically designed for continual learning (CL) on graph data, diverging from the conventional focus on independent data types like images and text. The framework utilizes 20 public datasets, segmented into multiple tasks tailored to various continual learning settings, including task-, class-, domain-, and time-incremental settings at node, edge, and graph levels. The performance of diverse CL methods under these settings is assessed using four evaluation metrics: average performance, average forgetting, intransigence, and forward transfer."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe general motivation of building benchmarks for continual learning on graphs is interesting and practical for the graph learning community. \n2.\tThere are some merits in the design of the experiments. Different settings are considered and evaluated. \n3.\tThe code is well-organized and the documentation is relatively easy to understand."
            },
            "weaknesses": {
                "value": "1.\tOne major concern is the large incompleteness of the evaluation results(about one third of entries in tables are n/a). The author should be clear on why methods are not applicable. Besides, three methods (PackNet, Piggyback, HAT) only support the task-IL setting. Why does the author include them as part of baselines, since they are not generalizable?\n2.\tThere are a few claims that are doubtful in terms of the comparison with exciting benchmarks. In Appendix G.3 and Table 9, the authors claim that the same implemented method has about on average 28.6% fewer lines of code. However, simply comparing the line counts is not meaningful to demonstrate its own strength. The reviewer suggests the author calculate the running time of each method implemented by the author and existing works for a fair comparison. \n3.\tThe reviewer appreciated that the author stated the weakness in terms of the small number of tasks due to the limited labeled data. However, this is also an important contribution to the benchmarks (and differentiates from the existing works). Even a synthetic dataset is supposed to suffice.\n4.\tA few results seem problematic. For the methods \u2018PackNet\u2019 and \u2018Piggyback\u2019, the average forgetting on a few datasets is 0.000\u00b10.000 for each number of tasks. The number of digits seems not enough to differentiate the results. Other reasons need to be discussed if available."
            },
            "questions": {
                "value": "Please see weakness 1 to 4."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N.A."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4873/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727530866,
        "cdate": 1698727530866,
        "tmdate": 1699636471520,
        "mdate": 1699636471520,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TrfZsfL3r2",
        "forum": "W9DxKDCVnr",
        "replyto": "W9DxKDCVnr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_DN96"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_DN96"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an extensive benchmark for graph continual learning. Currently, literatures in graph continual learning domain are lack of standards and inconsistent with the settings and evaluation dataset and metrics. This work aims to solve this problem by proposing a comprehensive evaluation benchmark with 31 scenarios based on 20 real world graphs. The work groups graph continual learning settings into four, including task-incremental, class-incremental, domain-incremental and time-incremental, and 3 levels of problems Moreover, this work provides the evaluation results of 10 graph CL methods using the provided benchmark."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Graph continual learning is a relatively unexplored field compared to continual learning research in other modalities. A primary obstacle is the lack of a standard evaluation protocol, including benchmark datasets, settings, and metrics. This paper addresses this gap, working diligently toward establishing such standards.\n\nIn this work, the authors systematically propose a benchmark designed to cover all possible scenarios in graph continual learning. Furthermore, for each scenario, results from 10 graph continual learning methods are provided, facilitating future comparisons and research.\n\nThe technical details supplied in the paper are comprehensive, and the codebase is well-documented, adding value to the paper and aiding in reproducibility."
            },
            "weaknesses": {
                "value": "While the authors have diligently developed a benchmark comprising 12 combinations of graph CL settings, the comprehensiveness of this benchmark in capturing the breadth of potential scenarios within graph CL problems remains somewhat ambiguous to me. Taking a different vantage point, such as data availability in the past, introduces unique scenarios. For instance, a situation where past data is inaccessible could arise, drawing parallels to the data-free setting observed in image CL problems [ref-1].\n\n[ref-1] Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning, James Smith et al., ICCV 2021\n\n\nGiven the distinct nature of graph CL, scenarios involving incremental learning with the addition of new nodes typically presume a direct connection to the existing graph. This raises an intriguing question: what happens when one or more of these new nodes are not interconnected? Addressing and discussing this scenario would significantly enhance the scope and utility of this benchmark paper."
            },
            "questions": {
                "value": "It is not clear to me the motivating example shown in Figure 3 (there are changes in (a) the number of nodes, (b) the number of edges, (c) the number of classes (or domains), and (d) the distribution over classes) is covered by the proposed settings. Could you provide a detailed explanation to clarify this matter?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4873/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4873/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4873/Reviewer_DN96"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4873/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698822021248,
        "cdate": 1698822021248,
        "tmdate": 1700680937122,
        "mdate": 1700680937122,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zkF67w7Jtz",
        "forum": "W9DxKDCVnr",
        "replyto": "W9DxKDCVnr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_amhN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4873/Reviewer_amhN"
        ],
        "content": {
            "summary": {
                "value": "The work is a benchmark for graph continual learning, which does assume the graph to learn is fixed. In other words, it is a setting that extends the continual learning/ lifelong learning to graph data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. This paper propose a easy-to-use framework for implementation of graph CL methods. \n\n2. Some preliminary experimental results using the framework are provided."
            },
            "weaknesses": {
                "value": "1. This paper does not have any technical contribution, and is mostly dividing the existing public graphs into different tasks for graph continual learning, therefore may not be suitable for ICLR.\n\n2. Even from the perspective of proposing new datasets/benchmark/evaluation, this paper has limited contribution. The proposed continual learning setting and splitting is same as standard continual learning on non-graph data, and the work in this paper to divide them is trivial. \n\n3. As for the contribution of a new framework for implementation and evaluation for graph CL methods. It seems like the contribution is an easy-to-use software for facilitating coding, which is off the scope of AI research."
            },
            "questions": {
                "value": "1. What is the essential difference between CL and graph CL? Is simply an extension of CL methods to graph data?\n\n2. There are also other works on graph CL, is the experiment settings in this paper consistent with them?\n\n3. Among the datasets used in this paper, which are already used by graph CL works, which are new?\n\n4. For the same datasets used by both this work and the other graph CL works, are the experimental settings the same? Are the results the same?\n\n5. The methods experimented in this paper also include some works with public code, e.g. GEM. Can the proposed framework obtain reasonably similar results as their official implementation?\n\n6. Can this framework be used on computer vision tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4873/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837596701,
        "cdate": 1698837596701,
        "tmdate": 1699636471372,
        "mdate": 1699636471372,
        "license": "CC BY 4.0",
        "version": 2
    }
]