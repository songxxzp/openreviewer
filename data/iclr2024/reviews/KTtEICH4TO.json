[
    {
        "id": "S1QjVu1qVk",
        "forum": "KTtEICH4TO",
        "replyto": "KTtEICH4TO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_UC4D"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_UC4D"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an innovative contact-based representation for non-prehensile manipulators, which aims to enhance the robot's ability to manipulate objects. A pre-training model is utilized to predict the contact between the gripper and the object, thereby providing the policy with a more detailed understanding of the robot-object interaction. The state-based policy is then distilled into a vision-based one for implementation in real-world scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The creation of this representation is commendable, as it underscores the importance of using the full functionality of the gripper for contact. The algorithm designed for its training is intriguing and appears to be well thought out.\n2. The experimental results convincingly demonstrate the model's capability, efficiency, and superiority compared to alternative methods. Furthermore, experiments using real robots with zero-shot transfer highlight the model's robustness, thereby solidifying the research."
            },
            "weaknesses": {
                "value": "1. The scope of manipulation tasks in this research is restricted to single-object state maneuvering using a closed gripper. Incorporating more intricate robot-object interactions, such as grasping, could help to fully utilize the robot's kinematic capabilities and cover more complex scenarios.\n2. The paper measures the success of the tasks using a \"success rate.\" However, necessary details, like the specific criteria used to determine successful manipulation, lacks clarity. Moreover, the goal state illustrated in the manipulation videos (or their screenshots) appears to be a snapshot of a future state, which does not accurately represent the actual desired outcome."
            },
            "questions": {
                "value": "1. Could you elaborate on the \"success rate\" metric used in your experiments? What specific criteria are used to determine a successful manipulation?\n2. Can you explain how do you measure the physical parameters in the real world and make sure they are aligned or well-simulated in simulations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Reviewer_UC4D"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9206/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698386920806,
        "cdate": 1698386920806,
        "tmdate": 1700635357102,
        "mdate": 1700635357102,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8GkrLGc73K",
        "forum": "KTtEICH4TO",
        "replyto": "KTtEICH4TO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_dbmK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_dbmK"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a novel method for nonprehensile manipulation using reinforcement learning (RL). Traditional RL struggles with diverse object shapes and high-dimensional sensory inputs. The authors introduce a contact-based object representation and pretraining pipeline, using a patch-based transformer encoder for point clouds, enabling scalable training. Their approach offers time- and data-efficient learning, with successful zero-shot transfers to real-world objects."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper motivates well, and the techniques presented are sound.\n2. The paper is well-written and easy to follow.\n3. The presented method shows good generalization ability to unseen objects and sim-to-real scenarios."
            },
            "weaknesses": {
                "value": "1. The novelty of this work is marginal. basically, it just applies point-cloud-based reinforcement learning to nonprehensile manipulation tasks.\n\n2. The generation of the collision label is questionable with the coverage of the collision states, i.e., if this work truly aims for generalization on unseen objects, I wonder how the collision prediction network be generalized to the unseen geometry.\n\n3. Besides, if the contact network is trained as a guide for the encoder, how does it guarantee to generate a collision-free policy? The collision decoder itself is not perfect (due to the coverage issue and neural network prediction), and the influence on the encoder is indirect (leads to less perfect), not to mention the policy is distilled from the teacher network to the student network (even less perfect).\n\n4. Since this method is \"contact-based\"? In a broad sense, all the manipulation is contact-based, but I assume the word choice here is for the embedding induced by the contact network. Then, though the authors have conducted extensive baseline methods on the encoder side, in my opinion, they should also discuss different decoder schemes to justify the \"contact-based\" name. For example:\n\n(a). the encoder is directly trained by the policy network? That is, no contact decoder to pretrain the encoder.\n\n(b). the decoder is a geometry reconstruction network. In this sense, the encoder can capture the geometry information of the object point cloud and hand. I see no apparent reason why the \"action and rewards\" cannot be done with such kinds of decoders.\n\n5. Another possibility of the naming is due to the r_contact in the reward, but the contact potential is not given exactly, since the essential d_h,o is built upon the distance from the CoM of the object to the tip. Which does not prevent collision/intersection between the gripper and hand.\n\nTherefore, if the contact is not necessarily determinant or explicitly modeled for policy training in both network design and reward shaping, the only sane way to interpret the contact-based would be in the broadest sense, i.e., all the manipulation is contact-based. In this sense, I would suggest removing the \"contact-based\" in the title, which would give wrong expectations to the readers. Or the paper can present stronger relevance of \"contact\" to the object representation."
            },
            "questions": {
                "value": "See the weakness section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9206/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698702482378,
        "cdate": 1698702482378,
        "tmdate": 1699637158319,
        "mdate": 1699637158319,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nABov1Sp1e",
        "forum": "KTtEICH4TO",
        "replyto": "KTtEICH4TO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_LafH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_LafH"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces CORN, a Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects. The system combines deep reinforcement learning with a novel contact-based object representation to effectively manipulate a variety of shapes and sizes of objects. The key innovation lies in the use of a lightweight patch-based Transformer architecture to process point clouds, enabling large-scale parallel training across thousands of environments. The efficacy of CORN is validated through a series of experiments, demonstrating zero-shot transferability to novel real-world objects."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces an approach to nonprehensile manipulation of general unseen objects, a challenging area in robotics. \n- The methodology is laid out with a clear structure, and the paper provides a set of experimental results to back its proposals. \n- The work has potential implications for the field of robotics, particularly in object manipulation, although the full extent of its impact may require further exploration and validation."
            },
            "weaknesses": {
                "value": "- Lack of Unique Design for Complex Operations: The paper emphasizes in the introduction that its approach can execute more complex robotic arm operations than prior grasping work. However, in the method description, there appears to be no clear unique design to directly support this motivation, raising doubts about the novelty and effectiveness of the method.\n- Overemphasis on \"Contact\": While the authors place particular emphasis on the importance of \"contact\" in nonprehensile operations, it seems that the equally vital role of \"contact\" in grasping tasks has not been adequately considered. This imbalanced emphasis may impact the comprehensiveness of the method and its practical applicability.\n- Questioning the Novelty of Point Cloud Processing: The paper utilizes a Transformer-based architecture to process point cloud data, but this approach does not appear groundbreaking, emphasizing the need for a more detailed description of the policy network design.\n- Insufficient Description of the Policy Network: The paper provides a relatively concise description of the policy network, lacking in-depth details, which might hinder readers from fully understanding the workings of the method and its potential advantages.\n- Inadequate Experimental Setup: The paper does not offer detailed information related to actions and reward settings in the experiments, which is crucial for evaluating the effectiveness of the reinforcement learning portion.\nIn summary, these points highlight potential shortcomings in the paper concerning method description, evidence of novelty, and experimental setup. They offer specific directions for improvement to the authors, aiming to enhance the persuasiveness of the paper and provide a clearer conveyance of their research outcomes."
            },
            "questions": {
                "value": "- The paper strongly emphasizes the role of \"contact\" in nonprehensile manipulation. How does this emphasis differ in importance from its role in grasping tasks?\n- The description of the policy network is relatively concise. Could the authors provide more details on its design and working principles?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Reviewer_LafH"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9206/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743217335,
        "cdate": 1698743217335,
        "tmdate": 1700750592015,
        "mdate": 1700750592015,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lVkXfCjclz",
        "forum": "KTtEICH4TO",
        "replyto": "KTtEICH4TO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_4HBK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9206/Reviewer_4HBK"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel method for non-prehensile manipulation, i.e. manipulating an object that is not graspable via poking, pivoting and toppling from an initial pose to a goal pose. There are two major technical contributions:\n- A novel pre-training objective on predicting which parts of the object point cloud are in contact with the gripper\n- A novel patch-based transformer architecture that allows efficient encoding of point clouds and other modalities such as robot gripper state.\n\nThe paper also provides a new dataset on non-prehensile manipulation with over 300 different objects."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The model is trained entirely in simulation and achieves over 70% success rate in the real world with zero-shot sim-to-real transfer.\n- The model finishes 2 million steps training in less than a day.\n- The objects tested have good diversity. Over 20 objects are tested in the real world and over 300 objects are used in simulation. The test objects have significant geometric difference from the training objects.\n- The paper addresses an important and difficult problem in contact-rich manipulation, which has significant impact on expanding a robot\u2019s manipulation ability to more diverse objects in the real world.\n- The experiments are very comprehensive, covering all the key parts of the design, including the point encoder and the pre-training objective.\n- The hyperparameters are well documented in the appendix, which is important for reproducing the results."
            },
            "weaknesses": {
                "value": "- The model takes the difference between current object pose and target object pose as input. This can bring significant engineering challenge since object segmentation and pose tracking in the real world can be difficult. However, the authors documented their approach very well in Sec. A.3.\n- The method only works on object well separated from clutter on a tabletop. This is related to the above assumption for the object pose, since having more than one object in close contact will make object segmentation and pose tracking even more challenging."
            },
            "questions": {
                "value": "- What is the coordinate frame of the hand pose input? Since the hand pose is sampled near the object to ensure good data balance for contact/no contact during pre-training, will the hand pose go out of distribution during policy learning?\n- In Figure 7, is the scale of the success rate the same for the two plots? It seems that the final success rate doesn\u2019t match up for the green, red, purple and brown curves.\n- Which simulator is used? I didn\u2019t find it in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "10: strong accept, should be highlighted at the conference"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9206/Reviewer_4HBK"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9206/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699240566185,
        "cdate": 1699240566185,
        "tmdate": 1699637158104,
        "mdate": 1699637158104,
        "license": "CC BY 4.0",
        "version": 2
    }
]