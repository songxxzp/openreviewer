[
    {
        "id": "E3kdriGSqM",
        "forum": "SLw9fp4yI6",
        "replyto": "SLw9fp4yI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_Gru5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_Gru5"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces model arithmetic, a new method for controlled text generation (CTG). Model arithmetic works by solving for combinations of divergences between a base distribution and attribute distributions that may be full token-wise probabilities or classifiers. Particularly, model arithmetic allows weighted linear combinations of such distributions (positive or negative) and a union operator which is defined to allow probability mass to come from either the base distribution or the attribute distribution. The authors find the method works well for toxicity reduction, as well as for different attributes in a conversation model. The authors also demonstrate that speculative sampling works with the proposed technique to increase efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The method of combining attributes in model arithmetic is inventive\n- Derivations of the solutions to the model arithmetic optimizations are interesting\n- It is useful to know that this works with speculative sampling\n- Results seem to generally support that the framing of attribute combination works, particularly the toxicity results"
            },
            "weaknesses": {
                "value": "- The paper largely frames against other CTG methods, which use a magnitude variable lambda to control the effect of the given attribute. However, model arithmetic does not seem to provide a more principled definition of magnitude of effect--users will still simply pick a weight, that does not necessarily have an intuitive interpretation\n- Similarly, it is not quite clear how or when such a method can be applied. Two example applications are given. \n   - The first is toxicity which does use both the linear and union operators but only in conjunction with weights that seem to be quite hand tuned (0.9, 0.96, 0.99). It would be useful to also see a simpler framing of this problem with model arithmetic, e.g. simply subtracting the M_toxic instead of the union. The question I am trying to get at here is: does toxicity require the full complexity of model arithmetic? It seems like a fairly simple application which may simply require a subtraction, in which case the need for more complex proposed model arithmetic might not be supported here.\n   - While the second application, conversation, presents a more complex use-case for model arithmetic, it seems that the complex application space means that no baselines would work or be comparable here. So this application also does not make a complete case for the full complexity of model arithmetic improving on past work."
            },
            "questions": {
                "value": "Do the authors have other examples of how model arithmetic might intuitively be used?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Reviewer_Gru5"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9377/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698737489270,
        "cdate": 1698737489270,
        "tmdate": 1700714513888,
        "mdate": 1700714513888,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jKZS833UEW",
        "forum": "SLw9fp4yI6",
        "replyto": "SLw9fp4yI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_gF67"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_gF67"
        ],
        "content": {
            "summary": {
                "value": "The authors present a framework during inference time that can compose models together using arithmetic for controllable text generation without the need for additional fine-tuning. They present proofs that seem to simplify prior controllable text generation algorithms and provide regions or ways to extend them effectively. They show performance gains for 3 large models on toxicity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) I think the motivation here is clear. It'd be great to do this kind of a thing with already trained models. You really do want to compose them and do arithmetic with them, especially as these models become more expensive to train and impossible for the vast majority of us to do any development or even significant fine-tuning, instruction-tuning, rlhf etc. on them.\n\n2) The empirical results on toxicity are nice; the methods seem to reduce them in so far as the perspective api can adjudicate."
            },
            "weaknesses": {
                "value": "1) Experimentation seems a little weak. It'd be great to compare with some of the work that's come out of UW/AI2 in the past couple of years like DExperts, which you cite but dont compare with, and Quark (Lu et al. 2022). It'd also be great to compare with GeDi and a few other baselines. That'd strengthen the experimental component.\n\n2) On the experimentation side again, it'd be great to have a section on using human eval to evaluate a small subset of the generations to see if humans agree that it indeed is reducing toxicity or whether its an artifact or oddity of the perspective api evaluation.\n\n3) On the experimentation side, it'd be nice to see how well these methods work for smaller models (e.g. GPT2, GPT2-large)"
            },
            "questions": {
                "value": "1) How do you think model averaging via output distributions could compare with weight averaging of the model parameters? Would be curious to know your thoughts here.\n\n2) How straight forward and performant would it be to swap in different models for each part here and capture the output distribution, if the vocabulary was shared?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Reviewer_gF67"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9377/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821094610,
        "cdate": 1698821094610,
        "tmdate": 1700713399724,
        "mdate": 1700713399724,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HI7Jse9UP1",
        "forum": "SLw9fp4yI6",
        "replyto": "SLw9fp4yI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_Ne4m"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_Ne4m"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces \"model arithmetic,\" a framework for combining multiple large language models (LLMs) to modulate \nspecific attributes in controlled text generation (CTG). The framework employs a structured, formulaic method to accomplish \nits objectives and encompasses many existing CTG methods. Empirical evidence demonstrates its superiority in reducing toxicity\nover previous approaches. Additionally, the authors propose an innovative speculative sampling technique to \nminimize the computational demands of model arithmetic."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* This ia a pretty principled framework for CTG. Many prior work can also be expressed in the framework.\n* It is grounded on the concept of KL-optimality, offering a fresh perspective and strengthening its theoretical foundation.\n* The proofs presented are thorough and complete, bolstering the theoretical underpinning of the framework.\n* It presents innovative speculative sampling technique."
            },
            "weaknesses": {
                "value": "* The core concept closely resembles \"PREADD\" (Pei et al., 2023), which also relies on composing multiple LLMs to control desired attributes and using prompts to construct different LLMs with desired attributes.\n* The comparison in Table 5, showing the toxicity reduction results, appears biased. PREADD is tested in a single ad-hoc configuration, whereas model arithmetic is assessed across six, potentially skewing fairness.\n* The toxicity reduction comparison in Table 5 is limited, omitting works like Liu et al. 2021, despite its relevance mentioned on page 16.\n(In the discussion period, the authors pointed out that work of Liu et al. 2021 relies on expensive fine-tuning with training data, which is different from their zero-shot regime.)\n* The evaluation is restricted to toxicity reduction, whereas other CTG studies often explore sentiment or topic control as well. It is recommended to broaden the evaluation scope to these areas as well. (In the discussion period, the revised version added an extra experiment evaluating model arithmetic on sentiment control in Appendix F, showing that their method also outperforms existing work.)"
            },
            "questions": {
                "value": "Please respond to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Reviewer_Ne4m"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9377/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699446615078,
        "cdate": 1699446615078,
        "tmdate": 1700655686249,
        "mdate": 1700655686249,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "294WvaLe2c",
        "forum": "SLw9fp4yI6",
        "replyto": "SLw9fp4yI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_dPAm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_dPAm"
        ],
        "content": {
            "summary": {
                "value": "**TL;DR** This paper generalizes a number of model control techniques to combine different token and classifier distributions as generalized \u201cLanguage Model Arithmetic\u201d expressions that can evaluate arbitrary linear combinations of token probability distributions, binary classifiers, and token distributions combined with union and intersection operators. Furthermore the authors show that speculative sampling can be used to make this process quite efficient. Experiments on toxicity reduction, topic control, and efficiency validate these properties. The paper is well-written and unifies different methods under a novel framework that pushes forward new possibilities. Results are less thorough than I would have hoped, but I believe this paper deserves to be accepted.\n\nThe paper begins by discussing the downsides of prompting as a method of controlling text generation, referencing past work that has shown that prompting is not reliable, efficient, or interpretable. They then suggest that doing a kind of \u201cmodel arithmetic\u201d where different distributions are composed via an altered version of speculative sampling can result in distributions that match the original intention of the user, though how one decides on the arithmetic formula for models is left unspecified. Necessary background is then reviewed.\n\nFor their first contribution, the authors describe a framework for weighting various predictions more or less depending on how \u2018important\u2019 they are for some externally defined purpose, as represented by weighting functions f_i. They then prove that given that the sum of weights f_i is positive and independent of which token is being weighted, they can find a weighting that minimizes the KL divergence through a simple softmax computation. While intuitive in retrospect, this is quite an interesting insight when framed as a method of control. They use this framing and result to define Language Model Arithmetic as an arithmetic combination of different weighting functions and distributions that meet the previously described assumptions. It is an elegant trick to first ensure that the weighting functions add up to a constant value to find an easy minimization, and then use further weightings to control what distribution is being optimized for, and the authors describe this method quite clearly.\n\nHaving described this approach, the authors show how previous controlled text generation methods can actually be expressed in their framework. So far, the authors have only described linear combinations of different token-level distributions, but the authors also show that a binary classifier can be added to the optimization, since we can convert minimizing the classifiers value to a difference of two KL divergence terms. This allows Language Model Arithmetic to further generalize past approaches. However, it\u2019s worth noting that in practice approximations must be used since the described theorems only apply when a distribution based on classifying _every possible next word in the vocabulary_ can be computed, which is generally very expensive since vocabularies are often in the tens or even hundreds of thousands. To be fair, previous work with similar methods also had to approximate the full distribution by using only the top-k highest probability tokens, so while this is a flaw, it is no worse than previous methods.\n\nNext the authors introduce the union operator for Language Model Arithmetic (and briefly mention the unused intersection operator), which essentially takes distributions Q_1 and Q_2, and expresses an optimization objective to maximize the probability per token under the max given by either Q_1 and Q_2. This is achieved by attaching an indicator function to KL divergence terms, that is non-zero for Q_1 only when its KL divergence is lower for a certain token than Q_2 and vice versa.\n\nThe authors then move on to showing that speculative sampling, a method recently invented to allow sampling from a cheaper proposal distribution by validating from a target distribution and resampling where necessary, can be generalized to sampling from Language Model Arithmetic expression. In short the authors propose to use individual terms in Language Model Arithmetic expressions as proposal distributions and target distributions that are chained together to sample from the full expression of the desired distribution combination. This only works with full token distributions, but binary classifiers can be used at the first step to essentially limit the hypothesis space. This creates a caveat where multiple binary classifiers can\u2019t be chained together efficiently.\n\nExperimental validation is done in three parts: toxicity reduction, fine grained control over text generation topics, and speed improvements from speculative sampling. \n\n\nFor toxicity reduction, the results shown in Table 5 convincingly show that by combining multiple of the proposed techniques for Language Model Arithmetic, toxicity in generated text (at least according to the given classifier) while achieving lower perplexities than previous methods. The authors show that using large coefficients in Language Model Arithmetic eventually degrades perplexity, but show that multiple different coefficients still perform decently. A more thorough study of sensitivity of Language Model Arithmetic to different coefficients and expressions would have made this set of experiments more convincing.\n\nFor fine grained controlled text generation, the authors show that over two different Language Model Arithmetic expressions, linearly increasing the strength of a component linearly increases classifier scores for that component over generated text. The one exception is the \u201csports\u201d topic, which is sigmoidal, but still shows relatively clear control. While these experiments are positive. I feel that they could have been shown and done more thoroughly. For instance, three things I would have liked to see:\n\n- Accompanying perplexity graphs to the shown classifier results that  validate whether the model continues to generate sensical text rather than just \u201cfootball football football\u201d, which seems like it may indeed happen at some point given the high perplexities in the toxicity reduction section.\n- Only two different Language Model Arithmetic expressions are tested. They are interesting, complex expressions, but one big question that\u2019s left unanswered is how much fiddling has to be done to find the right Language Model Arithmetic expression? If the complexity of prompting is replaced by the complexity of finding the right expression, then this is less of a win for the proposed method.\n- It would be useful to see what happens when multiple lambda values are changed and whether interference becomes too strong after a certain point.\n\nThe results in this section are nice, and they are partially substantiated by being a generalization of previous methods, but they feel a little thin.\n\nFor the final set of results, the authors show that using speculative sampling makes the problem of evaluating Language Model Arithmetic expressions for generation much less onerous. In particular, the metric of \u201cmodel calls per token\u201d is focused on (which I think is exactly the right metric, as it scales with model size). The authors show that model calls per token is reduced with speculative sampling and that this reduction only grows with more complex formulas, which is a big win. It seems that this is because successive terms in a Language Model Arithmetic formula affect the result less, as there is a limited distribution of options that will be possible given that some achieve extremely low probability under certain distributions. It would be interesting to see if the order of evaluation could be optimized, since terms with large coefficients will likely save more time if evaluated first.\n\nRelated work that was not mentioned in the background or fully connected to the proposed method are reviewed, and the paper concludes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- Language Model Arithmetic as expressed seems to be an elegant generalization of a number of past approaches, while adding significantly more expressivity.\n- The use of speculative sampling to speed-up evaluation of what is usually quite costly multi-model inference, in a way that scales better the more models are being sampled from is clever and very promising.\n- The results, while somewhat more limited than I would have hoped, are promising.\n- The paper is well-written and connects to previous work while showing its novelty. The appendices are thorough and I found all the details I was looking for when double-checking the finer points of method and evaluation."
            },
            "weaknesses": {
                "value": "The biggest weakness of this paper is the lack of a more thorough evaluation. I think this breaks down into three categories:\n- **Lack of finer grained analysis of generation.** Neither a human or an LLM-backed evaluation (e.g., with GPT-4) was done, only classifier and perplexity based evaluations (where perplexity is taken under the original vanilla language model). This means that text could be qualitatively strange in some capacity, and none of the evaluations would show it as long as the original model is not too surprised by it. I find this somewhat worrying, as the problem with many model control techniques is the fact that they collapse onto strange parts of the distribution that are low perplexity but still wrong, e.g. the repetition with greedy and beam search.\n- **Lack of different generative scenarios.** While section 5.2 shows fine grained control over the generated topic, this is an extremely limited generation scenario where all the model has to do is speak about a specific topic. Evaluation on controlled generation, personalized summarization or translation, coherent essay writing, or any somewhat more defined generation scenario would have made evaluation more convincing.\n- **Lack of exploration of the space of possible expressions.** The authors present an extremely general method for constructing interesting distributions to sample from, but only test a handful. It would be disappointing if it turned out that this technique is extremely brittle to the specific Language Model Arithmetic expression that is used, which would simply have transported the complexity of prompting to the complexity of finding the right arithmetic expression. The results in the paper do not suggest this is the case, but evaluate only 4 different expressions for quality, with the rest of the results only changing the coefficient values or testing speed."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Reviewer_dPAm"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9377/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699490160962,
        "cdate": 1699490160962,
        "tmdate": 1700707686155,
        "mdate": 1700707686155,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qLlG2bPTFf",
        "forum": "SLw9fp4yI6",
        "replyto": "SLw9fp4yI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_bqfK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9377/Reviewer_bqfK"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an inference framework for composing and biasing LLMs without training on task-specific datasets, which may allow for more precise control of generate text. Speculative sampling, which is a popular technique for LLMs, can also extend to the proposed method. Experimental results demonstrate that the proposed method outperforms several baselines on the task of toxicity reduction."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method based on model arithmetic is interesting and general.\n\n2. Experimental results show its effectiveness on toxicity reduction and fine-grained controlled text generation tasks."
            },
            "weaknesses": {
                "value": "1. The proposed method needs heavy human design for specific tasks. The formulas for toxicity reduction (Table 5) and fine-grained control (Section 5.2) is not intuitive. I wonder whether there is a principle or a theoretically-supported method to choose operators and determine their coefficients for different tasks. If these are just empirical tries, the applicability of the proposed method may be largely degraded.\n\n2. The position of this paper needs to be further considered. In my view, the proposed method seems like a general form of existing works because the operators based on linear combinations and classifiers are not first proposed by this paper. They have been already studied in the line of work on controlled text generation. The current position may exaggerate the contribution and novelty of the proposed method."
            },
            "questions": {
                "value": "I have included my questions in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9377/Reviewer_bqfK"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9377/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699678670605,
        "cdate": 1699678670605,
        "tmdate": 1699678670605,
        "mdate": 1699678670605,
        "license": "CC BY 4.0",
        "version": 2
    }
]