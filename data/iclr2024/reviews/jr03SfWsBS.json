[
    {
        "id": "oHTqaUcKxl",
        "forum": "jr03SfWsBS",
        "replyto": "jr03SfWsBS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
        ],
        "content": {
            "summary": {
                "value": "The problem the paper considers is building accurate models subject to a fairness constraint. There are many ways of building models but it is difficult to compare between different methods because a) the model performance depends on the underlying classifier and b) the models satisfy the fairness constraint up to different relaxations.\n\nThis paper seeks to solve both problems and run a large experiment on many different methods and models. They start with an approach they call \"unprocessing\" which takes the underlying classifier and removes the fairness constraint. In this way, different models can then reasonably be compared to each other. They then postprocess the classifiers to achieve the fairness constraint. There is an optimal way to achieve the postprocessing so this step also lets different models be compared to each other."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. A simple way of comparing models with different fairness constraints. I hope this becomes widely adopted and used before people introduce their XYZ fairness algorithm.\n\n2. A comprehensive evaluation of lots of models on four data sets. I especially liked two observations from their results:\n\n* Models subject to a fairness constraint can actually achieve higher accuracy than models not subject to a fairness constraint when compared fairly (pun intended). The explanation they give is that fair training can take longer and use more resources because of the complexity in the algorithms.\n\n* In their words: \n\n\"Crucially, postprocessing the single most accurate model resulted in the fair optima for all values of fairness constraint violation on all datasets, either dominating or matching other contender models (within 95% confidence intervals). That is, all optimal trade-offs between fairness and accuracy can be retrieved by applying different group-specific thresholds to the same underlying risk scores.\"\n\nI think this is intuitively obvious and it's nice to see experimental confirmation.\n\n3. A technical description of how to achieve relaxed parity."
            },
            "weaknesses": {
                "value": "1. I found the technical description of how to achieve relaxed parity jarring from the rest of the paper. I would have liked this section to be longer and for more explanations there. I did find the figures quite helpful in understanding it.\n\n2. A big selling point of the paper is the extent of their experiments. I think the reason they were able to do this is because they had access to a ton of compute. All the data sets and models (I believe) are easily accessible. If this is the case, I'm not sure that \"having lots of compute\" is really something we should reward as a contribution.\n\n3. I found their approach intuitively obvious: Of course given a classifier, you can vary how much it violates a reward constraint in an optimal way. So I think the contribution here would be because (it seems like) no one has done this before rather than because it is so interesting."
            },
            "questions": {
                "value": "Is there anything in my assessment you disagree with?\n\nHave you considered putting your approach into a popular package so that researchers can quickly and easily compare their models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697817956449,
        "cdate": 1697817956449,
        "tmdate": 1700686272337,
        "mdate": 1700686272337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4LGyD8ke3u",
        "forum": "jr03SfWsBS",
        "replyto": "jr03SfWsBS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
        ],
        "content": {
            "summary": {
                "value": "This work performs an extensive benchmark for 1000 models to compare the error rate disparity and accuracy trade-offs. To make a fair comparison, the constrained models, either trained with pre-processing techniques or in-processing learning constraints, are unprocessed to yield the corresponding optimal unconstrained model. Through these assessments, the authors convey a straightforward yet crucial finding: achieving fairness is best attained by training the most effective unconstrained model available and subsequently employing post-processing techniques to fine-tune the thresholds."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- I like the way the authors pose the narrative of this work. The structure is well-defined, presenting experimental details clearly. \n-  I think the concept of \"unprocessing\" is a novel and effective method to discover the optimal unconstrained model corresponding to the constrained models.\n- In general, the evaluation is solid and can provide enough insights to the practitioners.\n- In my personal opinion, this paper satisfies my standard of acceptance but does not reach the rating of 8. So I would rather recommend a rating of 6."
            },
            "weaknesses": {
                "value": "- I would like to see a comparison between the real unconstrained model and the unprocessed version of the constrained model. This comparison is necessary and could enhance the claim that unprocessing can be applied to find the optimal unconstrained model.\n- Section 4 is just a standard LP problem in solving Equal Odds with post-processing. It is not novel and there is no need to write down it in the main paper.\n- The author has admitted that their evaluation is only applied to tabular data, with a focus on 5 different partitions of the FolkTables dataset. It would be interesting to see how the conclusions can still be generalized to tasks with rich representations."
            },
            "questions": {
                "value": "- How efficient is it to solve the LP problem? Can I just exhaustively search all the combinations of the thresholds and plot the Pareto frontiers of the fairness-accuracy trade-offs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698629452985,
        "cdate": 1698629452985,
        "tmdate": 1699635954755,
        "mdate": 1699635954755,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Y3RxJ9zg4F",
        "forum": "jr03SfWsBS",
        "replyto": "jr03SfWsBS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
        ],
        "content": {
            "summary": {
                "value": "There have been many proposals in the recent literature to train fair ML models. This paper evaluates thousands of such models, and finds that a simple postprocessing technique achieves the fairness-accuracy Pareto frontier."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "This type of comprehensive benchmarking of thousands of models adds a ton of value to the algorithmic fairness literature. I think the result that a simple postprocessing step achieves the Pareo frontier is very significant. I applaud the authors for taking on this task."
            },
            "weaknesses": {
                "value": "None"
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806868067,
        "cdate": 1698806868067,
        "tmdate": 1699635954687,
        "mdate": 1699635954687,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ngmy5jMDXK",
        "forum": "jr03SfWsBS",
        "replyto": "jr03SfWsBS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the relation fairness-accuracy tradeoff. In particular, the paper considers the relation between fairness (in terms of Equalized Odds) violation and accuracy of the predictor, before and after \"unprocessing\", and claims based on empirical observations that any Pareto-optimal tradeoff between accuracy and empirical EOdds violation can be achieved by postprocessing.\n\n---\n\n**Post-rebuttal**\n\nThe authors claim that Theorem 5.6 of Hardt et al. (2016) strengthens the result of empirical studies considered in the work. It would be helpful if such discussion can be incorporated in the manuscript to help readers understand this connection. After engaging with authors and going through comments by other reviewers, I have increased my evaluation from 5 to 6."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strength of the paper comes from the extensive empirical experiments and the efforts to present the observation (that Pareto-optimal tradeoff can potentially be achieved by postprocessing. The experiments are conducted on a relatively new data set (compared to standard baseline data sets in the literature), and the setup includes exact and relaxed EOdds (Hardt et al., 2016)."
            },
            "weaknesses": {
                "value": "The weakness of the paper comes from the lack of a certain level of theoretical derivation to justify the empirical findings. The proposed term \"unprocessing\", as noted by authors, \"roughly corresponds to the inverse of postprocessing\", is more of less confusing (for reasons detailed in Section __Questions__). While one can observe from extensive empirical evaluations that Pareto-optimal tradeoffs can be achieved (setting aside numerical indeterminacy), there is a worry that the results can only provide limited insight regarding the not-clearly-motivated unprocessing procedure."
            },
            "questions": {
                "value": "__Question 1__: what is the exact relation between unprocessing and postprocessing?\n\nBased on Hardt et al. (2016), the postprocessing strategy for EOdds is trading off True Positive Rates (TPRs) and False Positive Rates (FPRs) across different demographic groups. Such procedure is _oblivious_, in the sense that only the joint distribution $(A, Y, \\hat{Y})$ are utilized in the postprocessing procedure. If this specific way of postprocessing is of interest in the paper, I am not sure how to understand the relation between unprocessing and postprocessing. I can see why authors draw an analogy between unprocessing and the inverse of postprocessing. According to Equation 1, unprocessing starts from the postprocessed $\\hat{Y}$ and aims to find the unconstrained optimized predictor. How can we do that with obliviously postprocessed $\\hat{Y}$? How to make sure the unprocessed predictor has a sensible mapping from input features to target variable?\n\n\n\n__Question 2__: regarding the claim that _any_ Pareto-optimal tradeoff can be achieved by postprocessing\n\nFollow up to Question 1, if the postprocessing is defined as in Hardt et al. (2016), it would be very helpful if authors can provide a clear characterization of the relation between unprocessing and such definition of postprocessing, so that readers can understand why unprocessing is a helpful analyzing tool to understand the importance of postprocessing. Empirical evaluations can be strengthened by some certain level of theoretical analysis to make the results and message more convincing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698863650769,
        "cdate": 1698863650769,
        "tmdate": 1701010814218,
        "mdate": 1701010814218,
        "license": "CC BY 4.0",
        "version": 2
    }
]