[
    {
        "id": "LE5TFQUpP6",
        "forum": "bLpUtGyf9g",
        "replyto": "bLpUtGyf9g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_61UD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_61UD"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for boundary denoising to tackle video activity localization. A model architecture DenoiseLoc is proposed, together with a boundary denoising training method. The authors argue that a single step denoising is better than the diffusion process with multiple steps. Experiments show some improvement over the previous state-of-the-art."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The experimental results show some improvements over the previous state-of-the-art."
            },
            "weaknesses": {
                "value": "Most importantly, the method part is not clear. It is rather hard to follow through most of the written parts. Figure 2\u2019s caption also does not provide a clear overview of the proposed method and the novel aspects.\n\n\nIn Figure 2, it is rather confusing what the pipeline actually is. For instance, the ground truth span/noise injection part should definitely not be part of the inference pipeline. So, it is not clear what is done during the inference process.\n\n\nSuddenly, in 3.2.2, the dynamic convolution is used without much explanation. Why is it important to the proposed design? What is the dynamic convolution exactly doing, and why no other design can be used? It is not well motivated.\n\n\nThe boundary denoising training part in 3.2.3 is not clear at all. How the method works, what loss is used, where the loss is applied, and why it is designed this way is not clear. Why do we need to divide into two different groups? How does the model use both of them during training?\n\nImportantly, since boundary denoising has been widely explored, what are the further insights that make the proposed method more effective than previous works? This has not been clearly expressed.\n\n\n\n\nExperimentally, there are also some parts not well established.\n\nMost importantly, it is very strange to me why adding diffusion will lead to performance drops. Furthermore, the more steps used, the worse the performance seems to get. This is totally different from what is usually observed in many diffusion-based works (for generation and for prediction tasks). Usually, the benefit of using a single step is only for efficiency purposes. Furthermore, the given reason is also not convincing. It would be good if the authors provide a lot more details about how diffusion is used, and more qualitative/quantitative evidence to substantiate this claim, since it is quite a strong and counterintuitive claim.\n\n\nIt seems that more ablations are required for various designs, for example the various designs in denoising training. But, currently the method is too unclear for me to suggest concrete settings.\n\n\n\n\n\n\n\nNote that there are some mistakes with the spelling/formatting. This does not affect the score. Some examples are:\n\nPg 2 bottom: citation formats are mixed up, and all the authors of the papers are listed in the citation.\nPg 1 and Pg 2: \u201cQV-Hightlights\u201d\nPg 9: \u201cprediction the denoised proposal\u201d, \u201cmore discussion\u201d\n\nThroughout, please standardize as DenoiseLoc (instead of denoiseloc at several parts)."
            },
            "questions": {
                "value": "Apart from the above concerns, some other specific questions are below.\n\n\n1)\tCould the authors provide the time gains from using a single denoising step against multiple?\n2)\tCould the authors provide the model size and time gains as compared to previous state-of-the-art methods?\n3)\tIn table 4, when the dB measure for noise is used, what exactly does it mean in this context?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698250675033,
        "cdate": 1698250675033,
        "tmdate": 1699636726712,
        "mdate": 1699636726712,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bgCHdp7bsJ",
        "forum": "bLpUtGyf9g",
        "replyto": "bLpUtGyf9g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_6dfr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_6dfr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed an encoder-decoder model, namely DenoiseLoc, for video activity localization. DenoiseLoc introduces a boundary-denoising paradigm to address the challenge of uncertain action boundaries. DenoiseLoc leverages across modalities in the encoder and progressively refines learnable proposals and noisy ground truth spans in decoder layers. Extensive experiments on standard benchmarks demonstrate the effectiveness of the proposed DenoiseLoc."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- A novel boundary-denoising paradigm is proposed to address the challenge of uncertain action boundaries in video activity localization task.\n- Extensive experiments on standard benchmarks demonstrate the effectiveness of the proposed DenoiseLoc.\n- It is interesting to find that satisfactory performance can be achieved with very few proposals and very few denoising steps."
            },
            "weaknesses": {
                "value": "-  Lack of visual analysis. It would be helpful to understand the properties of the proposed method if some cases can be visually analyzed.\n- \"DenoiseLoc\" and \"denoiseloc\" are used interchangeably, which confuses readers. It is recommended that all be changed to \"DenoiseLoc\"."
            },
            "questions": {
                "value": "Please refer to Weaknesses for more details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698421603641,
        "cdate": 1698421603641,
        "tmdate": 1699636726572,
        "mdate": 1699636726572,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JCgigvMzWM",
        "forum": "bLpUtGyf9g",
        "replyto": "bLpUtGyf9g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_uvci"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_uvci"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles an important and common challenge of boundary ambiguity in the video action localization task. The authors adopt the encoder-decoder framework as DETR for embedding video/caption features and predicting the boundary locations. The proposed denoiseloc aims at regress more precise boundaries by noise injection. Extensive experiments to demonstrate the effectiveness of denoiseloc."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The inspiration of boundary-denoising training approach has good novelty.\n+ This paper is well-organized and the proposed method achieves good performance."
            },
            "weaknesses": {
                "value": "- This paper uses a complex symbol system, which makes it difficult to read. \\epsilon presents the number of fixed consecutive frames and then it presents a vector of a span. n, which represents a quantitative index, is sometimes a subscript and sometimes a superscript.\n- The process of denoising is unclear. Which loss function is used for boundary denoising? The core technology is a proposal augmentation strategy to obtain more candidate proposals for training?\n- Missing related works of boundary ambiguity and temporal grounding.\n\nWang Z, Gao Z, Wang L, et al. Boundary-aware cascade networks for temporal action segmentation[C]. ECCV2020.\n\nXia K, Wang L, Zhou S, et al. Learning to refactor action and co-occurrence features for temporal action localization[C]. CVPR2022.\n- Typo. L5 of Sec. 3.2."
            },
            "questions": {
                "value": "- What is the definition of an action span or temporal span?\n- What do 0.25 and 0.75 mean in the Sec. 3.2.3? Negative proposal set is from the inside or outside of the ground truth?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6486/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6486/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6486/Reviewer_uvci"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698475156138,
        "cdate": 1698475156138,
        "tmdate": 1700738230217,
        "mdate": 1700738230217,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "T1qRy9Ldsf",
        "forum": "bLpUtGyf9g",
        "replyto": "bLpUtGyf9g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_UMQX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6486/Reviewer_UMQX"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles the problem of video activity localization, specifically given language descriptions. The main challenge of this task is boundary ambiguity caused by the annotator subjectivity and the smoothness of temporal events. To this end, the authors design a novel framework, named denoiseloc, aiming to progressively refine the moment predictions. To facilitate the model training, boundary-denoising training scheme is adopted, which encourages the decoder to reconstruct ground truths from the noisy moments. In the experiments on two benchmarks, MAD and QVHighlights, the effectiveness of the proposed method is validated."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper is well-written and easy to follow with good readability.\n+ The figures well represent the proposed method, helping the understanding.\n+ The proposed approach surpasses the strong competitors on both benchmarks.\n+ The comparison between Denoiseloc and Diffuseloc is interesting, and brings valuable insights."
            },
            "weaknesses": {
                "value": "- Some important details of the method are missing. In its current form, the information about the model is insufficient in the manuscript.\n\n(1) DETR-like approaches conventionally adopt the moment representation of (center, width). In contrast, the authors stated that they express a moment as start and end. In this case, the start position can be predicted as a larger value than the end position. How do the authors handle this?\n\n(2) The details of temporal ROI alignment and DynamicConv layer are missing. I would like to suggest the authors to include graphical illustrations of these operations at least in the appendix for help the understanding.\n\n(3) In the boundary-denoising process, the model generates two types of noise-injected proposals, i.e., positive and negative sets. To my understanding, the proposals in the positive set have their corresponding ground truths by design, so the model learns to recover the ground-truth moments from them. However, there is a lack of explanations about the role of the proposals in the negative set. Are they also used to recover ground truths? Or do they serve as negative samples for classification? If the former is the case, how is the matching performed? In addition, what happens if they overlap with ground truths? Will it disturb the training?\n\n- The comparisons with existing DETR-approaches seem not fair. To my knowledge, the DETR-based approaches (e.g., Moment-DETR and UMT) leverage four encoder layers and two decoder layers with a total of 10 queries on QVHighlights. On the other hand, the proposed architecture utilizes (at most) four times more encoder/decoder layers than those of the competitors, and three times more moment queries than those of the competitors. This makes it unclear whether the performance gains come from increased parameters or the proposed algorithm, and it is highly encouraged to perform comparisons under the same setting. In addition, comparisons on the computational cost and the memory consumption will be beneficial. Meanwhile, one of the state-of-the-art method, QD-DETR [1], is missing in the comparison table. If included, the proposed method shows inferior performances even with more layers and more queries.\n\n[1] Moon et al., \u201cQuery-Dependent Video Representation for Moment Retrieval and Highlight Detection\u201d, CVPR, 2023."
            },
            "questions": {
                "value": "Please refer to the Weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6486/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6486/Reviewer_UMQX",
                    "ICLR.cc/2024/Conference/Submission6486/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698839780699,
        "cdate": 1698839780699,
        "tmdate": 1700733881569,
        "mdate": 1700733881569,
        "license": "CC BY 4.0",
        "version": 2
    }
]