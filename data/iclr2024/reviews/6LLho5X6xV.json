[
    {
        "id": "PTOvHDjbcQ",
        "forum": "6LLho5X6xV",
        "replyto": "6LLho5X6xV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_KBNh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_KBNh"
        ],
        "content": {
            "summary": {
                "value": "The paper delves into the application of large language models (LLM) to tabular data, presenting a novel approach utilizing the transformer model.\n\nTo address the unique characteristics of tabular data, the authors introduce \"TabUnit\", a method to amalgamate data type, column name, and cell values into comprehensive cell vectors. These vectors are then processed through transformer-based encoders and fed into a shallow LSTM decoder to regenerate tokens for the target label column.\n\nUpon pre-training the UniTabE model using 13B samples from Kaggle, the authors fine-tuned it on 12 chosen classification and evaluation datasets. The results reveal a significant improvement over prior methods that lack pre-training."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Quality:\nThe paper's quality stands out as it presents a model pre-trained on an impressively large tabular prediction dataset encompassing 13B samples. The authors conducted a meticulous evaluation of the model with contemporary tabular prediction baselines.\n\n2. Significance:\nThe results offered by the authors are particularly enlightening. While they tout the enhanced performance derived from pre-training on expansive tabular data, a closer examination (as reflected in Table 3) indicates only a slight uplift in downstream task performance post-fine-tuning, especially given the model's exposure to 13B samples. This subtle observation underscores the intricate challenges posed by tabular data prediction, taking into account its inherent heterogeneity and noise. It's pivotal to recognize that these findings could potentially delineate a performance benchmark for similar BERT-inspired methods in tabular prediction. This could galvanize researchers to delve deeper into innovative tabular modeling paradigms and re-evaluate data processing strategies for tabular prediction."
            },
            "weaknesses": {
                "value": "1. Evaluation:\nGiven the vastness of the training data, with 13B samples spanning 303 diverse domains, the evaluation datasets chosen seem somewhat narrow in scope. The comprehensive variety of training domains calls for an equivalently diverse evaluation to genuinely test the model's versatility and adaptability. Authors should consider widening their evaluation scope by leveraging an even more diverse array of tabular datasets.\n\n2. Results:\nWhile Table 3 does indicate that UniTabE marginally outperforms other baselines, the incremental gain appears to be disproportionate to the extensive computational overhead of the pre-training phase. It's noteworthy that the performance between a ground-up UniTabE (from scratch) and a pre-trained plus fine-tuned UniTabE are remarkably similar, prompting questions about the efficiency of the elaborate pre-training process.\n\n3. Method:\nThe paper's tab unit processing technique, although novel in its implementation, seems to draw heavily from precedents like TransTab and FT-Transformer. Additionally, the supervised strategies, such as multi-cell masking and contrastive learning, bear significant resemblance to methodologies detailed in prior research."
            },
            "questions": {
                "value": "1. Table 3 Variants:\nThe descriptions of the three UniTabE variants presented in Table 3\u2014namely scratch, +XGBOOST, and fine-tune\u2014appear to be absent. Notably, UniTabE scratch seems to rival the performance of UniTabE fine-tune and even surpasses UniTabE+XGBOOST in many instances. Given that UniTabE has been exposed to 13B tabular samples, this outcome raises questions. What factors might account for this similarity in performance, especially between the scratch and fine-tuned versions? Moreover, would broadening the evaluation across a more diverse set of datasets provide deeper insights into the tangible benefits of UniTabE pre-training?\n\n2. Llama2 13B Training:\nRegarding Llama2's tabular prediction training, how exactly was the model trained to handle tabular data predictions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7524/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698086990321,
        "cdate": 1698086990321,
        "tmdate": 1699636908914,
        "mdate": 1699636908914,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BTQIIV4rr8",
        "forum": "6LLho5X6xV",
        "replyto": "6LLho5X6xV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_es5d"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_es5d"
        ],
        "content": {
            "summary": {
                "value": "This paper presents UniTabE - a universal pretraining method for tabular data that consists of three components: tabular unit decomposition, encoding, and decoding. Compared to prior work, a key novelty of this model is that it is trained from scratch, and it involves innovations in terms of developing a TabUnit splitter and a simple decoder. The compilation of a large dataset for model training is also an interesting undertaking. The evaluation section provides a large number of experiments, showing the improvement brought by UniTabE on fine-tuned and zero-shot classification, regression tasks, and missing data prediction, whereas a series of ablations show the benefit of each aspect of the method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1) The paper is well-written and easy to follow. It provides information that should suffice to reproduce the presented method.\n\nS2) The methodological contributions are clearly indicated and well-justified by the paper. \n\nS3) The paper contributes a novel dataset and set of models, that should be interesting to practitioners working with tables.\n\nS4) The experimental section shows the benefit of this method against competitive baselines. Ablation studies are provided to ensure that the improvement comes from the expected method components.\n\nS5) To my knowledge, the undertaking to create such a foundational model for tables is novel. I agree with the authors that it can be very impactful given the amount of tabular data online."
            },
            "weaknesses": {
                "value": "W1) The paper lacks a discussion of the ethical and legal aspects of the data, including biases, copyright, and licensing.\n\nW2) The proposed method has a strong performance against the baselines consistently, but the baseline choices are inconsistent across the experiments. Can the authors motivate the reason for selecting certain baselines for each experiment, especially for Tables 4 and 5?\n\nW3) The paper talks about generalization to tables with more columns, but the generalization to tables with more complicated structures (e.g., multi-row and multi-column blocks) is not discussed. I am wondering how are such tables handled by the UniTabE.\n\nMinor:\n* Figure 3a is impossible to read - please enlarge the figure for the follow-up version, and ideally provide more guidance/commentary about it in the paper.\n* Typo: \"Expect for \" -> \"Except for\"\n* The commentary of Table 3 (page 9) is unclear, as it refers to \"a slight performance enhancement\", even though the two versions seem to perform more-or-less on par."
            },
            "questions": {
                "value": "Q1) Given that a pretty large amount of data from Kaggle is used for pretraining of UniTabE, I would appreciate it if the authors could comment on the aspect of data licensing, copyright, and ethics of use. Also, what would the use of this model as a foundational model for tables entail given the specific tables used for pretraining?\n\nQ2) Can the authors motivate the reason for selecting certain baselines for each experiment, especially for tables 4 and 5?\n\nQ3) How does UniTabE handle tables with more complicated structures, where the organization of columns and rows is less obvious?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Given that the authors use a large amount of data from Kaggle, I was surprised to not see any discussion on the licensing, ethics of use, and copyright of this data. I would appreciate it if the authors could clarify this aspect."
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7524/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7524/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7524/Reviewer_es5d"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7524/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767894817,
        "cdate": 1698767894817,
        "tmdate": 1699636908759,
        "mdate": 1699636908759,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yQ8kn72mof",
        "forum": "6LLho5X6xV",
        "replyto": "6LLho5X6xV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_3wag"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7524/Reviewer_3wag"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a transformer model for table classification and regression. The authors curated a large set of Kaggle datasets for training and evaluation. The central component of the proposed architecture is the TabUnit, which embeds data type, column name and column value respectively, and fuses as well as links the embeddings via gates. The authors propose to use a Transformer encoder and LSTM as decoder. The model is pre-trained by different strategies, namely cell and column masking and siamese triplet loss based on (partial-) row contents. Fine-tuning then entails predicting missing columns for a new dataset specialisied prompts for tasks such as question answering. The authors trained the Transformer on a self-collected dataset comprising 13 billion tables. The approach is evaluated for standard, fine-tuned as well as combined version (with XGBoost). Part of the evaluation is done for Kaggel tasks (12), where the approach is compared to XGBoost and TransTab. The rest of the evaluation is performed for 7 public datasets, where a larger amount of competitors is compared against. The results show that the proposed approach often achieves superior performance in terms of AUC/R2. In addition, multiple ablation studies also highlight, among others, robustness of the approach towards missing data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The chosen topic of the paper is highly relevant to the venue, as tabular machine learning is, as argued in the paper, often overlooked but highly important in industrial applications.\n\nThe proposed approach to learn designated embeddings for data type, column name and values within the TabUnit is sensible and is different to existing approaches. In addition, the authors collect a large dataset for training their Transformer. It would be value adding to open-source such a model.\n\nThe work incorporates a large number of competitors in part of the evaluation (on open datasets): The authors include more than 10 baseline approaches of recent papers to compare the performance of their approach on a selected sample of open datasets. The chosen baselines, here, are well-chosen. The authors also provide ablation studies wrt to ther model design, highlighting the implications of omitting parts of the architecture. Lastly, the predictive performance of the approach is often better than the competitors."
            },
            "weaknesses": {
                "value": "It is unclear why only part of the evaluation was done for all Transformer-based competitors and why no regression results for a XGBoost regressor have been generated. It would have been highly insightful to have the same evaluation as for the open datasets.\n\nIt would also have been insightful to compare to a representative AutoML approach in order to see the boundaries of the approach. Of course, it does not have to be assumed that the model has to beat the best tuned models, but it should come close enough. \n\nWhile the results are promising, the gap between the competitors is often rather small. This is not to reduce the quality of the predictive performance, as the task at hand is very difficult and competitive, it just shows that competitors are already strong. \n\nWhile part of the evaluation is exhaustive in terms of baseline approaches, the evaluation contains relatively little open datasets compared to some of the competing papers. It would be beneficial to add more thorough design decisions to why the datasets have been chosen or why they are sufficiently representative.\n\nThe ablation study with respect to robustness is very interesting and highlights another benefit of the method - being able to deal with missing data. It would be intersting to know if this result holds over the other competitors too.\n\nA minor point (as many competitors were looked at): It would have intersting to see the performance of TUTA, as similar to the proposed approach, more refined embeddings are learned."
            },
            "questions": {
                "value": "Will get code / the trained model be made available?\n\nWhy was the evaluation only in part conducted with all competitors?\n\nWhat are the most challenging datasets you tested the method on?\n\nWhat are other advantages of the proposed approach next to pure predictive performance? Is the method's robustness superior to the other competitors as well?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7524/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835605866,
        "cdate": 1698835605866,
        "tmdate": 1699636908659,
        "mdate": 1699636908659,
        "license": "CC BY 4.0",
        "version": 2
    }
]