[
    {
        "id": "NnDY3zZIXH",
        "forum": "mavWQw7DnC",
        "replyto": "mavWQw7DnC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the interpretability problem \u201cbecause the user interacted with item $j$, we recommend item $i$ to the user\u201d in a factorization model commonly used in recommender systems. From the perspective of contrapositive logit (\u201cbecause the user did not interact with item $j$, we did not recommend item $i$ to the user\u201d), this paper proposes a new explanation algorithm (Contra+) consisting of two steps: (1) perturbing the user embedding to ensure item $i$ is not recommended; (2) given the perturbed user embedding, identifying the historical items that have lost most relevance to the user. Overall, the proposed algorithm is interesting but is more empirical and lacks theoretical guarantees."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. the writing is well and the presentation is clear.\n\n2. the topic is interesting."
            },
            "weaknesses": {
                "value": "1. the proposed method is more empirical and lacks theoretical guarantees (see main question 1 for more details).\n\n2. something about the key logic of the algorithm is not clearly explained (see main question 2 for more details)."
            },
            "questions": {
                "value": "**Main Questions**\n\n1.\tthe perspective of contrapositive logit is not fully novel. In fact, Pearl (1999)[1] defined the notation of **probability of necessary causation**, which follows the same logic as contrapositive. There may be some connection between the probability of necessary causation and the method proposed in this paper. Linking the method proposed in this paper with the necessary causality probability may provide a theoretical guarantee for the method proposed in this paper. Could you discuss something about the possible connections?\n\n2.\tHere are some questions about the key logic of the proposed method.\n\n>(1) In terms of the perturbation, (a) Why only the user embedding is perturbed and not the item embedding? It is a bit confusing to me. intuitively, the user after the perturbation is no longer the same user before. (b) Do all user-item pairs, using the same strength ($\\gamma$ and $\\epsilon$ in equation (4)) of perturbation? (c) How to choose the parameters $\\gamma$ and $\\epsilon$ in practical applications?\n\n>(2) For step 2, i.e., identifying the historical items that have lost most relevance to the user. Why the historical items that have lost the most relevance to the new perturbed user embedding is the explanation? Is it equivalent to the statement \u201cbecause the user did not interact with item $j$, we did not recommend item $i$ to the user\u201d? \n\n[1] Judea Pearl (1999), Probabilities of causation: three counterfactual interpretations and their identification.\n\n\n**Minor Questions**\n\n(1)\tThere are some problems with the format of the citation. For example, at the end of the first paragraph in the Introduction, the citation format should appear as (Lu et al., 2012; Aggarwal et al., 2016; Beel et al., 2016; Jannach et al., 2022), which can be generated using the \\citep{XXX} command.\n\n(2)\tThere are some grammatical errors. For example, at the end of the Abstract, \u201c\u2026 because the user did not **interacted** with item $j$ \u2026.\u201d should be  \u201c\u2026 because the user did not **interact** with item $j$ \u2026.\u201d."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743664205,
        "cdate": 1698743664205,
        "tmdate": 1699636569636,
        "mdate": 1699636569636,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZfZwbc8ijP",
        "forum": "mavWQw7DnC",
        "replyto": "mavWQw7DnC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
        ],
        "content": {
            "summary": {
                "value": "This paper is trying to address the challenge of explaining recommendations, which is meaningful and important because recommender systems like factorization models based or neural network based are lack of transparency. The paper introduces a novel approach called \"contrapositive explanations (Contra+)\" to provide clear and efficient explanations for recommendations. Contra+ focuses on finding explanations in the form of \"Because the user interacted with item j, we recommend item i to the user.\" This is in contrast to traditional counterfactual explanations, which aim to explain why an item was not recommended. This paper provides detailed discussion for previous methods, many toy examples and figures to make the concepts easier for readers to understand. Finally, the authors demonstrate the effectiveness and efficiency of Contra+ through empirical experiments on real-world datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1: This paper considers a interesting questions (explaining recommendation system) from a contrapositive perspective, which is novel.\n\nS2: This paper provides detailed discussion for previous methods, many toy examples and figures to make the concepts easier for readers to understand.\n\nS3: This paper gives a comprehensive review of differences and similarities between contrapositive and counterfactual explanations."
            },
            "weaknesses": {
                "value": "W1: The key concern is whether there is another way to get the \"explanation\". Further, is there infinite number of ways to perturbation the embedding that can achieve the same purpose, i.e., \"We did not recommend item i to user u\"? In such case, does each way of perturbing embedding correspond to a different h, i.e., \"User u would not have interacted with item h\"? How can we distinguish merits and drawbacks of each perturbation?\n\nW2: Previous literature like Tan et al. [1], studied cause on a particular aspect, i.e., If the item had been slightly worse on [aspect(s)], then it will not be recommended. This can find the cause on a particular aspect, whereas in this paper, the cause is found on perturbation on all embedding. Is any comments for the difference?\n\nW3: The authors give a lot of toy examples, such as rain and slippery roads, or godfather and godfather 2. Can some experiments be added to give some examples of real world datasets where the proposed method finds an explanation? For example, in Netflix or ML-1M, are there any cases where users don't interact with \"computer\" because \"cell phone\" is not suggested?\n\nW4: Counterfactual explanations don't necessarily guarantee removing the explanation or changing the recommendation. Therefore, in figure 1, counterfactual explanations should be 1 as a proportion of all areas, that is, 1/(1+2+3+4), not 1/(1+2).\n\nW5: The experiment process is Evaluations part is not so clear. For example, why is $M_{contra}$ greater than 1? In addition, consider doing some runtime experiments and some other hyper-parameter sensitivity analysis or in-depth analysis like the effect of varying total amount data could be better.\n\n[1] Juntao Tan, Shuyuan Xu, Yingqiang Ge, Yunqi Li, Xu Chen, and Yongfeng Zhang. Counterfactual explainable recommendation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pp. 1784\u20131793, 2021"
            },
            "questions": {
                "value": "Please refer to the weaknesses part for the questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698838035856,
        "cdate": 1698838035856,
        "tmdate": 1699636569546,
        "mdate": 1699636569546,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mYrPXF3Szv",
        "forum": "mavWQw7DnC",
        "replyto": "mavWQw7DnC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_5dmR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5544/Reviewer_5dmR"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an interesting explanation method to explain recommendation systems through contrapositive perturbations, leveraging the key insight that (negation of B => negation of A) and (A=>B) are equivalent . The proposed method is computational efficient to SVD and MLP-based recommender systems. Lastly, the paper evaluates the approach against benchmarks on several datasets to demonstrate its effectiveness and efficiency in explanations. \n\nThe approach seems novel and interesting but have some questions and concerns on the experimentation session.  Mostly concern if the paper is comparing to the compelling baselines, and M_contra seems to on part to \"influence\" functions in some datasets:\nQ1: do we have compelling baselines to compare against? The reason asked is because if we comparing item similarity and influence comparing to random, they seem to be not very statistically different in M_contra in many cases (i.,e, Figure 2 on Dimension 32 for # of expl Q2:  in Figure 4, it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected?"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper proposes an interesting explanation method to explain recommendation systems through contrapositive perturbations, leveraging the key insight that (negation of B => negation of A) and (A=>B) are equivalent . The proposed method is computational efficient to SVD and MLP-based recommender systems. Lastly, the paper evaluates the approach against benchmarks on several datasets to demonstrate its effectiveness and efficiency in explanations."
            },
            "weaknesses": {
                "value": "Mostly have some concern and/or questions on the Experiment session if the paper is comparing to the compelling baselines. \nQ1: do we have compelling baselines to compare against? The reason asked is because if we comparing item similarity and influence comparing to random, they seem to be not very statistically different in M_contra in many cases (i.,e, Figure 2 on Dimension 32 for # of expl Q2:  in Figure 4, it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected?"
            },
            "questions": {
                "value": "Mostly have some concern and/or questions on the Experiment session to prove out on the claims. \nQ1: in Figure (2) and (3), as the number pf experiments increase, in particular at 5, it seems that the contrapositive approach is non-stats sign from other baselines, especially Item Similarity or Influence. Was this the expected behavior?  \nQ2: in Figure 4,  it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699274175477,
        "cdate": 1699274175477,
        "tmdate": 1699636569451,
        "mdate": 1699636569451,
        "license": "CC BY 4.0",
        "version": 2
    }
]