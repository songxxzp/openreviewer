[
    {
        "id": "SANkVZSPin",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_1YJJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_1YJJ"
        ],
        "forum": "bWzxhtl1HP",
        "replyto": "bWzxhtl1HP",
        "content": {
            "summary": {
                "value": "I was one of the reviewers for this paper for NeurIPS 2023, I have carefully revisited the paper again for the ICLR submission, and write my new reviews as below.\n\nThis paper studies unsupervised representation learning with generative diffusion probabilistic models with specific exploration of the diffusion steps. The main research idea originates from the observation/assumption that image attributes are gradually lost along the diffusion process with increasing levels of Gaussian noises. The authors propose DiTi (named after Diffusion Time-step) to learn a step-specific feature to capture the information of lost attributes, and then leverage this feature of modular attributes as the inductive bias for unsupervised learning. Experimental tests of the feature are conducted on two settings, namely the attribute classification and counterfactual generation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper elaborates well on the concept of attribute loss, which is the fundamental observation for the proposed DiTi method, and is in general easy to follow.\n\n- The idea to learn a step specific feature to encode the lost attribute information as the inductive bias for unsupervised learning is reasonable and intuitive.\n\n- Experimental results show improvement over several baseline methods on CelebA, FFHQ and LSUN-Bedroom datasets.\n\n- Compared to the previous manuscript from NeurIPS, it seems that the authors have incorporated the comparison of the proposed work with several existing works that touch on the representation learning with DMs, which helps to clarify the differences between this paper and existing literature (but this part is also a little biased, as specified below)."
            },
            "weaknesses": {
                "value": "Since this is my second time reviewing this paper, I think most of my questions concerning the technical details have been resolved and clarified. While I acknowledge that the paper is well-written and has its merits to enlighten the studies of combining representation learning and diffusion models, there are a few of my concerns.\n\n- First, I echo with my previous NeurIPS reviewers folks on the concern: whether it is the direct direction to actually integrate DMs into the current representation learning paradigm? Based on our previous discussions, the proposed method has a higher computational/time cost compared to its contrastive counterparts. And if the argument here is because the contrastive paradigms lose attribute information, then it seems to me the proposed DiTi may not be the optimal method to introduce the attribute inductive bias.\n \n- Second, in the related work section, the authors include a comparison with the current DM for representation learning methods. I find this new part slightly biased, because the approaches in 2) and 3) are not really proposed under the context of representation learning. For instance, (Kwon et al., 2022) proposed the bottleneck feature of the U-Net under the context of image editing; similar to (Preechakul et al., 2022), in which separate autoencoders are learned to achieve editing purposes. I think while these works do touch the latent features/attributes in DMs, they tackle different scenarios other than representation learning. In other words, the first concern is not resolved by comparing these works.\n\n- Going towards the technical level, one concern (less urgent in my sense) is that the proposed DiTi method shares quite similarities with PDAE, with the main difference in the disentanglement, with the cost of more hyper-parameters."
            },
            "questions": {
                "value": "In general, I don\u2019t have specific questions to ask at this time and still have mixed feelings as in my first-time review of this work. I think this paper has its own merits/advantages and drawbacks/disadvantages at the same time, and thus keep my tentative rating as borderline but will update it according to other reviewers and further discussions later."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Reviewer_1YJJ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3386/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697298968310,
        "cdate": 1697298968310,
        "tmdate": 1699636289501,
        "mdate": 1699636289501,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5FPxJglnen",
        "forum": "bWzxhtl1HP",
        "replyto": "bWzxhtl1HP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_5NeX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_5NeX"
        ],
        "content": {
            "summary": {
                "value": "This work proposes DiTi, a method that learns disentangled representations in an unsupervised fashion. The work first provides insights into the inductive bias of Denoising Diffusion Probabilistic Models that can be leveraged for learning decoupled features, with theoretical grounding. Then the work proposes to leverage the inherent connection between timesteps and modular attributes to learn a set of features from the residuals. Finally, the feature can be used for both downstream inference (e.g., attribute prediction) and counterfactual generation, surpassing prior works in both tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* This work provides a link between the timesteps and the modular attributes with an intuitive explanation and theoretical proof.\n* This work proposes a simple yet effective approach to learn disentangled features along with the diffusion model training that follows from the discoveries during the analysis.\n* This work outperforms previous unsupervised feature learning methods that do not disentangle the features on attribute classification tasks. This work also shows higher-quality counterfactual generations compared to previous works."
            },
            "weaknesses": {
                "value": "* This work trains models from scratch. Due to the introduced term for disentangled feature learning, the model needs to be re-trained.\n* The authors only evaluated the proposed method with datasets that are domain-specific (e.g., CelebA, FFHQ). The method has not been evaluated on large models trained on more diverse and general image datasets (e.g., LAION). Therefore, it does not indicate whether the method can scale to more complicated settings."
            },
            "questions": {
                "value": "* Do the subsets have to be uniform? Does it benefit the method if we have more features for coarser or finer features?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3386/Reviewer_5NeX"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3386/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698689468726,
        "cdate": 1698689468726,
        "tmdate": 1699636289428,
        "mdate": 1699636289428,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tYVF71pa8c",
        "forum": "bWzxhtl1HP",
        "replyto": "bWzxhtl1HP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_Cjby"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_Cjby"
        ],
        "content": {
            "summary": {
                "value": "This work aims to disentangle the modular attributes in the DDPM framework by exploiting the granularity of feature details at different time steps of the diffusion models. The work finds that the fine feature components are encoded in the earlier time steps of the forward diffusion process while the coarse details are at the later time steps. A encoder decoder approach with partitioned features  at different time steps are proposed to allow for disentangled representations. Experiments are performed on bedroom, CelebA and FFHQ datasets where the method outperforms prior art."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The paper is well-written and easy to read. The motivation of the work related to learning the disentangled modular attributes in diffusion models is promising. Claims are supported with theoretical reasoning. \n\n+ The experiments are performed on different face datasets such as CelebA, FFHQ, and the Bedrooms dataset. The approach outperforms prior work on metrics such as AP, Pearson-r, and MSE. \n\n+ Ablations are provided regarding the choice of partitioning and optimization strategies."
            },
            "weaknesses": {
                "value": "- The qualitative results shown in figure 5 do not show consistent improvements wrt to modular editing. In the second row, for example, the eyeglasses appear in the middle range and disappears again in the final ranges.  Are the time steps plotted in a cumulative fashion within the  early/middle/late \u201ct\u201d range. \n\n- On the use of timesteps [100-300] and it corresponding to the maximum value of the loss: One would expect the loss to be greater at the later stages when the image becomes complete noise. Eg: it should be difficult to construct image from t =1000 to t =700. Can a plot be included for different samples to validate this? \n\n- Comparison to SIMCLR: SimCLR does obtain a higher accuracy on attributes affecting local appearances (e.g., \u201cHat\u201d). We postulate that its contrastive training has some effects in regularizing f as an injective mapping\u201d . This is not clear. What is being implied in these findings. Does this mean that the proposed approach depends on attribute correlations?"
            },
            "questions": {
                "value": "- From point 2 above, it will be great to include the plot to validate the time steps and loss. \n-The results presented in the manuscript hold for unconditional models. Do the findings also extend to conditional models? \nAlso see weaknesses above.\n\n\nMinor: The equations are missing parenthesis on expectation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3386/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698728915230,
        "cdate": 1698728915230,
        "tmdate": 1699636289351,
        "mdate": 1699636289351,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wPztMP4DDp",
        "forum": "bWzxhtl1HP",
        "replyto": "bWzxhtl1HP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_Kc2k"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3386/Reviewer_Kc2k"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a unique perspective on exploiting the image-noise ratio across different time steps in diffusion models and offers a framework for learning useful and disentangled representations from diffusion models. The authors argue that as t increases, images progressively loss information starting from details to global structures during noise injection, and learning a complementary feature representation conveying the corrupted information can help make the representation more disentangled. Experiments are performed on multiple image datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of systematically studying the representation changes during the noise injection of diffusion models is interesting and has great potential in further understanding the diffusion models. \n\n2. The paper is written in good presentation quality in general. The definitions such as attribute loss are adequately formulated and illustrated with figures. \n\n3. The quantitative results in Table 1 seem strong. \n\n4. The method is built on top of pretrained diffusion models, which I believe can help reduce the cost of representation learning."
            },
            "weaknesses": {
                "value": "The empirical discussions on counterfactual generation (section 5.3) are relatively weak as the effectiveness is only supported by a few examples. Especially for the bedroom experiments, I personally feel like it's not easy to justify the authors' claim that 'DiTi is the only method that generates faithful counterfactuals' based on the given examples.\n\nAnd since this paper focuses on unsupervised representation learning, more empirical results regarding how the learned disentanglement can improve the overall representation quality can be a huge plus. \n\nFor example, do the learned disentangled representations enable human intervention to mitigate spurious correlations? \n\nHow is the quality of the representation when evaluated in a more general setting such as ImageNet-style recognition? \n\nOne concern I do have is that as diffusion is trained by image reconstruction, the learned feature will inevitably contain considerable information regarding the background (probably in late step t), and how will this affect the general representation quality?"
            },
            "questions": {
                "value": "Could the authors provide a brief discussion for [1]?\n\n\n---\n[1] Diffusion Based Representation Learning, arxiv"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3386/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699057022194,
        "cdate": 1699057022194,
        "tmdate": 1699636289278,
        "mdate": 1699636289278,
        "license": "CC BY 4.0",
        "version": 2
    }
]