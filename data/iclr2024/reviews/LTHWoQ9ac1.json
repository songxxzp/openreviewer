[
    {
        "id": "qqEBGa8dRM",
        "forum": "LTHWoQ9ac1",
        "replyto": "LTHWoQ9ac1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_jnH1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_jnH1"
        ],
        "content": {
            "summary": {
                "value": "The work addresses the problem of personalized algorithmic recourse\nwhere the cost function of the user has to be learned by interacting\nwith the user. The problem is formalized as learning a Mahalanobis\ndistance in state space, and combining it with two existing approaches\nfor differentiable and non-differentiable classifiers respectively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "In the cases in which the use is assumed to provide consistent\nfeedback, the approach is technically sound, and it is nicely adapted\nto deal with both differentiable and non-differentible classifiers.\n\nThe manuscript is well written and clear, and the algorithmic solutions are well motivated.\n\nThe authors made a substantial effort in comparing with existing\nalternatives, including a recent approach (De Toni et al, 2022) for\nwhich no implementation is currently available."
            },
            "weaknesses": {
                "value": "User inconsistencies are dealt in a less principled way in my\nopinion. The authors do provide in the supplement a (computationally\nchallenging) solution to account for inconsistencies. However this\nassumes to have a given max percentage of inconsistencies. Approaches\nto account for user inconsistencies typically assume a user response\nmodel, where the probability of a wrong preference feedback grows with\nthe similarity between instances. This is one of the advantages of a\nBayesian approach to preference elicitation.\n \nThe approach provides cost-learning functionalities on top of two\nexisting approaches, a differentiable and a non-differentiable one. It\nthus inherits the limitations of these approaches, e.g. for the\nnon-differentiable approach, the fact that recourse can only be\nachieved by moving to an example in the training set that achieves\nrecourse. This is suboptimal, as a new user could achieve recourse in\na way that is different from training users and has lower cost. These\nlimitations should also be mentioned."
            },
            "questions": {
                "value": "Is it possible to incorporate a user response model modelling uncertainty in feedback?\n\nDid you study how your approach behaves when faced with inconsistent users? This is major advantage of Bayesian approaches to preference elicitation.."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698614778488,
        "cdate": 1698614778488,
        "tmdate": 1699637102266,
        "mdate": 1699637102266,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7eUscAIx5g",
        "forum": "LTHWoQ9ac1",
        "replyto": "LTHWoQ9ac1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_Qous"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_Qous"
        ],
        "content": {
            "summary": {
                "value": "The paper presents ReAP, a method to generate personalised recourse suggestions via preference elicitation. The authors provide a technique to learn a personalized cost function, for each user, by asking preference questions. The authors also show extended versions of a gradient-based and graph-based approach for recourse that exploit their learned cost function. Lastly, they validate ReAP with some experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The topic of the paper is timely, and I think it is a direction which needs to be explored by the recourse community in order to make this field progress (and more realistic). The paper is also clear in its exposition, the idea is well-motivated and the formalization of the problem is straightforward."
            },
            "weaknesses": {
                "value": "The main concern is that I do not see the advantages of this approach compared to the closets-related method PEAR [1]. While it is true that they seem to rely on some sort of causal graph, which might be hard to get, their technique can be in principle applied to different cost functions (even the one presented here) and they provide a Bayesian model to incorporate uncertainty over the user answers. Therefore, it is not clear to me the benefits of ReAP over PEAR.\n\nIn the introduction, the author says \u201c [...] our framework can perform well even when the dimension of the feature space grows large [...]\u201d. First, this assertion is true only under a synthetic setting. Real-world users will find it difficult to compare profiles with too many features. For this reason, I would have expected to see experiments on \u201cnoisy\u201d users, which is a common scenario in the preference elicitation literature [2]. Equation 2 seems to accommodate it, but I think it would have made the evaluation less synthetic to see some results concerning the role of $\\epsilon$.\n\nLastly, ReAP disentangle the elicitation part from the recourse generation (Figure 1). However, if the number of features is truly high, we might just need to estimate only the cost of the features we need for recourse, rather than the full matrix $A$. Moreover, it might be desirable that we just ask the user the right questions to estimate the perfect recourse for him/her, rather than the ones minimizing the smallest projection distance. \n\n[1] De Toni, Giovanni, et al. \u201cPersonalized Algorithmic Recourse with Preference Elicitation\" arXiv preprint arXiv:2205.13743 (2022). (it appears a new version of the paper was published the last May).\n[2] Viappiani & Boutilier. \"Optimal bayesian recommendation sets and myopically optimal choice query sets.\" NeurIPS (2010)."
            },
            "questions": {
                "value": "* Why did the author not include PEAR as a baseline in the main paper (while it is present in the Appendix)? I think it is the most suitable competitor since its method can be applied in principle to all cost functions, it employs a more targeted approach to the recourse pair selection and it deals with the user\u2019s uncertainty in a most principled way.\n\n* How do you explain the fact that Watcher and ReAP achieve almost the same cost/validity in all four datasets (Table 1)? \n\n* In Figure 4, would it be possible to show the results also for a random strategy to select the recourse pairs to show the user? It is a common check to understand if the experimental setting is not too simple (considering also the concerns of Table 1).\n\n* What happens if the users are \u201cnoisy\u201d in their answers? For example, they gave a wrong answer to the preference questions. Equation 2 seems to accommodate this issue, but I do not see any experiments showing the effect of $\\epsilon$ in the cost estimation quality and/or final recourse.\n\n* What is the novelty of the approaches presented in Sections 4.1 and 4.2? Especially section 4.1 seems a trivial extension of Watcher et al."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698670266001,
        "cdate": 1698670266001,
        "tmdate": 1699637102140,
        "mdate": 1699637102140,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "U52nhLZOux",
        "forum": "LTHWoQ9ac1",
        "replyto": "LTHWoQ9ac1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_r13q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_r13q"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for learning a human subject\u2019s recourse preferences, so as to deliver better options in the problem of algorithmic recourse. Then, methods are presenting for providing recourses given a learned cost function. The paper is technically innovative, and the approach it presents is very reasonable. The method assumes a Mahalanobis cost function for the user, and it gradually restricts the space of cost functions that is consistent with queried user preferences. Query selection is done to find aggressive cuts of the candidate set space in order to efficiently reduce the candidate set size. Existing gradient-based and blackbox (graph-based) recourse selection algorithms are adapted to using the learned cost functions. Experiments are conducted to compare the proposed method with two common baselines, Wachter et al 2018 and DiCE. It\u2019s shown that the method does reduce ground-truth user cost over time (using simulated, identifiable cost functions) and the method does at least as well as baselines."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Very Important: The proposed method tackles an important problem in a reasonable way. It\u2019s clear that algorithmic recourse mechanisms should be able to leverage subject feedback/preferences to improve recourse quality. The proposed method makes reasonable choices at every turn as it tackles this problem. The cost function family is well motivated, and it is nice that this method reduces to simpler Euclidean-distance-based approaches at T=0 queries. The cost inference pipeline is naturally integrated with different optimization procedures for recourse selection (although this could take some work, as evidenced by the integration with FACE). The approximation to the O(n^2) search in cost inference is not only reasonable but actually a nice feature of the method, since it encodes a bias for selecting pairs where there could be a lot of information gain in the query.\n- Important: The development of sequential recourses when combining the method with FACE is technically impressive and likely to be useful for downstream applications with real subjects.\n- Important: The evaluation shows that the proposed method does learn user preferences over time and thereby lowers ground-truth user cost over additional queries with simulated ground truth preferences. On a number of datasets, the method works at least as well as past baselines.\n- Important: The paper provides a lot of context to its approach through extensive connections to related work."
            },
            "weaknesses": {
                "value": "- Important: So, why wasn\u2019t a comparison conducted against Rawal and Lakkararaju (2022)? I agree that the Bradley-Terry cost model is not expressive enough to capture many realistic cost functions, but then again this criticism should apply to the Mahalanobis family as well. I do not understand why it is claimed without further substantiation that the proposed method would perform better in high dimensions than the Bradley-Terry model, and so I worry that this is a key missing baseline in the current work. It could be that their method works as well as as the ReAP, while being conceptually simpler than ReAP.\n- Important: Another question about the method is its limited improvements over even simple baselines on common datasets. There is often no clear improvement over a method from 2018. I wonder if this is an artifact of the simple ground-truth cost function distribution \u2014 could this distribution produce more heterogenous cost functions that better separate methods (particularly by being poorly approximated by a simple Euclidean distance)? Regardless, this is a mark against the method. While there are more noticeable improvements against FACE on the sequential recourses (Table 2), it\u2019s not clear whether these are statistically significant."
            },
            "questions": {
                "value": "- What is the size of the solution set returned by DiCE? Is the comparison with ReAP fair in terms of computational cost and subject query cost?\n- Comment: You might also reference https://arxiv.org/pdf/2111.01235.pdf, which investigates using a distribution over plausible cost functions to find a set of recourses that could better satisfy a user.\n- Why optimize over the worst case cost function? How might results vary based on the ground truth cost function distribution and the choice of optimizing over the worst case cost function vs some centroid cost function or expected cost function."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8776/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8776/Reviewer_r13q",
                    "ICLR.cc/2024/Conference/Submission8776/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698704995795,
        "cdate": 1698704995795,
        "tmdate": 1700666139788,
        "mdate": 1700666139788,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EI6oUVqdBI",
        "forum": "LTHWoQ9ac1",
        "replyto": "LTHWoQ9ac1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_WLdg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8776/Reviewer_WLdg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an approach to recourse generation when the user\u2019s cost is unknown. To learn the user\u2019s cost, pairwise comparisons between points are used and a space of consistent cost matrices is maintained. A min-max objective is used for choosing a recourse either via a gradient-based or a graph-based approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Adding preference elicitation for learning user cost makes a nice extension to previous work\n* The paper is clearly written\n* The experimental results look encouraging"
            },
            "weaknesses": {
                "value": "* It is hard to understand the effect of some approximations (for example, decomposed maximization over edges). An empirical evaluation can help shed some light on that.\n* Some details are missing from the experiments (dimension d etc)"
            },
            "questions": {
                "value": "* Queries are chosen from the positive set D_1 only. Does it make sense to consider points from D_0 or new points that have no label (since this is only for the purpose of preference learning), especially in the case of single recourse?\n* The worst-case objective might be too conservative, resulting in longer paths. It would be interesting to compare it at least empirically to other choices (A* for example, or a random A \\in U_P).\n* Sequential recourse: the problem in Eq (7) doesn\u2019t seem like the real problem that needs to be solved. The set U_P updates after every step, and this changes the argmax A and therefore w_ij. Am I missing anything?\n* Computation of \\bar{w}_ij: maximizing independently over each edge ij is even more conservative. Is it possible to estimate the difference in computed weights between independent and joint optimization (for some small problems)?\n* Section 5.1: what is the dimension d in the experiments? Can you comment on the cost of solving (5) using MOSEK? How does it scale up with d?\n* Section 5.3: how is lambda chosen for the gradient-based objective?\n* In Table 2, what is the average path length?\n* Section 6: \u201cWe \u2026 extend the heuristics to choose the questions from pairwise comparison to multiple-option questions.\u201d I didn\u2019t see where this was done. Can you point to the right section?\n\nOther questions / comments:\n* \u201caddictive\u201d => \u201cadditive\u201d\n* Typo: Algorithm 1, should be \u201c\\lambda > 0\u201d in \u201cparameters\u201d?\n* In section 3.2, consider adding an algorithm block instead of enumerating the steps.\n* Also, in section 4.2 it would be good to have an algorithm block for the graph-based approach.\n* Mean rank is referred to in \u201cRecourse generation\u201d (section 5.1), but defined only later, in 5.2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Responsible research practice (e.g., human subjects, data release)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Check overlap with submission 4706.\nI think it's actually fine, the papers study the same problem but propose different solutions."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8776/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698879499871,
        "cdate": 1698879499871,
        "tmdate": 1699637101830,
        "mdate": 1699637101830,
        "license": "CC BY 4.0",
        "version": 2
    }
]