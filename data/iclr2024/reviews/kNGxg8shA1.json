[
    {
        "id": "SfKoAdrbya",
        "forum": "kNGxg8shA1",
        "replyto": "kNGxg8shA1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_7Duj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_7Duj"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the problem of node feature noise in graph learning. In this paper, the author claims that existing methods make an unrealistic assumption that the noise in the node features is independent of the graph structure or node labels, while a more realistic assumption should be that noisy node features may entail both structure and label noise. Under such an assumption, this paper proposes a principled noisy graph learning framework named PRINGLE to address the feature noise problem in graph learning. Experimental results based on several datasets are reported."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "-\tThe problem of feature noise in graph learning is an important problem.\n-\tTo the best of my knowledge, the assumption that noisy node features may entail both structure and label noise is novel, and this paper provides examples and empirical evidence to show that such an assumption is realistic.\n-\tThe proposed PRINGLE method includes a deep generative model that directly models the data-generating process of the feature-dependent graph noise to capture the relationship among the variables that introduce noise. The proposed PRINGLE method generally makes sense.\n-\tEmpirical evidence based on both existing benchmark datasets and newly collected datasets has been provided to show that PRINGLE outperforms state-of-the-art baselines in addressing the feature-dependent graph noise problem."
            },
            "weaknesses": {
                "value": "-\tMinor issues about the typo: \u201cthe graph structure OF node labels\u201d in line 4 of the abstract should be \u201cthe graph structure OR node labels\u201d if I am not misunderstanding. Besides, in line 5 of page 5, \u201cintroduces\u201d should be \u201cintroduce\u201d."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698647086636,
        "cdate": 1698647086636,
        "tmdate": 1699636809915,
        "mdate": 1699636809915,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vRDKlBpGMh",
        "forum": "kNGxg8shA1",
        "replyto": "kNGxg8shA1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_sHVZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_sHVZ"
        ],
        "content": {
            "summary": {
                "value": "This paper discovers practical limitations of conventional graph noise in terms of node features, i.e., the noise in node features is independent of the graph structure or node label. To mitigate the limitations of the existing assumption, the paper introduces a more realistic graph noise scenario called feature-dependent graph-noise (FDGN). Technically, the paper devises a deep generative model that directly captures the causal relationships among the variables in the DGP of FDGN and also derives a tractable and feasible learning objective based on variational inference. Empirically, the paper justifies the effectiveness of FDGN by conducting experiments on six datasets with both node classification and link prediction tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The investigated problem of graph noise is essential. The paper breaks the existing assumption of feature noise, which is new to the community.\n\nThe paper is solid and extensive from a technical perspective.\n\nThe presentation and drawn figures are generally clear and easy to understand.\n\nThe paper is also theoretically grounded, with detailed justification elaborated on.\n\nSeveral technical details, case studies, and evaluation results are also elaborated on in the Appendix."
            },
            "weaknesses": {
                "value": "Although some basic examples are given, the practical existence of causal relationships among X, A, and Y, i.e., \"$A \u2190 X, Y \u2190 X, Y \u2190 A$,\" should be further justified and supported by real-world evidence and materials. In other words, the paper should further explain why, in reality, noisy node features may entail both structure and label noise to be more convincing and practically worthy, especially in e-commerce systems.\n\nFurther, if \"$A \u2190 X, Y \u2190 X, Y \u2190 A$\" is true, why does the paper not choose to directly learn a clean latent $Z_X$ but choose to learn two latent variables $Z_A, Z_Y$.\n\nThe overall novelty is neutral. The technical key contributions of the paper are within the proposed causal model and its instantiation with a variational inference network. It skillfully combines both worlds and designs a relatively complex objective based on the KL divergence.\n\nThe writing can be largely improved. For example, there are too many \"i.e., A/X/Y\" in Section 3.1, which do not provide any further information but simple notations.\nBesides, I would suggest the paper analyze the complexity of FDGN and provide running time or training curves.\n\nIn addition, most of the references are before 2023. I would suggest the paper have a discussion with one work [1] using variation inference for causal learning and one work [2] learning latent variables $Z_A, Z_Y$ for structural denoising, which are technically relevant to the proposed FDGN.\n\n[1] GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs. NeurIPS 2022.\n\n[2] Combating Bilateral Edge Noise for Robust Link Prediction. NeurIPS 2023."
            },
            "questions": {
                "value": "Please refer to the above weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811091982,
        "cdate": 1698811091982,
        "tmdate": 1699636809810,
        "mdate": 1699636809810,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pQbGMN02lo",
        "forum": "kNGxg8shA1",
        "replyto": "kNGxg8shA1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_MMoz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_MMoz"
        ],
        "content": {
            "summary": {
                "value": "The paper show that many existing robustness-enhancing methods assume noise in node features is independent of the graph structure or node labels. This is potentially an unrealistic assumption in real-world situations. In response, the authors propose a novel noise scenario called feature-dependent graph-noise (FDGN) and an accompanying generative model to address it."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The experiments are extensive. \n2. The performance is good. \n3. A new dataset is introduced."
            },
            "weaknesses": {
                "value": "1. The proposed setting is a combination of popular GNN with label noise and [1]. It is better to clarify more application examples in real-world.\n2. A lot of GNN with label noise works are missed [2]. \n3. The abstract cannot summarize the methodology, which makes the paper unreadable. \n4. Why the last three losses share the same weights in Eq. 4? \n5. Why the generative methods can release the label noise? \n\n\n[1] Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels\n\n[2] Learning on Graphs under Label Noise"
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Reviewer_MMoz"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698819278291,
        "cdate": 1698819278291,
        "tmdate": 1699636809679,
        "mdate": 1699636809679,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1VwftsqDBj",
        "forum": "kNGxg8shA1",
        "replyto": "kNGxg8shA1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_sE61"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6941/Reviewer_sE61"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a new setting under graph weakly-supervised learning, named feature-dependent graph-noise, where the noise could be presented on either edge, label, and feature. To counter this proposed noise, authors leveraged the variational autoencoder (VAE) to model the latent variable and capture the causal relationship."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Authors adapt a causal prospective to justify the feature-dependent graph-noise, which is intuitive and sensible under mild assumptions.\n\n2. This paper is overall well-presentated, the ideas are easy-to-follow.\n\n3. The proposed metod demonstarates strong performances over multiple settings (graph noise, edge noise, label noise, feature noise)."
            },
            "weaknesses": {
                "value": "1. The proposed solution lacks technical novelty, using VAE to model the causal relationship and counter noise has already been proposed by [1]. This paper only incrementally adapts that solution on the graph.\n\n2. The proposed solutions lack theoretical support, the derivation on ELBO are well-known results, and the authors are only re-stating them here.\n\n3. The proposed solution seems to have very high complexity (there are three encoder-decoder pairs, and three objectives to compute), therefore an efficiency analysis is needed."
            },
            "questions": {
                "value": "not at the moment"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6941/Reviewer_sE61"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698840227371,
        "cdate": 1698840227371,
        "tmdate": 1699673109903,
        "mdate": 1699673109903,
        "license": "CC BY 4.0",
        "version": 2
    }
]