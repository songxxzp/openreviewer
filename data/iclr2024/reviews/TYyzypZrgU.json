[
    {
        "id": "5OOsXKsShr",
        "forum": "TYyzypZrgU",
        "replyto": "TYyzypZrgU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_g76t"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_g76t"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a control theoretic perspective for learning with knowledge graphs that represents domain models and constraints. Their proposed deep learning approach constrains parameters with these knowledge graphs. The paper includes theoretical analysis and experiments on the CLEVRER and CLEVERER-Humans datasets, which focuses on question answering in videos."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The broad idea of training networks whose parameters abide by ground truth graph structures from domain-specific knowledge graphs is clever. I appreciate the author\u2019s analysis on how the stated constrained optimization problem can be reformulated to be a soft-constrained problem, though I cannot provide feedback on the theory parts of the paper."
            },
            "weaknesses": {
                "value": "W1. I am quite confused at the paper formulation and key points. I\u2019m not quite sure how this very in-depth drone example is relevant to constraining NNs where constraints are specified as knowledge graphs. I also don\u2019t understand what part of this is \u201cdomain-grounding\u201d. What is being grounded to the domain?\n\nW2. It seems like deriving graph structured abstractions from NN parameters is a core part of the paper, but I don\u2019t understand the authors\u2019 motivation for not using GNNs, and instead proposing the complex method in Figure 3. Are there ablations to show that this is important? \n\nW3. Is the knowledge graph given in train and in test? The training and test paradigm is very unclear. What information is given? \n\nW4. This also seems constrained to knowledge graphs where all edge relationships are the same; usually knowledge graphs depict different relations in the edges. In the drone example given this seems to be the case.\n\nW5. What are the ground truth graphs for CLEVRER and CLEVRER-Humans? How is the knowledge graph queried to collision events? Can you give more examples of \u201cdomain models\u201d?\n\nNit: The figures are also quite confusing."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5685/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5685/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5685/Reviewer_g76t"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698285882450,
        "cdate": 1698285882450,
        "tmdate": 1699636594320,
        "mdate": 1699636594320,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rLCx5ZJpzr",
        "forum": "TYyzypZrgU",
        "replyto": "TYyzypZrgU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_f8Mp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_f8Mp"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a solution that incorporates symbolic representation (knowledge graphs) for domain understanding into the architecture of neural networks. The approach is inspired by control barrier function from control theory and aims to impose domain knowledge-graph constraints during training. The effectiveness of the approach is demonstrated using two benchmark datasets: CLEVRER and CLEVRER-Humans, which focus on spatiotemporal reasoning and question answering."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper presents an interesting idea of enforcing knowledge-graph-derived constraints in neural network training. It helps better recover the graphical structures underlying physical trajectories (e.g., collision event graphs)."
            },
            "weaknesses": {
                "value": "The paper presentation is much below the quality requirment of the conference. For example, the paper spent a lot of effort describing drone dynamics and knowledge graphs for drone navigation, which is completely irrelevant to the experiments. Furthermore, there is no clear description of\b what's exactly the form of the KGs used in the experiments, what's the prediction task of the KG; etc.\n\nAll the experimental results are compared with transductive KG methods, which I don't understand how they are related to the CLEVRER QA tasks..."
            },
            "questions": {
                "value": "What are those pictures in Figure 6 (KGs, KG querying software)? I can't find the relevant code in the supplementary zip.\n\nWhat's the difference between the CBF-inspired formulation and just auxiliary training losses? For example, Embedding Symbolic Knowledge into Deep Networks https://proceedings.neurips.cc/paper/2019/hash/7b66b4fd401a271a1c7224027ce111bc-Abstract.html"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790773485,
        "cdate": 1698790773485,
        "tmdate": 1699636594210,
        "mdate": 1699636594210,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wjrMpL7mZz",
        "forum": "TYyzypZrgU",
        "replyto": "TYyzypZrgU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_vq2f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_vq2f"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a framework for integrating domain knowledge (expressed with knowledge graphs) into neural networks. The main idea is to benefit from concepts in control theory and design a differentiable objective that constrains model predictions within the domain of allowed parameters. In doing this, the authors introduce the notion of control barrier function (CBF) and extend it to neural models where the graph resulting from its representation is compared to the ground-truth knowledge graph. The experiments are conducted over two spatiotemporal reasoning benchmarks: CLEVRER and CLEVRER-Humans, where the model attains better performances w.r.t. standard GNNs competitors and it is highly performant within the leader board of CLEVRER."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Merging neural processing with symbolic information is a hot topic within Neuro-Symbolic AI that has potential benefits for improving standard neural computing. Knowledge graphs are well known in the community, as well as tools for handling them, and merging them within neural networks is a promising research area. \n\nThe authors' idea to make use of control theory is new and deserves attention as a principled way to impose constraints in the model. One key property is the forward invariance that guarantees that once constraints are satisfied, there is forward compliance with them. This is interesting and the analysis of the optimization is also included. Furthermore, the injection of the knowledge graph evidences improvements to neural competitors."
            },
            "weaknesses": {
                "value": "The presented material is of high quality but misses citing relevant works in the field that are more aligned to the applications of knowledge in learning. In particular, the study in knowledge grounding is quite (seen as NeSy AI) is quite progressed, see [1], as well as works integrating GNNs in vision, see [2]. It should be clear why the baselines chosen represent the SotA and it should be mentioned clearly what are key differences of the proposed method. In particular, semantic regularization losses were proposed both in fuzzy and probabilistic logic, see [3,4].\n\nThe paper presents the intuition on control theory in an intuitive manner but lacks further details that could be useful for a more thorough comprehension of the contribution. In particular, devoting all details of the model in Figure 3 and other explanations in the figures renders the presentation quite heavy and some details are not entirely clear or not in evidence enough. \n\nIt is written that the nodes of the predicted graph must match the ground truth but it is not clear how it is done with the \"asymmetric inner product\". What are $\\alpha$ and $\\beta$? How are the nodes of the graph derived from the input $\\mathbf x$ and from its last hidden layer? Is the implementation of the model sensible to the initial choice of the ground truth graph?\n\nThe authors introduce the fact that forward compliance with the constraints can be guaranteed upon finding initial states that satisfy the constraints. This is however hard to impose at the beginning of the learning and it leaves open how and whether the model would converge to be compliant. It is more realistic not to be entirely compliant, but it is not discussed what are the implications. How does the model behave in those scenarios?\n\n[1] De Raedt, Luc, et al. \"From statistical relational to neuro-symbolic artificial intelligence.\" arXiv (2020) \\\n[2] Senior, Henry, et al. \"Graph Neural Networks in Vision-Language Image Understanding: A Survey.\" arXiv (2023) \\\n[3] Diligenti, Michelangelo, Marco Gori, and Claudio Sacca. \"Semantic-based regularization for learning and inference.\" AI (2017) \\\n[4] Xu, Jingyi, et al. \"A semantic loss function for deep learning with symbolic knowledge.\" ICML (2018) \\"
            },
            "questions": {
                "value": "I understood that the proposed method also applies to context beyond spatio-temporal reasoning. Is that the case? What would be the comparison with static image reasoning tasks like semantic image interpretation [5]? \n\nOther questions are asked in the previous sections.\n\n[5] Donadello, Ivan, Luciano Serafini, and Artur D'Avila Garcez. \"Logic tensor networks for semantic image interpretation.\" arXiv (2017).\n\n### Update on review\n\nAfter seeing other reviewers' replies, I changed my vote to reject due to the quality of the presented material. I align with the claims that the paper could have been presented in a better way and the experimental description is somehow confusing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5685/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5685/Reviewer_vq2f",
                    "ICLR.cc/2024/Conference/Submission5685/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698877347887,
        "cdate": 1698877347887,
        "tmdate": 1700722710669,
        "mdate": 1700722710669,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ovuvit2BEh",
        "forum": "TYyzypZrgU",
        "replyto": "TYyzypZrgU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_1Yru"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5685/Reviewer_1Yru"
        ],
        "content": {
            "summary": {
                "value": "Inspired by dynamical systems, the authors propose a constraint on the internal features of a neural network. In particular, they design a knowledge graph with constraints focused towards spatiotemporal reasoning. They then show that thus constraining the learning process leads to better domain grounding (i.e. stronger reliance on the underlying data generative process). The authors also propose an interpretability score to quantify how strongly the learned constraints are followed for a particular reasoning instance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The analogy drawn to dynamical system constraints and neural network inductive biases, and its use define a novel KG driven learning constraint is a clever modelling choice for spatiotemoral reasoning."
            },
            "weaknesses": {
                "value": "* The authors define domain grounding as \"grounding in reality or truth\". Then they mention in \"Related Work\" that domain grounding in NNs has been attempted via in-context learning. This is a very limited view of prior work on grounding in neural networks. I think the authors need to include more references/discussion on prior work on grounding them on external structured/unstructured data: visual scenes [1], external knowledge [2], information retrieval [3] etc.\n\n* \"These constraints typically do not form an intrinsic component of the...model; instead, they arise from environmental or domain-specific information.\" The authors work links to the work huge body of work in neural network learning and reasoning involving inductive biases that do exactly what the authors seek to do - invoke constraints on the model, the data, or the learning process that reflect domain-specific information [4]. In particular, introducing problem based constraints on the hidden representation. Beyond the dynamical systems analogy, how is this sort of constraining on the hidden representation by introducing a constrained loss function component anything novel?\n\n* I fail to see how such a method translates/scales to a different domain. Defining the domain specific KG constraint model would involve strong human priors informed by the domain knowledge. Any solution is by definition rendered to be highly domain specific and limited. \n\n**References**  \n\n1. Wang, P., Wu, Q., Shen, C., Dick, A. and Van Den Hengel, A., 2017. Fvqa: Fact-based visual question answering. IEEE transactions on pattern analysis and machine intelligence, 40(10), pp.2413-2427.\n2. Ji, Z., Liu, Z., Lee, N., Yu, T., Wilie, B., Zeng, M. and Fung, P., 2023, July. Rho: Reducing hallucination in open-domain dialogues with knowledge grounding. In Findings of the Association for Computational Linguistics: ACL 2023 (pp. 4504-4522).\n3. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K\u00fcttler, H., Lewis, M., Yih, W.T., Rockt\u00e4schel, T. and Riedel, S., 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33, pp.9459-9474.\n4. Goyal, A. and Bengio, Y., 2022. Inductive biases for deep learning of higher-level cognition. Proceedings of the Royal Society A, 478(2266), p.20210068."
            },
            "questions": {
                "value": "Since a lot of the important modelling details and derivations are currently in figure captions, would it be possible for the authors to reorganize their paper with a supplementary section to improve readability?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5685/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699039980138,
        "cdate": 1699039980138,
        "tmdate": 1699636593758,
        "mdate": 1699636593758,
        "license": "CC BY 4.0",
        "version": 2
    }
]