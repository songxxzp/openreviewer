[
    {
        "id": "AuGv3uuiCa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_bd8T"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_bd8T"
        ],
        "forum": "AKZtQO81GQ",
        "replyto": "AKZtQO81GQ",
        "content": {
            "summary": {
                "value": "This paper is about the evaluation of machine learning models to detect undesirable behaviour, such as inconsistent behaviour across subgroups of the test data. The contribution is a novel metric named SkewSize. It is a scalar measuring the skewness across classes of the effect size of subgroup identity (based on some biased/sensitive attribute) on the model's predictions. The metric is shown to be applicable in a variety of settings, and its utility is demonstrated with recent existing vision and vision-and-language models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Clear motivation, important problem. The need for finer-grained evaluation of models is clearly shown with the motivating example that exposes how existing metrics can be misleading.\n\n- The novel metric seems sounds and grounded in solid statistical principles.\n\n- The applicability to various settings is demonstrated both in a controlled environment (dSprites) and in a practical/realistic scenario (vision and V&L models)."
            },
            "weaknesses": {
                "value": "I see no clear flaws in this paper."
            },
            "questions": {
                "value": "N/A. This seems to be a strong paper: it addresses an important problem that seems to have been overlooked, with a method that appears technically sound, and that is demonstrated in both controlled and realistic settings.\n\nMinor suggestions:\n- \"*quantify the numbers*\" -> \"aggregate\"\n- \"open-ended predictions\": need a dash\n- \"visual language models\", \"vision language models\", ... I think the most common term is \"vision-and-language models\"\n- Sect 2.1: \"On the other hand\": should only be used if there was another statement before starting with \"on the one hand\". I think that here you can replace it with \"Alternatively\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697281366795,
        "cdate": 1697281366795,
        "tmdate": 1699636565455,
        "mdate": 1699636565455,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IkSRevTZpe",
        "forum": "AKZtQO81GQ",
        "replyto": "AKZtQO81GQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_kSV6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_kSV6"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel metric, SKEWSIZE, designed to identify biases in a model's predictions. The authors first establish the need for such a metric by providing several examples where existing metrics fall short in capturing inherent biases. The proposed SKEWSIZE metric is applicable in a variety of scenarios, including synthetic data, distribution shift/multi-class classification, and open-ended predictions. This wide applicability is demonstrated through a series of experiments in Section 3."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well-structured and comprehensive, beginning with various motivational examples and addressing the shortcomings of existing metrics. The authors then propose their method and try to demonstrate that SKEWSIZE outperforms previous metrics in more practical, large-scale scenarios via experiments.\n\n2. The research question - seeking a better metric to capture model bias - is clearly defined and of importance in the field.\n\n3. The experiments conducted demonstrate the versatility of the proposed metric, showing its applicability across different tasks."
            },
            "weaknesses": {
                "value": "1. The novelty of the proposed metric is a concern. The use of contingency tables, relevant statistics, and skewness for data analysis is not a new thing. It appears that SKEWSIZE merely combines these elements to measure fairness/bias. Could the authors elucidate further on what makes their proposed metric unique?\n\n2. The discussion in Section 2.2 is constrained to cases with only two items in Z. Is it feasible to extend this discussion to scenarios with multiple items?\n\n3. Regarding the experiment section, it's unclear how computing the correlation between SKEWSIZE and other metrics, as done in Sections 3.2 and 3.3, demonstrates \"that the proposed metric identifies issues with models not exposed by these other metrics\"."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Although the paper is related to \"societal considerations including fairness, safety, privacy\", it doesn't seem to raise any ethical concerns based on the content presented."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5517/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5517/Reviewer_kSV6",
                    "ICLR.cc/2024/Conference/Submission5517/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698031303327,
        "cdate": 1698031303327,
        "tmdate": 1700383368288,
        "mdate": 1700383368288,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PLql2uYSOZ",
        "forum": "AKZtQO81GQ",
        "replyto": "AKZtQO81GQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_1DWK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_1DWK"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the SkewSize metric, an approach for characterizing model bias by accounting for systematic mismatches in prediction errors across subgroups. The metric provides a more comprehensive evaluation of model bias than traditional metrics, such as worst-group accuracy or accuracy gap, and is demonstrated to be effective in various settings, including vision models and vision-language models, uncovering biases that other metrics might miss."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- SkewSize is demonstrated to be applicable in a variety of settings, including vision models, domain shift benchmarks, and large-scale vision-language models. Its versatility and effectiveness make it a valuable tool for assessing biases in different contexts.\n- Model bias is a crucial concern in practical applications of machine learning. The paper's focus on characterizing and quantifying bias is highly relevant in building fair and trustworthy AI systems."
            },
            "weaknesses": {
                "value": "- The paper's SkewSize metric is based on statistical concepts such as skewness and chi-square tests, which may not represent a fundamentally novel approach. While it introduces a new metric, the underlying statistical principles are not groundbreaking.\n- The paper may lack excitement or the potential to generate significant interest, as it builds upon established statistical techniques rather than introducing innovative or revolutionary methodologies.\n- While the paper identifies biases in model predictions using the SkewSize metric, it doesn't definitively confirm whether these biases are genuine or artifacts. The sensitivity of the metric could potentially lead to the detection of biases that are not practically significant.\n- There's a concern that the SkewSize metric might be overly sensitive to minor variations or noise in data, which could result in an overemphasis on biases that may not be robust or practically impactful.\n- The paper doesn't thoroughly address the potential for false positives when using the SkewSize metric. It's crucial to differentiate between genuine biases and statistical anomalies.\n- The paper doesn't provide a strong discussion of the ethical or practical implications of its findings. While it highlights biases, it may not offer clear guidance on how to address or mitigate these biases in real-world applications."
            },
            "questions": {
                "value": "- In the code implementation of SkewSize, why the degree of freedom is calculated by the minimum of the prediction class and subgroup class minus 1? Shouldn't it be $(prediction class - 1)*(subgroup class - 1)$?\n- When there exists a large group of object classes, the effect size may be large by chance, hence the calculated SkewSize will tend to be skew. I wonder if the authors have conducted experiments to understand the robustness of the proposed metric. SkewSize seems to be very sensitive in that it can identify potential bias in the model predictions. However, it is not clear that in the case where no bias exists in the predictions, SkewSize also demonstrates some degree of skewness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698619959133,
        "cdate": 1698619959133,
        "tmdate": 1699636565221,
        "mdate": 1699636565221,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nfIW9uRWU4",
        "forum": "AKZtQO81GQ",
        "replyto": "AKZtQO81GQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_6Zhw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5517/Reviewer_6Zhw"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a novel statistical measure- named SKEWSIZE, to qualify and detect bias present in a deep learning model. The proposed metric is shown to be more sensitive and exact in finding presence of bias, as validated by experiments across diverse datasets in different settings."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The presentation, writing and problem statement are clear.\n2. Sheds light on utility of statistical measures in identification of bias in deep models.\n3. Through three different settings, the authors demonstrate that the proposed SKEWSIZE metric successfully captures presence of bias more accurately than other conventional measures, for example, accuracy gap, worst group accuracy etc."
            },
            "weaknesses": {
                "value": "1. The comparison with respect to other benchmark methods is somewhat unfair. The authors should study effectiveness of statistical measures (in general) in identifying bias. For example, one could perform a statistical test (e.g. MWU test) with null hypothesis that the model scores for a subgroup (that represents a bias attribute) comes from the same distribution of as model scores without any subgrouping. An acceptance of the null hypothesis (using p-value) would indicate an absence of bias and rejection of the null hypothesis in favour of alternate hypothesis would indicate the presence of bias with respect to the subgrouping attribute.\n2. Essentially, it is probably important to present benchmark comparisons on how the standard statistical measures and methods perform in identifying bias as baselines. Then only it presents us opportunity to appreciate the proposed specific statistical measure in bias identification."
            },
            "questions": {
                "value": "Refer to the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5517/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5517/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5517/Reviewer_6Zhw"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5517/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698864267639,
        "cdate": 1698864267639,
        "tmdate": 1699636565128,
        "mdate": 1699636565128,
        "license": "CC BY 4.0",
        "version": 2
    }
]