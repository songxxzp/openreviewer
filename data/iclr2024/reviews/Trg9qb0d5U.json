[
    {
        "id": "uMIEO4y2Xu",
        "forum": "Trg9qb0d5U",
        "replyto": "Trg9qb0d5U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_THQj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_THQj"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an approach to estimate the bounds for test accuracy of a given model without access to test data. In particular,it first generates prototype vectors for each class, and then generates k-1 additional vectors for each initial prototype (by \u201cperturbing\u201d the initial prototype towards the class boundary with respect to each of the other k-1 classes). The aggregated pairwise cosine similarity of the prototypes (intra-class and inter-class) is used to estimate the test accuracy. To evaluate their methods, the authors show their method can successfully bound models\u2019s test accuracy on CIFAR-10 and CIFAR-100."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.an interesting problem to study\n\n2.smart, intuitive methodology\n\n3.the proposed method seems to work fine for bounding testing accuracy"
            },
            "weaknesses": {
                "value": "1.insufficient evaluation\n\nThe evaluation is only conducted on two similar ResNet models and two small datasets (CIFAR-10 and CIFAR-100) and makes the results less convincing. At least an additional model on a larger dataset (e.g., ImageNet) should be checked.\n\n2.writing can be improved\n\nThe language usage is sub-optimal. For example, there are five \u201cWe believe\u201d in the paper which should not be used frequently. There are also quite a few grammar errors: e.g., at the end of introduction, \u201cThe metric for assessing the classifier, we use its weight vectors\u201d."
            },
            "questions": {
                "value": "-table1, what if less than 25% data is used?\n\n-how generalizable the proposed method is on a larger dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697669389045,
        "cdate": 1697669389045,
        "tmdate": 1699636770223,
        "mdate": 1699636770223,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "53lp253pv5",
        "forum": "Trg9qb0d5U",
        "replyto": "Trg9qb0d5U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_Szfc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_Szfc"
        ],
        "content": {
            "summary": {
                "value": "The paper creatively tried to evaluate trained deep neural networks without any data, either training, validation or testing data. The idea of evaluating the network with no data is innovative and attractive, however, the empirical results are not convincing enough that the approach is ready to be used."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. the idea of evaluating the network without any data is very attractive. \n\n2. the overall flow of the paper is written in a fairly straightforward way, easy to follow, although there are many typos."
            },
            "weaknesses": {
                "value": "1. the major issue is the application of this method. The authors unfortunately didn't show convincing evidence that the method is applicable to a broader scope. For example, the experiments are only conducted with ResNet18 over CIFAR10 and CIFAR100 datasets, the choices such as learning rates are from a fixed pattern, so it's hard to evaluate how generalize this method is. \n    - in addition, the ResNet18 over CIFAR10 dataset can achieve over 90 percent accuracy since years ago, e.g. see https://github.com/kuangliu/pytorch-cifar the authors can only get 85 does not seem very convincing. \n\n2. the results at Table 1 are all the same number, this also seems weird. \n\n3. there are quite a few typos, e.g., ResNet14, CIFAR10 and 500, etc. In eq. (9), there are two types of G, and in (10), there are two different types of H, which posts challenge of reading this paper further."
            },
            "questions": {
                "value": "1. it could be helpful if the authors explain the reason why numbers in table 1 are all the same."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791027099,
        "cdate": 1698791027099,
        "tmdate": 1699636770097,
        "mdate": 1699636770097,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0RWscN9wHs",
        "forum": "Trg9qb0d5U",
        "replyto": "Trg9qb0d5U",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_QA6N"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6708/Reviewer_QA6N"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel method for estimating the test accuracy of a DNN classifier without any test data. Specifically, the paper proposes three metrics to assess the training quality of the classification layer and the feature extraction backbones. The proposed method is evaluated with two models (Resnet-14 and Resnet-18) on two datasets (Cifar-10 and Cifar-100)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- A novel method for estimating the test accuracy of a DNN classifier.\n- Empirical evaluation with two datasets and two models."
            },
            "weaknesses": {
                "value": "- Significance of the paper. \nI felt confused about the significance of the proposed research when I read the abstract-what is the importance of estimating a DNN classifier\u2019s accuracy without any test data? Unfortunately, I did not find a clear motivation after reading the introduction. The test accuracy of a DNN is strongly related to the dataset it is going to be tested. Without any test data, one may only estimate its accuracy on the training dataset or a test dataset from a similar distribution. However, in the real-world scenario, practitioners usually found the test data shifted from the training data. In this case, the proposed research seems not to be significant enough without further clarification and discussion.\nBesides, clearly, the proposed method may only work for DNN classifiers. Therefore, I would suggest replacing the terms of general DNN with DNN classifiers throughout the paper.\n\n- Presentation is not good enough. \nI believe the paper could be significantly improved with another round of revision. The introduction does not provide a broader assessment of the importance of the research topic while introducing some very basic details about training a DNN and details of the proposed method. Besides, the related work is extremely short and may make the audience confused about whether the proposed research problem is important enough.\n\n- Missing related work. \nThe references only include 19 papers, and 2 of them are datasets. The review of the relevant work is simply not comprehensive and detailed enough.\nThere is an important line of related work that uses a few test examples to estimate the test accuracy of a model [1] [2] [3] [4]. I feel it is necessary to include them as that would help audiences understand why estimating test accuracy without any test data is important compared with sample-efficient testing work.\n\n[1] Kossen, Jannik, et al. \u201cActive testing: Sample-efficient model evaluation.\u201d International Conference on Machine Learning. PMLR, 2021.\n\n[2] Kossen, Jannik, et al. \u201cActive surrogate estimators: An active learning approach to label-efficient model evaluation.\u201d Advances in Neural Information Processing Systems 35 (2022): 24557-24570.\n\n[3] Chen, Junjie, et al. \u201cPractical accuracy estimation for efficient deep neural network testing.\u201d ACM Transactions on Software Engineering and Methodology (TOSEM) 29.4 (2020): 1-35.\n\n[4] Li, Zenan, et al. \u201cBoosting operational DNN testing efficiency through conditioning.\u201d Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 2019."
            },
            "questions": {
                "value": "How does the proposed method compare with the sample-efficient test accuracy estimation methods? What is the importance and significance of estimating a DNN\u2019s accuracy without any test data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6708/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805088580,
        "cdate": 1698805088580,
        "tmdate": 1699636769982,
        "mdate": 1699636769982,
        "license": "CC BY 4.0",
        "version": 2
    }
]