[
    {
        "id": "6kl8ZFkmA2",
        "forum": "3Ok7ccvtf3",
        "replyto": "3Ok7ccvtf3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_n57L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_n57L"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel method to tackle the problem of unlearning in recommender systems. This is a relevant and critical challenge due to changing user preferences and updating privacy laws and regulations. The proposed method works in the collaborative filtering setting and, in particular, the Matrix Factorization models. The authors propose learning an additional model called the rescue model on a corrected version of the data that has to be unlearned. This is followed by the application of a convolution fusion function (CFF) on the latent space of the previous (faulty) model and the rescue model. The CFF dilutes the impact of the unwanted data, resulting in a final model where the latent features are closer to the original model (before the faulty preferences were learned). The authors compare their approach with two existing unlearning approaches and find an improvement in RMSE. They also evaluate their approach on various combinations of user and data percentages for which the unlearning process has to be done."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper addresses a critical and relevant problem which is not explored much in the recommendation systems domain\n2. The authors propose a unique and novel approach for the unlearning problem in the context of recommendation systems\n3. The proposed approach seems to be more efficient and computationally feasible than the existing mentioned methods\n4. The authors have experimented with various combinations of user and data % to analyze the effect of unlearning using their approach. 5. They have also compared their method with existing unlearning approaches."
            },
            "weaknesses": {
                "value": "Significant improvements need to be made in the paper writing, style and structure. Concepts need to be properly defined and equation variables explained. E.g.-\n1. In section 3.1, R is not mathematically defined in terms of u, v and r. \n2. In equation 1, what are $\\alpha$ and $\\gamma$ in D$\\alpha$/D$\\gamma$? $\\alpha$ was also previously defined as the learning rate hyper-parameter. \n3. In theorem 1, motivate the need for $\\eta$ (to approximate or simulate the faulty preference to items) or give more context. \n4. Why is the definition of $U_{lf1}$, $U_{lf2}$ and $U_{lf3}$ the same as the definition of $I_{lf1}$, $I_{lf2}$ and $I_{lf3}$?\n5. Two different definitions of D\u2019 are provided in sections 4.2 and 4.3.1\n6. What does D\u2019 = (D||Dfl) mean in equation 6?\n7. While there is an improvement in RMSE for the proposed method compared to the baselines, the magnitude of improvement is not very convincing. Can additional metrics like AUC, NDCG etc. be used for evaluation?"
            },
            "questions": {
                "value": "1. Is $n_{list}$ for a particular user or all users? What are the dimensions of $D{n_list}$?\n2. What is $D_{fl}$ in figure 1? (referred to as the faulty dataset) Is it referring to $D{n_list}$ or $D_{fl1}$?\n3. Why is the definition of $U_{lf1}$, $U_{lf2}$ and $U_{lf3}$ the same as the definition of $I_{lf1}$, $I_{lf2}$ and $I_{lf3}$?\n4. What does D\u2019 = (D||Dfl) mean in equation 6?\n5. In section 4.3.4, what is $D_{un}$? Is it the same as $D_{fl1}$? If so, why is a different term used?\n6. In section 5.2, how were the values 64 and 0.03 selected for the hyper parameters? Is it expected that these values will be the same for both datasets?\n7. In section 6, where are RMSE2 and RMSE3 in table 3? What are M1 and Mf in table 3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3195/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3195/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3195/Reviewer_n57L"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811504780,
        "cdate": 1698811504780,
        "tmdate": 1699636267670,
        "mdate": 1699636267670,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Xdw1ywtpcU",
        "forum": "3Ok7ccvtf3",
        "replyto": "3Ok7ccvtf3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_o6ud"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_o6ud"
        ],
        "content": {
            "summary": {
                "value": "This paper underscores the significance of the \"right to be forgotten\" in recommendations and, in line with this, investigates the challenge of recommendation unlearning. The authors delve into the critical elements of recommendation unlearning, particularly focusing on time efficiency and the possible absence of complete data. They endeavor to facilitate unlearning from a pre-trained model by utilizing only the data that needs to be removed and eliminating the need for starting from scratch. In pursuit of this objective, the authors introduce a convolution fusion-based unlearning framework."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1: The utilization of convolution fusion for achieving unlearning appears to be a novel approach.\nS2: The proposed method exclusively leverages the unlearning data and eliminates the necessity for a complete retraining from the ground up."
            },
            "weaknesses": {
                "value": "W1: In the context of unlearning, the most critical objective is the effective removal of unwanted data from a trained model. Unfortunately, the paper doesn't provide a clear guarantee in this regard. The only supporting evidence seems to be Theorem 1, but it's unclear how the theorem ensures the removal of unwanted data. It appears that the theorem can only justify that a model is closer to \"the legitimate one\" than another model.\n\nW2: The rationale behind how the convolution fusion function can derive the unlearned model based on the faulty and rescue models is not adequately explained.\n\nW3: The paper makes use of numerous symbols, but some remain unexplained. For instance, \"D_\u03b3\" in equation (1) and \"D||D_fl\" could benefit from clarification.\n\nW4: Certain claims in the paper may be overstated. The authors claim that their work is the first to unlearn from a pre-trained model using only specified data for unlearning without the need for training from scratch. However, the cited paper \"Recommendation unlearning via influence function\" also possesses these characteristics.\n\nW5: There is a noticeable omission of related recommendation unlearning works, such as references [1,2,3].\n\nW6: The experiments conducted in the paper are insufficient to validate the effectiveness of the proposed methods. In the context of recommendation unlearning, there are typically three key objectives, as discussed in the authors' cited papers: 1) unlearning efficacy (ensuring the removal of unwanted data), 2) unlearning efficiency, and 3) recommendation performance. The authors appear to have overlooked the first two aspects in their evaluation.\n\n[1] Li, Yuyuan, et al. \"Selective and collaborative influence function for efficient recommendation unlearning.\" Expert Systems with Applications 234 (2023): 121025.\n[2] Yuan, Wei, et al. \"Federated unlearning for on-device recommendation.\" Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 2023.\n[3] Schelter, Sebastian, Mozhdeh Ariannezhad, and Maarten de Rijke. \"Forget Me Now: Fast and Exact Unlearning in Neighborhood-based Recommendation.\" SIGIR 2023."
            },
            "questions": {
                "value": "How does the proposed method ensure the effective removal of unwanted data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827647075,
        "cdate": 1698827647075,
        "tmdate": 1699636267574,
        "mdate": 1699636267574,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3DlO05ghxI",
        "forum": "3Ok7ccvtf3",
        "replyto": "3Ok7ccvtf3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_GJxA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_GJxA"
        ],
        "content": {
            "summary": {
                "value": "The authors propose an unlearning approach without training from scratch in the recommendation system. By fusing two different latent features in a convolution fusion-based framework, we can obtain an unlearning model approximate to the retrained model. Experiment results show the convolution fusion-based framework outperforms other baseline models on two public datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors propose a novel unlearning approach in recommendation systems. By applying the convolution fusion function, the data in recommendation systems can be unlearned. Furthermore, the authors also provide proof to show that the convolution fusion function actually generates a fading effect, and this effect can be used to unlearn the data. The approach is simple but effective in matrix factorization-based recommendation systems.\n2. Experiments show that the proposed approach outperforms SISA and Retrain in two public datasets."
            },
            "weaknesses": {
                "value": "1. In Section 2.2, the authors mention the work of Chen et al. (2022) and Zhang et al. (2023), which also study the recommendation unlearning. However, there is no comparison with these methods in the experiment section. Are there any reasons why the authors do not compare these two works? Otherwise, the authors can try to compare with those previous studies to make the results more convincing.\n2. In Table 2(a), the authors only show that the proposed approach is better than SISA and Retrain if 10% of users want to forget 50% of their ratings. The experiments would be more convincing if the authors could show more different settings in Table 2(a). For example, 10% of users want to forget 30% of their ratings, or 30% want to forget 10% of their ratings.\n3. The convolution fusion function can only be applied in matrix factorization. The feasibility of the proposed approach to the neural-network-based recommendation systems, which are more popular now, is not discussed in the paper."
            },
            "questions": {
                "value": "1. Why are there no comparisons between proposed methods with previous important baselines, such as Chen et al. (2022) and Zhang et al. (2023)?\n2. Why is there only one parameter setting in Table 2(a)? Can the authors add more settings and compare the results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698912983314,
        "cdate": 1698912983314,
        "tmdate": 1699636267479,
        "mdate": 1699636267479,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "63S3eScE7l",
        "forum": "3Ok7ccvtf3",
        "replyto": "3Ok7ccvtf3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_HcxE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3195/Reviewer_HcxE"
        ],
        "content": {
            "summary": {
                "value": "In this paper the authors propose an unlearning method for recommendation systems based on matrix factorization. The method achieves unlearning by diluting the impact of unwanted data. Empirical studies can been done on Movielens-100K and Movielens-1M data to show the efficacy of the proposed method."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper proposes a new method for matrix factorization unlearning which is not studied by prior research works."
            },
            "weaknesses": {
                "value": "* The presentation of the paper is poor. The problem itself is defined with vague descriptive languages rather than rigorous math languages. Theorem 1 doesn't make sense to first time readers as either \"convolution Fusion Function\" or the \"fading effect\" are not defined. I still don't know what the author tries to show even after the \"proof\" of the theorem. Besides, you cannot prove a theorem by \n\"empirical analysis\".  Overall the paper reads awkwardly and very confusing even for someone familiar with the context. I would suggest the authors to refactor the paper and have the notations and the problem settings properly defined before going into methods.\n\n* The experiments and evaluation metrics are also confusing. The author conducts experiment comparing the proposed method with re-training and SISA. However, the only metrics reported is the RMSE on the test data. While the proposed method has lower RMSE than both baselines, I am not convinced the proposed model is a better approach: How do you guarantee the unwanted data is unlearned? What the evaluation metric showing the new model does not contain unwanted info? Without such guarantee, isn't the model trained on full data always outperforming ones trained on partial data (i.e. retrain and SISA)?"
            },
            "questions": {
                "value": "* What's 'fading effect' in Theorem 1? Can you define it?\n* Section 4.3.4 \"hence, the final matrix...\", what's the final matrix?\n* Does the unwanted data span across the training & test split or only in training?\n* How do you evaluate if the unlearned model contains any info from the unwanted data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3195/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699149183885,
        "cdate": 1699149183885,
        "tmdate": 1699636267361,
        "mdate": 1699636267361,
        "license": "CC BY 4.0",
        "version": 2
    }
]