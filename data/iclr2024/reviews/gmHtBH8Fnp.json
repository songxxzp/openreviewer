[
    {
        "id": "ztHKNx0obr",
        "forum": "gmHtBH8Fnp",
        "replyto": "gmHtBH8Fnp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_yjBg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_yjBg"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an analysis of the impact of imbalance in the data distribution and implementation of class activation maps for binary classifiers. The authors present their results on the CELEB-A dataset using the AFFACT-u and AFFACT-b classifier. They analyze the proportional energy of the activation corresponding to each label."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "See summary"
            },
            "weaknesses": {
                "value": "1. Comparisons against methods capable of rebalancing/mitigating the effects of the underlying distribution are lacking. Methods such as logit adjustment Menon et al, Sharpness aware minimization Foret et al, and Rangwani et al to name a few are missing.\n2. It would be helpful if the authors could elaborate further on the novelty of their contribution since this appears to not differ significantly from standard grad-cam implementation.\n3. How do these aforementioned (1) methods of proportional energy compare against when analyzed with existing methods such as grad cam?\n\n\n[1] Long-tail learning via logit adjustment by Menon et al\n[2] Sharpness-Aware Minimization for Efficiently Improving Generalization Foret et al\n[3] Escaping Saddle Points for Effective Generalization on Class-Imbalanced Data by Rangwani et al"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Reviewer_yjBg"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1268/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697965402527,
        "cdate": 1697965402527,
        "tmdate": 1699636053667,
        "mdate": 1699636053667,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iakkNRFeG2",
        "forum": "gmHtBH8Fnp",
        "replyto": "gmHtBH8Fnp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_XzHa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_XzHa"
        ],
        "content": {
            "summary": {
                "value": "This paper works with the gradient-based class activation mapping (CAM) technique. In particular, the procedure is mainly used with multiclass classifiers and the authors modified it to work with binary classifiers. The authors then investigated an unbalanced classifier AFFACT-u on the Celeb A dataset. First, they verified that the classifier performs well on the majority class for binary classification. However, visualization from CAM techniques show that the reasoning for majority class prediction is not always valid. On the other hand, minority classes are predicted with high error but the reasonable areas of the image get highlighted through CAM. Their proposed classifier AFFACT-b shows better behavior in such a scenario in terms of both classification error and CAM visualization."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is mostly well written and easy to follow. The authors performed detailed experimentation on the Celeb A dataset to explain their findings.\n2. The proposed AFFACT-b classifier clearly performs better than the AFFACT-u classifier on the Celeb A dataset. This can be seen through multiple results, e.g., FNR/FPR, proportional energy and CAM."
            },
            "weaknesses": {
                "value": "1. The authors bring up some of the weaknesses with respect to the experimentation in the discussion section. For example, they only used two binary attribute prediction networks, they experimented with only one dataset, they have used only one network topology etc. These shortcomings take away from the validity of the current work and further experimental exploration is required.\n2. I am not fully convinced by the authors claim \"One would expect that the biased classifier has learned to extract features mainly from the majority classes and that the proportional energy of the activations mainly reside in certain specific regions of the image where the attributes is located.\" In fact, for highly imbalanced binary datasets I would expect the classifier to learn very little about the majority class. Let me take an extreme example where all n/n examples belong to the majority class. In this case, the classifier would see many instances from the \"majority\" class but wouldn't learn anything about it. Similarly if (n-1) and 1 examples belong to the majority and minority classes respectively, we would expect the classifier to learn very little about the majority class. However, if we put a large weight on the minority class, the classifier might learn about some of its distinguishing features. Thus the finding of biased binary attribute classifiers ignoring the majority classes is not surprising to me."
            },
            "questions": {
                "value": "1. I would like to know the authors thoughts about the concern raised in Weakness 2.\n2. In Section 3.3, the authors mention that they only select frontal test images using a heuristic. I understand the heuristic but some more understanding (maybe examples) would be helpful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1268/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698541624079,
        "cdate": 1698541624079,
        "tmdate": 1699636053587,
        "mdate": 1699636053587,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3223BAQf9U",
        "forum": "gmHtBH8Fnp",
        "replyto": "gmHtBH8Fnp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_uTPu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_uTPu"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors make slight changes on CAM (Class Activation Mapping) methods to adapt them to the binary classification. Then, they use the resulting technique to visualize the results returned two binary classifiers, AFFACT-u and AFFACT-b classifiers to demonstrate the classification of the majority class is based on the corners of the images or the bias neuron of the final layer."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Main strengths of the paper can be summarized as follows:\n1) The authors adopt CAM methods for binary classification.\n2) The authors introduce AFFACT-b network as an alternative to the classical AFFACT classifier."
            },
            "weaknesses": {
                "value": "Main weaknesses of the paper can be summarized as follows:\n1) The authors argue that CAM techniques are designed for multi-class classifiers and they cannot be used for binary classification using a single logit at the classification layer. Therefore, they introduce a technique to adopt it to such binary classification scenarios. However, for binary classification, one can easily use two class weights that produce two logits without any extra effort (cross entropy loss function using the softmax with two classes), and CAM methods can be used directly. What is the reason for going all this trouble?\n2) In general both the novelty and contribution are very limited. Affact-b network uses a well-known loss function from the literature. Also, all findings are built based on AFFACT classifiers which limits the value of the findings. As noted in the discussion, the findings must be also evaluated on different classifiers and loss functions. More precisely, for binary classification, there are one-class type classifiers [R1,R2] using hyperspheres or polyhedral regions that focus on positive data which are more appropriate for imbalanced datasets.\n3) I strongly believe that there are problems with the created masks. Such mask must be prepared with qualified psychologists. For example, smiling is not only confined with the lips as given in Supplementary material. Smiling activates regions in the vicinity of cheeks and eyes (see https://www.youtube.com/watch?v=0vlJ-8gXMII&ab_channel=NoldusHumanBehavior). \n4) The authors use FNR and FPR rates for measuring accuracy. This is unacceptable. For binary classification especially in imbalanced datasets, map scores obtained from precision recall curves or ROC curves must be used. FNR and FPR largely depend on selected thresholds and they can be misleading. For binary classification, the important thing is the order of scores not the actual scores.\nReferences:\n[R1] Cevikalp et al., Deep compact polyhedral conic classifier for open and closed set recognition, Pattern recognition, 2021.\n[R2] Ruff. et al., Rethinking assumptions in deep anomaly detection, ICML Workshops, 2021."
            },
            "questions": {
                "value": "I wonder why the authors did not make any evaluation with the binary classifier using two class weights yielding two logits. In that case, one ca directly use CAM methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1268/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742806038,
        "cdate": 1698742806038,
        "tmdate": 1699636053511,
        "mdate": 1699636053511,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pTLfI6HwCV",
        "forum": "gmHtBH8Fnp",
        "replyto": "gmHtBH8Fnp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_rwvH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1268/Reviewer_rwvH"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to highlight the properties of binary classifiers when trained on unbalanced and balanced datasets. The scope of bias is limited to \u201cspurious correlations\u201d among attributes in face datasets. The authors adapt gradient-based CAM techniques to work with binary classifiers and compare imbalanced and balanced models. They also study the interpretability of the proposed method and the baselines via CAMs.\n\nThe authors find that biased binary attribute classifiers tend to ignore the majority classes, leading to poor performance in these classes, and that balanced models perform better in the majority classes and achieve comparable performance in the minority classes. Their work localises the source of bias to the \u201cbias neuron\u201d of the final output layer.\n\nThe authors conclude that it is essential to balance the dataset to improve the performance of binary classifiers. They also suggest that visualising the regions of interest can help improve the interpretability of binary classifiers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This work addresses the shortcomings of GradCAM in binary classification tasks.\n2. The authors have discovered that attributes from majority classes are not necessarily learnt better, which is an intriguing observation contrary to popular beliefs.\n3. The experiments reveal the issues in off-the-self classifiers (AFFACT) with the help of CAMs.\n4. The authors have identified potential improvements in [1] by using the loss of [2].\n\n\n        [1] G\u00fcnther, Manuel, Andras Rozsa, and Terranee E. Boult. \"Affact: Alignment-free facial attribute classification technique.\" 2017 IEEE International Joint Conference on Biometrics (IJCB). IEEE, 2017.\n        [2] Rudd, Ethan M., Manuel G\u00fcnther, and Terrance E. Boult. \"Moon: A mixed objective optimization network for the recognition of facial attributes.\" Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14. Springer International Publishing, 2016."
            },
            "weaknesses": {
                "value": "1. The overall presentation of the paper could be improved\n2. The relationship between modifying GradCAM and balancing the model appears disconnected.\n3. This work seems derivative, extending [1] with the help of [2] without any clear explanation of observations.\n4. Lack of experiments and proper baselines to benchmark against. AFFACT, being effective, is an old approach. Authors need to compare their method with newer ones to make a statement regarding the existence and relevance of this shortcoming.\n5. In Table 1, there\u2019s a tradeoff between FPR and FNR in AFFACT-b, which is not clearly explained. Making the higher scores bold for AFFACT-u makes the table open for misinterpretation."
            },
            "questions": {
                "value": "1. A binary classifier is a special class of categorical classifiers with two classes. It is more generic to use categorical classifiers in tasks with $>= 2$ classes for consistency, and the loss function of a BCE aligns with that of CE with 2 classes. The motivation behind modifying the GradCAM implementation for binary classifiers is not well-presented.\n2. The statement from the abstract, \u201cthough most real-world tasks are binary classification\u201d is not well-founded. Binary classification might solve all tasks using a one-vs-rest approach. Still, the utility of multi-class classification is an actively researched and important aspect which cannot be ignored.\n3. How the authors arrive at the conclusion that the \u201cbias neuron of the last layer is responsible for inducing low performance in minority classes\u201d is unclear.\n4. Is avoiding attention at corners the only improvement that\u2019s made possible in this work? The difference in scores is too negligible to understand.\n5. The proposed method also attends to the corners (Blurry, Figure 2), and hence, the effect of the \u201cbias neuron\u201d (if such a thing exists) is still not done away with completely with the suggested approach.\n6. Figure 1 is a direct copy-paste of Figure 2 in [2]. Can you cite it?\n7. Is the proposed method only applicable to the AFFACT family of models? What happens if we have separate binary classifiers for each attribute?\n8. In the set of experiments, the bias is examined mostly in one direction- where the \"unbiased\" means \"presence : absence of an attribute is 1 : 1\" and biased means \"presence : absence of an attribute is P : 1\" (0<P<1).  Do the results hold if bias is studied from other side, that is,  \"unbiased\" means \"presence : absence of an attribute is 1 : 1\" and biased means \"presence : absence of an attribute is 1 : P\" (0<P<1)? The authors can carry out experiments to understand this.\n9. What is the need for modifying GradCam for binary classification? We can have two neurons and apply softmax on top of it -- that should work for the traditional GradCam."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1268/Reviewer_rwvH"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1268/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698829231615,
        "cdate": 1698829231615,
        "tmdate": 1699636053434,
        "mdate": 1699636053434,
        "license": "CC BY 4.0",
        "version": 2
    }
]