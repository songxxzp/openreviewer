[
    {
        "id": "9qgOUytLqz",
        "forum": "hj9ZuNimRl",
        "replyto": "hj9ZuNimRl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_Uu92"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_Uu92"
        ],
        "content": {
            "summary": {
                "value": "The authors proposed a mesh mover based PDE solver in this paper. The solver consists of two main components: a mesh mover and a neural PDE solver. The mesh mover is trained unsupervised based on a physical loss motivated by optimal-transport based Monge-Amp`ere mesh movement method. The GNN neural PDE solver is trained supervised given solutions from numerical simulations. The experiments show that the proposed method can outperform existing NN solvers on 2D Burger's equation and flow past cylinder cases."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The idea to design a neural PDE solver with mesh movement method is novel.\n- The Monge-Amp`ere equation motivated physics loss for mesh mover training is intuitive. \n- The use of BFGS for memory intensive training and the sampling method for Monge-Ampere equation are sound.\n- The background part is informative and help understand the proposed method."
            },
            "weaknesses": {
                "value": "- One essential challenge for r-adaptive (i.e., mesh movement) based mesh adaptive methods is mesh tangling. The mesh tangling happens when the mesh have elements with negative Jacobian-determinant, or in other words, the edges of mesh nodes come across each other after being moved. Although the optimal-transport based Monge-Amp`ere mesh movement method is designed to alleviate the mesh tangling issue, it is hard to guarantee tangling-free especially for a learned model, which only has a soft physical loss as the constraint. It is unclear how the proposed DMM perform regarding mesh tangling as there are no related evaluations in the paper.\n- The Monge-Amp`ere based physical loss is the key contribution of this paper, however it is not clear how each part of the loss i.e. $loss_{equation}$, $loss_{bound}$ and $loss_{convex}$ contribute to the model performance.\n- The experiments are limited to one fixed mesh resolution (48 x 48 or 2521 triangular lattices) and there are no evaluations on generalization of the proposed model, i.e., trained on a (small) resolution and test on other (potentially larger) resolution. Therefore, it is not clear how the proposed method perform given unseen data / boundary conditions/ physical parameters in equations. \n- The presentation and text of the paper should be improved."
            },
            "questions": {
                "value": "- The mesh tangling is a key challenge for mesh movement methods. It is hard to evaluate the performance of the proposed mesh mover without the evaluations on this potential issue. I would suggest that adding a solid discussion for mesh tangling will improve the soundness of this paper.\n- Regarding to the physical loss, the $loss_{equation}$ part is designed based on the difference between the current mesh and the uniform mesh. In a time-dependent problem, does it indicate the mesh mover always move the mesh nodes starting from the very initial uniform mesh without using the moved mesh in the last timestep? Does this strategy perform better comparing to reuse the previous moved mesh as the starting mesh? \n- An ablation study for contributions of each components in the physical loss ($loss_{equation}$, $loss_{bound}$ and $loss_{convex}$) will help evaluate its effectiveness.\n- Mesh movement methods may struggle with cases where the monitor functions give large values near boundaries, e.g. the peak values of the initial conditions of the burger's equation are located close to simulation domain boundary. It would be more convincing if there are such test cases for evaluating the proposed model. \n- It is mentioned in the paper that the mesh for Burger's is 48x48, however it is only 20x20 shown in Figure 2. Are there any missing results for the 48 x 48 resolution?\n\nMinors:\n- The DMM model architecture is not shown in Figure 2(a)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Reviewer_Uu92"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5965/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698483181960,
        "cdate": 1698483181960,
        "tmdate": 1700764553056,
        "mdate": 1700764553056,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QMaPvl0GXP",
        "forum": "hj9ZuNimRl",
        "replyto": "hj9ZuNimRl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_W4Uo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_W4Uo"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a mesh moving method to improve dynamics learning of graph neural networks. Theoretical understanding of the neural mesh adapter is provided, and empirical results are shown on two problems: the Burgers' equation and flow past cylinder, both in 2D."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "A detailed explanation was provided for the framework, with plenty of background information. The method applies well in practice, and the appendix provides enough technical detail on results in the main paper."
            },
            "weaknesses": {
                "value": "1. Runtimes should be mentioned for the proposed model, especially when comparing with equivalent methods such as GNN, CNN, FNO and LAMP. How much overhead does DMM require, and what number of extra trainable parameters are we talking about in practice?\n2. When training the DMM separately, how well is the physics loss being minimized? It is important to know to what extent the equations need to be satisfied until we see an improvement in MM-PDE.\n3. A sentence of explanation should be added when training the DMM, where we use a combination of both Adam and BFGS, but only finetune the last layer. Did this show the best performance? Why did Adam alone not suffice. When the high memory consumption is mentioned, what numbers is required by the two example problems shown in this paper?\n4. From a practitioner's perspective, it is unclear why the metric for cell volume matters for the examples, aside from showing that the DMM loss was minimized. Most importantly, we never perform any testing on the adapted/moved mesh, hence its structure can be arbitrary as long as it is conducive to the training of the GNN. It has been shown that uniform meshes as a representation perform worse, but is it the case that reducing the cell volume std and range will also monotonically decrease the test loss of the model? \n5. For the non-uniform grid example in flow past cylinder, CNN and FNO were not considered. Would the non-uniform equivalent of FNO, the Geometry-Aware FNO GeoFNO, be applicable as a baseline? If so, comparing with non-uniform state-of-the-art methods would strengthen the paper as well.  \n6. More details should be added on the experimental results, for example, for the flow past cylinder, is the MSE computed on just the velocity, or also pressures? The values reported in Table 2 seem relatively high then, perhaps visualization of the rollout results could also be added to the appendix."
            },
            "questions": {
                "value": "1. The implications of the ablation study are that having a trainable DMM performs better, but having it trainable also means now it is finetuning on the MSE loss from the solution data, hence the DMM equations may no longer hold. Did you quantify the std and range of cell volumes after this mm+end2end training as well?\n2. How are the DMM loss derivatives computed, using finite differences, or autodifferentiability?\n3. Is there any limitation in terms of extending the framework to 3D problems? Computational complexity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Reviewer_W4Uo"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5965/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698694556822,
        "cdate": 1698694556822,
        "tmdate": 1699636636943,
        "mdate": 1699636636943,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L5IBkYwCyf",
        "forum": "hj9ZuNimRl",
        "replyto": "hj9ZuNimRl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_qbBA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5965/Reviewer_qbBA"
        ],
        "content": {
            "summary": {
                "value": "The authors have introduced the Data-free Mesh Mover (DMM) as an innovative component for neural PDE solvers. DMM functions as a mesh adaptation solver, facilitating the adjustment of node positions within a uniform mesh. It's referred to as \"data-free\" because it achieves an optimal mesh configuration by solving the Monge-Ampere equation. The DMM is subsequently integrated with the MM-PDE (Message passing neural PDE solvers) to enhance overall accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The application of adaptive meshes will improve the accuracy."
            },
            "weaknesses": {
                "value": "- The efficiency of DMM requires further comprehensive demonstration.\n- The contribution of this work appears to be incremental, as the core neural PDE solver used is essentially the message passing neural PDE solver developed by Brandstetter et al."
            },
            "questions": {
                "value": "- My main concern is on the efficiency of DMM. As data-free, for each input solution $u$, training is needed. Then this can be very costly. Can authors compare the time if using the conventional PDE solver for the mesh adaptation? \n- For time-dependent problems, what is the input $u$? At the current time step or the next time step? The singularity of the solution could move. The mesh obtained for $u_k$ may not be suitable for $u_{k+1}$. \n- The error listed in Table 1 shows MM-PDE only improves from around $2 \\times 10^{-6}$ to $6.7 \\times 10^{-7}$ and in Table 2 is from $0.0258$ to $0.0141$ using a bigger GNN. Then a fair comparison is the computational time of MM-PDE and the bigger GNN to achieve the same error. A bigger GNN may need a larger model size, but since no DMM solver is involved, the overall time might be smaller. Again, this is related to Question 1: the efficiency of DMM.\n- Evaluation metric. Why not compute the interpolation error directly instead of an upper bound on the interpolation error?\n- \"Two-order\" should be corrected to \"second order.\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5965/Reviewer_qbBA",
                    "ICLR.cc/2024/Conference/Submission5965/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5965/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723495332,
        "cdate": 1698723495332,
        "tmdate": 1700684198686,
        "mdate": 1700684198686,
        "license": "CC BY 4.0",
        "version": 2
    }
]