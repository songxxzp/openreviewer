[
    {
        "id": "GafhgEOVUm",
        "forum": "m8KWOgE0Cn",
        "replyto": "m8KWOgE0Cn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_ewfD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_ewfD"
        ],
        "content": {
            "summary": {
                "value": "In this study, the authors introduce a federated domain adaptation model designed to train personalized FL models. The model in question is an adaptation of the FENDA domain adaptation method, leveraging both a global feature extractor and a local feature extractor to adapt data across different domains. Evaluations of the model have been conducted on an FL benchmark dataset as well as a real-world clinical dataset."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The experimental design is thorough, and the paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "My major concern is a significant oversight in this work, which is the absence of discussions of an important line of related works - federated domain adaptation/generalization. This topic is closely related to the central topic of this paper. There are many advanced techniques for federated domain adaptation/generalization in recent years, for examples [1-2] and numerous other contributions in this domain. Yet, the authors seem to have omitted any discussion contrasting their proposed model with these works, nor have they incorporated them as baseline models for comparison. The decision to utilize the FENDA model, which appears potentially outdated in the domain adaptation field, raises concerns. Without comparing the proposed model against current SOTA methods in the field of federated domain adaptation, it is hard to assert that the domain adaptation strategy showcased here represents the state-of-the-art in FL.\n\n[1] Yao, C. H., Gong, B., Qi, H., Cui, Y., Zhu, Y., & Yang, M. H. (2022). Federated multi-target domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1424-1433).\n[2] Zhang, R., Xu, Q., Yao, J., Zhang, Y., Tian, Q., & Wang, Y. (2023). Federated domain generalization with generalization adjustment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3954-3963)."
            },
            "questions": {
                "value": "Please address the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Reviewer_ewfD"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698516332072,
        "cdate": 1698516332072,
        "tmdate": 1699636221077,
        "mdate": 1699636221077,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BpHRT6fTD8",
        "forum": "m8KWOgE0Cn",
        "replyto": "m8KWOgE0Cn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_Hvzv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_Hvzv"
        ],
        "content": {
            "summary": {
                "value": "This paper adapts the FENDA method to the federated setting. The central concept involves maintaining both local feature extractors and global feature extractors for each client, with the central server utilizing Fedavg to aggregate the weights of the global feature extractors from each client. The paper rigorously assesses the proposed method using benchmarks and real-world tasks, enhancing evaluation robustness by conscientiously selecting checkpoints based on cross-validation and employing additional baseline comparisons."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The method is comprehensible and straightforward.\n- The experiments meticulously evaluate the proposed method by selecting the appropriate checkpoints, which are convincing and robust. The real-world clinical scenarios are well-suited for federated learning."
            },
            "weaknesses": {
                "value": "- This paper addresses the challenge of personalized federated learning using heterogeneous local datasets; however, the mechanism is not thoroughly explained. The proposed method draws inspiration from domain adaptation, where distribution shifts naturally occur. In this paper, local clients have datasets sampled from various distributions. The question arises: What types of distribution shifts (such as feature shifts or label shifts) can the proposed method effectively handle?"
            },
            "questions": {
                "value": "Please describe the mechanism of the proposed method in detail and elucidate its effectiveness in addressing different types of distribution shifts, particularly in the context of client dataset heterogeneity."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Reviewer_Hvzv",
                    "ICLR.cc/2024/Conference/Submission2784/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698658096700,
        "cdate": 1698658096700,
        "tmdate": 1700715213617,
        "mdate": 1700715213617,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3BllYQY4zh",
        "forum": "m8KWOgE0Cn",
        "replyto": "m8KWOgE0Cn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_ubEK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_ubEK"
        ],
        "content": {
            "summary": {
                "value": "This work expands on the federated learning space in clinincal domain by extending the FENDA method (a domain adaptation method) to federated learning, while showing improvements on the FLamby benchmark."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Clear presentation, well written paper. \n- Appropriate comparison of baselines on the FLamby benchmark.\n- Extensive analysis of multiple other baselines"
            },
            "weaknesses": {
                "value": "- It would be nicer to also see a table of the results, rather than a visual representation due to the number of settings. Minor comment: The color choices for the bar graphs seem to represent goodness, with red being worse and blue being better; however, the different colors are a little jarring and could cause confusion.\n- The performance benefit compared to APFL shown in Fig. 2 is not very clear, also in Fig. 3, a similar obersvation can be made for FedAVG and APFL"
            },
            "questions": {
                "value": "- The idea of using domain adaptation seems like a natural pairing with FL. Can the authors include a discussion on the inherent differences / relationships between these 2 fields for better context? Google scholar reveals some papers such as https://arxiv.org/abs/1911.02054 and https://arxiv.org/abs/1912.06733 which may be relevant.\n- Is it possible to release a version of the code that works for open-source datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2784/Reviewer_ubEK"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698739683672,
        "cdate": 1698739683672,
        "tmdate": 1699636220860,
        "mdate": 1699636220860,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EZmkBzHXRN",
        "forum": "m8KWOgE0Cn",
        "replyto": "m8KWOgE0Cn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_kWTA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2784/Reviewer_kWTA"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce FENDA-FL, an adaptation of the Frustratingly Easy Neural Domain Adaptation (FENDA) method for FL, focusing on the personalized FL paradigm where each participant trains a model tailored to their local data distribution. The effectiveness of FENDA-FL is demonstrated through comprehensive experiments using various clinically relevant datasets, including a subset from the FLamby benchmark and tasks from the GEMINI datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The application of the FENDA method, originally used for domain adaptation, to Federated Learning (FL) is effective, aligning domain-agnostic features with FL's global components and domain-specific traits with local elements."
            },
            "weaknesses": {
                "value": "- While adapting FENDA's concept to the FL scenario required some modifications, the application of FENDA in this methodology appears overly incremental. The approach of combining features to utilize both global and local information, as opposed to APFL's method of aggregating logits, is not particularly novel.\n- The methodological contribution to the ICLR community unclear. The application of FENDA to federated learning is straightforward, \"federated checkpointing\" is conceptually a combination early stopping with federated learning.\n- The paper lacks a thorough ablation study on federated checkpointing methods. Additionally, while it benefits from not restricting the network architectures between global and local feature extractors, it would have been informative to show performance variations with the use of diverse network architectures.\n- The paper could greatly improve the visibility of performance differences between methodologies in its figures. Currently, the color-coding for each method is not distinct enough, and the representation of all performances via bar graphs makes it challenging to discern if the differences, including standard deviations, are statistically significant. In terms of visibility, it falls significantly short."
            },
            "questions": {
                "value": "Please see the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2784/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698838870799,
        "cdate": 1698838870799,
        "tmdate": 1699636220792,
        "mdate": 1699636220792,
        "license": "CC BY 4.0",
        "version": 2
    }
]