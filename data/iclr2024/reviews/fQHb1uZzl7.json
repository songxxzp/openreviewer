[
    {
        "id": "nclKPlabOl",
        "forum": "fQHb1uZzl7",
        "replyto": "fQHb1uZzl7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission806/Reviewer_HY22"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission806/Reviewer_HY22"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a dense matching estimation method by unifying both feature and cost volume aggregation with transformer. The authors first analyze the merits and faults of feature and cost aggregation and then claim that using them interleavely could improve the feature representation. Experiment results show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. To the best of my knowledge, this is the first work that discusses the relationship between feature and cost aggregation (learning). The authors carefully discuss their merits and faults in Sec.1 and Sec.3.\n2. Interleavely aggregating features between feature and cost volumes is interesting. The visualization results of Fig.2, and Fig.3 also verify the effectiveness.\n3. The authors provide complete experimental details in the supplementary."
            },
            "weaknesses": {
                "value": "1. The usage of \"aggregation\" is a little confusing. In my opinion, \"aggregation\" means combining multiple features into a single one, which should usually be used to describe the process of attention aggregation of ($QK^T$ and $V$). However, I am not sure whether \"aggregation\" is suitable to be used to indicate the whole learning process of cost volume learning. Because many cost volume learning is not related to attention learning.\n2. Although the authors analyze the merits of feature/cost aggregation, some claims have not been clarified. For example, feature matching is \"challenged by repetitive patterns and background clutters\", while cost volume learning enjoys \"robustness to repetitive patterns and background clutter\". No evidence is shown in this paper to support this claim.\n3. The authors did not formulate the method presentation well in Sec.4 and Fig.4, which makes the proposed method suffer from too complicated designs and difficult to follow. I strongly recommend the authors introduce the shape and reshape of the most important tensors to make the whole pipeline clearer. The concatenation in Eq(3) is operated along which dimension? Why $C'$ appears again in Eq.5 as $QK^T$, while $C'$ should be already defined as the output of the cost volume feature?\n4. The experiments are not solid enough. The proposed method needs to be compared with more recent methods. In the geometric matching results from Tab2, most competitors are from 2020 and 2021, which are far from \"state-of-the-art\". Only one flow estimation method is considered (GMFlow). However, as discussed in the supplementary, the comparison is not fair, because GMFlow is trained on Sintel rather than DPED-CityScape-ADE+MegaDepth fine-tuning. Besides, all these competitors are trained on DPED-CityScape-ADE **or** MegaDepth (the proposed method is trained with DPED-CityScape-ADE **and** MegaDepth finetuning) as said in supplementary B.1. The authors should clarify this."
            },
            "questions": {
                "value": "As discussed in the related works, many stereo-matching and optical flow works use Transformer-based cost aggregation networks. \nThe idea proposed in this paper should be a general way to improve all feature matching-based tasks, and I think there are no enormous model differences among stereo, flow, and dense matching. So the authors should compare these SOTA stereo and flow methods in a more fair way. For example, re-training the model with the same data setting for dense matching or verifying the effectiveness of the proposed method in stereo and flow estimation benchmarks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698486722506,
        "cdate": 1698486722506,
        "tmdate": 1699636007877,
        "mdate": 1699636007877,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pjApO7ILGu",
        "forum": "fQHb1uZzl7",
        "replyto": "fQHb1uZzl7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission806/Reviewer_gxEA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission806/Reviewer_gxEA"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to combine feature and cost aggregation to address the dense feature matching task.\n\nThe main idea is to use cost score matrix for both self- and cross-attention feature updating, to learn more discriminative features and compute better cost matrix.\n\nExperiments on some semantic and geometric matching datasets show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) This paper is generally presented well;\n\n2) The idea of use cost score matrix for both self- and cross-attention feature updating is simple and effective;\n\n3) Experimental results are good."
            },
            "weaknesses": {
                "value": "1)  Section 5.1. It is quite blurry for me whether previous state-of-the-art methods in Table 1 and 2 are trained on the same datasets; For example, the proposed method is trained on the DPED-CityScape-ADE and MegaDepth datasets;\n\n2) The performance of the proposed method on the optical flow (KITTI, Sintel) task is blurry for me;\n\n3) It's good to see the improved matching performance on the HPatches dataset. However, I want to see whether the improved matching would lead to better Rotation and translation estimations. \n\n4) Using cost score matrix for both self- and cross-attention feature updating is good. However, this contribution may be constrained to large overlapping ratio between images. If pairwise images have small overlapping ratio, the cost score matrix is noisy, and may provide wrong guidance for feature updating. Would you please check whether the proposed method works on some challenging image pairs from the MegaDepth dataset.\n\n5) Please show some failure cases."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636963108,
        "cdate": 1698636963108,
        "tmdate": 1699636007792,
        "mdate": 1699636007792,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VZu8hjoEUk",
        "forum": "fQHb1uZzl7",
        "replyto": "fQHb1uZzl7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission806/Reviewer_4EyK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission806/Reviewer_4EyK"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new vision transformer architecture to conduct feature aggregation and cost aggregation for dense matching tasks. The authors show distinct characteristics of feature aggregation and cost aggregation. and use self- and cross-attention mechanisms to unify the feature and cost aggregation. They validate the effectiveness of the proposed method with semantic matching and geometry matching."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea to unify feature aggregation and cost aggregation is interesting. It compensates for the lack of semantic information in cost representation and helps to drive the features in each image to become more compatible with others.\n2. They conduct extensive experiments on semantic matching and geometry matching to validate the effectiveness of the proposed method UFC. UFC can improve the matching performance. And they provide step-by-step ablations of each component.\n3. The paper is well-organized and easy to understand. The authors visualize the changes in feature maps and cost volumes, which helps understand how their method works. I see that feature aggregation can preserve semantic information and geometry structure and the cost aggregation reduces the noise in cost volumes."
            },
            "weaknesses": {
                "value": "1. In visualization results Figure 2, features with integrative aggregation methodology preserve the semantic information. However, it seems the proposed method damages the local discriminative ability of features."
            },
            "questions": {
                "value": "1. The local discriminative ability of features is also important for dense matching tasks. I would like to see an analysis of whether the proposed method causes damage in this perspective or whether this issue can be avoided in some design of the method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission806/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission806/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission806/Reviewer_4EyK"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698732767371,
        "cdate": 1698732767371,
        "tmdate": 1699636007716,
        "mdate": 1699636007716,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iPnM5osvMB",
        "forum": "fQHb1uZzl7",
        "replyto": "fQHb1uZzl7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission806/Reviewer_96VU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission806/Reviewer_96VU"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an integrative feature and cost aggregation modules in a CNN architecture for a semantic correspondence task. The introduced module cleans up noisy matches in the cost volume and thus improves the matching accuracy. The paper demonstrates better accuracy on semantic matching and geometric matching tasks by using their method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Good results\n\n  The paper achieves good accuracy on both semantic and geometric matching tasks (Table 1 and 2). It demonstrates the effectiveness of the proposed aggregation modules.\n\n- Detail analysis\n\n  The paper provides a sufficient amount of analysis. Fig. 3 visualizes the qualitative comparison of the proposed modules (from (f) to (h)). Further, the ablation study (Table 3 and 4) validates the proposed ideas."
            },
            "weaknesses": {
                "value": "Despite the good accuracy on both tasks, there are concerns about novelty/contributions.\n\n- Existing ideas in other literature\n\n  Similar ideas on feature and cost volume aggregation have been demonstrated in other literature such as stereo matching [a,b] and optical flow estimation [c]. Actually the related work section (Sec. 2) summarizes those relevant papers very well. Compared to the existing solutions, what would be the new technical design (in self-/cross-attention) of the proposed module, except for applying it to semantic & geometric matching problems? Can the newer technical design from the proposed module also benefit other tasks that use cost volume, eg., stereo matching, optical flow, scene flow, etc. ?\n\n   [a] Attention-Aware Feature Aggregation for Real-time Stereo Matching on Edge Devices, ACCV 2020\n   \n   [b] Attention Concatenation Volume for Accurate and Efficient Stereo Matching, CVPR 2022\n   \n   [c] GMFlow: Learning Optical Flow via Global Matching, CVPR 2022\n\n- Limitation\n\n  Discussion on the limitation is missing. What would be the limitation of the method or unsolved problems?\n\n\n- Can the paper provide more qualitative examples and discuss where the gain mainly originates?\n\n  Table 4 shows the accuracy improvement by adding more components. I am wondering if the paper can also include some qualitative examples and discuss where the gain mainly originates, such as resolving some particular matching ambiguity. It would be great if the paper can provide more insights related to its improvement."
            },
            "questions": {
                "value": "- Increase of learnable parameters\n\n  How many number of learnable parameters account for the new module (i.e., integrative feature and cost aggregation module)? How significant are they compared to the number of parameters of the entire network (15.5M)? Probably it's also good to include an extra column in Table 3 and 4 for the number of network parameters.\n\n- Resolution of the cost volume\n\n  What's the resolution of the cost volume (saying the input image resolution is HxW)? At each level the features are upsampled ($D^{l}_s$), but how can the resolution of the cost volume ($C^{l})$ remain the same over different pyramid levels? Is there any reason to fix the resolution of the cost volume?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission806/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812465428,
        "cdate": 1698812465428,
        "tmdate": 1699636007642,
        "mdate": 1699636007642,
        "license": "CC BY 4.0",
        "version": 2
    }
]