[
    {
        "id": "CEQskxkbUn",
        "forum": "u7LFI98JI6",
        "replyto": "u7LFI98JI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_9eTr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_9eTr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes GraphDeepONet, an autoregressive model that combine DeepONet and GNN to solve partial differential equation. GraphDeepONet outperforms existing GNN-based neural PDE solvers on both regular and irregular grids. By inheriting the advantages from DeepONet, the proposed method can perform prediction on arbitrary grids. Moreover, this method is able to do time extrapolation which is not feasible in the traditional DeepONet."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This method incorporates time information into the branch net using a GNN and enables time extrapolation prediction for PDE. \n- Compared to other GNN-based PDE solvers, GraphDeepONet shows superior accuracy in predicting solution at arbitrary positions on irregular grids. \n- The proposed method has a theoretical guarantee that it is universally capable of approximating continuous operators for arbitrary time intervals.\n- Overall this paper is well-written, and the presentation is clear and easy to follow."
            },
            "weaknesses": {
                "value": "The evaluation of the proposed methods is not enough, specifically:\n- 1D Burger equation and 2D shallow water are much easier PDEs. In most papers, 2D incompressible Navier-Stokes equation is considered as a test PDE. I highly recommend authors to add experiments on 2D NS equation to show the effectiveness of their method.\n- In table 1, the performance of GraphDeepONet are consistently worse than FNO-2D, and FNO-2D is not a recent model on regular grid. This could be a major weakness. I recommend authors compare their method with state-of-the-art model on regular grids, such as FFNO [2] and GFNO [3].\n- For irregular domain, there are several FNO-based method can handle irregular grids, such as GeoFNO [1] and FFNO[2]. For completeness, I think these methods should also be considered as baselines on irregular grids.\n\n[1] Li, Zongyi, et al. \"Fourier neural operator with learned deformations for pdes on general geometries.\" arXiv preprint arXiv:2207.05209 (2022).\\\n[2] Tran, Alasdair, et al. \"Factorized fourier neural operators.\" arXiv preprint arXiv:2111.13802 (2021). \\\n[3] Helwig, Jacob, et al. \"Group Equivariant Fourier Neural Operators for Partial Differential Equations.\" arXiv preprint arXiv:2306.05697 (2023)."
            },
            "questions": {
                "value": "see weakness part"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7592/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698693812924,
        "cdate": 1698693812924,
        "tmdate": 1699636919809,
        "mdate": 1699636919809,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MUiNXc6chB",
        "forum": "u7LFI98JI6",
        "replyto": "u7LFI98JI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_XsTS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_XsTS"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes GraphDeepONet (GDON), which extends the capacity of DeepONet [Lu+ 2019] to enable extrapolating time evolution. The authors suggest incorporating temporal information into the branch net instead of the trunk net. The mathematical analysis shows that the method still maintains the universal approximation property. In addition, theorem 2 shows that graph-based models can fail to approximate a solution to the considered problem, implying the superiority of the proposed operator-based approach that enables interpolation in space. The experimental results demonstrate that the proposed approach has good stability regarding irregular grids."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The method extends operator learning approaches by separating dependencies of time and space into branch net and trunk net, respectively.\n* The theoretical analysis supports the methods' expressibility and superiority compared to graph-based models.\n* Experimental results show that the method has good stability regarding irregular grids, which is preferable in a realistic application."
            },
            "weaknesses": {
                "value": "* The experiments seem not to be complete. The method incorporates global interaction using Equation 8. Therefore, it would be fair to compare with graph neural networks with varying numbers of hops visible to GNNs. In addition, the authors should show the computation time-accuracy tradeoff because the method seems to have a massive computation cost.\n* Related to the first point, it is not clear to use machine learning over classical numerical analyses. The authors should clarify the superiority of the method compared to classical analysis, e.g., in terms of computational time.\n* The paper states that the method can predict the solution for any x in R^d (Section 3.5). However, the reviewer believes the method can interpolate in space but extrapolate. Therefore, the reviewer suggests the authors weaken the statement, e.g., x in \\Omega. Otherwise, the authors should demonstrate that the method can extrapolate in space.\n\n### Minor points\n* In Section 1, the term \"Trunk net\" is used without explanation, which could be unclear for readers unfamiliar with DeepONet. Therefore, the authors could add some explanations about it or not touch such details in the introduction.\n* In Table 1, \\pi could be \\pm.\n* Section 4 (Comparison with GNN-based PDE-solvers): \"2 summarizes\" -> \"Table 2 summarizes\""
            },
            "questions": {
                "value": "* The paper states that the method can deal with periodic boundary conditions. How about other ones (e.g., Dirichlet and Neumann)?\n* By looking at Figure 3, the proposed method gives a non-smooth solution in time and space. Why does it happen and how to improve the situation? The smoothness of the solution is sometimes essential for downstream tasks if we would like to compute the derivative of the solution.\n* By MPNN, the authors mean MP-PDE [Brandstetter+ 2022]? In my understanding, MPNN usually refers to the message-passing neural networks [Glimer+ 2017]. If the authors mean [Brandstetter+ 2022], the reviewer recommends using MP-PDE or other appropriate abbreviations different from MPNN. If the authors did not compare with MP-PDE, the reviewer strongly recommends doing it because the dataset is extracted from that work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Reviewer_XsTS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7592/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698695243164,
        "cdate": 1698695243164,
        "tmdate": 1699636919688,
        "mdate": 1699636919688,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4eOAmYt8CO",
        "forum": "u7LFI98JI6",
        "replyto": "u7LFI98JI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_Y4J4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_Y4J4"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a graph-based DeepONet to learn a data-driven operator that can infer an approximation to the solution at arbitrary query points. The presentation feels disjointed for different parts of the paper. The theoretical contributions are arguably minor versus those in Brandstetter et al. ICLR 2022 and Lanthaler et al. TrMA 2022, and the neural architecture is almost exactly the same with VIDON (Prasthofer et al. arXiv:2205.11404, page 3 to page 4), while experimentally performs worse than Lee-Cho-Hwang ICLR 2023 in Burgers' benchmark. Currently, this paper does not read as an ICLR caliber paper."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- One of the key changes from coefficient based on initial (previous) input and \"basis\" being spatial-temporal to coefficient varies time to time, and the \"basis\" fixed. This is a mathematically well-motivated (similar to semi-discretization for functions in Bochner spaces), and meshes well with traditional reduced-order methods for spatiotemporal PDEs.\n- The latent representations (lots of channels) are updated in an autoregressive fashion, instead of doing so for the predicted solution (single channel for a scalar function). Taking advantage of the natural architectural advantage (though references are missing)."
            },
            "weaknesses": {
                "value": "- The key theorem, Theorem 1, is almost identical to Theorem 3.1 in the VIDON paper, even how it is proved through breaking the error down using a split taking advantages of pseudo-inverses. The only addition to Theorem 3.1 in VIDON paper is the summation in time. However, for all the PDEs with the first order time derivatives, the natural Bochner space is $L^2([0, t], V)$ where $V$ is a Sobolev space spatially, due to various energy laws. This makes how the solutions are aggregated in time in Theorem 1 is not quite right.\n- The coefficients are aggregated using an attention-like product, yet in the UAT proved later, it is not proved that this choice of coefficient has the capacity to combine the \"basis\" get the error bound. A more handily different form is used on page 16 before definition 2. $c_j$ is out of nowhere in the proof of Lemma 2 as well, the $|\\cdot |_{\\ell^p}$ goes undefined as well.\n- In the proof of Theorem 2, it reads \"$\\mathcal{G}_{\\text{graph}}$ in Definition [ ]\".\n- The proof of Theorem 2 uses a very special grid to show the undefined $\\mathcal{G}_{\\text{graph}}$ above cannot approximate the solution with a very special initial condition. Given this grid, and the 50-50 chance $\\mu$ associated with $f_1$, $f_2$ constructed on this grid, the new model will still fail to approximate.\n- While I understand the $\\{\\tau_j(\\cdot)\\}$ are mostly referred to as \"basis\" in DeepONet literature, this feels quite uncomfortable. Unlike FNO having a natural basis, in DeepONet, there is no effort to actually make this set a basis. Especially, it is long known in the transfer learning community, a large number of channels in latent, especially expanded from a few initial channels, introduced a lot of redundancy.\n- On page 6, it says \"since the GraphDeepONet use the trunk net to learn\nthe global basis, it offers a significant advantage in enforcing the boundary condition $B[u] = 0$\nas hard constraints\". This does not make sense at all: even for the simplest homogeneous Dirichlet BC that $u=0$ on $\\partial \\Omega$, given any $\\boldsymbol{x}\\in \\partial \\Omega$, if the BC are \"hard constraints\", then $\\tau_j(\\boldsymbol{x})$ should be exactly 0, and there is no such MLP that can do this. \n- Missing references and/or baseline comparison:\n    - NN-based ROM/POD for time-dependent PDEs. Equation (3) is the same with the Karhunen-Loeve decomposition used in POD, e.g., $u(t, x) - u(t_0, x)$ is approximated by $\\sum_{j=1}^p a_j(t) \\tau_j(x)$ where $\\tau_j(x)$ are spatial functions corresponding to the POD modes and $a_j(t)$ are the amplitudes of these modes in time.\n    - Galerkin projection method for PDE operator learning using Transformers.\n    - Efforts to make FNO work for arbitrary collocation points, such as Vandermonde NO (arXiv:2305.19663), NUFFT-based FNO (arXiv:2212.04689).\n    - Latent state dynamics/marching schemes, e.g., Yin et al, ICLR 2023.\n\n### Minor things\n- Page 3: I have rarely seen people using $\\dfrac{\\partial^2 u}{\\partial \\boldsymbol{x}^2}$ to represent the Hessian in PDE textbooks, e.g., please check Evans Appendix A.3 and A.5.\n- Page 3: if $\\mathcal{G}$ represents a mapping between function spaces, then the notation \"$\\mathcal{G}: u^0(\\boldsymbol{x}) \\mapsto u^k(\\boldsymbol{x})$\" is technically incorrect."
            },
            "questions": {
                "value": "- Page 5: How $\\phi$ and $\\psi$ are constructed is quite unclear, for example, given a different set of \"sensor\" points, does the user have to give the adjacency matrix as well? and how the adjacency matrix are multiplied? What quantifies as the \"neighboring\" nodes?\n- VIDON paper does not have a spatiotemporal architecture, how the authors change VIDON to ensure a fair comparison with the new proposed model?\n- Throughout the paper, the function in consideration has periodical boundary condition. On page 6, it says \"GraphDeepONet can enforce periodic boundaries\", please explain how enforcing PBC is possible.\n- The time extrapolation comparison figure has a very weird artifact for GraphDeepONet."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7592/Reviewer_Y4J4"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7592/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824798531,
        "cdate": 1698824798531,
        "tmdate": 1699636919559,
        "mdate": 1699636919559,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "X8aWN7vDmG",
        "forum": "u7LFI98JI6",
        "replyto": "u7LFI98JI6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_Rs7H"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7592/Reviewer_Rs7H"
        ],
        "content": {
            "summary": {
                "value": "This paper combines GNN with DeepOnet for dynamic modeling, empirically shows better predictive accuracy, and shows some theoretical analysis on theoretical guarantee."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors demonstrate the ability to extrapolate which DeepONet cannot do and show this approach can achieve better predictive accuracy compared to another graph-based method and is able to better enforce boundary conditions (due to DeepONet formulation)."
            },
            "weaknesses": {
                "value": "It's not clear why we want to have DeepONet + GNN. It seems that the main modification is having a DeepONet-inspired decoder to get the solution at any spatial point. It would be nice to have the intuition or insights behind this. experiments-wise - one 1D example and one 2D example also seems not as strong as other paper published."
            },
            "questions": {
                "value": "1. I am curious about the intuition and reason that this method outperforms another graph-based approach on irregular grids - such as MeshGrpahNet. \n2. how are the input graph edges formed? \n3. how is the boundary condition enforced like Ricker or Neumann or periodic enforced?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7592/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699245923801,
        "cdate": 1699245923801,
        "tmdate": 1699636919452,
        "mdate": 1699636919452,
        "license": "CC BY 4.0",
        "version": 2
    }
]