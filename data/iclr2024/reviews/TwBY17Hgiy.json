[
    {
        "id": "zN6GMcz4kW",
        "forum": "TwBY17Hgiy",
        "replyto": "TwBY17Hgiy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_4RSv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_4RSv"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a structured 3D-aware regularizer for multi-task learning (MTL) in computer vision. The regularizer interfaces multiple tasks by projecting features from an image encoder to a shared 3D feature space and decoding them into task output space through differentiable rendering."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper provides clear explanations of the proposed method, the problem it addresses, and the evaluation process. \n\n* The paper's contributions have significant implications for multi-task learning in computer vision. The structured 3D-aware regularizer can be integrated into existing models, improving their performance and reducing noise in cross-task correlations."
            },
            "weaknesses": {
                "value": "* The paper could benefit from a more extensive analysis of the proposed method's computational efficiency. While it is mentioned that the regularizer does not introduce additional computational cost for inference, a more detailed analysis or comparison with other methods in terms of computational efficiency would strengthen the paper.\n\n* It would be beneficial to discuss the limitations or potential failure cases of the proposed 3D-aware regularizer. It would be valuable to address any potential drawbacks or scenarios where the regularizer may not be as effective.\n\n* The paper lacks a thorough comparison with existing state-of-the-art methods in multi-task learning. It would be beneficial to include comparisons with other regularization techniques or approaches that address the problem of noisy cross-task correlations."
            },
            "questions": {
                "value": "See weakness section for more details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2635/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698532916351,
        "cdate": 1698532916351,
        "tmdate": 1699636203495,
        "mdate": 1699636203495,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xitnNgElI2",
        "forum": "TwBY17Hgiy",
        "replyto": "TwBY17Hgiy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_boi3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_boi3"
        ],
        "content": {
            "summary": {
                "value": "The paper tackles the problem of multi-task learning for dense tasks like depth prediction, semantic segmentation, normal estimation. Cross-task correlations are noisy and there is no 3D regularization. The paper proposes introducing a latent that is structured and 3D-aware (by outputting a K-planes representation) and uses projection with differentiable rendering and a task specific decoder. The 3D awareness combined with view dependent rendering can be used to both regularize the 3D structure and multi-view consistency on the same 3D latent. Results are shown in NYUv2 and PASCAL-Context datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is quite well-written and easy to follow. The main idea of the paper is clear - to output a 3D feature representation from an image (using K-planes), which can then be used as part of a NeRF-like neural rendering pipeline to project the feature into a 2D feature image which can then be used by a task-specific decoder."
            },
            "weaknesses": {
                "value": "Predicting 3D representations (to use in neural rendering) from unlabeled 2D images and/or text is a relatively common idea [1, 2, 3, 4, 5]. The paper applies this idea in a multi-task setting, and adds a multi-view consistency for multi-view dataset. The results are not highly compelling compared to the baselines in the paper, which may internally learn some 3D structure too. So the explicit formulation of the 3D latent structure is not well motivated, unless the task requires some view editing or novel view synthesis, or an explicit 3D object representation, etc.\n\n____\n[1] Chan, Eric R., et al. \"pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.\n\n[2] Cai, Shengqu, et al. \"Pix2nerf: Unsupervised conditional p-gan for single image to neural radiance fields translation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.\n\n[3] Lin, Chen-Hsuan, et al. \"Magic3d: High-resolution text-to-3d content creation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[4] Zhang, Jingbo, et al. \"Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields.\" arXiv preprint arXiv:2305.11588 (2023). \n\n[5] Gu, Jiatao, et al. \"Stylenerf: A style-based 3d-aware generator for high-resolution image synthesis.\" arXiv preprint arXiv:2110.08985 (2021)."
            },
            "questions": {
                "value": "1. Its unclear if the results are statistically significant compared to the baseline. Since the method can be applied on any baseline MTL architecture, it is unclear if the improvements (especially in Table 2) are just due to randomness of the SGD training dynamics or is an actual improvement. Results over 3-5 trials should be reported if the improvements are marginal/inconsistent.\n\n2. Table 3 shows that multiview consistency may not help in a MTL scenario considered in the paper. What is the significance of this section?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2635/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698628996702,
        "cdate": 1698628996702,
        "tmdate": 1699636203404,
        "mdate": 1699636203404,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FieGFJNYrT",
        "forum": "TwBY17Hgiy",
        "replyto": "TwBY17Hgiy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_girT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_girT"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a structured 3D-aware regularizer that interfaces multiple tasks through the projection of features extracted from an image encoder to a shared 3D feature space and decodes them into their task output space through differentiable rendering. The experiment results are relatively good and promising."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, I like this idea pretty much. For me, this work is like creating a new research line that makes most recognition methods 3D aware, which is dual to another research line that makes 2D image generation tasks 3D-aware. Although the introduced 3D-awared encoder does not explicitly give the 3D representation (I mean this method could not output decent 3D mesh), it gives way to investigating the 3D properties in most recognition tasks."
            },
            "weaknesses": {
                "value": "I paid a lot of expectations on the experiments after reading the Abstract and Introduction sections, but the experiments were not strong enough to match my expectations."
            },
            "questions": {
                "value": "For example, \n1. how is the 3D quality of the learned nerf? \n2. Any geometric insights about the performance improvement? otherwise, it will just be like a regularization paper (1 point improvement, that's all).\n3. I think MTL might not be the best task to show the benefit of your method, do you have any ideas on that?\n\nOverall, I think this is a decent paper to accept, and I know the questions I made above might not be easy to answer. I will increase my score if the authors can offer some convincing and motivated answers."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2635/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698765540314,
        "cdate": 1698765540314,
        "tmdate": 1699636203323,
        "mdate": 1699636203323,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dUHwQoWM9z",
        "forum": "TwBY17Hgiy",
        "replyto": "TwBY17Hgiy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_aMPL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2635/Reviewer_aMPL"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to improve multi-task dense prediction by introducing a 3D representation branch during training. This 3D-aware branch(a triplane representation with volumetric render) shares the same backbone as a conventional multi-task learning setup. This NeRF branch encourages the feature extracted from the backbone to contain rich 3D information and to follow the physical imaging process. \n This 3D-aware head also enables supervising with multi-view consistency. Experiments show that this auxiliary 3D aware branch helps improve the performance of the conventional branch during inference when the 3D aware branch is dropped."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) Interesting idea, the auxilary 3D aware branch  forces the backbone to be truly 3D-aware. This method also improves the alignment between different prediction heads and the depth/density head as they will be rendered following the physical imaging process.\n\n(2) Using 3D aware representation as an auxiliary branch only for regularization also enables fast inference, which is a new and interesting idea to me."
            },
            "weaknesses": {
                "value": "(1) The 3D aware branch uses Triplane representation and volumetric render, which needs a specific camera model (intrinsic matrix). So it is suspicious that the model can somehow overfit to the specific camera parameters.  As a comparison, pixel-aligned scene representation (i.e., PiFU) can resolve this problem and it uses NDC representation.\nFor scenes with different camera parameters, the performance is unclear.\n\n(2) Although the tri-plane representation has significantly reduced the memory cost and rendering of NeRF. Rendering the whole image and calculating the gradient is still a heavy burden. Common practice includes random sampling or pixel binning.  In the supplement material, there is an incomplete explanation. It is important to clarify the NeRF sampling implementation and extra training cost(memory footprint and FLOPS)"
            },
            "questions": {
                "value": "My main concerns are (1) the potential camera overfitting problem, and (2) The extra training cost introduced by the NeRF head."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2635/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828824774,
        "cdate": 1698828824774,
        "tmdate": 1699636203137,
        "mdate": 1699636203137,
        "license": "CC BY 4.0",
        "version": 2
    }
]