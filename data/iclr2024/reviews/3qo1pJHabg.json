[
    {
        "id": "AbEdcv7tvP",
        "forum": "3qo1pJHabg",
        "replyto": "3qo1pJHabg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_DMWE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_DMWE"
        ],
        "content": {
            "summary": {
                "value": "This work presents a study on improving object tracking performance on adversarial data while maintaining the model's superiority over clean data. The essence is building a spatial-temporal implicit representation using the semantic text guidance of the object of interest extracted from the language-image model. Then the novel representation is used to reconstruct incoming frames. Experimental results on different benchmarks show the effectiveness of the proposed framework. Overall, the paper sounds reasonable."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The writing is clear and easy to follow.\n- Introducing language embedding to adversarial training is interesting.\n- Reconstructing video frames to defend against adversarial attacks is reasonable.\n- Experimental results are sufficient."
            },
            "weaknesses": {
                "value": "- Although it's interesting to introduce nlp embedding in the adversarial defense framework, it sounds not so reasonable. Using a template seems enough for the purpose. Besides, single-object tracking is class-agnostic. What if the object class is unknown? How to run the proposed model in this situation?\n- Lack of experiments on more challenging benchmarks, e.g. trackingnet, tnl2k (Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark).\n- It is noticed that only SiamRPN++ is used as the baseline model. The baseline model is out of date. Do the effectiveness and conclusion still hold on recent transformer-based models, like OSTrack, SwinTrack, MixFormer? What if the tracking model is already able to track objects using natural language like the algorithms introduced in tnl2k."
            },
            "questions": {
                "value": "Please conduct experiments on recent trackers and provide results on more challenging and up-to-date benchmarks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698736494100,
        "cdate": 1698736494100,
        "tmdate": 1699636434280,
        "mdate": 1699636434280,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nCYWv4SYaQ",
        "forum": "3qo1pJHabg",
        "replyto": "3qo1pJHabg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_n1Fj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_n1Fj"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method to defend visual object tracking against adversarial attacks. They introduce a spatial-temporal implicit representation (STIR) that constructs neighboring pixels, and a language-driven resample network (LResampleNet) that provides consistency between reconstructed frames and object templates. They use the CLIP model to guide their approach. The effectiveness of their method is demonstrated through experiments on the OTB100, VOT2019, and UAV123 datasets, which show that it can effectively defend against recent VOT attack methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed method considers both the spatial and temporal information during defense, which is reasonable.\n2. Using the language-image model to guide the defense process is interesting.\n3. The experiments are thorough, including the defense results against various attack methods, as well as ablation studies on the efficiency of each component."
            },
            "weaknesses": {
                "value": "1. Provide visual comparisons among clean images, adversarial images, and the image after defense to show the visual effects and their difference. The tracking results should be added as well.\n2. For the experiments, the reviewer suggests that the authors compare with basic defense methods, including adversarial training and image preprocessing (e.g., resize or compression). And analyze the pros and cons between the proposed method and the defense methods mentioned above.\n3. In Table 1, for the results without defense, how to implement the attack is not clear. In other words, which attack method is selected for the results in Table 1?\n4. There are some minor problems, and the author should polish this paper again.\n- In Table1, defends -> defense?\n- In Table 2 and 3, IouAttack -> IoUAttack. It is a typo."
            },
            "questions": {
                "value": "1. Please supply the visual comparisons among clean images, adversarial images, and the image after defense.\n2. Please compare with other basic defense methods, like resizing or compression.\n3. Please state the details of the experiments in Table 1.\n4. Fix the typos and polish this paper again."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698894500851,
        "cdate": 1698894500851,
        "tmdate": 1699636434216,
        "mdate": 1699636434216,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9DyIrPTRDD",
        "forum": "3qo1pJHabg",
        "replyto": "3qo1pJHabg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_bxnS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4565/Reviewer_bxnS"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an adversarial defense method against recent attacks on visual object tracking. The defense method is guided by the language-image mode CLIP to reconstruct the area that has been perturbed by attacks. Two modules named the spatial-temporal implicit representation (STIR) and the language-driven resample network (LResampleNet) are involved in the whole framework to obtain a consistent representation. The experimental results against four attack methods are evaluated on three datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of using an image-language model (CLIP) to defend against adversarial attacks is interesting.\n2. The experiments show the effectiveness of the proposed defense against various types of adversarial attacks and can be applied to different trackers (e.g., CNN-based and transformer-based trackers)."
            },
            "weaknesses": {
                "value": "1. The proposed method basically relies on the reconstruction technology to destroy the distribution of perturbations. For VOT, does the proposed method reconstruct the whole search image? An intuitive and simple idea is to apply the inversion technology in StyleGAN or Diffusion on it, does it work? Please give some analysis on this point.\n2. Please provides some visual result on the difference between clean images and adversarial examples, and between clean images and defense examples, to show how the distribution of adversarial perturbations is reduced or suppressed. \n3. The writing of the paper needs to improve. Some results in supplementary materials can be combined in the main paper to better support the effectiveness of the proposed method."
            },
            "questions": {
                "value": "1. Please provide some analysis on directly implementing the inversion technology in StyleGAN or Diffusion.\n2. Please provide some visual results before and after attacks to intuitively illustrate how the adversarial perturbations are eliminated. \n3. Add the key results and analysis in supplementary materials to the main paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698897874898,
        "cdate": 1698897874898,
        "tmdate": 1699636434119,
        "mdate": 1699636434119,
        "license": "CC BY 4.0",
        "version": 2
    }
]