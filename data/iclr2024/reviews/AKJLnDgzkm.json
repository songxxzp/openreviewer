[
    {
        "id": "fzBCK4HvEN",
        "forum": "AKJLnDgzkm",
        "replyto": "AKJLnDgzkm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission413/Reviewer_A4aM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission413/Reviewer_A4aM"
        ],
        "content": {
            "summary": {
                "value": "The authors aim to promote societal safety by assisting researchers in developing and assessing multi-agent AI systems. They propose a new benchmark called Welfare Diplomacy for measuring the cooperative capabilities of AI systems., and introduce a general-sum variant of the zero-sum board game Diplomacy, where players must balance military conquest and domestic welfare. They implement the rules of Welfare Diplomacy using an open-source Diplomacy engine and construct baseline agents using zero-shot prompted language models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe authors introduce Welfare Diplomacy (WD) and provide an implementation in an open-source Diplomacy library.\n2.\tThis paper provides theoretical and empirical evidence highlighting the benefits of WD compared to the existing benchmark, Zero-Sum Diplomacy (SD).\n3.\tThe authors develop a language model (LM) scaffolding system to create competent zero-shot baseline agents for WD."
            },
            "weaknesses": {
                "value": "1. Pareto-efficient equilibria are often not stable\uff0cand there may be various factors that can lead to deviations from the equilibrium, such as imperfect information, externalities, or strategic behavior. These deviations can disrupt the equilibrium and lead to a new outcome that is not Pareto-efficient.\n2. It is challenging to attain Pareto-efficient equilibria, and how to achieve optimal Nash welfare remains unclear."
            },
            "questions": {
                "value": "1.\tAs this paper aims to enhance societal safety by aiding researchers in the development and evaluation of multi-agent AI systems, could you please provide examples that illustrate the potential benefits of using benchmarks in real-world scenarios?\n2.\tDespite the existence of multiple Pareto-efficient Nash Equilibria (NEs), they often display instability, particularly in complex or realistic scenarios. How can we effectively tackle this challenge?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698309260553,
        "cdate": 1698309260553,
        "tmdate": 1699635968022,
        "mdate": 1699635968022,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uy57XuI8LQ",
        "forum": "AKJLnDgzkm",
        "replyto": "AKJLnDgzkm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Welfare Diplomacy, a variant of the game of Diplomacy that incorporates the balancing of military conquest and domestic welfare. The authors evaluate the proposed variant by developing language model-based agents and comparing different state-of-the-art language models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The game of diplomacy is an important challenge in multi-agent research, and the concept of welfare diplomacy is interesting. \n2.  The paper effectively explains the differences between the proposed game and existing benchmarks. By making two modifications to the game rules, the nature of the game has been altered, incentivizing players to pursue peace and promoting cooperation.\n3. The proposed game and prompts are open-sourced, and experimental results are extensive."
            },
            "weaknesses": {
                "value": "1. Some arguments regarding the motivations of welfare diplomacy lack rigor and may be questionable. It has been repeatedly claimed in the paper that \"While Standard Diplomacy (SD) has features that make it interesting as an environment for cooperative AI research, it is zero-sum and incentivizes the development of cooperation-undermining capabilities\" and `In contrast to SD, WD is general-sum'.  However, it has been pointed out in [1] that \"In Diplomacy, seven players... coordinate their actions to both cooperate and compete with each other,\" suggesting that standard diplomacy is not necessarily a zero-sum game. If standard diplomacy were indeed zero-sum, cooperation would not be involved, similar to chess and heads-up poker.\n\n2. The theoretical results are hard to interpret. It would be helpful to clarify the meaning of $\\pi^k$ as a NE and how Theorem 1 relates to the main claim.\n\n3. Some important technical details lack clarity. The terms \"zero-shot prompted language model\", \"zero-shot baseline\" and \"zero-shot evaluations\" are used throughout the paper without any specific explanation. Additionally, it would be helpful to provide justification for constructing the exploiter in the paper. Does there exist any agent that has better exploitative power?\n\n[1] \"Human-level play in the game of Diplomacy by combining language models with strategic reasoning\", Science 2022."
            },
            "questions": {
                "value": "I would like to see responses to the aforementioned weaknesses.\n\nIn addition, I have a question about the metric \"basic proficiency\". Currently, it is the mean of \"the rate of model outputs that are valid JSON and thus able to be parsed without error, the rate of submitted orders that are valid possible orders, and the fraction of global SCs owned by any player and not left neutral.\" While the first two are understandable, I don't understand why the fraction of global SCs should be considered as an aspect of 'basic proficiency'. To me, it is more like a metric about social welfare."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698375705193,
        "cdate": 1698375705193,
        "tmdate": 1699635967928,
        "mdate": 1699635967928,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Vf4QGmWwkK",
        "forum": "AKJLnDgzkm",
        "replyto": "AKJLnDgzkm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Welfare Diplomacy (WD), a variant of Diplomacy that considers more about agent cooperation. The paper offers \n(1) Motivation and illustration of environment design \n(2) Nash equilibrium analysis of WD\n(3) Experiments that benchmark different LLM models' Nash Welfare and exploitability."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall I think this is a great paper, the strengths can be addressed as follows:\n(1) The paper is clearly written and easy to follow.\n(2) The paper proposes a new environment variant to benchmark the agent cooperation ability and clearly illustrate the motivation.\n(3) The paper offers a theoretical analysis of its proposed environment and verifies the reasonability of the proposed environment.\n(4) The experiments successfully help benchmark the agent cooperation ability."
            },
            "weaknesses": {
                "value": "The weaknesses are summarized as follows:\n\n(1) The author can try to include more experiment results and ablation studies such as prompt sensitivity, hyperparameter effects, etc.\n(2) The author should try to incorporate human-LLM mixed experiments to see how human engagement can influence LLM performance.\n(3) Some human analysis of LLM's policy should be conducted to better understand LLM's performance."
            },
            "questions": {
                "value": "I have the following questions and suggestions:\n1. There exist several typos in the paper, e.g. in the first line of section 3 certain NEs certain NEs.\n2. Can the authors elaborate more on how the theoretical analysis simplifies the real WD game in section 3.2.1 and theorem 1 and what is the gap between the theoretical analysis and the real WD game?\n3. I recommend the author slightly modify the title as the cooperation discussed in the paper is the cooperation in a general-sum game. It can help distinguish itself from the fully cooperative setting.\n4. From my perspective, what differentiates the current LLM agent from the previous agent is the ability of the agent to communicate with other agents using language. As shown in the paper, there exist some Pareto efficient policies theoretically. I am a little bit worried about, why bother LLM to do such thing if we can theoretically derive the optimal action (I understand this is a game of language so a language encoder is necessary, but you can also train a language-based RL agent to purely output action). What do the authors think the language communication here can help? My first thought is that communication here can be used during the bargain game and help the equilibrium selection. Can the language help in some other cases (like helping policies but it again fails in the case if you can theoretically derive some optimal action)?\n5. It seems most models, except advanced LLMs like GPT-4, cannot have policies that are significantly better than the random baseline, what could be the reasons?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission413/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission413/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793880081,
        "cdate": 1698793880081,
        "tmdate": 1699635967860,
        "mdate": 1699635967860,
        "license": "CC BY 4.0",
        "version": 2
    }
]