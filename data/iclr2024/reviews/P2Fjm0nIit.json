[
    {
        "id": "eiXAKq11pg",
        "forum": "P2Fjm0nIit",
        "replyto": "P2Fjm0nIit",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_L3yU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_L3yU"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel compression method for grid-based NeRF models, such as TensoRF. It optimized three latent codes and a decoder during training time, after training the full feature grid was omitted to reduce storage size. To achieve original rendering quality it directly reconstructs the full resolution feature plane with the learned latent code and decoder. Furthermore, an importance-weighted training loss was adopted to push the optimization focus on grid location that contributes more in rendering and a binary entropy mask to further reduce redundancy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The semantics of the paper is smooth, and the proposed method is simple yet effective, it achieves better performance than previous methods that have a more sophisticated procedure, and the overall framework is very straightforward, so there should be no difficulty for other to reproduce."
            },
            "weaknesses": {
                "value": "1. The improvement over the previous method is not so significant,  the TC-TensoRF-L only shows notable improvement in the LLFF dataset, while in other datasets, it only brings minor performance gain in both visual quality\uff08PSNR\uff09and storage size. Though it provides a trade-off curve against VQ-TensoRF, the author only changed the codebook size of VQ-TensoRF, which may indicate that the curve was not drawn on the optimal hyper-parameter for VQ-TensoRF.\n\n2.  Though the author has discussed DVGO and Plenoxels and tends to treat applying compression to those methods as a future work, I believe this could be a major weakness to not showing that the proposed is capable of generalize to other grid-based methods. As those methods have different design methodology e.g. plenoxels is already sparse and do not rely on MLP to recover feature in grid point. and it is important to show the proposed transform coding can still work for different types of grid-based nerf."
            },
            "questions": {
                "value": "what is the final composition of the storage size? It would be better to display the composition in a chart or figure to help others better understand the proposed method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6958/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6958/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6958/Reviewer_L3yU"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6958/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698595105282,
        "cdate": 1698595105282,
        "tmdate": 1699636812657,
        "mdate": 1699636812657,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7WH4I7LBSm",
        "forum": "P2Fjm0nIit",
        "replyto": "P2Fjm0nIit",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_n1mE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_n1mE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to compress the NeRF model\u2019s feature grids using end-to-end optimized neural compression. By transmitting the latent code and a lightweight decoder, this method can significantly reduce the storage costs of NeRFs. Experiments on different\ndatasets show that this method is capable of compressing diverse NeRF scenes to a smaller size and outperforms previous works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper is overall well-written and easy to read. \n\n2) The proposed method applies a neural transform coding framework to compress the feature planes in NeRF. The overall performance is good, especially at relatively low bitrates. This method can be treated as a new route for NeRF compression besides network pruning and quantization."
            },
            "weaknesses": {
                "value": "1) Compared with existing work like VQ-TensorRF, the performance gain of the proposed method under a similar compression ratio is marginal in some cases (for low compression). Besides, this work is currently only designed for feature plane-based NeRF methods while other compared methods are more generalized.\n\n2) The training and rendering time, especially the time needed for compressing and decompressing the features should be provided and compared with previous works.\n\n3) The overall contribution of this paper is not sufficient enough. The transform coding framework is also similar to existing frameworks in image and video compression."
            },
            "questions": {
                "value": "The author proposed the latent decoder without an encoder. It will better demonstrate the efficiency by also showing the performance of a compressor with both an encoder and decoder during training and then drop the encoder during inference."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6958/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668214906,
        "cdate": 1698668214906,
        "tmdate": 1699636812544,
        "mdate": 1699636812544,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gHblRt88HO",
        "forum": "P2Fjm0nIit",
        "replyto": "P2Fjm0nIit",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_GuYn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6958/Reviewer_GuYn"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel method for efficiently compressing a grid-based NeRF model. It utilizes neural compression method to compress the model's feature grids. Specifically, the authors design an encoder-free architecture with a lightweight decoder, and present a weighted-rate-distortion loss incorporated a masked entropy coding mechanism to reduce redundance. The results show that the proposed method outperforms existing works."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well-written and effectively communicates the proposed method and its technical details. The authors provide clear explanations of the neural compression based framework.\n2. The paper introduces a novel neural compression based framework for NeRF, which is a unique approach compared to existing compression methods that rely on pruning or vector quantization."
            },
            "weaknesses": {
                "value": "1. While the introduction of a neural compression method to encode the grid representation has demonstrated superior RD performance, the underlying motivation for this approach is not adequately elucidated\n\n2. The novelty of this paper is not sufficient. The introduction of the weighted-rate-distortion loss lacks significant new contributions, as it heavily relies on an existing importance score calculation method [1]. The proposed binary mask entropy coding resembles the concept of importance map-based bit allocation schemes, such as in [2]. Moreover, the compression method falls short in considering contextual information for further reduction of spatial redundancy.\n\n[1] Compressing Volumetric Radiance Fields to 1 MB. CVPR 2023.\n[2] Learning End-to-End Lossy Image Compression: A Benchmark. TPAMI 2022.\n\n3. It would be beneficial to include a comparison of the training time between the proposed method and other established methods. Additionally, the paper should provide a more precise breakdown of the storage sizes for each component, including the decoder, entropy model, binary mask, and grid feature.\n\n4. The term 'transform coding' in the paper's title may not be entirely appropriate, as the paper employs an encoder-free framework that directly learns the latent code without involving analysis transforms within the coding paradigm"
            },
            "questions": {
                "value": "1.\"What are the advantages of the proposed compression method when compared to existing pruning or vector quantization methods?\"\n2.\"Have the authors considered the results of incorporating an encoder and training the entire network end-to-end?\"\n3.\"It is recommended that the authors provide a detailed breakdown of the storage size for each component to offer a more comprehensive understanding.\"\n4. In Figure 5, I noticed that the blue curve (TC-TensoRF-L) is situated below the orange (w/ Factorized Prior) and green (w/o Importance Weight) curves in the lower bitrate range. Could you please provide an explanation for this observation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6958/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698674351558,
        "cdate": 1698674351558,
        "tmdate": 1699636812287,
        "mdate": 1699636812287,
        "license": "CC BY 4.0",
        "version": 2
    }
]