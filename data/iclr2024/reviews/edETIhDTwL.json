[
    {
        "id": "y0at0BwtbA",
        "forum": "edETIhDTwL",
        "replyto": "edETIhDTwL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_zx9B"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_zx9B"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an end-to-end physiological signal emotion recognition model, and it achieved first place in all four tracks of the EPiC Challenge. Building upon the FED-Former, the model incorporates Two-Stage Attention (TSA) to capture temporal dependencies in the data. The paper implements multi-task learning for valence and arousal prediction tasks. The main contributions of the paper are as follows: 1. It proposes an end-to-end emotion recognition model based on physiological signals. 2. It enhances the FED-Former model to capture temporal dependencies between data. 3. The model performs exceptionally well across four tasks: Across-time scenario, Across-subject scenario, Across-elicitor scenario, and Across-version scenario."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "#originality:\nThis paper demonstrates a good level of originality. Firstly, it addresses a problem in the field related to long-term time series forecasting in the time domain. Secondly, the proposed solution is simple yet effective. Although its overall structure is quite similar to FED-Former, the use of Two-stage Attention proves to be innovative and efficient. Furthermore, it performs well in scenarios across all four tasks, highlighting the model's originality.\n\n#quality:\nThe quality of this work is relatively mediocre, mainly due to issues with experimental rigor, especially the lack of comprehensive model comparisons and tasks. Although the paper shines in terms of the model's performance, conducting more comparisons with traditional tasks would significantly enhance the paper's quality. The methodological rigor and reliability require improvement. There are also concerns regarding the overall presentation of results, figures, and tables, as there is a lack of graphical representation, and the experimental results are relatively limited.\n\n#clarity:\nThe clarity of this paper is relatively good, but there is still room for improvement. The content is well-structured, with logical connections throughout. However, there are some drawbacks: 1. The representation of certain letters is not very intuitive and may lead to confusion. 2. There is a lack of illustrations, making the descriptions less visually informative. 3. In the 'METHODOLOGY' section, the explanation of sequence length is somewhat disjointed and may not be easily understood by readers. 4. The description of the resolution DSW embedding is not very clear.\n\n#significance:\nThe limited experimental results are a significant factor affecting its impact. If there were more comprehensive experimental results, this paper would have a significant impact. It has made a substantial contribution to the field by addressing the capture of long-term temporal dependencies in the time domain through an end-to-end model. While the preprocessing stage may pose some challenges, the practical utility of the model surpasses that of a simple machine learning classification model. It also avoids the need for complex feature engineering."
            },
            "weaknesses": {
                "value": "1. The originality of the model's architecture is somewhat limited. Despite its focus on temporal considerations, it relies on a frequency domain model, and its fundamental structure closely resembles that of FED-Former.\n\n2. The model's real-world applicability raises questions. While it exhibits strong performance in just four tasks from a single competition, it lacks comprehensive comparisons with other existing models, making its effectiveness less persuasive. To bolster your argument, I recommend introducing additional datasets for comparative analysis, thereby reinforcing the model's practical utility."
            },
            "questions": {
                "value": "Questions:\n\nIn the methodology section, could you elaborate more on the sources and rationale behind your ideas, rather than merely describing the structure? In the EXPERIMENT SETTINGS section, could you provide specific details about your experiment's hyperparameters to facilitate model reproducibility for readers?\n\nSuggestions:\n\nTo enhance the paper, start by conducting experiments on a broader spectrum of datasets to evaluate the model's performance and establish its feasibility. Make an effort to include comparative analyses with other existing models wherever applicable. Additionally, aim to incorporate more visual aids to offer a more lucid representation of your concepts. Given the numerous symbols within your paper, improving the intuitiveness of these notations is essential.\n\n\n---------After rebuttal--------------\nThank the authors for providing the rebuttal. I have read the rebuttal and the other reviews. Based on the limited originality and the insufficient ablation studies as pointed out by other reviews, I decreased my rating to marginally below the acceptance threshold. Please consider the reviews and the rebuttal carefully for another submission."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Reviewer_zx9B"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8530/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698556358656,
        "cdate": 1698556358656,
        "tmdate": 1700721334239,
        "mdate": 1700721334239,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0QAf89WzPd",
        "forum": "edETIhDTwL",
        "replyto": "edETIhDTwL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_8PZe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_8PZe"
        ],
        "content": {
            "summary": {
                "value": "This study proposes a new method to analyze the link between physiological signals and emotional changes. By using a transformer-based model, the authors shift the focus from emotion recognition to predicting sequences of multivariate time series data. They employ a two-stage attention mechanism to process these signals, and through multitask learning, improve the prediction of two emotional states: valence and arousal. The model, when tested on a specific dataset, outperformed other methods from a related challenge in all evaluated scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The authors achieved SOTA performance on the EPiC challenge dataset."
            },
            "weaknesses": {
                "value": "1. I am having trouble seeing the contributions of this paper. It seems like the authors have used an existing model and fitted it on a new dataset. The authors have not tested whether the model is generalizable to other affective datasets. If authors could point out some key aspects of the papers contributions a bit more clearly it would be greatly appreciated. \n2. The interpretability of the results seem a bit lacking. Why does the author's proposed method outperform other participant's methods? Additionally, table 1 has a row labeled \"Scenario level.\" Could the authors clarify what this means?"
            },
            "questions": {
                "value": "1. Have the authors considered doing an ablation study on which physiological signals may be contributing the most to the performance? \n2. The authors mention that they \"capture the relationship between physiological signals and affective changes.\" Could you clarify to me how this relationship is captured with this model?\n3. This paper was submitted to the \"Primary Area: applications to neuroscience & cognitive science.\" I am having a bit of trouble seeing this paper's contribution to this area. Could the authors clarify this?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8530/Reviewer_8PZe"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8530/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698717075272,
        "cdate": 1698717075272,
        "tmdate": 1699637066566,
        "mdate": 1699637066566,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "90QQAEBaFm",
        "forum": "edETIhDTwL",
        "replyto": "edETIhDTwL",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_s9qV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8530/Reviewer_s9qV"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a transformer-based solution for physiological signal emotion recognition, by converting the recognition task to a multivariate time prediction task. The authors decompose the signals into separate time and frequency domain representations using self-attention mechanisms and capture channel dependencies. The proposed system outperforms other participants in the Emotion Physiology and Experience Collaboration challenge."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The authors utilizes some state-of-the-art mechanisms, such as wavelet and Fourier attention, to decompose the physiological signals into separate frequency domain and time domain representations.\n2. The authors introduce a two-stage attention mechanism to capture the dependencies between signals. This addresses the challenge of having both cross-time and cross-dimension dependencies and improves the model's ability."
            },
            "weaknesses": {
                "value": "1. There should be more ablation studies to prove each component in the proposed method works.\n2. The related work section introduces some references and attention mechanisms that the authors used, without the information about the following compared works. \n3. The replace of the MSAs in the encoder should have evidence to prove its rationality and efficiency, so as the frequency and time domain TSA in the decoders.\n4. Many simple formula notations are cumbersome, for example, we have long been familiar with the attention mechanisms."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8530/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722543797,
        "cdate": 1698722543797,
        "tmdate": 1699637066440,
        "mdate": 1699637066440,
        "license": "CC BY 4.0",
        "version": 2
    }
]